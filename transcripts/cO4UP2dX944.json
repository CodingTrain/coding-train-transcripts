{
  "id": "rvweabzbvjhmmgmputhnt7xuz4",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/cO4UP2dX944.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/86315 [00:00<?, ?frames/s]\n  3%|▎         | 2624/86315 [00:05<02:51, 487.34frames/s]\n  6%|▋         | 5496/86315 [00:11<02:42, 498.07frames/s]\n  9%|▉         | 8140/86315 [00:16<02:40, 487.65frames/s]\n 13%|█▎        | 10876/86315 [00:22<02:33, 492.17frames/s]\n 16%|█▌        | 13802/86315 [00:28<02:34, 469.33frames/s]\n 19%|█▉        | 16674/86315 [00:34<02:22, 490.36frames/s]\n 23%|██▎       | 19422/86315 [00:39<02:13, 499.31frames/s]\n 26%|██▌       | 22306/86315 [00:45<02:10, 492.16frames/s]\n 29%|██▉       | 25206/86315 [00:52<02:09, 472.93frames/s]\n 33%|███▎      | 28156/86315 [01:00<02:13, 434.40frames/s]\n 36%|███▌      | 30924/86315 [01:09<02:24, 384.61frames/s]\n 39%|███▉      | 33664/86315 [01:18<02:31, 348.21frames/s]\n 42%|████▏     | 36476/86315 [01:28<02:31, 329.55frames/s]\n 46%|████▌     | 39408/86315 [01:38<02:26, 319.37frames/s]\n 49%|████▉     | 42228/86315 [01:48<02:23, 306.61frames/s]\n 52%|█████▏    | 45212/86315 [01:57<02:11, 313.28frames/s]\n 56%|█████▌    | 48004/86315 [02:06<02:03, 309.87frames/s]\n 59%|█████▊    | 50576/86315 [02:13<01:49, 327.80frames/s]\n 62%|██████▏   | 53572/86315 [02:20<01:32, 352.74frames/s]\n 65%|██████▌   | 56492/86315 [02:25<01:15, 396.02frames/s]\n 69%|██████▉   | 59416/86315 [02:30<01:00, 447.81frames/s]\n 72%|███████▏  | 62296/86315 [02:37<00:54, 437.50frames/s]\n 75%|███████▌  | 65108/86315 [02:44<00:49, 428.60frames/s]\n 79%|███████▊  | 67868/86315 [02:53<00:48, 377.28frames/s]\n 81%|████████▏ | 70326/86315 [03:01<00:44, 360.66frames/s]\n 85%|████████▍ | 73090/86315 [03:10<00:38, 345.02frames/s]\n 88%|████████▊ | 76046/86315 [03:17<00:28, 365.91frames/s]\n 92%|█████████▏| 78982/86315 [03:23<00:18, 391.63frames/s]\n 94%|█████████▎| 80902/86315 [03:28<00:13, 391.73frames/s]\n 97%|█████████▋| 83798/86315 [03:35<00:06, 400.76frames/s]\n 99%|█████████▊| 85226/86315 [03:40<00:02, 365.33frames/s]\n99%|█████████▊| 85226/86315 [03:52<00:02, 366.72frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.26616216960706207,
        "compression_ratio": 1.5817490494296578,
        "end": 6.48,
        "id": 0,
        "no_speech_prob": 0.007575128227472305,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello and welcome to another beginner's guide to machine learning with ml5js in JavaScript.",
        "tokens": [
          50364,
          2425,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          281,
          3479,
          2539,
          365,
          23271,
          20,
          25530,
          294,
          15778,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.26616216960706207,
        "compression_ratio": 1.5817490494296578,
        "end": 10.44,
        "id": 1,
        "no_speech_prob": 0.007575128227472305,
        "seek": 0,
        "start": 6.48,
        "temperature": 0,
        "text": " So I'm here, it's been a while since I added a video to this playlist and a bunch of things",
        "tokens": [
          50688,
          407,
          286,
          478,
          510,
          11,
          309,
          311,
          668,
          257,
          1339,
          1670,
          286,
          3869,
          257,
          960,
          281,
          341,
          16788,
          293,
          257,
          3840,
          295,
          721,
          50886
        ]
      },
      {
        "avg_logprob": -0.26616216960706207,
        "compression_ratio": 1.5817490494296578,
        "end": 13.48,
        "id": 2,
        "no_speech_prob": 0.007575128227472305,
        "seek": 0,
        "start": 10.44,
        "temperature": 0,
        "text": " about the ml5 library itself have changed.",
        "tokens": [
          50886,
          466,
          264,
          23271,
          20,
          6405,
          2564,
          362,
          3105,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.26616216960706207,
        "compression_ratio": 1.5817490494296578,
        "end": 17.080000000000002,
        "id": 3,
        "no_speech_prob": 0.007575128227472305,
        "seek": 0,
        "start": 13.48,
        "temperature": 0,
        "text": " There's a new release, 0.3.1.",
        "tokens": [
          51038,
          821,
          311,
          257,
          777,
          4374,
          11,
          1958,
          13,
          18,
          13,
          16,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.26616216960706207,
        "compression_ratio": 1.5817490494296578,
        "end": 21.72,
        "id": 4,
        "no_speech_prob": 0.007575128227472305,
        "seek": 0,
        "start": 17.080000000000002,
        "temperature": 0,
        "text": " There is a brand new website which you can find right here at ml5js.org.",
        "tokens": [
          51218,
          821,
          307,
          257,
          3360,
          777,
          3144,
          597,
          291,
          393,
          915,
          558,
          510,
          412,
          23271,
          20,
          25530,
          13,
          4646,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.26616216960706207,
        "compression_ratio": 1.5817490494296578,
        "end": 26.240000000000002,
        "id": 5,
        "no_speech_prob": 0.007575128227472305,
        "seek": 0,
        "start": 21.72,
        "temperature": 0,
        "text": " So to some extent this video is really an update about the library, but I'm also going",
        "tokens": [
          51450,
          407,
          281,
          512,
          8396,
          341,
          960,
          307,
          534,
          364,
          5623,
          466,
          264,
          6405,
          11,
          457,
          286,
          478,
          611,
          516,
          51676
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 31.64,
        "id": 6,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 26.24,
        "temperature": 0,
        "text": " to look at one particular feature, a new feature of the library, sound classification.",
        "tokens": [
          50364,
          281,
          574,
          412,
          472,
          1729,
          4111,
          11,
          257,
          777,
          4111,
          295,
          264,
          6405,
          11,
          1626,
          21538,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 36,
        "id": 7,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 31.64,
        "temperature": 0,
        "text": " The machine learning model that I'm going to use in this video is the speech command",
        "tokens": [
          50634,
          440,
          3479,
          2539,
          2316,
          300,
          286,
          478,
          516,
          281,
          764,
          294,
          341,
          960,
          307,
          264,
          6218,
          5622,
          50852
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 37,
        "id": 8,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 36,
        "temperature": 0,
        "text": " recognizer.",
        "tokens": [
          50852,
          3068,
          6545,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 42.959999999999994,
        "id": 9,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 37,
        "temperature": 0,
        "text": " And this is a model available from Google as part of TensorFlow.js models.",
        "tokens": [
          50902,
          400,
          341,
          307,
          257,
          2316,
          2435,
          490,
          3329,
          382,
          644,
          295,
          37624,
          13,
          25530,
          5245,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 44.599999999999994,
        "id": 10,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 42.959999999999994,
        "temperature": 0,
        "text": " Now so this is a really important distinction.",
        "tokens": [
          51200,
          823,
          370,
          341,
          307,
          257,
          534,
          1021,
          16844,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 48.2,
        "id": 11,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 44.599999999999994,
        "temperature": 0,
        "text": " I am not here to train a sound classifier.",
        "tokens": [
          51282,
          286,
          669,
          406,
          510,
          281,
          3847,
          257,
          1626,
          1508,
          9902,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 52.4,
        "id": 12,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 48.2,
        "temperature": 0,
        "text": " I might do that in a future video and show you about how to apply transfer learning,",
        "tokens": [
          51462,
          286,
          1062,
          360,
          300,
          294,
          257,
          2027,
          960,
          293,
          855,
          291,
          466,
          577,
          281,
          3079,
          5003,
          2539,
          11,
          51672
        ]
      },
      {
        "avg_logprob": -0.24377195500145274,
        "compression_ratio": 1.6508474576271186,
        "end": 54.959999999999994,
        "id": 13,
        "no_speech_prob": 0.030673058703541756,
        "seek": 2624,
        "start": 52.4,
        "temperature": 0,
        "text": " which is something I did with images, also to sounds.",
        "tokens": [
          51672,
          597,
          307,
          746,
          286,
          630,
          365,
          5267,
          11,
          611,
          281,
          3263,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2534678695548294,
        "compression_ratio": 1.6231884057971016,
        "end": 60.76,
        "id": 14,
        "no_speech_prob": 0.008984913118183613,
        "seek": 5496,
        "start": 54.96,
        "temperature": 0,
        "text": " I'm just going to make use of a freely available pre-trained machine learning model.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          652,
          764,
          295,
          257,
          16433,
          2435,
          659,
          12,
          17227,
          2001,
          3479,
          2539,
          2316,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.2534678695548294,
        "compression_ratio": 1.6231884057971016,
        "end": 65.36,
        "id": 15,
        "no_speech_prob": 0.008984913118183613,
        "seek": 5496,
        "start": 60.76,
        "temperature": 0,
        "text": " Anytime you use one of those things, even in just a playful and experimental way, which",
        "tokens": [
          50654,
          39401,
          291,
          764,
          472,
          295,
          729,
          721,
          11,
          754,
          294,
          445,
          257,
          30730,
          293,
          17069,
          636,
          11,
          597,
          50884
        ]
      },
      {
        "avg_logprob": -0.2534678695548294,
        "compression_ratio": 1.6231884057971016,
        "end": 69.08,
        "id": 16,
        "no_speech_prob": 0.008984913118183613,
        "seek": 5496,
        "start": 65.36,
        "temperature": 0,
        "text": " is what I'm doing, it's good to do a little bit of research and take a look at, well,",
        "tokens": [
          50884,
          307,
          437,
          286,
          478,
          884,
          11,
          309,
          311,
          665,
          281,
          360,
          257,
          707,
          857,
          295,
          2132,
          293,
          747,
          257,
          574,
          412,
          11,
          731,
          11,
          51070
        ]
      },
      {
        "avg_logprob": -0.2534678695548294,
        "compression_ratio": 1.6231884057971016,
        "end": 70.12,
        "id": 17,
        "no_speech_prob": 0.008984913118183613,
        "seek": 5496,
        "start": 69.08,
        "temperature": 0,
        "text": " how is this trained?",
        "tokens": [
          51070,
          577,
          307,
          341,
          8895,
          30,
          51122
        ]
      },
      {
        "avg_logprob": -0.2534678695548294,
        "compression_ratio": 1.6231884057971016,
        "end": 71.12,
        "id": 18,
        "no_speech_prob": 0.008984913118183613,
        "seek": 5496,
        "start": 70.12,
        "temperature": 0,
        "text": " What was the data?",
        "tokens": [
          51122,
          708,
          390,
          264,
          1412,
          30,
          51172
        ]
      },
      {
        "avg_logprob": -0.2534678695548294,
        "compression_ratio": 1.6231884057971016,
        "end": 75.12,
        "id": 19,
        "no_speech_prob": 0.008984913118183613,
        "seek": 5496,
        "start": 71.12,
        "temperature": 0,
        "text": " What are the considerations around how the data was collected?",
        "tokens": [
          51172,
          708,
          366,
          264,
          24070,
          926,
          577,
          264,
          1412,
          390,
          11087,
          30,
          51372
        ]
      },
      {
        "avg_logprob": -0.2534678695548294,
        "compression_ratio": 1.6231884057971016,
        "end": 81.4,
        "id": 20,
        "no_speech_prob": 0.008984913118183613,
        "seek": 5496,
        "start": 75.12,
        "temperature": 0,
        "text": " And so I encourage you to read through the readme here on GitHub, and in particular to",
        "tokens": [
          51372,
          400,
          370,
          286,
          5373,
          291,
          281,
          1401,
          807,
          264,
          1401,
          1398,
          510,
          322,
          23331,
          11,
          293,
          294,
          1729,
          281,
          51686
        ]
      },
      {
        "avg_logprob": -0.312580865004967,
        "compression_ratio": 1.543726235741445,
        "end": 86.72,
        "id": 21,
        "no_speech_prob": 0.33452439308166504,
        "seek": 8140,
        "start": 81.4,
        "temperature": 0,
        "text": " click over and read the original paper about this speech commands model.",
        "tokens": [
          50364,
          2052,
          670,
          293,
          1401,
          264,
          3380,
          3035,
          466,
          341,
          6218,
          16901,
          2316,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.312580865004967,
        "compression_ratio": 1.543726235741445,
        "end": 91.08000000000001,
        "id": 22,
        "no_speech_prob": 0.33452439308166504,
        "seek": 8140,
        "start": 86.72,
        "temperature": 0,
        "text": " And there you'll see, if you look, it talks about some of the data sets, like Mozilla's",
        "tokens": [
          50630,
          400,
          456,
          291,
          603,
          536,
          11,
          498,
          291,
          574,
          11,
          309,
          6686,
          466,
          512,
          295,
          264,
          1412,
          6352,
          11,
          411,
          3335,
          26403,
          311,
          50848
        ]
      },
      {
        "avg_logprob": -0.312580865004967,
        "compression_ratio": 1.543726235741445,
        "end": 96,
        "id": 23,
        "no_speech_prob": 0.33452439308166504,
        "seek": 8140,
        "start": 91.08000000000001,
        "temperature": 0,
        "text": " common voice data set, 500 hours from 20,000 different people.",
        "tokens": [
          50848,
          2689,
          3177,
          1412,
          992,
          11,
          5923,
          2496,
          490,
          945,
          11,
          1360,
          819,
          561,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.312580865004967,
        "compression_ratio": 1.543726235741445,
        "end": 100.44,
        "id": 24,
        "no_speech_prob": 0.33452439308166504,
        "seek": 8140,
        "start": 96,
        "temperature": 0,
        "text": " This Libre speech, 1,000 hours of read English speech.",
        "tokens": [
          51094,
          639,
          15834,
          265,
          6218,
          11,
          502,
          11,
          1360,
          2496,
          295,
          1401,
          3669,
          6218,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.312580865004967,
        "compression_ratio": 1.543726235741445,
        "end": 101.44,
        "id": 25,
        "no_speech_prob": 0.33452439308166504,
        "seek": 8140,
        "start": 100.44,
        "temperature": 0,
        "text": " I don't know how to say this.",
        "tokens": [
          51316,
          286,
          500,
          380,
          458,
          577,
          281,
          584,
          341,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.312580865004967,
        "compression_ratio": 1.543726235741445,
        "end": 107.76,
        "id": 26,
        "no_speech_prob": 0.33452439308166504,
        "seek": 8140,
        "start": 101.44,
        "temperature": 0,
        "text": " Tidy digits, tididits, t-digits, 25,000 digit sequences, which apparently was probably me,",
        "tokens": [
          51366,
          314,
          38836,
          27011,
          11,
          9422,
          327,
          1208,
          11,
          256,
          12,
          25259,
          1208,
          11,
          3552,
          11,
          1360,
          14293,
          22978,
          11,
          597,
          7970,
          390,
          1391,
          385,
          11,
          51682
        ]
      },
      {
        "avg_logprob": -0.312580865004967,
        "compression_ratio": 1.543726235741445,
        "end": 108.76,
        "id": 27,
        "no_speech_prob": 0.33452439308166504,
        "seek": 8140,
        "start": 107.76,
        "temperature": 0,
        "text": " right?",
        "tokens": [
          51682,
          558,
          30,
          51732
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 112.4,
        "id": 28,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 108.76,
        "temperature": 0,
        "text": " It was probably hours and hours of me reading this random number book over and over again.",
        "tokens": [
          50364,
          467,
          390,
          1391,
          2496,
          293,
          2496,
          295,
          385,
          3760,
          341,
          4974,
          1230,
          1446,
          670,
          293,
          670,
          797,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 114.92,
        "id": 29,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 112.4,
        "temperature": 0,
        "text": " But so I encourage you to check out this paper.",
        "tokens": [
          50546,
          583,
          370,
          286,
          5373,
          291,
          281,
          1520,
          484,
          341,
          3035,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 122.08000000000001,
        "id": 30,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 114.92,
        "temperature": 0,
        "text": " And you can also find code for how to use this model at TensorFlow.js in the TF.js models",
        "tokens": [
          50672,
          400,
          291,
          393,
          611,
          915,
          3089,
          337,
          577,
          281,
          764,
          341,
          2316,
          412,
          37624,
          13,
          25530,
          294,
          264,
          40964,
          13,
          25530,
          5245,
          51030
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 123.08000000000001,
        "id": 31,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 122.08000000000001,
        "temperature": 0,
        "text": " GitHub repo itself.",
        "tokens": [
          51030,
          23331,
          49040,
          2564,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 127.28,
        "id": 32,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 123.08000000000001,
        "temperature": 0,
        "text": " I also want to interrupt this video for a second to talk about how the sound classifier",
        "tokens": [
          51080,
          286,
          611,
          528,
          281,
          12729,
          341,
          960,
          337,
          257,
          1150,
          281,
          751,
          466,
          577,
          264,
          1626,
          1508,
          9902,
          51290
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 128.28,
        "id": 33,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 127.28,
        "temperature": 0,
        "text": " actually works.",
        "tokens": [
          51290,
          767,
          1985,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 130.82,
        "id": 34,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 128.28,
        "temperature": 0,
        "text": " This is kind of a surprising little tidbit.",
        "tokens": [
          51340,
          639,
          307,
          733,
          295,
          257,
          8830,
          707,
          9422,
          5260,
          13,
          51467
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 135.42000000000002,
        "id": 35,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 130.82,
        "temperature": 0,
        "text": " And I'll come back to this more if at some point I create a video about training your",
        "tokens": [
          51467,
          400,
          286,
          603,
          808,
          646,
          281,
          341,
          544,
          498,
          412,
          512,
          935,
          286,
          1884,
          257,
          960,
          466,
          3097,
          428,
          51697
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 136.42000000000002,
        "id": 36,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 135.42000000000002,
        "temperature": 0,
        "text": " own sound classifier.",
        "tokens": [
          51697,
          1065,
          1626,
          1508,
          9902,
          13,
          51747
        ]
      },
      {
        "avg_logprob": -0.2386547702175754,
        "compression_ratio": 1.6850152905198776,
        "end": 138.02,
        "id": 37,
        "no_speech_prob": 0.046031758189201355,
        "seek": 10876,
        "start": 136.42000000000002,
        "temperature": 0,
        "text": " Now, there's different ways you could do this.",
        "tokens": [
          51747,
          823,
          11,
          456,
          311,
          819,
          2098,
          291,
          727,
          360,
          341,
          13,
          51827
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 140.48000000000002,
        "id": 38,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 138.28,
        "temperature": 0,
        "text": " This isn't the way to make a sound classifier.",
        "tokens": [
          50377,
          639,
          1943,
          380,
          264,
          636,
          281,
          652,
          257,
          1626,
          1508,
          9902,
          13,
          50487
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 143.02,
        "id": 39,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 140.48000000000002,
        "temperature": 0,
        "text": " But this is the way that this particular model works.",
        "tokens": [
          50487,
          583,
          341,
          307,
          264,
          636,
          300,
          341,
          1729,
          2316,
          1985,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 146.9,
        "id": 40,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 143.02,
        "temperature": 0,
        "text": " It's actually, shockingly, amazingly doing image classification.",
        "tokens": [
          50614,
          467,
          311,
          767,
          11,
          5588,
          12163,
          11,
          31762,
          884,
          3256,
          21538,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 152.62,
        "id": 41,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 146.9,
        "temperature": 0,
        "text": " So if you imagine we have this thing that's called a convolutional neural network, this",
        "tokens": [
          50808,
          407,
          498,
          291,
          3811,
          321,
          362,
          341,
          551,
          300,
          311,
          1219,
          257,
          45216,
          304,
          18161,
          3209,
          11,
          341,
          51094
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 159.10000000000002,
        "id": 42,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 152.62,
        "temperature": 0,
        "text": " is the underlying architecture, the structure of that machine learning model that does the",
        "tokens": [
          51094,
          307,
          264,
          14217,
          9482,
          11,
          264,
          3877,
          295,
          300,
          3479,
          2539,
          2316,
          300,
          775,
          264,
          51418
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 160.10000000000002,
        "id": 43,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 159.10000000000002,
        "temperature": 0,
        "text": " classification.",
        "tokens": [
          51418,
          21538,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 164.22,
        "id": 44,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 160.10000000000002,
        "temperature": 0,
        "text": " Typically, this kind of model is something that we would put images in.",
        "tokens": [
          51468,
          23129,
          11,
          341,
          733,
          295,
          2316,
          307,
          746,
          300,
          321,
          576,
          829,
          5267,
          294,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.2552226298564189,
        "compression_ratio": 1.782442748091603,
        "end": 166.74,
        "id": 45,
        "no_speech_prob": 0.0005193001707084477,
        "seek": 13802,
        "start": 164.22,
        "temperature": 0,
        "text": " Like we might have images of cats.",
        "tokens": [
          51674,
          1743,
          321,
          1062,
          362,
          5267,
          295,
          11111,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 169.26000000000002,
        "id": 46,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 166.74,
        "temperature": 0,
        "text": " We might have an image of a turtle.",
        "tokens": [
          50364,
          492,
          1062,
          362,
          364,
          3256,
          295,
          257,
          22866,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 171.9,
        "id": 47,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 169.26000000000002,
        "temperature": 0,
        "text": " No, that's not really a turtle, but whatever.",
        "tokens": [
          50490,
          883,
          11,
          300,
          311,
          406,
          534,
          257,
          22866,
          11,
          457,
          2035,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 178.70000000000002,
        "id": 48,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 171.9,
        "temperature": 0,
        "text": " So the idea is that we're sending these images in and getting back a label and maybe a confidence",
        "tokens": [
          50622,
          407,
          264,
          1558,
          307,
          300,
          321,
          434,
          7750,
          613,
          5267,
          294,
          293,
          1242,
          646,
          257,
          7645,
          293,
          1310,
          257,
          6687,
          50962
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 179.70000000000002,
        "id": 49,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 178.70000000000002,
        "temperature": 0,
        "text": " score.",
        "tokens": [
          50962,
          6175,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 180.70000000000002,
        "id": 50,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 179.70000000000002,
        "temperature": 0,
        "text": " So it's the same idea.",
        "tokens": [
          51012,
          407,
          309,
          311,
          264,
          912,
          1558,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 189.26000000000002,
        "id": 51,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 180.70000000000002,
        "temperature": 0,
        "text": " The only thing is now we want to send in audio and get back a label like up or 1 and a confidence",
        "tokens": [
          51062,
          440,
          787,
          551,
          307,
          586,
          321,
          528,
          281,
          2845,
          294,
          6278,
          293,
          483,
          646,
          257,
          7645,
          411,
          493,
          420,
          502,
          293,
          257,
          6687,
          51490
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 190.26000000000002,
        "id": 52,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 189.26000000000002,
        "temperature": 0,
        "text": " score.",
        "tokens": [
          51490,
          6175,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.25858371697583243,
        "compression_ratio": 1.7095238095238094,
        "end": 194.22,
        "id": 53,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 16674,
        "start": 190.26000000000002,
        "temperature": 0,
        "text": " So how would we convert sound into an image?",
        "tokens": [
          51540,
          407,
          577,
          576,
          321,
          7620,
          1626,
          666,
          364,
          3256,
          30,
          51738
        ]
      },
      {
        "avg_logprob": -0.24266144537156628,
        "compression_ratio": 1.5573122529644268,
        "end": 200.34,
        "id": 54,
        "no_speech_prob": 0.00041084762779064476,
        "seek": 19422,
        "start": 194.5,
        "temperature": 0,
        "text": " Now again, there are other neural network architectures of which you could receive sound",
        "tokens": [
          50378,
          823,
          797,
          11,
          456,
          366,
          661,
          18161,
          3209,
          6331,
          1303,
          295,
          597,
          291,
          727,
          4774,
          1626,
          50670
        ]
      },
      {
        "avg_logprob": -0.24266144537156628,
        "compression_ratio": 1.5573122529644268,
        "end": 203.62,
        "id": 55,
        "no_speech_prob": 0.00041084762779064476,
        "seek": 19422,
        "start": 200.34,
        "temperature": 0,
        "text": " data in maybe a more direct fashion.",
        "tokens": [
          50670,
          1412,
          294,
          1310,
          257,
          544,
          2047,
          6700,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.24266144537156628,
        "compression_ratio": 1.5573122529644268,
        "end": 210.26,
        "id": 56,
        "no_speech_prob": 0.00041084762779064476,
        "seek": 19422,
        "start": 203.62,
        "temperature": 0,
        "text": " But if you've ever looked at a graphic equalizer or some type of sound visualization system,",
        "tokens": [
          50834,
          583,
          498,
          291,
          600,
          1562,
          2956,
          412,
          257,
          14089,
          2681,
          6545,
          420,
          512,
          2010,
          295,
          1626,
          25801,
          1185,
          11,
          51166
        ]
      },
      {
        "avg_logprob": -0.24266144537156628,
        "compression_ratio": 1.5573122529644268,
        "end": 215.02,
        "id": 57,
        "no_speech_prob": 0.00041084762779064476,
        "seek": 19422,
        "start": 210.26,
        "temperature": 0,
        "text": " I've made examples like this in p5, you can draw something that's often referred to as",
        "tokens": [
          51166,
          286,
          600,
          1027,
          5110,
          411,
          341,
          294,
          280,
          20,
          11,
          291,
          393,
          2642,
          746,
          300,
          311,
          2049,
          10839,
          281,
          382,
          51404
        ]
      },
      {
        "avg_logprob": -0.24266144537156628,
        "compression_ratio": 1.5573122529644268,
        "end": 223.06,
        "id": 58,
        "no_speech_prob": 0.00041084762779064476,
        "seek": 19422,
        "start": 215.02,
        "temperature": 0,
        "text": " the spectrogram, which is basically a graph of all the various amplitudes of frequencies",
        "tokens": [
          51404,
          264,
          6177,
          340,
          1342,
          11,
          597,
          307,
          1936,
          257,
          4295,
          295,
          439,
          264,
          3683,
          9731,
          16451,
          295,
          20250,
          51806
        ]
      },
      {
        "avg_logprob": -0.20683257076718392,
        "compression_ratio": 1.7808764940239044,
        "end": 225.54,
        "id": 59,
        "no_speech_prob": 0.00016093025624286383,
        "seek": 22306,
        "start": 223.1,
        "temperature": 0,
        "text": " of the wave patterns of the sound itself.",
        "tokens": [
          50366,
          295,
          264,
          5772,
          8294,
          295,
          264,
          1626,
          2564,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.20683257076718392,
        "compression_ratio": 1.7808764940239044,
        "end": 232.66,
        "id": 60,
        "no_speech_prob": 0.00016093025624286383,
        "seek": 22306,
        "start": 225.54,
        "temperature": 0,
        "text": " So if we took like a one second spectrogram and made that into an image, we could then",
        "tokens": [
          50488,
          407,
          498,
          321,
          1890,
          411,
          257,
          472,
          1150,
          6177,
          340,
          1342,
          293,
          1027,
          300,
          666,
          364,
          3256,
          11,
          321,
          727,
          550,
          50844
        ]
      },
      {
        "avg_logprob": -0.20683257076718392,
        "compression_ratio": 1.7808764940239044,
        "end": 238.78,
        "id": 61,
        "no_speech_prob": 0.00016093025624286383,
        "seek": 22306,
        "start": 232.66,
        "temperature": 0,
        "text": " send that image into a convolutional neural network saying that's the image that is produced",
        "tokens": [
          50844,
          2845,
          300,
          3256,
          666,
          257,
          45216,
          304,
          18161,
          3209,
          1566,
          300,
          311,
          264,
          3256,
          300,
          307,
          7126,
          51150
        ]
      },
      {
        "avg_logprob": -0.20683257076718392,
        "compression_ratio": 1.7808764940239044,
        "end": 242.26,
        "id": 62,
        "no_speech_prob": 0.00016093025624286383,
        "seek": 22306,
        "start": 238.78,
        "temperature": 0,
        "text": " from the spectrogram of somebody saying the word up.",
        "tokens": [
          51150,
          490,
          264,
          6177,
          340,
          1342,
          295,
          2618,
          1566,
          264,
          1349,
          493,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.20683257076718392,
        "compression_ratio": 1.7808764940239044,
        "end": 247.66,
        "id": 63,
        "no_speech_prob": 0.00016093025624286383,
        "seek": 22306,
        "start": 242.26,
        "temperature": 0,
        "text": " So underneath the hood, this machine learning system, even though it's designed to work",
        "tokens": [
          51324,
          407,
          7223,
          264,
          13376,
          11,
          341,
          3479,
          2539,
          1185,
          11,
          754,
          1673,
          309,
          311,
          4761,
          281,
          589,
          51594
        ]
      },
      {
        "avg_logprob": -0.20683257076718392,
        "compression_ratio": 1.7808764940239044,
        "end": 252.06,
        "id": 64,
        "no_speech_prob": 0.00016093025624286383,
        "seek": 22306,
        "start": 247.66,
        "temperature": 0,
        "text": " with audio data, it first takes that audio data, converts it into an image, and then",
        "tokens": [
          51594,
          365,
          6278,
          1412,
          11,
          309,
          700,
          2516,
          300,
          6278,
          1412,
          11,
          38874,
          309,
          666,
          364,
          3256,
          11,
          293,
          550,
          51814
        ]
      },
      {
        "avg_logprob": -0.2430873410455112,
        "compression_ratio": 1.688976377952756,
        "end": 257.54,
        "id": 65,
        "no_speech_prob": 0.001187873538583517,
        "seek": 25206,
        "start": 252.06,
        "temperature": 0,
        "text": " sends it through a very similar types of neural network architecture to standard image",
        "tokens": [
          50364,
          14790,
          309,
          807,
          257,
          588,
          2531,
          3467,
          295,
          18161,
          3209,
          9482,
          281,
          3832,
          3256,
          50638
        ]
      },
      {
        "avg_logprob": -0.2430873410455112,
        "compression_ratio": 1.688976377952756,
        "end": 258.54,
        "id": 66,
        "no_speech_prob": 0.001187873538583517,
        "seek": 25206,
        "start": 257.54,
        "temperature": 0,
        "text": " classification models.",
        "tokens": [
          50638,
          21538,
          5245,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.2430873410455112,
        "compression_ratio": 1.688976377952756,
        "end": 262.1,
        "id": 67,
        "no_speech_prob": 0.001187873538583517,
        "seek": 25206,
        "start": 258.54,
        "temperature": 0,
        "text": " And you can read more about that in that paper itself.",
        "tokens": [
          50688,
          400,
          291,
          393,
          1401,
          544,
          466,
          300,
          294,
          300,
          3035,
          2564,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.2430873410455112,
        "compression_ratio": 1.688976377952756,
        "end": 269.54,
        "id": 68,
        "no_speech_prob": 0.001187873538583517,
        "seek": 25206,
        "start": 262.1,
        "temperature": 0,
        "text": " However, I'm going to show you how to access this model in a quick way with the ml5 library.",
        "tokens": [
          50866,
          2908,
          11,
          286,
          478,
          516,
          281,
          855,
          291,
          577,
          281,
          2105,
          341,
          2316,
          294,
          257,
          1702,
          636,
          365,
          264,
          23271,
          20,
          6405,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2430873410455112,
        "compression_ratio": 1.688976377952756,
        "end": 274.94,
        "id": 69,
        "no_speech_prob": 0.001187873538583517,
        "seek": 25206,
        "start": 269.54,
        "temperature": 0,
        "text": " And this is the new as of today, which is, I don't know, what's today's date?",
        "tokens": [
          51238,
          400,
          341,
          307,
          264,
          777,
          382,
          295,
          965,
          11,
          597,
          307,
          11,
          286,
          500,
          380,
          458,
          11,
          437,
          311,
          965,
          311,
          4002,
          30,
          51508
        ]
      },
      {
        "avg_logprob": -0.2430873410455112,
        "compression_ratio": 1.688976377952756,
        "end": 275.94,
        "id": 70,
        "no_speech_prob": 0.001187873538583517,
        "seek": 25206,
        "start": 274.94,
        "temperature": 0,
        "text": " June 13, 2019.",
        "tokens": [
          51508,
          6928,
          3705,
          11,
          6071,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.2430873410455112,
        "compression_ratio": 1.688976377952756,
        "end": 281.56,
        "id": 71,
        "no_speech_prob": 0.001187873538583517,
        "seek": 25206,
        "start": 275.94,
        "temperature": 0,
        "text": " I'm going to show you how to use this with the ml5 library as it stands today.",
        "tokens": [
          51558,
          286,
          478,
          516,
          281,
          855,
          291,
          577,
          281,
          764,
          341,
          365,
          264,
          23271,
          20,
          6405,
          382,
          309,
          7382,
          965,
          13,
          51839
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 283.52,
        "id": 72,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 282.06,
        "temperature": 0,
        "text": " So I'm going to click here under reference.",
        "tokens": [
          50389,
          407,
          286,
          478,
          516,
          281,
          2052,
          510,
          833,
          6408,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 286.8,
        "id": 73,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 283.52,
        "temperature": 0,
        "text": " One thing you should see, there's a lot of new features have been added to the ml5 library.",
        "tokens": [
          50462,
          1485,
          551,
          291,
          820,
          536,
          11,
          456,
          311,
          257,
          688,
          295,
          777,
          4122,
          362,
          668,
          3869,
          281,
          264,
          23271,
          20,
          6405,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 289.64,
        "id": 74,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 286.8,
        "temperature": 0,
        "text": " I'm going to come back and do videos about more of those.",
        "tokens": [
          50626,
          286,
          478,
          516,
          281,
          808,
          646,
          293,
          360,
          2145,
          466,
          544,
          295,
          729,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 292.12,
        "id": 75,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 289.64,
        "temperature": 0,
        "text": " But the one I want to highlight here is sound classifier.",
        "tokens": [
          50768,
          583,
          264,
          472,
          286,
          528,
          281,
          5078,
          510,
          307,
          1626,
          1508,
          9902,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 293.12,
        "id": 76,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 292.12,
        "temperature": 0,
        "text": " So I'm going to click on this.",
        "tokens": [
          50892,
          407,
          286,
          478,
          516,
          281,
          2052,
          322,
          341,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 299.24,
        "id": 77,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 293.12,
        "temperature": 0,
        "text": " And for all of the different functions available in ml5, you'll find a documentation page with",
        "tokens": [
          50942,
          400,
          337,
          439,
          295,
          264,
          819,
          6828,
          2435,
          294,
          23271,
          20,
          11,
          291,
          603,
          915,
          257,
          14333,
          3028,
          365,
          51248
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 304.84000000000003,
        "id": 78,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 299.24,
        "temperature": 0,
        "text": " some narrative documentation, a little bit of a code snippet, and then some written documentation",
        "tokens": [
          51248,
          512,
          9977,
          14333,
          11,
          257,
          707,
          857,
          295,
          257,
          3089,
          35623,
          302,
          11,
          293,
          550,
          512,
          3720,
          14333,
          51528
        ]
      },
      {
        "avg_logprob": -0.20814975793810858,
        "compression_ratio": 1.7602523659305993,
        "end": 309.24,
        "id": 79,
        "no_speech_prob": 0.03676470369100571,
        "seek": 28156,
        "start": 304.84000000000003,
        "temperature": 0,
        "text": " about what the function names are and the various parameters and things like that.",
        "tokens": [
          51528,
          466,
          437,
          264,
          2445,
          5288,
          366,
          293,
          264,
          3683,
          9834,
          293,
          721,
          411,
          300,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 312.56,
        "id": 80,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 309.56,
        "temperature": 0,
        "text": " By the way, I'm noticing now, this will hopefully not read.",
        "tokens": [
          50380,
          3146,
          264,
          636,
          11,
          286,
          478,
          21814,
          586,
          11,
          341,
          486,
          4696,
          406,
          1401,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 314.72,
        "id": 81,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 312.56,
        "temperature": 0,
        "text": " This is like a mistake.",
        "tokens": [
          50530,
          639,
          307,
          411,
          257,
          6146,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 319.84000000000003,
        "id": 82,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 314.72,
        "temperature": 0,
        "text": " This is documentation that's actually for either body pics or maybe the unit model,",
        "tokens": [
          50638,
          639,
          307,
          14333,
          300,
          311,
          767,
          337,
          2139,
          1772,
          46690,
          420,
          1310,
          264,
          4985,
          2316,
          11,
          50894
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 321.40000000000003,
        "id": 83,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 319.84000000000003,
        "temperature": 0,
        "text": " which does something called image segmentation.",
        "tokens": [
          50894,
          597,
          775,
          746,
          1219,
          3256,
          9469,
          399,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 322.40000000000003,
        "id": 84,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 321.40000000000003,
        "temperature": 0,
        "text": " So we've got to get that fixed.",
        "tokens": [
          50972,
          407,
          321,
          600,
          658,
          281,
          483,
          300,
          6806,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 327.92,
        "id": 85,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 322.40000000000003,
        "temperature": 0,
        "text": " I'm sure many GitHub issues and fixes will be out and done by the time you see this.",
        "tokens": [
          51022,
          286,
          478,
          988,
          867,
          23331,
          2663,
          293,
          32539,
          486,
          312,
          484,
          293,
          1096,
          538,
          264,
          565,
          291,
          536,
          341,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 331.64,
        "id": 86,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 327.92,
        "temperature": 0,
        "text": " So in case you've forgotten how to use the ml5 library, I'm just going to show you as",
        "tokens": [
          51298,
          407,
          294,
          1389,
          291,
          600,
          11832,
          577,
          281,
          764,
          264,
          23271,
          20,
          6405,
          11,
          286,
          478,
          445,
          516,
          281,
          855,
          291,
          382,
          51484
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 334.56,
        "id": 87,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 331.64,
        "temperature": 0,
        "text": " it's documented on the ml5 web page.",
        "tokens": [
          51484,
          309,
          311,
          23007,
          322,
          264,
          23271,
          20,
          3670,
          3028,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.23709013802664622,
        "compression_ratio": 1.6633986928104576,
        "end": 336.64,
        "id": 88,
        "no_speech_prob": 0.0888102725148201,
        "seek": 30924,
        "start": 334.56,
        "temperature": 0,
        "text": " So first of all, you can go here to this quick start.",
        "tokens": [
          51630,
          407,
          700,
          295,
          439,
          11,
          291,
          393,
          352,
          510,
          281,
          341,
          1702,
          722,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 341.28,
        "id": 89,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 336.64,
        "temperature": 0,
        "text": " You can actually just click on this open p5 web editor sketch with ml5.js added.",
        "tokens": [
          50364,
          509,
          393,
          767,
          445,
          2052,
          322,
          341,
          1269,
          280,
          20,
          3670,
          9839,
          12325,
          365,
          23271,
          20,
          13,
          25530,
          3869,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 342.28,
        "id": 90,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 341.28,
        "temperature": 0,
        "text": " You know what?",
        "tokens": [
          50596,
          509,
          458,
          437,
          30,
          50646
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 343.28,
        "id": 91,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 342.28,
        "temperature": 0,
        "text": " I'm going to do that.",
        "tokens": [
          50646,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 344.28,
        "id": 92,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 343.28,
        "temperature": 0,
        "text": " That's the way I'm going to do it.",
        "tokens": [
          50696,
          663,
          311,
          264,
          636,
          286,
          478,
          516,
          281,
          360,
          309,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 350.52,
        "id": 93,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 344.28,
        "temperature": 0,
        "text": " But you also could just put a script tag in your HTML page referencing the current version",
        "tokens": [
          50746,
          583,
          291,
          611,
          727,
          445,
          829,
          257,
          5755,
          6162,
          294,
          428,
          17995,
          3028,
          40582,
          264,
          2190,
          3037,
          51058
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 353.64,
        "id": 94,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 350.52,
        "temperature": 0,
        "text": " of the library, which as I said, is 0.3.1 as of today.",
        "tokens": [
          51058,
          295,
          264,
          6405,
          11,
          597,
          382,
          286,
          848,
          11,
          307,
          1958,
          13,
          18,
          13,
          16,
          382,
          295,
          965,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 356.96,
        "id": 95,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 353.64,
        "temperature": 0,
        "text": " But probably while you're watching it, it'll be a higher number.",
        "tokens": [
          51214,
          583,
          1391,
          1339,
          291,
          434,
          1976,
          309,
          11,
          309,
          603,
          312,
          257,
          2946,
          1230,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 360.3,
        "id": 96,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 356.96,
        "temperature": 0,
        "text": " So let me go and just open up this link here.",
        "tokens": [
          51380,
          407,
          718,
          385,
          352,
          293,
          445,
          1269,
          493,
          341,
          2113,
          510,
          13,
          51547
        ]
      },
      {
        "avg_logprob": -0.20458375706392176,
        "compression_ratio": 1.5598591549295775,
        "end": 364.76,
        "id": 97,
        "no_speech_prob": 0.004609392955899239,
        "seek": 33664,
        "start": 360.3,
        "temperature": 0,
        "text": " And now I'm in the p5 web editor.",
        "tokens": [
          51547,
          400,
          586,
          286,
          478,
          294,
          264,
          280,
          20,
          3670,
          9839,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 368.8,
        "id": 98,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 364.88,
        "temperature": 0,
        "text": " You can see the name of the sketch is ml5.js boilerplate.",
        "tokens": [
          50370,
          509,
          393,
          536,
          264,
          1315,
          295,
          264,
          12325,
          307,
          23271,
          20,
          13,
          25530,
          39228,
          37008,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 370.84,
        "id": 99,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 368.8,
        "temperature": 0,
        "text": " Thank you, Joey Lee, who's a contributor to ml5.",
        "tokens": [
          50566,
          1044,
          291,
          11,
          23764,
          6957,
          11,
          567,
          311,
          257,
          42859,
          281,
          23271,
          20,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 375.4,
        "id": 100,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 370.84,
        "temperature": 0,
        "text": " He's done a ton of work on the website and all the different features.",
        "tokens": [
          50668,
          634,
          311,
          1096,
          257,
          2952,
          295,
          589,
          322,
          264,
          3144,
          293,
          439,
          264,
          819,
          4122,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 377.52,
        "id": 101,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 375.4,
        "temperature": 0,
        "text": " And oh, this should actually be 3.1.",
        "tokens": [
          50896,
          400,
          1954,
          11,
          341,
          820,
          767,
          312,
          805,
          13,
          16,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 378.52,
        "id": 102,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 377.52,
        "temperature": 0,
        "text": " I'm going to fix that.",
        "tokens": [
          51002,
          286,
          478,
          516,
          281,
          3191,
          300,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 379.52,
        "id": 103,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 378.52,
        "temperature": 0,
        "text": " Uh-huh.",
        "tokens": [
          51052,
          4019,
          12,
          18710,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 381.14,
        "id": 104,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 379.52,
        "temperature": 0,
        "text": " I'm going to hit save.",
        "tokens": [
          51102,
          286,
          478,
          516,
          281,
          2045,
          3155,
          13,
          51183
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 387.32,
        "id": 105,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 381.14,
        "temperature": 0,
        "text": " And then I'm going to rename it to sound classifier.",
        "tokens": [
          51183,
          400,
          550,
          286,
          478,
          516,
          281,
          36741,
          309,
          281,
          1626,
          1508,
          9902,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 391.08,
        "id": 106,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 387.32,
        "temperature": 0,
        "text": " And I am going to then go over here and go to sketch.js.",
        "tokens": [
          51492,
          400,
          286,
          669,
          516,
          281,
          550,
          352,
          670,
          510,
          293,
          352,
          281,
          12325,
          13,
          25530,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 392.08,
        "id": 107,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 391.08,
        "temperature": 0,
        "text": " And I'm going to run this.",
        "tokens": [
          51680,
          400,
          286,
          478,
          516,
          281,
          1190,
          341,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 393.08,
        "id": 108,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 392.08,
        "temperature": 0,
        "text": " And we should see.",
        "tokens": [
          51730,
          400,
          321,
          820,
          536,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.26234350399095185,
        "compression_ratio": 1.6872586872586872,
        "end": 394.08,
        "id": 109,
        "no_speech_prob": 0.019718175753951073,
        "seek": 36476,
        "start": 393.08,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51780,
          821,
          321,
          352,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 399,
        "id": 110,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 394.4,
        "temperature": 0,
        "text": " So now we know it's working because there's a little console log to log ml5.version.",
        "tokens": [
          50380,
          407,
          586,
          321,
          458,
          309,
          311,
          1364,
          570,
          456,
          311,
          257,
          707,
          11076,
          3565,
          281,
          3565,
          23271,
          20,
          13,
          29153,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 401.8,
        "id": 111,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 399,
        "temperature": 0,
        "text": " If I hadn't imported the ml5 library, I wouldn't see that.",
        "tokens": [
          50610,
          759,
          286,
          8782,
          380,
          25524,
          264,
          23271,
          20,
          6405,
          11,
          286,
          2759,
          380,
          536,
          300,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 403.28,
        "id": 112,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 401.8,
        "temperature": 0,
        "text": " We see that here.",
        "tokens": [
          50750,
          492,
          536,
          300,
          510,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 405.24,
        "id": 113,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 403.28,
        "temperature": 0,
        "text": " So what are we going to do?",
        "tokens": [
          50824,
          407,
          437,
          366,
          321,
          516,
          281,
          360,
          30,
          50922
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 407.68,
        "id": 114,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 405.24,
        "temperature": 0,
        "text": " Let's load the sound classifier.",
        "tokens": [
          50922,
          961,
          311,
          3677,
          264,
          1626,
          1508,
          9902,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 412,
        "id": 115,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 407.68,
        "temperature": 0,
        "text": " Now most of the models, I haven't been using this in my previous videos, most of the models",
        "tokens": [
          51044,
          823,
          881,
          295,
          264,
          5245,
          11,
          286,
          2378,
          380,
          668,
          1228,
          341,
          294,
          452,
          3894,
          2145,
          11,
          881,
          295,
          264,
          5245,
          51260
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 417.03999999999996,
        "id": 116,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 412,
        "temperature": 0,
        "text": " in ml5 are now actually available to you in preload, meaning you don't need a callback",
        "tokens": [
          51260,
          294,
          23271,
          20,
          366,
          586,
          767,
          2435,
          281,
          291,
          294,
          659,
          2907,
          11,
          3620,
          291,
          500,
          380,
          643,
          257,
          818,
          3207,
          51512
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 418.03999999999996,
        "id": 117,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 417.03999999999996,
        "temperature": 0,
        "text": " function.",
        "tokens": [
          51512,
          2445,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 421.28,
        "id": 118,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 418.03999999999996,
        "temperature": 0,
        "text": " You can just load the model in preload, and it'll be ready by the time you get to set",
        "tokens": [
          51562,
          509,
          393,
          445,
          3677,
          264,
          2316,
          294,
          659,
          2907,
          11,
          293,
          309,
          603,
          312,
          1919,
          538,
          264,
          565,
          291,
          483,
          281,
          992,
          51724
        ]
      },
      {
        "avg_logprob": -0.21130809268435916,
        "compression_ratio": 1.6983050847457628,
        "end": 422.28,
        "id": 119,
        "no_speech_prob": 0.20945636928081512,
        "seek": 39408,
        "start": 421.28,
        "temperature": 0,
        "text": " up.",
        "tokens": [
          51724,
          493,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 425.91999999999996,
        "id": 120,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 422.47999999999996,
        "temperature": 0,
        "text": " So I'm going to make a variable called sound classifier.",
        "tokens": [
          50374,
          407,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          1626,
          1508,
          9902,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 431.26,
        "id": 121,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 425.91999999999996,
        "temperature": 0,
        "text": " In preload, I'm going to say sound classifier equals ml5 sound classifier.",
        "tokens": [
          50546,
          682,
          659,
          2907,
          11,
          286,
          478,
          516,
          281,
          584,
          1626,
          1508,
          9902,
          6915,
          23271,
          20,
          1626,
          1508,
          9902,
          13,
          50813
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 435.55999999999995,
        "id": 122,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 431.26,
        "temperature": 0,
        "text": " Now I need to tell it what model I want to load.",
        "tokens": [
          50813,
          823,
          286,
          643,
          281,
          980,
          309,
          437,
          2316,
          286,
          528,
          281,
          3677,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 439.79999999999995,
        "id": 123,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 435.55999999999995,
        "temperature": 0,
        "text": " So I need to in here put the name of the model I want to load.",
        "tokens": [
          51028,
          407,
          286,
          643,
          281,
          294,
          510,
          829,
          264,
          1315,
          295,
          264,
          2316,
          286,
          528,
          281,
          3677,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 443.35999999999996,
        "id": 124,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 439.79999999999995,
        "temperature": 0,
        "text": " And in theory, in the future, there might be a bunch of different options, different",
        "tokens": [
          51240,
          400,
          294,
          5261,
          11,
          294,
          264,
          2027,
          11,
          456,
          1062,
          312,
          257,
          3840,
          295,
          819,
          3956,
          11,
          819,
          51418
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 448.08,
        "id": 125,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 443.35999999999996,
        "temperature": 0,
        "text": " kinds of sound classifiers, or maybe a sound classifier you've trained yourself that you",
        "tokens": [
          51418,
          3685,
          295,
          1626,
          1508,
          23463,
          11,
          420,
          1310,
          257,
          1626,
          1508,
          9902,
          291,
          600,
          8895,
          1803,
          300,
          291,
          51654
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 449.08,
        "id": 126,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 448.08,
        "temperature": 0,
        "text": " want to put in there.",
        "tokens": [
          51654,
          528,
          281,
          829,
          294,
          456,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.21537722711977753,
        "compression_ratio": 1.902621722846442,
        "end": 452.11999999999995,
        "id": 127,
        "no_speech_prob": 0.07695630192756653,
        "seek": 42228,
        "start": 449.08,
        "temperature": 0,
        "text": " And I'll come back eventually, show you videos about how to do that.",
        "tokens": [
          51704,
          400,
          286,
          603,
          808,
          646,
          4728,
          11,
          855,
          291,
          2145,
          466,
          577,
          281,
          360,
          300,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 456.44,
        "id": 128,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 452.96,
        "temperature": 0,
        "text": " But for right now, I'm just going to say speech commands, and then I already forgot what it",
        "tokens": [
          50406,
          583,
          337,
          558,
          586,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          6218,
          16901,
          11,
          293,
          550,
          286,
          1217,
          5298,
          437,
          309,
          50580
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 457.44,
        "id": 129,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 456.44,
        "temperature": 0,
        "text": " was called.",
        "tokens": [
          50580,
          390,
          1219,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 460.28000000000003,
        "id": 130,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 457.44,
        "temperature": 0,
        "text": " So I'm going to go back to the ml5 website, which is here.",
        "tokens": [
          50630,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          23271,
          20,
          3144,
          11,
          597,
          307,
          510,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 461.28000000000003,
        "id": 131,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 460.28000000000003,
        "temperature": 0,
        "text": " I'm going to go to reference.",
        "tokens": [
          50772,
          286,
          478,
          516,
          281,
          352,
          281,
          6408,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 464.6,
        "id": 132,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 461.28000000000003,
        "temperature": 0,
        "text": " I'm going to go to sound classifier, and I'm looking for it here.",
        "tokens": [
          50822,
          286,
          478,
          516,
          281,
          352,
          281,
          1626,
          1508,
          9902,
          11,
          293,
          286,
          478,
          1237,
          337,
          309,
          510,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 467.52,
        "id": 133,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 464.6,
        "temperature": 0,
        "text": " So it's speech commands 18w.",
        "tokens": [
          50988,
          407,
          309,
          311,
          6218,
          16901,
          2443,
          86,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 472.06,
        "id": 134,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 467.52,
        "temperature": 0,
        "text": " This is a particular model that's been trained on 18 specific words.",
        "tokens": [
          51134,
          639,
          307,
          257,
          1729,
          2316,
          300,
          311,
          668,
          8895,
          322,
          2443,
          2685,
          2283,
          13,
          51361
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 473.52,
        "id": 135,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 472.06,
        "temperature": 0,
        "text": " And you can see what those are.",
        "tokens": [
          51361,
          400,
          291,
          393,
          536,
          437,
          729,
          366,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 479.04,
        "id": 136,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 473.52,
        "temperature": 0,
        "text": " The 10 digits from 0 to 9, up, down, left, right, go, stop, yes, no.",
        "tokens": [
          51434,
          440,
          1266,
          27011,
          490,
          1958,
          281,
          1722,
          11,
          493,
          11,
          760,
          11,
          1411,
          11,
          558,
          11,
          352,
          11,
          1590,
          11,
          2086,
          11,
          572,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.22290044252564306,
        "compression_ratio": 1.6654804270462633,
        "end": 480.04,
        "id": 137,
        "no_speech_prob": 0.008577346801757812,
        "seek": 45212,
        "start": 479.04,
        "temperature": 0,
        "text": " That's 18.",
        "tokens": [
          51710,
          663,
          311,
          2443,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2514017105102539,
        "compression_ratio": 1.5829145728643217,
        "end": 483.24,
        "id": 138,
        "no_speech_prob": 0.000245369243202731,
        "seek": 48004,
        "start": 480.16,
        "temperature": 0,
        "text": " 10 digits, 8 different words.",
        "tokens": [
          50370,
          1266,
          27011,
          11,
          1649,
          819,
          2283,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.2514017105102539,
        "compression_ratio": 1.5829145728643217,
        "end": 488.64000000000004,
        "id": 139,
        "no_speech_prob": 0.000245369243202731,
        "seek": 48004,
        "start": 483.24,
        "temperature": 0,
        "text": " All right, so now I'm going to go, so it's 18w.",
        "tokens": [
          50524,
          1057,
          558,
          11,
          370,
          586,
          286,
          478,
          516,
          281,
          352,
          11,
          370,
          309,
          311,
          2443,
          86,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.2514017105102539,
        "compression_ratio": 1.5829145728643217,
        "end": 493.24,
        "id": 140,
        "no_speech_prob": 0.000245369243202731,
        "seek": 48004,
        "start": 488.64000000000004,
        "temperature": 0,
        "text": " And then once that model is loaded, I need a callback.",
        "tokens": [
          50794,
          400,
          550,
          1564,
          300,
          2316,
          307,
          13210,
          11,
          286,
          643,
          257,
          818,
          3207,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2514017105102539,
        "compression_ratio": 1.5829145728643217,
        "end": 498.32000000000005,
        "id": 141,
        "no_speech_prob": 0.000245369243202731,
        "seek": 48004,
        "start": 493.24,
        "temperature": 0,
        "text": " So I could just say sound classifier classify.",
        "tokens": [
          51024,
          407,
          286,
          727,
          445,
          584,
          1626,
          1508,
          9902,
          33872,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2514017105102539,
        "compression_ratio": 1.5829145728643217,
        "end": 500.24,
        "id": 142,
        "no_speech_prob": 0.000245369243202731,
        "seek": 48004,
        "start": 498.32000000000005,
        "temperature": 0,
        "text": " I might just call it got results.",
        "tokens": [
          51278,
          286,
          1062,
          445,
          818,
          309,
          658,
          3542,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.2514017105102539,
        "compression_ratio": 1.5829145728643217,
        "end": 503,
        "id": 143,
        "no_speech_prob": 0.000245369243202731,
        "seek": 48004,
        "start": 500.24,
        "temperature": 0,
        "text": " So in other words, I'm, oh, it's not defined, right?",
        "tokens": [
          51374,
          407,
          294,
          661,
          2283,
          11,
          286,
          478,
          11,
          1954,
          11,
          309,
          311,
          406,
          7642,
          11,
          558,
          30,
          51512
        ]
      },
      {
        "avg_logprob": -0.2514017105102539,
        "compression_ratio": 1.5829145728643217,
        "end": 505.76,
        "id": 144,
        "no_speech_prob": 0.000245369243202731,
        "seek": 48004,
        "start": 503,
        "temperature": 0,
        "text": " So I'm telling the sound classifier to classify.",
        "tokens": [
          51512,
          407,
          286,
          478,
          3585,
          264,
          1626,
          1508,
          9902,
          281,
          33872,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 510.2,
        "id": 145,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 505.76,
        "temperature": 0,
        "text": " Now, by default, it's just going to listen to the microphone's audio.",
        "tokens": [
          50364,
          823,
          11,
          538,
          7576,
          11,
          309,
          311,
          445,
          516,
          281,
          2140,
          281,
          264,
          10952,
          311,
          6278,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 513.64,
        "id": 146,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 510.2,
        "temperature": 0,
        "text": " Maybe in the future, part of ml5 will be able to offer hooks",
        "tokens": [
          50586,
          2704,
          294,
          264,
          2027,
          11,
          644,
          295,
          23271,
          20,
          486,
          312,
          1075,
          281,
          2626,
          26485,
          50758
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 516.76,
        "id": 147,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 513.64,
        "temperature": 0,
        "text": " to how you can connect it to a different audio source.",
        "tokens": [
          50758,
          281,
          577,
          291,
          393,
          1745,
          309,
          281,
          257,
          819,
          6278,
          4009,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 520.92,
        "id": 148,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 516.76,
        "temperature": 0,
        "text": " But it's basically just going to work with the microphone's audio.",
        "tokens": [
          50914,
          583,
          309,
          311,
          1936,
          445,
          516,
          281,
          589,
          365,
          264,
          10952,
          311,
          6278,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 526.52,
        "id": 149,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 520.92,
        "temperature": 0,
        "text": " Then I can write a function called got results.",
        "tokens": [
          51122,
          1396,
          286,
          393,
          2464,
          257,
          2445,
          1219,
          658,
          3542,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 528.48,
        "id": 150,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 526.52,
        "temperature": 0,
        "text": " And I'm going to get rid of the draw loop,",
        "tokens": [
          51402,
          400,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          2642,
          6367,
          11,
          51500
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 530.04,
        "id": 151,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 528.48,
        "temperature": 0,
        "text": " because I don't need that right now.",
        "tokens": [
          51500,
          570,
          286,
          500,
          380,
          643,
          300,
          558,
          586,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2510716485195473,
        "compression_ratio": 1.6605166051660516,
        "end": 535.72,
        "id": 152,
        "no_speech_prob": 0.017176227644085884,
        "seek": 50576,
        "start": 530.04,
        "temperature": 0,
        "text": " Let me just turn off auto refresh so that it doesn't keep refreshing.",
        "tokens": [
          51578,
          961,
          385,
          445,
          1261,
          766,
          8399,
          15134,
          370,
          300,
          309,
          1177,
          380,
          1066,
          19772,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.24717877705891927,
        "compression_ratio": 1.7857142857142858,
        "end": 541.4,
        "id": 153,
        "no_speech_prob": 0.00005562199658015743,
        "seek": 53572,
        "start": 536.32,
        "temperature": 0,
        "text": " Now, if you remember, ml5 employs error first callbacks,",
        "tokens": [
          50394,
          823,
          11,
          498,
          291,
          1604,
          11,
          23271,
          20,
          846,
          49522,
          6713,
          700,
          818,
          17758,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.24717877705891927,
        "compression_ratio": 1.7857142857142858,
        "end": 546.32,
        "id": 154,
        "no_speech_prob": 0.00005562199658015743,
        "seek": 53572,
        "start": 541.4,
        "temperature": 0,
        "text": " meaning the callback function requires two arguments, an error",
        "tokens": [
          50648,
          3620,
          264,
          818,
          3207,
          2445,
          7029,
          732,
          12869,
          11,
          364,
          6713,
          50894
        ]
      },
      {
        "avg_logprob": -0.24717877705891927,
        "compression_ratio": 1.7857142857142858,
        "end": 550.0400000000001,
        "id": 155,
        "no_speech_prob": 0.00005562199658015743,
        "seek": 53572,
        "start": 546.32,
        "temperature": 0,
        "text": " argument in case something went wrong, and a data or a result",
        "tokens": [
          50894,
          6770,
          294,
          1389,
          746,
          1437,
          2085,
          11,
          293,
          257,
          1412,
          420,
          257,
          1874,
          51080
        ]
      },
      {
        "avg_logprob": -0.24717877705891927,
        "compression_ratio": 1.7857142857142858,
        "end": 552.28,
        "id": 156,
        "no_speech_prob": 0.00005562199658015743,
        "seek": 53572,
        "start": 550.0400000000001,
        "temperature": 0,
        "text": " or some other argument where the actual stuff is.",
        "tokens": [
          51080,
          420,
          512,
          661,
          6770,
          689,
          264,
          3539,
          1507,
          307,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.24717877705891927,
        "compression_ratio": 1.7857142857142858,
        "end": 555.4,
        "id": 157,
        "no_speech_prob": 0.00005562199658015743,
        "seek": 53572,
        "start": 552.28,
        "temperature": 0,
        "text": " So I'm going to say error, and then I'm going to say results.",
        "tokens": [
          51192,
          407,
          286,
          478,
          516,
          281,
          584,
          6713,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          3542,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.24717877705891927,
        "compression_ratio": 1.7857142857142858,
        "end": 557.64,
        "id": 158,
        "no_speech_prob": 0.00005562199658015743,
        "seek": 53572,
        "start": 555.4,
        "temperature": 0,
        "text": " And then I could do a little basic error handling.",
        "tokens": [
          51348,
          400,
          550,
          286,
          727,
          360,
          257,
          707,
          3875,
          6713,
          13175,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.24717877705891927,
        "compression_ratio": 1.7857142857142858,
        "end": 564.9200000000001,
        "id": 159,
        "no_speech_prob": 0.00005562199658015743,
        "seek": 53572,
        "start": 557.64,
        "temperature": 0,
        "text": " I'm just going to say console log something went wrong.",
        "tokens": [
          51460,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          3565,
          746,
          1437,
          2085,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 569.5999999999999,
        "id": 160,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 564.92,
        "temperature": 0,
        "text": " And then I can also actually log the error.",
        "tokens": [
          50364,
          400,
          550,
          286,
          393,
          611,
          767,
          3565,
          264,
          6713,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 578.16,
        "id": 161,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 574.16,
        "temperature": 0,
        "text": " And then I'm going to say console log results.",
        "tokens": [
          50826,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11076,
          3565,
          3542,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 580.56,
        "id": 162,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 578.16,
        "temperature": 0,
        "text": " So let's see if we get anything.",
        "tokens": [
          51026,
          407,
          718,
          311,
          536,
          498,
          321,
          483,
          1340,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 583.36,
        "id": 163,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 580.56,
        "temperature": 0,
        "text": " Oh, I have to run it again.",
        "tokens": [
          51146,
          876,
          11,
          286,
          362,
          281,
          1190,
          309,
          797,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 584.7199999999999,
        "id": 164,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 583.36,
        "temperature": 0,
        "text": " You can ignore this error.",
        "tokens": [
          51286,
          509,
          393,
          11200,
          341,
          6713,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 587.88,
        "id": 165,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 584.7199999999999,
        "temperature": 0,
        "text": " Oh, something came in.",
        "tokens": [
          51354,
          876,
          11,
          746,
          1361,
          294,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 589.4399999999999,
        "id": 166,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 587.88,
        "temperature": 0,
        "text": " Ready?",
        "tokens": [
          51512,
          9944,
          30,
          51590
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 591.28,
        "id": 167,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 589.4399999999999,
        "temperature": 0,
        "text": " Up.",
        "tokens": [
          51590,
          5858,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.29470852745903864,
        "compression_ratio": 1.4712041884816753,
        "end": 594.16,
        "id": 168,
        "no_speech_prob": 0.000006962247425690293,
        "seek": 56492,
        "start": 591.28,
        "temperature": 0,
        "text": " I just want to stop and mention that if you're following this along,",
        "tokens": [
          51682,
          286,
          445,
          528,
          281,
          1590,
          293,
          2152,
          300,
          498,
          291,
          434,
          3480,
          341,
          2051,
          11,
          51826
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 596.76,
        "id": 169,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 594.1999999999999,
        "temperature": 0,
        "text": " hopefully your browser is asking for permission",
        "tokens": [
          50366,
          4696,
          428,
          11185,
          307,
          3365,
          337,
          11226,
          50494
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 598.0799999999999,
        "id": 170,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 596.76,
        "temperature": 0,
        "text": " to use the microphone.",
        "tokens": [
          50494,
          281,
          764,
          264,
          10952,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 600.7199999999999,
        "id": 171,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 598.0799999999999,
        "temperature": 0,
        "text": " The reason why that didn't happen here in this video",
        "tokens": [
          50560,
          440,
          1778,
          983,
          300,
          994,
          380,
          1051,
          510,
          294,
          341,
          960,
          50692
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 603.04,
        "id": 172,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 600.7199999999999,
        "temperature": 0,
        "text": " is because I've already set my browser",
        "tokens": [
          50692,
          307,
          570,
          286,
          600,
          1217,
          992,
          452,
          11185,
          50808
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 607.48,
        "id": 173,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 603.04,
        "temperature": 0,
        "text": " to allow use of the microphone on the p5 web editor pages.",
        "tokens": [
          50808,
          281,
          2089,
          764,
          295,
          264,
          10952,
          322,
          264,
          280,
          20,
          3670,
          9839,
          7183,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 610.88,
        "id": 174,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 607.48,
        "temperature": 0,
        "text": " But for security, you can't just access anybody's microphone",
        "tokens": [
          51030,
          583,
          337,
          3825,
          11,
          291,
          393,
          380,
          445,
          2105,
          4472,
          311,
          10952,
          51200
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 613,
        "id": 175,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 610.88,
        "temperature": 0,
        "text": " from a web page without the user giving permission.",
        "tokens": [
          51200,
          490,
          257,
          3670,
          3028,
          1553,
          264,
          4195,
          2902,
          11226,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 614.64,
        "id": 176,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 613,
        "temperature": 0,
        "text": " So hopefully you saw that happen.",
        "tokens": [
          51306,
          407,
          4696,
          291,
          1866,
          300,
          1051,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 617,
        "id": 177,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 614.64,
        "temperature": 0,
        "text": " And if you didn't, that might be why you run into an error",
        "tokens": [
          51388,
          400,
          498,
          291,
          994,
          380,
          11,
          300,
          1062,
          312,
          983,
          291,
          1190,
          666,
          364,
          6713,
          51506
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 619.54,
        "id": 178,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 617,
        "temperature": 0,
        "text": " if you haven't given that permission.",
        "tokens": [
          51506,
          498,
          291,
          2378,
          380,
          2212,
          300,
          11226,
          13,
          51633
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 621.3399999999999,
        "id": 179,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 619.54,
        "temperature": 0,
        "text": " This is getting a little hard to debug just",
        "tokens": [
          51633,
          639,
          307,
          1242,
          257,
          707,
          1152,
          281,
          24083,
          445,
          51723
        ]
      },
      {
        "avg_logprob": -0.24388012783132867,
        "compression_ratio": 1.788273615635179,
        "end": 622.9599999999999,
        "id": 180,
        "no_speech_prob": 0.00019716870156116784,
        "seek": 59416,
        "start": 621.3399999999999,
        "temperature": 0,
        "text": " because so much stuff is happening here",
        "tokens": [
          51723,
          570,
          370,
          709,
          1507,
          307,
          2737,
          510,
          51804
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 624.2,
        "id": 181,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 622.96,
        "temperature": 0,
        "text": " in the console and this huge arrays.",
        "tokens": [
          50364,
          294,
          264,
          11076,
          293,
          341,
          2603,
          41011,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 625.76,
        "id": 182,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 624.2,
        "temperature": 0,
        "text": " But there's actually something that I",
        "tokens": [
          50426,
          583,
          456,
          311,
          767,
          746,
          300,
          286,
          50504
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 629.72,
        "id": 183,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 625.76,
        "temperature": 0,
        "text": " missed that I could add here, which is an options variable.",
        "tokens": [
          50504,
          6721,
          300,
          286,
          727,
          909,
          510,
          11,
          597,
          307,
          364,
          3956,
          7006,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 631.4000000000001,
        "id": 184,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 629.72,
        "temperature": 0,
        "text": " So one of the things I can tell, there's",
        "tokens": [
          50702,
          407,
          472,
          295,
          264,
          721,
          286,
          393,
          980,
          11,
          456,
          311,
          50786
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 634.44,
        "id": 185,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 631.4000000000001,
        "temperature": 0,
        "text": " a lot of things I can set as properties or parameters",
        "tokens": [
          50786,
          257,
          688,
          295,
          721,
          286,
          393,
          992,
          382,
          7221,
          420,
          9834,
          50938
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 636.48,
        "id": 186,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 634.44,
        "temperature": 0,
        "text": " for how the sound classifier should work.",
        "tokens": [
          50938,
          337,
          577,
          264,
          1626,
          1508,
          9902,
          820,
          589,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 638.9200000000001,
        "id": 187,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 636.48,
        "temperature": 0,
        "text": " But there's a very simple one, which",
        "tokens": [
          51040,
          583,
          456,
          311,
          257,
          588,
          2199,
          472,
          11,
          597,
          51162
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 640.96,
        "id": 188,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 638.9200000000001,
        "temperature": 0,
        "text": " I'm going to just look it up in the documentation",
        "tokens": [
          51162,
          286,
          478,
          516,
          281,
          445,
          574,
          309,
          493,
          294,
          264,
          14333,
          51264
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 642.0400000000001,
        "id": 189,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 640.96,
        "temperature": 0,
        "text": " because I don't remember.",
        "tokens": [
          51264,
          570,
          286,
          500,
          380,
          1604,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 644.2,
        "id": 190,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 642.0400000000001,
        "temperature": 0,
        "text": " It's called the probability threshold.",
        "tokens": [
          51318,
          467,
          311,
          1219,
          264,
          8482,
          14678,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 646.64,
        "id": 191,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 644.2,
        "temperature": 0,
        "text": " So I'm actually just going to copy paste this here.",
        "tokens": [
          51426,
          407,
          286,
          478,
          767,
          445,
          516,
          281,
          5055,
          9163,
          341,
          510,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.2417202956384892,
        "compression_ratio": 1.8041237113402062,
        "end": 651.08,
        "id": 192,
        "no_speech_prob": 0.017441650852560997,
        "seek": 62296,
        "start": 646.64,
        "temperature": 0,
        "text": " What this means is basically the sound classifier",
        "tokens": [
          51548,
          708,
          341,
          1355,
          307,
          1936,
          264,
          1626,
          1508,
          9902,
          51770
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 653.96,
        "id": 193,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 651.08,
        "temperature": 0,
        "text": " is going to trigger an event where it's going to come.",
        "tokens": [
          50364,
          307,
          516,
          281,
          7875,
          364,
          2280,
          689,
          309,
          311,
          516,
          281,
          808,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 656.24,
        "id": 194,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 653.96,
        "temperature": 0,
        "text": " Right now, I'm console logging all of this information",
        "tokens": [
          50508,
          1779,
          586,
          11,
          286,
          478,
          11076,
          27991,
          439,
          295,
          341,
          1589,
          50622
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 659.86,
        "id": 195,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 656.24,
        "temperature": 0,
        "text": " about what it thinks it heard based on a confidence",
        "tokens": [
          50622,
          466,
          437,
          309,
          7309,
          309,
          2198,
          2361,
          322,
          257,
          6687,
          50803
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 663.08,
        "id": 196,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 659.86,
        "temperature": 0,
        "text": " level for how sure it is it heard one of those keywords.",
        "tokens": [
          50803,
          1496,
          337,
          577,
          988,
          309,
          307,
          309,
          2198,
          472,
          295,
          729,
          21009,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 665.36,
        "id": 197,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 663.08,
        "temperature": 0,
        "text": " And right now, a lot of those events are triggering",
        "tokens": [
          50964,
          400,
          558,
          586,
          11,
          257,
          688,
          295,
          729,
          3931,
          366,
          40406,
          51078
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 667.4000000000001,
        "id": 198,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 665.36,
        "temperature": 0,
        "text": " because I don't know what the default probability",
        "tokens": [
          51078,
          570,
          286,
          500,
          380,
          458,
          437,
          264,
          7576,
          8482,
          51180
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 668.08,
        "id": 199,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 667.4000000000001,
        "temperature": 0,
        "text": " threshold is.",
        "tokens": [
          51180,
          14678,
          307,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 669.5600000000001,
        "id": 200,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 668.08,
        "temperature": 0,
        "text": " Maybe it was 0.7.",
        "tokens": [
          51214,
          2704,
          309,
          390,
          1958,
          13,
          22,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 670.72,
        "id": 201,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 669.5600000000001,
        "temperature": 0,
        "text": " Maybe it's 0.5.",
        "tokens": [
          51288,
          2704,
          309,
          311,
          1958,
          13,
          20,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 672.2800000000001,
        "id": 202,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 670.72,
        "temperature": 0,
        "text": " But I'm going to make that really high.",
        "tokens": [
          51346,
          583,
          286,
          478,
          516,
          281,
          652,
          300,
          534,
          1090,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 673.88,
        "id": 203,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 672.2800000000001,
        "temperature": 0,
        "text": " I'm going to say 0.95.",
        "tokens": [
          51424,
          286,
          478,
          516,
          281,
          584,
          1958,
          13,
          15718,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 676.24,
        "id": 204,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 673.88,
        "temperature": 0,
        "text": " So it has to have a 95% of them.",
        "tokens": [
          51504,
          407,
          309,
          575,
          281,
          362,
          257,
          13420,
          4,
          295,
          552,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.2116739413882262,
        "compression_ratio": 1.7046979865771812,
        "end": 678.6800000000001,
        "id": 205,
        "no_speech_prob": 0.00003269921580795199,
        "seek": 65108,
        "start": 676.24,
        "temperature": 0,
        "text": " The machine learning model has to calculate",
        "tokens": [
          51622,
          440,
          3479,
          2539,
          2316,
          575,
          281,
          8873,
          51744
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 683.7199999999999,
        "id": 206,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 678.68,
        "temperature": 0,
        "text": " a 95% confidence score before it gives the event back to me",
        "tokens": [
          50364,
          257,
          13420,
          4,
          6687,
          6175,
          949,
          309,
          2709,
          264,
          2280,
          646,
          281,
          385,
          50616
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 685,
        "id": 207,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 683.7199999999999,
        "temperature": 0,
        "text": " in ml5.",
        "tokens": [
          50616,
          294,
          23271,
          20,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 687.9599999999999,
        "id": 208,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 685,
        "temperature": 0,
        "text": " Once I've created that options variable with 0.95,",
        "tokens": [
          50680,
          3443,
          286,
          600,
          2942,
          300,
          3956,
          7006,
          365,
          1958,
          13,
          15718,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 690.06,
        "id": 209,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 687.9599999999999,
        "temperature": 0,
        "text": " I need to pass it into the constructor",
        "tokens": [
          50828,
          286,
          643,
          281,
          1320,
          309,
          666,
          264,
          47479,
          50933
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 691.5999999999999,
        "id": 210,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 690.06,
        "temperature": 0,
        "text": " as the second argument.",
        "tokens": [
          50933,
          382,
          264,
          1150,
          6770,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 693.52,
        "id": 211,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 691.5999999999999,
        "temperature": 0,
        "text": " So now, we pass it in there.",
        "tokens": [
          51010,
          407,
          586,
          11,
          321,
          1320,
          309,
          294,
          456,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 694.7199999999999,
        "id": 212,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 693.52,
        "temperature": 0,
        "text": " I'm going to run the sketch.",
        "tokens": [
          51106,
          286,
          478,
          516,
          281,
          1190,
          264,
          12325,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 696.3599999999999,
        "id": 213,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 694.7199999999999,
        "temperature": 0,
        "text": " I'm going to say the keyword up.",
        "tokens": [
          51166,
          286,
          478,
          516,
          281,
          584,
          264,
          20428,
          493,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 698.52,
        "id": 214,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 696.3599999999999,
        "temperature": 0,
        "text": " And then I'm going to try to look into the console",
        "tokens": [
          51248,
          400,
          550,
          286,
          478,
          516,
          281,
          853,
          281,
          574,
          666,
          264,
          11076,
          51356
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 699.76,
        "id": 215,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 698.52,
        "temperature": 0,
        "text": " to see if that's what came in.",
        "tokens": [
          51356,
          281,
          536,
          498,
          300,
          311,
          437,
          1361,
          294,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.25908866550611415,
        "compression_ratio": 1.6126126126126126,
        "end": 703.26,
        "id": 216,
        "no_speech_prob": 0.0001634644577279687,
        "seek": 67868,
        "start": 702.76,
        "temperature": 0,
        "text": " Up.",
        "tokens": [
          51568,
          5858,
          13,
          51593
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 704.5,
        "id": 217,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 703.9,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50396,
          400,
          456,
          321,
          352,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 705.62,
        "id": 218,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 704.5,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          50426,
          2053,
          412,
          300,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 708.26,
        "id": 219,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 705.62,
        "temperature": 0,
        "text": " Now, other stuff is coming in, but you saw it there.",
        "tokens": [
          50482,
          823,
          11,
          661,
          1507,
          307,
          1348,
          294,
          11,
          457,
          291,
          1866,
          309,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 710.66,
        "id": 220,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 708.26,
        "temperature": 0,
        "text": " So rather than debug with the console,",
        "tokens": [
          50614,
          407,
          2831,
          813,
          24083,
          365,
          264,
          11076,
          11,
          50734
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 715.3,
        "id": 221,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 710.66,
        "temperature": 0,
        "text": " let me actually put what I said onto the web page itself.",
        "tokens": [
          50734,
          718,
          385,
          767,
          829,
          437,
          286,
          848,
          3911,
          264,
          3670,
          3028,
          2564,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 717.26,
        "id": 222,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 715.3,
        "temperature": 0,
        "text": " Also, to make this easier to see,",
        "tokens": [
          50966,
          2743,
          11,
          281,
          652,
          341,
          3571,
          281,
          536,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 721.1,
        "id": 223,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 717.26,
        "temperature": 0,
        "text": " let me actually console.log results index 0 label",
        "tokens": [
          51064,
          718,
          385,
          767,
          11076,
          13,
          4987,
          3542,
          8186,
          1958,
          7645,
          51256
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 722.9,
        "id": 224,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 721.1,
        "temperature": 0,
        "text": " and results index 0.",
        "tokens": [
          51256,
          293,
          3542,
          8186,
          1958,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 724.62,
        "id": 225,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 722.9,
        "temperature": 0,
        "text": " I believe it's called confidence.",
        "tokens": [
          51346,
          286,
          1697,
          309,
          311,
          1219,
          6687,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 727.7,
        "id": 226,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 724.62,
        "temperature": 0,
        "text": " So rather than have this big array logging in the console,",
        "tokens": [
          51432,
          407,
          2831,
          813,
          362,
          341,
          955,
          10225,
          27991,
          294,
          264,
          11076,
          11,
          51586
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 729.5,
        "id": 227,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 727.7,
        "temperature": 0,
        "text": " let me actually just call it confidence.",
        "tokens": [
          51586,
          718,
          385,
          767,
          445,
          818,
          309,
          6687,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.5407521218964548,
        "compression_ratio": 1.8015873015873016,
        "end": 730.9,
        "id": 228,
        "no_speech_prob": 0.00003480796658550389,
        "seek": 70326,
        "start": 729.5,
        "temperature": 0,
        "text": " And then I'm going to say, well, I",
        "tokens": [
          51676,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          731,
          11,
          286,
          51746
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 733.1,
        "id": 229,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 730.9,
        "temperature": 0,
        "text": " don't want this big array logging in the console.",
        "tokens": [
          50364,
          500,
          380,
          528,
          341,
          955,
          10225,
          27991,
          294,
          264,
          11076,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 734.1,
        "id": 230,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 733.1,
        "temperature": 0,
        "text": " Let me do this.",
        "tokens": [
          50474,
          961,
          385,
          360,
          341,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 737.06,
        "id": 231,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 734.1,
        "temperature": 0,
        "text": " All right, so now we need to have a 95% confidence.",
        "tokens": [
          50524,
          1057,
          558,
          11,
          370,
          586,
          321,
          643,
          281,
          362,
          257,
          13420,
          4,
          6687,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 740.8199999999999,
        "id": 232,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 737.06,
        "temperature": 0,
        "text": " And I'm going to run this.",
        "tokens": [
          50672,
          400,
          286,
          478,
          516,
          281,
          1190,
          341,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 743.3,
        "id": 233,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 740.8199999999999,
        "temperature": 0,
        "text": " Up.",
        "tokens": [
          50860,
          5858,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 750.6999999999999,
        "id": 234,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 743.3,
        "temperature": 0,
        "text": " 3, 4, 5, 6, 7, 8.",
        "tokens": [
          50984,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1649,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 756.06,
        "id": 235,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 750.6999999999999,
        "temperature": 0,
        "text": " I'm quickly adding background color white to the HTML body",
        "tokens": [
          51354,
          286,
          478,
          2661,
          5127,
          3678,
          2017,
          2418,
          281,
          264,
          17995,
          1772,
          51622
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 757.98,
        "id": 236,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 756.06,
        "temperature": 0,
        "text": " because what I want to then do just quickly,",
        "tokens": [
          51622,
          570,
          437,
          286,
          528,
          281,
          550,
          360,
          445,
          2661,
          11,
          51718
        ]
      },
      {
        "avg_logprob": -0.28455176443423863,
        "compression_ratio": 1.4862385321100917,
        "end": 760.46,
        "id": 237,
        "no_speech_prob": 0.010169490240514278,
        "seek": 73090,
        "start": 757.98,
        "temperature": 0,
        "text": " but before I finish this off, but to finish this off,",
        "tokens": [
          51718,
          457,
          949,
          286,
          2413,
          341,
          766,
          11,
          457,
          281,
          2413,
          341,
          766,
          11,
          51842
        ]
      },
      {
        "avg_logprob": -0.23406307822779604,
        "compression_ratio": 1.6701030927835052,
        "end": 763.94,
        "id": 238,
        "no_speech_prob": 0.000018925014956039377,
        "seek": 76046,
        "start": 760.52,
        "temperature": 0,
        "text": " let me just add a DOM element using the p5 DOM library.",
        "tokens": [
          50367,
          718,
          385,
          445,
          909,
          257,
          35727,
          4478,
          1228,
          264,
          280,
          20,
          35727,
          6405,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.23406307822779604,
        "compression_ratio": 1.6701030927835052,
        "end": 767.14,
        "id": 239,
        "no_speech_prob": 0.000018925014956039377,
        "seek": 76046,
        "start": 763.94,
        "temperature": 0,
        "text": " I'm going to just say result p for results paragraph.",
        "tokens": [
          50538,
          286,
          478,
          516,
          281,
          445,
          584,
          1874,
          280,
          337,
          3542,
          18865,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.23406307822779604,
        "compression_ratio": 1.6701030927835052,
        "end": 776.1,
        "id": 240,
        "no_speech_prob": 0.000018925014956039377,
        "seek": 76046,
        "start": 767.14,
        "temperature": 0,
        "text": " I'm going to say result p equals create p waiting.",
        "tokens": [
          50698,
          286,
          478,
          516,
          281,
          584,
          1874,
          280,
          6915,
          1884,
          280,
          3806,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.23406307822779604,
        "compression_ratio": 1.6701030927835052,
        "end": 782.1800000000001,
        "id": 241,
        "no_speech_prob": 0.000018925014956039377,
        "seek": 76046,
        "start": 776.1,
        "temperature": 0,
        "text": " And then right now, I'm going to say result p.html.",
        "tokens": [
          51146,
          400,
          550,
          558,
          586,
          11,
          286,
          478,
          516,
          281,
          584,
          1874,
          280,
          13,
          357,
          15480,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.23406307822779604,
        "compression_ratio": 1.6701030927835052,
        "end": 784.4200000000001,
        "id": 242,
        "no_speech_prob": 0.000018925014956039377,
        "seek": 76046,
        "start": 782.1800000000001,
        "temperature": 0,
        "text": " Then I can turn these results into a string",
        "tokens": [
          51450,
          1396,
          286,
          393,
          1261,
          613,
          3542,
          666,
          257,
          6798,
          51562
        ]
      },
      {
        "avg_logprob": -0.23406307822779604,
        "compression_ratio": 1.6701030927835052,
        "end": 785.86,
        "id": 243,
        "no_speech_prob": 0.000018925014956039377,
        "seek": 76046,
        "start": 784.4200000000001,
        "temperature": 0,
        "text": " by using a string literal.",
        "tokens": [
          51562,
          538,
          1228,
          257,
          6798,
          20411,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.23406307822779604,
        "compression_ratio": 1.6701030927835052,
        "end": 789.82,
        "id": 244,
        "no_speech_prob": 0.000018925014956039377,
        "seek": 76046,
        "start": 785.86,
        "temperature": 0,
        "text": " So backtick and then put curly brackets.",
        "tokens": [
          51634,
          407,
          646,
          83,
          618,
          293,
          550,
          829,
          32066,
          26179,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.2934835729464679,
        "compression_ratio": 1.3161290322580645,
        "end": 794.98,
        "id": 245,
        "no_speech_prob": 0.0002780277864076197,
        "seek": 78982,
        "start": 789.82,
        "temperature": 0,
        "text": " Put a colon here and curly brackets and a close backtick.",
        "tokens": [
          50364,
          4935,
          257,
          8255,
          510,
          293,
          32066,
          26179,
          293,
          257,
          1998,
          646,
          83,
          618,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.2934835729464679,
        "compression_ratio": 1.3161290322580645,
        "end": 800.82,
        "id": 246,
        "no_speech_prob": 0.0002780277864076197,
        "seek": 78982,
        "start": 794.98,
        "temperature": 0,
        "text": " And let me also say result p style.",
        "tokens": [
          50622,
          400,
          718,
          385,
          611,
          584,
          1874,
          280,
          3758,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2934835729464679,
        "compression_ratio": 1.3161290322580645,
        "end": 801.7,
        "id": 247,
        "no_speech_prob": 0.0002780277864076197,
        "seek": 78982,
        "start": 800.82,
        "temperature": 0,
        "text": " Is it font size?",
        "tokens": [
          50914,
          1119,
          309,
          10703,
          2744,
          30,
          50958
        ]
      },
      {
        "avg_logprob": -0.2934835729464679,
        "compression_ratio": 1.3161290322580645,
        "end": 805.2600000000001,
        "id": 248,
        "no_speech_prob": 0.0002780277864076197,
        "seek": 78982,
        "start": 801.7,
        "temperature": 0,
        "text": " Font size, just 32 points.",
        "tokens": [
          50958,
          43901,
          2744,
          11,
          445,
          8858,
          2793,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.2934835729464679,
        "compression_ratio": 1.3161290322580645,
        "end": 806.38,
        "id": 249,
        "no_speech_prob": 0.0002780277864076197,
        "seek": 78982,
        "start": 805.2600000000001,
        "temperature": 0,
        "text": " So we'll be able to see it.",
        "tokens": [
          51136,
          407,
          321,
          603,
          312,
          1075,
          281,
          536,
          309,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.2934835729464679,
        "compression_ratio": 1.3161290322580645,
        "end": 808.3000000000001,
        "id": 250,
        "no_speech_prob": 0.0002780277864076197,
        "seek": 78982,
        "start": 806.38,
        "temperature": 0,
        "text": " All right, here we go.",
        "tokens": [
          51192,
          1057,
          558,
          11,
          510,
          321,
          352,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2934835729464679,
        "compression_ratio": 1.3161290322580645,
        "end": 809.0200000000001,
        "id": 251,
        "no_speech_prob": 0.0002780277864076197,
        "seek": 78982,
        "start": 808.3000000000001,
        "temperature": 0,
        "text": " Ready for this?",
        "tokens": [
          51288,
          9944,
          337,
          341,
          30,
          51324
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 822.46,
        "id": 252,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 809.02,
        "temperature": 0,
        "text": " 1, 2, 5, up, down, left, right.",
        "tokens": [
          50364,
          502,
          11,
          568,
          11,
          1025,
          11,
          493,
          11,
          760,
          11,
          1411,
          11,
          558,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 826.1,
        "id": 253,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 822.46,
        "temperature": 0,
        "text": " OK, so you could imagine now what you could do with this.",
        "tokens": [
          51036,
          2264,
          11,
          370,
          291,
          727,
          3811,
          586,
          437,
          291,
          727,
          360,
          365,
          341,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 829.62,
        "id": 254,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 826.1,
        "temperature": 0,
        "text": " For example, you could control a game with your voice.",
        "tokens": [
          51218,
          1171,
          1365,
          11,
          291,
          727,
          1969,
          257,
          1216,
          365,
          428,
          3177,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 832.26,
        "id": 255,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 829.62,
        "temperature": 0,
        "text": " In fact, I'm going to do that in one of my coding challenge",
        "tokens": [
          51394,
          682,
          1186,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          294,
          472,
          295,
          452,
          17720,
          3430,
          51526
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 832.86,
        "id": 256,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 832.26,
        "temperature": 0,
        "text": " videos.",
        "tokens": [
          51526,
          2145,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 834.78,
        "id": 257,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 832.86,
        "temperature": 0,
        "text": " So take a look at this video's description.",
        "tokens": [
          51556,
          407,
          747,
          257,
          574,
          412,
          341,
          960,
          311,
          3855,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 836.86,
        "id": 258,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 834.78,
        "temperature": 0,
        "text": " I'm going to do a coding challenge where I program",
        "tokens": [
          51652,
          286,
          478,
          516,
          281,
          360,
          257,
          17720,
          3430,
          689,
          286,
          1461,
          51756
        ]
      },
      {
        "avg_logprob": -0.2573170893400618,
        "compression_ratio": 1.5857142857142856,
        "end": 837.98,
        "id": 259,
        "no_speech_prob": 0.0005112542421557009,
        "seek": 80902,
        "start": 836.86,
        "temperature": 0,
        "text": " the Google Dinosaur game.",
        "tokens": [
          51756,
          264,
          3329,
          413,
          15220,
          3463,
          1216,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.30719904899597167,
        "compression_ratio": 1.564516129032258,
        "end": 840.14,
        "id": 260,
        "no_speech_prob": 0.000035912707971874624,
        "seek": 83798,
        "start": 837.98,
        "temperature": 0,
        "text": " And then I'm going to add this sound classifier",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          516,
          281,
          909,
          341,
          1626,
          1508,
          9902,
          50472
        ]
      },
      {
        "avg_logprob": -0.30719904899597167,
        "compression_ratio": 1.564516129032258,
        "end": 841.5,
        "id": 261,
        "no_speech_prob": 0.000035912707971874624,
        "seek": 83798,
        "start": 840.14,
        "temperature": 0,
        "text": " to have the dinosaur jump.",
        "tokens": [
          50472,
          281,
          362,
          264,
          23627,
          3012,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.30719904899597167,
        "compression_ratio": 1.564516129032258,
        "end": 842.4200000000001,
        "id": 262,
        "no_speech_prob": 0.000035912707971874624,
        "seek": 83798,
        "start": 841.5,
        "temperature": 0,
        "text": " Because if it won't be a dinosaur,",
        "tokens": [
          50540,
          1436,
          498,
          309,
          1582,
          380,
          312,
          257,
          23627,
          11,
          50586
        ]
      },
      {
        "avg_logprob": -0.30719904899597167,
        "compression_ratio": 1.564516129032258,
        "end": 844.9,
        "id": 263,
        "no_speech_prob": 0.000035912707971874624,
        "seek": 83798,
        "start": 842.4200000000001,
        "temperature": 0,
        "text": " it'll be a unicorn, to have the unicorn jump",
        "tokens": [
          50586,
          309,
          603,
          312,
          257,
          28122,
          11,
          281,
          362,
          264,
          28122,
          3012,
          50710
        ]
      },
      {
        "avg_logprob": -0.30719904899597167,
        "compression_ratio": 1.564516129032258,
        "end": 846.46,
        "id": 264,
        "no_speech_prob": 0.000035912707971874624,
        "seek": 83798,
        "start": 844.9,
        "temperature": 0,
        "text": " when I say the key word up.",
        "tokens": [
          50710,
          562,
          286,
          584,
          264,
          2141,
          1349,
          493,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.30719904899597167,
        "compression_ratio": 1.564516129032258,
        "end": 849.34,
        "id": 265,
        "no_speech_prob": 0.000035912707971874624,
        "seek": 83798,
        "start": 846.46,
        "temperature": 0,
        "text": " All right, thanks for watching this additional ML5 tutorial",
        "tokens": [
          50788,
          1057,
          558,
          11,
          3231,
          337,
          1976,
          341,
          4497,
          21601,
          20,
          7073,
          50932
        ]
      },
      {
        "avg_logprob": -0.30719904899597167,
        "compression_ratio": 1.564516129032258,
        "end": 852.26,
        "id": 266,
        "no_speech_prob": 0.000035912707971874624,
        "seek": 83798,
        "start": 849.34,
        "temperature": 0,
        "text": " video about sound classification in the browser.",
        "tokens": [
          50932,
          960,
          466,
          1626,
          21538,
          294,
          264,
          11185,
          13,
          51078
        ]
      }
    ],
    "transcription": " Hello and welcome to another beginner's guide to machine learning with ml5js in JavaScript. So I'm here, it's been a while since I added a video to this playlist and a bunch of things about the ml5 library itself have changed. There's a new release, 0.3.1. There is a brand new website which you can find right here at ml5js.org. So to some extent this video is really an update about the library, but I'm also going to look at one particular feature, a new feature of the library, sound classification. The machine learning model that I'm going to use in this video is the speech command recognizer. And this is a model available from Google as part of TensorFlow.js models. Now so this is a really important distinction. I am not here to train a sound classifier. I might do that in a future video and show you about how to apply transfer learning, which is something I did with images, also to sounds. I'm just going to make use of a freely available pre-trained machine learning model. Anytime you use one of those things, even in just a playful and experimental way, which is what I'm doing, it's good to do a little bit of research and take a look at, well, how is this trained? What was the data? What are the considerations around how the data was collected? And so I encourage you to read through the readme here on GitHub, and in particular to click over and read the original paper about this speech commands model. And there you'll see, if you look, it talks about some of the data sets, like Mozilla's common voice data set, 500 hours from 20,000 different people. This Libre speech, 1,000 hours of read English speech. I don't know how to say this. Tidy digits, tididits, t-digits, 25,000 digit sequences, which apparently was probably me, right? It was probably hours and hours of me reading this random number book over and over again. But so I encourage you to check out this paper. And you can also find code for how to use this model at TensorFlow.js in the TF.js models GitHub repo itself. I also want to interrupt this video for a second to talk about how the sound classifier actually works. This is kind of a surprising little tidbit. And I'll come back to this more if at some point I create a video about training your own sound classifier. Now, there's different ways you could do this. This isn't the way to make a sound classifier. But this is the way that this particular model works. It's actually, shockingly, amazingly doing image classification. So if you imagine we have this thing that's called a convolutional neural network, this is the underlying architecture, the structure of that machine learning model that does the classification. Typically, this kind of model is something that we would put images in. Like we might have images of cats. We might have an image of a turtle. No, that's not really a turtle, but whatever. So the idea is that we're sending these images in and getting back a label and maybe a confidence score. So it's the same idea. The only thing is now we want to send in audio and get back a label like up or 1 and a confidence score. So how would we convert sound into an image? Now again, there are other neural network architectures of which you could receive sound data in maybe a more direct fashion. But if you've ever looked at a graphic equalizer or some type of sound visualization system, I've made examples like this in p5, you can draw something that's often referred to as the spectrogram, which is basically a graph of all the various amplitudes of frequencies of the wave patterns of the sound itself. So if we took like a one second spectrogram and made that into an image, we could then send that image into a convolutional neural network saying that's the image that is produced from the spectrogram of somebody saying the word up. So underneath the hood, this machine learning system, even though it's designed to work with audio data, it first takes that audio data, converts it into an image, and then sends it through a very similar types of neural network architecture to standard image classification models. And you can read more about that in that paper itself. However, I'm going to show you how to access this model in a quick way with the ml5 library. And this is the new as of today, which is, I don't know, what's today's date? June 13, 2019. I'm going to show you how to use this with the ml5 library as it stands today. So I'm going to click here under reference. One thing you should see, there's a lot of new features have been added to the ml5 library. I'm going to come back and do videos about more of those. But the one I want to highlight here is sound classifier. So I'm going to click on this. And for all of the different functions available in ml5, you'll find a documentation page with some narrative documentation, a little bit of a code snippet, and then some written documentation about what the function names are and the various parameters and things like that. By the way, I'm noticing now, this will hopefully not read. This is like a mistake. This is documentation that's actually for either body pics or maybe the unit model, which does something called image segmentation. So we've got to get that fixed. I'm sure many GitHub issues and fixes will be out and done by the time you see this. So in case you've forgotten how to use the ml5 library, I'm just going to show you as it's documented on the ml5 web page. So first of all, you can go here to this quick start. You can actually just click on this open p5 web editor sketch with ml5.js added. You know what? I'm going to do that. That's the way I'm going to do it. But you also could just put a script tag in your HTML page referencing the current version of the library, which as I said, is 0.3.1 as of today. But probably while you're watching it, it'll be a higher number. So let me go and just open up this link here. And now I'm in the p5 web editor. You can see the name of the sketch is ml5.js boilerplate. Thank you, Joey Lee, who's a contributor to ml5. He's done a ton of work on the website and all the different features. And oh, this should actually be 3.1. I'm going to fix that. Uh-huh. I'm going to hit save. And then I'm going to rename it to sound classifier. And I am going to then go over here and go to sketch.js. And I'm going to run this. And we should see. There we go. So now we know it's working because there's a little console log to log ml5.version. If I hadn't imported the ml5 library, I wouldn't see that. We see that here. So what are we going to do? Let's load the sound classifier. Now most of the models, I haven't been using this in my previous videos, most of the models in ml5 are now actually available to you in preload, meaning you don't need a callback function. You can just load the model in preload, and it'll be ready by the time you get to set up. So I'm going to make a variable called sound classifier. In preload, I'm going to say sound classifier equals ml5 sound classifier. Now I need to tell it what model I want to load. So I need to in here put the name of the model I want to load. And in theory, in the future, there might be a bunch of different options, different kinds of sound classifiers, or maybe a sound classifier you've trained yourself that you want to put in there. And I'll come back eventually, show you videos about how to do that. But for right now, I'm just going to say speech commands, and then I already forgot what it was called. So I'm going to go back to the ml5 website, which is here. I'm going to go to reference. I'm going to go to sound classifier, and I'm looking for it here. So it's speech commands 18w. This is a particular model that's been trained on 18 specific words. And you can see what those are. The 10 digits from 0 to 9, up, down, left, right, go, stop, yes, no. That's 18. 10 digits, 8 different words. All right, so now I'm going to go, so it's 18w. And then once that model is loaded, I need a callback. So I could just say sound classifier classify. I might just call it got results. So in other words, I'm, oh, it's not defined, right? So I'm telling the sound classifier to classify. Now, by default, it's just going to listen to the microphone's audio. Maybe in the future, part of ml5 will be able to offer hooks to how you can connect it to a different audio source. But it's basically just going to work with the microphone's audio. Then I can write a function called got results. And I'm going to get rid of the draw loop, because I don't need that right now. Let me just turn off auto refresh so that it doesn't keep refreshing. Now, if you remember, ml5 employs error first callbacks, meaning the callback function requires two arguments, an error argument in case something went wrong, and a data or a result or some other argument where the actual stuff is. So I'm going to say error, and then I'm going to say results. And then I could do a little basic error handling. I'm just going to say console log something went wrong. And then I can also actually log the error. And then I'm going to say console log results. So let's see if we get anything. Oh, I have to run it again. You can ignore this error. Oh, something came in. Ready? Up. I just want to stop and mention that if you're following this along, hopefully your browser is asking for permission to use the microphone. The reason why that didn't happen here in this video is because I've already set my browser to allow use of the microphone on the p5 web editor pages. But for security, you can't just access anybody's microphone from a web page without the user giving permission. So hopefully you saw that happen. And if you didn't, that might be why you run into an error if you haven't given that permission. This is getting a little hard to debug just because so much stuff is happening here in the console and this huge arrays. But there's actually something that I missed that I could add here, which is an options variable. So one of the things I can tell, there's a lot of things I can set as properties or parameters for how the sound classifier should work. But there's a very simple one, which I'm going to just look it up in the documentation because I don't remember. It's called the probability threshold. So I'm actually just going to copy paste this here. What this means is basically the sound classifier is going to trigger an event where it's going to come. Right now, I'm console logging all of this information about what it thinks it heard based on a confidence level for how sure it is it heard one of those keywords. And right now, a lot of those events are triggering because I don't know what the default probability threshold is. Maybe it was 0.7. Maybe it's 0.5. But I'm going to make that really high. I'm going to say 0.95. So it has to have a 95% of them. The machine learning model has to calculate a 95% confidence score before it gives the event back to me in ml5. Once I've created that options variable with 0.95, I need to pass it into the constructor as the second argument. So now, we pass it in there. I'm going to run the sketch. I'm going to say the keyword up. And then I'm going to try to look into the console to see if that's what came in. Up. And there we go. Look at that. Now, other stuff is coming in, but you saw it there. So rather than debug with the console, let me actually put what I said onto the web page itself. Also, to make this easier to see, let me actually console.log results index 0 label and results index 0. I believe it's called confidence. So rather than have this big array logging in the console, let me actually just call it confidence. And then I'm going to say, well, I don't want this big array logging in the console. Let me do this. All right, so now we need to have a 95% confidence. And I'm going to run this. Up. 3, 4, 5, 6, 7, 8. I'm quickly adding background color white to the HTML body because what I want to then do just quickly, but before I finish this off, but to finish this off, let me just add a DOM element using the p5 DOM library. I'm going to just say result p for results paragraph. I'm going to say result p equals create p waiting. And then right now, I'm going to say result p.html. Then I can turn these results into a string by using a string literal. So backtick and then put curly brackets. Put a colon here and curly brackets and a close backtick. And let me also say result p style. Is it font size? Font size, just 32 points. So we'll be able to see it. All right, here we go. Ready for this? 1, 2, 5, up, down, left, right. OK, so you could imagine now what you could do with this. For example, you could control a game with your voice. In fact, I'm going to do that in one of my coding challenge videos. So take a look at this video's description. I'm going to do a coding challenge where I program the Google Dinosaur game. And then I'm going to add this sound classifier to have the dinosaur jump. Because if it won't be a dinosaur, it'll be a unicorn, to have the unicorn jump when I say the key word up. All right, thanks for watching this additional ML5 tutorial video about sound classification in the browser.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:32.20626Z",
  "started_at": "2023-09-26T21:13:54.900242Z",
  "completed_at": "2023-09-26T21:17:51.126381Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=cO4UP2dX944",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 236.226139
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/rvweabzbvjhmmgmputhnt7xuz4/cancel",
    "get": "https://api.replicate.com/v1/predictions/rvweabzbvjhmmgmputhnt7xuz4"
  }
}