{
  "id": "smn2v4jbiv4lu4waqemzryzieu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/4L4JyWyb3oI.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/871551 [00:00<?, ?frames/s]\n  0%|          | 3000/871551 [00:01<08:20, 1735.26frames/s]\n  1%|          | 5542/871551 [00:04<13:01, 1108.85frames/s]\n  1%|          | 8418/871551 [00:09<18:56, 759.38frames/s] \n  1%|▏         | 11418/871551 [00:14<19:47, 724.34frames/s]\n  2%|▏         | 14014/871551 [00:17<19:47, 721.91frames/s]\n  2%|▏         | 16754/871551 [00:21<19:09, 743.39frames/s]\n  2%|▏         | 19754/871551 [00:26<20:43, 685.16frames/s]\n  3%|▎         | 22754/871551 [00:30<19:37, 720.68frames/s]\n  3%|▎         | 25538/871551 [00:34<20:17, 694.85frames/s]\n  3%|▎         | 28256/871551 [00:39<21:15, 661.34frames/s]\n  4%|▎         | 30640/871551 [00:42<21:03, 665.69frames/s]\n  4%|▍         | 33640/871551 [00:46<20:01, 697.43frames/s]\n  4%|▍         | 36200/871551 [00:49<18:50, 739.24frames/s]\n  4%|▍         | 38864/871551 [00:53<20:16, 684.24frames/s]\n  5%|▍         | 41864/871551 [00:57<19:27, 710.74frames/s]\n  5%|▌         | 44812/871551 [01:00<17:26, 789.85frames/s]\n  5%|▌         | 47592/871551 [01:03<16:21, 839.82frames/s]\n  6%|▌         | 50220/871551 [01:07<17:22, 788.20frames/s]\n  6%|▌         | 52820/871551 [01:11<17:57, 759.52frames/s]\n  6%|▋         | 55820/871551 [01:13<16:12, 838.85frames/s]\n  7%|▋         | 58184/871551 [01:16<15:50, 855.50frames/s]\n  7%|▋         | 61000/871551 [01:21<18:38, 724.72frames/s]\n  7%|▋         | 64000/871551 [01:27<20:33, 654.91frames/s]\n  8%|▊         | 66816/871551 [01:32<22:27, 597.13frames/s]\n  8%|▊         | 69504/871551 [01:38<23:50, 560.56frames/s]\n  8%|▊         | 72304/871551 [01:43<24:29, 543.72frames/s]\n  9%|▊         | 74866/871551 [01:46<21:23, 620.68frames/s]\n  9%|▉         | 77866/871551 [01:50<20:39, 640.42frames/s]\n  9%|▉         | 80454/871551 [01:55<20:48, 633.47frames/s]\n 10%|▉         | 83378/871551 [01:59<20:24, 643.64frames/s]\n 10%|▉         | 85550/871551 [02:03<21:05, 621.33frames/s]\n 10%|█         | 88190/871551 [02:07<20:58, 622.54frames/s]\n 10%|█         | 90778/871551 [02:12<22:34, 576.56frames/s]\n 11%|█         | 93566/871551 [02:17<21:49, 594.26frames/s]\n 11%|█         | 96378/871551 [02:22<22:58, 562.28frames/s]\n 11%|█▏        | 98978/871551 [02:26<22:19, 576.65frames/s]\n 12%|█▏        | 101856/871551 [02:31<21:10, 605.92frames/s]\n 12%|█▏        | 104360/871551 [02:36<22:24, 570.64frames/s]\n 12%|█▏        | 107020/871551 [02:41<23:21, 545.52frames/s]\n 13%|█▎        | 109608/871551 [02:46<24:06, 526.82frames/s]\n 13%|█▎        | 112448/871551 [02:51<22:32, 561.11frames/s]\n 13%|█▎        | 115088/871551 [02:56<22:30, 560.14frames/s]\n 13%|█▎        | 117584/871551 [03:01<23:19, 538.83frames/s]\n 14%|█▍        | 120292/871551 [03:07<24:29, 511.29frames/s]\n 14%|█▍        | 122484/871551 [03:11<24:55, 500.86frames/s]\n 14%|█▍        | 124796/871551 [03:14<22:39, 549.29frames/s]\n 15%|█▍        | 127300/871551 [03:17<20:30, 604.96frames/s]\n 15%|█▍        | 129812/871551 [03:22<21:15, 581.40frames/s]\n 15%|█▌        | 132604/871551 [03:27<21:48, 564.80frames/s]\n 16%|█▌        | 135372/871551 [03:32<20:35, 595.67frames/s]\n 16%|█▌        | 138140/871551 [03:37<21:35, 566.00frames/s]\n 16%|█▌        | 140780/871551 [03:42<21:51, 557.41frames/s]\n 16%|█▋        | 143204/871551 [03:47<22:37, 536.38frames/s]\n 17%|█▋        | 145636/871551 [03:53<24:21, 496.69frames/s]\n 17%|█▋        | 148164/871551 [03:58<24:58, 482.85frames/s]\n 17%|█▋        | 151094/871551 [04:12<35:13, 340.85frames/s]\n 18%|█▊        | 153758/871551 [04:17<31:11, 383.44frames/s]\n 18%|█▊        | 156558/871551 [04:22<27:35, 431.86frames/s]\n 18%|█▊        | 159286/871551 [04:27<26:37, 445.82frames/s]\n 19%|█▊        | 161918/871551 [04:33<27:01, 437.70frames/s]\n 19%|█▉        | 164318/871551 [04:37<24:31, 480.52frames/s]\n 19%|█▉        | 167030/871551 [04:41<21:32, 545.09frames/s]\n 20%|█▉        | 170030/871551 [04:43<17:53, 653.23frames/s]\n 20%|█▉        | 172862/871551 [04:47<16:50, 691.47frames/s]\n 20%|██        | 175862/871551 [04:49<14:15, 812.87frames/s]\n 21%|██        | 178862/871551 [04:53<14:30, 796.11frames/s]\n 21%|██        | 181622/871551 [04:59<17:49, 645.12frames/s]\n 21%|██        | 184142/871551 [05:05<19:36, 584.04frames/s]\n 21%|██▏       | 186742/871551 [05:10<20:37, 553.23frames/s]\n 22%|██▏       | 189742/871551 [05:15<20:12, 562.19frames/s]\n 22%|██▏       | 192398/871551 [05:20<20:30, 551.84frames/s]\n 22%|██▏       | 195022/871551 [05:24<19:05, 590.67frames/s]\n 23%|██▎       | 197614/871551 [05:29<19:28, 576.66frames/s]\n 23%|██▎       | 199886/871551 [05:33<20:00, 559.46frames/s]\n 23%|██▎       | 202734/871551 [05:38<19:49, 562.27frames/s]\n 24%|██▎       | 205510/871551 [05:43<19:14, 577.16frames/s]\n 24%|██▍       | 207974/871551 [05:45<17:12, 642.58frames/s]\n 24%|██▍       | 210974/871551 [05:50<17:06, 643.64frames/s]\n 25%|██▍       | 213910/871551 [05:54<16:49, 651.62frames/s]\n 25%|██▍       | 216704/871551 [06:01<19:17, 565.87frames/s]\n 25%|██▌       | 219152/871551 [06:06<20:04, 541.61frames/s]\n 25%|██▌       | 221904/871551 [06:11<19:51, 545.39frames/s]\n 26%|██▌       | 224904/871551 [06:17<20:34, 523.97frames/s]\n 26%|██▌       | 227640/871551 [06:23<21:05, 508.89frames/s]\n 26%|██▋       | 230376/871551 [06:29<22:13, 480.85frames/s]\n 27%|██▋       | 232968/871551 [06:35<22:53, 464.85frames/s]\n 27%|██▋       | 235600/871551 [06:40<22:02, 480.84frames/s]\n 27%|██▋       | 238248/871551 [06:45<20:56, 504.16frames/s]\n 28%|██▊       | 241248/871551 [06:48<17:30, 599.81frames/s]\n 28%|██▊       | 244064/871551 [06:52<16:32, 632.24frames/s]\n 28%|██▊       | 246992/871551 [06:57<17:12, 604.71frames/s]\n 29%|██▊       | 249642/871551 [07:02<17:36, 588.80frames/s]\n 29%|██▉       | 252428/871551 [07:07<18:07, 569.39frames/s]\n 29%|██▉       | 255100/871551 [07:13<19:18, 532.02frames/s]\n 30%|██▉       | 257644/871551 [07:18<19:39, 520.43frames/s]\n 30%|██▉       | 260644/871551 [07:24<19:36, 519.37frames/s]\n 30%|███       | 263388/871551 [07:27<16:55, 598.79frames/s]\n 31%|███       | 265852/871551 [07:32<17:41, 570.70frames/s]\n 31%|███       | 268852/871551 [07:37<17:20, 579.17frames/s]\n 31%|███       | 271148/871551 [07:41<17:38, 567.45frames/s]\n 31%|███▏      | 273868/871551 [07:47<18:30, 538.01frames/s]\n 32%|███▏      | 276868/871551 [07:50<16:12, 611.24frames/s]\n 32%|███▏      | 279868/871551 [07:54<15:18, 644.06frames/s]\n 32%|███▏      | 282684/871551 [07:59<15:11, 646.38frames/s]\n 33%|███▎      | 285116/871551 [08:03<15:22, 635.98frames/s]\n 33%|███▎      | 287468/871551 [08:07<16:09, 602.40frames/s]\n 33%|███▎      | 289756/871551 [08:11<16:02, 604.23frames/s]\n 34%|███▎      | 292372/871551 [08:16<17:21, 555.90frames/s]\n 34%|███▍      | 295142/871551 [08:21<17:12, 558.49frames/s]\n 34%|███▍      | 298142/871551 [08:24<14:10, 674.34frames/s]\n 35%|███▍      | 300982/871551 [08:29<14:35, 651.44frames/s]\n 35%|███▍      | 303798/871551 [08:34<15:58, 592.28frames/s]\n 35%|███▌      | 306462/871551 [08:39<15:55, 591.64frames/s]\n 35%|███▌      | 309206/871551 [08:43<15:31, 604.01frames/s]\n 36%|███▌      | 312014/871551 [08:49<16:17, 572.17frames/s]\n 36%|███▌      | 314790/871551 [08:54<16:27, 563.81frames/s]\n 36%|███▋      | 317334/871551 [08:57<15:00, 615.22frames/s]\n 37%|███▋      | 320022/871551 [09:02<15:37, 588.17frames/s]\n 37%|███▋      | 322694/871551 [09:06<15:10, 602.78frames/s]\n 37%|███▋      | 325694/871551 [09:10<14:17, 636.92frames/s]\n 38%|███▊      | 328368/871551 [09:15<14:25, 627.57frames/s]\n 38%|███▊      | 330290/871551 [09:17<13:08, 686.05frames/s]\n 38%|███▊      | 333010/871551 [09:19<11:33, 777.00frames/s]\n 39%|███▊      | 335730/871551 [09:22<10:47, 827.12frames/s]\n 39%|███▉      | 338730/871551 [09:25<09:39, 919.97frames/s]\n 39%|███▉      | 341730/871551 [09:27<08:55, 988.64frames/s]\n 40%|███▉      | 344730/871551 [09:29<08:02, 1092.53frames/s]\n 40%|███▉      | 347546/871551 [09:32<08:25, 1037.48frames/s]\n 40%|████      | 350546/871551 [09:35<08:34, 1013.61frames/s]\n 41%|████      | 353418/871551 [09:39<09:15, 932.54frames/s] \n 41%|████      | 355522/871551 [09:41<09:15, 928.91frames/s]\n 41%|████      | 355522/871551 [09:57<09:15, 928.91frames/s]\n 41%|████      | 357890/871551 [10:03<27:51, 307.31frames/s]\n 41%|████▏     | 360250/871551 [10:16<33:22, 255.37frames/s]\n 41%|████▏     | 360250/871551 [10:27<33:22, 255.37frames/s]\n 42%|████▏     | 363130/871551 [10:27<33:29, 252.95frames/s]\n 42%|████▏     | 365826/871551 [10:33<28:53, 291.70frames/s]\n 42%|████▏     | 368578/871551 [10:39<24:50, 337.41frames/s]\n 43%|████▎     | 371282/871551 [10:45<22:54, 364.00frames/s]\n 43%|████▎     | 374282/871551 [10:48<18:44, 442.07frames/s]\n 43%|████▎     | 376930/871551 [10:53<16:56, 486.81frames/s]\n 44%|████▎     | 379570/871551 [11:00<18:30, 442.91frames/s]\n 44%|████▍     | 382482/871551 [11:04<16:39, 489.12frames/s]\n 44%|████▍     | 385416/871551 [11:09<15:37, 518.48frames/s]\n 45%|████▍     | 388416/871551 [11:14<14:13, 565.95frames/s]\n 45%|████▍     | 391024/871551 [11:18<14:23, 556.70frames/s]\n 45%|████▌     | 394024/871551 [11:25<14:53, 534.34frames/s]\n 46%|████▌     | 396968/871551 [11:30<15:03, 525.18frames/s]\n 46%|████▌     | 399752/871551 [11:36<14:59, 524.48frames/s]\n 46%|████▌     | 402216/871551 [11:40<14:54, 524.96frames/s]\n 46%|████▋     | 405168/871551 [11:47<15:41, 495.56frames/s]\n 47%|████▋     | 407816/871551 [11:50<13:53, 556.62frames/s]\n 47%|████▋     | 410760/871551 [11:54<12:01, 638.39frames/s]\n 47%|████▋     | 413464/871551 [11:57<11:13, 679.70frames/s]\n 48%|████▊     | 415528/871551 [12:00<11:07, 683.68frames/s]\n 48%|████▊     | 418128/871551 [12:04<11:14, 672.20frames/s]\n 48%|████▊     | 420066/871551 [12:07<11:37, 647.47frames/s]\n 49%|████▊     | 422874/871551 [12:10<10:08, 737.90frames/s]\n 49%|████▉     | 425874/871551 [12:13<09:23, 791.27frames/s]\n 49%|████▉     | 428698/871551 [12:17<09:41, 761.81frames/s]\n 49%|████▉     | 431410/871551 [12:19<07:53, 929.55frames/s]\n 50%|████▉     | 434250/871551 [12:23<09:01, 806.98frames/s]\n 50%|█████     | 437082/871551 [12:29<11:06, 651.99frames/s]\n 50%|█████     | 439706/871551 [12:34<11:26, 628.86frames/s]\n 51%|█████     | 442482/871551 [12:40<12:17, 582.09frames/s]\n 51%|█████     | 445250/871551 [12:45<12:33, 565.66frames/s]\n 51%|█████▏    | 447994/871551 [12:50<12:32, 562.90frames/s]\n 52%|█████▏    | 450650/871551 [12:55<13:06, 534.83frames/s]\n 52%|█████▏    | 453170/871551 [12:59<12:24, 562.34frames/s]\n 52%|█████▏    | 455538/871551 [13:02<11:37, 596.20frames/s]\n 53%|█████▎    | 458138/871551 [13:07<11:59, 574.23frames/s]\n 53%|█████▎    | 460626/871551 [13:12<11:49, 579.28frames/s]\n 53%|█████▎    | 463234/871551 [13:17<12:20, 551.38frames/s]\n 53%|█████▎    | 466234/871551 [13:23<12:54, 523.44frames/s]\n 54%|█████▍    | 469194/871551 [13:28<12:01, 557.97frames/s]\n 54%|█████▍    | 472034/871551 [13:44<20:04, 331.59frames/s]\n 54%|█████▍    | 474594/871551 [13:49<17:39, 374.64frames/s]\n 55%|█████▍    | 477098/871551 [13:53<15:47, 416.26frames/s]\n 55%|█████▌    | 479458/871551 [13:58<15:02, 434.39frames/s]\n 55%|█████▌    | 482010/871551 [14:03<14:00, 463.41frames/s]\n 56%|█████▌    | 484674/871551 [14:08<13:29, 477.76frames/s]\n 56%|█████▌    | 487506/871551 [14:13<12:56, 494.31frames/s]\n 56%|█████▌    | 490202/871551 [14:19<13:04, 486.08frames/s]\n 57%|█████▋    | 493074/871551 [14:25<12:53, 489.20frames/s]\n 57%|█████▋    | 495938/871551 [14:30<12:16, 510.10frames/s]\n 57%|█████▋    | 498690/871551 [14:36<12:37, 491.97frames/s]\n 58%|█████▊    | 501314/871551 [14:41<12:25, 496.82frames/s]\n 58%|█████▊    | 503940/871551 [14:48<13:15, 462.10frames/s]\n 58%|█████▊    | 506582/871551 [14:52<12:08, 501.00frames/s]\n 58%|█████▊    | 509430/871551 [14:58<12:14, 493.01frames/s]\n 59%|█████▉    | 512430/871551 [15:01<10:33, 566.91frames/s]\n 59%|█████▉    | 515230/871551 [15:05<09:54, 598.92frames/s]\n 59%|█████▉    | 518030/871551 [15:08<08:41, 677.30frames/s]\n 60%|█████▉    | 520646/871551 [15:12<08:43, 669.76frames/s]\n 60%|█████▉    | 522774/871551 [15:15<08:27, 686.90frames/s]\n 60%|██████    | 525494/871551 [15:18<07:33, 762.65frames/s]\n 61%|██████    | 528238/871551 [15:21<07:04, 807.84frames/s]\n 61%|██████    | 531238/871551 [15:24<06:32, 867.18frames/s]\n 61%|██████▏   | 533934/871551 [15:27<06:17, 894.89frames/s]\n 62%|██████▏   | 536934/871551 [15:29<05:27, 1022.73frames/s]\n 62%|██████▏   | 539670/871551 [15:32<05:34, 993.42frames/s] \n 62%|██████▏   | 539966/871551 [15:32<06:05, 908.17frames/s]\n 62%|██████▏   | 542694/871551 [15:34<04:37, 1183.85frames/s]\n 63%|██████▎   | 545430/871551 [15:39<06:28, 839.47frames/s] \n 63%|██████▎   | 548246/871551 [15:45<08:39, 621.92frames/s]\n 63%|██████▎   | 551054/871551 [15:52<10:06, 528.13frames/s]\n 64%|██████▎   | 553678/871551 [15:57<09:41, 546.20frames/s]\n 64%|██████▍   | 556470/871551 [16:03<10:12, 514.35frames/s]\n 64%|██████▍   | 559374/871551 [16:08<09:43, 534.83frames/s]\n 65%|██████▍   | 562230/871551 [16:13<09:24, 547.53frames/s]\n 65%|██████▍   | 564958/871551 [16:19<09:44, 524.20frames/s]\n 65%|██████▌   | 567958/871551 [16:25<09:51, 513.13frames/s]\n 65%|██████▌   | 570782/871551 [16:29<09:12, 544.06frames/s]\n 66%|██████▌   | 573286/871551 [16:34<09:16, 535.84frames/s]\n 66%|██████▌   | 576286/871551 [16:35<06:58, 704.83frames/s]\n 66%|██████▋   | 578846/871551 [16:40<07:26, 654.92frames/s]\n 67%|██████▋   | 581846/871551 [16:44<07:16, 663.85frames/s]\n 67%|██████▋   | 584846/871551 [16:49<07:01, 680.41frames/s]\n 67%|██████▋   | 587422/871551 [16:51<06:24, 739.81frames/s]\n 68%|██████▊   | 590246/871551 [16:56<06:40, 703.12frames/s]\n 68%|██████▊   | 593166/871551 [17:01<06:56, 669.05frames/s]\n 68%|██████▊   | 595766/871551 [17:06<07:24, 620.92frames/s]\n 69%|██████▊   | 598502/871551 [17:10<07:14, 628.67frames/s]\n 69%|██████▉   | 601166/871551 [17:15<07:30, 599.82frames/s]\n 69%|██████▉   | 603838/871551 [17:20<07:56, 562.02frames/s]\n 70%|██████▉   | 606694/871551 [17:26<08:13, 536.87frames/s]\n 70%|██████▉   | 609694/871551 [17:28<06:25, 679.97frames/s]\n 70%|███████   | 612694/871551 [17:43<11:12, 385.16frames/s]\n 71%|███████   | 615526/871551 [17:48<09:43, 438.47frames/s]\n 71%|███████   | 618526/871551 [17:53<09:06, 463.29frames/s]\n 71%|███████▏  | 621526/871551 [17:55<07:01, 592.86frames/s]\n 72%|███████▏  | 624062/871551 [17:57<06:01, 684.67frames/s]\n 72%|███████▏  | 627062/871551 [18:00<05:16, 772.41frames/s]\n 72%|███████▏  | 629734/871551 [18:04<05:22, 750.98frames/s]\n 73%|███████▎  | 632006/871551 [18:08<05:41, 701.10frames/s]\n 73%|███████▎  | 635006/871551 [18:14<06:35, 597.51frames/s]\n 73%|███████▎  | 637670/871551 [18:18<06:12, 627.54frames/s]\n 73%|███████▎  | 640390/871551 [18:20<05:20, 720.71frames/s]\n 74%|███████▍  | 643390/871551 [18:22<04:10, 910.59frames/s]\n 74%|███████▍  | 646390/871551 [18:24<03:48, 985.97frames/s]\n 74%|███████▍  | 649126/871551 [18:29<04:28, 828.71frames/s]\n 75%|███████▍  | 651606/871551 [18:32<04:32, 808.00frames/s]\n 75%|███████▌  | 654366/871551 [18:36<04:49, 751.21frames/s]\n 75%|███████▌  | 657366/871551 [18:41<05:03, 706.82frames/s]\n 76%|███████▌  | 660366/871551 [18:45<04:52, 721.97frames/s]\n 76%|███████▌  | 663086/871551 [18:49<04:49, 719.21frames/s]\n 76%|███████▋  | 665670/871551 [18:53<04:54, 700.04frames/s]\n 77%|███████▋  | 668238/871551 [18:58<05:12, 650.66frames/s]\n 77%|███████▋  | 671238/871551 [19:02<05:01, 664.21frames/s]\n 77%|███████▋  | 673966/871551 [19:06<04:50, 681.14frames/s]\n 78%|███████▊  | 676622/871551 [19:11<05:13, 622.50frames/s]\n 78%|███████▊  | 679622/871551 [19:14<04:33, 701.44frames/s]\n 78%|███████▊  | 682622/871551 [19:17<03:55, 801.39frames/s]\n 79%|███████▊  | 685622/871551 [19:19<03:23, 911.49frames/s]\n 79%|███████▉  | 688310/871551 [19:21<03:13, 946.91frames/s]\n 79%|███████▉  | 691310/871551 [19:24<03:01, 994.84frames/s]\n 80%|███████▉  | 694310/871551 [19:26<02:34, 1148.73frames/s]\n 80%|███████▉  | 696366/871551 [19:28<02:32, 1151.72frames/s]\n 80%|████████  | 699022/871551 [19:30<02:29, 1157.41frames/s]\n 80%|████████  | 701566/871551 [19:33<02:49, 1002.09frames/s]\n 81%|████████  | 704278/871551 [19:37<03:00, 929.25frames/s] \n 81%|████████  | 707278/871551 [19:43<03:44, 731.34frames/s]\n 81%|████████▏ | 709894/871551 [19:48<04:09, 647.68frames/s]\n 82%|████████▏ | 711830/871551 [19:50<03:47, 702.68frames/s]\n 82%|████████▏ | 714134/871551 [19:52<03:21, 781.48frames/s]\n 82%|████████▏ | 716614/871551 [19:56<03:39, 705.05frames/s]\n 83%|████████▎ | 719398/871551 [19:59<03:18, 768.43frames/s]\n 83%|████████▎ | 722184/871551 [20:05<04:01, 617.36frames/s]\n 83%|████████▎ | 725184/871551 [20:10<03:50, 634.33frames/s]\n 83%|████████▎ | 726880/871551 [20:12<03:30, 686.89frames/s]\n 84%|████████▎ | 729544/871551 [20:15<03:19, 713.04frames/s]\n 84%|████████▍ | 732184/871551 [20:20<03:32, 656.19frames/s]\n 84%|████████▍ | 734848/871551 [20:25<03:40, 620.68frames/s]\n 85%|████████▍ | 737600/871551 [20:30<03:44, 595.43frames/s]\n 85%|████████▍ | 740600/871551 [20:35<03:40, 592.87frames/s]\n 85%|████████▌ | 743600/871551 [20:36<02:43, 784.66frames/s]\n 86%|████████▌ | 746320/871551 [20:41<02:57, 707.33frames/s]\n 86%|████████▌ | 748880/871551 [20:45<03:03, 669.54frames/s]\n 86%|████████▌ | 751552/871551 [20:51<03:27, 579.42frames/s]\n 87%|████████▋ | 754552/871551 [20:56<03:13, 604.53frames/s]\n 87%|████████▋ | 757048/871551 [20:57<02:33, 747.59frames/s]\n 87%|████████▋ | 760048/871551 [21:01<02:30, 742.81frames/s]\n 87%|████████▋ | 762456/871551 [21:04<02:23, 761.51frames/s]\n 88%|████████▊ | 765096/871551 [21:09<02:36, 678.70frames/s]\n 88%|████████▊ | 768096/871551 [21:14<02:41, 642.43frames/s]\n 88%|████████▊ | 770816/871551 [21:19<02:39, 630.62frames/s]\n 89%|████████▉ | 773816/871551 [21:25<02:53, 562.24frames/s]\n 89%|████████▉ | 776224/871551 [21:30<02:52, 554.06frames/s]\n 89%|████████▉ | 778808/871551 [21:35<02:58, 520.89frames/s]\n 90%|████████▉ | 781360/871551 [21:41<02:59, 503.26frames/s]\n 90%|████████▉ | 784024/871551 [21:45<02:40, 545.46frames/s]\n 90%|█████████ | 786680/871551 [21:50<02:34, 547.92frames/s]\n 91%|█████████ | 789144/871551 [21:54<02:31, 545.13frames/s]\n 91%|█████████ | 791824/871551 [21:58<02:18, 576.68frames/s]\n 91%|█████████ | 794160/871551 [22:03<02:20, 552.03frames/s]\n 91%|█████████▏| 796720/871551 [22:08<02:18, 540.91frames/s]\n 92%|█████████▏| 799584/871551 [22:13<02:14, 535.78frames/s]\n 92%|█████████▏| 800656/871551 [22:16<02:15, 524.27frames/s]\n 92%|█████████▏| 803216/871551 [22:18<01:44, 650.93frames/s]\n 92%|█████████▏| 806046/871551 [22:23<01:46, 614.80frames/s]\n 93%|█████████▎| 808582/871551 [22:28<01:55, 547.29frames/s]\n 93%|█████████▎| 811222/871551 [22:34<01:53, 529.25frames/s]\n 93%|█████████▎| 813574/871551 [22:38<01:49, 529.43frames/s]\n 94%|█████████▎| 816182/871551 [22:41<01:32, 596.43frames/s]\n 94%|█████████▍| 819182/871551 [22:45<01:21, 642.02frames/s]\n 94%|█████████▍| 821654/871551 [22:48<01:07, 734.62frames/s]\n 95%|█████████▍| 823942/871551 [22:51<01:09, 685.90frames/s]\n 95%|█████████▍| 826782/871551 [22:57<01:13, 610.10frames/s]\n 95%|█████████▌| 829782/871551 [23:02<01:06, 630.39frames/s]\n 96%|█████████▌| 832406/871551 [23:05<00:59, 662.05frames/s]\n 96%|█████████▌| 835406/871551 [23:10<00:56, 642.30frames/s]\n 96%|█████████▌| 838160/871551 [23:21<01:15, 444.59frames/s]\n 96%|█████████▋| 840768/871551 [23:35<01:39, 310.02frames/s]\n 97%|█████████▋| 843344/871551 [23:40<01:18, 359.88frames/s]\n 97%|█████████▋| 845952/871551 [23:45<01:04, 399.25frames/s]\n 97%|█████████▋| 848728/871551 [23:49<00:51, 447.37frames/s]\n 98%|█████████▊| 851160/871551 [23:53<00:41, 492.48frames/s]\n 98%|█████████▊| 853992/871551 [23:59<00:37, 474.12frames/s]\n 98%|█████████▊| 856992/871551 [24:04<00:28, 517.40frames/s]\n 99%|█████████▊| 859736/871551 [24:09<00:23, 510.83frames/s]\n 99%|█████████▉| 862560/871551 [24:14<00:16, 541.39frames/s]\n 99%|█████████▉| 865344/871551 [24:19<00:11, 533.56frames/s]\n100%|█████████▉| 868344/871551 [24:24<00:05, 564.04frames/s]\n100%|█████████▉| 871344/871551 [24:25<00:00, 739.52frames/s]\n100%|██████████| 871551/871551 [24:26<00:00, 714.30frames/s]\n100%|██████████| 871551/871551 [24:26<00:00, 594.35frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.9505967140197754,
        "compression_ratio": 0.2727272727272727,
        "end": 2,
        "id": 0,
        "no_speech_prob": 0.17601874470710754,
        "seek": 0,
        "start": 0,
        "temperature": 0.4,
        "text": " You",
        "tokens": [
          50364,
          220,
          3223,
          50464
        ]
      },
      {
        "avg_logprob": -0.41993557612101234,
        "compression_ratio": 1.355072463768116,
        "end": 43.34,
        "id": 1,
        "no_speech_prob": 0.0033714885357767344,
        "seek": 3000,
        "start": 30,
        "temperature": 0,
        "text": " I'm muted. I'm muted. Of course. Okay. I'm back. Ah",
        "tokens": [
          50364,
          286,
          478,
          32808,
          13,
          286,
          478,
          32808,
          13,
          2720,
          1164,
          13,
          1033,
          13,
          286,
          478,
          646,
          13,
          2438,
          51031
        ]
      },
      {
        "avg_logprob": -0.41993557612101234,
        "compression_ratio": 1.355072463768116,
        "end": 53.42,
        "id": 2,
        "no_speech_prob": 0.0033714885357767344,
        "seek": 3000,
        "start": 46.44,
        "temperature": 0,
        "text": " Also, it happens to me I'm not muted anymore. Hello. Welcome to the coding train. It is me Dan on a Monday",
        "tokens": [
          51186,
          2743,
          11,
          309,
          2314,
          281,
          385,
          286,
          478,
          406,
          32808,
          3602,
          13,
          2425,
          13,
          4027,
          281,
          264,
          17720,
          3847,
          13,
          467,
          307,
          385,
          3394,
          322,
          257,
          8138,
          51535
        ]
      },
      {
        "avg_logprob": -0.41993557612101234,
        "compression_ratio": 1.355072463768116,
        "end": 55.42,
        "id": 3,
        "no_speech_prob": 0.0033714885357767344,
        "seek": 3000,
        "start": 53.42,
        "temperature": 0,
        "text": " I think it's Monday at least",
        "tokens": [
          51535,
          286,
          519,
          309,
          311,
          8138,
          412,
          1935,
          51635
        ]
      },
      {
        "avg_logprob": -0.2654401971659529,
        "compression_ratio": 1.5725190839694656,
        "end": 58.58,
        "id": 4,
        "no_speech_prob": 0.0007321033626794815,
        "seek": 5542,
        "start": 56.42,
        "temperature": 0,
        "text": " But I had this very spicy lunch",
        "tokens": [
          50414,
          583,
          286,
          632,
          341,
          588,
          9127,
          6349,
          50522
        ]
      },
      {
        "avg_logprob": -0.2654401971659529,
        "compression_ratio": 1.5725190839694656,
        "end": 62.120000000000005,
        "id": 5,
        "no_speech_prob": 0.0007321033626794815,
        "seek": 5542,
        "start": 59.300000000000004,
        "temperature": 0,
        "text": " This is what I was talking about a second ago before I realized I was muted",
        "tokens": [
          50558,
          639,
          307,
          437,
          286,
          390,
          1417,
          466,
          257,
          1150,
          2057,
          949,
          286,
          5334,
          286,
          390,
          32808,
          50699
        ]
      },
      {
        "avg_logprob": -0.2654401971659529,
        "compression_ratio": 1.5725190839694656,
        "end": 65.54,
        "id": 6,
        "no_speech_prob": 0.0007321033626794815,
        "seek": 5542,
        "start": 62.300000000000004,
        "temperature": 0,
        "text": " And it's my head is like a little bit in the clouds right now",
        "tokens": [
          50708,
          400,
          309,
          311,
          452,
          1378,
          307,
          411,
          257,
          707,
          857,
          294,
          264,
          12193,
          558,
          586,
          50870
        ]
      },
      {
        "avg_logprob": -0.2654401971659529,
        "compression_ratio": 1.5725190839694656,
        "end": 70.18,
        "id": 7,
        "no_speech_prob": 0.0007321033626794815,
        "seek": 5542,
        "start": 66.7,
        "temperature": 0,
        "text": " Yes, everybody in the chat is saying no audio. But as soon as",
        "tokens": [
          50928,
          1079,
          11,
          2201,
          294,
          264,
          5081,
          307,
          1566,
          572,
          6278,
          13,
          583,
          382,
          2321,
          382,
          51102
        ]
      },
      {
        "avg_logprob": -0.2654401971659529,
        "compression_ratio": 1.5725190839694656,
        "end": 74.18,
        "id": 8,
        "no_speech_prob": 0.0007321033626794815,
        "seek": 5542,
        "start": 71.14,
        "temperature": 0,
        "text": " Shortly, you're gonna catch up to me. I have I have something to say",
        "tokens": [
          51150,
          40109,
          11,
          291,
          434,
          799,
          3745,
          493,
          281,
          385,
          13,
          286,
          362,
          286,
          362,
          746,
          281,
          584,
          51302
        ]
      },
      {
        "avg_logprob": -0.2654401971659529,
        "compression_ratio": 1.5725190839694656,
        "end": 84.18,
        "id": 9,
        "no_speech_prob": 0.0007321033626794815,
        "seek": 5542,
        "start": 77.06,
        "temperature": 0,
        "text": " I'm very worried about this live stream today. So if you happen to tune in on Friday, you might recall that the",
        "tokens": [
          51446,
          286,
          478,
          588,
          5804,
          466,
          341,
          1621,
          4309,
          965,
          13,
          407,
          498,
          291,
          1051,
          281,
          10864,
          294,
          322,
          6984,
          11,
          291,
          1062,
          9901,
          300,
          264,
          51802
        ]
      },
      {
        "avg_logprob": -0.3111550554316095,
        "compression_ratio": 1.6570048309178744,
        "end": 88.44000000000001,
        "id": 10,
        "no_speech_prob": 0.0000024439561912004137,
        "seek": 8418,
        "start": 84.78,
        "temperature": 0,
        "text": " Streams froze the computer would freeze. I had to restart a bunch of times",
        "tokens": [
          50394,
          24904,
          82,
          46077,
          264,
          3820,
          576,
          15959,
          13,
          286,
          632,
          281,
          21022,
          257,
          3840,
          295,
          1413,
          50577
        ]
      },
      {
        "avg_logprob": -0.3111550554316095,
        "compression_ratio": 1.6570048309178744,
        "end": 93.86000000000001,
        "id": 11,
        "no_speech_prob": 0.0000024439561912004137,
        "seek": 8418,
        "start": 91.86000000000001,
        "temperature": 0,
        "text": " And so I",
        "tokens": [
          50748,
          400,
          370,
          286,
          50848
        ]
      },
      {
        "avg_logprob": -0.3111550554316095,
        "compression_ratio": 1.6570048309178744,
        "end": 99.64000000000001,
        "id": 12,
        "no_speech_prob": 0.0000024439561912004137,
        "seek": 8418,
        "start": 94.18,
        "temperature": 0,
        "text": " Tried to do a few things on the computer. For example, I it's not this computer by the way",
        "tokens": [
          50864,
          314,
          2428,
          281,
          360,
          257,
          1326,
          721,
          322,
          264,
          3820,
          13,
          1171,
          1365,
          11,
          286,
          309,
          311,
          406,
          341,
          3820,
          538,
          264,
          636,
          51137
        ]
      },
      {
        "avg_logprob": -0.3111550554316095,
        "compression_ratio": 1.6570048309178744,
        "end": 105.98,
        "id": 13,
        "no_speech_prob": 0.0000024439561912004137,
        "seek": 8418,
        "start": 99.72000000000001,
        "temperature": 0,
        "text": " So this laptop here is not the machine. That is the problem the machine. That is the problem is",
        "tokens": [
          51141,
          407,
          341,
          10732,
          510,
          307,
          406,
          264,
          3479,
          13,
          663,
          307,
          264,
          1154,
          264,
          3479,
          13,
          663,
          307,
          264,
          1154,
          307,
          51454
        ]
      },
      {
        "avg_logprob": -0.3111550554316095,
        "compression_ratio": 1.6570048309178744,
        "end": 108.5,
        "id": 14,
        "no_speech_prob": 0.0000024439561912004137,
        "seek": 8418,
        "start": 106.5,
        "temperature": 0,
        "text": " How can I show this to you?",
        "tokens": [
          51480,
          1012,
          393,
          286,
          855,
          341,
          281,
          291,
          30,
          51580
        ]
      },
      {
        "avg_logprob": -0.3111550554316095,
        "compression_ratio": 1.6570048309178744,
        "end": 113.34,
        "id": 15,
        "no_speech_prob": 0.0000024439561912004137,
        "seek": 8418,
        "start": 109.9,
        "temperature": 0,
        "text": " This is gonna be very awkward let's try this",
        "tokens": [
          51650,
          639,
          307,
          799,
          312,
          588,
          11411,
          718,
          311,
          853,
          341,
          51822
        ]
      },
      {
        "avg_logprob": -0.35055636016415875,
        "compression_ratio": 1.524390243902439,
        "end": 117.02000000000001,
        "id": 16,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 11418,
        "start": 115.18,
        "temperature": 0,
        "text": " Yes",
        "tokens": [
          50414,
          1079,
          50506
        ]
      },
      {
        "avg_logprob": -0.35055636016415875,
        "compression_ratio": 1.524390243902439,
        "end": 121.78,
        "id": 17,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 11418,
        "start": 117.02000000000001,
        "temperature": 0,
        "text": " Sure. Okay the machine that is the problem is",
        "tokens": [
          50506,
          4894,
          13,
          1033,
          264,
          3479,
          300,
          307,
          264,
          1154,
          307,
          50744
        ]
      },
      {
        "avg_logprob": -0.35055636016415875,
        "compression_ratio": 1.524390243902439,
        "end": 128.78,
        "id": 18,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 11418,
        "start": 124.74000000000001,
        "temperature": 0,
        "text": " This one on the floor over there it is affectionately known as",
        "tokens": [
          50892,
          639,
          472,
          322,
          264,
          4123,
          670,
          456,
          309,
          307,
          20080,
          1592,
          2570,
          382,
          51094
        ]
      },
      {
        "avg_logprob": -0.35055636016415875,
        "compression_ratio": 1.524390243902439,
        "end": 137,
        "id": 19,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 11418,
        "start": 130.02,
        "temperature": 0,
        "text": " It doesn't have an affectionate name. It's a it's a Mac Pro. It looks like a little trash can it has it has served me well",
        "tokens": [
          51156,
          467,
          1177,
          380,
          362,
          364,
          20080,
          473,
          1315,
          13,
          467,
          311,
          257,
          309,
          311,
          257,
          5707,
          1705,
          13,
          467,
          1542,
          411,
          257,
          707,
          11321,
          393,
          309,
          575,
          309,
          575,
          7584,
          385,
          731,
          51505
        ]
      },
      {
        "avg_logprob": -0.35055636016415875,
        "compression_ratio": 1.524390243902439,
        "end": 140.14000000000001,
        "id": 20,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 11418,
        "start": 138.14000000000001,
        "temperature": 0,
        "text": " over the years",
        "tokens": [
          51562,
          670,
          264,
          924,
          51662
        ]
      },
      {
        "avg_logprob": -0.3483951126319775,
        "compression_ratio": 1.4244186046511629,
        "end": 148,
        "id": 21,
        "no_speech_prob": 0.0009697360801510513,
        "seek": 14014,
        "start": 140.5,
        "temperature": 0,
        "text": " But recently it started to overheat I believe so I did something which is called to reset I",
        "tokens": [
          50382,
          583,
          3938,
          309,
          1409,
          281,
          29807,
          267,
          286,
          1697,
          370,
          286,
          630,
          746,
          597,
          307,
          1219,
          281,
          14322,
          286,
          50757
        ]
      },
      {
        "avg_logprob": -0.3483951126319775,
        "compression_ratio": 1.4244186046511629,
        "end": 150.61999999999998,
        "id": 22,
        "no_speech_prob": 0.0009697360801510513,
        "seek": 14014,
        "start": 148.61999999999998,
        "temperature": 0,
        "text": " Didn't know about this. Thank you to Austin",
        "tokens": [
          50788,
          11151,
          380,
          458,
          466,
          341,
          13,
          1044,
          291,
          281,
          15356,
          50888
        ]
      },
      {
        "avg_logprob": -0.3483951126319775,
        "compression_ratio": 1.4244186046511629,
        "end": 153.61999999999998,
        "id": 23,
        "no_speech_prob": 0.0009697360801510513,
        "seek": 14014,
        "start": 151.61999999999998,
        "temperature": 0,
        "text": " Austin",
        "tokens": [
          50938,
          15356,
          51038
        ]
      },
      {
        "avg_logprob": -0.3483951126319775,
        "compression_ratio": 1.4244186046511629,
        "end": 158.07999999999998,
        "id": 24,
        "no_speech_prob": 0.0009697360801510513,
        "seek": 14014,
        "start": 153.61999999999998,
        "temperature": 0,
        "text": " Reset Mac SMC I tried to do this",
        "tokens": [
          51038,
          5015,
          302,
          5707,
          13115,
          34,
          286,
          3031,
          281,
          360,
          341,
          51261
        ]
      },
      {
        "avg_logprob": -0.3483951126319775,
        "compression_ratio": 1.4244186046511629,
        "end": 162.72,
        "id": 25,
        "no_speech_prob": 0.0009697360801510513,
        "seek": 14014,
        "start": 160.01999999999998,
        "temperature": 0,
        "text": " Also, this microphone is in like a weird place",
        "tokens": [
          51358,
          2743,
          11,
          341,
          10952,
          307,
          294,
          411,
          257,
          3657,
          1081,
          51493
        ]
      },
      {
        "avg_logprob": -0.3483951126319775,
        "compression_ratio": 1.4244186046511629,
        "end": 167.54,
        "id": 26,
        "no_speech_prob": 0.0009697360801510513,
        "seek": 14014,
        "start": 165.54,
        "temperature": 0,
        "text": " It's going wrong today",
        "tokens": [
          51634,
          467,
          311,
          516,
          2085,
          965,
          51734
        ]
      },
      {
        "avg_logprob": -0.26621828273851045,
        "compression_ratio": 1.75,
        "end": 173.94,
        "id": 27,
        "no_speech_prob": 0.00018522368918638676,
        "seek": 16754,
        "start": 168.14,
        "temperature": 0,
        "text": " So I tried to I did this I also upgraded the machine to Mojave because why not",
        "tokens": [
          50394,
          407,
          286,
          3031,
          281,
          286,
          630,
          341,
          286,
          611,
          24133,
          264,
          3479,
          281,
          3335,
          73,
          946,
          570,
          983,
          406,
          50684
        ]
      },
      {
        "avg_logprob": -0.26621828273851045,
        "compression_ratio": 1.75,
        "end": 181.14,
        "id": 28,
        "no_speech_prob": 0.00018522368918638676,
        "seek": 16754,
        "start": 174.94,
        "temperature": 0,
        "text": " Wipe some stuff off the machine and as you can see I am live streaming from that machine and it has not crashed yet",
        "tokens": [
          50734,
          343,
          6527,
          512,
          1507,
          766,
          264,
          3479,
          293,
          382,
          291,
          393,
          536,
          286,
          669,
          1621,
          11791,
          490,
          300,
          3479,
          293,
          309,
          575,
          406,
          24190,
          1939,
          51044
        ]
      },
      {
        "avg_logprob": -0.26621828273851045,
        "compression_ratio": 1.75,
        "end": 188.34,
        "id": 29,
        "no_speech_prob": 0.00018522368918638676,
        "seek": 16754,
        "start": 181.14,
        "temperature": 0,
        "text": " But I wish I had pressed the button start streaming just like five minutes earlier because the machine started beeping",
        "tokens": [
          51044,
          583,
          286,
          3172,
          286,
          632,
          17355,
          264,
          2960,
          722,
          11791,
          445,
          411,
          1732,
          2077,
          3071,
          570,
          264,
          3479,
          1409,
          34800,
          51404
        ]
      },
      {
        "avg_logprob": -0.26621828273851045,
        "compression_ratio": 1.75,
        "end": 193.72,
        "id": 30,
        "no_speech_prob": 0.00018522368918638676,
        "seek": 16754,
        "start": 188.66,
        "temperature": 0,
        "text": " So it does this weird beeping. I've never heard. I wish I have recorded this. It sounds a little like this",
        "tokens": [
          51420,
          407,
          309,
          775,
          341,
          3657,
          34800,
          13,
          286,
          600,
          1128,
          2198,
          13,
          286,
          3172,
          286,
          362,
          8287,
          341,
          13,
          467,
          3263,
          257,
          707,
          411,
          341,
          51673
        ]
      },
      {
        "avg_logprob": -0.28266870653307113,
        "compression_ratio": 1.4824120603015076,
        "end": 203.22,
        "id": 31,
        "no_speech_prob": 0.00002468268939992413,
        "seek": 19754,
        "start": 197.78,
        "temperature": 0,
        "text": " I've never heard a Mac computer do this before it does it and then it just stops",
        "tokens": [
          50376,
          286,
          600,
          1128,
          2198,
          257,
          5707,
          3820,
          360,
          341,
          949,
          309,
          775,
          309,
          293,
          550,
          309,
          445,
          10094,
          50648
        ]
      },
      {
        "avg_logprob": -0.28266870653307113,
        "compression_ratio": 1.4824120603015076,
        "end": 206.54,
        "id": 32,
        "no_speech_prob": 0.00002468268939992413,
        "seek": 19754,
        "start": 203.66,
        "temperature": 0,
        "text": " And then I thought maybe then it would freeze",
        "tokens": [
          50670,
          400,
          550,
          286,
          1194,
          1310,
          550,
          309,
          576,
          15959,
          50814
        ]
      },
      {
        "avg_logprob": -0.28266870653307113,
        "compression_ratio": 1.4824120603015076,
        "end": 213.45999999999998,
        "id": 33,
        "no_speech_prob": 0.00002468268939992413,
        "seek": 19754,
        "start": 206.54,
        "temperature": 0,
        "text": " I don't know so anybody has any idea what that could possibly be please let me know I did install some monitoring stuff and",
        "tokens": [
          50814,
          286,
          500,
          380,
          458,
          370,
          4472,
          575,
          604,
          1558,
          437,
          300,
          727,
          6264,
          312,
          1767,
          718,
          385,
          458,
          286,
          630,
          3625,
          512,
          11028,
          1507,
          293,
          51160
        ]
      },
      {
        "avg_logprob": -0.28266870653307113,
        "compression_ratio": 1.4824120603015076,
        "end": 216.94,
        "id": 34,
        "no_speech_prob": 0.00002468268939992413,
        "seek": 19754,
        "start": 214.94,
        "temperature": 0,
        "text": " for example",
        "tokens": [
          51234,
          337,
          1365,
          51334
        ]
      },
      {
        "avg_logprob": -0.28266870653307113,
        "compression_ratio": 1.4824120603015076,
        "end": 223.89999999999998,
        "id": 35,
        "no_speech_prob": 0.00002468268939992413,
        "seek": 19754,
        "start": 221.89999999999998,
        "temperature": 0,
        "text": " It does say the",
        "tokens": [
          51582,
          467,
          775,
          584,
          264,
          51682
        ]
      },
      {
        "avg_logprob": -0.28266870653307113,
        "compression_ratio": 1.4824120603015076,
        "end": 227.18,
        "id": 36,
        "no_speech_prob": 0.00002468268939992413,
        "seek": 19754,
        "start": 225.18,
        "temperature": 0,
        "text": " CPU is currently",
        "tokens": [
          51746,
          13199,
          307,
          4362,
          51846
        ]
      },
      {
        "avg_logprob": -0.3022859803922884,
        "compression_ratio": 1.5064377682403434,
        "end": 230.94,
        "id": 37,
        "no_speech_prob": 0.000025464407372055575,
        "seek": 22754,
        "start": 228.1,
        "temperature": 0,
        "text": " 148 degrees that's I believe in Fahrenheit and",
        "tokens": [
          50392,
          3499,
          23,
          5310,
          300,
          311,
          286,
          1697,
          294,
          31199,
          293,
          50534
        ]
      },
      {
        "avg_logprob": -0.3022859803922884,
        "compression_ratio": 1.5064377682403434,
        "end": 233.22,
        "id": 38,
        "no_speech_prob": 0.000025464407372055575,
        "seek": 22754,
        "start": 231.78,
        "temperature": 0,
        "text": " the",
        "tokens": [
          50576,
          264,
          50648
        ]
      },
      {
        "avg_logprob": -0.3022859803922884,
        "compression_ratio": 1.5064377682403434,
        "end": 235.78,
        "id": 39,
        "no_speech_prob": 0.000025464407372055575,
        "seek": 22754,
        "start": 233.22,
        "temperature": 0,
        "text": " Tell me like a GPU temperature somewhere here",
        "tokens": [
          50648,
          5115,
          385,
          411,
          257,
          18407,
          4292,
          4079,
          510,
          50776
        ]
      },
      {
        "avg_logprob": -0.3022859803922884,
        "compression_ratio": 1.5064377682403434,
        "end": 242.01999999999998,
        "id": 40,
        "no_speech_prob": 0.000025464407372055575,
        "seek": 22754,
        "start": 236.98,
        "temperature": 0,
        "text": " System, I don't I installed something. I think some people recommend some other things that might even be better",
        "tokens": [
          50836,
          8910,
          11,
          286,
          500,
          380,
          286,
          8899,
          746,
          13,
          286,
          519,
          512,
          561,
          2748,
          512,
          661,
          721,
          300,
          1062,
          754,
          312,
          1101,
          51088
        ]
      },
      {
        "avg_logprob": -0.3022859803922884,
        "compression_ratio": 1.5064377682403434,
        "end": 244.78,
        "id": 41,
        "no_speech_prob": 0.000025464407372055575,
        "seek": 22754,
        "start": 242.78,
        "temperature": 0,
        "text": " Activity monitor, so I don't know",
        "tokens": [
          51126,
          3251,
          4253,
          6002,
          11,
          370,
          286,
          500,
          380,
          458,
          51226
        ]
      },
      {
        "avg_logprob": -0.3022859803922884,
        "compression_ratio": 1.5064377682403434,
        "end": 248.06,
        "id": 42,
        "no_speech_prob": 0.000025464407372055575,
        "seek": 22754,
        "start": 246.06,
        "temperature": 0,
        "text": " We're gonna go",
        "tokens": [
          51290,
          492,
          434,
          799,
          352,
          51390
        ]
      },
      {
        "avg_logprob": -0.3022859803922884,
        "compression_ratio": 1.5064377682403434,
        "end": 255.38,
        "id": 43,
        "no_speech_prob": 0.000025464407372055575,
        "seek": 22754,
        "start": 250.89999999999998,
        "temperature": 0,
        "text": " Patrick in the chat writes won't help if it's overheating. It's likely a hardware issue dust",
        "tokens": [
          51532,
          13980,
          294,
          264,
          5081,
          13657,
          1582,
          380,
          854,
          498,
          309,
          311,
          29807,
          990,
          13,
          467,
          311,
          3700,
          257,
          8837,
          2734,
          8634,
          51756
        ]
      },
      {
        "avg_logprob": -0.27097556988398236,
        "compression_ratio": 1.6550218340611353,
        "end": 259.02,
        "id": 44,
        "no_speech_prob": 0.0005976552492938936,
        "seek": 25538,
        "start": 256.02,
        "temperature": 0,
        "text": " I was hoping that maybe it was like an issue with the fan",
        "tokens": [
          50396,
          286,
          390,
          7159,
          300,
          1310,
          309,
          390,
          411,
          364,
          2734,
          365,
          264,
          3429,
          50546
        ]
      },
      {
        "avg_logprob": -0.27097556988398236,
        "compression_ratio": 1.6550218340611353,
        "end": 266.2,
        "id": 45,
        "no_speech_prob": 0.0005976552492938936,
        "seek": 25538,
        "start": 259.3,
        "temperature": 0,
        "text": " But like somehow like it didn't know how to turn the fan on and off properly and upgrading would fix that in my fantasies",
        "tokens": [
          50560,
          583,
          411,
          6063,
          411,
          309,
          994,
          380,
          458,
          577,
          281,
          1261,
          264,
          3429,
          322,
          293,
          766,
          6108,
          293,
          36249,
          576,
          3191,
          300,
          294,
          452,
          31255,
          530,
          50905
        ]
      },
      {
        "avg_logprob": -0.27097556988398236,
        "compression_ratio": 1.6550218340611353,
        "end": 268.58,
        "id": 46,
        "no_speech_prob": 0.0005976552492938936,
        "seek": 25538,
        "start": 266.58,
        "temperature": 0,
        "text": " So anyway, I'm here",
        "tokens": [
          50924,
          407,
          4033,
          11,
          286,
          478,
          510,
          51024
        ]
      },
      {
        "avg_logprob": -0.27097556988398236,
        "compression_ratio": 1.6550218340611353,
        "end": 270.98,
        "id": 47,
        "no_speech_prob": 0.0005976552492938936,
        "seek": 25538,
        "start": 268.98,
        "temperature": 0,
        "text": " I am going to",
        "tokens": [
          51044,
          286,
          669,
          516,
          281,
          51144
        ]
      },
      {
        "avg_logprob": -0.27097556988398236,
        "compression_ratio": 1.6550218340611353,
        "end": 277.38,
        "id": 48,
        "no_speech_prob": 0.0005976552492938936,
        "seek": 25538,
        "start": 271.58,
        "temperature": 0,
        "text": " Do this live stream today up until the moment the computer crashes if it does not crash",
        "tokens": [
          51174,
          1144,
          341,
          1621,
          4309,
          965,
          493,
          1826,
          264,
          1623,
          264,
          3820,
          28642,
          498,
          309,
          775,
          406,
          8252,
          51464
        ]
      },
      {
        "avg_logprob": -0.27097556988398236,
        "compression_ratio": 1.6550218340611353,
        "end": 282.56,
        "id": 49,
        "no_speech_prob": 0.0005976552492938936,
        "seek": 25538,
        "start": 277.94,
        "temperature": 0,
        "text": " Great if it does crash I might come back just to say that the machine crashed",
        "tokens": [
          51492,
          3769,
          498,
          309,
          775,
          8252,
          286,
          1062,
          808,
          646,
          445,
          281,
          584,
          300,
          264,
          3479,
          24190,
          51723
        ]
      },
      {
        "avg_logprob": -0.27570060944892993,
        "compression_ratio": 1.4488636363636365,
        "end": 288.04,
        "id": 50,
        "no_speech_prob": 0.0024342783726751804,
        "seek": 28256,
        "start": 282.6,
        "temperature": 0,
        "text": " But then I think if it does crash I'm going to spend the rest of my time trying to find a different computer",
        "tokens": [
          50366,
          583,
          550,
          286,
          519,
          498,
          309,
          775,
          8252,
          286,
          478,
          516,
          281,
          3496,
          264,
          1472,
          295,
          452,
          565,
          1382,
          281,
          915,
          257,
          819,
          3820,
          50638
        ]
      },
      {
        "avg_logprob": -0.27570060944892993,
        "compression_ratio": 1.4488636363636365,
        "end": 296.16,
        "id": 51,
        "no_speech_prob": 0.0024342783726751804,
        "seek": 28256,
        "start": 289.08,
        "temperature": 0,
        "text": " Today, so I'm sorry to go on and on about this. I keep looking over to see if I'm still live",
        "tokens": [
          50690,
          2692,
          11,
          370,
          286,
          478,
          2597,
          281,
          352,
          322,
          293,
          322,
          466,
          341,
          13,
          286,
          1066,
          1237,
          670,
          281,
          536,
          498,
          286,
          478,
          920,
          1621,
          51044
        ]
      },
      {
        "avg_logprob": -0.27570060944892993,
        "compression_ratio": 1.4488636363636365,
        "end": 298.8,
        "id": 52,
        "no_speech_prob": 0.0024342783726751804,
        "seek": 28256,
        "start": 296.8,
        "temperature": 0,
        "text": " Let me check the slack channel",
        "tokens": [
          51076,
          961,
          385,
          1520,
          264,
          29767,
          2269,
          51176
        ]
      },
      {
        "avg_logprob": -0.27570060944892993,
        "compression_ratio": 1.4488636363636365,
        "end": 306.4,
        "id": 53,
        "no_speech_prob": 0.0024342783726751804,
        "seek": 28256,
        "start": 304.4,
        "temperature": 0,
        "text": " And yeah, all right so",
        "tokens": [
          51456,
          400,
          1338,
          11,
          439,
          558,
          370,
          51556
        ]
      },
      {
        "avg_logprob": -0.31748081158988084,
        "compression_ratio": 1.4829268292682927,
        "end": 308.59999999999997,
        "id": 54,
        "no_speech_prob": 0.0004044664674438536,
        "seek": 30640,
        "start": 306.59999999999997,
        "temperature": 0,
        "text": " Welcome",
        "tokens": [
          50374,
          4027,
          50474
        ]
      },
      {
        "avg_logprob": -0.31748081158988084,
        "compression_ratio": 1.4829268292682927,
        "end": 315.84,
        "id": 55,
        "no_speech_prob": 0.0004044664674438536,
        "seek": 30640,
        "start": 309,
        "temperature": 0,
        "text": " To the coding train what you are about to watch today is a person me do some coding tutorials and",
        "tokens": [
          50494,
          1407,
          264,
          17720,
          3847,
          437,
          291,
          366,
          466,
          281,
          1159,
          965,
          307,
          257,
          954,
          385,
          360,
          512,
          17720,
          17616,
          293,
          50836
        ]
      },
      {
        "avg_logprob": -0.31748081158988084,
        "compression_ratio": 1.4829268292682927,
        "end": 318.35999999999996,
        "id": 56,
        "no_speech_prob": 0.0004044664674438536,
        "seek": 30640,
        "start": 316.35999999999996,
        "temperature": 0,
        "text": " today's topic will be",
        "tokens": [
          50862,
          965,
          311,
          4829,
          486,
          312,
          50962
        ]
      },
      {
        "avg_logprob": -0.31748081158988084,
        "compression_ratio": 1.4829268292682927,
        "end": 327.23999999999995,
        "id": 57,
        "no_speech_prob": 0.0004044664674438536,
        "seek": 30640,
        "start": 324.23999999999995,
        "temperature": 0,
        "text": " Decentralized social networks like mastodon and making a bot for them",
        "tokens": [
          51256,
          1346,
          2207,
          2155,
          1602,
          2093,
          9590,
          411,
          27055,
          378,
          266,
          293,
          1455,
          257,
          10592,
          337,
          552,
          51406
        ]
      },
      {
        "avg_logprob": -0.31748081158988084,
        "compression_ratio": 1.4829268292682927,
        "end": 333.67999999999995,
        "id": 58,
        "no_speech_prob": 0.0004044664674438536,
        "seek": 30640,
        "start": 329,
        "temperature": 0,
        "text": " Kind of trying to use the soundboard again, it's been a while all right, so I'm gonna jump right into this",
        "tokens": [
          51494,
          9242,
          295,
          1382,
          281,
          764,
          264,
          1626,
          3787,
          797,
          11,
          309,
          311,
          668,
          257,
          1339,
          439,
          558,
          11,
          370,
          286,
          478,
          799,
          3012,
          558,
          666,
          341,
          51728
        ]
      },
      {
        "avg_logprob": -0.328275777525821,
        "compression_ratio": 1.3496503496503496,
        "end": 340.28,
        "id": 59,
        "no_speech_prob": 0.00011773845471907407,
        "seek": 33640,
        "start": 337.32,
        "temperature": 0,
        "text": " I've got to situate myself here first",
        "tokens": [
          50410,
          286,
          600,
          658,
          281,
          2054,
          473,
          2059,
          510,
          700,
          50558
        ]
      },
      {
        "avg_logprob": -0.328275777525821,
        "compression_ratio": 1.3496503496503496,
        "end": 343.08,
        "id": 60,
        "no_speech_prob": 0.00011773845471907407,
        "seek": 33640,
        "start": 341.08,
        "temperature": 0,
        "text": " which is to go to",
        "tokens": [
          50598,
          597,
          307,
          281,
          352,
          281,
          50698
        ]
      },
      {
        "avg_logprob": -0.328275777525821,
        "compression_ratio": 1.3496503496503496,
        "end": 347.44,
        "id": 61,
        "no_speech_prob": 0.00011773845471907407,
        "seek": 33640,
        "start": 343.59999999999997,
        "temperature": 0,
        "text": " This YouTube channel called the coding train go to playlists",
        "tokens": [
          50724,
          639,
          3088,
          2269,
          1219,
          264,
          17720,
          3847,
          352,
          281,
          862,
          36693,
          50916
        ]
      },
      {
        "avg_logprob": -0.328275777525821,
        "compression_ratio": 1.3496503496503496,
        "end": 354.91999999999996,
        "id": 62,
        "no_speech_prob": 0.00011773845471907407,
        "seek": 33640,
        "start": 350.44,
        "temperature": 0,
        "text": " Created playlists, I think I'm looking for session",
        "tokens": [
          51066,
          11972,
          292,
          862,
          36693,
          11,
          286,
          519,
          286,
          478,
          1237,
          337,
          5481,
          51290
        ]
      },
      {
        "avg_logprob": -0.328275777525821,
        "compression_ratio": 1.3496503496503496,
        "end": 357.71999999999997,
        "id": 63,
        "no_speech_prob": 0.00011773845471907407,
        "seek": 33640,
        "start": 355.84,
        "temperature": 0,
        "text": " six",
        "tokens": [
          51336,
          2309,
          51430
        ]
      },
      {
        "avg_logprob": -0.328275777525821,
        "compression_ratio": 1.3496503496503496,
        "end": 359.71999999999997,
        "id": 64,
        "no_speech_prob": 0.00011773845471907407,
        "seek": 33640,
        "start": 357.71999999999997,
        "temperature": 0,
        "text": " five four",
        "tokens": [
          51430,
          1732,
          1451,
          51530
        ]
      },
      {
        "avg_logprob": -0.328275777525821,
        "compression_ratio": 1.3496503496503496,
        "end": 362,
        "id": 65,
        "no_speech_prob": 0.00011773845471907407,
        "seek": 33640,
        "start": 360,
        "temperature": 0,
        "text": " There we go",
        "tokens": [
          51544,
          821,
          321,
          352,
          51644
        ]
      },
      {
        "avg_logprob": -0.28780039737099095,
        "compression_ratio": 1.671497584541063,
        "end": 366.28,
        "id": 66,
        "no_speech_prob": 0.00010889580880757421,
        "seek": 36200,
        "start": 362.8,
        "temperature": 0,
        "text": " This is not what I'm looking for this is what I'm looking for okay",
        "tokens": [
          50404,
          639,
          307,
          406,
          437,
          286,
          478,
          1237,
          337,
          341,
          307,
          437,
          286,
          478,
          1237,
          337,
          1392,
          50578
        ]
      },
      {
        "avg_logprob": -0.28780039737099095,
        "compression_ratio": 1.671497584541063,
        "end": 370.12,
        "id": 67,
        "no_speech_prob": 0.00010889580880757421,
        "seek": 36200,
        "start": 368.12,
        "temperature": 0,
        "text": " Setting up a Twitter",
        "tokens": [
          50670,
          21063,
          493,
          257,
          5794,
          50770
        ]
      },
      {
        "avg_logprob": -0.28780039737099095,
        "compression_ratio": 1.671497584541063,
        "end": 373.4,
        "id": 68,
        "no_speech_prob": 0.00010889580880757421,
        "seek": 36200,
        "start": 370.32,
        "temperature": 0,
        "text": " All right, so what I am going to do today is",
        "tokens": [
          50780,
          1057,
          558,
          11,
          370,
          437,
          286,
          669,
          516,
          281,
          360,
          965,
          307,
          50934
        ]
      },
      {
        "avg_logprob": -0.28780039737099095,
        "compression_ratio": 1.671497584541063,
        "end": 379.68,
        "id": 69,
        "no_speech_prob": 0.00010889580880757421,
        "seek": 36200,
        "start": 374.88,
        "temperature": 0,
        "text": " Does the new machine have to be a Mac no it doesn't have to be a Mac it has to be a machine",
        "tokens": [
          51008,
          4402,
          264,
          777,
          3479,
          362,
          281,
          312,
          257,
          5707,
          572,
          309,
          1177,
          380,
          362,
          281,
          312,
          257,
          5707,
          309,
          575,
          281,
          312,
          257,
          3479,
          51248
        ]
      },
      {
        "avg_logprob": -0.28780039737099095,
        "compression_ratio": 1.671497584541063,
        "end": 382.72,
        "id": 70,
        "no_speech_prob": 0.00010889580880757421,
        "seek": 36200,
        "start": 380.16,
        "temperature": 0,
        "text": " That I can use that will do all the things that I need",
        "tokens": [
          51272,
          663,
          286,
          393,
          764,
          300,
          486,
          360,
          439,
          264,
          721,
          300,
          286,
          643,
          51400
        ]
      },
      {
        "avg_logprob": -0.28780039737099095,
        "compression_ratio": 1.671497584541063,
        "end": 388.64,
        "id": 71,
        "no_speech_prob": 0.00010889580880757421,
        "seek": 36200,
        "start": 383.36,
        "temperature": 0,
        "text": " Notably take inputs from multiple cameras from the laptop HDMI out",
        "tokens": [
          51432,
          1726,
          1188,
          747,
          15743,
          490,
          3866,
          8622,
          490,
          264,
          10732,
          30811,
          484,
          51696
        ]
      },
      {
        "avg_logprob": -0.33280722702605814,
        "compression_ratio": 1.4293193717277486,
        "end": 394.2,
        "id": 72,
        "no_speech_prob": 0.00007484426896553487,
        "seek": 38864,
        "start": 389.52,
        "temperature": 0,
        "text": " Audio inputs, and it will stream and run open broadcast studio. That's all that the machine needs to do",
        "tokens": [
          50408,
          25706,
          15743,
          11,
          293,
          309,
          486,
          4309,
          293,
          1190,
          1269,
          9975,
          6811,
          13,
          663,
          311,
          439,
          300,
          264,
          3479,
          2203,
          281,
          360,
          50642
        ]
      },
      {
        "avg_logprob": -0.33280722702605814,
        "compression_ratio": 1.4293193717277486,
        "end": 397.64,
        "id": 73,
        "no_speech_prob": 0.00007484426896553487,
        "seek": 38864,
        "start": 395.12,
        "temperature": 0,
        "text": " And you know so far. It's kind of working ask",
        "tokens": [
          50688,
          400,
          291,
          458,
          370,
          1400,
          13,
          467,
          311,
          733,
          295,
          1364,
          1029,
          50814
        ]
      },
      {
        "avg_logprob": -0.33280722702605814,
        "compression_ratio": 1.4293193717277486,
        "end": 403.32,
        "id": 74,
        "no_speech_prob": 0.00007484426896553487,
        "seek": 38864,
        "start": 398.52,
        "temperature": 0,
        "text": " Louie Rossman about the Mac stuff says Jason yeah, okay?",
        "tokens": [
          50858,
          7272,
          414,
          16140,
          1601,
          466,
          264,
          5707,
          1507,
          1619,
          11181,
          1338,
          11,
          1392,
          30,
          51098
        ]
      },
      {
        "avg_logprob": -0.33280722702605814,
        "compression_ratio": 1.4293193717277486,
        "end": 407.08,
        "id": 75,
        "no_speech_prob": 0.00007484426896553487,
        "seek": 38864,
        "start": 405.08,
        "temperature": 0,
        "text": " All right, so",
        "tokens": [
          51186,
          1057,
          558,
          11,
          370,
          51286
        ]
      },
      {
        "avg_logprob": -0.33280722702605814,
        "compression_ratio": 1.4293193717277486,
        "end": 411.96,
        "id": 76,
        "no_speech_prob": 0.00007484426896553487,
        "seek": 38864,
        "start": 408.91999999999996,
        "temperature": 0,
        "text": " I'm gonna jump right in I'm gonna open up a few",
        "tokens": [
          51378,
          286,
          478,
          799,
          3012,
          558,
          294,
          286,
          478,
          799,
          1269,
          493,
          257,
          1326,
          51530
        ]
      },
      {
        "avg_logprob": -0.33280722702605814,
        "compression_ratio": 1.4293193717277486,
        "end": 416.32,
        "id": 77,
        "no_speech_prob": 0.00007484426896553487,
        "seek": 38864,
        "start": 414.32,
        "temperature": 0,
        "text": " URLs",
        "tokens": [
          51648,
          43267,
          51748
        ]
      },
      {
        "avg_logprob": -0.3810782773154123,
        "compression_ratio": 1.2877697841726619,
        "end": 421.03999999999996,
        "id": 78,
        "no_speech_prob": 0.00034596980549395084,
        "seek": 41864,
        "start": 418.84,
        "temperature": 0,
        "text": " Enjoy mess that's what I'm looking for here",
        "tokens": [
          50374,
          15411,
          2082,
          300,
          311,
          437,
          286,
          478,
          1237,
          337,
          510,
          50484
        ]
      },
      {
        "avg_logprob": -0.3810782773154123,
        "compression_ratio": 1.2877697841726619,
        "end": 430.47999999999996,
        "id": 79,
        "no_speech_prob": 0.00034596980549395084,
        "seek": 41864,
        "start": 424.8,
        "temperature": 0,
        "text": " This is the order and then I need one more what I want activity pub",
        "tokens": [
          50672,
          639,
          307,
          264,
          1668,
          293,
          550,
          286,
          643,
          472,
          544,
          437,
          286,
          528,
          5191,
          1535,
          50956
        ]
      },
      {
        "avg_logprob": -0.3810782773154123,
        "compression_ratio": 1.2877697841726619,
        "end": 437.76,
        "id": 80,
        "no_speech_prob": 0.00034596980549395084,
        "seek": 41864,
        "start": 432.56,
        "temperature": 0,
        "text": " And I also would like a mastodon on github",
        "tokens": [
          51060,
          400,
          286,
          611,
          576,
          411,
          257,
          27055,
          378,
          266,
          322,
          290,
          355,
          836,
          51320
        ]
      },
      {
        "avg_logprob": -0.3810782773154123,
        "compression_ratio": 1.2877697841726619,
        "end": 441.76,
        "id": 81,
        "no_speech_prob": 0.00034596980549395084,
        "seek": 41864,
        "start": 439.76,
        "temperature": 0,
        "text": " Which is here, okay",
        "tokens": [
          51420,
          3013,
          307,
          510,
          11,
          1392,
          51520
        ]
      },
      {
        "avg_logprob": -0.3810782773154123,
        "compression_ratio": 1.2877697841726619,
        "end": 448.12,
        "id": 82,
        "no_speech_prob": 0.00034596980549395084,
        "seek": 41864,
        "start": 446.12,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51738,
          1033,
          51838
        ]
      },
      {
        "avg_logprob": -0.3106561140580611,
        "compression_ratio": 1.3641975308641976,
        "end": 453.2,
        "id": 83,
        "no_speech_prob": 0.00011235129932174459,
        "seek": 44812,
        "start": 448.36,
        "temperature": 0,
        "text": " Need a marker I need to make sure the whiteboard camera is working which it is",
        "tokens": [
          50376,
          16984,
          257,
          15247,
          286,
          643,
          281,
          652,
          988,
          264,
          2418,
          3787,
          2799,
          307,
          1364,
          597,
          309,
          307,
          50618
        ]
      },
      {
        "avg_logprob": -0.3106561140580611,
        "compression_ratio": 1.3641975308641976,
        "end": 462.8,
        "id": 84,
        "no_speech_prob": 0.00011235129932174459,
        "seek": 44812,
        "start": 460.8,
        "temperature": 0,
        "text": " And we shall begin",
        "tokens": [
          50998,
          400,
          321,
          4393,
          1841,
          51098
        ]
      },
      {
        "avg_logprob": -0.3106561140580611,
        "compression_ratio": 1.3641975308641976,
        "end": 475.92,
        "id": 85,
        "no_speech_prob": 0.00011235129932174459,
        "seek": 44812,
        "start": 468.48,
        "temperature": 0,
        "text": " Josh is writing probably not enough RAM for streaming. Maybe you're not referring to this oh, yeah, I see this computer has",
        "tokens": [
          51382,
          9785,
          307,
          3579,
          1391,
          406,
          1547,
          14561,
          337,
          11791,
          13,
          2704,
          291,
          434,
          406,
          13761,
          281,
          341,
          1954,
          11,
          1338,
          11,
          286,
          536,
          341,
          3820,
          575,
          51754
        ]
      },
      {
        "avg_logprob": -0.5115667898443681,
        "compression_ratio": 1.375,
        "end": 480.64000000000004,
        "id": 86,
        "no_speech_prob": 0.00017130565538536757,
        "seek": 47592,
        "start": 476.92,
        "temperature": 0,
        "text": " This computer is let me just give you all the specs here. It is a",
        "tokens": [
          50414,
          639,
          3820,
          307,
          718,
          385,
          445,
          976,
          291,
          439,
          264,
          27911,
          510,
          13,
          467,
          307,
          257,
          50600
        ]
      },
      {
        "avg_logprob": -0.5115667898443681,
        "compression_ratio": 1.375,
        "end": 484.08000000000004,
        "id": 87,
        "no_speech_prob": 0.00017130565538536757,
        "seek": 47592,
        "start": 481.2,
        "temperature": 0,
        "text": " 2000 late 2013 Mac Pro",
        "tokens": [
          50628,
          8132,
          3469,
          9012,
          5707,
          1705,
          50772
        ]
      },
      {
        "avg_logprob": -0.5115667898443681,
        "compression_ratio": 1.375,
        "end": 487.92,
        "id": 88,
        "no_speech_prob": 0.00017130565538536757,
        "seek": 47592,
        "start": 484.40000000000003,
        "temperature": 0,
        "text": " The processor is a 3.5 gigahertz 6 core Intel",
        "tokens": [
          50788,
          440,
          15321,
          307,
          257,
          805,
          13,
          20,
          8741,
          64,
          35655,
          1386,
          4965,
          19762,
          50964
        ]
      },
      {
        "avg_logprob": -0.5115667898443681,
        "compression_ratio": 1.375,
        "end": 495.04,
        "id": 89,
        "no_speech_prob": 0.00017130565538536757,
        "seek": 47592,
        "start": 488.88,
        "temperature": 0,
        "text": " Gian the on e5 is 16 gigabytes of some sort of DDR 3",
        "tokens": [
          51012,
          41958,
          264,
          322,
          308,
          20,
          307,
          3165,
          42741,
          295,
          512,
          1333,
          295,
          49272,
          805,
          51320
        ]
      },
      {
        "avg_logprob": -0.5115667898443681,
        "compression_ratio": 1.375,
        "end": 497.84000000000003,
        "id": 90,
        "no_speech_prob": 0.00017130565538536757,
        "seek": 47592,
        "start": 496.08000000000004,
        "temperature": 0,
        "text": " 1866",
        "tokens": [
          51372,
          2443,
          15237,
          51460
        ]
      },
      {
        "avg_logprob": -0.5115667898443681,
        "compression_ratio": 1.375,
        "end": 502.20000000000005,
        "id": 91,
        "no_speech_prob": 0.00017130565538536757,
        "seek": 47592,
        "start": 497.84000000000003,
        "temperature": 0,
        "text": " 1866 megahertz RAM its graphics card is an AMD fire pro d500",
        "tokens": [
          51460,
          2443,
          15237,
          17986,
          35655,
          14561,
          1080,
          11837,
          2920,
          307,
          364,
          34808,
          2610,
          447,
          274,
          7526,
          51678
        ]
      },
      {
        "avg_logprob": -0.34960350237394633,
        "compression_ratio": 1.398989898989899,
        "end": 506.96,
        "id": 92,
        "no_speech_prob": 0.000047575329517712817,
        "seek": 50220,
        "start": 502.71999999999997,
        "temperature": 0,
        "text": " 3,000 72 megabytes and I even have I even have",
        "tokens": [
          50390,
          805,
          11,
          1360,
          18731,
          10816,
          24538,
          293,
          286,
          754,
          362,
          286,
          754,
          362,
          50602
        ]
      },
      {
        "avg_logprob": -0.34960350237394633,
        "compression_ratio": 1.398989898989899,
        "end": 509.71999999999997,
        "id": 93,
        "no_speech_prob": 0.000047575329517712817,
        "seek": 50220,
        "start": 507.71999999999997,
        "temperature": 0,
        "text": " Right over here. I'm going to show you something",
        "tokens": [
          50640,
          1779,
          670,
          510,
          13,
          286,
          478,
          516,
          281,
          855,
          291,
          746,
          50740
        ]
      },
      {
        "avg_logprob": -0.34960350237394633,
        "compression_ratio": 1.398989898989899,
        "end": 514.16,
        "id": 94,
        "no_speech_prob": 0.000047575329517712817,
        "seek": 50220,
        "start": 510.84,
        "temperature": 0,
        "text": " Remarkable I thought would fix all my problems",
        "tokens": [
          50796,
          4080,
          809,
          712,
          286,
          1194,
          576,
          3191,
          439,
          452,
          2740,
          50962
        ]
      },
      {
        "avg_logprob": -0.34960350237394633,
        "compression_ratio": 1.398989898989899,
        "end": 518.16,
        "id": 95,
        "no_speech_prob": 0.000047575329517712817,
        "seek": 50220,
        "start": 516.16,
        "temperature": 0,
        "text": " We should use this today though I",
        "tokens": [
          51062,
          492,
          820,
          764,
          341,
          965,
          1673,
          286,
          51162
        ]
      },
      {
        "avg_logprob": -0.34960350237394633,
        "compression_ratio": 1.398989898989899,
        "end": 524.6,
        "id": 96,
        "no_speech_prob": 0.000047575329517712817,
        "seek": 50220,
        "start": 518.76,
        "temperature": 0,
        "text": " Have this black magic design eGPU. This is an external GPU",
        "tokens": [
          51192,
          3560,
          341,
          2211,
          5585,
          1715,
          308,
          38,
          8115,
          13,
          639,
          307,
          364,
          8320,
          18407,
          51484
        ]
      },
      {
        "avg_logprob": -0.34960350237394633,
        "compression_ratio": 1.398989898989899,
        "end": 528.2,
        "id": 97,
        "no_speech_prob": 0.000047575329517712817,
        "seek": 50220,
        "start": 526.2,
        "temperature": 0,
        "text": " Unfortunately it only takes Thunderbolt 3",
        "tokens": [
          51564,
          8590,
          309,
          787,
          2516,
          21023,
          39477,
          805,
          51664
        ]
      },
      {
        "avg_logprob": -0.3092011865579857,
        "compression_ratio": 1.25,
        "end": 531.96,
        "id": 98,
        "no_speech_prob": 0.00012533469998743385,
        "seek": 52820,
        "start": 528.96,
        "temperature": 0,
        "text": " Which is not a thing apparently I can",
        "tokens": [
          50402,
          3013,
          307,
          406,
          257,
          551,
          7970,
          286,
          393,
          50552
        ]
      },
      {
        "avg_logprob": -0.3092011865579857,
        "compression_ratio": 1.25,
        "end": 540.6800000000001,
        "id": 99,
        "no_speech_prob": 0.00012533469998743385,
        "seek": 52820,
        "start": 533.6800000000001,
        "temperature": 0,
        "text": " Use with that Mac Pro from late 2013, but I thought maybe if I use an external GPU it would",
        "tokens": [
          50638,
          8278,
          365,
          300,
          5707,
          1705,
          490,
          3469,
          9012,
          11,
          457,
          286,
          1194,
          1310,
          498,
          286,
          764,
          364,
          8320,
          18407,
          309,
          576,
          50988
        ]
      },
      {
        "avg_logprob": -0.3092011865579857,
        "compression_ratio": 1.25,
        "end": 543.6,
        "id": 100,
        "no_speech_prob": 0.00012533469998743385,
        "seek": 52820,
        "start": 541.5200000000001,
        "temperature": 0,
        "text": " Would solve a lot of my problems all right?",
        "tokens": [
          51030,
          6068,
          5039,
          257,
          688,
          295,
          452,
          2740,
          439,
          558,
          30,
          51134
        ]
      },
      {
        "avg_logprob": -0.3092011865579857,
        "compression_ratio": 1.25,
        "end": 548.88,
        "id": 101,
        "no_speech_prob": 0.00012533469998743385,
        "seek": 52820,
        "start": 546.88,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51298,
          1033,
          51398
        ]
      },
      {
        "avg_logprob": -0.3092011865579857,
        "compression_ratio": 1.25,
        "end": 551.5600000000001,
        "id": 102,
        "no_speech_prob": 0.00012533469998743385,
        "seek": 52820,
        "start": 549.5600000000001,
        "temperature": 0,
        "text": " Welcome everyone",
        "tokens": [
          51432,
          4027,
          1518,
          51532
        ]
      },
      {
        "avg_logprob": -0.3910139846801758,
        "compression_ratio": 1.26890756302521,
        "end": 560.2,
        "id": 103,
        "no_speech_prob": 0.000969681772403419,
        "seek": 55820,
        "start": 558.2,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50364,
          286,
          50464
        ]
      },
      {
        "avg_logprob": -0.3910139846801758,
        "compression_ratio": 1.26890756302521,
        "end": 577.6400000000001,
        "id": 104,
        "no_speech_prob": 0.000969681772403419,
        "seek": 55820,
        "start": 570.88,
        "temperature": 0,
        "text": " Hello, this is a first video in a new series about making a Mastodon bot",
        "tokens": [
          50998,
          2425,
          11,
          341,
          307,
          257,
          700,
          960,
          294,
          257,
          777,
          2638,
          466,
          1455,
          257,
          376,
          525,
          378,
          266,
          10592,
          51336
        ]
      },
      {
        "avg_logprob": -0.3910139846801758,
        "compression_ratio": 1.26890756302521,
        "end": 579.6400000000001,
        "id": 105,
        "no_speech_prob": 0.000969681772403419,
        "seek": 55820,
        "start": 577.6400000000001,
        "temperature": 0,
        "text": " And you might be asking yourself, okay?",
        "tokens": [
          51336,
          400,
          291,
          1062,
          312,
          3365,
          1803,
          11,
          1392,
          30,
          51436
        ]
      },
      {
        "avg_logprob": -0.3910139846801758,
        "compression_ratio": 1.26890756302521,
        "end": 581.84,
        "id": 106,
        "no_speech_prob": 0.000969681772403419,
        "seek": 55820,
        "start": 579.72,
        "temperature": 0,
        "text": " Why are you making what is Mastodon?",
        "tokens": [
          51440,
          1545,
          366,
          291,
          1455,
          437,
          307,
          376,
          525,
          378,
          266,
          30,
          51546
        ]
      },
      {
        "avg_logprob": -0.32172047008167615,
        "compression_ratio": 1.5676691729323309,
        "end": 586.32,
        "id": 107,
        "no_speech_prob": 0.018262984231114388,
        "seek": 58184,
        "start": 582.2,
        "temperature": 0,
        "text": " Why are you making a Mastodon bot, and why should I care?",
        "tokens": [
          50382,
          1545,
          366,
          291,
          1455,
          257,
          376,
          525,
          378,
          266,
          10592,
          11,
          293,
          983,
          820,
          286,
          1127,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.32172047008167615,
        "compression_ratio": 1.5676691729323309,
        "end": 588.24,
        "id": 108,
        "no_speech_prob": 0.018262984231114388,
        "seek": 58184,
        "start": 586.32,
        "temperature": 0,
        "text": " I'm not really sure why you should care",
        "tokens": [
          50588,
          286,
          478,
          406,
          534,
          988,
          983,
          291,
          820,
          1127,
          50684
        ]
      },
      {
        "avg_logprob": -0.32172047008167615,
        "compression_ratio": 1.5676691729323309,
        "end": 595.84,
        "id": 109,
        "no_speech_prob": 0.018262984231114388,
        "seek": 58184,
        "start": 588.24,
        "temperature": 0,
        "text": " But I'm gonna try to answer those other questions that you yourself can decide so this playlist is essentially a replacement",
        "tokens": [
          50684,
          583,
          286,
          478,
          799,
          853,
          281,
          1867,
          729,
          661,
          1651,
          300,
          291,
          1803,
          393,
          4536,
          370,
          341,
          16788,
          307,
          4476,
          257,
          14419,
          51064
        ]
      },
      {
        "avg_logprob": -0.32172047008167615,
        "compression_ratio": 1.5676691729323309,
        "end": 602.44,
        "id": 110,
        "no_speech_prob": 0.018262984231114388,
        "seek": 58184,
        "start": 596.2,
        "temperature": 0,
        "text": " For session for Twitter API and bots with node.js so I am I'm gonna not redo",
        "tokens": [
          51082,
          1171,
          5481,
          337,
          5794,
          9362,
          293,
          35410,
          365,
          9984,
          13,
          25530,
          370,
          286,
          669,
          286,
          478,
          799,
          406,
          29956,
          51394
        ]
      },
      {
        "avg_logprob": -0.32172047008167615,
        "compression_ratio": 1.5676691729323309,
        "end": 610,
        "id": 111,
        "no_speech_prob": 0.018262984231114388,
        "seek": 58184,
        "start": 603.0400000000001,
        "temperature": 0,
        "text": " 15.1 and 15.2 if you have never used node before or don't know what npm is you can go back and watch those two videos",
        "tokens": [
          51424,
          2119,
          13,
          16,
          293,
          2119,
          13,
          17,
          498,
          291,
          362,
          1128,
          1143,
          9984,
          949,
          420,
          500,
          380,
          458,
          437,
          297,
          14395,
          307,
          291,
          393,
          352,
          646,
          293,
          1159,
          729,
          732,
          2145,
          51772
        ]
      },
      {
        "avg_logprob": -0.2878228538056724,
        "compression_ratio": 1.7333333333333334,
        "end": 615.04,
        "id": 112,
        "no_speech_prob": 0.003884310834109783,
        "seek": 61000,
        "start": 610.16,
        "temperature": 0,
        "text": " But I'm gonna start here basically with setting up setting up a Twitter setting up a Mastodon",
        "tokens": [
          50372,
          583,
          286,
          478,
          799,
          722,
          510,
          1936,
          365,
          3287,
          493,
          3287,
          493,
          257,
          5794,
          3287,
          493,
          257,
          376,
          525,
          378,
          266,
          50616
        ]
      },
      {
        "avg_logprob": -0.2878228538056724,
        "compression_ratio": 1.7333333333333334,
        "end": 618.48,
        "id": 113,
        "no_speech_prob": 0.003884310834109783,
        "seek": 61000,
        "start": 615.36,
        "temperature": 0,
        "text": " And so what is Mastodon? Why are we here so the Twitter API?",
        "tokens": [
          50632,
          400,
          370,
          437,
          307,
          376,
          525,
          378,
          266,
          30,
          1545,
          366,
          321,
          510,
          370,
          264,
          5794,
          9362,
          30,
          50788
        ]
      },
      {
        "avg_logprob": -0.2878228538056724,
        "compression_ratio": 1.7333333333333334,
        "end": 627.16,
        "id": 114,
        "no_speech_prob": 0.003884310834109783,
        "seek": 61000,
        "start": 619.68,
        "temperature": 0,
        "text": " Which I use to create these set of tutorials recently changed quite a bit, so it is much harder to sign up for a",
        "tokens": [
          50848,
          3013,
          286,
          764,
          281,
          1884,
          613,
          992,
          295,
          17616,
          3938,
          3105,
          1596,
          257,
          857,
          11,
          370,
          309,
          307,
          709,
          6081,
          281,
          1465,
          493,
          337,
          257,
          51222
        ]
      },
      {
        "avg_logprob": -0.2878228538056724,
        "compression_ratio": 1.7333333333333334,
        "end": 629.08,
        "id": 115,
        "no_speech_prob": 0.003884310834109783,
        "seek": 61000,
        "start": 627.68,
        "temperature": 0,
        "text": " new account",
        "tokens": [
          51248,
          777,
          2696,
          51318
        ]
      },
      {
        "avg_logprob": -0.2878228538056724,
        "compression_ratio": 1.7333333333333334,
        "end": 633.26,
        "id": 116,
        "no_speech_prob": 0.003884310834109783,
        "seek": 61000,
        "start": 629.08,
        "temperature": 0,
        "text": " Authorized for automation making a bot that posts in an automatic way to Twitter",
        "tokens": [
          51318,
          20216,
          1602,
          337,
          17769,
          1455,
          257,
          10592,
          300,
          12300,
          294,
          364,
          12509,
          636,
          281,
          5794,
          51527
        ]
      },
      {
        "avg_logprob": -0.2878228538056724,
        "compression_ratio": 1.7333333333333334,
        "end": 639.92,
        "id": 117,
        "no_speech_prob": 0.003884310834109783,
        "seek": 61000,
        "start": 633.26,
        "temperature": 0,
        "text": " They also changed something about the API called the streaming API the way you could connect to Twitter and listen for certain events",
        "tokens": [
          51527,
          814,
          611,
          3105,
          746,
          466,
          264,
          9362,
          1219,
          264,
          11791,
          9362,
          264,
          636,
          291,
          727,
          1745,
          281,
          5794,
          293,
          2140,
          337,
          1629,
          3931,
          51860
        ]
      },
      {
        "avg_logprob": -0.2952043176666508,
        "compression_ratio": 1.750809061488673,
        "end": 642.28,
        "id": 118,
        "no_speech_prob": 0.0004173074848949909,
        "seek": 64000,
        "start": 640.04,
        "temperature": 0,
        "text": " They change the API and that is no longer available",
        "tokens": [
          50366,
          814,
          1319,
          264,
          9362,
          293,
          300,
          307,
          572,
          2854,
          2435,
          50478
        ]
      },
      {
        "avg_logprob": -0.2952043176666508,
        "compression_ratio": 1.750809061488673,
        "end": 649.8,
        "id": 119,
        "no_speech_prob": 0.0004173074848949909,
        "seek": 64000,
        "start": 642.72,
        "temperature": 0,
        "text": " So while I encourage you to still experiment with Twitter as a platform if you so like if today is your first day",
        "tokens": [
          50500,
          407,
          1339,
          286,
          5373,
          291,
          281,
          920,
          5120,
          365,
          5794,
          382,
          257,
          3663,
          498,
          291,
          370,
          411,
          498,
          965,
          307,
          428,
          700,
          786,
          50854
        ]
      },
      {
        "avg_logprob": -0.2952043176666508,
        "compression_ratio": 1.750809061488673,
        "end": 656.16,
        "id": 120,
        "no_speech_prob": 0.0004173074848949909,
        "seek": 64000,
        "start": 650.4,
        "temperature": 0,
        "text": " Wanting to like learn some stuff about node and social networking and making up no social networks and making a bot that post",
        "tokens": [
          50884,
          11773,
          278,
          281,
          411,
          1466,
          512,
          1507,
          466,
          9984,
          293,
          2093,
          17985,
          293,
          1455,
          493,
          572,
          2093,
          9590,
          293,
          1455,
          257,
          10592,
          300,
          2183,
          51172
        ]
      },
      {
        "avg_logprob": -0.2952043176666508,
        "compression_ratio": 1.750809061488673,
        "end": 660.24,
        "id": 121,
        "no_speech_prob": 0.0004173074848949909,
        "seek": 64000,
        "start": 656.6,
        "temperature": 0,
        "text": " Mastodon is going to be a more pleasurable easygoing experience for you",
        "tokens": [
          51194,
          376,
          525,
          378,
          266,
          307,
          516,
          281,
          312,
          257,
          544,
          35122,
          25863,
          1858,
          8102,
          1752,
          337,
          291,
          51376
        ]
      },
      {
        "avg_logprob": -0.2952043176666508,
        "compression_ratio": 1.750809061488673,
        "end": 664.28,
        "id": 122,
        "no_speech_prob": 0.0004173074848949909,
        "seek": 64000,
        "start": 660.24,
        "temperature": 0,
        "text": " That's going to allow you to express your creativity in a much more immediate way, and then there's another reason",
        "tokens": [
          51376,
          663,
          311,
          516,
          281,
          2089,
          291,
          281,
          5109,
          428,
          12915,
          294,
          257,
          709,
          544,
          11629,
          636,
          11,
          293,
          550,
          456,
          311,
          1071,
          1778,
          51578
        ]
      },
      {
        "avg_logprob": -0.2952043176666508,
        "compression_ratio": 1.750809061488673,
        "end": 668.16,
        "id": 123,
        "no_speech_prob": 0.0004173074848949909,
        "seek": 64000,
        "start": 664.64,
        "temperature": 0,
        "text": " It has to do with this idea called decentralization so Twitter",
        "tokens": [
          51596,
          467,
          575,
          281,
          360,
          365,
          341,
          1558,
          1219,
          26515,
          2144,
          370,
          5794,
          51772
        ]
      },
      {
        "avg_logprob": -0.28872853767972034,
        "compression_ratio": 1.730909090909091,
        "end": 672.28,
        "id": 124,
        "no_speech_prob": 0.0022516511380672455,
        "seek": 66816,
        "start": 668.4,
        "temperature": 0,
        "text": " I don't know if you've noticed it's kind of an awful place to be for the most part",
        "tokens": [
          50376,
          286,
          500,
          380,
          458,
          498,
          291,
          600,
          5694,
          309,
          311,
          733,
          295,
          364,
          11232,
          1081,
          281,
          312,
          337,
          264,
          881,
          644,
          50570
        ]
      },
      {
        "avg_logprob": -0.28872853767972034,
        "compression_ratio": 1.730909090909091,
        "end": 677.4399999999999,
        "id": 125,
        "no_speech_prob": 0.0022516511380672455,
        "seek": 66816,
        "start": 672.28,
        "temperature": 0,
        "text": " I don't want to get too far down that discussion, but is there is there another way?",
        "tokens": [
          50570,
          286,
          500,
          380,
          528,
          281,
          483,
          886,
          1400,
          760,
          300,
          5017,
          11,
          457,
          307,
          456,
          307,
          456,
          1071,
          636,
          30,
          50828
        ]
      },
      {
        "avg_logprob": -0.28872853767972034,
        "compression_ratio": 1.730909090909091,
        "end": 681.8199999999999,
        "id": 126,
        "no_speech_prob": 0.0022516511380672455,
        "seek": 66816,
        "start": 677.4399999999999,
        "temperature": 0,
        "text": " Is there another way that we can communicate with each other in a less centralized?",
        "tokens": [
          50828,
          1119,
          456,
          1071,
          636,
          300,
          321,
          393,
          7890,
          365,
          1184,
          661,
          294,
          257,
          1570,
          32395,
          30,
          51047
        ]
      },
      {
        "avg_logprob": -0.28872853767972034,
        "compression_ratio": 1.730909090909091,
        "end": 688.8399999999999,
        "id": 127,
        "no_speech_prob": 0.0022516511380672455,
        "seek": 66816,
        "start": 682.7199999999999,
        "temperature": 0,
        "text": " governed and owned by large corporations kind of way and one way to do that is with a concept called",
        "tokens": [
          51092,
          35529,
          293,
          11684,
          538,
          2416,
          17676,
          733,
          295,
          636,
          293,
          472,
          636,
          281,
          360,
          300,
          307,
          365,
          257,
          3410,
          1219,
          51398
        ]
      },
      {
        "avg_logprob": -0.28872853767972034,
        "compression_ratio": 1.730909090909091,
        "end": 695.04,
        "id": 128,
        "no_speech_prob": 0.0022516511380672455,
        "seek": 66816,
        "start": 689.48,
        "temperature": 0,
        "text": " Decentralization and Mastodon is an open source. I don't know maybe I should go somewhere where it actually says what it is",
        "tokens": [
          51430,
          1346,
          2207,
          2155,
          2144,
          293,
          376,
          525,
          378,
          266,
          307,
          364,
          1269,
          4009,
          13,
          286,
          500,
          380,
          458,
          1310,
          286,
          820,
          352,
          4079,
          689,
          309,
          767,
          1619,
          437,
          309,
          307,
          51708
        ]
      },
      {
        "avg_logprob": -0.2841605162009215,
        "compression_ratio": 1.6185897435897436,
        "end": 701.7199999999999,
        "id": 129,
        "no_speech_prob": 0.002050605835393071,
        "seek": 69504,
        "start": 695.7199999999999,
        "temperature": 0,
        "text": " Well you can read follow friends discover new ones publish anything you want link pictures text video all in a platform that is community-owned",
        "tokens": [
          50398,
          1042,
          291,
          393,
          1401,
          1524,
          1855,
          4411,
          777,
          2306,
          11374,
          1340,
          291,
          528,
          2113,
          5242,
          2487,
          960,
          439,
          294,
          257,
          3663,
          300,
          307,
          1768,
          12,
          14683,
          50698
        ]
      },
      {
        "avg_logprob": -0.2841605162009215,
        "compression_ratio": 1.6185897435897436,
        "end": 707.64,
        "id": 130,
        "no_speech_prob": 0.002050605835393071,
        "seek": 69504,
        "start": 701.7199999999999,
        "temperature": 0,
        "text": " And ad free no this is not like some sort of sponsored video. I'm experimenting with this platform because it interests me",
        "tokens": [
          50698,
          400,
          614,
          1737,
          572,
          341,
          307,
          406,
          411,
          512,
          1333,
          295,
          16621,
          960,
          13,
          286,
          478,
          29070,
          365,
          341,
          3663,
          570,
          309,
          8847,
          385,
          50994
        ]
      },
      {
        "avg_logprob": -0.2841605162009215,
        "compression_ratio": 1.6185897435897436,
        "end": 709.64,
        "id": 131,
        "no_speech_prob": 0.002050605835393071,
        "seek": 69504,
        "start": 708.16,
        "temperature": 0,
        "text": " and",
        "tokens": [
          51020,
          293,
          51094
        ]
      },
      {
        "avg_logprob": -0.2841605162009215,
        "compression_ratio": 1.6185897435897436,
        "end": 712.48,
        "id": 132,
        "no_speech_prob": 0.002050605835393071,
        "seek": 69504,
        "start": 709.64,
        "temperature": 0,
        "text": " Maybe it'll interest you it is an open source project",
        "tokens": [
          51094,
          2704,
          309,
          603,
          1179,
          291,
          309,
          307,
          364,
          1269,
          4009,
          1716,
          51236
        ]
      },
      {
        "avg_logprob": -0.2841605162009215,
        "compression_ratio": 1.6185897435897436,
        "end": 718.3199999999999,
        "id": 133,
        "no_speech_prob": 0.002050605835393071,
        "seek": 69504,
        "start": 712.48,
        "temperature": 0,
        "text": " You can see it's on github here and the decentralization runs with a protocol called activity pub",
        "tokens": [
          51236,
          509,
          393,
          536,
          309,
          311,
          322,
          290,
          355,
          836,
          510,
          293,
          264,
          26515,
          2144,
          6676,
          365,
          257,
          10336,
          1219,
          5191,
          1535,
          51528
        ]
      },
      {
        "avg_logprob": -0.2841605162009215,
        "compression_ratio": 1.6185897435897436,
        "end": 723.04,
        "id": 134,
        "no_speech_prob": 0.002050605835393071,
        "seek": 69504,
        "start": 718.3199999999999,
        "temperature": 0,
        "text": " So let me try to give you an understanding of what I mean by all this stuff, okay?",
        "tokens": [
          51528,
          407,
          718,
          385,
          853,
          281,
          976,
          291,
          364,
          3701,
          295,
          437,
          286,
          914,
          538,
          439,
          341,
          1507,
          11,
          1392,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.35424599280724156,
        "compression_ratio": 1.4137931034482758,
        "end": 725.56,
        "id": 135,
        "no_speech_prob": 0.000008801033800409641,
        "seek": 72304,
        "start": 723.56,
        "temperature": 0,
        "text": " So what is Twitter ultimately?",
        "tokens": [
          50390,
          407,
          437,
          307,
          5794,
          6284,
          30,
          50490
        ]
      },
      {
        "avg_logprob": -0.35424599280724156,
        "compression_ratio": 1.4137931034482758,
        "end": 736.68,
        "id": 136,
        "no_speech_prob": 0.000008801033800409641,
        "seek": 72304,
        "start": 732.92,
        "temperature": 0,
        "text": " Just give me a second a little coughing fit here",
        "tokens": [
          50858,
          1449,
          976,
          385,
          257,
          1150,
          257,
          707,
          39375,
          3318,
          510,
          51046
        ]
      },
      {
        "avg_logprob": -0.35424599280724156,
        "compression_ratio": 1.4137931034482758,
        "end": 744.64,
        "id": 137,
        "no_speech_prob": 0.000008801033800409641,
        "seek": 72304,
        "start": 740.12,
        "temperature": 0,
        "text": " What is Twitter, I don't know if anyone should really answer that question, but I",
        "tokens": [
          51218,
          708,
          307,
          5794,
          11,
          286,
          500,
          380,
          458,
          498,
          2878,
          820,
          534,
          1867,
          300,
          1168,
          11,
          457,
          286,
          51444
        ]
      },
      {
        "avg_logprob": -0.35424599280724156,
        "compression_ratio": 1.4137931034482758,
        "end": 748.66,
        "id": 138,
        "no_speech_prob": 0.000008801033800409641,
        "seek": 72304,
        "start": 745.36,
        "temperature": 0,
        "text": " Will give you a little framework so Twitter",
        "tokens": [
          51480,
          3099,
          976,
          291,
          257,
          707,
          8388,
          370,
          5794,
          51645
        ]
      },
      {
        "avg_logprob": -0.3360372211622155,
        "compression_ratio": 1.7142857142857142,
        "end": 756.9,
        "id": 139,
        "no_speech_prob": 0.0010987176792696118,
        "seek": 74866,
        "start": 749.5,
        "temperature": 0,
        "text": " Is a company they run probably a lot of servers you can sign you can be sitting on your",
        "tokens": [
          50406,
          1119,
          257,
          2237,
          436,
          1190,
          1391,
          257,
          688,
          295,
          15909,
          291,
          393,
          1465,
          291,
          393,
          312,
          3798,
          322,
          428,
          50776
        ]
      },
      {
        "avg_logprob": -0.3360372211622155,
        "compression_ratio": 1.7142857142857142,
        "end": 760.2199999999999,
        "id": 140,
        "no_speech_prob": 0.0010987176792696118,
        "seek": 74866,
        "start": 757.86,
        "temperature": 0,
        "text": " Laptop or your you know phone",
        "tokens": [
          50824,
          441,
          2796,
          404,
          420,
          428,
          291,
          458,
          2593,
          50942
        ]
      },
      {
        "avg_logprob": -0.3360372211622155,
        "compression_ratio": 1.7142857142857142,
        "end": 764.3399999999999,
        "id": 141,
        "no_speech_prob": 0.0010987176792696118,
        "seek": 74866,
        "start": 760.3,
        "temperature": 0,
        "text": " That's a phone apparently and you can sign up for an account on Twitter",
        "tokens": [
          50946,
          663,
          311,
          257,
          2593,
          7970,
          293,
          291,
          393,
          1465,
          493,
          337,
          364,
          2696,
          322,
          5794,
          51148
        ]
      },
      {
        "avg_logprob": -0.3360372211622155,
        "compression_ratio": 1.7142857142857142,
        "end": 767.98,
        "id": 142,
        "no_speech_prob": 0.0010987176792696118,
        "seek": 74866,
        "start": 764.38,
        "temperature": 0,
        "text": " You could give yourself a Twitter username like at Shiffman",
        "tokens": [
          51150,
          509,
          727,
          976,
          1803,
          257,
          5794,
          30351,
          411,
          412,
          1160,
          3661,
          1601,
          51330
        ]
      },
      {
        "avg_logprob": -0.3360372211622155,
        "compression_ratio": 1.7142857142857142,
        "end": 772.26,
        "id": 143,
        "no_speech_prob": 0.0010987176792696118,
        "seek": 74866,
        "start": 767.98,
        "temperature": 0,
        "text": " And then you could post messages like the heart emoji",
        "tokens": [
          51330,
          400,
          550,
          291,
          727,
          2183,
          7897,
          411,
          264,
          1917,
          31595,
          51544
        ]
      },
      {
        "avg_logprob": -0.3360372211622155,
        "compression_ratio": 1.7142857142857142,
        "end": 778.38,
        "id": 144,
        "no_speech_prob": 0.0010987176792696118,
        "seek": 74866,
        "start": 772.26,
        "temperature": 0,
        "text": " And you can read other messages that other people are sending in to Twitter this",
        "tokens": [
          51544,
          400,
          291,
          393,
          1401,
          661,
          7897,
          300,
          661,
          561,
          366,
          7750,
          294,
          281,
          5794,
          341,
          51850
        ]
      },
      {
        "avg_logprob": -0.29361060570026265,
        "compression_ratio": 1.7321428571428572,
        "end": 782.54,
        "id": 145,
        "no_speech_prob": 0.00004757525312015787,
        "seek": 77866,
        "start": 778.8199999999999,
        "temperature": 0,
        "text": " Is what you would refer to as a centralized platform",
        "tokens": [
          50372,
          1119,
          437,
          291,
          576,
          2864,
          281,
          382,
          257,
          32395,
          3663,
          50558
        ]
      },
      {
        "avg_logprob": -0.29361060570026265,
        "compression_ratio": 1.7321428571428572,
        "end": 787.62,
        "id": 146,
        "no_speech_prob": 0.00004757525312015787,
        "seek": 77866,
        "start": 783.8199999999999,
        "temperature": 0,
        "text": " The software that runs Twitter is on a particular server",
        "tokens": [
          50622,
          440,
          4722,
          300,
          6676,
          5794,
          307,
          322,
          257,
          1729,
          7154,
          50812
        ]
      },
      {
        "avg_logprob": -0.29361060570026265,
        "compression_ratio": 1.7321428571428572,
        "end": 794.02,
        "id": 147,
        "no_speech_prob": 0.00004757525312015787,
        "seek": 77866,
        "start": 787.62,
        "temperature": 0,
        "text": " It's proprietary the way Twitter is governed and how where what certain posts are allowed and aren't allowed are all",
        "tokens": [
          50812,
          467,
          311,
          38992,
          264,
          636,
          5794,
          307,
          35529,
          293,
          577,
          689,
          437,
          1629,
          12300,
          366,
          4350,
          293,
          3212,
          380,
          4350,
          366,
          439,
          51132
        ]
      },
      {
        "avg_logprob": -0.29361060570026265,
        "compression_ratio": 1.7321428571428572,
        "end": 799.5799999999999,
        "id": 148,
        "no_speech_prob": 0.00004757525312015787,
        "seek": 77866,
        "start": 794.6999999999999,
        "temperature": 0,
        "text": " Run by this same company and all of your data all of the tweets",
        "tokens": [
          51166,
          8950,
          538,
          341,
          912,
          2237,
          293,
          439,
          295,
          428,
          1412,
          439,
          295,
          264,
          25671,
          51410
        ]
      },
      {
        "avg_logprob": -0.29361060570026265,
        "compression_ratio": 1.7321428571428572,
        "end": 804.54,
        "id": 149,
        "no_speech_prob": 0.00004757525312015787,
        "seek": 77866,
        "start": 799.5799999999999,
        "temperature": 0,
        "text": " You've ever posted all of your user information your password stuff all of that is stored on this",
        "tokens": [
          51410,
          509,
          600,
          1562,
          9437,
          439,
          295,
          428,
          4195,
          1589,
          428,
          11524,
          1507,
          439,
          295,
          300,
          307,
          12187,
          322,
          341,
          51658
        ]
      },
      {
        "avg_logprob": -0.2901205657630838,
        "compression_ratio": 1.8783783783783783,
        "end": 809.02,
        "id": 150,
        "no_speech_prob": 0.00023781927302479744,
        "seek": 80454,
        "start": 804.74,
        "temperature": 0,
        "text": " Decentralized server the web in its origins if you go back and look at the history of the web",
        "tokens": [
          50374,
          1346,
          2207,
          2155,
          1602,
          7154,
          264,
          3670,
          294,
          1080,
          22721,
          498,
          291,
          352,
          646,
          293,
          574,
          412,
          264,
          2503,
          295,
          264,
          3670,
          50588
        ]
      },
      {
        "avg_logprob": -0.2901205657630838,
        "compression_ratio": 1.8783783783783783,
        "end": 813.38,
        "id": 151,
        "no_speech_prob": 0.00023781927302479744,
        "seek": 80454,
        "start": 809.98,
        "temperature": 0,
        "text": " Didn't really start as this idea of a centralized platform",
        "tokens": [
          50636,
          11151,
          380,
          534,
          722,
          382,
          341,
          1558,
          295,
          257,
          32395,
          3663,
          50806
        ]
      },
      {
        "avg_logprob": -0.2901205657630838,
        "compression_ratio": 1.8783783783783783,
        "end": 822.62,
        "id": 152,
        "no_speech_prob": 0.00023781927302479744,
        "seek": 80454,
        "start": 819.02,
        "temperature": 0,
        "text": " The web didn't start with this idea of a centralized platform",
        "tokens": [
          51088,
          440,
          3670,
          994,
          380,
          722,
          365,
          341,
          1558,
          295,
          257,
          32395,
          3663,
          51268
        ]
      },
      {
        "avg_logprob": -0.2901205657630838,
        "compression_ratio": 1.8783783783783783,
        "end": 828.3399999999999,
        "id": 153,
        "no_speech_prob": 0.00023781927302479744,
        "seek": 80454,
        "start": 822.86,
        "temperature": 0,
        "text": " The idea was many different nodes all interconnected being able to share and publish with each other",
        "tokens": [
          51280,
          440,
          1558,
          390,
          867,
          819,
          13891,
          439,
          36611,
          885,
          1075,
          281,
          2073,
          293,
          11374,
          365,
          1184,
          661,
          51554
        ]
      },
      {
        "avg_logprob": -0.2901205657630838,
        "compression_ratio": 1.8783783783783783,
        "end": 833.78,
        "id": 154,
        "no_speech_prob": 0.00023781927302479744,
        "seek": 80454,
        "start": 828.3399999999999,
        "temperature": 0,
        "text": " And so there is this is coming slowly entering the zeitgeist now this idea of decentralized platforms",
        "tokens": [
          51554,
          400,
          370,
          456,
          307,
          341,
          307,
          1348,
          5692,
          11104,
          264,
          49367,
          432,
          468,
          586,
          341,
          1558,
          295,
          32870,
          9473,
          51826
        ]
      },
      {
        "avg_logprob": -0.33685527270353294,
        "compression_ratio": 1.6223175965665235,
        "end": 840.1,
        "id": 155,
        "no_speech_prob": 0.0010322046000510454,
        "seek": 83378,
        "start": 833.78,
        "temperature": 0,
        "text": " Probably if you're not familiar with that you probably familiar with something called Bitcoin right which runs on something called blockchain",
        "tokens": [
          50364,
          9210,
          498,
          291,
          434,
          406,
          4963,
          365,
          300,
          291,
          1391,
          4963,
          365,
          746,
          1219,
          11414,
          558,
          597,
          6676,
          322,
          746,
          1219,
          17176,
          50680
        ]
      },
      {
        "avg_logprob": -0.33685527270353294,
        "compression_ratio": 1.6223175965665235,
        "end": 846.8199999999999,
        "id": 156,
        "no_speech_prob": 0.0010322046000510454,
        "seek": 83378,
        "start": 840.1,
        "temperature": 0,
        "text": " Which is a protocol for decentralized financial transactions, which I am NOT gonna make any videos about at least anytime soon, but",
        "tokens": [
          50680,
          3013,
          307,
          257,
          10336,
          337,
          32870,
          4669,
          16856,
          11,
          597,
          286,
          669,
          12854,
          799,
          652,
          604,
          2145,
          466,
          412,
          1935,
          13038,
          2321,
          11,
          457,
          51016
        ]
      },
      {
        "avg_logprob": -0.33685527270353294,
        "compression_ratio": 1.6223175965665235,
        "end": 850.14,
        "id": 157,
        "no_speech_prob": 0.0010322046000510454,
        "seek": 83378,
        "start": 848.14,
        "temperature": 0,
        "text": " Mastodon is a",
        "tokens": [
          51082,
          376,
          525,
          378,
          266,
          307,
          257,
          51182
        ]
      },
      {
        "avg_logprob": -0.33685527270353294,
        "compression_ratio": 1.6223175965665235,
        "end": 855.5,
        "id": 158,
        "no_speech_prob": 0.0010322046000510454,
        "seek": 83378,
        "start": 850.3,
        "temperature": 0,
        "text": " D open-source decentralized social social network. I have so much trouble saying that word",
        "tokens": [
          51190,
          413,
          1269,
          12,
          41676,
          32870,
          2093,
          2093,
          3209,
          13,
          286,
          362,
          370,
          709,
          5253,
          1566,
          300,
          1349,
          51450
        ]
      },
      {
        "avg_logprob": -0.4824889965271682,
        "compression_ratio": 1.516431924882629,
        "end": 857.5,
        "id": 159,
        "no_speech_prob": 0.0001420219923602417,
        "seek": 85550,
        "start": 855.5,
        "temperature": 0,
        "text": " Do you like trains?",
        "tokens": [
          50364,
          1144,
          291,
          411,
          16329,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.4824889965271682,
        "compression_ratio": 1.516431924882629,
        "end": 864.9,
        "id": 160,
        "no_speech_prob": 0.0001420219923602417,
        "seek": 85550,
        "start": 862.9,
        "temperature": 0,
        "text": " Mastodon",
        "tokens": [
          50734,
          376,
          525,
          378,
          266,
          50834
        ]
      },
      {
        "avg_logprob": -0.4824889965271682,
        "compression_ratio": 1.516431924882629,
        "end": 866.9,
        "id": 161,
        "no_speech_prob": 0.0001420219923602417,
        "seek": 85550,
        "start": 864.9,
        "temperature": 0,
        "text": " Mastodon is an open-source",
        "tokens": [
          50834,
          376,
          525,
          378,
          266,
          307,
          364,
          1269,
          12,
          41676,
          50934
        ]
      },
      {
        "avg_logprob": -0.4824889965271682,
        "compression_ratio": 1.516431924882629,
        "end": 868.9,
        "id": 162,
        "no_speech_prob": 0.0001420219923602417,
        "seek": 85550,
        "start": 866.9,
        "temperature": 0,
        "text": " Decentralized social network and",
        "tokens": [
          50934,
          1346,
          2207,
          2155,
          1602,
          2093,
          3209,
          293,
          51034
        ]
      },
      {
        "avg_logprob": -0.4824889965271682,
        "compression_ratio": 1.516431924882629,
        "end": 874.9,
        "id": 163,
        "no_speech_prob": 0.0001420219923602417,
        "seek": 85550,
        "start": 868.9,
        "temperature": 0,
        "text": " It probably resembles Twitter the most but there's some nuance to that so how is it different? How does it work?",
        "tokens": [
          51034,
          467,
          1391,
          34433,
          5794,
          264,
          881,
          457,
          456,
          311,
          512,
          42625,
          281,
          300,
          370,
          577,
          307,
          309,
          819,
          30,
          1012,
          775,
          309,
          589,
          30,
          51334
        ]
      },
      {
        "avg_logprob": -0.4824889965271682,
        "compression_ratio": 1.516431924882629,
        "end": 878.9,
        "id": 164,
        "no_speech_prob": 0.0001420219923602417,
        "seek": 85550,
        "start": 874.9,
        "temperature": 0,
        "text": " Well number one is there is no single server for example",
        "tokens": [
          51334,
          1042,
          1230,
          472,
          307,
          456,
          307,
          572,
          2167,
          7154,
          337,
          1365,
          51534
        ]
      },
      {
        "avg_logprob": -0.4824889965271682,
        "compression_ratio": 1.516431924882629,
        "end": 881.9,
        "id": 165,
        "no_speech_prob": 0.0001420219923602417,
        "seek": 85550,
        "start": 878.9,
        "temperature": 0,
        "text": " I have actually set up my own server known as an internet server",
        "tokens": [
          51534,
          286,
          362,
          767,
          992,
          493,
          452,
          1065,
          7154,
          2570,
          382,
          364,
          4705,
          7154,
          51684
        ]
      },
      {
        "avg_logprob": -0.26257552419389996,
        "compression_ratio": 1.6554621848739495,
        "end": 886.18,
        "id": 166,
        "no_speech_prob": 0.007937736809253693,
        "seek": 88190,
        "start": 881.98,
        "temperature": 0,
        "text": " For example, I have actually set up my own server known as an instance and",
        "tokens": [
          50368,
          1171,
          1365,
          11,
          286,
          362,
          767,
          992,
          493,
          452,
          1065,
          7154,
          2570,
          382,
          364,
          5197,
          293,
          50578
        ]
      },
      {
        "avg_logprob": -0.26257552419389996,
        "compression_ratio": 1.6554621848739495,
        "end": 891.6999999999999,
        "id": 167,
        "no_speech_prob": 0.007937736809253693,
        "seek": 88190,
        "start": 887.34,
        "temperature": 0,
        "text": " I'm not going to show you in this series how to set up your own Mastodon in instance",
        "tokens": [
          50636,
          286,
          478,
          406,
          516,
          281,
          855,
          291,
          294,
          341,
          2638,
          577,
          281,
          992,
          493,
          428,
          1065,
          376,
          525,
          378,
          266,
          294,
          5197,
          50854
        ]
      },
      {
        "avg_logprob": -0.26257552419389996,
        "compression_ratio": 1.6554621848739495,
        "end": 896.62,
        "id": 168,
        "no_speech_prob": 0.007937736809253693,
        "seek": 88190,
        "start": 891.6999999999999,
        "temperature": 0,
        "text": " But if that's of interest I certainly can provide some resources to do that and I could do a video about setting one up",
        "tokens": [
          50854,
          583,
          498,
          300,
          311,
          295,
          1179,
          286,
          3297,
          393,
          2893,
          512,
          3593,
          281,
          360,
          300,
          293,
          286,
          727,
          360,
          257,
          960,
          466,
          3287,
          472,
          493,
          51100
        ]
      },
      {
        "avg_logprob": -0.26257552419389996,
        "compression_ratio": 1.6554621848739495,
        "end": 900.06,
        "id": 169,
        "no_speech_prob": 0.007937736809253693,
        "seek": 88190,
        "start": 896.66,
        "temperature": 0,
        "text": " My instance is at a particular domain",
        "tokens": [
          51102,
          1222,
          5197,
          307,
          412,
          257,
          1729,
          9274,
          51272
        ]
      },
      {
        "avg_logprob": -0.26257552419389996,
        "compression_ratio": 1.6554621848739495,
        "end": 902.38,
        "id": 170,
        "no_speech_prob": 0.007937736809253693,
        "seek": 88190,
        "start": 900.74,
        "temperature": 0,
        "text": " choo-choo",
        "tokens": [
          51306,
          1586,
          78,
          12,
          339,
          1986,
          51388
        ]
      },
      {
        "avg_logprob": -0.26257552419389996,
        "compression_ratio": 1.6554621848739495,
        "end": 904.38,
        "id": 171,
        "no_speech_prob": 0.007937736809253693,
        "seek": 88190,
        "start": 902.38,
        "temperature": 0,
        "text": " dot space",
        "tokens": [
          51388,
          5893,
          1901,
          51488
        ]
      },
      {
        "avg_logprob": -0.26257552419389996,
        "compression_ratio": 1.6554621848739495,
        "end": 907.78,
        "id": 172,
        "no_speech_prob": 0.007937736809253693,
        "seek": 88190,
        "start": 904.5,
        "temperature": 0,
        "text": " This is my Mastodon instance, so we'll call it choo-choo",
        "tokens": [
          51494,
          639,
          307,
          452,
          376,
          525,
          378,
          266,
          5197,
          11,
          370,
          321,
          603,
          818,
          309,
          1586,
          78,
          12,
          339,
          1986,
          51658
        ]
      },
      {
        "avg_logprob": -0.32369319252345874,
        "compression_ratio": 1.8858695652173914,
        "end": 912.5799999999999,
        "id": 173,
        "no_speech_prob": 0.00010889581608353183,
        "seek": 90778,
        "start": 908.6999999999999,
        "temperature": 0,
        "text": " There are other Mastodon in instances for example",
        "tokens": [
          50410,
          821,
          366,
          661,
          376,
          525,
          378,
          266,
          294,
          14519,
          337,
          1365,
          50604
        ]
      },
      {
        "avg_logprob": -0.32369319252345874,
        "compression_ratio": 1.8858695652173914,
        "end": 915.66,
        "id": 174,
        "no_speech_prob": 0.00010889581608353183,
        "seek": 90778,
        "start": 913.5,
        "temperature": 0,
        "text": " Mastodon dot social",
        "tokens": [
          50650,
          376,
          525,
          378,
          266,
          5893,
          2093,
          50758
        ]
      },
      {
        "avg_logprob": -0.32369319252345874,
        "compression_ratio": 1.8858695652173914,
        "end": 919.62,
        "id": 175,
        "no_speech_prob": 0.00010889581608353183,
        "seek": 90778,
        "start": 916.8199999999999,
        "temperature": 0,
        "text": " There is also let me let me erase some of this stuff here",
        "tokens": [
          50816,
          821,
          307,
          611,
          718,
          385,
          718,
          385,
          23525,
          512,
          295,
          341,
          1507,
          510,
          50956
        ]
      },
      {
        "avg_logprob": -0.32369319252345874,
        "compression_ratio": 1.8858695652173914,
        "end": 921.62,
        "id": 176,
        "no_speech_prob": 0.00010889581608353183,
        "seek": 90778,
        "start": 920.38,
        "temperature": 0,
        "text": " choo-choo",
        "tokens": [
          50994,
          1586,
          78,
          12,
          339,
          1986,
          51056
        ]
      },
      {
        "avg_logprob": -0.32369319252345874,
        "compression_ratio": 1.8858695652173914,
        "end": 923.62,
        "id": 177,
        "no_speech_prob": 0.00010889581608353183,
        "seek": 90778,
        "start": 921.62,
        "temperature": 0,
        "text": " Mastodon dot social",
        "tokens": [
          51056,
          376,
          525,
          378,
          266,
          5893,
          2093,
          51156
        ]
      },
      {
        "avg_logprob": -0.32369319252345874,
        "compression_ratio": 1.8858695652173914,
        "end": 926.98,
        "id": 178,
        "no_speech_prob": 0.00010889581608353183,
        "seek": 90778,
        "start": 923.6999999999999,
        "temperature": 0,
        "text": " There are some other ones that I have seen for example. There is",
        "tokens": [
          51160,
          821,
          366,
          512,
          661,
          2306,
          300,
          286,
          362,
          1612,
          337,
          1365,
          13,
          821,
          307,
          51324
        ]
      },
      {
        "avg_logprob": -0.32369319252345874,
        "compression_ratio": 1.8858695652173914,
        "end": 935.66,
        "id": 179,
        "no_speech_prob": 0.00010889581608353183,
        "seek": 90778,
        "start": 928.06,
        "temperature": 0,
        "text": " This dot social which is an instance for people interested in data visualization. I presume there is another instance called",
        "tokens": [
          51378,
          639,
          5893,
          2093,
          597,
          307,
          364,
          5197,
          337,
          561,
          3102,
          294,
          1412,
          25801,
          13,
          286,
          43283,
          456,
          307,
          1071,
          5197,
          1219,
          51758
        ]
      },
      {
        "avg_logprob": -0.31487908884256827,
        "compression_ratio": 1.7137254901960783,
        "end": 937.9,
        "id": 180,
        "no_speech_prob": 0.00007602372352266684,
        "seek": 93566,
        "start": 936.18,
        "temperature": 0,
        "text": " bots in",
        "tokens": [
          50390,
          35410,
          294,
          50476
        ]
      },
      {
        "avg_logprob": -0.31487908884256827,
        "compression_ratio": 1.7137254901960783,
        "end": 943.38,
        "id": 181,
        "no_speech_prob": 0.00007602372352266684,
        "seek": 93566,
        "start": 937.9,
        "temperature": 0,
        "text": " Dot space which I'm going to use in this series to make a bot that runs on this bot in space",
        "tokens": [
          50476,
          38753,
          1901,
          597,
          286,
          478,
          516,
          281,
          764,
          294,
          341,
          2638,
          281,
          652,
          257,
          10592,
          300,
          6676,
          322,
          341,
          10592,
          294,
          1901,
          50750
        ]
      },
      {
        "avg_logprob": -0.31487908884256827,
        "compression_ratio": 1.7137254901960783,
        "end": 945.9399999999999,
        "id": 182,
        "no_speech_prob": 0.00007602372352266684,
        "seek": 93566,
        "start": 943.38,
        "temperature": 0,
        "text": " So the idea here is I've set up this instance",
        "tokens": [
          50750,
          407,
          264,
          1558,
          510,
          307,
          286,
          600,
          992,
          493,
          341,
          5197,
          50878
        ]
      },
      {
        "avg_logprob": -0.31487908884256827,
        "compression_ratio": 1.7137254901960783,
        "end": 950.4399999999999,
        "id": 183,
        "no_speech_prob": 0.00007602372352266684,
        "seek": 93566,
        "start": 945.9399999999999,
        "temperature": 0,
        "text": " Let's say you want to sign up for an account with this particular instance you would go",
        "tokens": [
          50878,
          961,
          311,
          584,
          291,
          528,
          281,
          1465,
          493,
          337,
          364,
          2696,
          365,
          341,
          1729,
          5197,
          291,
          576,
          352,
          51103
        ]
      },
      {
        "avg_logprob": -0.31487908884256827,
        "compression_ratio": 1.7137254901960783,
        "end": 953.6999999999999,
        "id": 184,
        "no_speech_prob": 0.00007602372352266684,
        "seek": 93566,
        "start": 950.4399999999999,
        "temperature": 0,
        "text": " I'll show it to you say you would go there and you would sign up and so my",
        "tokens": [
          51103,
          286,
          603,
          855,
          309,
          281,
          291,
          584,
          291,
          576,
          352,
          456,
          293,
          291,
          576,
          1465,
          493,
          293,
          370,
          452,
          51266
        ]
      },
      {
        "avg_logprob": -0.31487908884256827,
        "compression_ratio": 1.7137254901960783,
        "end": 961.66,
        "id": 185,
        "no_speech_prob": 0.00007602372352266684,
        "seek": 93566,
        "start": 954.2199999999999,
        "temperature": 0,
        "text": " Username I'm a client my like picture of my like laptop over here, which is strangely. It's a weird bizarre angle",
        "tokens": [
          51292,
          4958,
          28704,
          286,
          478,
          257,
          6423,
          452,
          411,
          3036,
          295,
          452,
          411,
          10732,
          670,
          510,
          11,
          597,
          307,
          39851,
          13,
          467,
          311,
          257,
          3657,
          18265,
          5802,
          51664
        ]
      },
      {
        "avg_logprob": -0.31487908884256827,
        "compression_ratio": 1.7137254901960783,
        "end": 963.78,
        "id": 186,
        "no_speech_prob": 0.00007602372352266684,
        "seek": 93566,
        "start": 961.66,
        "temperature": 0,
        "text": " I am Shiffman",
        "tokens": [
          51664,
          286,
          669,
          1160,
          3661,
          1601,
          51770
        ]
      },
      {
        "avg_logprob": -0.3150077864181164,
        "compression_ratio": 1.752808988764045,
        "end": 966.78,
        "id": 187,
        "no_speech_prob": 0.00008349608106072992,
        "seek": 96378,
        "start": 964.78,
        "temperature": 0,
        "text": " At choo-choo",
        "tokens": [
          50414,
          1711,
          1586,
          78,
          12,
          339,
          1986,
          50514
        ]
      },
      {
        "avg_logprob": -0.3150077864181164,
        "compression_ratio": 1.752808988764045,
        "end": 969.38,
        "id": 188,
        "no_speech_prob": 0.00008349608106072992,
        "seek": 96378,
        "start": 967.54,
        "temperature": 0,
        "text": " Dot space",
        "tokens": [
          50552,
          38753,
          1901,
          50644
        ]
      },
      {
        "avg_logprob": -0.3150077864181164,
        "compression_ratio": 1.752808988764045,
        "end": 971.38,
        "id": 189,
        "no_speech_prob": 0.00008349608106072992,
        "seek": 96378,
        "start": 969.38,
        "temperature": 0,
        "text": " So this is my local",
        "tokens": [
          50644,
          407,
          341,
          307,
          452,
          2654,
          50744
        ]
      },
      {
        "avg_logprob": -0.3150077864181164,
        "compression_ratio": 1.752808988764045,
        "end": 973.54,
        "id": 190,
        "no_speech_prob": 0.00008349608106072992,
        "seek": 96378,
        "start": 971.62,
        "temperature": 0,
        "text": " This is my local",
        "tokens": [
          50756,
          639,
          307,
          452,
          2654,
          50852
        ]
      },
      {
        "avg_logprob": -0.3150077864181164,
        "compression_ratio": 1.752808988764045,
        "end": 980.3399999999999,
        "id": 191,
        "no_speech_prob": 0.00008349608106072992,
        "seek": 96378,
        "start": 973.54,
        "temperature": 0,
        "text": " Mastodon instance when I want to sign on when I want to post something I post it I sign on through this server",
        "tokens": [
          50852,
          376,
          525,
          378,
          266,
          5197,
          562,
          286,
          528,
          281,
          1465,
          322,
          562,
          286,
          528,
          281,
          2183,
          746,
          286,
          2183,
          309,
          286,
          1465,
          322,
          807,
          341,
          7154,
          51192
        ]
      },
      {
        "avg_logprob": -0.3150077864181164,
        "compression_ratio": 1.752808988764045,
        "end": 986.0799999999999,
        "id": 192,
        "no_speech_prob": 0.00008349608106072992,
        "seek": 96378,
        "start": 980.3399999999999,
        "temperature": 0,
        "text": " I post it through this server my account is with this server, but there is this concept called Federation",
        "tokens": [
          51192,
          286,
          2183,
          309,
          807,
          341,
          7154,
          452,
          2696,
          307,
          365,
          341,
          7154,
          11,
          457,
          456,
          307,
          341,
          3410,
          1219,
          27237,
          51479
        ]
      },
      {
        "avg_logprob": -0.3150077864181164,
        "compression_ratio": 1.752808988764045,
        "end": 989.78,
        "id": 193,
        "no_speech_prob": 0.00008349608106072992,
        "seek": 96378,
        "start": 987.78,
        "temperature": 0,
        "text": " Sounds like something I'm Star Trek",
        "tokens": [
          51564,
          14576,
          411,
          746,
          286,
          478,
          5705,
          25845,
          51664
        ]
      },
      {
        "avg_logprob": -0.31344679898993916,
        "compression_ratio": 1.606837606837607,
        "end": 992.18,
        "id": 194,
        "no_speech_prob": 0.00000707188200976816,
        "seek": 98978,
        "start": 990.18,
        "temperature": 0,
        "text": " And it kind of is which",
        "tokens": [
          50384,
          400,
          309,
          733,
          295,
          307,
          597,
          50484
        ]
      },
      {
        "avg_logprob": -0.31344679898993916,
        "compression_ratio": 1.606837606837607,
        "end": 997.5799999999999,
        "id": 195,
        "no_speech_prob": 0.00000707188200976816,
        "seek": 98978,
        "start": 992.26,
        "temperature": 0,
        "text": " Federation and I know I kind of getting close to writing off the top is a way for all of these instances",
        "tokens": [
          50488,
          27237,
          293,
          286,
          458,
          286,
          733,
          295,
          1242,
          1998,
          281,
          3579,
          766,
          264,
          1192,
          307,
          257,
          636,
          337,
          439,
          295,
          613,
          14519,
          50754
        ]
      },
      {
        "avg_logprob": -0.31344679898993916,
        "compression_ratio": 1.606837606837607,
        "end": 1001.68,
        "id": 196,
        "no_speech_prob": 0.00000707188200976816,
        "seek": 98978,
        "start": 997.9,
        "temperature": 0,
        "text": " To communicate with each other in a decentralized fashion",
        "tokens": [
          50770,
          1407,
          7890,
          365,
          1184,
          661,
          294,
          257,
          32870,
          6700,
          50959
        ]
      },
      {
        "avg_logprob": -0.31344679898993916,
        "compression_ratio": 1.606837606837607,
        "end": 1011.12,
        "id": 197,
        "no_speech_prob": 0.00000707188200976816,
        "seek": 98978,
        "start": 1003.6999999999999,
        "temperature": 0,
        "text": " So if I post something saying like hello, I ate oatmeal for breakfast this morning",
        "tokens": [
          51060,
          407,
          498,
          286,
          2183,
          746,
          1566,
          411,
          7751,
          11,
          286,
          8468,
          47223,
          337,
          8201,
          341,
          2446,
          51431
        ]
      },
      {
        "avg_logprob": -0.31344679898993916,
        "compression_ratio": 1.606837606837607,
        "end": 1018.56,
        "id": 198,
        "no_speech_prob": 0.00000707188200976816,
        "seek": 98978,
        "start": 1012.02,
        "temperature": 0,
        "text": " This post that I make through here will get propagated throughout the entire network of Mastodon instances",
        "tokens": [
          51476,
          639,
          2183,
          300,
          286,
          652,
          807,
          510,
          486,
          483,
          12425,
          770,
          3710,
          264,
          2302,
          3209,
          295,
          376,
          525,
          378,
          266,
          14519,
          51803
        ]
      },
      {
        "avg_logprob": -0.2765317542530666,
        "compression_ratio": 1.7763713080168777,
        "end": 1024.6399999999999,
        "id": 199,
        "no_speech_prob": 0.000013007048437430058,
        "seek": 101856,
        "start": 1018.68,
        "temperature": 0,
        "text": " so there is both when you're browsing Mastodon, there's both this idea of a local timeline as",
        "tokens": [
          50370,
          370,
          456,
          307,
          1293,
          562,
          291,
          434,
          38602,
          376,
          525,
          378,
          266,
          11,
          456,
          311,
          1293,
          341,
          1558,
          295,
          257,
          2654,
          12933,
          382,
          50668
        ]
      },
      {
        "avg_logprob": -0.2765317542530666,
        "compression_ratio": 1.7763713080168777,
        "end": 1028.6599999999999,
        "id": 200,
        "no_speech_prob": 0.000013007048437430058,
        "seek": 101856,
        "start": 1025.48,
        "temperature": 0,
        "text": " Well as a federated or you can think of it as global timeline",
        "tokens": [
          50710,
          1042,
          382,
          257,
          38024,
          770,
          420,
          291,
          393,
          519,
          295,
          309,
          382,
          4338,
          12933,
          50869
        ]
      },
      {
        "avg_logprob": -0.2765317542530666,
        "compression_ratio": 1.7763713080168777,
        "end": 1033.36,
        "id": 201,
        "no_speech_prob": 0.000013007048437430058,
        "seek": 101856,
        "start": 1028.6599999999999,
        "temperature": 0,
        "text": " And I'll show you this in a second I could browse and just look at all the posts. I think they're called toots",
        "tokens": [
          50869,
          400,
          286,
          603,
          855,
          291,
          341,
          294,
          257,
          1150,
          286,
          727,
          31442,
          293,
          445,
          574,
          412,
          439,
          264,
          12300,
          13,
          286,
          519,
          436,
          434,
          1219,
          281,
          1971,
          51104
        ]
      },
      {
        "avg_logprob": -0.2765317542530666,
        "compression_ratio": 1.7763713080168777,
        "end": 1036.1599999999999,
        "id": 202,
        "no_speech_prob": 0.000013007048437430058,
        "seek": 101856,
        "start": 1034.48,
        "temperature": 0,
        "text": " all the toots",
        "tokens": [
          51160,
          439,
          264,
          281,
          1971,
          51244
        ]
      },
      {
        "avg_logprob": -0.2765317542530666,
        "compression_ratio": 1.7763713080168777,
        "end": 1043.6,
        "id": 203,
        "no_speech_prob": 0.000013007048437430058,
        "seek": 101856,
        "start": 1036.1599999999999,
        "temperature": 0,
        "text": " For people who are at this instance are all the toots from people all throughout the federated universe of instances by the way the protocol",
        "tokens": [
          51244,
          1171,
          561,
          567,
          366,
          412,
          341,
          5197,
          366,
          439,
          264,
          281,
          1971,
          490,
          561,
          439,
          3710,
          264,
          38024,
          770,
          6445,
          295,
          14519,
          538,
          264,
          636,
          264,
          10336,
          51616
        ]
      },
      {
        "avg_logprob": -0.2581233476337634,
        "compression_ratio": 1.754646840148699,
        "end": 1051.04,
        "id": 204,
        "no_speech_prob": 0.0003859613207168877,
        "seek": 104360,
        "start": 1044,
        "temperature": 0,
        "text": " That is used for all of this for the for all the communication to propagate throughout the network. I think I mentioned this already",
        "tokens": [
          50384,
          663,
          307,
          1143,
          337,
          439,
          295,
          341,
          337,
          264,
          337,
          439,
          264,
          6101,
          281,
          48256,
          3710,
          264,
          3209,
          13,
          286,
          519,
          286,
          2835,
          341,
          1217,
          50736
        ]
      },
      {
        "avg_logprob": -0.2581233476337634,
        "compression_ratio": 1.754646840148699,
        "end": 1054.04,
        "id": 205,
        "no_speech_prob": 0.0003859613207168877,
        "seek": 104360,
        "start": 1052.04,
        "temperature": 0,
        "text": " It's called activity pub",
        "tokens": [
          50786,
          467,
          311,
          1219,
          5191,
          1535,
          50886
        ]
      },
      {
        "avg_logprob": -0.2581233476337634,
        "compression_ratio": 1.754646840148699,
        "end": 1059.28,
        "id": 206,
        "no_speech_prob": 0.0003859613207168877,
        "seek": 104360,
        "start": 1055.1999999999998,
        "temperature": 0,
        "text": " So the software that runs a particular server is completely open source",
        "tokens": [
          50944,
          407,
          264,
          4722,
          300,
          6676,
          257,
          1729,
          7154,
          307,
          2584,
          1269,
          4009,
          51148
        ]
      },
      {
        "avg_logprob": -0.2581233476337634,
        "compression_ratio": 1.754646840148699,
        "end": 1062.7199999999998,
        "id": 207,
        "no_speech_prob": 0.0003859613207168877,
        "seek": 104360,
        "start": 1059.28,
        "temperature": 0,
        "text": " It took me a while to get it up and running, but I have it up and running here",
        "tokens": [
          51148,
          467,
          1890,
          385,
          257,
          1339,
          281,
          483,
          309,
          493,
          293,
          2614,
          11,
          457,
          286,
          362,
          309,
          493,
          293,
          2614,
          510,
          51320
        ]
      },
      {
        "avg_logprob": -0.2581233476337634,
        "compression_ratio": 1.754646840148699,
        "end": 1065.4399999999998,
        "id": 208,
        "no_speech_prob": 0.0003859613207168877,
        "seek": 104360,
        "start": 1062.7199999999998,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to show you my account here",
        "tokens": [
          51320,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          855,
          291,
          452,
          2696,
          510,
          51456
        ]
      },
      {
        "avg_logprob": -0.2581233476337634,
        "compression_ratio": 1.754646840148699,
        "end": 1070.1999999999998,
        "id": 209,
        "no_speech_prob": 0.0003859613207168877,
        "seek": 104360,
        "start": 1065.4399999999998,
        "temperature": 0,
        "text": " I'm going to show you bots in space which is an instance designed for people who want to make bots",
        "tokens": [
          51456,
          286,
          478,
          516,
          281,
          855,
          291,
          35410,
          294,
          1901,
          597,
          307,
          364,
          5197,
          4761,
          337,
          561,
          567,
          528,
          281,
          652,
          35410,
          51694
        ]
      },
      {
        "avg_logprob": -0.2626521963822214,
        "compression_ratio": 1.6523297491039426,
        "end": 1074,
        "id": 210,
        "no_speech_prob": 0.0017545644659548998,
        "seek": 107020,
        "start": 1070.24,
        "temperature": 0,
        "text": " I'm going to sign up and create a bot on bots in space and interact with it here",
        "tokens": [
          50366,
          286,
          478,
          516,
          281,
          1465,
          493,
          293,
          1884,
          257,
          10592,
          322,
          35410,
          294,
          1901,
          293,
          4648,
          365,
          309,
          510,
          50554
        ]
      },
      {
        "avg_logprob": -0.2626521963822214,
        "compression_ratio": 1.6523297491039426,
        "end": 1077.32,
        "id": 211,
        "no_speech_prob": 0.0017545644659548998,
        "seek": 107020,
        "start": 1074,
        "temperature": 0,
        "text": " and then just show you how the global network of stuff works, so",
        "tokens": [
          50554,
          293,
          550,
          445,
          855,
          291,
          577,
          264,
          4338,
          3209,
          295,
          1507,
          1985,
          11,
          370,
          50720
        ]
      },
      {
        "avg_logprob": -0.2626521963822214,
        "compression_ratio": 1.6523297491039426,
        "end": 1083.48,
        "id": 212,
        "no_speech_prob": 0.0017545644659548998,
        "seek": 107020,
        "start": 1078.04,
        "temperature": 0,
        "text": " The only prerequisites really for you going to the next video is to have node",
        "tokens": [
          50756,
          440,
          787,
          38333,
          15398,
          3324,
          534,
          337,
          291,
          516,
          281,
          264,
          958,
          960,
          307,
          281,
          362,
          9984,
          51028
        ]
      },
      {
        "avg_logprob": -0.2626521963822214,
        "compression_ratio": 1.6523297491039426,
        "end": 1084.92,
        "id": 213,
        "no_speech_prob": 0.0017545644659548998,
        "seek": 107020,
        "start": 1083.72,
        "temperature": 0,
        "text": " installed on your computer",
        "tokens": [
          51040,
          8899,
          322,
          428,
          3820,
          51100
        ]
      },
      {
        "avg_logprob": -0.2626521963822214,
        "compression_ratio": 1.6523297491039426,
        "end": 1091.3600000000001,
        "id": 214,
        "no_speech_prob": 0.0017545644659548998,
        "seek": 107020,
        "start": 1084.92,
        "temperature": 0,
        "text": " And you can go back and watch my two sort of intro to node for Twitter bots videos and the same concepts there will apply",
        "tokens": [
          51100,
          400,
          291,
          393,
          352,
          646,
          293,
          1159,
          452,
          732,
          1333,
          295,
          12897,
          281,
          9984,
          337,
          5794,
          35410,
          2145,
          293,
          264,
          912,
          10392,
          456,
          486,
          3079,
          51422
        ]
      },
      {
        "avg_logprob": -0.2626521963822214,
        "compression_ratio": 1.6523297491039426,
        "end": 1093.3600000000001,
        "id": 215,
        "no_speech_prob": 0.0017545644659548998,
        "seek": 107020,
        "start": 1091.3600000000001,
        "temperature": 0,
        "text": " Although I'm going to use different node packages",
        "tokens": [
          51422,
          5780,
          286,
          478,
          516,
          281,
          764,
          819,
          9984,
          17401,
          51522
        ]
      },
      {
        "avg_logprob": -0.2626521963822214,
        "compression_ratio": 1.6523297491039426,
        "end": 1096.0800000000002,
        "id": 216,
        "no_speech_prob": 0.0017545644659548998,
        "seek": 107020,
        "start": 1094.0800000000002,
        "temperature": 0,
        "text": " What else do I want to say about this?",
        "tokens": [
          51558,
          708,
          1646,
          360,
          286,
          528,
          281,
          584,
          466,
          341,
          30,
          51658
        ]
      },
      {
        "avg_logprob": -0.5572356758536873,
        "compression_ratio": 1.6983471074380165,
        "end": 1098.8,
        "id": 217,
        "no_speech_prob": 0.0019265597220510244,
        "seek": 109608,
        "start": 1096.8,
        "temperature": 0,
        "text": " Yeah, okay",
        "tokens": [
          50400,
          865,
          11,
          1392,
          50500
        ]
      },
      {
        "avg_logprob": -0.5572356758536873,
        "compression_ratio": 1.6983471074380165,
        "end": 1101.8,
        "id": 218,
        "no_speech_prob": 0.0019265597220510244,
        "seek": 109608,
        "start": 1099.8,
        "temperature": 0,
        "text": " Coming back over here",
        "tokens": [
          50550,
          12473,
          646,
          670,
          510,
          50650
        ]
      },
      {
        "avg_logprob": -0.5572356758536873,
        "compression_ratio": 1.6983471074380165,
        "end": 1111.6,
        "id": 219,
        "no_speech_prob": 0.0019265597220510244,
        "seek": 109608,
        "start": 1104,
        "temperature": 0,
        "text": " Okay, so ah so this is the github repository where is the open source mastodon project is I encourage you to check that out",
        "tokens": [
          50760,
          1033,
          11,
          370,
          3716,
          370,
          341,
          307,
          264,
          290,
          355,
          836,
          25841,
          689,
          307,
          264,
          1269,
          4009,
          27055,
          378,
          266,
          1716,
          307,
          286,
          5373,
          291,
          281,
          1520,
          300,
          484,
          51140
        ]
      },
      {
        "avg_logprob": -0.5572356758536873,
        "compression_ratio": 1.6983471074380165,
        "end": 1117.84,
        "id": 220,
        "no_speech_prob": 0.0019265597220510244,
        "seek": 109608,
        "start": 1111.6,
        "temperature": 0,
        "text": " This is some more information about activity pub which is the protocol for decentralized social networking lots of other services",
        "tokens": [
          51140,
          639,
          307,
          512,
          544,
          1589,
          466,
          5191,
          1535,
          597,
          307,
          264,
          10336,
          337,
          32870,
          2093,
          17985,
          3195,
          295,
          661,
          3328,
          51452
        ]
      },
      {
        "avg_logprob": -0.5572356758536873,
        "compression_ratio": 1.6983471074380165,
        "end": 1124.48,
        "id": 221,
        "no_speech_prob": 0.0019265597220510244,
        "seek": 109608,
        "start": 1118.1599999999999,
        "temperature": 0,
        "text": " Also use activity pub there are the you know this idea of decentralized the decentralized web is not limited to just the web",
        "tokens": [
          51468,
          2743,
          764,
          5191,
          1535,
          456,
          366,
          264,
          291,
          458,
          341,
          1558,
          295,
          32870,
          264,
          32870,
          3670,
          307,
          406,
          5567,
          281,
          445,
          264,
          3670,
          51784
        ]
      },
      {
        "avg_logprob": -0.29502256790010056,
        "compression_ratio": 1.591743119266055,
        "end": 1132.1200000000001,
        "id": 222,
        "no_speech_prob": 0.00007967210694914684,
        "seek": 112448,
        "start": 1124.64,
        "temperature": 0,
        "text": " Decentralized web is not limited to mastodon one simple example of that and then here now you can see whoops here is my",
        "tokens": [
          50372,
          1346,
          2207,
          2155,
          1602,
          3670,
          307,
          406,
          5567,
          281,
          27055,
          378,
          266,
          472,
          2199,
          1365,
          295,
          300,
          293,
          550,
          510,
          586,
          291,
          393,
          536,
          567,
          3370,
          510,
          307,
          452,
          50746
        ]
      },
      {
        "avg_logprob": -0.29502256790010056,
        "compression_ratio": 1.591743119266055,
        "end": 1137.2,
        "id": 223,
        "no_speech_prob": 0.00007967210694914684,
        "seek": 112448,
        "start": 1132.8,
        "temperature": 0,
        "text": " Mastodon instance you can see that if I go to choo-choo dot space I am there",
        "tokens": [
          50780,
          376,
          525,
          378,
          266,
          5197,
          291,
          393,
          536,
          300,
          498,
          286,
          352,
          281,
          1586,
          78,
          12,
          339,
          1986,
          5893,
          1901,
          286,
          669,
          456,
          51000
        ]
      },
      {
        "avg_logprob": -0.29502256790010056,
        "compression_ratio": 1.591743119266055,
        "end": 1141.48,
        "id": 224,
        "no_speech_prob": 0.00007967210694914684,
        "seek": 112448,
        "start": 1137.2,
        "temperature": 0,
        "text": " It looks like I am on some kind of social network thing where I can say hey",
        "tokens": [
          51000,
          467,
          1542,
          411,
          286,
          669,
          322,
          512,
          733,
          295,
          2093,
          3209,
          551,
          689,
          286,
          393,
          584,
          4177,
          51214
        ]
      },
      {
        "avg_logprob": -0.29502256790010056,
        "compression_ratio": 1.591743119266055,
        "end": 1144.2,
        "id": 225,
        "no_speech_prob": 0.00007967210694914684,
        "seek": 112448,
        "start": 1142.2,
        "temperature": 0,
        "text": " whoops hey I am",
        "tokens": [
          51250,
          567,
          3370,
          4177,
          286,
          669,
          51350
        ]
      },
      {
        "avg_logprob": -0.29502256790010056,
        "compression_ratio": 1.591743119266055,
        "end": 1147.56,
        "id": 226,
        "no_speech_prob": 0.00007967210694914684,
        "seek": 112448,
        "start": 1144.88,
        "temperature": 0,
        "text": " live on YouTube right now and",
        "tokens": [
          51384,
          1621,
          322,
          3088,
          558,
          586,
          293,
          51518
        ]
      },
      {
        "avg_logprob": -0.29502256790010056,
        "compression_ratio": 1.591743119266055,
        "end": 1150.88,
        "id": 227,
        "no_speech_prob": 0.00007967210694914684,
        "seek": 112448,
        "start": 1148.88,
        "temperature": 0,
        "text": " Can you make a little train?",
        "tokens": [
          51584,
          1664,
          291,
          652,
          257,
          707,
          3847,
          30,
          51684
        ]
      },
      {
        "avg_logprob": -0.35981054043551103,
        "compression_ratio": 1.6967213114754098,
        "end": 1157.2,
        "id": 228,
        "no_speech_prob": 0.0030752955935895443,
        "seek": 115088,
        "start": 1151.88,
        "temperature": 0,
        "text": " And a little I know you're just gonna have to watch me do this I have to pick my emojis very carefully and thoughtfully",
        "tokens": [
          50414,
          400,
          257,
          707,
          286,
          458,
          291,
          434,
          445,
          799,
          362,
          281,
          1159,
          385,
          360,
          341,
          286,
          362,
          281,
          1888,
          452,
          19611,
          40371,
          588,
          7500,
          293,
          1194,
          2277,
          50680
        ]
      },
      {
        "avg_logprob": -0.35981054043551103,
        "compression_ratio": 1.6967213114754098,
        "end": 1161.8400000000001,
        "id": 229,
        "no_speech_prob": 0.0030752955935895443,
        "seek": 115088,
        "start": 1157.8000000000002,
        "temperature": 0,
        "text": " Rainbows really like clouds or anything no. I don't know okay. That'll be enough",
        "tokens": [
          50710,
          14487,
          21118,
          534,
          411,
          12193,
          420,
          1340,
          572,
          13,
          286,
          500,
          380,
          458,
          1392,
          13,
          663,
          603,
          312,
          1547,
          50912
        ]
      },
      {
        "avg_logprob": -0.35981054043551103,
        "compression_ratio": 1.6967213114754098,
        "end": 1166.5,
        "id": 230,
        "no_speech_prob": 0.0030752955935895443,
        "seek": 115088,
        "start": 1162.2,
        "temperature": 0,
        "text": " I'm gonna post that you can see there. It is and it is there on the local timeline",
        "tokens": [
          50930,
          286,
          478,
          799,
          2183,
          300,
          291,
          393,
          536,
          456,
          13,
          467,
          307,
          293,
          309,
          307,
          456,
          322,
          264,
          2654,
          12933,
          51145
        ]
      },
      {
        "avg_logprob": -0.35981054043551103,
        "compression_ratio": 1.6967213114754098,
        "end": 1173.2800000000002,
        "id": 231,
        "no_speech_prob": 0.0030752955935895443,
        "seek": 115088,
        "start": 1166.5,
        "temperature": 0,
        "text": " So this is the local timeline you can see kweek on there look ma. I'm on the live stream now. Here's the thing because",
        "tokens": [
          51145,
          407,
          341,
          307,
          264,
          2654,
          12933,
          291,
          393,
          536,
          350,
          23188,
          322,
          456,
          574,
          463,
          13,
          286,
          478,
          322,
          264,
          1621,
          4309,
          586,
          13,
          1692,
          311,
          264,
          551,
          570,
          51484
        ]
      },
      {
        "avg_logprob": -0.35981054043551103,
        "compression_ratio": 1.6967213114754098,
        "end": 1175.8400000000001,
        "id": 232,
        "no_speech_prob": 0.0030752955935895443,
        "seek": 115088,
        "start": 1173.96,
        "temperature": 0,
        "text": " my instance",
        "tokens": [
          51518,
          452,
          5197,
          51612
        ]
      },
      {
        "avg_logprob": -0.26064880495148945,
        "compression_ratio": 1.7303370786516854,
        "end": 1181.6399999999999,
        "id": 233,
        "no_speech_prob": 0.022976255044341087,
        "seek": 117584,
        "start": 1175.84,
        "temperature": 0,
        "text": " Is something I just set up and it's running off of a digital ocean server. I it's like $10 a month",
        "tokens": [
          50364,
          1119,
          746,
          286,
          445,
          992,
          493,
          293,
          309,
          311,
          2614,
          766,
          295,
          257,
          4562,
          7810,
          7154,
          13,
          286,
          309,
          311,
          411,
          1848,
          3279,
          257,
          1618,
          50654
        ]
      },
      {
        "avg_logprob": -0.26064880495148945,
        "compression_ratio": 1.7303370786516854,
        "end": 1185.9599999999998,
        "id": 234,
        "no_speech_prob": 0.022976255044341087,
        "seek": 117584,
        "start": 1181.6399999999999,
        "temperature": 0,
        "text": " It's like two gigabytes of RAM. I just signed up for it digital ocean is a hosting provider",
        "tokens": [
          50654,
          467,
          311,
          411,
          732,
          42741,
          295,
          14561,
          13,
          286,
          445,
          8175,
          493,
          337,
          309,
          4562,
          7810,
          307,
          257,
          16058,
          12398,
          50870
        ]
      },
      {
        "avg_logprob": -0.26064880495148945,
        "compression_ratio": 1.7303370786516854,
        "end": 1189.82,
        "id": 235,
        "no_speech_prob": 0.022976255044341087,
        "seek": 117584,
        "start": 1187,
        "temperature": 0,
        "text": " Not a sponsor, but could be a digital ocean you're listening",
        "tokens": [
          50922,
          1726,
          257,
          16198,
          11,
          457,
          727,
          312,
          257,
          4562,
          7810,
          291,
          434,
          4764,
          51063
        ]
      },
      {
        "avg_logprob": -0.26064880495148945,
        "compression_ratio": 1.7303370786516854,
        "end": 1196.62,
        "id": 236,
        "no_speech_prob": 0.022976255044341087,
        "seek": 117584,
        "start": 1190.72,
        "temperature": 0,
        "text": " I'm not the signups are not open so to get an invite code to sign up on the choo-choo space",
        "tokens": [
          51108,
          286,
          478,
          406,
          264,
          1465,
          7528,
          366,
          406,
          1269,
          370,
          281,
          483,
          364,
          7980,
          3089,
          281,
          1465,
          493,
          322,
          264,
          1586,
          78,
          12,
          339,
          1986,
          1901,
          51403
        ]
      },
      {
        "avg_logprob": -0.26064880495148945,
        "compression_ratio": 1.7303370786516854,
        "end": 1202.9199999999998,
        "id": 237,
        "no_speech_prob": 0.022976255044341087,
        "seek": 117584,
        "start": 1197.1999999999998,
        "temperature": 0,
        "text": " Instance you can be if you're a member of the YouTube channel or a patron of the channel you can you can sign up there",
        "tokens": [
          51432,
          2730,
          719,
          291,
          393,
          312,
          498,
          291,
          434,
          257,
          4006,
          295,
          264,
          3088,
          2269,
          420,
          257,
          21843,
          295,
          264,
          2269,
          291,
          393,
          291,
          393,
          1465,
          493,
          456,
          51718
        ]
      },
      {
        "avg_logprob": -0.31721292082796393,
        "compression_ratio": 1.627906976744186,
        "end": 1206,
        "id": 238,
        "no_speech_prob": 0.0005192915559746325,
        "seek": 120292,
        "start": 1202.96,
        "temperature": 0,
        "text": " But I'm just you know I don't I don't want to mention it",
        "tokens": [
          50366,
          583,
          286,
          478,
          445,
          291,
          458,
          286,
          500,
          380,
          286,
          500,
          380,
          528,
          281,
          2152,
          309,
          50518
        ]
      },
      {
        "avg_logprob": -0.31721292082796393,
        "compression_ratio": 1.627906976744186,
        "end": 1209.68,
        "id": 239,
        "no_speech_prob": 0.0005192915559746325,
        "seek": 120292,
        "start": 1207.68,
        "temperature": 0,
        "text": " Let me go back",
        "tokens": [
          50602,
          961,
          385,
          352,
          646,
          50702
        ]
      },
      {
        "avg_logprob": -0.31721292082796393,
        "compression_ratio": 1.627906976744186,
        "end": 1214.52,
        "id": 240,
        "no_speech_prob": 0.0005192915559746325,
        "seek": 120292,
        "start": 1210.64,
        "temperature": 0,
        "text": " Matthea who will be watching this later. I don't want to go on and on if I don't want to like mention the",
        "tokens": [
          50750,
          6789,
          3322,
          64,
          567,
          486,
          312,
          1976,
          341,
          1780,
          13,
          286,
          500,
          380,
          528,
          281,
          352,
          322,
          293,
          322,
          498,
          286,
          500,
          380,
          528,
          281,
          411,
          2152,
          264,
          50944
        ]
      },
      {
        "avg_logprob": -0.31721292082796393,
        "compression_ratio": 1.627906976744186,
        "end": 1221.52,
        "id": 241,
        "no_speech_prob": 0.0005192915559746325,
        "seek": 120292,
        "start": 1215.04,
        "temperature": 0,
        "text": " Patron membership stuff during the that's important for the live stream context, but because I might open it up later",
        "tokens": [
          50970,
          4379,
          2044,
          16560,
          1507,
          1830,
          264,
          300,
          311,
          1021,
          337,
          264,
          1621,
          4309,
          4319,
          11,
          457,
          570,
          286,
          1062,
          1269,
          309,
          493,
          1780,
          51294
        ]
      },
      {
        "avg_logprob": -0.31721292082796393,
        "compression_ratio": 1.627906976744186,
        "end": 1224.8400000000001,
        "id": 242,
        "no_speech_prob": 0.0005192915559746325,
        "seek": 120292,
        "start": 1222.4,
        "temperature": 0,
        "text": " So let me just kind of re-say what I was saying before",
        "tokens": [
          51338,
          407,
          718,
          385,
          445,
          733,
          295,
          319,
          12,
          21664,
          437,
          286,
          390,
          1566,
          949,
          51460
        ]
      },
      {
        "avg_logprob": -0.6070063710212708,
        "compression_ratio": 1.4161073825503356,
        "end": 1230.84,
        "id": 243,
        "no_speech_prob": 0.000008013368642423302,
        "seek": 122484,
        "start": 1224.84,
        "temperature": 0,
        "text": " I'm afraid to go to the global timeline, but maybe I'll maybe I will let me just quickly peek",
        "tokens": [
          50364,
          286,
          478,
          4638,
          281,
          352,
          281,
          264,
          4338,
          12933,
          11,
          457,
          1310,
          286,
          603,
          1310,
          286,
          486,
          718,
          385,
          445,
          2661,
          19604,
          50664
        ]
      },
      {
        "avg_logprob": -0.6070063710212708,
        "compression_ratio": 1.4161073825503356,
        "end": 1235.84,
        "id": 244,
        "no_speech_prob": 0.000008013368642423302,
        "seek": 122484,
        "start": 1233.84,
        "temperature": 0,
        "text": " Okay, it's not terrible",
        "tokens": [
          50814,
          1033,
          11,
          309,
          311,
          406,
          6237,
          50914
        ]
      },
      {
        "avg_logprob": -0.6070063710212708,
        "compression_ratio": 1.4161073825503356,
        "end": 1239.1599999999999,
        "id": 245,
        "no_speech_prob": 0.000008013368642423302,
        "seek": 122484,
        "start": 1237.1599999999999,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50980,
          1033,
          51080
        ]
      },
      {
        "avg_logprob": -0.6070063710212708,
        "compression_ratio": 1.4161073825503356,
        "end": 1241.3999999999999,
        "id": 246,
        "no_speech_prob": 0.000008013368642423302,
        "seek": 122484,
        "start": 1239.3999999999999,
        "temperature": 0,
        "text": " Let me go back what was I saying",
        "tokens": [
          51092,
          961,
          385,
          352,
          646,
          437,
          390,
          286,
          1566,
          51192
        ]
      },
      {
        "avg_logprob": -0.6070063710212708,
        "compression_ratio": 1.4161073825503356,
        "end": 1247.9599999999998,
        "id": 247,
        "no_speech_prob": 0.000008013368642423302,
        "seek": 122484,
        "start": 1244.24,
        "temperature": 0,
        "text": " You could see the I don't know I don't know where I was",
        "tokens": [
          51334,
          509,
          727,
          536,
          264,
          286,
          500,
          380,
          458,
          286,
          500,
          380,
          458,
          689,
          286,
          390,
          51520
        ]
      },
      {
        "avg_logprob": -0.9254705575796274,
        "compression_ratio": 1.7826086956521738,
        "end": 1251.32,
        "id": 248,
        "no_speech_prob": 0.000046837511035846546,
        "seek": 124796,
        "start": 1248.96,
        "temperature": 0,
        "text": " I'm just gonna do that whole little section again",
        "tokens": [
          50414,
          286,
          478,
          445,
          799,
          360,
          300,
          1379,
          707,
          3541,
          797,
          50532
        ]
      },
      {
        "avg_logprob": -0.9254705575796274,
        "compression_ratio": 1.7826086956521738,
        "end": 1258,
        "id": 249,
        "no_speech_prob": 0.000046837511035846546,
        "seek": 124796,
        "start": 1254.96,
        "temperature": 0,
        "text": " Sorry for the live people who this will be annoying to",
        "tokens": [
          50714,
          4919,
          337,
          264,
          1621,
          561,
          567,
          341,
          486,
          312,
          11304,
          281,
          50866
        ]
      },
      {
        "avg_logprob": -0.9254705575796274,
        "compression_ratio": 1.7826086956521738,
        "end": 1269.88,
        "id": 250,
        "no_speech_prob": 0.000046837511035846546,
        "seek": 124796,
        "start": 1266,
        "temperature": 0,
        "text": " Okay, so here we are and what I can do is I can go to the global timeline",
        "tokens": [
          51266,
          1033,
          11,
          370,
          510,
          321,
          366,
          293,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          352,
          281,
          264,
          4338,
          12933,
          51460
        ]
      },
      {
        "avg_logprob": -0.9254705575796274,
        "compression_ratio": 1.7826086956521738,
        "end": 1273,
        "id": 251,
        "no_speech_prob": 0.000046837511035846546,
        "seek": 124796,
        "start": 1269.88,
        "temperature": 0,
        "text": " I can go to the global timeline and I can go to the global timeline",
        "tokens": [
          51460,
          286,
          393,
          352,
          281,
          264,
          4338,
          12933,
          293,
          286,
          393,
          352,
          281,
          264,
          4338,
          12933,
          51616
        ]
      },
      {
        "avg_logprob": -0.29979750122686827,
        "compression_ratio": 1.592274678111588,
        "end": 1275.56,
        "id": 252,
        "no_speech_prob": 0.0011335439048707485,
        "seek": 127300,
        "start": 1273.56,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50392,
          1033,
          50492
        ]
      },
      {
        "avg_logprob": -0.29979750122686827,
        "compression_ratio": 1.592274678111588,
        "end": 1280.52,
        "id": 253,
        "no_speech_prob": 0.0011335439048707485,
        "seek": 127300,
        "start": 1275.68,
        "temperature": 0,
        "text": " So here we are and what I can do now is I just first of all let me just show you a couple links",
        "tokens": [
          50498,
          407,
          510,
          321,
          366,
          293,
          437,
          286,
          393,
          360,
          586,
          307,
          286,
          445,
          700,
          295,
          439,
          718,
          385,
          445,
          855,
          291,
          257,
          1916,
          6123,
          50740
        ]
      },
      {
        "avg_logprob": -0.29979750122686827,
        "compression_ratio": 1.592274678111588,
        "end": 1282.52,
        "id": 254,
        "no_speech_prob": 0.0011335439048707485,
        "seek": 127300,
        "start": 1280.52,
        "temperature": 0,
        "text": " Which will all be in this videos description",
        "tokens": [
          50740,
          3013,
          486,
          439,
          312,
          294,
          341,
          2145,
          3855,
          50840
        ]
      },
      {
        "avg_logprob": -0.29979750122686827,
        "compression_ratio": 1.592274678111588,
        "end": 1289.12,
        "id": 255,
        "no_speech_prob": 0.0011335439048707485,
        "seek": 127300,
        "start": 1282.64,
        "temperature": 0,
        "text": " This is the github open source repository for the mastodon software that I'm running currently on my server",
        "tokens": [
          50846,
          639,
          307,
          264,
          290,
          355,
          836,
          1269,
          4009,
          25841,
          337,
          264,
          27055,
          378,
          266,
          4722,
          300,
          286,
          478,
          2614,
          4362,
          322,
          452,
          7154,
          51170
        ]
      },
      {
        "avg_logprob": -0.29979750122686827,
        "compression_ratio": 1.592274678111588,
        "end": 1296.4,
        "id": 256,
        "no_speech_prob": 0.0011335439048707485,
        "seek": 127300,
        "start": 1290.4,
        "temperature": 0,
        "text": " Over here. I just I think I mentioned this did I show I'm so confused did I show help me out for a second in",
        "tokens": [
          51234,
          4886,
          510,
          13,
          286,
          445,
          286,
          519,
          286,
          2835,
          341,
          630,
          286,
          855,
          286,
          478,
          370,
          9019,
          630,
          286,
          855,
          854,
          385,
          484,
          337,
          257,
          1150,
          294,
          51534
        ]
      },
      {
        "avg_logprob": -0.29979750122686827,
        "compression_ratio": 1.592274678111588,
        "end": 1298.12,
        "id": 257,
        "no_speech_prob": 0.0011335439048707485,
        "seek": 127300,
        "start": 1296.4,
        "temperature": 0,
        "text": " the chat",
        "tokens": [
          51534,
          264,
          5081,
          51620
        ]
      },
      {
        "avg_logprob": -0.26888281898160954,
        "compression_ratio": 1.628158844765343,
        "end": 1303.56,
        "id": 258,
        "no_speech_prob": 0.004905334673821926,
        "seek": 129812,
        "start": 1298.12,
        "temperature": 0,
        "text": " Did I show these earlier like I'm confused because I tried to do this video last week and then I got messed up",
        "tokens": [
          50364,
          2589,
          286,
          855,
          613,
          3071,
          411,
          286,
          478,
          9019,
          570,
          286,
          3031,
          281,
          360,
          341,
          960,
          1036,
          1243,
          293,
          550,
          286,
          658,
          16507,
          493,
          50636
        ]
      },
      {
        "avg_logprob": -0.26888281898160954,
        "compression_ratio": 1.628158844765343,
        "end": 1306,
        "id": 259,
        "no_speech_prob": 0.004905334673821926,
        "seek": 129812,
        "start": 1303.6799999999998,
        "temperature": 0,
        "text": " Did I already earlier today?",
        "tokens": [
          50642,
          2589,
          286,
          1217,
          3071,
          965,
          30,
          50758
        ]
      },
      {
        "avg_logprob": -0.26888281898160954,
        "compression_ratio": 1.628158844765343,
        "end": 1312.52,
        "id": 260,
        "no_speech_prob": 0.004905334673821926,
        "seek": 129812,
        "start": 1306.52,
        "temperature": 0,
        "text": " Show the github repository and this page and I'm now repeating myself like when I was doing my intro that I went to the whiteboard",
        "tokens": [
          50784,
          6895,
          264,
          290,
          355,
          836,
          25841,
          293,
          341,
          3028,
          293,
          286,
          478,
          586,
          18617,
          2059,
          411,
          562,
          286,
          390,
          884,
          452,
          12897,
          300,
          286,
          1437,
          281,
          264,
          2418,
          3787,
          51084
        ]
      },
      {
        "avg_logprob": -0.26888281898160954,
        "compression_ratio": 1.628158844765343,
        "end": 1314.6399999999999,
        "id": 261,
        "no_speech_prob": 0.004905334673821926,
        "seek": 129812,
        "start": 1312.6399999999999,
        "temperature": 0,
        "text": " Does anybody remember?",
        "tokens": [
          51090,
          4402,
          4472,
          1604,
          30,
          51190
        ]
      },
      {
        "avg_logprob": -0.26888281898160954,
        "compression_ratio": 1.628158844765343,
        "end": 1321.6,
        "id": 262,
        "no_speech_prob": 0.004905334673821926,
        "seek": 129812,
        "start": 1316.1599999999999,
        "temperature": 0,
        "text": " Let me know in the slack channel or we're here. Oh, I made that digital ocean joke",
        "tokens": [
          51266,
          961,
          385,
          458,
          294,
          264,
          29767,
          2269,
          420,
          321,
          434,
          510,
          13,
          876,
          11,
          286,
          1027,
          300,
          4562,
          7810,
          7647,
          51538
        ]
      },
      {
        "avg_logprob": -0.26888281898160954,
        "compression_ratio": 1.628158844765343,
        "end": 1326.04,
        "id": 263,
        "no_speech_prob": 0.004905334673821926,
        "seek": 129812,
        "start": 1322.6,
        "temperature": 0,
        "text": " I'm gonna have to make that again because they could be a sponsor for real",
        "tokens": [
          51588,
          286,
          478,
          799,
          362,
          281,
          652,
          300,
          797,
          570,
          436,
          727,
          312,
          257,
          16198,
          337,
          957,
          51760
        ]
      },
      {
        "avg_logprob": -0.613249610452091,
        "compression_ratio": 1.5333333333333334,
        "end": 1328.04,
        "id": 264,
        "no_speech_prob": 0.000016964208043646067,
        "seek": 132604,
        "start": 1326.04,
        "temperature": 0,
        "text": " Yes, one of the first things okay",
        "tokens": [
          50364,
          1079,
          11,
          472,
          295,
          264,
          700,
          721,
          1392,
          50464
        ]
      },
      {
        "avg_logprob": -0.613249610452091,
        "compression_ratio": 1.5333333333333334,
        "end": 1335.72,
        "id": 265,
        "no_speech_prob": 0.000016964208043646067,
        "seek": 132604,
        "start": 1331.32,
        "temperature": 0,
        "text": " All right, so I'm just gonna like come over here to my instance whoops no no no no",
        "tokens": [
          50628,
          1057,
          558,
          11,
          370,
          286,
          478,
          445,
          799,
          411,
          808,
          670,
          510,
          281,
          452,
          5197,
          567,
          3370,
          572,
          572,
          572,
          572,
          50848
        ]
      },
      {
        "avg_logprob": -0.613249610452091,
        "compression_ratio": 1.5333333333333334,
        "end": 1346.76,
        "id": 266,
        "no_speech_prob": 0.000016964208043646067,
        "seek": 132604,
        "start": 1341.56,
        "temperature": 0,
        "text": " You showed activity hub, but not the repo okay great. Thank you, so I'm not gonna show activity hub again",
        "tokens": [
          51140,
          509,
          4712,
          5191,
          11838,
          11,
          457,
          406,
          264,
          49040,
          1392,
          869,
          13,
          1044,
          291,
          11,
          370,
          286,
          478,
          406,
          799,
          855,
          5191,
          11838,
          797,
          51400
        ]
      },
      {
        "avg_logprob": -0.613249610452091,
        "compression_ratio": 1.5333333333333334,
        "end": 1349.6399999999999,
        "id": 267,
        "no_speech_prob": 0.000016964208043646067,
        "seek": 132604,
        "start": 1347.6399999999999,
        "temperature": 0,
        "text": " So I'll just come over here",
        "tokens": [
          51444,
          407,
          286,
          603,
          445,
          808,
          670,
          510,
          51544
        ]
      },
      {
        "avg_logprob": -0.613249610452091,
        "compression_ratio": 1.5333333333333334,
        "end": 1353.72,
        "id": 268,
        "no_speech_prob": 0.000016964208043646067,
        "seek": 132604,
        "start": 1349.72,
        "temperature": 0,
        "text": " Okay. Oh welcome new member or Nico Finkernadine",
        "tokens": [
          51548,
          1033,
          13,
          876,
          2928,
          777,
          4006,
          420,
          15115,
          479,
          475,
          1248,
          345,
          533,
          51748
        ]
      },
      {
        "avg_logprob": -0.42742799457750824,
        "compression_ratio": 1.63003663003663,
        "end": 1357.64,
        "id": 269,
        "no_speech_prob": 0.003376356093212962,
        "seek": 135372,
        "start": 1353.72,
        "temperature": 0,
        "text": " And please the first thing you should do is tell me how to pronounce your name and",
        "tokens": [
          50364,
          400,
          1767,
          264,
          700,
          551,
          291,
          820,
          360,
          307,
          980,
          385,
          577,
          281,
          19567,
          428,
          1315,
          293,
          50560
        ]
      },
      {
        "avg_logprob": -0.42742799457750824,
        "compression_ratio": 1.63003663003663,
        "end": 1365.32,
        "id": 270,
        "no_speech_prob": 0.003376356093212962,
        "seek": 135372,
        "start": 1358.28,
        "temperature": 0,
        "text": " You can go and check the community tab and there's a link there with an invite code to join this Mastodon instance",
        "tokens": [
          50592,
          509,
          393,
          352,
          293,
          1520,
          264,
          1768,
          4421,
          293,
          456,
          311,
          257,
          2113,
          456,
          365,
          364,
          7980,
          3089,
          281,
          3917,
          341,
          376,
          525,
          378,
          266,
          5197,
          50944
        ]
      },
      {
        "avg_logprob": -0.42742799457750824,
        "compression_ratio": 1.63003663003663,
        "end": 1366.84,
        "id": 271,
        "no_speech_prob": 0.003376356093212962,
        "seek": 135372,
        "start": 1365.32,
        "temperature": 0,
        "text": " If you're so interested",
        "tokens": [
          50944,
          759,
          291,
          434,
          370,
          3102,
          51020
        ]
      },
      {
        "avg_logprob": -0.42742799457750824,
        "compression_ratio": 1.63003663003663,
        "end": 1369.16,
        "id": 272,
        "no_speech_prob": 0.003376356093212962,
        "seek": 135372,
        "start": 1366.84,
        "temperature": 0,
        "text": " Okay. Thank you everybody for the comments. All right",
        "tokens": [
          51020,
          1033,
          13,
          1044,
          291,
          2201,
          337,
          264,
          3053,
          13,
          1057,
          558,
          51136
        ]
      },
      {
        "avg_logprob": -0.42742799457750824,
        "compression_ratio": 1.63003663003663,
        "end": 1378.04,
        "id": 273,
        "no_speech_prob": 0.003376356093212962,
        "seek": 135372,
        "start": 1372.2,
        "temperature": 0,
        "text": " Okay, so now we're over here this is the join mastodon org website you can find out a lot of information",
        "tokens": [
          51288,
          1033,
          11,
          370,
          586,
          321,
          434,
          670,
          510,
          341,
          307,
          264,
          3917,
          27055,
          378,
          266,
          14045,
          3144,
          291,
          393,
          915,
          484,
          257,
          688,
          295,
          1589,
          51580
        ]
      },
      {
        "avg_logprob": -0.42742799457750824,
        "compression_ratio": 1.63003663003663,
        "end": 1381.4,
        "id": 274,
        "no_speech_prob": 0.003376356093212962,
        "seek": 135372,
        "start": 1378.04,
        "temperature": 0,
        "text": " I would encourage you to click on this how it works. What is it?",
        "tokens": [
          51580,
          286,
          576,
          5373,
          291,
          281,
          2052,
          322,
          341,
          577,
          309,
          1985,
          13,
          708,
          307,
          309,
          30,
          51748
        ]
      },
      {
        "avg_logprob": -0.4596401289397595,
        "compression_ratio": 1.5537848605577689,
        "end": 1384.6000000000001,
        "id": 275,
        "no_speech_prob": 0.02716558240354061,
        "seek": 138140,
        "start": 1381.4,
        "temperature": 0,
        "text": " On video which is on YouTube which will explain all that much better than I did",
        "tokens": [
          50364,
          1282,
          960,
          597,
          307,
          322,
          3088,
          597,
          486,
          2903,
          439,
          300,
          709,
          1101,
          813,
          286,
          630,
          50524
        ]
      },
      {
        "avg_logprob": -0.4596401289397595,
        "compression_ratio": 1.5537848605577689,
        "end": 1388.3600000000001,
        "id": 276,
        "no_speech_prob": 0.02716558240354061,
        "seek": 138140,
        "start": 1385.16,
        "temperature": 0,
        "text": " Get started you can find a different instance that you might like to join",
        "tokens": [
          50552,
          3240,
          1409,
          291,
          393,
          915,
          257,
          819,
          5197,
          300,
          291,
          1062,
          411,
          281,
          3917,
          50712
        ]
      },
      {
        "avg_logprob": -0.4596401289397595,
        "compression_ratio": 1.5537848605577689,
        "end": 1391.8200000000002,
        "id": 277,
        "no_speech_prob": 0.02716558240354061,
        "seek": 138140,
        "start": 1389.3200000000002,
        "temperature": 0,
        "text": " This is the github open source repository",
        "tokens": [
          50760,
          639,
          307,
          264,
          290,
          355,
          836,
          1269,
          4009,
          25841,
          50885
        ]
      },
      {
        "avg_logprob": -0.4596401289397595,
        "compression_ratio": 1.5537848605577689,
        "end": 1395.3200000000002,
        "id": 278,
        "no_speech_prob": 0.02716558240354061,
        "seek": 138140,
        "start": 1392.92,
        "temperature": 0,
        "text": " With with the software that's running now and now",
        "tokens": [
          50940,
          2022,
          365,
          264,
          4722,
          300,
          311,
          2614,
          586,
          293,
          586,
          51060
        ]
      },
      {
        "avg_logprob": -0.4596401289397595,
        "compression_ratio": 1.5537848605577689,
        "end": 1398.92,
        "id": 279,
        "no_speech_prob": 0.02716558240354061,
        "seek": 138140,
        "start": 1396.92,
        "temperature": 0,
        "text": " Here is my instance",
        "tokens": [
          51140,
          1692,
          307,
          452,
          5197,
          51240
        ]
      },
      {
        "avg_logprob": -0.4596401289397595,
        "compression_ratio": 1.5537848605577689,
        "end": 1401.96,
        "id": 280,
        "no_speech_prob": 0.02716558240354061,
        "seek": 138140,
        "start": 1399.96,
        "temperature": 0,
        "text": " The choo-choo",
        "tokens": [
          51292,
          440,
          1586,
          78,
          12,
          339,
          1986,
          51392
        ]
      },
      {
        "avg_logprob": -0.4596401289397595,
        "compression_ratio": 1.5537848605577689,
        "end": 1407.8000000000002,
        "id": 281,
        "no_speech_prob": 0.02716558240354061,
        "seek": 138140,
        "start": 1402.52,
        "temperature": 0,
        "text": " People are notifying me and saying hi and look k weekman says look ma. I'm on the live stream. Okay, excellent",
        "tokens": [
          51420,
          3432,
          366,
          406,
          5489,
          385,
          293,
          1566,
          4879,
          293,
          574,
          350,
          1243,
          1601,
          1619,
          574,
          463,
          13,
          286,
          478,
          322,
          264,
          1621,
          4309,
          13,
          1033,
          11,
          7103,
          51684
        ]
      },
      {
        "avg_logprob": -0.4288492763743681,
        "compression_ratio": 1.676,
        "end": 1411.72,
        "id": 282,
        "no_speech_prob": 0.0006361412233673036,
        "seek": 140780,
        "start": 1407.8,
        "temperature": 0,
        "text": " Please use caution when posting now",
        "tokens": [
          50364,
          2555,
          764,
          23585,
          562,
          15978,
          586,
          50560
        ]
      },
      {
        "avg_logprob": -0.4288492763743681,
        "compression_ratio": 1.676,
        "end": 1414.36,
        "id": 283,
        "no_speech_prob": 0.0006361412233673036,
        "seek": 140780,
        "start": 1412.9199999999998,
        "temperature": 0,
        "text": " So this is what it looks like",
        "tokens": [
          50620,
          407,
          341,
          307,
          437,
          309,
          1542,
          411,
          50692
        ]
      },
      {
        "avg_logprob": -0.4288492763743681,
        "compression_ratio": 1.676,
        "end": 1418.68,
        "id": 284,
        "no_speech_prob": 0.0006361412233673036,
        "seek": 140780,
        "start": 1414.36,
        "temperature": 0,
        "text": " You can see it looks like some other social network service that you might sign up for the difference is",
        "tokens": [
          50692,
          509,
          393,
          536,
          309,
          1542,
          411,
          512,
          661,
          2093,
          3209,
          2643,
          300,
          291,
          1062,
          1465,
          493,
          337,
          264,
          2649,
          307,
          50908
        ]
      },
      {
        "avg_logprob": -0.4288492763743681,
        "compression_ratio": 1.676,
        "end": 1422.76,
        "id": 285,
        "no_speech_prob": 0.0006361412233673036,
        "seek": 140780,
        "start": 1418.9199999999998,
        "temperature": 0,
        "text": " I am actually running the software for it on my own server. This is server",
        "tokens": [
          50920,
          286,
          669,
          767,
          2614,
          264,
          4722,
          337,
          309,
          322,
          452,
          1065,
          7154,
          13,
          639,
          307,
          7154,
          51112
        ]
      },
      {
        "avg_logprob": -0.4288492763743681,
        "compression_ratio": 1.676,
        "end": 1428.04,
        "id": 286,
        "no_speech_prob": 0.0006361412233673036,
        "seek": 140780,
        "start": 1422.76,
        "temperature": 0,
        "text": " I happen to sign up through digital ocean, which is a web hosting company that is not a sponsor, but could be a sponsor",
        "tokens": [
          51112,
          286,
          1051,
          281,
          1465,
          493,
          807,
          4562,
          7810,
          11,
          597,
          307,
          257,
          3670,
          16058,
          2237,
          300,
          307,
          406,
          257,
          16198,
          11,
          457,
          727,
          312,
          257,
          16198,
          51376
        ]
      },
      {
        "avg_logprob": -0.4288492763743681,
        "compression_ratio": 1.676,
        "end": 1430.04,
        "id": 287,
        "no_speech_prob": 0.0006361412233673036,
        "seek": 140780,
        "start": 1428.04,
        "temperature": 0,
        "text": " Hello digital ocean",
        "tokens": [
          51376,
          2425,
          4562,
          7810,
          51476
        ]
      },
      {
        "avg_logprob": -0.4288492763743681,
        "compression_ratio": 1.676,
        "end": 1432.04,
        "id": 288,
        "no_speech_prob": 0.0006361412233673036,
        "seek": 140780,
        "start": 1430.04,
        "temperature": 0,
        "text": " But and you could set up your own",
        "tokens": [
          51476,
          583,
          293,
          291,
          727,
          992,
          493,
          428,
          1065,
          51576
        ]
      },
      {
        "avg_logprob": -0.49655277498306766,
        "compression_ratio": 1.8565891472868217,
        "end": 1437.48,
        "id": 289,
        "no_speech_prob": 0.10373526811599731,
        "seek": 143204,
        "start": 1432.28,
        "temperature": 0,
        "text": " And so what but here's what i'm going to do what you can look at other instances like bots in space",
        "tokens": [
          50376,
          400,
          370,
          437,
          457,
          510,
          311,
          437,
          741,
          478,
          516,
          281,
          360,
          437,
          291,
          393,
          574,
          412,
          661,
          14519,
          411,
          35410,
          294,
          1901,
          50636
        ]
      },
      {
        "avg_logprob": -0.49655277498306766,
        "compression_ratio": 1.8565891472868217,
        "end": 1439.8799999999999,
        "id": 290,
        "no_speech_prob": 0.10373526811599731,
        "seek": 143204,
        "start": 1437.6399999999999,
        "temperature": 0,
        "text": " This is the instance and you could sign up in the next video",
        "tokens": [
          50644,
          639,
          307,
          264,
          5197,
          293,
          291,
          727,
          1465,
          493,
          294,
          264,
          958,
          960,
          50756
        ]
      },
      {
        "avg_logprob": -0.49655277498306766,
        "compression_ratio": 1.8565891472868217,
        "end": 1443.8,
        "id": 291,
        "no_speech_prob": 0.10373526811599731,
        "seek": 143204,
        "start": 1439.8799999999999,
        "temperature": 0,
        "text": " I'm, actually going to sign up for an account here so I can make a bot that posts on it. You can see",
        "tokens": [
          50756,
          286,
          478,
          11,
          767,
          516,
          281,
          1465,
          493,
          337,
          364,
          2696,
          510,
          370,
          286,
          393,
          652,
          257,
          10592,
          300,
          12300,
          322,
          309,
          13,
          509,
          393,
          536,
          50952
        ]
      },
      {
        "avg_logprob": -0.49655277498306766,
        "compression_ratio": 1.8565891472868217,
        "end": 1450.28,
        "id": 292,
        "no_speech_prob": 0.10373526811599731,
        "seek": 143204,
        "start": 1444.6,
        "temperature": 0,
        "text": " Here's some bots already that are posting things the cyber painting bearded mire in the north pole inspired by hubert robert",
        "tokens": [
          50992,
          1692,
          311,
          512,
          35410,
          1217,
          300,
          366,
          15978,
          721,
          264,
          13411,
          5370,
          17455,
          292,
          275,
          621,
          294,
          264,
          6830,
          13208,
          7547,
          538,
          2137,
          4290,
          744,
          4290,
          51276
        ]
      },
      {
        "avg_logprob": -0.49655277498306766,
        "compression_ratio": 1.8565891472868217,
        "end": 1453.8,
        "id": 293,
        "no_speech_prob": 0.10373526811599731,
        "seek": 143204,
        "start": 1451.08,
        "temperature": 0,
        "text": " Okay, the sequel is here get ready for guards to",
        "tokens": [
          51316,
          1033,
          11,
          264,
          20622,
          307,
          510,
          483,
          1919,
          337,
          17652,
          281,
          51452
        ]
      },
      {
        "avg_logprob": -0.49655277498306766,
        "compression_ratio": 1.8565891472868217,
        "end": 1456.36,
        "id": 294,
        "no_speech_prob": 0.10373526811599731,
        "seek": 143204,
        "start": 1454.36,
        "temperature": 0,
        "text": " To the north pole inspired by hubert robert",
        "tokens": [
          51480,
          220,
          13342,
          264,
          6830,
          13208,
          7547,
          538,
          2137,
          4290,
          744,
          4290,
          51580
        ]
      },
      {
        "avg_logprob": -0.8004461148890053,
        "compression_ratio": 1.81640625,
        "end": 1462.12,
        "id": 295,
        "no_speech_prob": 0.09668455272912979,
        "seek": 145636,
        "start": 1457.24,
        "temperature": 0,
        "text": " Okay, so again, these are things that you can do on other services, but mastodon being open source",
        "tokens": [
          50408,
          1033,
          11,
          370,
          797,
          11,
          613,
          366,
          721,
          300,
          291,
          393,
          360,
          322,
          661,
          3328,
          11,
          457,
          27055,
          378,
          266,
          885,
          1269,
          4009,
          50652
        ]
      },
      {
        "avg_logprob": -0.8004461148890053,
        "compression_ratio": 1.81640625,
        "end": 1467.4799999999998,
        "id": 296,
        "no_speech_prob": 0.09668455272912979,
        "seek": 145636,
        "start": 1462.84,
        "temperature": 0,
        "text": " It's a really friendly and easy place to get started with in terms of the api",
        "tokens": [
          50688,
          467,
          311,
          257,
          534,
          9208,
          293,
          1858,
          1081,
          281,
          483,
          1409,
          365,
          294,
          2115,
          295,
          264,
          1882,
          72,
          50920
        ]
      },
      {
        "avg_logprob": -0.8004461148890053,
        "compression_ratio": 1.81640625,
        "end": 1472.84,
        "id": 297,
        "no_speech_prob": 0.09668455272912979,
        "seek": 145636,
        "start": 1467.56,
        "temperature": 0,
        "text": " Which i'm sure will rapidly change and who knows how quickly this video will go out of date, but that's the current",
        "tokens": [
          50924,
          3013,
          741,
          478,
          988,
          486,
          12910,
          1319,
          293,
          567,
          3255,
          577,
          2661,
          341,
          960,
          486,
          352,
          484,
          295,
          4002,
          11,
          457,
          300,
          311,
          264,
          2190,
          51188
        ]
      },
      {
        "avg_logprob": -0.8004461148890053,
        "compression_ratio": 1.81640625,
        "end": 1475.3999999999999,
        "id": 298,
        "no_speech_prob": 0.09668455272912979,
        "seek": 145636,
        "start": 1473.3999999999999,
        "temperature": 0,
        "text": " Spotlight, so let's go ahead and get started",
        "tokens": [
          51216,
          1738,
          310,
          2764,
          11,
          370,
          718,
          311,
          352,
          2286,
          293,
          483,
          1409,
          51316
        ]
      },
      {
        "avg_logprob": -0.8004461148890053,
        "compression_ratio": 1.81640625,
        "end": 1477.8,
        "id": 299,
        "no_speech_prob": 0.09668455272912979,
        "seek": 145636,
        "start": 1475.3999999999999,
        "temperature": 0,
        "text": " So let's go ahead and get started with the first one",
        "tokens": [
          51316,
          407,
          718,
          311,
          352,
          2286,
          293,
          483,
          1409,
          365,
          264,
          700,
          472,
          51436
        ]
      },
      {
        "avg_logprob": -0.8004461148890053,
        "compression_ratio": 1.81640625,
        "end": 1481.6399999999999,
        "id": 300,
        "no_speech_prob": 0.09668455272912979,
        "seek": 145636,
        "start": 1477.8,
        "temperature": 0,
        "text": " So let's go ahead and create a new bot and we're going to create a new bot",
        "tokens": [
          51436,
          407,
          718,
          311,
          352,
          2286,
          293,
          1884,
          257,
          777,
          10592,
          293,
          321,
          434,
          516,
          281,
          1884,
          257,
          777,
          10592,
          51628
        ]
      },
      {
        "avg_logprob": -0.26293824718844505,
        "compression_ratio": 1.7095808383233533,
        "end": 1485.5600000000002,
        "id": 301,
        "no_speech_prob": 0.24793308973312378,
        "seek": 148164,
        "start": 1482.44,
        "temperature": 0.2,
        "text": " And who knows how quickly this video will go out of date, but that's the current",
        "tokens": [
          50404,
          400,
          567,
          3255,
          577,
          2661,
          341,
          960,
          486,
          352,
          484,
          295,
          4002,
          11,
          457,
          300,
          311,
          264,
          2190,
          50560
        ]
      },
      {
        "avg_logprob": -0.26293824718844505,
        "compression_ratio": 1.7095808383233533,
        "end": 1489.64,
        "id": 302,
        "no_speech_prob": 0.24793308973312378,
        "seek": 148164,
        "start": 1485.8000000000002,
        "temperature": 0.2,
        "text": " Uh spot so, um, if you want to sign up for an account before the next video",
        "tokens": [
          50572,
          4019,
          4008,
          370,
          11,
          1105,
          11,
          498,
          291,
          528,
          281,
          1465,
          493,
          337,
          364,
          2696,
          949,
          264,
          958,
          960,
          50764
        ]
      },
      {
        "avg_logprob": -0.26293824718844505,
        "compression_ratio": 1.7095808383233533,
        "end": 1490.92,
        "id": 303,
        "no_speech_prob": 0.24793308973312378,
        "seek": 148164,
        "start": 1489.64,
        "temperature": 0.2,
        "text": " I'm going to do it in the next video",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          360,
          309,
          294,
          264,
          958,
          960,
          50828
        ]
      },
      {
        "avg_logprob": -0.26293824718844505,
        "compression_ratio": 1.7095808383233533,
        "end": 1496.5200000000002,
        "id": 304,
        "no_speech_prob": 0.24793308973312378,
        "seek": 148164,
        "start": 1490.92,
        "temperature": 0.2,
        "text": " I would uh recommend bots in space for a bot account and then you can also go i'm just going to open a new",
        "tokens": [
          50828,
          286,
          576,
          2232,
          2748,
          35410,
          294,
          1901,
          337,
          257,
          10592,
          2696,
          293,
          550,
          291,
          393,
          611,
          352,
          741,
          478,
          445,
          516,
          281,
          1269,
          257,
          777,
          51108
        ]
      },
      {
        "avg_logprob": -0.26293824718844505,
        "compression_ratio": 1.7095808383233533,
        "end": 1501.24,
        "id": 305,
        "no_speech_prob": 0.24793308973312378,
        "seek": 148164,
        "start": 1496.66,
        "temperature": 0.2,
        "text": " Incognito window actually, you know what? I don't have to this is one of the things that I like you can be logged in",
        "tokens": [
          51115,
          7779,
          2912,
          3528,
          4910,
          767,
          11,
          291,
          458,
          437,
          30,
          286,
          500,
          380,
          362,
          281,
          341,
          307,
          472,
          295,
          264,
          721,
          300,
          286,
          411,
          291,
          393,
          312,
          27231,
          294,
          51344
        ]
      },
      {
        "avg_logprob": -0.26293824718844505,
        "compression_ratio": 1.7095808383233533,
        "end": 1504.44,
        "id": 306,
        "no_speech_prob": 0.24793308973312378,
        "seek": 148164,
        "start": 1501.48,
        "temperature": 0.2,
        "text": " Multiple mastodon accounts. So if I go here get started",
        "tokens": [
          51356,
          40056,
          27055,
          378,
          266,
          9402,
          13,
          407,
          498,
          286,
          352,
          510,
          483,
          1409,
          51504
        ]
      },
      {
        "avg_logprob": -0.26293824718844505,
        "compression_ratio": 1.7095808383233533,
        "end": 1510.94,
        "id": 307,
        "no_speech_prob": 0.24793308973312378,
        "seek": 148164,
        "start": 1504.92,
        "temperature": 0.2,
        "text": " Um, i'm gonna you can see here are a whole bunch of servers. So like for example, I am a musician",
        "tokens": [
          51528,
          3301,
          11,
          741,
          478,
          799,
          291,
          393,
          536,
          510,
          366,
          257,
          1379,
          3840,
          295,
          15909,
          13,
          407,
          411,
          337,
          1365,
          11,
          286,
          669,
          257,
          19570,
          51829
        ]
      },
      {
        "avg_logprob": -0.23336673918224515,
        "compression_ratio": 1.6291079812206573,
        "end": 1513.42,
        "id": 308,
        "no_speech_prob": 0.000053908868721919134,
        "seek": 151094,
        "start": 1511.42,
        "temperature": 0,
        "text": " And I speak deutsch",
        "tokens": [
          50388,
          400,
          286,
          1710,
          23004,
          339,
          50488
        ]
      },
      {
        "avg_logprob": -0.23336673918224515,
        "compression_ratio": 1.6291079812206573,
        "end": 1519.9,
        "id": 309,
        "no_speech_prob": 0.000053908868721919134,
        "seek": 151094,
        "start": 1513.5800000000002,
        "temperature": 0,
        "text": " Um, then we can see here are some mastodon instances that I might want to sign up for so let's find one for the coding",
        "tokens": [
          50496,
          3301,
          11,
          550,
          321,
          393,
          536,
          510,
          366,
          512,
          27055,
          378,
          266,
          14519,
          300,
          286,
          1062,
          528,
          281,
          1465,
          493,
          337,
          370,
          718,
          311,
          915,
          472,
          337,
          264,
          17720,
          50812
        ]
      },
      {
        "avg_logprob": -0.23336673918224515,
        "compression_ratio": 1.6291079812206573,
        "end": 1521.98,
        "id": 310,
        "no_speech_prob": 0.000053908868721919134,
        "seek": 151094,
        "start": 1519.98,
        "temperature": 0,
        "text": " train besides choo-choo.space",
        "tokens": [
          50816,
          3847,
          11868,
          1586,
          78,
          12,
          339,
          1986,
          13,
          24824,
          50916
        ]
      },
      {
        "avg_logprob": -0.23336673918224515,
        "compression_ratio": 1.6291079812206573,
        "end": 1524.78,
        "id": 311,
        "no_speech_prob": 0.000053908868721919134,
        "seek": 151094,
        "start": 1522.78,
        "temperature": 0,
        "text": " um, I am a",
        "tokens": [
          50956,
          1105,
          11,
          286,
          669,
          257,
          51056
        ]
      },
      {
        "avg_logprob": -0.23336673918224515,
        "compression_ratio": 1.6291079812206573,
        "end": 1533.18,
        "id": 312,
        "no_speech_prob": 0.000053908868721919134,
        "seek": 151094,
        "start": 1526.38,
        "temperature": 0,
        "text": " A gamer developer. Should we say developer? I don't know. I guess that's the closest. I don't think i'm a developer and I speak english",
        "tokens": [
          51136,
          316,
          30266,
          10754,
          13,
          6454,
          321,
          584,
          10754,
          30,
          286,
          500,
          380,
          458,
          13,
          286,
          2041,
          300,
          311,
          264,
          13699,
          13,
          286,
          500,
          380,
          519,
          741,
          478,
          257,
          10754,
          293,
          286,
          1710,
          32169,
          51476
        ]
      },
      {
        "avg_logprob": -0.23336673918224515,
        "compression_ratio": 1.6291079812206573,
        "end": 1536.22,
        "id": 313,
        "no_speech_prob": 0.000053908868721919134,
        "seek": 151094,
        "start": 1534.22,
        "temperature": 0,
        "text": " And we can see here are some",
        "tokens": [
          51528,
          400,
          321,
          393,
          536,
          510,
          366,
          512,
          51628
        ]
      },
      {
        "avg_logprob": -0.23336673918224515,
        "compression_ratio": 1.6291079812206573,
        "end": 1537.5800000000002,
        "id": 314,
        "no_speech_prob": 0.000053908868721919134,
        "seek": 151094,
        "start": 1536.78,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51656,
          1105,
          51696
        ]
      },
      {
        "avg_logprob": -0.19355929627710458,
        "compression_ratio": 1.5046296296296295,
        "end": 1541.6599999999999,
        "id": 315,
        "no_speech_prob": 0.014954933896660805,
        "seek": 153758,
        "start": 1537.58,
        "temperature": 0,
        "text": " Here are some ones. Let's just cut that whole extra part here because I don't know what is going on",
        "tokens": [
          50364,
          1692,
          366,
          512,
          2306,
          13,
          961,
          311,
          445,
          1723,
          300,
          1379,
          2857,
          644,
          510,
          570,
          286,
          500,
          380,
          458,
          437,
          307,
          516,
          322,
          50568
        ]
      },
      {
        "avg_logprob": -0.19355929627710458,
        "compression_ratio": 1.5046296296296295,
        "end": 1550.22,
        "id": 316,
        "no_speech_prob": 0.014954933896660805,
        "seek": 153758,
        "start": 1544.36,
        "temperature": 0,
        "text": " Okay, thank you very much. Um, let me",
        "tokens": [
          50703,
          1033,
          11,
          1309,
          291,
          588,
          709,
          13,
          3301,
          11,
          718,
          385,
          50996
        ]
      },
      {
        "avg_logprob": -0.19355929627710458,
        "compression_ratio": 1.5046296296296295,
        "end": 1558.54,
        "id": 317,
        "no_speech_prob": 0.014954933896660805,
        "seek": 153758,
        "start": 1553.26,
        "temperature": 0,
        "text": " So if you want to sign up for a mastodon account not on choo-choo.space or um",
        "tokens": [
          51148,
          407,
          498,
          291,
          528,
          281,
          1465,
          493,
          337,
          257,
          27055,
          378,
          266,
          2696,
          406,
          322,
          1586,
          78,
          12,
          339,
          1986,
          13,
          24824,
          420,
          1105,
          51412
        ]
      },
      {
        "avg_logprob": -0.19355929627710458,
        "compression_ratio": 1.5046296296296295,
        "end": 1561.8999999999999,
        "id": 318,
        "no_speech_prob": 0.014954933896660805,
        "seek": 153758,
        "start": 1559.82,
        "temperature": 0,
        "text": " Or bots in space a new one for yourself",
        "tokens": [
          51476,
          1610,
          35410,
          294,
          1901,
          257,
          777,
          472,
          337,
          1803,
          51580
        ]
      },
      {
        "avg_logprob": -0.19355929627710458,
        "compression_ratio": 1.5046296296296295,
        "end": 1565.58,
        "id": 319,
        "no_speech_prob": 0.014954933896660805,
        "seek": 153758,
        "start": 1561.8999999999999,
        "temperature": 0,
        "text": " You can come you can go to join mastodon.org and you can go look here",
        "tokens": [
          51580,
          509,
          393,
          808,
          291,
          393,
          352,
          281,
          3917,
          27055,
          378,
          266,
          13,
          4646,
          293,
          291,
          393,
          352,
          574,
          510,
          51764
        ]
      },
      {
        "avg_logprob": -0.22707745311706046,
        "compression_ratio": 1.6891891891891893,
        "end": 1572.22,
        "id": 320,
        "no_speech_prob": 0.006192710716277361,
        "seek": 156558,
        "start": 1565.98,
        "temperature": 0,
        "text": " You can look for something like oh, you're an artist. Yes, and you speak, uh, english. Oh viz.social",
        "tokens": [
          50384,
          509,
          393,
          574,
          337,
          746,
          411,
          1954,
          11,
          291,
          434,
          364,
          5748,
          13,
          1079,
          11,
          293,
          291,
          1710,
          11,
          2232,
          11,
          32169,
          13,
          876,
          371,
          590,
          13,
          48600,
          50696
        ]
      },
      {
        "avg_logprob": -0.22707745311706046,
        "compression_ratio": 1.6891891891891893,
        "end": 1575.74,
        "id": 321,
        "no_speech_prob": 0.006192710716277361,
        "seek": 156558,
        "start": 1572.22,
        "temperature": 0,
        "text": " There we go a social space for anyone in data visualization creative coding, etc",
        "tokens": [
          50696,
          821,
          321,
          352,
          257,
          2093,
          1901,
          337,
          2878,
          294,
          1412,
          25801,
          5880,
          17720,
          11,
          5183,
          50872
        ]
      },
      {
        "avg_logprob": -0.22707745311706046,
        "compression_ratio": 1.6891891891891893,
        "end": 1578.9399999999998,
        "id": 322,
        "no_speech_prob": 0.006192710716277361,
        "seek": 156558,
        "start": 1575.98,
        "temperature": 0,
        "text": " And now we can see this is viz.social and you could sign up here",
        "tokens": [
          50884,
          400,
          586,
          321,
          393,
          536,
          341,
          307,
          371,
          590,
          13,
          48600,
          293,
          291,
          727,
          1465,
          493,
          510,
          51032
        ]
      },
      {
        "avg_logprob": -0.22707745311706046,
        "compression_ratio": 1.6891891891891893,
        "end": 1581.6599999999999,
        "id": 323,
        "no_speech_prob": 0.006192710716277361,
        "seek": 156558,
        "start": 1579.1,
        "temperature": 0,
        "text": " Now once again, even if you sign up at a certain instance",
        "tokens": [
          51040,
          823,
          1564,
          797,
          11,
          754,
          498,
          291,
          1465,
          493,
          412,
          257,
          1629,
          5197,
          51168
        ]
      },
      {
        "avg_logprob": -0.22707745311706046,
        "compression_ratio": 1.6891891891891893,
        "end": 1585.4199999999998,
        "id": 324,
        "no_speech_prob": 0.006192710716277361,
        "seek": 156558,
        "start": 1582.22,
        "temperature": 0,
        "text": " That's just your name and address and your local instance",
        "tokens": [
          51196,
          663,
          311,
          445,
          428,
          1315,
          293,
          2985,
          293,
          428,
          2654,
          5197,
          51356
        ]
      },
      {
        "avg_logprob": -0.22707745311706046,
        "compression_ratio": 1.6891891891891893,
        "end": 1592.86,
        "id": 325,
        "no_speech_prob": 0.006192710716277361,
        "seek": 156558,
        "start": 1585.4199999999998,
        "temperature": 0,
        "text": " But through federation through activity pub through decentralization you are still participating in the broader world. That is a mastodon",
        "tokens": [
          51356,
          583,
          807,
          4636,
          5053,
          807,
          5191,
          1535,
          807,
          26515,
          2144,
          291,
          366,
          920,
          13950,
          294,
          264,
          13227,
          1002,
          13,
          663,
          307,
          257,
          27055,
          378,
          266,
          51728
        ]
      },
      {
        "avg_logprob": -0.2291673853777457,
        "compression_ratio": 1.8295081967213114,
        "end": 1598.6999999999998,
        "id": 326,
        "no_speech_prob": 0.000022125139366835356,
        "seek": 159286,
        "start": 1592.86,
        "temperature": 0,
        "text": " Okay, so what's going to happen next in the next video? I am going to sign up for a bots in space account",
        "tokens": [
          50364,
          1033,
          11,
          370,
          437,
          311,
          516,
          281,
          1051,
          958,
          294,
          264,
          958,
          960,
          30,
          286,
          669,
          516,
          281,
          1465,
          493,
          337,
          257,
          35410,
          294,
          1901,
          2696,
          50656
        ]
      },
      {
        "avg_logprob": -0.2291673853777457,
        "compression_ratio": 1.8295081967213114,
        "end": 1600.78,
        "id": 327,
        "no_speech_prob": 0.000022125139366835356,
        "seek": 159286,
        "start": 1598.86,
        "temperature": 0,
        "text": " I'm going to show you how to get your api keys",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          855,
          291,
          577,
          281,
          483,
          428,
          1882,
          72,
          9317,
          50760
        ]
      },
      {
        "avg_logprob": -0.2291673853777457,
        "compression_ratio": 1.8295081967213114,
        "end": 1606.62,
        "id": 328,
        "no_speech_prob": 0.000022125139366835356,
        "seek": 159286,
        "start": 1600.78,
        "temperature": 0,
        "text": " I'm going to write a little node program that posts that toots to it automatically and and then i'm going to show you lots more",
        "tokens": [
          50760,
          286,
          478,
          516,
          281,
          2464,
          257,
          707,
          9984,
          1461,
          300,
          12300,
          300,
          281,
          1971,
          281,
          309,
          6772,
          293,
          293,
          550,
          741,
          478,
          516,
          281,
          855,
          291,
          3195,
          544,
          51052
        ]
      },
      {
        "avg_logprob": -0.2291673853777457,
        "compression_ratio": 1.8295081967213114,
        "end": 1612.4599999999998,
        "id": 329,
        "no_speech_prob": 0.000022125139366835356,
        "seek": 159286,
        "start": 1606.86,
        "temperature": 0,
        "text": " Ways and things and how the api works and different ways to post images and replies and favorite things and all that kind of stuff",
        "tokens": [
          51064,
          343,
          3772,
          293,
          721,
          293,
          577,
          264,
          1882,
          72,
          1985,
          293,
          819,
          2098,
          281,
          2183,
          5267,
          293,
          42289,
          293,
          2954,
          721,
          293,
          439,
          300,
          733,
          295,
          1507,
          51344
        ]
      },
      {
        "avg_logprob": -0.2291673853777457,
        "compression_ratio": 1.8295081967213114,
        "end": 1619.1799999999998,
        "id": 330,
        "no_speech_prob": 0.000022125139366835356,
        "seek": 159286,
        "start": 1612.54,
        "temperature": 0,
        "text": " Okay, so, uh, I hope you enjoyed this exploration of the open source project mastodon and I look forward to hearing what you think in the comments",
        "tokens": [
          51348,
          1033,
          11,
          370,
          11,
          2232,
          11,
          286,
          1454,
          291,
          4626,
          341,
          16197,
          295,
          264,
          1269,
          4009,
          1716,
          27055,
          378,
          266,
          293,
          286,
          574,
          2128,
          281,
          4763,
          437,
          291,
          519,
          294,
          264,
          3053,
          51680
        ]
      },
      {
        "avg_logprob": -0.281817303428167,
        "compression_ratio": 1.548913043478261,
        "end": 1621.66,
        "id": 331,
        "no_speech_prob": 0.00020662743190769106,
        "seek": 161918,
        "start": 1619.66,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50388,
          3301,
          50488
        ]
      },
      {
        "avg_logprob": -0.281817303428167,
        "compression_ratio": 1.548913043478261,
        "end": 1628.94,
        "id": 332,
        "no_speech_prob": 0.00020662743190769106,
        "seek": 161918,
        "start": 1623.66,
        "temperature": 0,
        "text": " Amr is writing his hair is darker than I remember. Is it my hair? I got a haircut. Nobody noticed my haircut",
        "tokens": [
          50588,
          2012,
          81,
          307,
          3579,
          702,
          2578,
          307,
          12741,
          813,
          286,
          1604,
          13,
          1119,
          309,
          452,
          2578,
          30,
          286,
          658,
          257,
          30328,
          13,
          9297,
          5694,
          452,
          30328,
          50852
        ]
      },
      {
        "avg_logprob": -0.281817303428167,
        "compression_ratio": 1.548913043478261,
        "end": 1631.66,
        "id": 333,
        "no_speech_prob": 0.00020662743190769106,
        "seek": 161918,
        "start": 1629.42,
        "temperature": 0,
        "text": " I went to a very nice barber shop over the weekend",
        "tokens": [
          50876,
          286,
          1437,
          281,
          257,
          588,
          1481,
          49906,
          3945,
          670,
          264,
          6711,
          50988
        ]
      },
      {
        "avg_logprob": -0.281817303428167,
        "compression_ratio": 1.548913043478261,
        "end": 1634.78,
        "id": 334,
        "no_speech_prob": 0.00020662743190769106,
        "seek": 161918,
        "start": 1632.78,
        "temperature": 0,
        "text": " in uh prospect heights brooklyn",
        "tokens": [
          51044,
          294,
          2232,
          15005,
          25930,
          2006,
          453,
          9896,
          51144
        ]
      },
      {
        "avg_logprob": -0.281817303428167,
        "compression_ratio": 1.548913043478261,
        "end": 1639.3400000000001,
        "id": 335,
        "no_speech_prob": 0.00020662743190769106,
        "seek": 161918,
        "start": 1635.74,
        "temperature": 0,
        "text": " And I had a lovely experience with a lovely barber",
        "tokens": [
          51192,
          400,
          286,
          632,
          257,
          7496,
          1752,
          365,
          257,
          7496,
          49906,
          51372
        ]
      },
      {
        "avg_logprob": -0.281817303428167,
        "compression_ratio": 1.548913043478261,
        "end": 1643.18,
        "id": 336,
        "no_speech_prob": 0.00020662743190769106,
        "seek": 161918,
        "start": 1640.78,
        "temperature": 0,
        "text": " Uh talked my ear off my ear is still on",
        "tokens": [
          51444,
          4019,
          2825,
          452,
          1273,
          766,
          452,
          1273,
          307,
          920,
          322,
          51564
        ]
      },
      {
        "avg_logprob": -0.29301995701260036,
        "compression_ratio": 1.391304347826087,
        "end": 1645.18,
        "id": 337,
        "no_speech_prob": 0.0003740864631254226,
        "seek": 164318,
        "start": 1643.18,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50364,
          3301,
          50464
        ]
      },
      {
        "avg_logprob": -0.29301995701260036,
        "compression_ratio": 1.391304347826087,
        "end": 1653.28,
        "id": 338,
        "no_speech_prob": 0.0003740864631254226,
        "seek": 164318,
        "start": 1647.26,
        "temperature": 0,
        "text": " It was very nice, okay, um any questions",
        "tokens": [
          50568,
          467,
          390,
          588,
          1481,
          11,
          1392,
          11,
          1105,
          604,
          1651,
          50869
        ]
      },
      {
        "avg_logprob": -0.29301995701260036,
        "compression_ratio": 1.391304347826087,
        "end": 1658.38,
        "id": 339,
        "no_speech_prob": 0.0003740864631254226,
        "seek": 164318,
        "start": 1656.7,
        "temperature": 0,
        "text": " Uh",
        "tokens": [
          51040,
          4019,
          51124
        ]
      },
      {
        "avg_logprob": -0.29301995701260036,
        "compression_ratio": 1.391304347826087,
        "end": 1662.48,
        "id": 340,
        "no_speech_prob": 0.0003740864631254226,
        "seek": 164318,
        "start": 1658.38,
        "temperature": 0,
        "text": " Did that like for those of you who have never heard of mastodon or decentralization",
        "tokens": [
          51124,
          2589,
          300,
          411,
          337,
          729,
          295,
          291,
          567,
          362,
          1128,
          2198,
          295,
          27055,
          378,
          266,
          420,
          26515,
          2144,
          51329
        ]
      },
      {
        "avg_logprob": -0.29301995701260036,
        "compression_ratio": 1.391304347826087,
        "end": 1666.94,
        "id": 341,
        "no_speech_prob": 0.0003740864631254226,
        "seek": 164318,
        "start": 1663.5800000000002,
        "temperature": 0,
        "text": " Before today, did you get something from that? Was that helpful? Interesting?",
        "tokens": [
          51384,
          4546,
          965,
          11,
          630,
          291,
          483,
          746,
          490,
          300,
          30,
          3027,
          300,
          4961,
          30,
          14711,
          30,
          51552
        ]
      },
      {
        "avg_logprob": -0.29301995701260036,
        "compression_ratio": 1.391304347826087,
        "end": 1670.3,
        "id": 342,
        "no_speech_prob": 0.0003740864631254226,
        "seek": 164318,
        "start": 1667.74,
        "temperature": 0,
        "text": " Useful. I can't believe this hasn't crashed yet",
        "tokens": [
          51592,
          8278,
          906,
          13,
          286,
          393,
          380,
          1697,
          341,
          6132,
          380,
          24190,
          1939,
          51720
        ]
      },
      {
        "avg_logprob": -0.2056538203977189,
        "compression_ratio": 1.3969465648854962,
        "end": 1676.22,
        "id": 343,
        "no_speech_prob": 0.00007484506204491481,
        "seek": 167030,
        "start": 1671.02,
        "temperature": 0,
        "text": " I almost want it to crash because I want to just I feel like it's just on the edge of crashing all the time",
        "tokens": [
          50400,
          286,
          1920,
          528,
          309,
          281,
          8252,
          570,
          286,
          528,
          281,
          445,
          286,
          841,
          411,
          309,
          311,
          445,
          322,
          264,
          4691,
          295,
          26900,
          439,
          264,
          565,
          50660
        ]
      },
      {
        "avg_logprob": -0.2056538203977189,
        "compression_ratio": 1.3969465648854962,
        "end": 1680.62,
        "id": 344,
        "no_speech_prob": 0.00007484506204491481,
        "seek": 167030,
        "start": 1678.62,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50780,
          1033,
          50880
        ]
      },
      {
        "avg_logprob": -0.2056538203977189,
        "compression_ratio": 1.3969465648854962,
        "end": 1688.86,
        "id": 345,
        "no_speech_prob": 0.00007484506204491481,
        "seek": 167030,
        "start": 1683.8999999999999,
        "temperature": 0,
        "text": " All right, so let me let me get set up here",
        "tokens": [
          51044,
          1057,
          558,
          11,
          370,
          718,
          385,
          718,
          385,
          483,
          992,
          493,
          510,
          51292
        ]
      },
      {
        "avg_logprob": -0.2056538203977189,
        "compression_ratio": 1.3969465648854962,
        "end": 1695.04,
        "id": 346,
        "no_speech_prob": 0.00007484506204491481,
        "seek": 167030,
        "start": 1692.22,
        "temperature": 0,
        "text": " For the next piece of this",
        "tokens": [
          51460,
          1171,
          264,
          958,
          2522,
          295,
          341,
          51601
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1702.78,
        "id": 347,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1700.78,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50388,
          286,
          50488
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1705.5,
        "id": 348,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1703.02,
        "temperature": 0,
        "text": " Have a lot more space I could work with here. Yeah",
        "tokens": [
          50500,
          3560,
          257,
          688,
          544,
          1901,
          286,
          727,
          589,
          365,
          510,
          13,
          865,
          50624
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1709.82,
        "id": 349,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1706.62,
        "temperature": 0,
        "text": " Um, so we're gonna go to choo choo dot space",
        "tokens": [
          50680,
          3301,
          11,
          370,
          321,
          434,
          799,
          352,
          281,
          1586,
          78,
          1586,
          78,
          5893,
          1901,
          50840
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1712.86,
        "id": 350,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1710.94,
        "temperature": 0,
        "text": " and bots",
        "tokens": [
          50896,
          293,
          35410,
          50992
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1714.86,
        "id": 351,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1712.86,
        "temperature": 0,
        "text": " bots in dot space",
        "tokens": [
          50992,
          35410,
          294,
          5893,
          1901,
          51092
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1719.58,
        "id": 352,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1716.62,
        "temperature": 0,
        "text": " I think I can close these things out",
        "tokens": [
          51180,
          286,
          519,
          286,
          393,
          1998,
          613,
          721,
          484,
          51328
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1724.06,
        "id": 353,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1722.54,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51476,
          3301,
          51552
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1726.06,
        "id": 354,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1724.06,
        "temperature": 0,
        "text": " Make that a little bit bigger",
        "tokens": [
          51552,
          4387,
          300,
          257,
          707,
          857,
          3801,
          51652
        ]
      },
      {
        "avg_logprob": -0.2124142517914643,
        "compression_ratio": 1.5664335664335665,
        "end": 1728.62,
        "id": 355,
        "no_speech_prob": 0.0007793058175593615,
        "seek": 170030,
        "start": 1726.54,
        "temperature": 0,
        "text": " Make this a little bit bigger",
        "tokens": [
          51676,
          4387,
          341,
          257,
          707,
          857,
          3801,
          51780
        ]
      },
      {
        "avg_logprob": -0.3451593138954856,
        "compression_ratio": 1.1944444444444444,
        "end": 1731.9799999999998,
        "id": 356,
        "no_speech_prob": 0.00018522322352509946,
        "seek": 172862,
        "start": 1729.5,
        "temperature": 0,
        "text": " A little local timeline. There we go. Okay",
        "tokens": [
          50408,
          316,
          707,
          2654,
          12933,
          13,
          821,
          321,
          352,
          13,
          1033,
          50532
        ]
      },
      {
        "avg_logprob": -0.3451593138954856,
        "compression_ratio": 1.1944444444444444,
        "end": 1737.26,
        "id": 357,
        "no_speech_prob": 0.00018522322352509946,
        "seek": 172862,
        "start": 1735.26,
        "temperature": 0,
        "text": " Um, okay",
        "tokens": [
          50696,
          3301,
          11,
          1392,
          50796
        ]
      },
      {
        "avg_logprob": -0.3451593138954856,
        "compression_ratio": 1.1944444444444444,
        "end": 1745.4399999999998,
        "id": 358,
        "no_speech_prob": 0.00018522322352509946,
        "seek": 172862,
        "start": 1738.9399999999998,
        "temperature": 0,
        "text": " All right, um, I think I am ready now to get started",
        "tokens": [
          50880,
          1057,
          558,
          11,
          1105,
          11,
          286,
          519,
          286,
          669,
          1919,
          586,
          281,
          483,
          1409,
          51205
        ]
      },
      {
        "avg_logprob": -0.3451593138954856,
        "compression_ratio": 1.1944444444444444,
        "end": 1757.1999999999998,
        "id": 359,
        "no_speech_prob": 0.00018522322352509946,
        "seek": 172862,
        "start": 1754.3799999999999,
        "temperature": 0,
        "text": " Oh, I need to have iterm",
        "tokens": [
          51652,
          876,
          11,
          286,
          643,
          281,
          362,
          309,
          966,
          51793
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1761.5,
        "id": 360,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1759.5,
        "temperature": 0,
        "text": " And let's go to",
        "tokens": [
          50408,
          400,
          718,
          311,
          352,
          281,
          50508
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1765.4199999999998,
        "id": 361,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1763.4199999999998,
        "temperature": 0,
        "text": " Uh",
        "tokens": [
          50604,
          4019,
          50704
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1770.1399999999999,
        "id": 362,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1765.9799999999998,
        "temperature": 0,
        "text": " Desktop make directory mastodon bot",
        "tokens": [
          50732,
          49044,
          652,
          21120,
          27055,
          378,
          266,
          10592,
          50940
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1774.3,
        "id": 363,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1772.62,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51064,
          1033,
          51148
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1776.78,
        "id": 364,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1774.3,
        "temperature": 0,
        "text": " Oh another new member. This is so nice of all of you",
        "tokens": [
          51148,
          876,
          1071,
          777,
          4006,
          13,
          639,
          307,
          370,
          1481,
          295,
          439,
          295,
          291,
          51272
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1779.3999999999999,
        "id": 365,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1777.7399999999998,
        "temperature": 0,
        "text": " uh",
        "tokens": [
          51320,
          2232,
          51403
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1780.6999999999998,
        "id": 366,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1779.3999999999999,
        "temperature": 0,
        "text": " Andras Yirmati",
        "tokens": [
          51403,
          400,
          3906,
          398,
          3692,
          6908,
          51468
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1783.7399999999998,
        "id": 367,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1780.6999999999998,
        "temperature": 0,
        "text": " Where are you from? I wonder Andras. Thank you for joining. Okay",
        "tokens": [
          51468,
          2305,
          366,
          291,
          490,
          30,
          286,
          2441,
          400,
          3906,
          13,
          1044,
          291,
          337,
          5549,
          13,
          1033,
          51620
        ]
      },
      {
        "avg_logprob": -0.32321901321411134,
        "compression_ratio": 1.36,
        "end": 1787.8999999999999,
        "id": 368,
        "no_speech_prob": 0.0005192855023778975,
        "seek": 175862,
        "start": 1785.02,
        "temperature": 0,
        "text": " So, um, so let me just for the live stream",
        "tokens": [
          51684,
          407,
          11,
          1105,
          11,
          370,
          718,
          385,
          445,
          337,
          264,
          1621,
          4309,
          51828
        ]
      },
      {
        "avg_logprob": -0.19472554433260034,
        "compression_ratio": 1.79,
        "end": 1793.8999999999999,
        "id": 369,
        "no_speech_prob": 0.00014425766130443662,
        "seek": 178862,
        "start": 1788.9399999999998,
        "temperature": 0,
        "text": " If you for anybody who's watching right now, if you go to choo choo dot space",
        "tokens": [
          50380,
          759,
          291,
          337,
          4472,
          567,
          311,
          1976,
          558,
          586,
          11,
          498,
          291,
          352,
          281,
          1586,
          78,
          1586,
          78,
          5893,
          1901,
          50628
        ]
      },
      {
        "avg_logprob": -0.19472554433260034,
        "compression_ratio": 1.79,
        "end": 1796.54,
        "id": 370,
        "no_speech_prob": 0.00014425766130443662,
        "seek": 178862,
        "start": 1794.54,
        "temperature": 0,
        "text": " Um, you're going to see this message",
        "tokens": [
          50660,
          3301,
          11,
          291,
          434,
          516,
          281,
          536,
          341,
          3636,
          50760
        ]
      },
      {
        "avg_logprob": -0.19472554433260034,
        "compression_ratio": 1.79,
        "end": 1801.34,
        "id": 371,
        "no_speech_prob": 0.00014425766130443662,
        "seek": 178862,
        "start": 1796.62,
        "temperature": 0,
        "text": " Sign up on another server registrations are reserved for coding train youtube members and patrons",
        "tokens": [
          50764,
          13515,
          493,
          322,
          1071,
          7154,
          11376,
          12154,
          366,
          24819,
          337,
          17720,
          3847,
          12487,
          2679,
          293,
          27559,
          51000
        ]
      },
      {
        "avg_logprob": -0.19472554433260034,
        "compression_ratio": 1.79,
        "end": 1804.4599999999998,
        "id": 372,
        "no_speech_prob": 0.00014425766130443662,
        "seek": 178862,
        "start": 1801.58,
        "temperature": 0,
        "text": " I'm doing this not because I want to have a closed thing",
        "tokens": [
          51012,
          286,
          478,
          884,
          341,
          406,
          570,
          286,
          528,
          281,
          362,
          257,
          5395,
          551,
          51156
        ]
      },
      {
        "avg_logprob": -0.19472554433260034,
        "compression_ratio": 1.79,
        "end": 1807.4199999999998,
        "id": 373,
        "no_speech_prob": 0.00014425766130443662,
        "seek": 178862,
        "start": 1804.4599999999998,
        "temperature": 0,
        "text": " I mean might make sense for this to be a member benefits. I don't know",
        "tokens": [
          51156,
          286,
          914,
          1062,
          652,
          2020,
          337,
          341,
          281,
          312,
          257,
          4006,
          5311,
          13,
          286,
          500,
          380,
          458,
          51304
        ]
      },
      {
        "avg_logprob": -0.19472554433260034,
        "compression_ratio": 1.79,
        "end": 1812.54,
        "id": 374,
        "no_speech_prob": 0.00014425766130443662,
        "seek": 178862,
        "start": 1807.8999999999999,
        "temperature": 0,
        "text": " Um, mostly i'm doing this because I just set the instance up and again, it's on a digital ocean server",
        "tokens": [
          51328,
          3301,
          11,
          5240,
          741,
          478,
          884,
          341,
          570,
          286,
          445,
          992,
          264,
          5197,
          493,
          293,
          797,
          11,
          309,
          311,
          322,
          257,
          4562,
          7810,
          7154,
          51560
        ]
      },
      {
        "avg_logprob": -0.19472554433260034,
        "compression_ratio": 1.79,
        "end": 1816.2199999999998,
        "id": 375,
        "no_speech_prob": 0.00014425766130443662,
        "seek": 178862,
        "start": 1812.62,
        "temperature": 0,
        "text": " I just picked a droplet. I didn't pick the five dollar a month. I picked a ten dollar a month",
        "tokens": [
          51564,
          286,
          445,
          6183,
          257,
          3789,
          14657,
          13,
          286,
          994,
          380,
          1888,
          264,
          1732,
          7241,
          257,
          1618,
          13,
          286,
          6183,
          257,
          2064,
          7241,
          257,
          1618,
          51744
        ]
      },
      {
        "avg_logprob": -0.2053385361381199,
        "compression_ratio": 1.6083916083916083,
        "end": 1818.54,
        "id": 376,
        "no_speech_prob": 0.00031013970146887004,
        "seek": 181622,
        "start": 1816.54,
        "temperature": 0,
        "text": " To give me a little bit more juice",
        "tokens": [
          50380,
          1407,
          976,
          385,
          257,
          707,
          857,
          544,
          8544,
          50480
        ]
      },
      {
        "avg_logprob": -0.2053385361381199,
        "compression_ratio": 1.6083916083916083,
        "end": 1823.1000000000001,
        "id": 377,
        "no_speech_prob": 0.00031013970146887004,
        "seek": 181622,
        "start": 1818.94,
        "temperature": 0,
        "text": " Um, but I I just i'm not sure about the sustainability of this and what's going to cost",
        "tokens": [
          50500,
          3301,
          11,
          457,
          286,
          286,
          445,
          741,
          478,
          406,
          988,
          466,
          264,
          16360,
          295,
          341,
          293,
          437,
          311,
          516,
          281,
          2063,
          50708
        ]
      },
      {
        "avg_logprob": -0.2053385361381199,
        "compression_ratio": 1.6083916083916083,
        "end": 1828.8,
        "id": 378,
        "no_speech_prob": 0.00031013970146887004,
        "seek": 181622,
        "start": 1823.26,
        "temperature": 0,
        "text": " So at the moment you can you can certainly participate and communicate on mastodon through the fact that it's decentralized",
        "tokens": [
          50716,
          407,
          412,
          264,
          1623,
          291,
          393,
          291,
          393,
          3297,
          8197,
          293,
          7890,
          322,
          27055,
          378,
          266,
          807,
          264,
          1186,
          300,
          309,
          311,
          32870,
          50993
        ]
      },
      {
        "avg_logprob": -0.2053385361381199,
        "compression_ratio": 1.6083916083916083,
        "end": 1832.38,
        "id": 379,
        "no_speech_prob": 0.00031013970146887004,
        "seek": 181622,
        "start": 1828.94,
        "temperature": 0,
        "text": " But you'll want to sign up with a personal account somewhere else or join",
        "tokens": [
          51000,
          583,
          291,
          603,
          528,
          281,
          1465,
          493,
          365,
          257,
          2973,
          2696,
          4079,
          1646,
          420,
          3917,
          51172
        ]
      },
      {
        "avg_logprob": -0.2053385361381199,
        "compression_ratio": 1.6083916083916083,
        "end": 1837.5,
        "id": 380,
        "no_speech_prob": 0.00031013970146887004,
        "seek": 181622,
        "start": 1833.1000000000001,
        "temperature": 0,
        "text": " The youtube channel, um, and then you'll get an invite code and maybe i'll open this up later",
        "tokens": [
          51208,
          440,
          12487,
          2269,
          11,
          1105,
          11,
          293,
          550,
          291,
          603,
          483,
          364,
          7980,
          3089,
          293,
          1310,
          741,
          603,
          1269,
          341,
          493,
          1780,
          51428
        ]
      },
      {
        "avg_logprob": -0.2053385361381199,
        "compression_ratio": 1.6083916083916083,
        "end": 1841.42,
        "id": 381,
        "no_speech_prob": 0.00031013970146887004,
        "seek": 181622,
        "start": 1837.9,
        "temperature": 0,
        "text": " Um as well as and look we got 22 users so far",
        "tokens": [
          51448,
          3301,
          382,
          731,
          382,
          293,
          574,
          321,
          658,
          5853,
          5022,
          370,
          1400,
          51624
        ]
      },
      {
        "avg_logprob": -0.23612631351575938,
        "compression_ratio": 1.691699604743083,
        "end": 1846.78,
        "id": 382,
        "no_speech_prob": 0.005219982471317053,
        "seek": 184142,
        "start": 1841.9,
        "temperature": 0,
        "text": " And then as well as bots in space which is open it's currently an open one",
        "tokens": [
          50388,
          400,
          550,
          382,
          731,
          382,
          35410,
          294,
          1901,
          597,
          307,
          1269,
          309,
          311,
          4362,
          364,
          1269,
          472,
          50632
        ]
      },
      {
        "avg_logprob": -0.23612631351575938,
        "compression_ratio": 1.691699604743083,
        "end": 1850.3000000000002,
        "id": 383,
        "no_speech_prob": 0.005219982471317053,
        "seek": 184142,
        "start": 1846.94,
        "temperature": 0,
        "text": " You'll notice that the main one mastodon.social for example",
        "tokens": [
          50640,
          509,
          603,
          3449,
          300,
          264,
          2135,
          472,
          27055,
          378,
          266,
          13,
          48600,
          337,
          1365,
          50808
        ]
      },
      {
        "avg_logprob": -0.23612631351575938,
        "compression_ratio": 1.691699604743083,
        "end": 1857.02,
        "id": 384,
        "no_speech_prob": 0.005219982471317053,
        "seek": 184142,
        "start": 1850.8400000000001,
        "temperature": 0,
        "text": " Also is registration on the server are currently closed due to high demand. Please sign up on mastodon.cloud instead",
        "tokens": [
          50835,
          2743,
          307,
          16847,
          322,
          264,
          7154,
          366,
          4362,
          5395,
          3462,
          281,
          1090,
          4733,
          13,
          2555,
          1465,
          493,
          322,
          27055,
          378,
          266,
          13,
          44495,
          2602,
          51144
        ]
      },
      {
        "avg_logprob": -0.23612631351575938,
        "compression_ratio": 1.691699604743083,
        "end": 1860.22,
        "id": 385,
        "no_speech_prob": 0.005219982471317053,
        "seek": 184142,
        "start": 1857.42,
        "temperature": 0,
        "text": " So I don't know, you know, I think that um",
        "tokens": [
          51164,
          407,
          286,
          500,
          380,
          458,
          11,
          291,
          458,
          11,
          286,
          519,
          300,
          1105,
          51304
        ]
      },
      {
        "avg_logprob": -0.23612631351575938,
        "compression_ratio": 1.691699604743083,
        "end": 1867.42,
        "id": 386,
        "no_speech_prob": 0.005219982471317053,
        "seek": 184142,
        "start": 1861.74,
        "temperature": 0,
        "text": " I think it's what I like about mastodon is that there are these, you know instances these little subgroups within the larger universe",
        "tokens": [
          51380,
          286,
          519,
          309,
          311,
          437,
          286,
          411,
          466,
          27055,
          378,
          266,
          307,
          300,
          456,
          366,
          613,
          11,
          291,
          458,
          14519,
          613,
          707,
          1422,
          17377,
          82,
          1951,
          264,
          4833,
          6445,
          51664
        ]
      },
      {
        "avg_logprob": -0.23012252165892413,
        "compression_ratio": 1.6300813008130082,
        "end": 1872.46,
        "id": 387,
        "no_speech_prob": 0.00012147962115705013,
        "seek": 186742,
        "start": 1867.5800000000002,
        "temperature": 0,
        "text": " So affinity groups maybe in a way so I do like the idea of opening up the choo-choo dot space",
        "tokens": [
          50372,
          407,
          39703,
          3935,
          1310,
          294,
          257,
          636,
          370,
          286,
          360,
          411,
          264,
          1558,
          295,
          5193,
          493,
          264,
          1586,
          78,
          12,
          339,
          1986,
          5893,
          1901,
          50616
        ]
      },
      {
        "avg_logprob": -0.23012252165892413,
        "compression_ratio": 1.6300813008130082,
        "end": 1877.74,
        "id": 388,
        "no_speech_prob": 0.00012147962115705013,
        "seek": 186742,
        "start": 1872.7,
        "temperature": 0,
        "text": " But also you might find one that's you know, maybe uh coding train is not your sole purpose in life",
        "tokens": [
          50628,
          583,
          611,
          291,
          1062,
          915,
          472,
          300,
          311,
          291,
          458,
          11,
          1310,
          2232,
          17720,
          3847,
          307,
          406,
          428,
          12321,
          4334,
          294,
          993,
          50880
        ]
      },
      {
        "avg_logprob": -0.23012252165892413,
        "compression_ratio": 1.6300813008130082,
        "end": 1881.9,
        "id": 389,
        "no_speech_prob": 0.00012147962115705013,
        "seek": 186742,
        "start": 1878.78,
        "temperature": 0,
        "text": " And you might find a different space that's well suited to you. Okay",
        "tokens": [
          50932,
          400,
          291,
          1062,
          915,
          257,
          819,
          1901,
          300,
          311,
          731,
          24736,
          281,
          291,
          13,
          1033,
          51088
        ]
      },
      {
        "avg_logprob": -0.23012252165892413,
        "compression_ratio": 1.6300813008130082,
        "end": 1886.22,
        "id": 390,
        "no_speech_prob": 0.00012147962115705013,
        "seek": 186742,
        "start": 1882.7,
        "temperature": 0,
        "text": " Which isn't to say that's joining the anyway, okay",
        "tokens": [
          51128,
          3013,
          1943,
          380,
          281,
          584,
          300,
          311,
          5549,
          264,
          4033,
          11,
          1392,
          51304
        ]
      },
      {
        "avg_logprob": -0.23012252165892413,
        "compression_ratio": 1.6300813008130082,
        "end": 1888.46,
        "id": 391,
        "no_speech_prob": 0.00012147962115705013,
        "seek": 186742,
        "start": 1887.26,
        "temperature": 0,
        "text": " All right",
        "tokens": [
          51356,
          1057,
          558,
          51416
        ]
      },
      {
        "avg_logprob": -0.23012252165892413,
        "compression_ratio": 1.6300813008130082,
        "end": 1892.14,
        "id": 392,
        "no_speech_prob": 0.00012147962115705013,
        "seek": 186742,
        "start": 1888.46,
        "temperature": 0,
        "text": " Okay, people are really sending me crazy stuff right now",
        "tokens": [
          51416,
          1033,
          11,
          561,
          366,
          534,
          7750,
          385,
          3219,
          1507,
          558,
          586,
          51600
        ]
      },
      {
        "avg_logprob": -0.23012252165892413,
        "compression_ratio": 1.6300813008130082,
        "end": 1895.26,
        "id": 393,
        "no_speech_prob": 0.00012147962115705013,
        "seek": 186742,
        "start": 1893.26,
        "temperature": 0,
        "text": " How did you do that?",
        "tokens": [
          51656,
          1012,
          630,
          291,
          360,
          300,
          30,
          51756
        ]
      },
      {
        "avg_logprob": -0.19979023933410645,
        "compression_ratio": 1.570048309178744,
        "end": 1901.66,
        "id": 394,
        "no_speech_prob": 0.00041083843098022044,
        "seek": 189742,
        "start": 1897.9,
        "temperature": 0,
        "text": " All right, this is really funny what's going on, uh so far I don't mind",
        "tokens": [
          50388,
          1057,
          558,
          11,
          341,
          307,
          534,
          4074,
          437,
          311,
          516,
          322,
          11,
          2232,
          370,
          1400,
          286,
          500,
          380,
          1575,
          50576
        ]
      },
      {
        "avg_logprob": -0.19979023933410645,
        "compression_ratio": 1.570048309178744,
        "end": 1909.3400000000001,
        "id": 395,
        "no_speech_prob": 0.00041083843098022044,
        "seek": 189742,
        "start": 1903.18,
        "temperature": 0,
        "text": " No, I don't mind this at all. In fact, I'd rather enjoy it, but please use discretion don't try to don't ruin my video",
        "tokens": [
          50652,
          883,
          11,
          286,
          500,
          380,
          1575,
          341,
          412,
          439,
          13,
          682,
          1186,
          11,
          286,
          1116,
          2831,
          2103,
          309,
          11,
          457,
          1767,
          764,
          30140,
          500,
          380,
          853,
          281,
          500,
          380,
          15514,
          452,
          960,
          50960
        ]
      },
      {
        "avg_logprob": -0.19979023933410645,
        "compression_ratio": 1.570048309178744,
        "end": 1912.3000000000002,
        "id": 396,
        "no_speech_prob": 0.00041083843098022044,
        "seek": 189742,
        "start": 1910.46,
        "temperature": 0,
        "text": " with nonsense, okay",
        "tokens": [
          51016,
          365,
          14925,
          11,
          1392,
          51108
        ]
      },
      {
        "avg_logprob": -0.19979023933410645,
        "compression_ratio": 1.570048309178744,
        "end": 1914.3000000000002,
        "id": 397,
        "no_speech_prob": 0.00041083843098022044,
        "seek": 189742,
        "start": 1912.3000000000002,
        "temperature": 0,
        "text": " um, all right, so",
        "tokens": [
          51108,
          1105,
          11,
          439,
          558,
          11,
          370,
          51208
        ]
      },
      {
        "avg_logprob": -0.19979023933410645,
        "compression_ratio": 1.570048309178744,
        "end": 1916.78,
        "id": 398,
        "no_speech_prob": 0.00041083843098022044,
        "seek": 189742,
        "start": 1914.78,
        "temperature": 0,
        "text": " Hi, thank you marius for your nice",
        "tokens": [
          51232,
          2421,
          11,
          1309,
          291,
          1849,
          4872,
          337,
          428,
          1481,
          51332
        ]
      },
      {
        "avg_logprob": -0.19979023933410645,
        "compression_ratio": 1.570048309178744,
        "end": 1920.22,
        "id": 399,
        "no_speech_prob": 0.00041083843098022044,
        "seek": 189742,
        "start": 1918.22,
        "temperature": 0,
        "text": " Uh comment, okay",
        "tokens": [
          51404,
          4019,
          2871,
          11,
          1392,
          51504
        ]
      },
      {
        "avg_logprob": -0.19979023933410645,
        "compression_ratio": 1.570048309178744,
        "end": 1923.98,
        "id": 400,
        "no_speech_prob": 0.00041083843098022044,
        "seek": 189742,
        "start": 1921.02,
        "temperature": 0,
        "text": " Um, so i'm back here i'm gonna go here, okay",
        "tokens": [
          51544,
          3301,
          11,
          370,
          741,
          478,
          646,
          510,
          741,
          478,
          799,
          352,
          510,
          11,
          1392,
          51692
        ]
      },
      {
        "avg_logprob": -0.195294341525516,
        "compression_ratio": 1.4911242603550297,
        "end": 1926.94,
        "id": 401,
        "no_speech_prob": 0.00012730996240861714,
        "seek": 192398,
        "start": 1924.94,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50412,
          1033,
          50512
        ]
      },
      {
        "avg_logprob": -0.195294341525516,
        "compression_ratio": 1.4911242603550297,
        "end": 1934.22,
        "id": 402,
        "no_speech_prob": 0.00012730996240861714,
        "seek": 192398,
        "start": 1927.26,
        "temperature": 0,
        "text": " Okay, we're back for another mastodon video and in this video i'm going to sign up for a bots in dot space account",
        "tokens": [
          50528,
          1033,
          11,
          321,
          434,
          646,
          337,
          1071,
          27055,
          378,
          266,
          960,
          293,
          294,
          341,
          960,
          741,
          478,
          516,
          281,
          1465,
          493,
          337,
          257,
          35410,
          294,
          5893,
          1901,
          2696,
          50876
        ]
      },
      {
        "avg_logprob": -0.195294341525516,
        "compression_ratio": 1.4911242603550297,
        "end": 1940.6200000000001,
        "id": 403,
        "no_speech_prob": 0.00012730996240861714,
        "seek": 192398,
        "start": 1934.94,
        "temperature": 0,
        "text": " Bots in space. I feel like I need some space music. Hold on. This is going to be totally worth it",
        "tokens": [
          50912,
          47224,
          294,
          1901,
          13,
          286,
          841,
          411,
          286,
          643,
          512,
          1901,
          1318,
          13,
          6962,
          322,
          13,
          639,
          307,
          516,
          281,
          312,
          3879,
          3163,
          309,
          51196
        ]
      },
      {
        "avg_logprob": -0.195294341525516,
        "compression_ratio": 1.4911242603550297,
        "end": 1945.5,
        "id": 404,
        "no_speech_prob": 0.00012730996240861714,
        "seek": 192398,
        "start": 1943.5,
        "temperature": 0,
        "text": " Oh, yeah, this is pretty good",
        "tokens": [
          51340,
          876,
          11,
          1338,
          11,
          341,
          307,
          1238,
          665,
          51440
        ]
      },
      {
        "avg_logprob": -0.195294341525516,
        "compression_ratio": 1.4911242603550297,
        "end": 1950.22,
        "id": 405,
        "no_speech_prob": 0.00012730996240861714,
        "seek": 192398,
        "start": 1948.22,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51576,
          1033,
          51676
        ]
      },
      {
        "avg_logprob": -0.8095674420347309,
        "compression_ratio": 1.7551020408163265,
        "end": 1952.38,
        "id": 406,
        "no_speech_prob": 0.0005441983230412006,
        "seek": 195022,
        "start": 1950.38,
        "temperature": 0,
        "text": " Okay, now I can really hear that",
        "tokens": [
          50372,
          1033,
          11,
          586,
          286,
          393,
          534,
          1568,
          300,
          50472
        ]
      },
      {
        "avg_logprob": -0.8095674420347309,
        "compression_ratio": 1.7551020408163265,
        "end": 1956.38,
        "id": 407,
        "no_speech_prob": 0.0005441983230412006,
        "seek": 195022,
        "start": 1954.38,
        "temperature": 0,
        "text": " And crazy feedback",
        "tokens": [
          50572,
          400,
          3219,
          5824,
          50672
        ]
      },
      {
        "avg_logprob": -0.8095674420347309,
        "compression_ratio": 1.7551020408163265,
        "end": 1962.94,
        "id": 408,
        "no_speech_prob": 0.0005441983230412006,
        "seek": 195022,
        "start": 1958.38,
        "temperature": 0,
        "text": " Well, hold on you know, I need to do is I need to mute this, okay, there we go. All right. Sorry everybody",
        "tokens": [
          50772,
          1042,
          11,
          1797,
          322,
          291,
          458,
          11,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          24523,
          341,
          11,
          1392,
          11,
          456,
          321,
          352,
          13,
          1057,
          558,
          13,
          4919,
          2201,
          51000
        ]
      },
      {
        "avg_logprob": -0.8095674420347309,
        "compression_ratio": 1.7551020408163265,
        "end": 1967.74,
        "id": 409,
        "no_speech_prob": 0.0005441983230412006,
        "seek": 195022,
        "start": 1965.74,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51140,
          1033,
          51240
        ]
      },
      {
        "avg_logprob": -0.8095674420347309,
        "compression_ratio": 1.7551020408163265,
        "end": 1972.3,
        "id": 410,
        "no_speech_prob": 0.0005441983230412006,
        "seek": 195022,
        "start": 1967.74,
        "temperature": 0,
        "text": " Hello, welcome to the second mastodon video in the first video. I'm going to be doing a video on",
        "tokens": [
          51240,
          2425,
          11,
          2928,
          281,
          264,
          1150,
          27055,
          378,
          266,
          960,
          294,
          264,
          700,
          960,
          13,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          960,
          322,
          51468
        ]
      },
      {
        "avg_logprob": -0.8095674420347309,
        "compression_ratio": 1.7551020408163265,
        "end": 1976.14,
        "id": 411,
        "no_speech_prob": 0.0005441983230412006,
        "seek": 195022,
        "start": 1972.94,
        "temperature": 0,
        "text": " The first mastodon video. I'm going to be doing a video on the first mastodon video",
        "tokens": [
          51500,
          440,
          700,
          27055,
          378,
          266,
          960,
          13,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          960,
          322,
          264,
          700,
          27055,
          378,
          266,
          960,
          51660
        ]
      },
      {
        "avg_logprob": -0.25420556169875125,
        "compression_ratio": 1.6175115207373272,
        "end": 1977.3400000000001,
        "id": 412,
        "no_speech_prob": 0.0015976588474586606,
        "seek": 197614,
        "start": 1976.22,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50368,
          1033,
          50424
        ]
      },
      {
        "avg_logprob": -0.25420556169875125,
        "compression_ratio": 1.6175115207373272,
        "end": 1980.38,
        "id": 413,
        "no_speech_prob": 0.0015976588474586606,
        "seek": 197614,
        "start": 1977.3400000000001,
        "temperature": 0,
        "text": " Hello, welcome to the second mastodon video in the first video",
        "tokens": [
          50424,
          2425,
          11,
          2928,
          281,
          264,
          1150,
          27055,
          378,
          266,
          960,
          294,
          264,
          700,
          960,
          50576
        ]
      },
      {
        "avg_logprob": -0.25420556169875125,
        "compression_ratio": 1.6175115207373272,
        "end": 1984.16,
        "id": 414,
        "no_speech_prob": 0.0015976588474586606,
        "seek": 197614,
        "start": 1980.38,
        "temperature": 0,
        "text": " I talked a bit about what mastodon is or at least my impressions of it the idea of decentralization",
        "tokens": [
          50576,
          286,
          2825,
          257,
          857,
          466,
          437,
          27055,
          378,
          266,
          307,
          420,
          412,
          1935,
          452,
          24245,
          295,
          309,
          264,
          1558,
          295,
          26515,
          2144,
          50765
        ]
      },
      {
        "avg_logprob": -0.25420556169875125,
        "compression_ratio": 1.6175115207373272,
        "end": 1990.72,
        "id": 415,
        "no_speech_prob": 0.0015976588474586606,
        "seek": 197614,
        "start": 1984.7800000000002,
        "temperature": 0,
        "text": " And in this video the reason why i'm doing this is I want to find a platform to write crazy weird experimental avant-garde",
        "tokens": [
          50796,
          400,
          294,
          341,
          960,
          264,
          1778,
          983,
          741,
          478,
          884,
          341,
          307,
          286,
          528,
          281,
          915,
          257,
          3663,
          281,
          2464,
          3219,
          3657,
          17069,
          13439,
          12,
          70,
          10866,
          51093
        ]
      },
      {
        "avg_logprob": -0.25420556169875125,
        "compression_ratio": 1.6175115207373272,
        "end": 1993.18,
        "id": 416,
        "no_speech_prob": 0.0015976588474586606,
        "seek": 197614,
        "start": 1991.74,
        "temperature": 0,
        "text": " art bots",
        "tokens": [
          51144,
          1523,
          35410,
          51216
        ]
      },
      {
        "avg_logprob": -0.25420556169875125,
        "compression_ratio": 1.6175115207373272,
        "end": 1995.3600000000001,
        "id": 417,
        "no_speech_prob": 0.0015976588474586606,
        "seek": 197614,
        "start": 1993.18,
        "temperature": 0,
        "text": " And so i'm going to use this platform",
        "tokens": [
          51216,
          400,
          370,
          741,
          478,
          516,
          281,
          764,
          341,
          3663,
          51325
        ]
      },
      {
        "avg_logprob": -0.25420556169875125,
        "compression_ratio": 1.6175115207373272,
        "end": 1998.8600000000001,
        "id": 418,
        "no_speech_prob": 0.0015976588474586606,
        "seek": 197614,
        "start": 1996.8600000000001,
        "temperature": 0,
        "text": " Bots in space",
        "tokens": [
          51400,
          47224,
          294,
          1901,
          51500
        ]
      },
      {
        "avg_logprob": -0.2974031589649342,
        "compression_ratio": 1.7257383966244726,
        "end": 2001.34,
        "id": 419,
        "no_speech_prob": 0.0017544723814353347,
        "seek": 199886,
        "start": 1999.34,
        "temperature": 0,
        "text": " It",
        "tokens": [
          50388,
          467,
          50488
        ]
      },
      {
        "avg_logprob": -0.2974031589649342,
        "compression_ratio": 1.7257383966244726,
        "end": 2007.1,
        "id": 420,
        "no_speech_prob": 0.0017544723814353347,
        "seek": 199886,
        "start": 2001.6599999999999,
        "temperature": 0,
        "text": " Sounds that this was going to you know, this idea seemed better when I thought of playing this music and didn't really turn out",
        "tokens": [
          50504,
          14576,
          300,
          341,
          390,
          516,
          281,
          291,
          458,
          11,
          341,
          1558,
          6576,
          1101,
          562,
          286,
          1194,
          295,
          2433,
          341,
          1318,
          293,
          994,
          380,
          534,
          1261,
          484,
          50776
        ]
      },
      {
        "avg_logprob": -0.2974031589649342,
        "compression_ratio": 1.7257383966244726,
        "end": 2011.74,
        "id": 421,
        "no_speech_prob": 0.0017544723814353347,
        "seek": 199886,
        "start": 2007.1,
        "temperature": 0,
        "text": " But so the first thing i'm going to want to do is sign up for an account here with bots in space",
        "tokens": [
          50776,
          583,
          370,
          264,
          700,
          551,
          741,
          478,
          516,
          281,
          528,
          281,
          360,
          307,
          1465,
          493,
          337,
          364,
          2696,
          510,
          365,
          35410,
          294,
          1901,
          51008
        ]
      },
      {
        "avg_logprob": -0.2974031589649342,
        "compression_ratio": 1.7257383966244726,
        "end": 2016.06,
        "id": 422,
        "no_speech_prob": 0.0017544723814353347,
        "seek": 199886,
        "start": 2012.06,
        "temperature": 0,
        "text": " and i'm going to say um sign up with uh",
        "tokens": [
          51024,
          293,
          741,
          478,
          516,
          281,
          584,
          1105,
          1465,
          493,
          365,
          2232,
          51224
        ]
      },
      {
        "avg_logprob": -0.2974031589649342,
        "compression_ratio": 1.7257383966244726,
        "end": 2018.6999999999998,
        "id": 423,
        "no_speech_prob": 0.0017544723814353347,
        "seek": 199886,
        "start": 2016.6999999999998,
        "temperature": 0,
        "text": " coding train bot",
        "tokens": [
          51256,
          17720,
          3847,
          10592,
          51356
        ]
      },
      {
        "avg_logprob": -0.2974031589649342,
        "compression_ratio": 1.7257383966244726,
        "end": 2022.2199999999998,
        "id": 424,
        "no_speech_prob": 0.0017544723814353347,
        "seek": 199886,
        "start": 2018.86,
        "temperature": 0,
        "text": " And I am going to use the email address daniel at the coding",
        "tokens": [
          51364,
          400,
          286,
          669,
          516,
          281,
          764,
          264,
          3796,
          2985,
          3277,
          1187,
          412,
          264,
          17720,
          51532
        ]
      },
      {
        "avg_logprob": -0.2974031589649342,
        "compression_ratio": 1.7257383966244726,
        "end": 2027.34,
        "id": 425,
        "no_speech_prob": 0.0017544723814353347,
        "seek": 199886,
        "start": 2023.5,
        "temperature": 0,
        "text": " Train.com i'm going to use the password. Ooh suggested password",
        "tokens": [
          51596,
          28029,
          13,
          1112,
          741,
          478,
          516,
          281,
          764,
          264,
          11524,
          13,
          7951,
          10945,
          11524,
          51788
        ]
      },
      {
        "avg_logprob": -0.20010846853256226,
        "compression_ratio": 1.641350210970464,
        "end": 2031.34,
        "id": 426,
        "no_speech_prob": 0.0006263158866204321,
        "seek": 202734,
        "start": 2027.34,
        "temperature": 0,
        "text": " I don't think I should use this because then you will all see it. I'm going to use the password",
        "tokens": [
          50364,
          286,
          500,
          380,
          519,
          286,
          820,
          764,
          341,
          570,
          550,
          291,
          486,
          439,
          536,
          309,
          13,
          286,
          478,
          516,
          281,
          764,
          264,
          11524,
          50564
        ]
      },
      {
        "avg_logprob": -0.20010846853256226,
        "compression_ratio": 1.641350210970464,
        "end": 2034.56,
        "id": 427,
        "no_speech_prob": 0.0006263158866204321,
        "seek": 202734,
        "start": 2031.98,
        "temperature": 0,
        "text": " I love blueberries are heart heart rainbow",
        "tokens": [
          50596,
          286,
          959,
          43722,
          366,
          1917,
          1917,
          18526,
          50725
        ]
      },
      {
        "avg_logprob": -0.20010846853256226,
        "compression_ratio": 1.641350210970464,
        "end": 2042.1399999999999,
        "id": 428,
        "no_speech_prob": 0.0006263158866204321,
        "seek": 202734,
        "start": 2039.26,
        "temperature": 0,
        "text": " Sure, you'll all be able to guess my password really easily",
        "tokens": [
          50960,
          4894,
          11,
          291,
          603,
          439,
          312,
          1075,
          281,
          2041,
          452,
          11524,
          534,
          3612,
          51104
        ]
      },
      {
        "avg_logprob": -0.20010846853256226,
        "compression_ratio": 1.641350210970464,
        "end": 2048.7799999999997,
        "id": 429,
        "no_speech_prob": 0.0006263158866204321,
        "seek": 202734,
        "start": 2042.6999999999998,
        "temperature": 0,
        "text": " Um, what is what do you what is this nonsense go away a message with confirmation link has been sent to your email address",
        "tokens": [
          51132,
          3301,
          11,
          437,
          307,
          437,
          360,
          291,
          437,
          307,
          341,
          14925,
          352,
          1314,
          257,
          3636,
          365,
          21871,
          2113,
          575,
          668,
          2279,
          281,
          428,
          3796,
          2985,
          51436
        ]
      },
      {
        "avg_logprob": -0.20010846853256226,
        "compression_ratio": 1.641350210970464,
        "end": 2051.2599999999998,
        "id": 430,
        "no_speech_prob": 0.0006263158866204321,
        "seek": 202734,
        "start": 2049.2599999999998,
        "temperature": 0,
        "text": " Hold on a second",
        "tokens": [
          51460,
          6962,
          322,
          257,
          1150,
          51560
        ]
      },
      {
        "avg_logprob": -0.20010846853256226,
        "compression_ratio": 1.641350210970464,
        "end": 2055.1,
        "id": 431,
        "no_speech_prob": 0.0006263158866204321,
        "seek": 202734,
        "start": 2051.5,
        "temperature": 0,
        "text": " Talk amongst yourselves. I am now going to attempt",
        "tokens": [
          51572,
          8780,
          12918,
          14791,
          13,
          286,
          669,
          586,
          516,
          281,
          5217,
          51752
        ]
      },
      {
        "avg_logprob": -0.27194088476675526,
        "compression_ratio": 1.361344537815126,
        "end": 2057.98,
        "id": 432,
        "no_speech_prob": 0.00020342353673186153,
        "seek": 205510,
        "start": 2055.98,
        "temperature": 0,
        "text": " To uh",
        "tokens": [
          50408,
          1407,
          2232,
          50508
        ]
      },
      {
        "avg_logprob": -0.27194088476675526,
        "compression_ratio": 1.361344537815126,
        "end": 2064.16,
        "id": 433,
        "no_speech_prob": 0.00020342353673186153,
        "seek": 205510,
        "start": 2061.66,
        "temperature": 0,
        "text": " I didn't get an email. Is it in my spam?",
        "tokens": [
          50692,
          286,
          994,
          380,
          483,
          364,
          3796,
          13,
          1119,
          309,
          294,
          452,
          24028,
          30,
          50817
        ]
      },
      {
        "avg_logprob": -0.27194088476675526,
        "compression_ratio": 1.361344537815126,
        "end": 2074.7999999999997,
        "id": 434,
        "no_speech_prob": 0.00020342353673186153,
        "seek": 205510,
        "start": 2068.54,
        "temperature": 0,
        "text": " It's not in my spam. Well, I did get some private messages from some nice people in my spam",
        "tokens": [
          51036,
          467,
          311,
          406,
          294,
          452,
          24028,
          13,
          1042,
          11,
          286,
          630,
          483,
          512,
          4551,
          7897,
          490,
          512,
          1481,
          561,
          294,
          452,
          24028,
          51349
        ]
      },
      {
        "avg_logprob": -0.27194088476675526,
        "compression_ratio": 1.361344537815126,
        "end": 2079.74,
        "id": 435,
        "no_speech_prob": 0.00020342353673186153,
        "seek": 205510,
        "start": 2077.74,
        "temperature": 0,
        "text": " Oh, this is such a fail",
        "tokens": [
          51496,
          876,
          11,
          341,
          307,
          1270,
          257,
          3061,
          51596
        ]
      },
      {
        "avg_logprob": -0.2701489804971098,
        "compression_ratio": 1.705607476635514,
        "end": 2082.8599999999997,
        "id": 436,
        "no_speech_prob": 0.0001881410862552002,
        "seek": 207974,
        "start": 2080.3799999999997,
        "temperature": 0,
        "text": " Ah, okay, oh it came through",
        "tokens": [
          50396,
          2438,
          11,
          1392,
          11,
          1954,
          309,
          1361,
          807,
          50520
        ]
      },
      {
        "avg_logprob": -0.2701489804971098,
        "compression_ratio": 1.705607476635514,
        "end": 2091.02,
        "id": 437,
        "no_speech_prob": 0.0001881410862552002,
        "seek": 207974,
        "start": 2083.5,
        "temperature": 0,
        "text": " So my confirmation came through and that's who you can edit this stuff out. I guess verify email address. Ah, my email address has been verified",
        "tokens": [
          50552,
          407,
          452,
          21871,
          1361,
          807,
          293,
          300,
          311,
          567,
          291,
          393,
          8129,
          341,
          1507,
          484,
          13,
          286,
          2041,
          16888,
          3796,
          2985,
          13,
          2438,
          11,
          452,
          3796,
          2985,
          575,
          668,
          31197,
          50928
        ]
      },
      {
        "avg_logprob": -0.2701489804971098,
        "compression_ratio": 1.705607476635514,
        "end": 2096.22,
        "id": 438,
        "no_speech_prob": 0.0001881410862552002,
        "seek": 207974,
        "start": 2091.8199999999997,
        "temperature": 0,
        "text": " Okay, I got the email. I verified my email address. I should be able to log in now",
        "tokens": [
          50968,
          1033,
          11,
          286,
          658,
          264,
          3796,
          13,
          286,
          31197,
          452,
          3796,
          2985,
          13,
          286,
          820,
          312,
          1075,
          281,
          3565,
          294,
          586,
          51188
        ]
      },
      {
        "avg_logprob": -0.2701489804971098,
        "compression_ratio": 1.705607476635514,
        "end": 2098.9399999999996,
        "id": 439,
        "no_speech_prob": 0.0001881410862552002,
        "seek": 207974,
        "start": 2096.9399999999996,
        "temperature": 0,
        "text": " coding",
        "tokens": [
          51224,
          17720,
          51324
        ]
      },
      {
        "avg_logprob": -0.2701489804971098,
        "compression_ratio": 1.705607476635514,
        "end": 2103.74,
        "id": 440,
        "no_speech_prob": 0.0001881410862552002,
        "seek": 207974,
        "start": 2099.5,
        "temperature": 0,
        "text": " Train bot if I could remember what my password is",
        "tokens": [
          51352,
          28029,
          10592,
          498,
          286,
          727,
          1604,
          437,
          452,
          11524,
          307,
          51564
        ]
      },
      {
        "avg_logprob": -0.2701489804971098,
        "compression_ratio": 1.705607476635514,
        "end": 2109.3399999999997,
        "id": 441,
        "no_speech_prob": 0.0001881410862552002,
        "seek": 207974,
        "start": 2106.14,
        "temperature": 0,
        "text": " I'll log in. Oh, no, that's that's not the password",
        "tokens": [
          51684,
          286,
          603,
          3565,
          294,
          13,
          876,
          11,
          572,
          11,
          300,
          311,
          300,
          311,
          406,
          264,
          11524,
          51844
        ]
      },
      {
        "avg_logprob": -0.2868255782913376,
        "compression_ratio": 1.5226130653266332,
        "end": 2112.8599999999997,
        "id": 442,
        "no_speech_prob": 0.00007967223791638389,
        "seek": 210974,
        "start": 2110.62,
        "temperature": 0,
        "text": " Oh, no, wait. Oh, I have to use my email",
        "tokens": [
          50408,
          876,
          11,
          572,
          11,
          1699,
          13,
          876,
          11,
          286,
          362,
          281,
          764,
          452,
          3796,
          50520
        ]
      },
      {
        "avg_logprob": -0.2868255782913376,
        "compression_ratio": 1.5226130653266332,
        "end": 2119.9799999999996,
        "id": 443,
        "no_speech_prob": 0.00007967223791638389,
        "seek": 210974,
        "start": 2113.8999999999996,
        "temperature": 0,
        "text": " Daniel oh great. Thanks for showing all my emails here. Oh auto fill whatever. Okay. Hold on",
        "tokens": [
          50572,
          8033,
          1954,
          869,
          13,
          2561,
          337,
          4099,
          439,
          452,
          12524,
          510,
          13,
          876,
          8399,
          2836,
          2035,
          13,
          1033,
          13,
          6962,
          322,
          50876
        ]
      },
      {
        "avg_logprob": -0.2868255782913376,
        "compression_ratio": 1.5226130653266332,
        "end": 2129.9799999999996,
        "id": 444,
        "no_speech_prob": 0.00007967223791638389,
        "seek": 210974,
        "start": 2127.9799999999996,
        "temperature": 0,
        "text": " Okay, so I click the uh",
        "tokens": [
          51276,
          1033,
          11,
          370,
          286,
          2052,
          264,
          2232,
          51376
        ]
      },
      {
        "avg_logprob": -0.2868255782913376,
        "compression_ratio": 1.5226130653266332,
        "end": 2133.8999999999996,
        "id": 445,
        "no_speech_prob": 0.00007967223791638389,
        "seek": 210974,
        "start": 2130.54,
        "temperature": 0,
        "text": " Verify my email. I have now put in my username and password",
        "tokens": [
          51404,
          4281,
          2505,
          452,
          3796,
          13,
          286,
          362,
          586,
          829,
          294,
          452,
          30351,
          293,
          11524,
          51572
        ]
      },
      {
        "avg_logprob": -0.2868255782913376,
        "compression_ratio": 1.5226130653266332,
        "end": 2139.1,
        "id": 446,
        "no_speech_prob": 0.00007967223791638389,
        "seek": 210974,
        "start": 2134.14,
        "temperature": 0,
        "text": " I'm gonna click log in and now welcome to mastodon. I'm gonna save this just why not?",
        "tokens": [
          51584,
          286,
          478,
          799,
          2052,
          3565,
          294,
          293,
          586,
          2928,
          281,
          27055,
          378,
          266,
          13,
          286,
          478,
          799,
          3155,
          341,
          445,
          983,
          406,
          30,
          51832
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2143.58,
        "id": 447,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2139.42,
        "temperature": 0,
        "text": " Um, this is my full handle at coding train bot at bots in space",
        "tokens": [
          50380,
          3301,
          11,
          341,
          307,
          452,
          1577,
          4813,
          412,
          17720,
          3847,
          10592,
          412,
          35410,
          294,
          1901,
          50588
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2146.86,
        "id": 448,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2144.14,
        "temperature": 0,
        "text": " Um, i'm not gonna skip through this little tutorial here",
        "tokens": [
          50616,
          3301,
          11,
          741,
          478,
          406,
          799,
          10023,
          807,
          341,
          707,
          7073,
          510,
          50752
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2150.2999999999997,
        "id": 449,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2147.02,
        "temperature": 0,
        "text": " But first thing i'm gonna do very important is i'm gonna go to edit profile",
        "tokens": [
          50760,
          583,
          700,
          551,
          741,
          478,
          799,
          360,
          588,
          1021,
          307,
          741,
          478,
          799,
          352,
          281,
          8129,
          7964,
          50924
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2153.1,
        "id": 450,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2150.86,
        "temperature": 0,
        "text": " And i'm just gonna go down here. I would want to put other stuff here",
        "tokens": [
          50952,
          400,
          741,
          478,
          445,
          799,
          352,
          760,
          510,
          13,
          286,
          576,
          528,
          281,
          829,
          661,
          1507,
          510,
          51064
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2155.9,
        "id": 451,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2153.1,
        "temperature": 0,
        "text": " And maybe i'll do that eventually but I want to go here and I want to click",
        "tokens": [
          51064,
          400,
          1310,
          741,
          603,
          360,
          300,
          4728,
          457,
          286,
          528,
          281,
          352,
          510,
          293,
          286,
          528,
          281,
          2052,
          51204
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2160.14,
        "id": 452,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2156.22,
        "temperature": 0,
        "text": " This is a bot account because uh, one of the nice things about mastodon",
        "tokens": [
          51220,
          639,
          307,
          257,
          10592,
          2696,
          570,
          2232,
          11,
          472,
          295,
          264,
          1481,
          721,
          466,
          27055,
          378,
          266,
          51416
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2164.14,
        "id": 453,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2160.22,
        "temperature": 0,
        "text": " It has a feature for you to indicate that a particular account is a bot which is you know",
        "tokens": [
          51420,
          467,
          575,
          257,
          4111,
          337,
          291,
          281,
          13330,
          300,
          257,
          1729,
          2696,
          307,
          257,
          10592,
          597,
          307,
          291,
          458,
          51616
        ]
      },
      {
        "avg_logprob": -0.20800549167019505,
        "compression_ratio": 1.750788643533123,
        "end": 2167.04,
        "id": 454,
        "no_speech_prob": 0.00030061413417570293,
        "seek": 213910,
        "start": 2164.2999999999997,
        "temperature": 0,
        "text": " A really nice thing to do in terms of transparency",
        "tokens": [
          51624,
          316,
          534,
          1481,
          551,
          281,
          360,
          294,
          2115,
          295,
          17131,
          51761
        ]
      },
      {
        "avg_logprob": -0.2140976267123441,
        "compression_ratio": 1.8868778280542986,
        "end": 2171.68,
        "id": 455,
        "no_speech_prob": 0.00012148098176112399,
        "seek": 216704,
        "start": 2167.84,
        "temperature": 0,
        "text": " Okay, the other thing that I want to do is I want to go down under development",
        "tokens": [
          50404,
          1033,
          11,
          264,
          661,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          352,
          760,
          833,
          3250,
          50596
        ]
      },
      {
        "avg_logprob": -0.2140976267123441,
        "compression_ratio": 1.8868778280542986,
        "end": 2175.84,
        "id": 456,
        "no_speech_prob": 0.00012148098176112399,
        "seek": 216704,
        "start": 2171.68,
        "temperature": 0,
        "text": " So i'm gonna hit save changes right down here in the bottom. There's a little option under development",
        "tokens": [
          50596,
          407,
          741,
          478,
          799,
          2045,
          3155,
          2962,
          558,
          760,
          510,
          294,
          264,
          2767,
          13,
          821,
          311,
          257,
          707,
          3614,
          833,
          3250,
          50804
        ]
      },
      {
        "avg_logprob": -0.2140976267123441,
        "compression_ratio": 1.8868778280542986,
        "end": 2179.06,
        "id": 457,
        "no_speech_prob": 0.00012148098176112399,
        "seek": 216704,
        "start": 2175.92,
        "temperature": 0,
        "text": " I'm going to want to click that and I want to create a new application",
        "tokens": [
          50808,
          286,
          478,
          516,
          281,
          528,
          281,
          2052,
          300,
          293,
          286,
          528,
          281,
          1884,
          257,
          777,
          3861,
          50965
        ]
      },
      {
        "avg_logprob": -0.2140976267123441,
        "compression_ratio": 1.8868778280542986,
        "end": 2183.44,
        "id": 458,
        "no_speech_prob": 0.00012148098176112399,
        "seek": 216704,
        "start": 2179.6,
        "temperature": 0,
        "text": " So i'm going to create a new application. It is coding train example bot",
        "tokens": [
          50992,
          407,
          741,
          478,
          516,
          281,
          1884,
          257,
          777,
          3861,
          13,
          467,
          307,
          17720,
          3847,
          1365,
          10592,
          51184
        ]
      },
      {
        "avg_logprob": -0.2140976267123441,
        "compression_ratio": 1.8868778280542986,
        "end": 2187.46,
        "id": 459,
        "no_speech_prob": 0.00012148098176112399,
        "seek": 216704,
        "start": 2184.4,
        "temperature": 0,
        "text": " The website will just be the coding train.com",
        "tokens": [
          51232,
          440,
          3144,
          486,
          445,
          312,
          264,
          17720,
          3847,
          13,
          1112,
          51385
        ]
      },
      {
        "avg_logprob": -0.2140976267123441,
        "compression_ratio": 1.8868778280542986,
        "end": 2191.52,
        "id": 460,
        "no_speech_prob": 0.00012148098176112399,
        "seek": 216704,
        "start": 2188.72,
        "temperature": 0,
        "text": " I want to what do I want to be able to do so?",
        "tokens": [
          51448,
          286,
          528,
          281,
          437,
          360,
          286,
          528,
          281,
          312,
          1075,
          281,
          360,
          370,
          30,
          51588
        ]
      },
      {
        "avg_logprob": -0.20813670248355506,
        "compression_ratio": 1.8791666666666667,
        "end": 2192.88,
        "id": 461,
        "no_speech_prob": 0.00006302691326709464,
        "seek": 219152,
        "start": 2191.52,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50364,
          407,
          50432
        ]
      },
      {
        "avg_logprob": -0.20813670248355506,
        "compression_ratio": 1.8791666666666667,
        "end": 2197.7599999999998,
        "id": 462,
        "no_speech_prob": 0.00006302691326709464,
        "seek": 219152,
        "start": 2192.88,
        "temperature": 0,
        "text": " You have a lot of options in terms of what permissions you can give your bot like maybe the bot",
        "tokens": [
          50432,
          509,
          362,
          257,
          688,
          295,
          3956,
          294,
          2115,
          295,
          437,
          32723,
          291,
          393,
          976,
          428,
          10592,
          411,
          1310,
          264,
          10592,
          50676
        ]
      },
      {
        "avg_logprob": -0.20813670248355506,
        "compression_ratio": 1.8791666666666667,
        "end": 2202.88,
        "id": 463,
        "no_speech_prob": 0.00006302691326709464,
        "seek": 219152,
        "start": 2198.8,
        "temperature": 0,
        "text": " Can only read certain things or only write certain things",
        "tokens": [
          50728,
          1664,
          787,
          1401,
          1629,
          721,
          420,
          787,
          2464,
          1629,
          721,
          50932
        ]
      },
      {
        "avg_logprob": -0.20813670248355506,
        "compression_ratio": 1.8791666666666667,
        "end": 2209.36,
        "id": 464,
        "no_speech_prob": 0.00006302691326709464,
        "seek": 219152,
        "start": 2202.88,
        "temperature": 0,
        "text": " But i'm actually going to keep the global the the red sort of global right checked and the red global read checked",
        "tokens": [
          50932,
          583,
          741,
          478,
          767,
          516,
          281,
          1066,
          264,
          4338,
          264,
          264,
          2182,
          1333,
          295,
          4338,
          558,
          10033,
          293,
          264,
          2182,
          4338,
          1401,
          10033,
          51256
        ]
      },
      {
        "avg_logprob": -0.20813670248355506,
        "compression_ratio": 1.8791666666666667,
        "end": 2214.8,
        "id": 465,
        "no_speech_prob": 0.00006302691326709464,
        "seek": 219152,
        "start": 2209.68,
        "temperature": 0,
        "text": " So that everything and follow so this bot can basically do everything it can read all the posts",
        "tokens": [
          51272,
          407,
          300,
          1203,
          293,
          1524,
          370,
          341,
          10592,
          393,
          1936,
          360,
          1203,
          309,
          393,
          1401,
          439,
          264,
          12300,
          51528
        ]
      },
      {
        "avg_logprob": -0.20813670248355506,
        "compression_ratio": 1.8791666666666667,
        "end": 2219.04,
        "id": 466,
        "no_speech_prob": 0.00006302691326709464,
        "seek": 219152,
        "start": 2214.96,
        "temperature": 0,
        "text": " It can write all as many posts at once and it can follow so i'm going to hit submit",
        "tokens": [
          51536,
          467,
          393,
          2464,
          439,
          382,
          867,
          12300,
          412,
          1564,
          293,
          309,
          393,
          1524,
          370,
          741,
          478,
          516,
          281,
          2045,
          10315,
          51740
        ]
      },
      {
        "avg_logprob": -0.18830585479736328,
        "compression_ratio": 1.791044776119403,
        "end": 2221.6,
        "id": 467,
        "no_speech_prob": 0.00014653001562692225,
        "seek": 221904,
        "start": 2219.6,
        "temperature": 0,
        "text": " And then i'm going to click here",
        "tokens": [
          50392,
          400,
          550,
          741,
          478,
          516,
          281,
          2052,
          510,
          50492
        ]
      },
      {
        "avg_logprob": -0.18830585479736328,
        "compression_ratio": 1.791044776119403,
        "end": 2227.68,
        "id": 468,
        "no_speech_prob": 0.00014653001562692225,
        "seek": 221904,
        "start": 2222.08,
        "temperature": 0,
        "text": " And now now the thing is this is stuff that I really do not want to share with anybody",
        "tokens": [
          50516,
          400,
          586,
          586,
          264,
          551,
          307,
          341,
          307,
          1507,
          300,
          286,
          534,
          360,
          406,
          528,
          281,
          2073,
          365,
          4472,
          50796
        ]
      },
      {
        "avg_logprob": -0.18830585479736328,
        "compression_ratio": 1.791044776119403,
        "end": 2232.48,
        "id": 469,
        "no_speech_prob": 0.00014653001562692225,
        "seek": 221904,
        "start": 2227.92,
        "temperature": 0,
        "text": " So at some point i'm going to regenerate this which i'm going to do right now. I'm actually going to uh,",
        "tokens": [
          50808,
          407,
          412,
          512,
          935,
          741,
          478,
          516,
          281,
          26358,
          473,
          341,
          597,
          741,
          478,
          516,
          281,
          360,
          558,
          586,
          13,
          286,
          478,
          767,
          516,
          281,
          2232,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.18830585479736328,
        "compression_ratio": 1.791044776119403,
        "end": 2239.7599999999998,
        "id": 470,
        "no_speech_prob": 0.00014653001562692225,
        "seek": 221904,
        "start": 2233.12,
        "temperature": 0,
        "text": " Oops, just here. I am back. I'm going to regenerate that access token. So, uh, and I don't really mind if",
        "tokens": [
          51068,
          21726,
          11,
          445,
          510,
          13,
          286,
          669,
          646,
          13,
          286,
          478,
          516,
          281,
          26358,
          473,
          300,
          2105,
          14862,
          13,
          407,
          11,
          2232,
          11,
          293,
          286,
          500,
          380,
          534,
          1575,
          498,
          51400
        ]
      },
      {
        "avg_logprob": -0.18830585479736328,
        "compression_ratio": 1.791044776119403,
        "end": 2243.04,
        "id": 471,
        "no_speech_prob": 0.00014653001562692225,
        "seek": 221904,
        "start": 2240.72,
        "temperature": 0,
        "text": " Who's going to be able to like type this quick enough and hack my bot?",
        "tokens": [
          51448,
          2102,
          311,
          516,
          281,
          312,
          1075,
          281,
          411,
          2010,
          341,
          1702,
          1547,
          293,
          10339,
          452,
          10592,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.18830585479736328,
        "compression_ratio": 1.791044776119403,
        "end": 2248.4,
        "id": 472,
        "no_speech_prob": 0.00014653001562692225,
        "seek": 221904,
        "start": 2243.12,
        "temperature": 0,
        "text": " But um here I come back, but um, this is not something you want to share. Okay",
        "tokens": [
          51568,
          583,
          1105,
          510,
          286,
          808,
          646,
          11,
          457,
          1105,
          11,
          341,
          307,
          406,
          746,
          291,
          528,
          281,
          2073,
          13,
          1033,
          51832
        ]
      },
      {
        "avg_logprob": -0.17489220844051703,
        "compression_ratio": 1.7716894977168949,
        "end": 2252.72,
        "id": 473,
        "no_speech_prob": 0.00006922108150320128,
        "seek": 224904,
        "start": 2250,
        "temperature": 0,
        "text": " Yeah, there we go, okay, so now uh",
        "tokens": [
          50412,
          865,
          11,
          456,
          321,
          352,
          11,
          1392,
          11,
          370,
          586,
          2232,
          50548
        ]
      },
      {
        "avg_logprob": -0.17489220844051703,
        "compression_ratio": 1.7716894977168949,
        "end": 2255.7599999999998,
        "id": 474,
        "no_speech_prob": 0.00006922108150320128,
        "seek": 224904,
        "start": 2253.7599999999998,
        "temperature": 0,
        "text": " Where am I? Oh, okay. You're gonna see it again",
        "tokens": [
          50600,
          2305,
          669,
          286,
          30,
          876,
          11,
          1392,
          13,
          509,
          434,
          799,
          536,
          309,
          797,
          50700
        ]
      },
      {
        "avg_logprob": -0.17489220844051703,
        "compression_ratio": 1.7716894977168949,
        "end": 2260.4,
        "id": 475,
        "no_speech_prob": 0.00006922108150320128,
        "seek": 224904,
        "start": 2256.56,
        "temperature": 0,
        "text": " Now you saw it again. Oh, whatever I failed. Hold on. Let me go back. Let me do that again",
        "tokens": [
          50740,
          823,
          291,
          1866,
          309,
          797,
          13,
          876,
          11,
          2035,
          286,
          7612,
          13,
          6962,
          322,
          13,
          961,
          385,
          352,
          646,
          13,
          961,
          385,
          360,
          300,
          797,
          50932
        ]
      },
      {
        "avg_logprob": -0.17489220844051703,
        "compression_ratio": 1.7716894977168949,
        "end": 2264.08,
        "id": 476,
        "no_speech_prob": 0.00006922108150320128,
        "seek": 224904,
        "start": 2262.08,
        "temperature": 0,
        "text": " Uh, all right",
        "tokens": [
          51016,
          4019,
          11,
          439,
          558,
          51116
        ]
      },
      {
        "avg_logprob": -0.17489220844051703,
        "compression_ratio": 1.7716894977168949,
        "end": 2270,
        "id": 477,
        "no_speech_prob": 0.00006922108150320128,
        "seek": 224904,
        "start": 2266.32,
        "temperature": 0,
        "text": " So what i'm going to do is i'm going to quickly just turn the screen off no, that's me",
        "tokens": [
          51228,
          407,
          437,
          741,
          478,
          516,
          281,
          360,
          307,
          741,
          478,
          516,
          281,
          2661,
          445,
          1261,
          264,
          2568,
          766,
          572,
          11,
          300,
          311,
          385,
          51412
        ]
      },
      {
        "avg_logprob": -0.17489220844051703,
        "compression_ratio": 1.7716894977168949,
        "end": 2274,
        "id": 478,
        "no_speech_prob": 0.00006922108150320128,
        "seek": 224904,
        "start": 2270.08,
        "temperature": 0,
        "text": " I'm going to turn the screen off. There we go. I'm going to regenerate that access token",
        "tokens": [
          51416,
          286,
          478,
          516,
          281,
          1261,
          264,
          2568,
          766,
          13,
          821,
          321,
          352,
          13,
          286,
          478,
          516,
          281,
          26358,
          473,
          300,
          2105,
          14862,
          51612
        ]
      },
      {
        "avg_logprob": -0.17489220844051703,
        "compression_ratio": 1.7716894977168949,
        "end": 2276.4,
        "id": 479,
        "no_speech_prob": 0.00006922108150320128,
        "seek": 224904,
        "start": 2274.48,
        "temperature": 0,
        "text": " Um, i'm going to go back",
        "tokens": [
          51636,
          3301,
          11,
          741,
          478,
          516,
          281,
          352,
          646,
          51732
        ]
      },
      {
        "avg_logprob": -0.2088180102890344,
        "compression_ratio": 1.7805755395683454,
        "end": 2280.56,
        "id": 480,
        "no_speech_prob": 0.00009314547060057521,
        "seek": 227640,
        "start": 2276.4,
        "temperature": 0,
        "text": " To i'm going to copy this stuff somewhere secret. Actually, i'm not going to worry about that now",
        "tokens": [
          50364,
          1407,
          741,
          478,
          516,
          281,
          5055,
          341,
          1507,
          4079,
          4054,
          13,
          5135,
          11,
          741,
          478,
          406,
          516,
          281,
          3292,
          466,
          300,
          586,
          50572
        ]
      },
      {
        "avg_logprob": -0.2088180102890344,
        "compression_ratio": 1.7805755395683454,
        "end": 2284,
        "id": 481,
        "no_speech_prob": 0.00009314547060057521,
        "seek": 227640,
        "start": 2280.56,
        "temperature": 0,
        "text": " I'm going to go back to mastodon then i'm going to put the screen back there I am",
        "tokens": [
          50572,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          27055,
          378,
          266,
          550,
          741,
          478,
          516,
          281,
          829,
          264,
          2568,
          646,
          456,
          286,
          669,
          50744
        ]
      },
      {
        "avg_logprob": -0.2088180102890344,
        "compression_ratio": 1.7805755395683454,
        "end": 2289.52,
        "id": 482,
        "no_speech_prob": 0.00009314547060057521,
        "seek": 227640,
        "start": 2284.4,
        "temperature": 0,
        "text": " Um so that uh, you can't hack my bot at this moment. All right, so what's next?",
        "tokens": [
          50764,
          3301,
          370,
          300,
          2232,
          11,
          291,
          393,
          380,
          10339,
          452,
          10592,
          412,
          341,
          1623,
          13,
          1057,
          558,
          11,
          370,
          437,
          311,
          958,
          30,
          51020
        ]
      },
      {
        "avg_logprob": -0.2088180102890344,
        "compression_ratio": 1.7805755395683454,
        "end": 2292.96,
        "id": 483,
        "no_speech_prob": 0.00009314547060057521,
        "seek": 227640,
        "start": 2290.1600000000003,
        "temperature": 0,
        "text": " I want there's a lot of different ways you could write a mastodon bot",
        "tokens": [
          51052,
          286,
          528,
          456,
          311,
          257,
          688,
          295,
          819,
          2098,
          291,
          727,
          2464,
          257,
          27055,
          378,
          266,
          10592,
          51192
        ]
      },
      {
        "avg_logprob": -0.2088180102890344,
        "compression_ratio": 1.7805755395683454,
        "end": 2300.08,
        "id": 484,
        "no_speech_prob": 0.00009314547060057521,
        "seek": 227640,
        "start": 2293.92,
        "temperature": 0,
        "text": " I'm sure you could come up with some way that I can't even think of right now. I'm going to use node.js",
        "tokens": [
          51240,
          286,
          478,
          988,
          291,
          727,
          808,
          493,
          365,
          512,
          636,
          300,
          286,
          393,
          380,
          754,
          519,
          295,
          558,
          586,
          13,
          286,
          478,
          516,
          281,
          764,
          9984,
          13,
          25530,
          51548
        ]
      },
      {
        "avg_logprob": -0.2088180102890344,
        "compression_ratio": 1.7805755395683454,
        "end": 2303.76,
        "id": 485,
        "no_speech_prob": 0.00009314547060057521,
        "seek": 227640,
        "start": 2300.08,
        "temperature": 0,
        "text": " Which is a javascript framework for executing javascript code",
        "tokens": [
          51548,
          3013,
          307,
          257,
          361,
          37331,
          5944,
          8388,
          337,
          32368,
          361,
          37331,
          5944,
          3089,
          51732
        ]
      },
      {
        "avg_logprob": -0.17675612026587464,
        "compression_ratio": 1.8333333333333333,
        "end": 2305.1200000000003,
        "id": 486,
        "no_speech_prob": 0.00004264682502252981,
        "seek": 230376,
        "start": 2304.1600000000003,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50384,
          1105,
          50432
        ]
      },
      {
        "avg_logprob": -0.17675612026587464,
        "compression_ratio": 1.8333333333333333,
        "end": 2310,
        "id": 487,
        "no_speech_prob": 0.00004264682502252981,
        "seek": 230376,
        "start": 2305.1200000000003,
        "temperature": 0,
        "text": " and uh, I am going to do all this from the command line, so I you",
        "tokens": [
          50432,
          293,
          2232,
          11,
          286,
          669,
          516,
          281,
          360,
          439,
          341,
          490,
          264,
          5622,
          1622,
          11,
          370,
          286,
          291,
          50676
        ]
      },
      {
        "avg_logprob": -0.17675612026587464,
        "compression_ratio": 1.8333333333333333,
        "end": 2313.36,
        "id": 488,
        "no_speech_prob": 0.00004264682502252981,
        "seek": 230376,
        "start": 2311.28,
        "temperature": 0,
        "text": " You're going to want to have node installed and you're going also",
        "tokens": [
          50740,
          509,
          434,
          516,
          281,
          528,
          281,
          362,
          9984,
          8899,
          293,
          291,
          434,
          516,
          611,
          50844
        ]
      },
      {
        "avg_logprob": -0.17675612026587464,
        "compression_ratio": 1.8333333333333333,
        "end": 2316.6400000000003,
        "id": 489,
        "no_speech_prob": 0.00004264682502252981,
        "seek": 230376,
        "start": 2313.6000000000004,
        "temperature": 0,
        "text": " You're going to want to have some shell access to your computer to be able to do this",
        "tokens": [
          50856,
          509,
          434,
          516,
          281,
          528,
          281,
          362,
          512,
          8720,
          2105,
          281,
          428,
          3820,
          281,
          312,
          1075,
          281,
          360,
          341,
          51008
        ]
      },
      {
        "avg_logprob": -0.17675612026587464,
        "compression_ratio": 1.8333333333333333,
        "end": 2321.0400000000004,
        "id": 490,
        "no_speech_prob": 0.00004264682502252981,
        "seek": 230376,
        "start": 2316.88,
        "temperature": 0,
        "text": " And i'll link to different workflow videos about how to get that stuff set up if you don't have that already",
        "tokens": [
          51020,
          400,
          741,
          603,
          2113,
          281,
          819,
          20993,
          2145,
          466,
          577,
          281,
          483,
          300,
          1507,
          992,
          493,
          498,
          291,
          500,
          380,
          362,
          300,
          1217,
          51228
        ]
      },
      {
        "avg_logprob": -0.17675612026587464,
        "compression_ratio": 1.8333333333333333,
        "end": 2326.48,
        "id": 491,
        "no_speech_prob": 0.00004264682502252981,
        "seek": 230376,
        "start": 2321.6800000000003,
        "temperature": 0,
        "text": " So what i'm going to do is i'm in a directory. I'm on coding train desktop mastodon bot",
        "tokens": [
          51260,
          407,
          437,
          741,
          478,
          516,
          281,
          360,
          307,
          741,
          478,
          294,
          257,
          21120,
          13,
          286,
          478,
          322,
          17720,
          3847,
          14502,
          27055,
          378,
          266,
          10592,
          51500
        ]
      },
      {
        "avg_logprob": -0.17675612026587464,
        "compression_ratio": 1.8333333333333333,
        "end": 2329.6800000000003,
        "id": 492,
        "no_speech_prob": 0.00004264682502252981,
        "seek": 230376,
        "start": 2327.1200000000003,
        "temperature": 0,
        "text": " The first thing i'm going to do is i'm just going to type npm init",
        "tokens": [
          51532,
          440,
          700,
          551,
          741,
          478,
          516,
          281,
          360,
          307,
          741,
          478,
          445,
          516,
          281,
          2010,
          297,
          14395,
          3157,
          51660
        ]
      },
      {
        "avg_logprob": -0.20664718416002062,
        "compression_ratio": 1.64453125,
        "end": 2332.96,
        "id": 493,
        "no_speech_prob": 0.00029595461091957986,
        "seek": 232968,
        "start": 2330.3199999999997,
        "temperature": 0,
        "text": " What this does is it starts up my node project?",
        "tokens": [
          50396,
          708,
          341,
          775,
          307,
          309,
          3719,
          493,
          452,
          9984,
          1716,
          30,
          50528
        ]
      },
      {
        "avg_logprob": -0.20664718416002062,
        "compression_ratio": 1.64453125,
        "end": 2339.44,
        "id": 494,
        "no_speech_prob": 0.00029595461091957986,
        "seek": 232968,
        "start": 2333.2799999999997,
        "temperature": 0,
        "text": " This is going to create a package.json file which has all the configuration information for my node project",
        "tokens": [
          50544,
          639,
          307,
          516,
          281,
          1884,
          257,
          7372,
          13,
          73,
          3015,
          3991,
          597,
          575,
          439,
          264,
          11694,
          1589,
          337,
          452,
          9984,
          1716,
          50852
        ]
      },
      {
        "avg_logprob": -0.20664718416002062,
        "compression_ratio": 1.64453125,
        "end": 2342.3199999999997,
        "id": 495,
        "no_speech_prob": 0.00029595461091957986,
        "seek": 232968,
        "start": 2339.44,
        "temperature": 0,
        "text": " I could just manually make that file or copy it from another project",
        "tokens": [
          50852,
          286,
          727,
          445,
          16945,
          652,
          300,
          3991,
          420,
          5055,
          309,
          490,
          1071,
          1716,
          50996
        ]
      },
      {
        "avg_logprob": -0.20664718416002062,
        "compression_ratio": 1.64453125,
        "end": 2346.8799999999997,
        "id": 496,
        "no_speech_prob": 0.00029595461091957986,
        "seek": 232968,
        "start": 2342.3999999999996,
        "temperature": 0,
        "text": " But it's nice that this tool will step me through it. So package name mastodon bot sounds good",
        "tokens": [
          51000,
          583,
          309,
          311,
          1481,
          300,
          341,
          2290,
          486,
          1823,
          385,
          807,
          309,
          13,
          407,
          7372,
          1315,
          27055,
          378,
          266,
          10592,
          3263,
          665,
          51224
        ]
      },
      {
        "avg_logprob": -0.20664718416002062,
        "compression_ratio": 1.64453125,
        "end": 2353.14,
        "id": 497,
        "no_speech_prob": 0.00029595461091957986,
        "seek": 232968,
        "start": 2347.12,
        "temperature": 0,
        "text": " This is version. I don't know 0.0.1. The description is example code for mastodon",
        "tokens": [
          51236,
          639,
          307,
          3037,
          13,
          286,
          500,
          380,
          458,
          1958,
          13,
          15,
          13,
          16,
          13,
          440,
          3855,
          307,
          1365,
          3089,
          337,
          27055,
          378,
          266,
          51537
        ]
      },
      {
        "avg_logprob": -0.20664718416002062,
        "compression_ratio": 1.64453125,
        "end": 2356,
        "id": 498,
        "no_speech_prob": 0.00029595461091957986,
        "seek": 232968,
        "start": 2354,
        "temperature": 0,
        "text": " bot on coding train",
        "tokens": [
          51580,
          10592,
          322,
          17720,
          3847,
          51680
        ]
      },
      {
        "avg_logprob": -0.2316392840761127,
        "compression_ratio": 1.5294117647058822,
        "end": 2362.26,
        "id": 499,
        "no_speech_prob": 0.00029593671206384897,
        "seek": 235600,
        "start": 2356.72,
        "temperature": 0,
        "text": " Entry point i'm gonna have a file called bot.js. I'm not going to worry about testing right now. I don't have a git repository",
        "tokens": [
          50400,
          3951,
          627,
          935,
          741,
          478,
          799,
          362,
          257,
          3991,
          1219,
          10592,
          13,
          25530,
          13,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          4997,
          558,
          586,
          13,
          286,
          500,
          380,
          362,
          257,
          18331,
          25841,
          50677
        ]
      },
      {
        "avg_logprob": -0.2316392840761127,
        "compression_ratio": 1.5294117647058822,
        "end": 2363.9,
        "id": 500,
        "no_speech_prob": 0.00029593671206384897,
        "seek": 235600,
        "start": 2362.88,
        "temperature": 0,
        "text": " bot",
        "tokens": [
          50708,
          10592,
          50759
        ]
      },
      {
        "avg_logprob": -0.2316392840761127,
        "compression_ratio": 1.5294117647058822,
        "end": 2365.28,
        "id": 501,
        "no_speech_prob": 0.00029593671206384897,
        "seek": 235600,
        "start": 2363.9,
        "temperature": 0,
        "text": " mastodon",
        "tokens": [
          50759,
          27055,
          378,
          266,
          50828
        ]
      },
      {
        "avg_logprob": -0.2316392840761127,
        "compression_ratio": 1.5294117647058822,
        "end": 2369.2,
        "id": 502,
        "no_speech_prob": 0.00029593671206384897,
        "seek": 235600,
        "start": 2365.28,
        "temperature": 0,
        "text": " Uh education will be some key words. The author is me",
        "tokens": [
          50828,
          4019,
          3309,
          486,
          312,
          512,
          2141,
          2283,
          13,
          440,
          3793,
          307,
          385,
          51024
        ]
      },
      {
        "avg_logprob": -0.2316392840761127,
        "compression_ratio": 1.5294117647058822,
        "end": 2374.24,
        "id": 503,
        "no_speech_prob": 0.00029593671206384897,
        "seek": 235600,
        "start": 2369.92,
        "temperature": 0,
        "text": " Um, I guess a license will be mit and this looks all looks good to me",
        "tokens": [
          51060,
          3301,
          11,
          286,
          2041,
          257,
          10476,
          486,
          312,
          2194,
          293,
          341,
          1542,
          439,
          1542,
          665,
          281,
          385,
          51276
        ]
      },
      {
        "avg_logprob": -0.2316392840761127,
        "compression_ratio": 1.5294117647058822,
        "end": 2377.92,
        "id": 504,
        "no_speech_prob": 0.00029593671206384897,
        "seek": 235600,
        "start": 2374.4,
        "temperature": 0,
        "text": " So now if I open this up in visual studio code",
        "tokens": [
          51284,
          407,
          586,
          498,
          286,
          1269,
          341,
          493,
          294,
          5056,
          6811,
          3089,
          51460
        ]
      },
      {
        "avg_logprob": -0.2316392840761127,
        "compression_ratio": 1.5294117647058822,
        "end": 2382.48,
        "id": 505,
        "no_speech_prob": 0.00029593671206384897,
        "seek": 235600,
        "start": 2379.52,
        "temperature": 0,
        "text": " We can see it has created a",
        "tokens": [
          51540,
          492,
          393,
          536,
          309,
          575,
          2942,
          257,
          51688
        ]
      },
      {
        "avg_logprob": -0.22365530075565462,
        "compression_ratio": 1.403973509933775,
        "end": 2389.68,
        "id": 506,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 238248,
        "start": 2382.88,
        "temperature": 0,
        "text": " It has created a package.json file with all of that information in it that I just typed",
        "tokens": [
          50384,
          467,
          575,
          2942,
          257,
          7372,
          13,
          73,
          3015,
          3991,
          365,
          439,
          295,
          300,
          1589,
          294,
          309,
          300,
          286,
          445,
          33941,
          50724
        ]
      },
      {
        "avg_logprob": -0.22365530075565462,
        "compression_ratio": 1.403973509933775,
        "end": 2392.16,
        "id": 507,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 238248,
        "start": 2390.16,
        "temperature": 0,
        "text": " I pause for a second",
        "tokens": [
          50748,
          286,
          10465,
          337,
          257,
          1150,
          50848
        ]
      },
      {
        "avg_logprob": -0.22365530075565462,
        "compression_ratio": 1.403973509933775,
        "end": 2401.52,
        "id": 508,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 238248,
        "start": 2399.52,
        "temperature": 0,
        "text": " Um, okay",
        "tokens": [
          51216,
          3301,
          11,
          1392,
          51316
        ]
      },
      {
        "avg_logprob": -0.22365530075565462,
        "compression_ratio": 1.403973509933775,
        "end": 2406.96,
        "id": 509,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 238248,
        "start": 2404.96,
        "temperature": 0,
        "text": " I feel like this is a little bit big",
        "tokens": [
          51488,
          286,
          841,
          411,
          341,
          307,
          257,
          707,
          857,
          955,
          51588
        ]
      },
      {
        "avg_logprob": -0.22365530075565462,
        "compression_ratio": 1.403973509933775,
        "end": 2411.52,
        "id": 510,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 238248,
        "start": 2408.8,
        "temperature": 0,
        "text": " Actually, I like that that's bigger and then now I can go",
        "tokens": [
          51680,
          5135,
          11,
          286,
          411,
          300,
          300,
          311,
          3801,
          293,
          550,
          586,
          286,
          393,
          352,
          51816
        ]
      },
      {
        "avg_logprob": -0.18809019646993497,
        "compression_ratio": 1.542857142857143,
        "end": 2414.88,
        "id": 511,
        "no_speech_prob": 0.00004331871241447516,
        "seek": 241248,
        "start": 2412.88,
        "temperature": 0,
        "text": " um to preferences",
        "tokens": [
          50384,
          1105,
          281,
          21910,
          50484
        ]
      },
      {
        "avg_logprob": -0.18809019646993497,
        "compression_ratio": 1.542857142857143,
        "end": 2418.8,
        "id": 512,
        "no_speech_prob": 0.00004331871241447516,
        "seek": 241248,
        "start": 2416.8,
        "temperature": 0,
        "text": " And change this",
        "tokens": [
          50580,
          400,
          1319,
          341,
          50680
        ]
      },
      {
        "avg_logprob": -0.18809019646993497,
        "compression_ratio": 1.542857142857143,
        "end": 2423.84,
        "id": 513,
        "no_speech_prob": 0.00004331871241447516,
        "seek": 241248,
        "start": 2421.2,
        "temperature": 0,
        "text": " And go here, yeah, that's better, okay. Um",
        "tokens": [
          50800,
          400,
          352,
          510,
          11,
          1338,
          11,
          300,
          311,
          1101,
          11,
          1392,
          13,
          3301,
          50932
        ]
      },
      {
        "avg_logprob": -0.18809019646993497,
        "compression_ratio": 1.542857142857143,
        "end": 2428.48,
        "id": 514,
        "no_speech_prob": 0.00004331871241447516,
        "seek": 241248,
        "start": 2426.48,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51064,
          1033,
          51164
        ]
      },
      {
        "avg_logprob": -0.18809019646993497,
        "compression_ratio": 1.542857142857143,
        "end": 2435.28,
        "id": 515,
        "no_speech_prob": 0.00004331871241447516,
        "seek": 241248,
        "start": 2430.16,
        "temperature": 0,
        "text": " Okay, the next thing that I want to do is create my javascript file that is going to run the bot",
        "tokens": [
          51248,
          1033,
          11,
          264,
          958,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          1884,
          452,
          361,
          37331,
          5944,
          3991,
          300,
          307,
          516,
          281,
          1190,
          264,
          10592,
          51504
        ]
      },
      {
        "avg_logprob": -0.18809019646993497,
        "compression_ratio": 1.542857142857143,
        "end": 2440.64,
        "id": 516,
        "no_speech_prob": 0.00004331871241447516,
        "seek": 241248,
        "start": 2435.52,
        "temperature": 0,
        "text": " So i'm just going to click new file and i'm going to say bot.js and just to test things out",
        "tokens": [
          51516,
          407,
          741,
          478,
          445,
          516,
          281,
          2052,
          777,
          3991,
          293,
          741,
          478,
          516,
          281,
          584,
          10592,
          13,
          25530,
          293,
          445,
          281,
          1500,
          721,
          484,
          51772
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2442.72,
        "id": 517,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2440.72,
        "temperature": 0,
        "text": " I'm going to say console.log",
        "tokens": [
          50368,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          50468
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2444.3199999999997,
        "id": 518,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2442.8599999999997,
        "temperature": 0,
        "text": " mastodon bot",
        "tokens": [
          50475,
          27055,
          378,
          266,
          10592,
          50548
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2446.16,
        "id": 519,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2444.3199999999997,
        "temperature": 0,
        "text": " starting dot dot dot",
        "tokens": [
          50548,
          2891,
          5893,
          5893,
          5893,
          50640
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2446.8799999999997,
        "id": 520,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2446.16,
        "temperature": 0,
        "text": " so",
        "tokens": [
          50640,
          370,
          50676
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2449.52,
        "id": 521,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2446.8799999999997,
        "temperature": 0,
        "text": " This is where all of my code for the bot is going to go",
        "tokens": [
          50676,
          639,
          307,
          689,
          439,
          295,
          452,
          3089,
          337,
          264,
          10592,
          307,
          516,
          281,
          352,
          50808
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2454.96,
        "id": 522,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2449.92,
        "temperature": 0,
        "text": " And the very first thing that i'm going to do is just test this code by executing it and the way that I do",
        "tokens": [
          50828,
          400,
          264,
          588,
          700,
          551,
          300,
          741,
          478,
          516,
          281,
          360,
          307,
          445,
          1500,
          341,
          3089,
          538,
          32368,
          309,
          293,
          264,
          636,
          300,
          286,
          360,
          51080
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2457.8399999999997,
        "id": 523,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2455.04,
        "temperature": 0,
        "text": " That is going back to terminal. And by the way, yes",
        "tokens": [
          51084,
          663,
          307,
          516,
          646,
          281,
          14709,
          13,
          400,
          538,
          264,
          636,
          11,
          2086,
          51224
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2460.48,
        "id": 524,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2458.48,
        "temperature": 0,
        "text": " There whoops",
        "tokens": [
          51256,
          821,
          567,
          3370,
          51356
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2462.8799999999997,
        "id": 525,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2460.8799999999997,
        "temperature": 0,
        "text": " It's not the right command",
        "tokens": [
          51376,
          467,
          311,
          406,
          264,
          558,
          5622,
          51476
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2465.8399999999997,
        "id": 526,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2463.8399999999997,
        "temperature": 0,
        "text": " How do I do that no",
        "tokens": [
          51524,
          1012,
          360,
          286,
          360,
          300,
          572,
          51624
        ]
      },
      {
        "avg_logprob": -0.20126071018455302,
        "compression_ratio": 1.7047619047619047,
        "end": 2469.92,
        "id": 527,
        "no_speech_prob": 0.0000861459702719003,
        "seek": 244064,
        "start": 2468.16,
        "temperature": 0,
        "text": " Yeah, there we go",
        "tokens": [
          51740,
          865,
          11,
          456,
          321,
          352,
          51828
        ]
      },
      {
        "avg_logprob": -0.19671117912218408,
        "compression_ratio": 1.6531531531531531,
        "end": 2471.92,
        "id": 528,
        "no_speech_prob": 0.00009915194095810875,
        "seek": 246992,
        "start": 2469.92,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50364,
          1105,
          50464
        ]
      },
      {
        "avg_logprob": -0.19671117912218408,
        "compression_ratio": 1.6531531531531531,
        "end": 2478.88,
        "id": 529,
        "no_speech_prob": 0.00009915194095810875,
        "seek": 246992,
        "start": 2474.16,
        "temperature": 0,
        "text": " And by the way, yes, there is actually a terminal directly in",
        "tokens": [
          50576,
          400,
          538,
          264,
          636,
          11,
          2086,
          11,
          456,
          307,
          767,
          257,
          14709,
          3838,
          294,
          50812
        ]
      },
      {
        "avg_logprob": -0.19671117912218408,
        "compression_ratio": 1.6531531531531531,
        "end": 2483.36,
        "id": 530,
        "no_speech_prob": 0.00009915194095810875,
        "seek": 246992,
        "start": 2479.52,
        "temperature": 0,
        "text": " Um in visual code studio and I could actually just run it right here",
        "tokens": [
          50844,
          3301,
          294,
          5056,
          3089,
          6811,
          293,
          286,
          727,
          767,
          445,
          1190,
          309,
          558,
          510,
          51036
        ]
      },
      {
        "avg_logprob": -0.19671117912218408,
        "compression_ratio": 1.6531531531531531,
        "end": 2488.8,
        "id": 531,
        "no_speech_prob": 0.00009915194095810875,
        "seek": 246992,
        "start": 2483.6800000000003,
        "temperature": 0,
        "text": " And by saying like node bot.js and maybe I should do that. This is so tiny though",
        "tokens": [
          51052,
          400,
          538,
          1566,
          411,
          9984,
          10592,
          13,
          25530,
          293,
          1310,
          286,
          820,
          360,
          300,
          13,
          639,
          307,
          370,
          5870,
          1673,
          51308
        ]
      },
      {
        "avg_logprob": -0.19671117912218408,
        "compression_ratio": 1.6531531531531531,
        "end": 2492.08,
        "id": 532,
        "no_speech_prob": 0.00009915194095810875,
        "seek": 246992,
        "start": 2489.2000000000003,
        "temperature": 0,
        "text": " Um, I don't know why i'm just not used to using this terminal yet",
        "tokens": [
          51328,
          3301,
          11,
          286,
          500,
          380,
          458,
          983,
          741,
          478,
          445,
          406,
          1143,
          281,
          1228,
          341,
          14709,
          1939,
          51472
        ]
      },
      {
        "avg_logprob": -0.19671117912218408,
        "compression_ratio": 1.6531531531531531,
        "end": 2496.42,
        "id": 533,
        "no_speech_prob": 0.00009915194095810875,
        "seek": 246992,
        "start": 2492.32,
        "temperature": 0,
        "text": " So i'm going to stick with my using a separate iterm and i'm going to run node bot.js",
        "tokens": [
          51484,
          407,
          741,
          478,
          516,
          281,
          2897,
          365,
          452,
          1228,
          257,
          4994,
          309,
          966,
          293,
          741,
          478,
          516,
          281,
          1190,
          9984,
          10592,
          13,
          25530,
          51689
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2500.1800000000003,
        "id": 534,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2497.06,
        "temperature": 0,
        "text": " And we can see all it's doing is console logging that mastodon bot starting",
        "tokens": [
          50396,
          400,
          321,
          393,
          536,
          439,
          309,
          311,
          884,
          307,
          11076,
          27991,
          300,
          27055,
          378,
          266,
          10592,
          2891,
          50552
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2503.3,
        "id": 535,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2500.26,
        "temperature": 0,
        "text": " Okay, how am I going to connect to mastodon?",
        "tokens": [
          50556,
          1033,
          11,
          577,
          669,
          286,
          516,
          281,
          1745,
          281,
          27055,
          378,
          266,
          30,
          50708
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2510.02,
        "id": 536,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2503.62,
        "temperature": 0,
        "text": " So in order to do this i'm going to use a node package that will communicate with the mastodon api directly",
        "tokens": [
          50724,
          407,
          294,
          1668,
          281,
          360,
          341,
          741,
          478,
          516,
          281,
          764,
          257,
          9984,
          7372,
          300,
          486,
          7890,
          365,
          264,
          27055,
          378,
          266,
          1882,
          72,
          3838,
          51044
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2512.66,
        "id": 537,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2510.9,
        "temperature": 0,
        "text": " So let's find that",
        "tokens": [
          51088,
          407,
          718,
          311,
          915,
          300,
          51176
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2514.66,
        "id": 538,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2512.66,
        "temperature": 0,
        "text": " Um, sure. Let's look at notifications",
        "tokens": [
          51176,
          3301,
          11,
          988,
          13,
          961,
          311,
          574,
          412,
          13426,
          51276
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2516.98,
        "id": 539,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2514.98,
        "temperature": 0,
        "text": " Um, let's let's node",
        "tokens": [
          51292,
          3301,
          11,
          718,
          311,
          718,
          311,
          9984,
          51392
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2519.92,
        "id": 540,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2517.92,
        "temperature": 0,
        "text": " mastodon api",
        "tokens": [
          51439,
          27055,
          378,
          266,
          1882,
          72,
          51539
        ]
      },
      {
        "avg_logprob": -0.23256753009298572,
        "compression_ratio": 1.6531531531531531,
        "end": 2524.28,
        "id": 541,
        "no_speech_prob": 0.0013044836232438684,
        "seek": 249642,
        "start": 2520.58,
        "temperature": 0,
        "text": " And let's see so what comes up mastodon-api-npm",
        "tokens": [
          51572,
          400,
          718,
          311,
          536,
          370,
          437,
          1487,
          493,
          27055,
          378,
          266,
          12,
          35891,
          12,
          77,
          14395,
          51757
        ]
      },
      {
        "avg_logprob": -0.1957150985454691,
        "compression_ratio": 1.6852589641434264,
        "end": 2528.5400000000004,
        "id": 542,
        "no_speech_prob": 0.00007368549995590001,
        "seek": 252428,
        "start": 2525.1600000000003,
        "temperature": 0,
        "text": " Um, this one looks pretty good. Let's go over to github",
        "tokens": [
          50408,
          3301,
          11,
          341,
          472,
          1542,
          1238,
          665,
          13,
          961,
          311,
          352,
          670,
          281,
          290,
          355,
          836,
          50577
        ]
      },
      {
        "avg_logprob": -0.1957150985454691,
        "compression_ratio": 1.6852589641434264,
        "end": 2533.48,
        "id": 543,
        "no_speech_prob": 0.00007368549995590001,
        "seek": 252428,
        "start": 2529.32,
        "temperature": 0,
        "text": " And see all right. So this is actually the one this is the one that i'm going to choose to use",
        "tokens": [
          50616,
          400,
          536,
          439,
          558,
          13,
          407,
          341,
          307,
          767,
          264,
          472,
          341,
          307,
          264,
          472,
          300,
          741,
          478,
          516,
          281,
          2826,
          281,
          764,
          50824
        ]
      },
      {
        "avg_logprob": -0.1957150985454691,
        "compression_ratio": 1.6852589641434264,
        "end": 2539.5600000000004,
        "id": 544,
        "no_speech_prob": 0.00007368549995590001,
        "seek": 252428,
        "start": 2533.88,
        "temperature": 0,
        "text": " Um, it was last updated eight days ago. I've used this before in making a practice example",
        "tokens": [
          50844,
          3301,
          11,
          309,
          390,
          1036,
          10588,
          3180,
          1708,
          2057,
          13,
          286,
          600,
          1143,
          341,
          949,
          294,
          1455,
          257,
          3124,
          1365,
          51128
        ]
      },
      {
        "avg_logprob": -0.1957150985454691,
        "compression_ratio": 1.6852589641434264,
        "end": 2541.8,
        "id": 545,
        "no_speech_prob": 0.00007368549995590001,
        "seek": 252428,
        "start": 2539.8,
        "temperature": 0,
        "text": " So this one is going to work fine for me",
        "tokens": [
          51140,
          407,
          341,
          472,
          307,
          516,
          281,
          589,
          2489,
          337,
          385,
          51240
        ]
      },
      {
        "avg_logprob": -0.1957150985454691,
        "compression_ratio": 1.6852589641434264,
        "end": 2544.92,
        "id": 546,
        "no_speech_prob": 0.00007368549995590001,
        "seek": 252428,
        "start": 2542.2000000000003,
        "temperature": 0,
        "text": " And so now the next thing that I need to do",
        "tokens": [
          51260,
          400,
          370,
          586,
          264,
          958,
          551,
          300,
          286,
          643,
          281,
          360,
          51396
        ]
      },
      {
        "avg_logprob": -0.1957150985454691,
        "compression_ratio": 1.6852589641434264,
        "end": 2551,
        "id": 547,
        "no_speech_prob": 0.00007368549995590001,
        "seek": 252428,
        "start": 2545.32,
        "temperature": 0,
        "text": " Is I need to run npm install because if i'm going to use this package to communicate with my bot",
        "tokens": [
          51416,
          1119,
          286,
          643,
          281,
          1190,
          297,
          14395,
          3625,
          570,
          498,
          741,
          478,
          516,
          281,
          764,
          341,
          7372,
          281,
          7890,
          365,
          452,
          10592,
          51700
        ]
      },
      {
        "avg_logprob": -0.24049954800992399,
        "compression_ratio": 1.691358024691358,
        "end": 2557.32,
        "id": 548,
        "no_speech_prob": 0.00014202232705429196,
        "seek": 255100,
        "start": 2551.56,
        "temperature": 0,
        "text": " I need to make sure I have it installed. So this npm install dash dash save mastodon-api",
        "tokens": [
          50392,
          286,
          643,
          281,
          652,
          988,
          286,
          362,
          309,
          8899,
          13,
          407,
          341,
          297,
          14395,
          3625,
          8240,
          8240,
          3155,
          27055,
          378,
          266,
          12,
          35891,
          50680
        ]
      },
      {
        "avg_logprob": -0.24049954800992399,
        "compression_ratio": 1.691358024691358,
        "end": 2562.6,
        "id": 549,
        "no_speech_prob": 0.00014202232705429196,
        "seek": 255100,
        "start": 2557.48,
        "temperature": 0,
        "text": " And yes, I could use yarn, which is another package manager for node, but i'm still i'm like an npm person",
        "tokens": [
          50688,
          400,
          2086,
          11,
          286,
          727,
          764,
          11400,
          11,
          597,
          307,
          1071,
          7372,
          6598,
          337,
          9984,
          11,
          457,
          741,
          478,
          920,
          741,
          478,
          411,
          364,
          297,
          14395,
          954,
          50944
        ]
      },
      {
        "avg_logprob": -0.24049954800992399,
        "compression_ratio": 1.691358024691358,
        "end": 2568.28,
        "id": 550,
        "no_speech_prob": 0.00014202232705429196,
        "seek": 255100,
        "start": 2564.28,
        "temperature": 0,
        "text": " Whenever there's the thing that's people are using instead of yarn, that's when i'll use yarn",
        "tokens": [
          51028,
          14159,
          456,
          311,
          264,
          551,
          300,
          311,
          561,
          366,
          1228,
          2602,
          295,
          11400,
          11,
          300,
          311,
          562,
          741,
          603,
          764,
          11400,
          51228
        ]
      },
      {
        "avg_logprob": -0.24049954800992399,
        "compression_ratio": 1.691358024691358,
        "end": 2572.68,
        "id": 551,
        "no_speech_prob": 0.00014202232705429196,
        "seek": 255100,
        "start": 2569.16,
        "temperature": 0,
        "text": " npm install save the dash dash save by the way is a",
        "tokens": [
          51272,
          297,
          14395,
          3625,
          3155,
          264,
          8240,
          8240,
          3155,
          538,
          264,
          636,
          307,
          257,
          51448
        ]
      },
      {
        "avg_logprob": -0.24049954800992399,
        "compression_ratio": 1.691358024691358,
        "end": 2576.44,
        "id": 552,
        "no_speech_prob": 0.00014202232705429196,
        "seek": 255100,
        "start": 2573.06,
        "temperature": 0,
        "text": " Argument so that it automatically gets added to the package.json file",
        "tokens": [
          51467,
          40081,
          2206,
          370,
          300,
          309,
          6772,
          2170,
          3869,
          281,
          264,
          7372,
          13,
          73,
          3015,
          3991,
          51636
        ]
      },
      {
        "avg_logprob": -0.22404637336730956,
        "compression_ratio": 1.6980392156862745,
        "end": 2580.62,
        "id": 553,
        "no_speech_prob": 0.0005703045753762126,
        "seek": 257644,
        "start": 2577,
        "temperature": 0,
        "text": " And there we go. So if I go over here we can see if I look in package.json",
        "tokens": [
          50392,
          400,
          456,
          321,
          352,
          13,
          407,
          498,
          286,
          352,
          670,
          510,
          321,
          393,
          536,
          498,
          286,
          574,
          294,
          7372,
          13,
          73,
          3015,
          50573
        ]
      },
      {
        "avg_logprob": -0.22404637336730956,
        "compression_ratio": 1.6980392156862745,
        "end": 2583.8,
        "id": 554,
        "no_speech_prob": 0.0005703045753762126,
        "seek": 257644,
        "start": 2581.8,
        "temperature": 0,
        "text": " There is now also a dependency",
        "tokens": [
          50632,
          821,
          307,
          586,
          611,
          257,
          33621,
          50732
        ]
      },
      {
        "avg_logprob": -0.22404637336730956,
        "compression_ratio": 1.6980392156862745,
        "end": 2590.2000000000003,
        "id": 555,
        "no_speech_prob": 0.0005703045753762126,
        "seek": 257644,
        "start": 2584.26,
        "temperature": 0,
        "text": " Mastodon-api. So that is now a project dependency and the first thing that I want to do to be able to use this",
        "tokens": [
          50755,
          376,
          525,
          378,
          266,
          12,
          35891,
          13,
          407,
          300,
          307,
          586,
          257,
          1716,
          33621,
          293,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          281,
          312,
          1075,
          281,
          764,
          341,
          51052
        ]
      },
      {
        "avg_logprob": -0.22404637336730956,
        "compression_ratio": 1.6980392156862745,
        "end": 2594.84,
        "id": 556,
        "no_speech_prob": 0.0005703045753762126,
        "seek": 257644,
        "start": 2591,
        "temperature": 0,
        "text": " Is and actually documentation here documentation people",
        "tokens": [
          51092,
          1119,
          293,
          767,
          14333,
          510,
          14333,
          561,
          51284
        ]
      },
      {
        "avg_logprob": -0.22404637336730956,
        "compression_ratio": 1.6980392156862745,
        "end": 2596.6,
        "id": 557,
        "no_speech_prob": 0.0005703045753762126,
        "seek": 257644,
        "start": 2595.48,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51316,
          1105,
          51372
        ]
      },
      {
        "avg_logprob": -0.22404637336730956,
        "compression_ratio": 1.6980392156862745,
        "end": 2601.88,
        "id": 558,
        "no_speech_prob": 0.0005703045753762126,
        "seek": 257644,
        "start": 2596.6,
        "temperature": 0,
        "text": " One let's actually just go over to examples and click on uh streaming and this is what I want",
        "tokens": [
          51372,
          1485,
          718,
          311,
          767,
          445,
          352,
          670,
          281,
          5110,
          293,
          2052,
          322,
          2232,
          11791,
          293,
          341,
          307,
          437,
          286,
          528,
          51636
        ]
      },
      {
        "avg_logprob": -0.22404637336730956,
        "compression_ratio": 1.6980392156862745,
        "end": 2604.92,
        "id": 559,
        "no_speech_prob": 0.0005703045753762126,
        "seek": 257644,
        "start": 2602.2000000000003,
        "temperature": 0,
        "text": " Oh, no, I don't. Oh my goodness. All right. Never mind. Hold on",
        "tokens": [
          51652,
          876,
          11,
          572,
          11,
          286,
          500,
          380,
          13,
          876,
          452,
          8387,
          13,
          1057,
          558,
          13,
          7344,
          1575,
          13,
          6962,
          322,
          51788
        ]
      },
      {
        "avg_logprob": -0.26038460812326203,
        "compression_ratio": 1.4776119402985075,
        "end": 2610.92,
        "id": 560,
        "no_speech_prob": 0.00007967222336446866,
        "seek": 260644,
        "start": 2606.84,
        "temperature": 0,
        "text": " I have my own examples. Um, I think it's just require",
        "tokens": [
          50384,
          286,
          362,
          452,
          1065,
          5110,
          13,
          3301,
          11,
          286,
          519,
          309,
          311,
          445,
          3651,
          50588
        ]
      },
      {
        "avg_logprob": -0.26038460812326203,
        "compression_ratio": 1.4776119402985075,
        "end": 2615.48,
        "id": 561,
        "no_speech_prob": 0.00007967222336446866,
        "seek": 260644,
        "start": 2612.84,
        "temperature": 0,
        "text": " Um, you no longer have to use alka, okay",
        "tokens": [
          50684,
          3301,
          11,
          291,
          572,
          2854,
          362,
          281,
          764,
          419,
          2330,
          11,
          1392,
          50816
        ]
      },
      {
        "avg_logprob": -0.26038460812326203,
        "compression_ratio": 1.4776119402985075,
        "end": 2618.92,
        "id": 562,
        "no_speech_prob": 0.00007967222336446866,
        "seek": 260644,
        "start": 2616.92,
        "temperature": 0,
        "text": " Hold on then",
        "tokens": [
          50888,
          6962,
          322,
          550,
          50988
        ]
      },
      {
        "avg_logprob": -0.26038460812326203,
        "compression_ratio": 1.4776119402985075,
        "end": 2633.88,
        "id": 563,
        "no_speech_prob": 0.00007967222336446866,
        "seek": 260644,
        "start": 2629.4,
        "temperature": 0,
        "text": " Breaking news alka in the chat is telling me that you no longer have to use dash dash save",
        "tokens": [
          51512,
          36715,
          2583,
          419,
          2330,
          294,
          264,
          5081,
          307,
          3585,
          385,
          300,
          291,
          572,
          2854,
          362,
          281,
          764,
          8240,
          8240,
          3155,
          51736
        ]
      },
      {
        "avg_logprob": -0.22845623794111233,
        "compression_ratio": 1.6136363636363635,
        "end": 2639.56,
        "id": 564,
        "no_speech_prob": 0.00014425787958316505,
        "seek": 263388,
        "start": 2633.96,
        "temperature": 0,
        "text": " So maybe it it adds it automatically whether or not use dash dash save or not. That's a nice little extra tip for today",
        "tokens": [
          50368,
          407,
          1310,
          309,
          309,
          10860,
          309,
          6772,
          1968,
          420,
          406,
          764,
          8240,
          8240,
          3155,
          420,
          406,
          13,
          663,
          311,
          257,
          1481,
          707,
          2857,
          4125,
          337,
          965,
          50648
        ]
      },
      {
        "avg_logprob": -0.22845623794111233,
        "compression_ratio": 1.6136363636363635,
        "end": 2644.6,
        "id": 565,
        "no_speech_prob": 0.00014425787958316505,
        "seek": 263388,
        "start": 2639.8,
        "temperature": 0,
        "text": " Okay, what I want to do, uh now is uh require it",
        "tokens": [
          50660,
          1033,
          11,
          437,
          286,
          528,
          281,
          360,
          11,
          2232,
          586,
          307,
          2232,
          3651,
          309,
          50900
        ]
      },
      {
        "avg_logprob": -0.22845623794111233,
        "compression_ratio": 1.6136363636363635,
        "end": 2650.04,
        "id": 566,
        "no_speech_prob": 0.00014425787958316505,
        "seek": 263388,
        "start": 2645.08,
        "temperature": 0,
        "text": " And again, i'm not using i'm in a sort of still i'm using require so i'm gonna say const",
        "tokens": [
          50924,
          400,
          797,
          11,
          741,
          478,
          406,
          1228,
          741,
          478,
          294,
          257,
          1333,
          295,
          920,
          741,
          478,
          1228,
          3651,
          370,
          741,
          478,
          799,
          584,
          1817,
          51172
        ]
      },
      {
        "avg_logprob": -0.22845623794111233,
        "compression_ratio": 1.6136363636363635,
        "end": 2652.7400000000002,
        "id": 567,
        "no_speech_prob": 0.00014425787958316505,
        "seek": 263388,
        "start": 2650.7400000000002,
        "temperature": 0,
        "text": " uh mastodon",
        "tokens": [
          51207,
          2232,
          27055,
          378,
          266,
          51307
        ]
      },
      {
        "avg_logprob": -0.22845623794111233,
        "compression_ratio": 1.6136363636363635,
        "end": 2658.52,
        "id": 568,
        "no_speech_prob": 0.00014425787958316505,
        "seek": 263388,
        "start": 2653.4,
        "temperature": 0,
        "text": " Equal let's just call it const m maybe no, let's I don't know mastodon equals require",
        "tokens": [
          51340,
          15624,
          304,
          718,
          311,
          445,
          818,
          309,
          1817,
          275,
          1310,
          572,
          11,
          718,
          311,
          286,
          500,
          380,
          458,
          27055,
          378,
          266,
          6915,
          3651,
          51596
        ]
      },
      {
        "avg_logprob": -0.21213750226782002,
        "compression_ratio": 1.6680161943319838,
        "end": 2665.4,
        "id": 569,
        "no_speech_prob": 0.00048028951277956367,
        "seek": 265852,
        "start": 2659.06,
        "temperature": 0,
        "text": " Mastodon dash api so I am now requiring it which meaning that's basically i'm importing it",
        "tokens": [
          50391,
          376,
          525,
          378,
          266,
          8240,
          1882,
          72,
          370,
          286,
          669,
          586,
          24165,
          309,
          597,
          3620,
          300,
          311,
          1936,
          741,
          478,
          43866,
          309,
          50708
        ]
      },
      {
        "avg_logprob": -0.21213750226782002,
        "compression_ratio": 1.6680161943319838,
        "end": 2670.36,
        "id": 570,
        "no_speech_prob": 0.00048028951277956367,
        "seek": 265852,
        "start": 2665.72,
        "temperature": 0,
        "text": " And then what I want to do is I want to connect and there's a lot of ways that you can",
        "tokens": [
          50724,
          400,
          550,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          1745,
          293,
          456,
          311,
          257,
          688,
          295,
          2098,
          300,
          291,
          393,
          50956
        ]
      },
      {
        "avg_logprob": -0.21213750226782002,
        "compression_ratio": 1.6680161943319838,
        "end": 2676.2,
        "id": 571,
        "no_speech_prob": 0.00048028951277956367,
        "seek": 265852,
        "start": 2671.08,
        "temperature": 0,
        "text": " Connect live in your code because maybe you're making an app and you want people to be authenticated with different accounts",
        "tokens": [
          50992,
          11653,
          1621,
          294,
          428,
          3089,
          570,
          1310,
          291,
          434,
          1455,
          364,
          724,
          293,
          291,
          528,
          561,
          281,
          312,
          9214,
          3587,
          365,
          819,
          9402,
          51248
        ]
      },
      {
        "avg_logprob": -0.21213750226782002,
        "compression_ratio": 1.6680161943319838,
        "end": 2680.04,
        "id": 572,
        "no_speech_prob": 0.00048028951277956367,
        "seek": 265852,
        "start": 2676.52,
        "temperature": 0,
        "text": " I don't need to do any of that. I just want to um",
        "tokens": [
          51264,
          286,
          500,
          380,
          643,
          281,
          360,
          604,
          295,
          300,
          13,
          286,
          445,
          528,
          281,
          1105,
          51440
        ]
      },
      {
        "avg_logprob": -0.21213750226782002,
        "compression_ratio": 1.6680161943319838,
        "end": 2683.64,
        "id": 573,
        "no_speech_prob": 0.00048028951277956367,
        "seek": 265852,
        "start": 2681.64,
        "temperature": 0,
        "text": " Uh do this",
        "tokens": [
          51520,
          4019,
          360,
          341,
          51620
        ]
      },
      {
        "avg_logprob": -0.21213750226782002,
        "compression_ratio": 1.6680161943319838,
        "end": 2687.42,
        "id": 574,
        "no_speech_prob": 0.00048028951277956367,
        "seek": 265852,
        "start": 2684.2,
        "temperature": 0,
        "text": " New uh constant m constant m equals new mastodon",
        "tokens": [
          51648,
          1873,
          2232,
          5754,
          275,
          5754,
          275,
          6915,
          777,
          27055,
          378,
          266,
          51809
        ]
      },
      {
        "avg_logprob": -0.2129091050889757,
        "compression_ratio": 1.7294117647058824,
        "end": 2690.68,
        "id": 575,
        "no_speech_prob": 0.000011300784535706043,
        "seek": 268852,
        "start": 2688.84,
        "temperature": 0,
        "text": " And i'm gonna do this",
        "tokens": [
          50380,
          400,
          741,
          478,
          799,
          360,
          341,
          50472
        ]
      },
      {
        "avg_logprob": -0.2129091050889757,
        "compression_ratio": 1.7294117647058824,
        "end": 2697.08,
        "id": 576,
        "no_speech_prob": 0.000011300784535706043,
        "seek": 268852,
        "start": 2690.68,
        "temperature": 0,
        "text": " And uh, i'm gonna need to put in my access token. I'm gonna need uh, I don't i'm not too worried about this and I need",
        "tokens": [
          50472,
          400,
          2232,
          11,
          741,
          478,
          799,
          643,
          281,
          829,
          294,
          452,
          2105,
          14862,
          13,
          286,
          478,
          799,
          643,
          2232,
          11,
          286,
          500,
          380,
          741,
          478,
          406,
          886,
          5804,
          466,
          341,
          293,
          286,
          643,
          50792
        ]
      },
      {
        "avg_logprob": -0.2129091050889757,
        "compression_ratio": 1.7294117647058824,
        "end": 2699.16,
        "id": 577,
        "no_speech_prob": 0.000011300784535706043,
        "seek": 268852,
        "start": 2697.16,
        "temperature": 0,
        "text": " to uh put in",
        "tokens": [
          50796,
          281,
          2232,
          829,
          294,
          50896
        ]
      },
      {
        "avg_logprob": -0.2129091050889757,
        "compression_ratio": 1.7294117647058824,
        "end": 2701.48,
        "id": 578,
        "no_speech_prob": 0.000011300784535706043,
        "seek": 268852,
        "start": 2699.48,
        "temperature": 0,
        "text": " my particular um",
        "tokens": [
          50912,
          452,
          1729,
          1105,
          51012
        ]
      },
      {
        "avg_logprob": -0.2129091050889757,
        "compression_ratio": 1.7294117647058824,
        "end": 2705.16,
        "id": 579,
        "no_speech_prob": 0.000011300784535706043,
        "seek": 268852,
        "start": 2703.16,
        "temperature": 0,
        "text": " Instance which is bots in space",
        "tokens": [
          51096,
          2730,
          719,
          597,
          307,
          35410,
          294,
          1901,
          51196
        ]
      },
      {
        "avg_logprob": -0.2129091050889757,
        "compression_ratio": 1.7294117647058824,
        "end": 2711.48,
        "id": 580,
        "no_speech_prob": 0.000011300784535706043,
        "seek": 268852,
        "start": 2705.56,
        "temperature": 0,
        "text": " So this is the this is the since I am now going to run my bot through bots in space the api",
        "tokens": [
          51216,
          407,
          341,
          307,
          264,
          341,
          307,
          264,
          1670,
          286,
          669,
          586,
          516,
          281,
          1190,
          452,
          10592,
          807,
          35410,
          294,
          1901,
          264,
          1882,
          72,
          51512
        ]
      },
      {
        "avg_logprob": -0.2101385824141964,
        "compression_ratio": 1.6872586872586872,
        "end": 2718.44,
        "id": 581,
        "no_speech_prob": 0.003123571164906025,
        "seek": 271148,
        "start": 2711.8,
        "temperature": 0,
        "text": " URL for making api queries is at bots in space bots in dot space slash api slash v1",
        "tokens": [
          50380,
          12905,
          337,
          1455,
          1882,
          72,
          24109,
          307,
          412,
          35410,
          294,
          1901,
          35410,
          294,
          5893,
          1901,
          17330,
          1882,
          72,
          17330,
          371,
          16,
          50712
        ]
      },
      {
        "avg_logprob": -0.2101385824141964,
        "compression_ratio": 1.6872586872586872,
        "end": 2722.6,
        "id": 582,
        "no_speech_prob": 0.003123571164906025,
        "seek": 271148,
        "start": 2718.52,
        "temperature": 0,
        "text": " Now maybe someday there'll be a v2 of the api a v3, but this should always work",
        "tokens": [
          50716,
          823,
          1310,
          19412,
          456,
          603,
          312,
          257,
          371,
          17,
          295,
          264,
          1882,
          72,
          257,
          371,
          18,
          11,
          457,
          341,
          820,
          1009,
          589,
          50920
        ]
      },
      {
        "avg_logprob": -0.2101385824141964,
        "compression_ratio": 1.6872586872586872,
        "end": 2725.4,
        "id": 583,
        "no_speech_prob": 0.003123571164906025,
        "seek": 271148,
        "start": 2723,
        "temperature": 0,
        "text": " Um, and now I just need to get that access token",
        "tokens": [
          50940,
          3301,
          11,
          293,
          586,
          286,
          445,
          643,
          281,
          483,
          300,
          2105,
          14862,
          51060
        ]
      },
      {
        "avg_logprob": -0.2101385824141964,
        "compression_ratio": 1.6872586872586872,
        "end": 2729.56,
        "id": 584,
        "no_speech_prob": 0.003123571164906025,
        "seek": 271148,
        "start": 2725.48,
        "temperature": 0,
        "text": " Which i'm throwing caution to the wind by the time you watch this video the access token will have changed",
        "tokens": [
          51064,
          3013,
          741,
          478,
          10238,
          23585,
          281,
          264,
          2468,
          538,
          264,
          565,
          291,
          1159,
          341,
          960,
          264,
          2105,
          14862,
          486,
          362,
          3105,
          51268
        ]
      },
      {
        "avg_logprob": -0.2101385824141964,
        "compression_ratio": 1.6872586872586872,
        "end": 2734.92,
        "id": 585,
        "no_speech_prob": 0.003123571164906025,
        "seek": 271148,
        "start": 2729.8,
        "temperature": 0,
        "text": " But just to show you um, i'm going to go back to here. I'm going to go to settings",
        "tokens": [
          51280,
          583,
          445,
          281,
          855,
          291,
          1105,
          11,
          741,
          478,
          516,
          281,
          352,
          646,
          281,
          510,
          13,
          286,
          478,
          516,
          281,
          352,
          281,
          6257,
          51536
        ]
      },
      {
        "avg_logprob": -0.2101385824141964,
        "compression_ratio": 1.6872586872586872,
        "end": 2738.68,
        "id": 586,
        "no_speech_prob": 0.003123571164906025,
        "seek": 271148,
        "start": 2735.64,
        "temperature": 0,
        "text": " That's fine. I'm going to go to um",
        "tokens": [
          51572,
          663,
          311,
          2489,
          13,
          286,
          478,
          516,
          281,
          352,
          281,
          1105,
          51724
        ]
      },
      {
        "avg_logprob": -0.28632255339286694,
        "compression_ratio": 1.5515151515151515,
        "end": 2747.24,
        "id": 587,
        "no_speech_prob": 0.000039442067645723,
        "seek": 273868,
        "start": 2739.64,
        "temperature": 0,
        "text": " Uh, where am I development a coding train example bot i'm going to grab the access token i'm going to paste it here",
        "tokens": [
          50412,
          4019,
          11,
          689,
          669,
          286,
          3250,
          257,
          17720,
          3847,
          1365,
          10592,
          741,
          478,
          516,
          281,
          4444,
          264,
          2105,
          14862,
          741,
          478,
          516,
          281,
          9163,
          309,
          510,
          50792
        ]
      },
      {
        "avg_logprob": -0.28632255339286694,
        "compression_ratio": 1.5515151515151515,
        "end": 2752.9199999999996,
        "id": 588,
        "no_speech_prob": 0.000039442067645723,
        "seek": 273868,
        "start": 2748.6,
        "temperature": 0,
        "text": " Uh, and then I think do you know, I'm pretty sure I need also the client",
        "tokens": [
          50860,
          4019,
          11,
          293,
          550,
          286,
          519,
          360,
          291,
          458,
          11,
          286,
          478,
          1238,
          988,
          286,
          643,
          611,
          264,
          6423,
          51076
        ]
      },
      {
        "avg_logprob": -0.28632255339286694,
        "compression_ratio": 1.5515151515151515,
        "end": 2755.7999999999997,
        "id": 589,
        "no_speech_prob": 0.000039442067645723,
        "seek": 273868,
        "start": 2753.7999999999997,
        "temperature": 0,
        "text": " uh secret",
        "tokens": [
          51120,
          2232,
          4054,
          51220
        ]
      },
      {
        "avg_logprob": -0.28632255339286694,
        "compression_ratio": 1.5515151515151515,
        "end": 2760.3599999999997,
        "id": 590,
        "no_speech_prob": 0.000039442067645723,
        "seek": 273868,
        "start": 2756.7599999999998,
        "temperature": 0,
        "text": " Which is this thing and uh",
        "tokens": [
          51268,
          3013,
          307,
          341,
          551,
          293,
          2232,
          51448
        ]
      },
      {
        "avg_logprob": -0.28632255339286694,
        "compression_ratio": 1.5515151515151515,
        "end": 2767.48,
        "id": 591,
        "no_speech_prob": 0.000039442067645723,
        "seek": 273868,
        "start": 2763.46,
        "temperature": 0,
        "text": " Client key which is this thing",
        "tokens": [
          51603,
          2033,
          1196,
          2141,
          597,
          307,
          341,
          551,
          51804
        ]
      },
      {
        "avg_logprob": -0.2083814257667178,
        "compression_ratio": 1.5082872928176796,
        "end": 2771.48,
        "id": 592,
        "no_speech_prob": 0.00005562011938309297,
        "seek": 276868,
        "start": 2769.48,
        "temperature": 0,
        "text": " And then now",
        "tokens": [
          50404,
          400,
          550,
          586,
          50504
        ]
      },
      {
        "avg_logprob": -0.2083814257667178,
        "compression_ratio": 1.5082872928176796,
        "end": 2778.52,
        "id": 593,
        "no_speech_prob": 0.00005562011938309297,
        "seek": 276868,
        "start": 2773.3199999999997,
        "temperature": 0,
        "text": " I should be all set and connected. So the next thing that I can do if i'm looking through this api",
        "tokens": [
          50596,
          286,
          820,
          312,
          439,
          992,
          293,
          4582,
          13,
          407,
          264,
          958,
          551,
          300,
          286,
          393,
          360,
          498,
          741,
          478,
          1237,
          807,
          341,
          1882,
          72,
          50856
        ]
      },
      {
        "avg_logprob": -0.2083814257667178,
        "compression_ratio": 1.5082872928176796,
        "end": 2781.16,
        "id": 594,
        "no_speech_prob": 0.00005562011938309297,
        "seek": 276868,
        "start": 2779.08,
        "temperature": 0,
        "text": " Um, oh, yeah, this is actually what I wanted to do",
        "tokens": [
          50884,
          3301,
          11,
          1954,
          11,
          1338,
          11,
          341,
          307,
          767,
          437,
          286,
          1415,
          281,
          360,
          50988
        ]
      },
      {
        "avg_logprob": -0.2083814257667178,
        "compression_ratio": 1.5082872928176796,
        "end": 2784.7599999999998,
        "id": 595,
        "no_speech_prob": 0.00005562011938309297,
        "seek": 276868,
        "start": 2782.12,
        "temperature": 0,
        "text": " Yeah, um is I can so now ah",
        "tokens": [
          51036,
          865,
          11,
          1105,
          307,
          286,
          393,
          370,
          586,
          3716,
          51168
        ]
      },
      {
        "avg_logprob": -0.2083814257667178,
        "compression_ratio": 1.5082872928176796,
        "end": 2788.04,
        "id": 596,
        "no_speech_prob": 0.00005562011938309297,
        "seek": 276868,
        "start": 2786.04,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51232,
          1033,
          51332
        ]
      },
      {
        "avg_logprob": -0.2083814257667178,
        "compression_ratio": 1.5082872928176796,
        "end": 2797.3999999999996,
        "id": 597,
        "no_speech_prob": 0.00005562011938309297,
        "seek": 276868,
        "start": 2791.72,
        "temperature": 0,
        "text": " I'm just pausing for a second because i'm seeing the chat. Um typo and secret",
        "tokens": [
          51516,
          286,
          478,
          445,
          2502,
          7981,
          337,
          257,
          1150,
          570,
          741,
          478,
          2577,
          264,
          5081,
          13,
          3301,
          2125,
          78,
          293,
          4054,
          51800
        ]
      },
      {
        "avg_logprob": -0.2620310677422418,
        "compression_ratio": 1.543956043956044,
        "end": 2801.08,
        "id": 598,
        "no_speech_prob": 0.00004469321356737055,
        "seek": 279868,
        "start": 2799.08,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50384,
          3301,
          50484
        ]
      },
      {
        "avg_logprob": -0.2620310677422418,
        "compression_ratio": 1.543956043956044,
        "end": 2808.7799999999997,
        "id": 599,
        "no_speech_prob": 0.00004469321356737055,
        "seek": 279868,
        "start": 2803.56,
        "temperature": 0,
        "text": " Um, oh I see that siraj is in the chat. Hello siraj and petros",
        "tokens": [
          50608,
          3301,
          11,
          1954,
          286,
          536,
          300,
          4735,
          1805,
          307,
          294,
          264,
          5081,
          13,
          2425,
          4735,
          1805,
          293,
          3817,
          2635,
          50869
        ]
      },
      {
        "avg_logprob": -0.2620310677422418,
        "compression_ratio": 1.543956043956044,
        "end": 2813.96,
        "id": 600,
        "no_speech_prob": 0.00004469321356737055,
        "seek": 279868,
        "start": 2811.96,
        "temperature": 0,
        "text": " My son's middle name is petros",
        "tokens": [
          51028,
          1222,
          1872,
          311,
          2808,
          1315,
          307,
          3817,
          2635,
          51128
        ]
      },
      {
        "avg_logprob": -0.2620310677422418,
        "compression_ratio": 1.543956043956044,
        "end": 2817.3199999999997,
        "id": 601,
        "no_speech_prob": 0.00004469321356737055,
        "seek": 279868,
        "start": 2815.08,
        "temperature": 0,
        "text": " I wrote secret. Okay. Thank you",
        "tokens": [
          51184,
          286,
          4114,
          907,
          81,
          302,
          13,
          1033,
          13,
          1044,
          291,
          51296
        ]
      },
      {
        "avg_logprob": -0.2620310677422418,
        "compression_ratio": 1.543956043956044,
        "end": 2820.6,
        "id": 602,
        "no_speech_prob": 0.00004469321356737055,
        "seek": 279868,
        "start": 2818.3599999999997,
        "temperature": 0,
        "text": " Uh, i'm being told that I wrote secret",
        "tokens": [
          51348,
          4019,
          11,
          741,
          478,
          885,
          1907,
          300,
          286,
          4114,
          4054,
          51460
        ]
      },
      {
        "avg_logprob": -0.2620310677422418,
        "compression_ratio": 1.543956043956044,
        "end": 2826.8399999999997,
        "id": 603,
        "no_speech_prob": 0.00004469321356737055,
        "seek": 279868,
        "start": 2821.56,
        "temperature": 0,
        "text": " So that should be secret. Thank you very much. All right. So here's the thing. Uh, we got to talk about something",
        "tokens": [
          51508,
          407,
          300,
          820,
          312,
          4054,
          13,
          1044,
          291,
          588,
          709,
          13,
          1057,
          558,
          13,
          407,
          510,
          311,
          264,
          551,
          13,
          4019,
          11,
          321,
          658,
          281,
          751,
          466,
          746,
          51772
        ]
      },
      {
        "avg_logprob": -0.20993753758872427,
        "compression_ratio": 1.7759562841530054,
        "end": 2834.1200000000003,
        "id": 604,
        "no_speech_prob": 0.00001644232906983234,
        "seek": 282684,
        "start": 2827.8,
        "temperature": 0,
        "text": " There are uh, three there are three core ways to engage with the mastodon api",
        "tokens": [
          50412,
          821,
          366,
          2232,
          11,
          1045,
          456,
          366,
          1045,
          4965,
          2098,
          281,
          4683,
          365,
          264,
          27055,
          378,
          266,
          1882,
          72,
          50728
        ]
      },
      {
        "avg_logprob": -0.20993753758872427,
        "compression_ratio": 1.7759562841530054,
        "end": 2839.08,
        "id": 605,
        "no_speech_prob": 0.00001644232906983234,
        "seek": 282684,
        "start": 2836.1200000000003,
        "temperature": 0,
        "text": " Sad to erase my beautifully decentralized diagram",
        "tokens": [
          50828,
          12269,
          281,
          23525,
          452,
          16525,
          32870,
          10686,
          50976
        ]
      },
      {
        "avg_logprob": -0.20993753758872427,
        "compression_ratio": 1.7759562841530054,
        "end": 2842.52,
        "id": 606,
        "no_speech_prob": 0.00001644232906983234,
        "seek": 282684,
        "start": 2839.96,
        "temperature": 0,
        "text": " There are three ways to engage with the mastodon api",
        "tokens": [
          51020,
          821,
          366,
          1045,
          2098,
          281,
          4683,
          365,
          264,
          27055,
          378,
          266,
          1882,
          72,
          51148
        ]
      },
      {
        "avg_logprob": -0.20993753758872427,
        "compression_ratio": 1.7759562841530054,
        "end": 2847.4,
        "id": 607,
        "no_speech_prob": 0.00001644232906983234,
        "seek": 282684,
        "start": 2843.48,
        "temperature": 0,
        "text": " And this is very similar to how twitter used to work and twitter doesn't work this way anymore",
        "tokens": [
          51196,
          400,
          341,
          307,
          588,
          2531,
          281,
          577,
          21439,
          1143,
          281,
          589,
          293,
          21439,
          1177,
          380,
          589,
          341,
          636,
          3602,
          51392
        ]
      },
      {
        "avg_logprob": -0.20993753758872427,
        "compression_ratio": 1.7759562841530054,
        "end": 2851.1600000000003,
        "id": 608,
        "no_speech_prob": 0.00001644232906983234,
        "seek": 282684,
        "start": 2847.56,
        "temperature": 0,
        "text": " But luckily for us mastodon does there is the get",
        "tokens": [
          51400,
          583,
          22880,
          337,
          505,
          27055,
          378,
          266,
          775,
          456,
          307,
          264,
          483,
          51580
        ]
      },
      {
        "avg_logprob": -0.22641665810032896,
        "compression_ratio": 1.6916299559471366,
        "end": 2854.2799999999997,
        "id": 609,
        "no_speech_prob": 0.00040447505307383835,
        "seek": 285116,
        "start": 2851.96,
        "temperature": 0,
        "text": " A get request is basically saying hey",
        "tokens": [
          50404,
          316,
          483,
          5308,
          307,
          1936,
          1566,
          4177,
          50520
        ]
      },
      {
        "avg_logprob": -0.22641665810032896,
        "compression_ratio": 1.6916299559471366,
        "end": 2860.04,
        "id": 610,
        "no_speech_prob": 0.00040447505307383835,
        "seek": 285116,
        "start": 2854.6,
        "temperature": 0,
        "text": " I would like to get a whole bunch of stuff like get me this list of user accounts get me this list of",
        "tokens": [
          50536,
          286,
          576,
          411,
          281,
          483,
          257,
          1379,
          3840,
          295,
          1507,
          411,
          483,
          385,
          341,
          1329,
          295,
          4195,
          9402,
          483,
          385,
          341,
          1329,
          295,
          50808
        ]
      },
      {
        "avg_logprob": -0.22641665810032896,
        "compression_ratio": 1.6916299559471366,
        "end": 2866.68,
        "id": 611,
        "no_speech_prob": 0.00040447505307383835,
        "seek": 285116,
        "start": 2860.6,
        "temperature": 0,
        "text": " Posts tooth statuses tweets, whatever you want to call them search for every toot that has the word mango in it",
        "tokens": [
          50836,
          10223,
          82,
          281,
          310,
          71,
          6558,
          279,
          25671,
          11,
          2035,
          291,
          528,
          281,
          818,
          552,
          3164,
          337,
          633,
          281,
          310,
          300,
          575,
          264,
          1349,
          23481,
          294,
          309,
          51140
        ]
      },
      {
        "avg_logprob": -0.22641665810032896,
        "compression_ratio": 1.6916299559471366,
        "end": 2869.64,
        "id": 612,
        "no_speech_prob": 0.00040447505307383835,
        "seek": 285116,
        "start": 2866.8399999999997,
        "temperature": 0,
        "text": " That's what get is for there is also post",
        "tokens": [
          51148,
          663,
          311,
          437,
          483,
          307,
          337,
          456,
          307,
          611,
          2183,
          51288
        ]
      },
      {
        "avg_logprob": -0.22641665810032896,
        "compression_ratio": 1.6916299559471366,
        "end": 2874.68,
        "id": 613,
        "no_speech_prob": 0.00040447505307383835,
        "seek": 285116,
        "start": 2870.2,
        "temperature": 0,
        "text": " I really should have written these in all capital letters post is for posting something to",
        "tokens": [
          51316,
          286,
          534,
          820,
          362,
          3720,
          613,
          294,
          439,
          4238,
          7825,
          2183,
          307,
          337,
          15978,
          746,
          281,
          51540
        ]
      },
      {
        "avg_logprob": -0.22658268817059404,
        "compression_ratio": 1.6077348066298343,
        "end": 2882.9199999999996,
        "id": 614,
        "no_speech_prob": 0.0002913684002123773,
        "seek": 287468,
        "start": 2875.22,
        "temperature": 0,
        "text": " Mastodon like for example, I want to post a new status or I want to follow or favorite or reblog something",
        "tokens": [
          50391,
          376,
          525,
          378,
          266,
          411,
          337,
          1365,
          11,
          286,
          528,
          281,
          2183,
          257,
          777,
          6558,
          420,
          286,
          528,
          281,
          1524,
          420,
          2954,
          420,
          12970,
          4987,
          746,
          50776
        ]
      },
      {
        "avg_logprob": -0.22658268817059404,
        "compression_ratio": 1.6077348066298343,
        "end": 2885,
        "id": 615,
        "no_speech_prob": 0.0002913684002123773,
        "seek": 287468,
        "start": 2883,
        "temperature": 0,
        "text": " All of those are posts",
        "tokens": [
          50780,
          1057,
          295,
          729,
          366,
          12300,
          50880
        ]
      },
      {
        "avg_logprob": -0.22658268817059404,
        "compression_ratio": 1.6077348066298343,
        "end": 2886.04,
        "id": 616,
        "no_speech_prob": 0.0002913684002123773,
        "seek": 287468,
        "start": 2885,
        "temperature": 0,
        "text": " and then",
        "tokens": [
          50880,
          293,
          550,
          50932
        ]
      },
      {
        "avg_logprob": -0.22658268817059404,
        "compression_ratio": 1.6077348066298343,
        "end": 2888.04,
        "id": 617,
        "no_speech_prob": 0.0002913684002123773,
        "seek": 287468,
        "start": 2886.04,
        "temperature": 0,
        "text": " There is what is really",
        "tokens": [
          50932,
          821,
          307,
          437,
          307,
          534,
          51032
        ]
      },
      {
        "avg_logprob": -0.22658268817059404,
        "compression_ratio": 1.6077348066298343,
        "end": 2894.68,
        "id": 618,
        "no_speech_prob": 0.0002913684002123773,
        "seek": 287468,
        "start": 2888.44,
        "temperature": 0,
        "text": " The exciting thing the streaming api the streaming api is a way for you to essentially have",
        "tokens": [
          51052,
          440,
          4670,
          551,
          264,
          11791,
          1882,
          72,
          264,
          11791,
          1882,
          72,
          307,
          257,
          636,
          337,
          291,
          281,
          4476,
          362,
          51364
        ]
      },
      {
        "avg_logprob": -0.22658268817059404,
        "compression_ratio": 1.6077348066298343,
        "end": 2897.56,
        "id": 619,
        "no_speech_prob": 0.0002913684002123773,
        "seek": 287468,
        "start": 2895.3199999999997,
        "temperature": 0,
        "text": " almost like a socket connection like",
        "tokens": [
          51396,
          1920,
          411,
          257,
          19741,
          4984,
          411,
          51508
        ]
      },
      {
        "avg_logprob": -0.20077181263130253,
        "compression_ratio": 1.7545126353790614,
        "end": 2903.4,
        "id": 620,
        "no_speech_prob": 0.005910796578973532,
        "seek": 289756,
        "start": 2898.2799999999997,
        "temperature": 0,
        "text": " A an attached connection to to mastodon where you're just listening for events",
        "tokens": [
          50400,
          316,
          364,
          8570,
          4984,
          281,
          281,
          27055,
          378,
          266,
          689,
          291,
          434,
          445,
          4764,
          337,
          3931,
          50656
        ]
      },
      {
        "avg_logprob": -0.20077181263130253,
        "compression_ratio": 1.7545126353790614,
        "end": 2907.4,
        "id": 621,
        "no_speech_prob": 0.005910796578973532,
        "seek": 289756,
        "start": 2903.64,
        "temperature": 0,
        "text": " So every time somebody follows somebody you'll get an event or every time somebody",
        "tokens": [
          50668,
          407,
          633,
          565,
          2618,
          10002,
          2618,
          291,
          603,
          483,
          364,
          2280,
          420,
          633,
          565,
          2618,
          50856
        ]
      },
      {
        "avg_logprob": -0.20077181263130253,
        "compression_ratio": 1.7545126353790614,
        "end": 2909.56,
        "id": 622,
        "no_speech_prob": 0.005910796578973532,
        "seek": 289756,
        "start": 2907.7999999999997,
        "temperature": 0,
        "text": " Posts the status you'll get an event",
        "tokens": [
          50876,
          10223,
          82,
          264,
          6558,
          291,
          603,
          483,
          364,
          2280,
          50964
        ]
      },
      {
        "avg_logprob": -0.20077181263130253,
        "compression_ratio": 1.7545126353790614,
        "end": 2915.32,
        "id": 623,
        "no_speech_prob": 0.005910796578973532,
        "seek": 289756,
        "start": 2909.56,
        "temperature": 0,
        "text": " So this is what's really powerful in the way that you can kind of engage with the service in a in a real-time",
        "tokens": [
          50964,
          407,
          341,
          307,
          437,
          311,
          534,
          4005,
          294,
          264,
          636,
          300,
          291,
          393,
          733,
          295,
          4683,
          365,
          264,
          2643,
          294,
          257,
          294,
          257,
          957,
          12,
          3766,
          51252
        ]
      },
      {
        "avg_logprob": -0.20077181263130253,
        "compression_ratio": 1.7545126353790614,
        "end": 2919.72,
        "id": 624,
        "no_speech_prob": 0.005910796578973532,
        "seek": 289756,
        "start": 2915.7799999999997,
        "temperature": 0,
        "text": " Synchronous way and unfortunately, this is a thing that twitter recently removed from their api",
        "tokens": [
          51275,
          26155,
          14613,
          563,
          636,
          293,
          7015,
          11,
          341,
          307,
          257,
          551,
          300,
          21439,
          3938,
          7261,
          490,
          641,
          1882,
          72,
          51472
        ]
      },
      {
        "avg_logprob": -0.20077181263130253,
        "compression_ratio": 1.7545126353790614,
        "end": 2923.72,
        "id": 625,
        "no_speech_prob": 0.005910796578973532,
        "seek": 289756,
        "start": 2919.72,
        "temperature": 0,
        "text": " And there's other ways to do the same exact thing, but it's a bit roundabout plus",
        "tokens": [
          51472,
          400,
          456,
          311,
          661,
          2098,
          281,
          360,
          264,
          912,
          1900,
          551,
          11,
          457,
          309,
          311,
          257,
          857,
          3098,
          21970,
          1804,
          51672
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2927.9599999999996,
        "id": 626,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2923.7999999999997,
        "temperature": 0,
        "text": " Good luck getting your bot approved from twitter or something that you can use there, okay",
        "tokens": [
          50368,
          2205,
          3668,
          1242,
          428,
          10592,
          10826,
          490,
          21439,
          420,
          746,
          300,
          291,
          393,
          764,
          456,
          11,
          1392,
          50576
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2934.2799999999997,
        "id": 627,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2929.16,
        "temperature": 0,
        "text": " So this in this video to test the first idea out. I just want to do a post",
        "tokens": [
          50636,
          407,
          341,
          294,
          341,
          960,
          281,
          1500,
          264,
          700,
          1558,
          484,
          13,
          286,
          445,
          528,
          281,
          360,
          257,
          2183,
          50892
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2936.52,
        "id": 628,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2934.52,
        "temperature": 0,
        "text": " So what I want to do is a post",
        "tokens": [
          50904,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          257,
          2183,
          51004
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2938.2,
        "id": 629,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2937.08,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51032,
          1033,
          51088
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2940.2,
        "id": 630,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2938.2,
        "temperature": 0,
        "text": " So coming back over here",
        "tokens": [
          51088,
          407,
          1348,
          646,
          670,
          510,
          51188
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2942.6,
        "id": 631,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2940.6,
        "temperature": 0,
        "text": " We can see this is what I have to do",
        "tokens": [
          51208,
          492,
          393,
          536,
          341,
          307,
          437,
          286,
          362,
          281,
          360,
          51308
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2945.24,
        "id": 632,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2943.24,
        "temperature": 0,
        "text": " a post",
        "tokens": [
          51340,
          257,
          2183,
          51440
        ]
      },
      {
        "avg_logprob": -0.1928128923688616,
        "compression_ratio": 1.65,
        "end": 2951.4199999999996,
        "id": 633,
        "no_speech_prob": 0.00023050523304846138,
        "seek": 292372,
        "start": 2945.56,
        "temperature": 0,
        "text": " With a some path now, what is the path? So now we need to look up mastodon api documentation",
        "tokens": [
          51456,
          2022,
          257,
          512,
          3100,
          586,
          11,
          437,
          307,
          264,
          3100,
          30,
          407,
          586,
          321,
          643,
          281,
          574,
          493,
          27055,
          378,
          266,
          1882,
          72,
          14333,
          51749
        ]
      },
      {
        "avg_logprob": -0.43772083282470703,
        "compression_ratio": 1.4796747967479675,
        "end": 2957.1800000000003,
        "id": 634,
        "no_speech_prob": 0.000245362869463861,
        "seek": 295142,
        "start": 2951.98,
        "temperature": 0,
        "text": " And we should be able to on this page here look under posts",
        "tokens": [
          50392,
          400,
          321,
          820,
          312,
          1075,
          281,
          322,
          341,
          3028,
          510,
          574,
          833,
          12300,
          50652
        ]
      },
      {
        "avg_logprob": -0.43772083282470703,
        "compression_ratio": 1.4796747967479675,
        "end": 2960.78,
        "id": 635,
        "no_speech_prob": 0.000245362869463861,
        "seek": 295142,
        "start": 2959.1800000000003,
        "temperature": 0,
        "text": " And we can see",
        "tokens": [
          50752,
          400,
          321,
          393,
          536,
          50832
        ]
      },
      {
        "avg_logprob": -0.43772083282470703,
        "compression_ratio": 1.4796747967479675,
        "end": 2965.9,
        "id": 636,
        "no_speech_prob": 0.000245362869463861,
        "seek": 295142,
        "start": 2960.78,
        "temperature": 0,
        "text": " I can this is a post for following something for blocking unblocking for muting",
        "tokens": [
          50832,
          286,
          393,
          341,
          307,
          257,
          2183,
          337,
          3480,
          746,
          337,
          17776,
          517,
          28830,
          278,
          337,
          5839,
          278,
          51088
        ]
      },
      {
        "avg_logprob": -0.43772083282470703,
        "compression_ratio": 1.4796747967479675,
        "end": 2968.96,
        "id": 637,
        "no_speech_prob": 0.000245362869463861,
        "seek": 295142,
        "start": 2966.46,
        "temperature": 0,
        "text": " But I want to post a status",
        "tokens": [
          51116,
          583,
          286,
          528,
          281,
          2183,
          257,
          6558,
          51241
        ]
      },
      {
        "avg_logprob": -0.44927379608154294,
        "compression_ratio": 1.6019900497512438,
        "end": 2983.9,
        "id": 638,
        "no_speech_prob": 0.00009027978376252577,
        "seek": 298142,
        "start": 2981.9,
        "temperature": 0,
        "text": " Hold on there we go",
        "tokens": [
          50388,
          6962,
          322,
          456,
          321,
          352,
          50488
        ]
      },
      {
        "avg_logprob": -0.44927379608154294,
        "compression_ratio": 1.6019900497512438,
        "end": 2990.38,
        "id": 639,
        "no_speech_prob": 0.00009027978376252577,
        "seek": 298142,
        "start": 2984.46,
        "temperature": 0,
        "text": " Sorry about that. This is where it is. I want to post a new status. So remember what is my api?",
        "tokens": [
          50516,
          4919,
          466,
          300,
          13,
          639,
          307,
          689,
          309,
          307,
          13,
          286,
          528,
          281,
          2183,
          257,
          777,
          6558,
          13,
          407,
          1604,
          437,
          307,
          452,
          1882,
          72,
          30,
          50812
        ]
      },
      {
        "avg_logprob": -0.44927379608154294,
        "compression_ratio": 1.6019900497512438,
        "end": 2997.26,
        "id": 640,
        "no_speech_prob": 0.00009027978376252577,
        "seek": 298142,
        "start": 2992.86,
        "temperature": 0,
        "text": " url it's this one so ultimately the end point that I want to go to is",
        "tokens": [
          50936,
          4038,
          75,
          309,
          311,
          341,
          472,
          370,
          6284,
          264,
          917,
          935,
          300,
          286,
          528,
          281,
          352,
          281,
          307,
          51156
        ]
      },
      {
        "avg_logprob": -0.44927379608154294,
        "compression_ratio": 1.6019900497512438,
        "end": 3000.62,
        "id": 641,
        "no_speech_prob": 0.00009027978376252577,
        "seek": 298142,
        "start": 2998.06,
        "temperature": 0,
        "text": " V1 statuses, but I don't do it here",
        "tokens": [
          51196,
          691,
          16,
          6558,
          279,
          11,
          457,
          286,
          500,
          380,
          360,
          309,
          510,
          51324
        ]
      },
      {
        "avg_logprob": -0.44927379608154294,
        "compression_ratio": 1.6019900497512438,
        "end": 3003.82,
        "id": 642,
        "no_speech_prob": 0.00009027978376252577,
        "seek": 298142,
        "start": 3001.42,
        "temperature": 0,
        "text": " The path I can put right here",
        "tokens": [
          51364,
          440,
          3100,
          286,
          393,
          829,
          558,
          510,
          51484
        ]
      },
      {
        "avg_logprob": -0.44927379608154294,
        "compression_ratio": 1.6019900497512438,
        "end": 3006.62,
        "id": 643,
        "no_speech_prob": 0.00009027978376252577,
        "seek": 298142,
        "start": 3004.62,
        "temperature": 0,
        "text": " statuses",
        "tokens": [
          51524,
          6558,
          279,
          51624
        ]
      },
      {
        "avg_logprob": -0.44927379608154294,
        "compression_ratio": 1.6019900497512438,
        "end": 3009.82,
        "id": 644,
        "no_speech_prob": 0.00009027978376252577,
        "seek": 298142,
        "start": 3006.62,
        "temperature": 0,
        "text": " Then I need some parameters and i'm going to put a new status",
        "tokens": [
          51624,
          1396,
          286,
          643,
          512,
          9834,
          293,
          741,
          478,
          516,
          281,
          829,
          257,
          777,
          6558,
          51784
        ]
      },
      {
        "avg_logprob": -0.2606177978515625,
        "compression_ratio": 1.6571428571428573,
        "end": 3012.54,
        "id": 645,
        "no_speech_prob": 0.00013982132077217102,
        "seek": 300982,
        "start": 3009.82,
        "temperature": 0,
        "text": " And I need some parameters and i'm going to put a callback",
        "tokens": [
          50364,
          400,
          286,
          643,
          512,
          9834,
          293,
          741,
          478,
          516,
          281,
          829,
          257,
          818,
          3207,
          50500
        ]
      },
      {
        "avg_logprob": -0.2606177978515625,
        "compression_ratio": 1.6571428571428573,
        "end": 3019.1800000000003,
        "id": 646,
        "no_speech_prob": 0.00013982132077217102,
        "seek": 300982,
        "start": 3013.1000000000004,
        "temperature": 0,
        "text": " Which I will use my fancy es6 arrow syntax that I have covered in other videos",
        "tokens": [
          50528,
          3013,
          286,
          486,
          764,
          452,
          10247,
          785,
          21,
          11610,
          28431,
          300,
          286,
          362,
          5343,
          294,
          661,
          2145,
          50832
        ]
      },
      {
        "avg_logprob": -0.2606177978515625,
        "compression_ratio": 1.6571428571428573,
        "end": 3022.94,
        "id": 647,
        "no_speech_prob": 0.00013982132077217102,
        "seek": 300982,
        "start": 3019.34,
        "temperature": 0,
        "text": " I'll come back to that in a second. So params, let's make that a separate variable",
        "tokens": [
          50840,
          286,
          603,
          808,
          646,
          281,
          300,
          294,
          257,
          1150,
          13,
          407,
          971,
          4070,
          11,
          718,
          311,
          652,
          300,
          257,
          4994,
          7006,
          51020
        ]
      },
      {
        "avg_logprob": -0.2606177978515625,
        "compression_ratio": 1.6571428571428573,
        "end": 3025.5800000000004,
        "id": 648,
        "no_speech_prob": 0.00013982132077217102,
        "seek": 300982,
        "start": 3023.5800000000004,
        "temperature": 0,
        "text": " It's a javascript object",
        "tokens": [
          51052,
          467,
          311,
          257,
          361,
          37331,
          5944,
          2657,
          51152
        ]
      },
      {
        "avg_logprob": -0.2606177978515625,
        "compression_ratio": 1.6571428571428573,
        "end": 3031.44,
        "id": 649,
        "no_speech_prob": 0.00013982132077217102,
        "seek": 300982,
        "start": 3026.1400000000003,
        "temperature": 0,
        "text": " So these params, this is super important. What are the parameters? Well, we can go back to the api documentation",
        "tokens": [
          51180,
          407,
          613,
          971,
          4070,
          11,
          341,
          307,
          1687,
          1021,
          13,
          708,
          366,
          264,
          9834,
          30,
          1042,
          11,
          321,
          393,
          352,
          646,
          281,
          264,
          1882,
          72,
          14333,
          51445
        ]
      },
      {
        "avg_logprob": -0.2606177978515625,
        "compression_ratio": 1.6571428571428573,
        "end": 3037.98,
        "id": 650,
        "no_speech_prob": 0.00013982132077217102,
        "seek": 300982,
        "start": 3032.2200000000003,
        "temperature": 0,
        "text": " And we can look here. They are I can say this is the status the text that I want to pose in reply to well",
        "tokens": [
          51484,
          400,
          321,
          393,
          574,
          510,
          13,
          814,
          366,
          286,
          393,
          584,
          341,
          307,
          264,
          6558,
          264,
          2487,
          300,
          286,
          528,
          281,
          10774,
          294,
          16972,
          281,
          731,
          51772
        ]
      },
      {
        "avg_logprob": -0.2844362750495832,
        "compression_ratio": 1.5991735537190082,
        "end": 3045.34,
        "id": 651,
        "no_speech_prob": 0.0005614705733023584,
        "seek": 303798,
        "start": 3038.54,
        "temperature": 0,
        "text": " Is it in reply to somebody a different an id of a different status media id is for images all sorts of stuff here language",
        "tokens": [
          50392,
          1119,
          309,
          294,
          16972,
          281,
          2618,
          257,
          819,
          364,
          4496,
          295,
          257,
          819,
          6558,
          3021,
          4496,
          307,
          337,
          5267,
          439,
          7527,
          295,
          1507,
          510,
          2856,
          50732
        ]
      },
      {
        "avg_logprob": -0.2844362750495832,
        "compression_ratio": 1.5991735537190082,
        "end": 3049.26,
        "id": 652,
        "no_speech_prob": 0.0005614705733023584,
        "seek": 303798,
        "start": 3045.42,
        "temperature": 0,
        "text": " Is it sensitive content? There's all sorts of things, but basically i'm just going to say",
        "tokens": [
          50736,
          1119,
          309,
          9477,
          2701,
          30,
          821,
          311,
          439,
          7527,
          295,
          721,
          11,
          457,
          1936,
          741,
          478,
          445,
          516,
          281,
          584,
          50928
        ]
      },
      {
        "avg_logprob": -0.2844362750495832,
        "compression_ratio": 1.5991735537190082,
        "end": 3052.86,
        "id": 653,
        "no_speech_prob": 0.0005614705733023584,
        "seek": 303798,
        "start": 3050.86,
        "temperature": 0,
        "text": " Status",
        "tokens": [
          51008,
          47409,
          51108
        ]
      },
      {
        "avg_logprob": -0.2844362750495832,
        "compression_ratio": 1.5991735537190082,
        "end": 3061.98,
        "id": 654,
        "no_speech_prob": 0.0005614705733023584,
        "seek": 303798,
        "start": 3055.26,
        "temperature": 0,
        "text": " And there we go, why why did you format yourself like this what kind of crazy indentation is that this isn't right",
        "tokens": [
          51228,
          400,
          456,
          321,
          352,
          11,
          983,
          983,
          630,
          291,
          7877,
          1803,
          411,
          341,
          437,
          733,
          295,
          3219,
          44494,
          399,
          307,
          300,
          341,
          1943,
          380,
          558,
          51564
        ]
      },
      {
        "avg_logprob": -0.2844362750495832,
        "compression_ratio": 1.5991735537190082,
        "end": 3064.62,
        "id": 655,
        "no_speech_prob": 0.0005614705733023584,
        "seek": 303798,
        "start": 3062.06,
        "temperature": 0,
        "text": " I'm gonna have to deal with that later. Okay, so now",
        "tokens": [
          51568,
          286,
          478,
          799,
          362,
          281,
          2028,
          365,
          300,
          1780,
          13,
          1033,
          11,
          370,
          586,
          51696
        ]
      },
      {
        "avg_logprob": -0.25314339438637534,
        "compression_ratio": 1.6040609137055837,
        "end": 3071.1,
        "id": 656,
        "no_speech_prob": 0.002434356138110161,
        "seek": 306462,
        "start": 3065.3399999999997,
        "temperature": 0,
        "text": " And then in the callback, what do I get I probably it's probably like error first callbacks i'm guessing",
        "tokens": [
          50400,
          400,
          550,
          294,
          264,
          818,
          3207,
          11,
          437,
          360,
          286,
          483,
          286,
          1391,
          309,
          311,
          1391,
          411,
          6713,
          700,
          818,
          17758,
          741,
          478,
          17939,
          50688
        ]
      },
      {
        "avg_logprob": -0.25314339438637534,
        "compression_ratio": 1.6040609137055837,
        "end": 3075.5,
        "id": 657,
        "no_speech_prob": 0.002434356138110161,
        "seek": 306462,
        "start": 3071.66,
        "temperature": 0,
        "text": " Error data i'm going to do this. So let's just do say like if error",
        "tokens": [
          50716,
          3300,
          2874,
          1412,
          741,
          478,
          516,
          281,
          360,
          341,
          13,
          407,
          718,
          311,
          445,
          360,
          584,
          411,
          498,
          6713,
          50908
        ]
      },
      {
        "avg_logprob": -0.25314339438637534,
        "compression_ratio": 1.6040609137055837,
        "end": 3078.38,
        "id": 658,
        "no_speech_prob": 0.002434356138110161,
        "seek": 306462,
        "start": 3076.2799999999997,
        "temperature": 0,
        "text": " console dot error error",
        "tokens": [
          50947,
          11076,
          5893,
          6713,
          6713,
          51052
        ]
      },
      {
        "avg_logprob": -0.25314339438637534,
        "compression_ratio": 1.6040609137055837,
        "end": 3082.2999999999997,
        "id": 659,
        "no_speech_prob": 0.002434356138110161,
        "seek": 306462,
        "start": 3080.2999999999997,
        "temperature": 0,
        "text": " And then otherwise",
        "tokens": [
          51148,
          400,
          550,
          5911,
          51248
        ]
      },
      {
        "avg_logprob": -0.25314339438637534,
        "compression_ratio": 1.6040609137055837,
        "end": 3085.9,
        "id": 660,
        "no_speech_prob": 0.002434356138110161,
        "seek": 306462,
        "start": 3082.7799999999997,
        "temperature": 0,
        "text": " Uh console dot log data. Okay",
        "tokens": [
          51272,
          4019,
          11076,
          5893,
          3565,
          1412,
          13,
          1033,
          51428
        ]
      },
      {
        "avg_logprob": -0.25314339438637534,
        "compression_ratio": 1.6040609137055837,
        "end": 3089.18,
        "id": 661,
        "no_speech_prob": 0.002434356138110161,
        "seek": 306462,
        "start": 3086.54,
        "temperature": 0,
        "text": " So now here we go. I have my code",
        "tokens": [
          51460,
          407,
          586,
          510,
          321,
          352,
          13,
          286,
          362,
          452,
          3089,
          51592
        ]
      },
      {
        "avg_logprob": -0.25314339438637534,
        "compression_ratio": 1.6040609137055837,
        "end": 3092.06,
        "id": 662,
        "no_speech_prob": 0.002434356138110161,
        "seek": 306462,
        "start": 3090.06,
        "temperature": 0,
        "text": " Right. I started the bot I connected",
        "tokens": [
          51636,
          1779,
          13,
          286,
          1409,
          264,
          10592,
          286,
          4582,
          51736
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3094.7,
        "id": 663,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3092.7,
        "temperature": 0,
        "text": " Here's all my secret information",
        "tokens": [
          50396,
          1692,
          311,
          439,
          452,
          4054,
          1589,
          50496
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3097.82,
        "id": 664,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3094.7,
        "temperature": 0,
        "text": " Credit card number and social security number is embedded in there somewhere",
        "tokens": [
          50496,
          36006,
          2920,
          1230,
          293,
          2093,
          3825,
          1230,
          307,
          16741,
          294,
          456,
          4079,
          50652
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3102.94,
        "id": 665,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3098.14,
        "temperature": 0,
        "text": " Here's my status that I want to post and there we go. And hopefully nobody's already hacked my account",
        "tokens": [
          50668,
          1692,
          311,
          452,
          6558,
          300,
          286,
          528,
          281,
          2183,
          293,
          456,
          321,
          352,
          13,
          400,
          4696,
          5079,
          311,
          1217,
          36218,
          452,
          2696,
          50908
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3105.66,
        "id": 666,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3103.58,
        "temperature": 0,
        "text": " And posted stuff. So let's go look over here",
        "tokens": [
          50940,
          400,
          9437,
          1507,
          13,
          407,
          718,
          311,
          352,
          574,
          670,
          510,
          51044
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3110.94,
        "id": 667,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3107.2599999999998,
        "temperature": 0,
        "text": " Okay, wait, no i'm in the wrong account where did I got to go to bots in space",
        "tokens": [
          51124,
          1033,
          11,
          1699,
          11,
          572,
          741,
          478,
          294,
          264,
          2085,
          2696,
          689,
          630,
          286,
          658,
          281,
          352,
          281,
          35410,
          294,
          1901,
          51308
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3114.38,
        "id": 668,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3112.38,
        "temperature": 0,
        "text": " Uh, and I got to go to my profile",
        "tokens": [
          51380,
          4019,
          11,
          293,
          286,
          658,
          281,
          352,
          281,
          452,
          7964,
          51480
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3117.5,
        "id": 669,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3115.18,
        "temperature": 0,
        "text": " Which isn't anything yet somewhere. It'll show up here",
        "tokens": [
          51520,
          3013,
          1943,
          380,
          1340,
          1939,
          4079,
          13,
          467,
          603,
          855,
          493,
          510,
          51636
        ]
      },
      {
        "avg_logprob": -0.2081621816335631,
        "compression_ratio": 1.643884892086331,
        "end": 3120.14,
        "id": 670,
        "no_speech_prob": 0.0011695001740008593,
        "seek": 309206,
        "start": 3118.14,
        "temperature": 0,
        "text": " Where's my profile? Is this me?",
        "tokens": [
          51668,
          2305,
          311,
          452,
          7964,
          30,
          1119,
          341,
          385,
          30,
          51768
        ]
      },
      {
        "avg_logprob": -0.37262771747730394,
        "compression_ratio": 1.6348547717842323,
        "end": 3123.1,
        "id": 671,
        "no_speech_prob": 0.0001795275165932253,
        "seek": 312014,
        "start": 3120.46,
        "temperature": 0,
        "text": " That's local who knows okay, let's run this code",
        "tokens": [
          50380,
          663,
          311,
          2654,
          567,
          3255,
          1392,
          11,
          718,
          311,
          1190,
          341,
          3089,
          50512
        ]
      },
      {
        "avg_logprob": -0.37262771747730394,
        "compression_ratio": 1.6348547717842323,
        "end": 3131.18,
        "id": 672,
        "no_speech_prob": 0.0001795275165932253,
        "seek": 312014,
        "start": 3125.58,
        "temperature": 0,
        "text": " Uh node bot.js, okay, we got an error mastodon is not defined. Why is mastodon not defined?",
        "tokens": [
          50636,
          4019,
          9984,
          10592,
          13,
          25530,
          11,
          1392,
          11,
          321,
          658,
          364,
          6713,
          27055,
          378,
          266,
          307,
          406,
          7642,
          13,
          1545,
          307,
          27055,
          378,
          266,
          406,
          7642,
          30,
          50916
        ]
      },
      {
        "avg_logprob": -0.37262771747730394,
        "compression_ratio": 1.6348547717842323,
        "end": 3137.1,
        "id": 673,
        "no_speech_prob": 0.0001795275165932253,
        "seek": 312014,
        "start": 3131.74,
        "temperature": 0,
        "text": " Because I used a capital down here and I didn't use a capital up here. So this mastodon",
        "tokens": [
          50944,
          1436,
          286,
          1143,
          257,
          4238,
          760,
          510,
          293,
          286,
          994,
          380,
          764,
          257,
          4238,
          493,
          510,
          13,
          407,
          341,
          27055,
          378,
          266,
          51212
        ]
      },
      {
        "avg_logprob": -0.37262771747730394,
        "compression_ratio": 1.6348547717842323,
        "end": 3142.54,
        "id": 674,
        "no_speech_prob": 0.0001795275165932253,
        "seek": 312014,
        "start": 3138.22,
        "temperature": 0,
        "text": " Importing the whole library is now a function that I can call to connect. So let's try this again",
        "tokens": [
          51268,
          26391,
          278,
          264,
          1379,
          6405,
          307,
          586,
          257,
          2445,
          300,
          286,
          393,
          818,
          281,
          1745,
          13,
          407,
          718,
          311,
          853,
          341,
          797,
          51484
        ]
      },
      {
        "avg_logprob": -0.37262771747730394,
        "compression_ratio": 1.6348547717842323,
        "end": 3147.9,
        "id": 675,
        "no_speech_prob": 0.0001795275165932253,
        "seek": 312014,
        "start": 3144.2999999999997,
        "temperature": 0,
        "text": " Oh that seemed to have worked except it didn't console log anything",
        "tokens": [
          51572,
          876,
          300,
          6576,
          281,
          362,
          2732,
          3993,
          309,
          994,
          380,
          11076,
          3565,
          1340,
          51752
        ]
      },
      {
        "avg_logprob": -0.5004047578380953,
        "compression_ratio": 1.4402985074626866,
        "end": 3150.3,
        "id": 676,
        "no_speech_prob": 0.00038596312515437603,
        "seek": 314790,
        "start": 3148.3,
        "temperature": 0,
        "text": " How do I tell if I",
        "tokens": [
          50384,
          1012,
          360,
          286,
          980,
          498,
          286,
          50484
        ]
      },
      {
        "avg_logprob": -0.5004047578380953,
        "compression_ratio": 1.4402985074626866,
        "end": 3158.2200000000003,
        "id": 677,
        "no_speech_prob": 0.00038596312515437603,
        "seek": 314790,
        "start": 3155.42,
        "temperature": 0,
        "text": " That didn't seem to work hold on time out for a second",
        "tokens": [
          50740,
          663,
          994,
          380,
          1643,
          281,
          589,
          1797,
          322,
          565,
          484,
          337,
          257,
          1150,
          50880
        ]
      },
      {
        "avg_logprob": -0.5004047578380953,
        "compression_ratio": 1.4402985074626866,
        "end": 3167.1,
        "id": 678,
        "no_speech_prob": 0.00038596312515437603,
        "seek": 314790,
        "start": 3163.7400000000002,
        "temperature": 0,
        "text": " I did path of status not statuses. Okay, so",
        "tokens": [
          51156,
          286,
          630,
          3100,
          295,
          6558,
          406,
          6558,
          279,
          13,
          1033,
          11,
          370,
          51324
        ]
      },
      {
        "avg_logprob": -0.5004047578380953,
        "compression_ratio": 1.4402985074626866,
        "end": 3173.34,
        "id": 679,
        "no_speech_prob": 0.00038596312515437603,
        "seek": 314790,
        "start": 3168.78,
        "temperature": 0,
        "text": " So that didn't work. All right. So how am I going that didn't seem to work?",
        "tokens": [
          51408,
          407,
          300,
          994,
          380,
          589,
          13,
          1057,
          558,
          13,
          407,
          577,
          669,
          286,
          516,
          300,
          994,
          380,
          1643,
          281,
          589,
          30,
          51636
        ]
      },
      {
        "avg_logprob": -0.4925800216532199,
        "compression_ratio": 1.8251121076233183,
        "end": 3179.6600000000003,
        "id": 680,
        "no_speech_prob": 0.0030753088649362326,
        "seek": 317334,
        "start": 3173.58,
        "temperature": 0,
        "text": " Thank you to wilbur in the chat who just told me that I actually put the wrong path here to the api",
        "tokens": [
          50376,
          1044,
          291,
          281,
          20501,
          13243,
          294,
          264,
          5081,
          567,
          445,
          1907,
          385,
          300,
          286,
          767,
          829,
          264,
          2085,
          3100,
          510,
          281,
          264,
          1882,
          72,
          50680
        ]
      },
      {
        "avg_logprob": -0.4925800216532199,
        "compression_ratio": 1.8251121076233183,
        "end": 3185.58,
        "id": 681,
        "no_speech_prob": 0.0030753088649362326,
        "seek": 317334,
        "start": 3180.2200000000003,
        "temperature": 0,
        "text": " So if I go back to the api documentation, you can see the path the endpoint is statuses plural",
        "tokens": [
          50708,
          407,
          498,
          286,
          352,
          646,
          281,
          264,
          1882,
          72,
          14333,
          11,
          291,
          393,
          536,
          264,
          3100,
          264,
          35795,
          307,
          6558,
          279,
          25377,
          50976
        ]
      },
      {
        "avg_logprob": -0.4925800216532199,
        "compression_ratio": 1.8251121076233183,
        "end": 3188.3,
        "id": 682,
        "no_speech_prob": 0.0030753088649362326,
        "seek": 317334,
        "start": 3186.3,
        "temperature": 0,
        "text": " So let's try this one more time",
        "tokens": [
          51012,
          407,
          718,
          311,
          853,
          341,
          472,
          544,
          565,
          51112
        ]
      },
      {
        "avg_logprob": -0.4925800216532199,
        "compression_ratio": 1.8251121076233183,
        "end": 3190.2200000000003,
        "id": 683,
        "no_speech_prob": 0.0030753088649362326,
        "seek": 317334,
        "start": 3188.92,
        "temperature": 0,
        "text": " statuses",
        "tokens": [
          51143,
          6558,
          279,
          51208
        ]
      },
      {
        "avg_logprob": -0.4925800216532199,
        "compression_ratio": 1.8251121076233183,
        "end": 3192.2200000000003,
        "id": 684,
        "no_speech_prob": 0.0030753088649362326,
        "seek": 317334,
        "start": 3190.2200000000003,
        "temperature": 0,
        "text": " And now let me run this again",
        "tokens": [
          51208,
          400,
          586,
          718,
          385,
          1190,
          341,
          797,
          51308
        ]
      },
      {
        "avg_logprob": -0.4925800216532199,
        "compression_ratio": 1.8251121076233183,
        "end": 3197.1800000000003,
        "id": 685,
        "no_speech_prob": 0.0030753088649362326,
        "seek": 317334,
        "start": 3192.94,
        "temperature": 0,
        "text": " Ah, look and we can see we got all this metadata back because it was successful",
        "tokens": [
          51344,
          2438,
          11,
          574,
          293,
          321,
          393,
          536,
          321,
          658,
          439,
          341,
          26603,
          646,
          570,
          309,
          390,
          4406,
          51556
        ]
      },
      {
        "avg_logprob": -0.4925800216532199,
        "compression_ratio": 1.8251121076233183,
        "end": 3200.2200000000003,
        "id": 686,
        "no_speech_prob": 0.0030753088649362326,
        "seek": 317334,
        "start": 3197.5,
        "temperature": 0,
        "text": " It was successful and it was successful and it was successful",
        "tokens": [
          51572,
          467,
          390,
          4406,
          293,
          309,
          390,
          4406,
          293,
          309,
          390,
          4406,
          51708
        ]
      },
      {
        "avg_logprob": -0.22194342777646822,
        "compression_ratio": 1.5226130653266332,
        "end": 3205.66,
        "id": 687,
        "no_speech_prob": 0.004905339330434799,
        "seek": 320022,
        "start": 3200.22,
        "temperature": 0,
        "text": " All this metadata back because it was successful if I go back here if I go to bots in space",
        "tokens": [
          50364,
          1057,
          341,
          26603,
          646,
          570,
          309,
          390,
          4406,
          498,
          286,
          352,
          646,
          510,
          498,
          286,
          352,
          281,
          35410,
          294,
          1901,
          50636
        ]
      },
      {
        "avg_logprob": -0.22194342777646822,
        "compression_ratio": 1.5226130653266332,
        "end": 3207.74,
        "id": 688,
        "no_speech_prob": 0.004905339330434799,
        "seek": 320022,
        "start": 3205.74,
        "temperature": 0,
        "text": " Look at that. There we are",
        "tokens": [
          50640,
          2053,
          412,
          300,
          13,
          821,
          321,
          366,
          50740
        ]
      },
      {
        "avg_logprob": -0.22194342777646822,
        "compression_ratio": 1.5226130653266332,
        "end": 3211.8999999999996,
        "id": 689,
        "no_speech_prob": 0.004905339330434799,
        "seek": 320022,
        "start": 3209.98,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50852,
          1033,
          50948
        ]
      },
      {
        "avg_logprob": -0.22194342777646822,
        "compression_ratio": 1.5226130653266332,
        "end": 3213.3399999999997,
        "id": 690,
        "no_speech_prob": 0.004905339330434799,
        "seek": 320022,
        "start": 3211.8999999999996,
        "temperature": 0,
        "text": " We did it",
        "tokens": [
          50948,
          492,
          630,
          309,
          51020
        ]
      },
      {
        "avg_logprob": -0.22194342777646822,
        "compression_ratio": 1.5226130653266332,
        "end": 3219.02,
        "id": 691,
        "no_speech_prob": 0.004905339330434799,
        "seek": 320022,
        "start": 3213.3399999999997,
        "temperature": 0,
        "text": " We successfully made our first mastodon bot that is posting just from",
        "tokens": [
          51020,
          492,
          10727,
          1027,
          527,
          700,
          27055,
          378,
          266,
          10592,
          300,
          307,
          15978,
          445,
          490,
          51304
        ]
      },
      {
        "avg_logprob": -0.22194342777646822,
        "compression_ratio": 1.5226130653266332,
        "end": 3223.3399999999997,
        "id": 692,
        "no_speech_prob": 0.004905339330434799,
        "seek": 320022,
        "start": 3221.3399999999997,
        "temperature": 0,
        "text": " Just from the node",
        "tokens": [
          51420,
          1449,
          490,
          264,
          9984,
          51520
        ]
      },
      {
        "avg_logprob": -0.22194342777646822,
        "compression_ratio": 1.5226130653266332,
        "end": 3226.9399999999996,
        "id": 693,
        "no_speech_prob": 0.004905339330434799,
        "seek": 320022,
        "start": 3223.66,
        "temperature": 0,
        "text": " Directly to mastodon. Okay, so there's a few things that I want to show you next",
        "tokens": [
          51536,
          18308,
          356,
          281,
          27055,
          378,
          266,
          13,
          1033,
          11,
          370,
          456,
          311,
          257,
          1326,
          721,
          300,
          286,
          528,
          281,
          855,
          291,
          958,
          51700
        ]
      },
      {
        "avg_logprob": -0.20237016116871553,
        "compression_ratio": 1.7333333333333334,
        "end": 3233.66,
        "id": 694,
        "no_speech_prob": 0.000024682709408807568,
        "seek": 322694,
        "start": 3227.42,
        "temperature": 0,
        "text": " I would like to show you number one is how to effectively hide your you can open source your bot but still hide your",
        "tokens": [
          50388,
          286,
          576,
          411,
          281,
          855,
          291,
          1230,
          472,
          307,
          577,
          281,
          8659,
          6479,
          428,
          291,
          393,
          1269,
          4009,
          428,
          10592,
          457,
          920,
          6479,
          428,
          50700
        ]
      },
      {
        "avg_logprob": -0.20237016116871553,
        "compression_ratio": 1.7333333333333334,
        "end": 3238.3,
        "id": 695,
        "no_speech_prob": 0.000024682709408807568,
        "seek": 322694,
        "start": 3234.7000000000003,
        "temperature": 0,
        "text": " Your client secret client code all that sort of stuff. So I want to show you that",
        "tokens": [
          50752,
          2260,
          6423,
          4054,
          6423,
          3089,
          439,
          300,
          1333,
          295,
          1507,
          13,
          407,
          286,
          528,
          281,
          855,
          291,
          300,
          50932
        ]
      },
      {
        "avg_logprob": -0.20237016116871553,
        "compression_ratio": 1.7333333333333334,
        "end": 3240.86,
        "id": 696,
        "no_speech_prob": 0.000024682709408807568,
        "seek": 322694,
        "start": 3238.86,
        "temperature": 0,
        "text": " And also we'll just look at some of the other",
        "tokens": [
          50960,
          400,
          611,
          321,
          603,
          445,
          574,
          412,
          512,
          295,
          264,
          661,
          51060
        ]
      },
      {
        "avg_logprob": -0.20237016116871553,
        "compression_ratio": 1.7333333333333334,
        "end": 3243.16,
        "id": 697,
        "no_speech_prob": 0.000024682709408807568,
        "seek": 322694,
        "start": 3241.16,
        "temperature": 0,
        "text": " parameters for um",
        "tokens": [
          51075,
          9834,
          337,
          1105,
          51175
        ]
      },
      {
        "avg_logprob": -0.20237016116871553,
        "compression_ratio": 1.7333333333333334,
        "end": 3245.66,
        "id": 698,
        "no_speech_prob": 0.000024682709408807568,
        "seek": 322694,
        "start": 3243.66,
        "temperature": 0,
        "text": " some of the other parameters for",
        "tokens": [
          51200,
          512,
          295,
          264,
          661,
          9834,
          337,
          51300
        ]
      },
      {
        "avg_logprob": -0.20237016116871553,
        "compression_ratio": 1.7333333333333334,
        "end": 3247.7200000000003,
        "id": 699,
        "no_speech_prob": 0.000024682709408807568,
        "seek": 322694,
        "start": 3245.7200000000003,
        "temperature": 0,
        "text": " posting",
        "tokens": [
          51303,
          15978,
          51403
        ]
      },
      {
        "avg_logprob": -0.20237016116871553,
        "compression_ratio": 1.7333333333333334,
        "end": 3254.2200000000003,
        "id": 700,
        "no_speech_prob": 0.000024682709408807568,
        "seek": 322694,
        "start": 3252.2200000000003,
        "temperature": 0,
        "text": " I'm getting a lot of notifications",
        "tokens": [
          51628,
          286,
          478,
          1242,
          257,
          688,
          295,
          13426,
          51728
        ]
      },
      {
        "avg_logprob": -0.332892817835654,
        "compression_ratio": 1.441860465116279,
        "end": 3261.52,
        "id": 701,
        "no_speech_prob": 0.00013341859448701143,
        "seek": 325694,
        "start": 3257.82,
        "temperature": 0,
        "text": " That sound you're hearing is the mastodon notification",
        "tokens": [
          50408,
          663,
          1626,
          291,
          434,
          4763,
          307,
          264,
          27055,
          378,
          266,
          11554,
          50593
        ]
      },
      {
        "avg_logprob": -0.332892817835654,
        "compression_ratio": 1.441860465116279,
        "end": 3265.18,
        "id": 702,
        "no_speech_prob": 0.00013341859448701143,
        "seek": 325694,
        "start": 3262.2200000000003,
        "temperature": 0,
        "text": " Where are we three? How did it get to be 326?",
        "tokens": [
          50628,
          2305,
          366,
          321,
          1045,
          30,
          1012,
          630,
          309,
          483,
          281,
          312,
          8858,
          21,
          30,
          50776
        ]
      },
      {
        "avg_logprob": -0.332892817835654,
        "compression_ratio": 1.441860465116279,
        "end": 3269.9,
        "id": 703,
        "no_speech_prob": 0.00013341859448701143,
        "seek": 325694,
        "start": 3265.9,
        "temperature": 0,
        "text": " Jeez louise. Oh, no, but I have to I started at 230. I thought I started at two",
        "tokens": [
          50812,
          48516,
          15185,
          908,
          13,
          876,
          11,
          572,
          11,
          457,
          286,
          362,
          281,
          286,
          1409,
          412,
          35311,
          13,
          286,
          1194,
          286,
          1409,
          412,
          732,
          51012
        ]
      },
      {
        "avg_logprob": -0.332892817835654,
        "compression_ratio": 1.441860465116279,
        "end": 3272.54,
        "id": 704,
        "no_speech_prob": 0.00013341859448701143,
        "seek": 325694,
        "start": 3270.54,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51044,
          1033,
          51144
        ]
      },
      {
        "avg_logprob": -0.332892817835654,
        "compression_ratio": 1.441860465116279,
        "end": 3278.46,
        "id": 705,
        "no_speech_prob": 0.00013341859448701143,
        "seek": 325694,
        "start": 3276.46,
        "temperature": 0,
        "text": " I like this",
        "tokens": [
          51340,
          286,
          411,
          341,
          51440
        ]
      },
      {
        "avg_logprob": -0.332892817835654,
        "compression_ratio": 1.441860465116279,
        "end": 3283.68,
        "id": 706,
        "no_speech_prob": 0.00013341859448701143,
        "seek": 325694,
        "start": 3278.78,
        "temperature": 0,
        "text": " All right, I got to do a couple things number one, I'm sorry all of you who like your four spaces of indentation",
        "tokens": [
          51456,
          1057,
          558,
          11,
          286,
          658,
          281,
          360,
          257,
          1916,
          721,
          1230,
          472,
          11,
          286,
          478,
          2597,
          439,
          295,
          291,
          567,
          411,
          428,
          1451,
          7673,
          295,
          44494,
          399,
          51701
        ]
      },
      {
        "avg_logprob": -0.26387206486293246,
        "compression_ratio": 1.2717391304347827,
        "end": 3287.8399999999997,
        "id": 707,
        "no_speech_prob": 0.0005792806041426957,
        "seek": 328368,
        "start": 3284.56,
        "temperature": 0,
        "text": " Um, I don't know where that happened",
        "tokens": [
          50408,
          3301,
          11,
          286,
          500,
          380,
          458,
          689,
          300,
          2011,
          50572
        ]
      },
      {
        "avg_logprob": -0.26387206486293246,
        "compression_ratio": 1.2717391304347827,
        "end": 3292.24,
        "id": 708,
        "no_speech_prob": 0.0005792806041426957,
        "seek": 328368,
        "start": 3290.24,
        "temperature": 0,
        "text": " How that got changed",
        "tokens": [
          50692,
          1012,
          300,
          658,
          3105,
          50792
        ]
      },
      {
        "avg_logprob": -0.26387206486293246,
        "compression_ratio": 1.2717391304347827,
        "end": 3302.8999999999996,
        "id": 709,
        "no_speech_prob": 0.0005792806041426957,
        "seek": 328368,
        "start": 3295.7599999999998,
        "temperature": 0,
        "text": " Um in my where did that get changed but I can't tolerate it",
        "tokens": [
          50968,
          3301,
          294,
          452,
          689,
          630,
          300,
          483,
          3105,
          457,
          286,
          393,
          380,
          25773,
          309,
          51325
        ]
      },
      {
        "avg_logprob": -0.5756719939562739,
        "compression_ratio": 1.2542372881355932,
        "end": 3305.14,
        "id": 710,
        "no_speech_prob": 0.0002780286886263639,
        "seek": 330290,
        "start": 3303.14,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50376,
          3301,
          50476
        ]
      },
      {
        "avg_logprob": -0.5756719939562739,
        "compression_ratio": 1.2542372881355932,
        "end": 3312.84,
        "id": 711,
        "no_speech_prob": 0.0002780286886263639,
        "seek": 330290,
        "start": 3310.34,
        "temperature": 0,
        "text": " Where where are these things? Let's hold on",
        "tokens": [
          50736,
          2305,
          689,
          366,
          613,
          721,
          30,
          961,
          311,
          1797,
          322,
          50861
        ]
      },
      {
        "avg_logprob": -0.5756719939562739,
        "compression_ratio": 1.2542372881355932,
        "end": 3322.26,
        "id": 712,
        "no_speech_prob": 0.0002780286886263639,
        "seek": 330290,
        "start": 3319.94,
        "temperature": 0,
        "text": " Setting is closer to the top. Okay",
        "tokens": [
          51216,
          21063,
          307,
          4966,
          281,
          264,
          1192,
          13,
          1033,
          51332
        ]
      },
      {
        "avg_logprob": -0.5756719939562739,
        "compression_ratio": 1.2542372881355932,
        "end": 3326.02,
        "id": 713,
        "no_speech_prob": 0.0002780286886263639,
        "seek": 330290,
        "start": 3324.02,
        "temperature": 0,
        "text": " Font size. Ah, there we go",
        "tokens": [
          51420,
          43901,
          2744,
          13,
          2438,
          11,
          456,
          321,
          352,
          51520
        ]
      },
      {
        "avg_logprob": -0.5756719939562739,
        "compression_ratio": 1.2542372881355932,
        "end": 3330.1,
        "id": 714,
        "no_speech_prob": 0.0002780286886263639,
        "seek": 330290,
        "start": 3328.1,
        "temperature": 0,
        "text": " There we go, it just went right past it",
        "tokens": [
          51624,
          821,
          321,
          352,
          11,
          309,
          445,
          1437,
          558,
          1791,
          309,
          51724
        ]
      },
      {
        "avg_logprob": -0.286779802495783,
        "compression_ratio": 1.3777777777777778,
        "end": 3332.8199999999997,
        "id": 715,
        "no_speech_prob": 0.0001559789088787511,
        "seek": 333010,
        "start": 3330.8199999999997,
        "temperature": 0,
        "text": " There we go, it just went right past it",
        "tokens": [
          50400,
          821,
          321,
          352,
          11,
          309,
          445,
          1437,
          558,
          1791,
          309,
          50500
        ]
      },
      {
        "avg_logprob": -0.286779802495783,
        "compression_ratio": 1.3777777777777778,
        "end": 3336.58,
        "id": 716,
        "no_speech_prob": 0.0001559789088787511,
        "seek": 333010,
        "start": 3334.58,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50588,
          1033,
          50688
        ]
      },
      {
        "avg_logprob": -0.286779802495783,
        "compression_ratio": 1.3777777777777778,
        "end": 3339.38,
        "id": 717,
        "no_speech_prob": 0.0001559789088787511,
        "seek": 333010,
        "start": 3336.58,
        "temperature": 0,
        "text": " You know user settings I don't I want to user everything",
        "tokens": [
          50688,
          509,
          458,
          4195,
          6257,
          286,
          500,
          380,
          286,
          528,
          281,
          4195,
          1203,
          50828
        ]
      },
      {
        "avg_logprob": -0.286779802495783,
        "compression_ratio": 1.3777777777777778,
        "end": 3343.38,
        "id": 718,
        "no_speech_prob": 0.0001559789088787511,
        "seek": 333010,
        "start": 3341.38,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50928,
          1033,
          51028
        ]
      },
      {
        "avg_logprob": -0.286779802495783,
        "compression_ratio": 1.3777777777777778,
        "end": 3348.04,
        "id": 719,
        "no_speech_prob": 0.0001559789088787511,
        "seek": 333010,
        "start": 3343.7,
        "temperature": 0,
        "text": " How come that doesn't do I actually have to change something no no",
        "tokens": [
          51044,
          1012,
          808,
          300,
          1177,
          380,
          360,
          286,
          767,
          362,
          281,
          1319,
          746,
          572,
          572,
          51261
        ]
      },
      {
        "avg_logprob": -0.286779802495783,
        "compression_ratio": 1.3777777777777778,
        "end": 3357.2999999999997,
        "id": 720,
        "no_speech_prob": 0.0001559789088787511,
        "seek": 333010,
        "start": 3354.42,
        "temperature": 0,
        "text": " What why why",
        "tokens": [
          51580,
          708,
          983,
          983,
          51724
        ]
      },
      {
        "avg_logprob": -0.3992073681889748,
        "compression_ratio": 1.3333333333333333,
        "end": 3359.6200000000003,
        "id": 721,
        "no_speech_prob": 0.00015118026931304485,
        "seek": 335730,
        "start": 3357.6200000000003,
        "temperature": 0,
        "text": " Why is it here?",
        "tokens": [
          50380,
          1545,
          307,
          309,
          510,
          30,
          50480
        ]
      },
      {
        "avg_logprob": -0.3992073681889748,
        "compression_ratio": 1.3333333333333333,
        "end": 3370.82,
        "id": 722,
        "no_speech_prob": 0.00015118026931304485,
        "seek": 335730,
        "start": 3367.46,
        "temperature": 0,
        "text": " Oh director like I skipped you guys are behind me",
        "tokens": [
          50872,
          876,
          5391,
          411,
          286,
          30193,
          291,
          1074,
          366,
          2261,
          385,
          51040
        ]
      },
      {
        "avg_logprob": -0.3992073681889748,
        "compression_ratio": 1.3333333333333333,
        "end": 3375.4,
        "id": 723,
        "no_speech_prob": 0.00015118026931304485,
        "seek": 335730,
        "start": 3372.98,
        "temperature": 0,
        "text": " Why why I can't I can't continue",
        "tokens": [
          51148,
          1545,
          983,
          286,
          393,
          380,
          286,
          393,
          380,
          2354,
          51269
        ]
      },
      {
        "avg_logprob": -0.3992073681889748,
        "compression_ratio": 1.3333333333333333,
        "end": 3386.1000000000004,
        "id": 724,
        "no_speech_prob": 0.00015118026931304485,
        "seek": 335730,
        "start": 3381.7000000000003,
        "temperature": 0,
        "text": " This setting is overridden based on the file contents when editor detection is on",
        "tokens": [
          51584,
          639,
          3287,
          307,
          670,
          81,
          6171,
          2361,
          322,
          264,
          3991,
          15768,
          562,
          9839,
          17784,
          307,
          322,
          51804
        ]
      },
      {
        "avg_logprob": -0.3558562469482422,
        "compression_ratio": 1.3153846153846154,
        "end": 3389.38,
        "id": 725,
        "no_speech_prob": 0.000010616098734317347,
        "seek": 338730,
        "start": 3387.38,
        "temperature": 0,
        "text": " oops",
        "tokens": [
          50368,
          34166,
          50468
        ]
      },
      {
        "avg_logprob": -0.3558562469482422,
        "compression_ratio": 1.3153846153846154,
        "end": 3397.1400000000003,
        "id": 726,
        "no_speech_prob": 0.000010616098734317347,
        "seek": 338730,
        "start": 3392.02,
        "temperature": 0,
        "text": " I want to turn that off then. Oh, I see because",
        "tokens": [
          50600,
          286,
          528,
          281,
          1261,
          300,
          766,
          550,
          13,
          876,
          11,
          286,
          536,
          570,
          50856
        ]
      },
      {
        "avg_logprob": -0.3558562469482422,
        "compression_ratio": 1.3153846153846154,
        "end": 3402.5,
        "id": 727,
        "no_speech_prob": 0.000010616098734317347,
        "seek": 338730,
        "start": 3399.86,
        "temperature": 0,
        "text": " Um, that makes sense that you would have this editor",
        "tokens": [
          50992,
          3301,
          11,
          300,
          1669,
          2020,
          300,
          291,
          576,
          362,
          341,
          9839,
          51124
        ]
      },
      {
        "avg_logprob": -0.3558562469482422,
        "compression_ratio": 1.3153846153846154,
        "end": 3410.42,
        "id": 728,
        "no_speech_prob": 0.000010616098734317347,
        "seek": 338730,
        "start": 3405.2200000000003,
        "temperature": 0,
        "text": " Editor detection, hold on come on two",
        "tokens": [
          51260,
          24281,
          17784,
          11,
          1797,
          322,
          808,
          322,
          732,
          51520
        ]
      },
      {
        "avg_logprob": -0.3558562469482422,
        "compression_ratio": 1.3153846153846154,
        "end": 3414.82,
        "id": 729,
        "no_speech_prob": 0.000010616098734317347,
        "seek": 338730,
        "start": 3412.82,
        "temperature": 0,
        "text": " One let's see auto surround",
        "tokens": [
          51640,
          1485,
          718,
          311,
          536,
          8399,
          6262,
          51740
        ]
      },
      {
        "avg_logprob": -0.3241675138473511,
        "compression_ratio": 1.3,
        "end": 3419.86,
        "id": 730,
        "no_speech_prob": 0.00012931493984069675,
        "seek": 341730,
        "start": 3417.86,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50392,
          407,
          50492
        ]
      },
      {
        "avg_logprob": -0.3241675138473511,
        "compression_ratio": 1.3,
        "end": 3432.5,
        "id": 731,
        "no_speech_prob": 0.00012931493984069675,
        "seek": 341730,
        "start": 3430.5,
        "temperature": 0,
        "text": " Is it because it like detected",
        "tokens": [
          51024,
          1119,
          309,
          570,
          309,
          411,
          21896,
          51124
        ]
      },
      {
        "avg_logprob": -0.3241675138473511,
        "compression_ratio": 1.3,
        "end": 3435.3,
        "id": 732,
        "no_speech_prob": 0.00012931493984069675,
        "seek": 341730,
        "start": 3433.3,
        "temperature": 0,
        "text": " for space",
        "tokens": [
          51164,
          337,
          1901,
          51264
        ]
      },
      {
        "avg_logprob": -0.3241675138473511,
        "compression_ratio": 1.3,
        "end": 3442.6800000000003,
        "id": 733,
        "no_speech_prob": 0.00012931493984069675,
        "seek": 341730,
        "start": 3435.6200000000003,
        "temperature": 0,
        "text": " And now if I take out all the for space you can't detect it and it will go back to two",
        "tokens": [
          51280,
          400,
          586,
          498,
          286,
          747,
          484,
          439,
          264,
          337,
          1901,
          291,
          393,
          380,
          5531,
          309,
          293,
          309,
          486,
          352,
          646,
          281,
          732,
          51633
        ]
      },
      {
        "avg_logprob": -0.28632891972859703,
        "compression_ratio": 1.4360902255639099,
        "end": 3450.98,
        "id": 734,
        "no_speech_prob": 0.00006814859807491302,
        "seek": 344730,
        "start": 3447.78,
        "temperature": 0,
        "text": " Spaces four. Ah, how do I change this?",
        "tokens": [
          50388,
          1738,
          2116,
          1451,
          13,
          2438,
          11,
          577,
          360,
          286,
          1319,
          341,
          30,
          50548
        ]
      },
      {
        "avg_logprob": -0.28632891972859703,
        "compression_ratio": 1.4360902255639099,
        "end": 3458.6600000000003,
        "id": 735,
        "no_speech_prob": 0.00006814859807491302,
        "seek": 344730,
        "start": 3454.98,
        "temperature": 0,
        "text": " How do I change that to four from two two look at that four",
        "tokens": [
          50748,
          1012,
          360,
          286,
          1319,
          300,
          281,
          1451,
          490,
          732,
          732,
          574,
          412,
          300,
          1451,
          50932
        ]
      },
      {
        "avg_logprob": -0.28632891972859703,
        "compression_ratio": 1.4360902255639099,
        "end": 3468.42,
        "id": 736,
        "no_speech_prob": 0.00006814859807491302,
        "seek": 344730,
        "start": 3461.46,
        "temperature": 0,
        "text": " When you open the code file at the bottom right you have to change it",
        "tokens": [
          51072,
          1133,
          291,
          1269,
          264,
          3089,
          3991,
          412,
          264,
          2767,
          558,
          291,
          362,
          281,
          1319,
          309,
          51420
        ]
      },
      {
        "avg_logprob": -0.28632891972859703,
        "compression_ratio": 1.4360902255639099,
        "end": 3472.98,
        "id": 737,
        "no_speech_prob": 0.00006814859807491302,
        "seek": 344730,
        "start": 3470.98,
        "temperature": 0,
        "text": " No",
        "tokens": [
          51548,
          883,
          51648
        ]
      },
      {
        "avg_logprob": -0.28632891972859703,
        "compression_ratio": 1.4360902255639099,
        "end": 3475.46,
        "id": 738,
        "no_speech_prob": 0.00006814859807491302,
        "seek": 344730,
        "start": 3473.46,
        "temperature": 0,
        "text": " I'm change view. Ah",
        "tokens": [
          51672,
          286,
          478,
          1319,
          1910,
          13,
          2438,
          51772
        ]
      },
      {
        "avg_logprob": -0.33981292966812376,
        "compression_ratio": 1.4586466165413534,
        "end": 3482.34,
        "id": 739,
        "no_speech_prob": 0.0011159820714965463,
        "seek": 347546,
        "start": 3475.78,
        "temperature": 0,
        "text": " Ah, ah, ah, ah, okay. Oh my god. Everything's okay now. Woof",
        "tokens": [
          50380,
          2438,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          1392,
          13,
          876,
          452,
          3044,
          13,
          5471,
          311,
          1392,
          586,
          13,
          10468,
          69,
          50708
        ]
      },
      {
        "avg_logprob": -0.33981292966812376,
        "compression_ratio": 1.4586466165413534,
        "end": 3485.14,
        "id": 740,
        "no_speech_prob": 0.0011159820714965463,
        "seek": 347546,
        "start": 3482.82,
        "temperature": 0,
        "text": " Oh, that was rough. That was really deep. That was really bad",
        "tokens": [
          50732,
          876,
          11,
          300,
          390,
          5903,
          13,
          663,
          390,
          534,
          2452,
          13,
          663,
          390,
          534,
          1578,
          50848
        ]
      },
      {
        "avg_logprob": -0.33981292966812376,
        "compression_ratio": 1.4586466165413534,
        "end": 3487.7,
        "id": 741,
        "no_speech_prob": 0.0011159820714965463,
        "seek": 347546,
        "start": 3485.7,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50876,
          1033,
          50976
        ]
      },
      {
        "avg_logprob": -0.33981292966812376,
        "compression_ratio": 1.4586466165413534,
        "end": 3496.18,
        "id": 742,
        "no_speech_prob": 0.0011159820714965463,
        "seek": 347546,
        "start": 3490.34,
        "temperature": 0,
        "text": " Okay, woof woof sweating like crazy",
        "tokens": [
          51108,
          1033,
          11,
          21657,
          69,
          21657,
          69,
          25438,
          411,
          3219,
          51400
        ]
      },
      {
        "avg_logprob": -0.33981292966812376,
        "compression_ratio": 1.4586466165413534,
        "end": 3502.02,
        "id": 743,
        "no_speech_prob": 0.0011159820714965463,
        "seek": 347546,
        "start": 3500.02,
        "temperature": 0,
        "text": " All right, all right everybody",
        "tokens": [
          51592,
          1057,
          558,
          11,
          439,
          558,
          2201,
          51692
        ]
      },
      {
        "avg_logprob": -0.21328185440657974,
        "compression_ratio": 1.5337423312883436,
        "end": 3513.62,
        "id": 744,
        "no_speech_prob": 0.0003006146871484816,
        "seek": 350546,
        "start": 3506.1,
        "temperature": 0,
        "text": " Woof woof. All right, so here's there's a couple options. Um",
        "tokens": [
          50396,
          10468,
          69,
          21657,
          69,
          13,
          1057,
          558,
          11,
          370,
          510,
          311,
          456,
          311,
          257,
          1916,
          3956,
          13,
          3301,
          50772
        ]
      },
      {
        "avg_logprob": -0.21328185440657974,
        "compression_ratio": 1.5337423312883436,
        "end": 3522.98,
        "id": 745,
        "no_speech_prob": 0.0003006146871484816,
        "seek": 350546,
        "start": 3516.26,
        "temperature": 0,
        "text": " Um, okay dot so i've never actually used dot env the dot env package before",
        "tokens": [
          50904,
          3301,
          11,
          1392,
          5893,
          370,
          741,
          600,
          1128,
          767,
          1143,
          5893,
          2267,
          264,
          5893,
          2267,
          7372,
          949,
          51240
        ]
      },
      {
        "avg_logprob": -0.21328185440657974,
        "compression_ratio": 1.5337423312883436,
        "end": 3525.38,
        "id": 746,
        "no_speech_prob": 0.0003006146871484816,
        "seek": 350546,
        "start": 3523.78,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51280,
          1105,
          51360
        ]
      },
      {
        "avg_logprob": -0.21328185440657974,
        "compression_ratio": 1.5337423312883436,
        "end": 3527.54,
        "id": 747,
        "no_speech_prob": 0.0003006146871484816,
        "seek": 350546,
        "start": 3525.38,
        "temperature": 0,
        "text": " I what I always do is",
        "tokens": [
          51360,
          286,
          437,
          286,
          1009,
          360,
          307,
          51468
        ]
      },
      {
        "avg_logprob": -0.21328185440657974,
        "compression_ratio": 1.5337423312883436,
        "end": 3534.18,
        "id": 748,
        "no_speech_prob": 0.0003006146871484816,
        "seek": 350546,
        "start": 3527.94,
        "temperature": 0,
        "text": " um, but so and then so I would make a dot env file and then I would get ignore it when I",
        "tokens": [
          51488,
          1105,
          11,
          457,
          370,
          293,
          550,
          370,
          286,
          576,
          652,
          257,
          5893,
          2267,
          3991,
          293,
          550,
          286,
          576,
          483,
          11200,
          309,
          562,
          286,
          51800
        ]
      },
      {
        "avg_logprob": -0.2813437262246775,
        "compression_ratio": 1.3118279569892473,
        "end": 3536.8199999999997,
        "id": 749,
        "no_speech_prob": 0.00023413318558596075,
        "seek": 353418,
        "start": 3534.8199999999997,
        "temperature": 0,
        "text": " Yeah, okay, so let me try doing that, okay",
        "tokens": [
          50396,
          865,
          11,
          1392,
          11,
          370,
          718,
          385,
          853,
          884,
          300,
          11,
          1392,
          50496
        ]
      },
      {
        "avg_logprob": -0.2813437262246775,
        "compression_ratio": 1.3118279569892473,
        "end": 3540.2599999999998,
        "id": 750,
        "no_speech_prob": 0.00023413318558596075,
        "seek": 353418,
        "start": 3538.2599999999998,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50568,
          1033,
          50668
        ]
      },
      {
        "avg_logprob": -0.2813437262246775,
        "compression_ratio": 1.3118279569892473,
        "end": 3544.58,
        "id": 751,
        "no_speech_prob": 0.00023413318558596075,
        "seek": 353418,
        "start": 3542.58,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50784,
          1033,
          50884
        ]
      },
      {
        "avg_logprob": -0.2813437262246775,
        "compression_ratio": 1.3118279569892473,
        "end": 3549.54,
        "id": 752,
        "no_speech_prob": 0.00023413318558596075,
        "seek": 353418,
        "start": 3547.46,
        "temperature": 0,
        "text": " All right, um, okay",
        "tokens": [
          51028,
          1057,
          558,
          11,
          1105,
          11,
          1392,
          51132
        ]
      },
      {
        "avg_logprob": -0.2813437262246775,
        "compression_ratio": 1.3118279569892473,
        "end": 3555.22,
        "id": 753,
        "no_speech_prob": 0.00023413318558596075,
        "seek": 353418,
        "start": 3553.22,
        "temperature": 0,
        "text": " Okay, oh wait, actually let me recycle the camera",
        "tokens": [
          51316,
          1033,
          11,
          1954,
          1699,
          11,
          767,
          718,
          385,
          32162,
          264,
          2799,
          51416
        ]
      },
      {
        "avg_logprob": -0.6735069358741844,
        "compression_ratio": 1.5027322404371584,
        "end": 3557.22,
        "id": 754,
        "no_speech_prob": 0.00048029140452854335,
        "seek": 355522,
        "start": 3555.22,
        "temperature": 0.4,
        "text": " All right",
        "tokens": [
          50364,
          1057,
          558,
          50464
        ]
      },
      {
        "avg_logprob": -0.6735069358741844,
        "compression_ratio": 1.5027322404371584,
        "end": 3564.18,
        "id": 755,
        "no_speech_prob": 0.00048029140452854335,
        "seek": 355522,
        "start": 3557.22,
        "temperature": 0.4,
        "text": " Okay, I am back i'm going to do some I made a mastodon bot all it did so far was tweet",
        "tokens": [
          50464,
          1033,
          11,
          286,
          669,
          646,
          741,
          478,
          516,
          281,
          360,
          512,
          286,
          1027,
          257,
          275,
          525,
          378,
          266,
          10592,
          439,
          309,
          630,
          370,
          1400,
          390,
          15258,
          50812
        ]
      },
      {
        "avg_logprob": -0.6735069358741844,
        "compression_ratio": 1.5027322404371584,
        "end": 3567.2999999999997,
        "id": 756,
        "no_speech_prob": 0.00048029140452854335,
        "seek": 355522,
        "start": 3564.8999999999996,
        "temperature": 0.4,
        "text": " Tweeted who did ah toot tweet",
        "tokens": [
          50848,
          314,
          10354,
          292,
          567,
          630,
          3716,
          281,
          310,
          15258,
          50968
        ]
      },
      {
        "avg_logprob": -0.6735069358741844,
        "compression_ratio": 1.5027322404371584,
        "end": 3571.9399999999996,
        "id": 757,
        "no_speech_prob": 0.00048029140452854335,
        "seek": 355522,
        "start": 3568.3399999999997,
        "temperature": 0.4,
        "text": " Blog post who knows what all this stuff is. All I know is that it said",
        "tokens": [
          51020,
          46693,
          2183,
          567,
          3255,
          437,
          439,
          341,
          1507,
          307,
          13,
          1057,
          286,
          458,
          307,
          300,
          309,
          848,
          51200
        ]
      },
      {
        "avg_logprob": -0.6735069358741844,
        "compression_ratio": 1.5027322404371584,
        "end": 3574.18,
        "id": 758,
        "no_speech_prob": 0.00048029140452854335,
        "seek": 355522,
        "start": 3572.8999999999996,
        "temperature": 0.4,
        "text": " choo-choo",
        "tokens": [
          51248,
          1586,
          78,
          12,
          339,
          1986,
          51312
        ]
      },
      {
        "avg_logprob": -0.6735069358741844,
        "compression_ratio": 1.5027322404371584,
        "end": 3578.8999999999996,
        "id": 759,
        "no_speech_prob": 0.00048029140452854335,
        "seek": 355522,
        "start": 3574.18,
        "temperature": 0.4,
        "text": " So I would like to show you some more things to uh, you know, to do",
        "tokens": [
          51312,
          407,
          286,
          576,
          411,
          281,
          855,
          291,
          512,
          544,
          721,
          281,
          2232,
          11,
          291,
          458,
          11,
          281,
          360,
          51548
        ]
      },
      {
        "avg_logprob": -0.8863426657284007,
        "compression_ratio": 1.8962962962962964,
        "end": 3583.62,
        "id": 760,
        "no_speech_prob": 0.057484906166791916,
        "seek": 357890,
        "start": 3579.7000000000003,
        "temperature": 0.2,
        "text": " So the first thing that I want to do is actually I don't want to have all of this, uh,",
        "tokens": [
          50404,
          407,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          767,
          286,
          500,
          380,
          528,
          281,
          362,
          439,
          295,
          341,
          11,
          2232,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.8863426657284007,
        "compression_ratio": 1.8962962962962964,
        "end": 3588.58,
        "id": 761,
        "no_speech_prob": 0.057484906166791916,
        "seek": 357890,
        "start": 3583.86,
        "temperature": 0.2,
        "text": " all of these secret keys and everything right here in my code because i'm going to upload this as an example",
        "tokens": [
          50612,
          439,
          295,
          613,
          4054,
          9317,
          293,
          1203,
          558,
          510,
          294,
          452,
          3089,
          570,
          741,
          478,
          516,
          281,
          6580,
          341,
          382,
          364,
          1365,
          50848
        ]
      },
      {
        "avg_logprob": -0.8863426657284007,
        "compression_ratio": 1.8962962962962964,
        "end": 3592.26,
        "id": 762,
        "no_speech_prob": 0.057484906166791916,
        "seek": 357890,
        "start": 3588.9,
        "temperature": 0.2,
        "text": " For other people to use I want to be able to hide that stuff away, but still use it",
        "tokens": [
          50864,
          1171,
          661,
          561,
          281,
          764,
          286,
          528,
          281,
          312,
          1075,
          281,
          6479,
          300,
          1507,
          1314,
          11,
          457,
          920,
          764,
          309,
          51032
        ]
      },
      {
        "avg_logprob": -0.8863426657284007,
        "compression_ratio": 1.8962962962962964,
        "end": 3594.82,
        "id": 763,
        "no_speech_prob": 0.057484906166791916,
        "seek": 357890,
        "start": 3592.26,
        "temperature": 0.2,
        "text": " And there's actually a wonderful node package. Thank you to",
        "tokens": [
          51032,
          400,
          456,
          311,
          767,
          257,
          3715,
          9984,
          7372,
          13,
          1044,
          291,
          281,
          51160
        ]
      },
      {
        "avg_logprob": -0.8863426657284007,
        "compression_ratio": 1.8962962962962964,
        "end": 3599.46,
        "id": 764,
        "no_speech_prob": 0.057484906166791916,
        "seek": 357890,
        "start": 3595.46,
        "temperature": 0.2,
        "text": " To the people who have been using it for a long time. It's called the chewy node package",
        "tokens": [
          51192,
          220,
          13342,
          264,
          561,
          567,
          362,
          668,
          1228,
          309,
          337,
          257,
          938,
          565,
          13,
          467,
          311,
          1219,
          264,
          220,
          339,
          1023,
          88,
          9984,
          7372,
          51392
        ]
      },
      {
        "avg_logprob": -0.8863426657284007,
        "compression_ratio": 1.8962962962962964,
        "end": 3602.5,
        "id": 765,
        "no_speech_prob": 0.057484906166791916,
        "seek": 357890,
        "start": 3599.46,
        "temperature": 0.2,
        "text": " And it's a really cool package. It's a really cool node package. It's a really cool",
        "tokens": [
          51392,
          400,
          309,
          311,
          257,
          534,
          1627,
          7372,
          13,
          467,
          311,
          257,
          534,
          1627,
          9984,
          7372,
          13,
          467,
          311,
          257,
          534,
          1627,
          51544
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3605.94,
        "id": 766,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3602.5,
        "temperature": 0.2,
        "text": " Package for other people to use I want to be able to hide that stuff away, but still use it",
        "tokens": [
          50364,
          18466,
          609,
          337,
          661,
          561,
          281,
          764,
          286,
          528,
          281,
          312,
          1075,
          281,
          6479,
          300,
          1507,
          1314,
          11,
          457,
          920,
          764,
          309,
          50536
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3608.26,
        "id": 767,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3605.94,
        "temperature": 0.2,
        "text": " And there's actually a wonderful node package. Thank you to",
        "tokens": [
          50536,
          400,
          456,
          311,
          767,
          257,
          3715,
          9984,
          7372,
          13,
          1044,
          291,
          281,
          50652
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3610.82,
        "id": 768,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3608.82,
        "temperature": 0.2,
        "text": " alka for the um",
        "tokens": [
          50680,
          419,
          2330,
          337,
          264,
          1105,
          50780
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3612.9,
        "id": 769,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3611.28,
        "temperature": 0.2,
        "text": " suggestion",
        "tokens": [
          50803,
          16541,
          50884
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3614.02,
        "id": 770,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3612.9,
        "temperature": 0.2,
        "text": " called",
        "tokens": [
          50884,
          1219,
          50940
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3616.5,
        "id": 771,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3614.02,
        "temperature": 0.2,
        "text": " Dot env so i'm going to say npm",
        "tokens": [
          50940,
          38753,
          2267,
          370,
          741,
          478,
          516,
          281,
          584,
          297,
          14395,
          51064
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3619.12,
        "id": 772,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3617.12,
        "temperature": 0.2,
        "text": " install dot env",
        "tokens": [
          51095,
          3625,
          5893,
          2267,
          51195
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3622.34,
        "id": 773,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3620.34,
        "temperature": 0.2,
        "text": " Install this node package",
        "tokens": [
          51256,
          31982,
          341,
          9984,
          7372,
          51356
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3628.66,
        "id": 774,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3622.34,
        "temperature": 0.2,
        "text": " And what this allows me to do is create environment variables for a particular project and that way I can",
        "tokens": [
          51356,
          400,
          437,
          341,
          4045,
          385,
          281,
          360,
          307,
          1884,
          2823,
          9102,
          337,
          257,
          1729,
          1716,
          293,
          300,
          636,
          286,
          393,
          51672
        ]
      },
      {
        "avg_logprob": -0.29681300208682104,
        "compression_ratio": 1.610655737704918,
        "end": 3631.3,
        "id": 775,
        "no_speech_prob": 0.029310408979654312,
        "seek": 360250,
        "start": 3629.3,
        "temperature": 0.2,
        "text": " upload the code without the",
        "tokens": [
          51704,
          6580,
          264,
          3089,
          1553,
          264,
          51804
        ]
      },
      {
        "avg_logprob": -0.21307323359641708,
        "compression_ratio": 1.8045112781954886,
        "end": 3638.42,
        "id": 776,
        "no_speech_prob": 0.00011235211422899738,
        "seek": 363130,
        "start": 3631.6200000000003,
        "temperature": 0,
        "text": " Values of those environment variables, but anybody who's using that code could set the own values set their own values of that those environment variables",
        "tokens": [
          50380,
          7188,
          1247,
          295,
          729,
          2823,
          9102,
          11,
          457,
          4472,
          567,
          311,
          1228,
          300,
          3089,
          727,
          992,
          264,
          1065,
          4190,
          992,
          641,
          1065,
          4190,
          295,
          300,
          729,
          2823,
          9102,
          50720
        ]
      },
      {
        "avg_logprob": -0.21307323359641708,
        "compression_ratio": 1.8045112781954886,
        "end": 3643.78,
        "id": 777,
        "no_speech_prob": 0.00011235211422899738,
        "seek": 363130,
        "start": 3638.6600000000003,
        "temperature": 0,
        "text": " So what i'm going to need to do is create a new file. I'm going to call it dot env",
        "tokens": [
          50732,
          407,
          437,
          741,
          478,
          516,
          281,
          643,
          281,
          360,
          307,
          1884,
          257,
          777,
          3991,
          13,
          286,
          478,
          516,
          281,
          818,
          309,
          5893,
          2267,
          50988
        ]
      },
      {
        "avg_logprob": -0.21307323359641708,
        "compression_ratio": 1.8045112781954886,
        "end": 3649.38,
        "id": 778,
        "no_speech_prob": 0.00011235211422899738,
        "seek": 363130,
        "start": 3644.5,
        "temperature": 0,
        "text": " So it's kind of like as you can see it right here. It's like a hidden file dot env. It even has this crazy",
        "tokens": [
          51024,
          407,
          309,
          311,
          733,
          295,
          411,
          382,
          291,
          393,
          536,
          309,
          558,
          510,
          13,
          467,
          311,
          411,
          257,
          7633,
          3991,
          5893,
          2267,
          13,
          467,
          754,
          575,
          341,
          3219,
          51268
        ]
      },
      {
        "avg_logprob": -0.21307323359641708,
        "compression_ratio": 1.8045112781954886,
        "end": 3651.86,
        "id": 779,
        "no_speech_prob": 0.00011235211422899738,
        "seek": 363130,
        "start": 3650.1000000000004,
        "temperature": 0,
        "text": " settings thing",
        "tokens": [
          51304,
          6257,
          551,
          51392
        ]
      },
      {
        "avg_logprob": -0.21307323359641708,
        "compression_ratio": 1.8045112781954886,
        "end": 3658.26,
        "id": 780,
        "no_speech_prob": 0.00011235211422899738,
        "seek": 363130,
        "start": 3651.86,
        "temperature": 0,
        "text": " And then in this oh look, there's all these extensions I could use probably to like format it in all sorts of fancy ways",
        "tokens": [
          51392,
          400,
          550,
          294,
          341,
          1954,
          574,
          11,
          456,
          311,
          439,
          613,
          25129,
          286,
          727,
          764,
          1391,
          281,
          411,
          7877,
          309,
          294,
          439,
          7527,
          295,
          10247,
          2098,
          51712
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3662.7400000000002,
        "id": 781,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3658.26,
        "temperature": 0,
        "text": " But i'm not going to be fancy what i'm going to do and i'm looking over here because thankfully",
        "tokens": [
          50364,
          583,
          741,
          478,
          406,
          516,
          281,
          312,
          10247,
          437,
          741,
          478,
          516,
          281,
          360,
          293,
          741,
          478,
          1237,
          670,
          510,
          570,
          27352,
          50588
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3665.94,
        "id": 782,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3663.3,
        "temperature": 0,
        "text": " Alka gave me some suggestions i'm going to say things like",
        "tokens": [
          50616,
          967,
          2330,
          2729,
          385,
          512,
          13396,
          741,
          478,
          516,
          281,
          584,
          721,
          411,
          50748
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3668.6600000000003,
        "id": 783,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3666.6600000000003,
        "temperature": 0,
        "text": " auth token equals",
        "tokens": [
          50784,
          6979,
          14862,
          6915,
          50884
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3670.26,
        "id": 784,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3669.0600000000004,
        "temperature": 0,
        "text": " client",
        "tokens": [
          50904,
          6423,
          50964
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3672.26,
        "id": 785,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3670.26,
        "temperature": 0,
        "text": " secret equals",
        "tokens": [
          50964,
          4054,
          6915,
          51064
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3677.7000000000003,
        "id": 786,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3672.34,
        "temperature": 0,
        "text": " Um, and i'm going to say client, uh id equals I think those are my three things so they're in the code",
        "tokens": [
          51068,
          3301,
          11,
          293,
          741,
          478,
          516,
          281,
          584,
          6423,
          11,
          2232,
          4496,
          6915,
          286,
          519,
          729,
          366,
          452,
          1045,
          721,
          370,
          436,
          434,
          294,
          264,
          3089,
          51336
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3680.26,
        "id": 787,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3678.26,
        "temperature": 0,
        "text": " Uh client key is this",
        "tokens": [
          51364,
          4019,
          6423,
          2141,
          307,
          341,
          51464
        ]
      },
      {
        "avg_logprob": -0.22348635537283762,
        "compression_ratio": 1.8206278026905829,
        "end": 3685.78,
        "id": 788,
        "no_speech_prob": 0.0018675316823646426,
        "seek": 365826,
        "start": 3681.2200000000003,
        "temperature": 0,
        "text": " I'm going to put this back in here client key. Okay, I guess client key is what I meant",
        "tokens": [
          51512,
          286,
          478,
          516,
          281,
          829,
          341,
          646,
          294,
          510,
          6423,
          2141,
          13,
          1033,
          11,
          286,
          2041,
          6423,
          2141,
          307,
          437,
          286,
          4140,
          51740
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3690.9,
        "id": 789,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3686.6600000000003,
        "temperature": 0,
        "text": " Um, do I need to does it need to be in quotes? Maybe somebody can tell me maybe it shouldn't be in quotes actually",
        "tokens": [
          50408,
          3301,
          11,
          360,
          286,
          643,
          281,
          775,
          309,
          643,
          281,
          312,
          294,
          19963,
          30,
          2704,
          2618,
          393,
          980,
          385,
          1310,
          309,
          4659,
          380,
          312,
          294,
          19963,
          767,
          50620
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3692.5,
        "id": 790,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3691.3,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50640,
          1105,
          50700
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3694.5,
        "id": 791,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3692.5,
        "temperature": 0,
        "text": " I'm going to get the client secret",
        "tokens": [
          50700,
          286,
          478,
          516,
          281,
          483,
          264,
          6423,
          4054,
          50800
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3698.42,
        "id": 792,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3695.38,
        "temperature": 0,
        "text": " Um, i'm going to go back to the env file and put that in here right now",
        "tokens": [
          50844,
          3301,
          11,
          741,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          2267,
          3991,
          293,
          829,
          300,
          294,
          510,
          558,
          586,
          50996
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3702.5,
        "id": 793,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3698.42,
        "temperature": 0,
        "text": " I'm using single quotes which may or may not be correct. Then i'm going to go back to my code",
        "tokens": [
          50996,
          286,
          478,
          1228,
          2167,
          19963,
          597,
          815,
          420,
          815,
          406,
          312,
          3006,
          13,
          1396,
          741,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          3089,
          51200
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3704.9,
        "id": 794,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3702.5800000000004,
        "temperature": 0,
        "text": " I'm going to get the access token",
        "tokens": [
          51204,
          286,
          478,
          516,
          281,
          483,
          264,
          2105,
          14862,
          51320
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3709.6200000000003,
        "id": 795,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3705.6200000000003,
        "temperature": 0,
        "text": " And i'm going to call it access token just to be consistent with my naming",
        "tokens": [
          51356,
          400,
          741,
          478,
          516,
          281,
          818,
          309,
          2105,
          14862,
          445,
          281,
          312,
          8398,
          365,
          452,
          25290,
          51556
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3711.38,
        "id": 796,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3710.5,
        "temperature": 0,
        "text": " uh",
        "tokens": [
          51600,
          2232,
          51644
        ]
      },
      {
        "avg_logprob": -0.20069554138183593,
        "compression_ratio": 1.8559322033898304,
        "end": 3712.82,
        "id": 797,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 368578,
        "start": 3711.38,
        "temperature": 0,
        "text": " and now",
        "tokens": [
          51644,
          293,
          586,
          51716
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3716.82,
        "id": 798,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3712.82,
        "temperature": 0,
        "text": " If I do this I can now go to my bot and I can also say",
        "tokens": [
          50364,
          759,
          286,
          360,
          341,
          286,
          393,
          586,
          352,
          281,
          452,
          10592,
          293,
          286,
          393,
          611,
          584,
          50564
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3722.44,
        "id": 799,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3718.88,
        "temperature": 0,
        "text": " Constant uh, uh env equals require",
        "tokens": [
          50667,
          37413,
          2232,
          11,
          2232,
          2267,
          6915,
          3651,
          50845
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3727,
        "id": 800,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3724.02,
        "temperature": 0,
        "text": " Uh, and then I want to require a dot env",
        "tokens": [
          50924,
          4019,
          11,
          293,
          550,
          286,
          528,
          281,
          3651,
          257,
          5893,
          2267,
          51073
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3730.02,
        "id": 801,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3728.42,
        "temperature": 0,
        "text": " and then",
        "tokens": [
          51144,
          293,
          550,
          51224
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3731.3,
        "id": 802,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3730.02,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51224,
          1105,
          51288
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3733.3,
        "id": 803,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3731.3,
        "temperature": 0,
        "text": " Wait time out for a second",
        "tokens": [
          51288,
          3802,
          565,
          484,
          337,
          257,
          1150,
          51388
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3735.3,
        "id": 804,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3733.3,
        "temperature": 0,
        "text": " acquire dot env dot",
        "tokens": [
          51388,
          20001,
          5893,
          2267,
          5893,
          51488
        ]
      },
      {
        "avg_logprob": -0.34437176987931534,
        "compression_ratio": 1.5333333333333334,
        "end": 3737.96,
        "id": 805,
        "no_speech_prob": 0.00022341476869769394,
        "seek": 371282,
        "start": 3735.36,
        "temperature": 0,
        "text": " Config oh and I need to all config. Okay",
        "tokens": [
          51491,
          44151,
          1954,
          293,
          286,
          643,
          281,
          439,
          6662,
          13,
          1033,
          51621
        ]
      },
      {
        "avg_logprob": -0.5346407347087618,
        "compression_ratio": 1.4770114942528736,
        "end": 3745.3,
        "id": 806,
        "no_speech_prob": 0.00010554554319242015,
        "seek": 374282,
        "start": 3743.3,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50388,
          3301,
          50488
        ]
      },
      {
        "avg_logprob": -0.5346407347087618,
        "compression_ratio": 1.4770114942528736,
        "end": 3748.5800000000004,
        "id": 807,
        "no_speech_prob": 0.00010554554319242015,
        "seek": 374282,
        "start": 3746.5800000000004,
        "temperature": 0,
        "text": " No quotes, okay",
        "tokens": [
          50552,
          883,
          19963,
          11,
          1392,
          50652
        ]
      },
      {
        "avg_logprob": -0.5346407347087618,
        "compression_ratio": 1.4770114942528736,
        "end": 3754.1800000000003,
        "id": 808,
        "no_speech_prob": 0.00010554554319242015,
        "seek": 374282,
        "start": 3749.38,
        "temperature": 0,
        "text": " And sample one. Yep. Yeah. Yeah. Okay. I will do that. Um without quotes, okay",
        "tokens": [
          50692,
          400,
          6889,
          472,
          13,
          7010,
          13,
          865,
          13,
          865,
          13,
          1033,
          13,
          286,
          486,
          360,
          300,
          13,
          3301,
          1553,
          19963,
          11,
          1392,
          50932
        ]
      },
      {
        "avg_logprob": -0.5346407347087618,
        "compression_ratio": 1.4770114942528736,
        "end": 3758.1800000000003,
        "id": 809,
        "no_speech_prob": 0.00010554554319242015,
        "seek": 374282,
        "start": 3756.1800000000003,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51032,
          3301,
          51132
        ]
      },
      {
        "avg_logprob": -0.5346407347087618,
        "compression_ratio": 1.4770114942528736,
        "end": 3761.2200000000003,
        "id": 810,
        "no_speech_prob": 0.00010554554319242015,
        "seek": 374282,
        "start": 3759.2200000000003,
        "temperature": 0,
        "text": " Okay, um",
        "tokens": [
          51184,
          1033,
          11,
          1105,
          51284
        ]
      },
      {
        "avg_logprob": -0.5346407347087618,
        "compression_ratio": 1.4770114942528736,
        "end": 3765.7000000000003,
        "id": 811,
        "no_speech_prob": 0.00010554554319242015,
        "seek": 374282,
        "start": 3762.5,
        "temperature": 0,
        "text": " Okay, actually just for consistency sake maybe i'll make this capital letters",
        "tokens": [
          51348,
          1033,
          11,
          767,
          445,
          337,
          14416,
          9717,
          1310,
          741,
          603,
          652,
          341,
          4238,
          7825,
          51508
        ]
      },
      {
        "avg_logprob": -0.5346407347087618,
        "compression_ratio": 1.4770114942528736,
        "end": 3769.3,
        "id": 812,
        "no_speech_prob": 0.00010554554319242015,
        "seek": 374282,
        "start": 3765.78,
        "temperature": 0,
        "text": " I don't know then i'm going to say then I need to call env dot config",
        "tokens": [
          51512,
          286,
          500,
          380,
          458,
          550,
          741,
          478,
          516,
          281,
          584,
          550,
          286,
          643,
          281,
          818,
          2267,
          5893,
          6662,
          51688
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3771.3,
        "id": 813,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3769.3,
        "temperature": 0.2,
        "text": " And then I'm going to say",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          50464
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3773.54,
        "id": 814,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3771.54,
        "temperature": 0.2,
        "text": " Uh, I'm going to say",
        "tokens": [
          50476,
          4019,
          11,
          286,
          478,
          516,
          281,
          584,
          50576
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3775.7000000000003,
        "id": 815,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3773.7000000000003,
        "temperature": 0.2,
        "text": " process dot env dot",
        "tokens": [
          50584,
          1399,
          5893,
          2267,
          5893,
          50684
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3777.38,
        "id": 816,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3776.1800000000003,
        "temperature": 0.2,
        "text": " uh",
        "tokens": [
          50708,
          2232,
          50768
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3779.38,
        "id": 817,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3777.38,
        "temperature": 0.2,
        "text": " client key",
        "tokens": [
          50768,
          6423,
          2141,
          50868
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3781.6200000000003,
        "id": 818,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3779.6200000000003,
        "temperature": 0.2,
        "text": " So I should this",
        "tokens": [
          50880,
          407,
          286,
          820,
          341,
          50980
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3787.2200000000003,
        "id": 819,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3782.34,
        "temperature": 0.2,
        "text": " Will now is that right process dot env? Let me take a look. I have the documentation over here",
        "tokens": [
          51016,
          3099,
          586,
          307,
          300,
          558,
          1399,
          5893,
          2267,
          30,
          961,
          385,
          747,
          257,
          574,
          13,
          286,
          362,
          264,
          14333,
          670,
          510,
          51260
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3790.42,
        "id": 820,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3788.02,
        "temperature": 0.2,
        "text": " Um, and then I should be able to now",
        "tokens": [
          51300,
          3301,
          11,
          293,
          550,
          286,
          820,
          312,
          1075,
          281,
          586,
          51420
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3793.2200000000003,
        "id": 821,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3791.2200000000003,
        "temperature": 0.2,
        "text": " I should be able to say",
        "tokens": [
          51460,
          286,
          820,
          312,
          1075,
          281,
          584,
          51560
        ]
      },
      {
        "avg_logprob": -0.9622058868408203,
        "compression_ratio": 1.6956521739130435,
        "end": 3795.7000000000003,
        "id": 822,
        "no_speech_prob": 0.0012448326451703906,
        "seek": 376930,
        "start": 3793.7000000000003,
        "temperature": 0.2,
        "text": " Process dot env dot",
        "tokens": [
          51584,
          31093,
          5893,
          2267,
          5893,
          51684
        ]
      },
      {
        "avg_logprob": -0.25824882586797077,
        "compression_ratio": 1.5674418604651164,
        "end": 3798.1,
        "id": 823,
        "no_speech_prob": 0.03067236766219139,
        "seek": 379570,
        "start": 3795.8599999999997,
        "temperature": 0,
        "text": " Let me take a look I have the documentation over here",
        "tokens": [
          50372,
          961,
          385,
          747,
          257,
          574,
          286,
          362,
          264,
          14333,
          670,
          510,
          50484
        ]
      },
      {
        "avg_logprob": -0.25824882586797077,
        "compression_ratio": 1.5674418604651164,
        "end": 3802.68,
        "id": 824,
        "no_speech_prob": 0.03067236766219139,
        "seek": 379570,
        "start": 3798.8999999999996,
        "temperature": 0,
        "text": " Um, yeah, I think that's right. So I should be able to grab those environment variables",
        "tokens": [
          50524,
          3301,
          11,
          1338,
          11,
          286,
          519,
          300,
          311,
          558,
          13,
          407,
          286,
          820,
          312,
          1075,
          281,
          4444,
          729,
          2823,
          9102,
          50713
        ]
      },
      {
        "avg_logprob": -0.25824882586797077,
        "compression_ratio": 1.5674418604651164,
        "end": 3805.22,
        "id": 825,
        "no_speech_prob": 0.03067236766219139,
        "seek": 379570,
        "start": 3803.3799999999997,
        "temperature": 0,
        "text": " whoops",
        "tokens": [
          50748,
          567,
          3370,
          50840
        ]
      },
      {
        "avg_logprob": -0.25824882586797077,
        "compression_ratio": 1.5674418604651164,
        "end": 3807.8799999999997,
        "id": 826,
        "no_speech_prob": 0.03067236766219139,
        "seek": 379570,
        "start": 3805.22,
        "temperature": 0,
        "text": " Just like this, uh, then the client secret",
        "tokens": [
          50840,
          1449,
          411,
          341,
          11,
          2232,
          11,
          550,
          264,
          6423,
          4054,
          50973
        ]
      },
      {
        "avg_logprob": -0.25824882586797077,
        "compression_ratio": 1.5674418604651164,
        "end": 3814.8999999999996,
        "id": 827,
        "no_speech_prob": 0.03067236766219139,
        "seek": 379570,
        "start": 3812.02,
        "temperature": 0,
        "text": " Then I should be able to grab this one and say",
        "tokens": [
          51180,
          1396,
          286,
          820,
          312,
          1075,
          281,
          4444,
          341,
          472,
          293,
          584,
          51324
        ]
      },
      {
        "avg_logprob": -0.25824882586797077,
        "compression_ratio": 1.5674418604651164,
        "end": 3819.62,
        "id": 828,
        "no_speech_prob": 0.03067236766219139,
        "seek": 379570,
        "start": 3817.62,
        "temperature": 0,
        "text": " Access token",
        "tokens": [
          51460,
          17166,
          14862,
          51560
        ]
      },
      {
        "avg_logprob": -0.25824882586797077,
        "compression_ratio": 1.5674418604651164,
        "end": 3824.8199999999997,
        "id": 829,
        "no_speech_prob": 0.03067236766219139,
        "seek": 379570,
        "start": 3819.62,
        "temperature": 0,
        "text": " Who knows if i've made some mistakes, but let's try running this now. Let's choo-choo",
        "tokens": [
          51560,
          2102,
          3255,
          498,
          741,
          600,
          1027,
          512,
          8038,
          11,
          457,
          718,
          311,
          853,
          2614,
          341,
          586,
          13,
          961,
          311,
          1586,
          78,
          12,
          339,
          1986,
          51820
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3826.82,
        "id": 830,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3825.3,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50388,
          1105,
          50464
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3828.82,
        "id": 831,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3826.82,
        "temperature": 0,
        "text": " Uh choo-choo choo-choo",
        "tokens": [
          50464,
          4019,
          1586,
          78,
          12,
          339,
          1986,
          1586,
          78,
          12,
          339,
          1986,
          50564
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3831.2200000000003,
        "id": 832,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3829.2200000000003,
        "temperature": 0,
        "text": " Let's say choo-choo twice",
        "tokens": [
          50584,
          961,
          311,
          584,
          1586,
          78,
          12,
          339,
          1986,
          6091,
          50684
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3833.7000000000003,
        "id": 833,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3831.7000000000003,
        "temperature": 0,
        "text": " And let's uh run",
        "tokens": [
          50708,
          400,
          718,
          311,
          2232,
          1190,
          50808
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3834.7400000000002,
        "id": 834,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3833.7000000000003,
        "temperature": 0,
        "text": " this",
        "tokens": [
          50808,
          341,
          50860
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3836.7400000000002,
        "id": 835,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3834.7400000000002,
        "temperature": 0,
        "text": " All right. I think this might have worked",
        "tokens": [
          50860,
          1057,
          558,
          13,
          286,
          519,
          341,
          1062,
          362,
          2732,
          50960
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3841.78,
        "id": 836,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3840.02,
        "temperature": 0,
        "text": " And we can see",
        "tokens": [
          51124,
          400,
          321,
          393,
          536,
          51212
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3843.78,
        "id": 837,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3841.78,
        "temperature": 0,
        "text": " Oh, this is the wrong page again",
        "tokens": [
          51212,
          876,
          11,
          341,
          307,
          264,
          2085,
          3028,
          797,
          51312
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3851.32,
        "id": 838,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3843.94,
        "temperature": 0,
        "text": " Choo-choo choo-choo. Okay, we can see that work. So the all of this stuff is now hidden inside",
        "tokens": [
          51320,
          761,
          1986,
          12,
          339,
          1986,
          1586,
          78,
          12,
          339,
          1986,
          13,
          1033,
          11,
          321,
          393,
          536,
          300,
          589,
          13,
          407,
          264,
          439,
          295,
          341,
          1507,
          307,
          586,
          7633,
          1854,
          51689
        ]
      },
      {
        "avg_logprob": -0.22463874061508934,
        "compression_ratio": 1.6,
        "end": 3854.1600000000003,
        "id": 839,
        "no_speech_prob": 0.000041985716961789876,
        "seek": 382482,
        "start": 3852.5,
        "temperature": 0,
        "text": " my uh",
        "tokens": [
          51748,
          452,
          2232,
          51831
        ]
      },
      {
        "avg_logprob": -0.2480591942282284,
        "compression_ratio": 1.6648936170212767,
        "end": 3858.72,
        "id": 840,
        "no_speech_prob": 0.001367002259939909,
        "seek": 385416,
        "start": 3854.16,
        "temperature": 0,
        "text": " environment file and what i'm also going to do now, um is i'm going to make a",
        "tokens": [
          50364,
          2823,
          3991,
          293,
          437,
          741,
          478,
          611,
          516,
          281,
          360,
          586,
          11,
          1105,
          307,
          741,
          478,
          516,
          281,
          652,
          257,
          50592
        ]
      },
      {
        "avg_logprob": -0.2480591942282284,
        "compression_ratio": 1.6648936170212767,
        "end": 3867.04,
        "id": 841,
        "no_speech_prob": 0.001367002259939909,
        "seek": 385416,
        "start": 3860.24,
        "temperature": 0,
        "text": " Um, i'm going to make another file called dot env sample and then i'm going to copy this into there",
        "tokens": [
          50668,
          3301,
          11,
          741,
          478,
          516,
          281,
          652,
          1071,
          3991,
          1219,
          5893,
          2267,
          6889,
          293,
          550,
          741,
          478,
          516,
          281,
          5055,
          341,
          666,
          456,
          51008
        ]
      },
      {
        "avg_logprob": -0.2480591942282284,
        "compression_ratio": 1.6648936170212767,
        "end": 3870.3999999999996,
        "id": 842,
        "no_speech_prob": 0.001367002259939909,
        "seek": 385416,
        "start": 3868.56,
        "temperature": 0,
        "text": " Whoops",
        "tokens": [
          51084,
          45263,
          51176
        ]
      },
      {
        "avg_logprob": -0.2480591942282284,
        "compression_ratio": 1.6648936170212767,
        "end": 3874.3199999999997,
        "id": 843,
        "no_speech_prob": 0.001367002259939909,
        "seek": 385416,
        "start": 3870.3999999999996,
        "temperature": 0,
        "text": " Except I don't know how to use this computer thingy. Oh",
        "tokens": [
          51176,
          16192,
          286,
          500,
          380,
          458,
          577,
          281,
          764,
          341,
          3820,
          551,
          88,
          13,
          876,
          51372
        ]
      },
      {
        "avg_logprob": -0.2480591942282284,
        "compression_ratio": 1.6648936170212767,
        "end": 3883.3799999999997,
        "id": 844,
        "no_speech_prob": 0.001367002259939909,
        "seek": 385416,
        "start": 3878.08,
        "temperature": 0,
        "text": " Hold on let me do that again. I hate computers. What about delete delete",
        "tokens": [
          51560,
          6962,
          322,
          718,
          385,
          360,
          300,
          797,
          13,
          286,
          4700,
          10807,
          13,
          708,
          466,
          12097,
          12097,
          51825
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3885.7599999999998,
        "id": 845,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3884.3999999999996,
        "temperature": 0,
        "text": " Go away",
        "tokens": [
          50376,
          1037,
          1314,
          50444
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3887.04,
        "id": 846,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3885.7599999999998,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50444,
          1033,
          50508
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3889.04,
        "id": 847,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3887.04,
        "temperature": 0,
        "text": " I'm going to copy this",
        "tokens": [
          50508,
          286,
          478,
          516,
          281,
          5055,
          341,
          50608
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3891.44,
        "id": 848,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3889.52,
        "temperature": 0,
        "text": " into here",
        "tokens": [
          50632,
          666,
          510,
          50728
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3893.2799999999997,
        "id": 849,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3891.44,
        "temperature": 0,
        "text": " And then i'm going to take out",
        "tokens": [
          50728,
          400,
          550,
          741,
          478,
          516,
          281,
          747,
          484,
          50820
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3894.8799999999997,
        "id": 850,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3893.2799999999997,
        "temperature": 0,
        "text": " all this stuff",
        "tokens": [
          50820,
          439,
          341,
          1507,
          50900
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3898.08,
        "id": 851,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3894.8799999999997,
        "temperature": 0,
        "text": " Um, i'm going to make uh, because eventually i'll put this on git",
        "tokens": [
          50900,
          3301,
          11,
          741,
          478,
          516,
          281,
          652,
          2232,
          11,
          570,
          4728,
          741,
          603,
          829,
          341,
          322,
          18331,
          51060
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3901.44,
        "id": 852,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3898.8799999999997,
        "temperature": 0,
        "text": " Um, i'm going to make a file called dot git ignore",
        "tokens": [
          51100,
          3301,
          11,
          741,
          478,
          516,
          281,
          652,
          257,
          3991,
          1219,
          5893,
          18331,
          11200,
          51228
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3904.48,
        "id": 853,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3902.16,
        "temperature": 0,
        "text": " And then i'm going to say a dot env",
        "tokens": [
          51264,
          400,
          550,
          741,
          478,
          516,
          281,
          584,
          257,
          5893,
          2267,
          51380
        ]
      },
      {
        "avg_logprob": -0.18145076901304955,
        "compression_ratio": 1.7696629213483146,
        "end": 3910.24,
        "id": 854,
        "no_speech_prob": 0.000004860438821197022,
        "seek": 388416,
        "start": 3905.04,
        "temperature": 0,
        "text": " So basically what i've done is i'm saying hey, this is my file dot env",
        "tokens": [
          51408,
          407,
          1936,
          437,
          741,
          600,
          1096,
          307,
          741,
          478,
          1566,
          4177,
          11,
          341,
          307,
          452,
          3991,
          5893,
          2267,
          51668
        ]
      },
      {
        "avg_logprob": -0.19175780979932938,
        "compression_ratio": 1.6564885496183206,
        "end": 3913.9199999999996,
        "id": 855,
        "no_speech_prob": 0.00015118156443350017,
        "seek": 391024,
        "start": 3910.3199999999997,
        "temperature": 0,
        "text": " That's my file that i'm only ever going to have locally on my computer",
        "tokens": [
          50368,
          663,
          311,
          452,
          3991,
          300,
          741,
          478,
          787,
          1562,
          516,
          281,
          362,
          16143,
          322,
          452,
          3820,
          50548
        ]
      },
      {
        "avg_logprob": -0.19175780979932938,
        "compression_ratio": 1.6564885496183206,
        "end": 3918.08,
        "id": 856,
        "no_speech_prob": 0.00015118156443350017,
        "seek": 391024,
        "start": 3914.64,
        "temperature": 0,
        "text": " But when I publish this i'm going to publish a sample one",
        "tokens": [
          50584,
          583,
          562,
          286,
          11374,
          341,
          741,
          478,
          516,
          281,
          11374,
          257,
          6889,
          472,
          50756
        ]
      },
      {
        "avg_logprob": -0.19175780979932938,
        "compression_ratio": 1.6564885496183206,
        "end": 3921.2799999999997,
        "id": 857,
        "no_speech_prob": 0.00015118156443350017,
        "seek": 391024,
        "start": 3918.3199999999997,
        "temperature": 0,
        "text": " Which has information basically about what you need to put in there",
        "tokens": [
          50768,
          3013,
          575,
          1589,
          1936,
          466,
          437,
          291,
          643,
          281,
          829,
          294,
          456,
          50916
        ]
      },
      {
        "avg_logprob": -0.19175780979932938,
        "compression_ratio": 1.6564885496183206,
        "end": 3927.9399999999996,
        "id": 858,
        "no_speech_prob": 0.00015118156443350017,
        "seek": 391024,
        "start": 3921.68,
        "temperature": 0,
        "text": " And then i'm going to make sure that the actual dot env file is not included if I ever check this into a git repository",
        "tokens": [
          50936,
          400,
          550,
          741,
          478,
          516,
          281,
          652,
          988,
          300,
          264,
          3539,
          5893,
          2267,
          3991,
          307,
          406,
          5556,
          498,
          286,
          1562,
          1520,
          341,
          666,
          257,
          18331,
          25841,
          51249
        ]
      },
      {
        "avg_logprob": -0.19175780979932938,
        "compression_ratio": 1.6564885496183206,
        "end": 3932.16,
        "id": 859,
        "no_speech_prob": 0.00015118156443350017,
        "seek": 391024,
        "start": 3928.3199999999997,
        "temperature": 0,
        "text": " Uploaded on github so to speak. All right, let's make sure this works",
        "tokens": [
          51268,
          624,
          21132,
          12777,
          322,
          290,
          355,
          836,
          370,
          281,
          1710,
          13,
          1057,
          558,
          11,
          718,
          311,
          652,
          988,
          341,
          1985,
          51460
        ]
      },
      {
        "avg_logprob": -0.19175780979932938,
        "compression_ratio": 1.6564885496183206,
        "end": 3938.56,
        "id": 860,
        "no_speech_prob": 0.00015118156443350017,
        "seek": 391024,
        "start": 3935.04,
        "temperature": 0,
        "text": " Still working, um, we can go here and i've said",
        "tokens": [
          51604,
          8291,
          1364,
          11,
          1105,
          11,
          321,
          393,
          352,
          510,
          293,
          741,
          600,
          848,
          51780
        ]
      },
      {
        "avg_logprob": -0.24501206582052665,
        "compression_ratio": 1.6877470355731226,
        "end": 3945.3599999999997,
        "id": 861,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 394024,
        "start": 3940.56,
        "temperature": 0,
        "text": " Somebody definitely hacked my bot so i'm going to reach is great because I had my keys up on the screen",
        "tokens": [
          50380,
          13463,
          2138,
          36218,
          452,
          10592,
          370,
          741,
          478,
          516,
          281,
          319,
          64,
          339,
          307,
          869,
          570,
          286,
          632,
          452,
          9317,
          493,
          322,
          264,
          2568,
          50620
        ]
      },
      {
        "avg_logprob": -0.24501206582052665,
        "compression_ratio": 1.6877470355731226,
        "end": 3951.9199999999996,
        "id": 862,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 394024,
        "start": 3946.8799999999997,
        "temperature": 0,
        "text": " Well done whoever you are and um, I am going to uh, take a break",
        "tokens": [
          50696,
          1042,
          1096,
          11387,
          291,
          366,
          293,
          1105,
          11,
          286,
          669,
          516,
          281,
          2232,
          11,
          747,
          257,
          1821,
          50948
        ]
      },
      {
        "avg_logprob": -0.24501206582052665,
        "compression_ratio": 1.6877470355731226,
        "end": 3953.4199999999996,
        "id": 863,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 394024,
        "start": 3952.4799999999996,
        "temperature": 0,
        "text": " and uh",
        "tokens": [
          50976,
          293,
          2232,
          51023
        ]
      },
      {
        "avg_logprob": -0.24501206582052665,
        "compression_ratio": 1.6877470355731226,
        "end": 3957.8399999999997,
        "id": 864,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 394024,
        "start": 3953.4199999999996,
        "temperature": 0,
        "text": " Regenerate my access keys so that nobody else can hack my bot keep them hidden in my environment file",
        "tokens": [
          51023,
          4791,
          7971,
          473,
          452,
          2105,
          9317,
          370,
          300,
          5079,
          1646,
          393,
          10339,
          452,
          10592,
          1066,
          552,
          7633,
          294,
          452,
          2823,
          3991,
          51244
        ]
      },
      {
        "avg_logprob": -0.24501206582052665,
        "compression_ratio": 1.6877470355731226,
        "end": 3960.64,
        "id": 865,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 394024,
        "start": 3958.16,
        "temperature": 0,
        "text": " and then I am going to",
        "tokens": [
          51260,
          293,
          550,
          286,
          669,
          516,
          281,
          51384
        ]
      },
      {
        "avg_logprob": -0.24501206582052665,
        "compression_ratio": 1.6877470355731226,
        "end": 3967.52,
        "id": 866,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 394024,
        "start": 3961.12,
        "temperature": 0,
        "text": " Before something bad happens. I'm going to just close out of this window and i'm going to come back and show you more",
        "tokens": [
          51408,
          4546,
          746,
          1578,
          2314,
          13,
          286,
          478,
          516,
          281,
          445,
          1998,
          484,
          295,
          341,
          4910,
          293,
          741,
          478,
          516,
          281,
          808,
          646,
          293,
          855,
          291,
          544,
          51728
        ]
      },
      {
        "avg_logprob": -0.24501206582052665,
        "compression_ratio": 1.6877470355731226,
        "end": 3969.68,
        "id": 867,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 394024,
        "start": 3968.16,
        "temperature": 0,
        "text": " about um",
        "tokens": [
          51760,
          466,
          1105,
          51836
        ]
      },
      {
        "avg_logprob": -0.25923049996752257,
        "compression_ratio": 1.6926605504587156,
        "end": 3973.68,
        "id": 868,
        "no_speech_prob": 0.0008040345855988562,
        "seek": 396968,
        "start": 3969.68,
        "temperature": 0,
        "text": " Writing mastodon bots and i'm going to i'm going to show you this fun thing called spoiler text",
        "tokens": [
          50364,
          32774,
          27055,
          378,
          266,
          35410,
          293,
          741,
          478,
          516,
          281,
          741,
          478,
          516,
          281,
          855,
          291,
          341,
          1019,
          551,
          1219,
          26927,
          2487,
          50564
        ]
      },
      {
        "avg_logprob": -0.25923049996752257,
        "compression_ratio": 1.6926605504587156,
        "end": 3980.56,
        "id": 869,
        "no_speech_prob": 0.0008040345855988562,
        "seek": 396968,
        "start": 3974.24,
        "temperature": 0,
        "text": " Um, and how to have the bot post to mastodon periodically every so often. Okay, so see you in the next video",
        "tokens": [
          50592,
          3301,
          11,
          293,
          577,
          281,
          362,
          264,
          10592,
          2183,
          281,
          27055,
          378,
          266,
          38916,
          633,
          370,
          2049,
          13,
          1033,
          11,
          370,
          536,
          291,
          294,
          264,
          958,
          960,
          50908
        ]
      },
      {
        "avg_logprob": -0.25923049996752257,
        "compression_ratio": 1.6926605504587156,
        "end": 3989.12,
        "id": 870,
        "no_speech_prob": 0.0008040345855988562,
        "seek": 396968,
        "start": 3983.2,
        "temperature": 0,
        "text": " All right, so I am going to now go to uh, choo choo not choo choo dot space no no bots in space",
        "tokens": [
          51040,
          1057,
          558,
          11,
          370,
          286,
          669,
          516,
          281,
          586,
          352,
          281,
          2232,
          11,
          1586,
          78,
          1586,
          78,
          406,
          1586,
          78,
          1586,
          78,
          5893,
          1901,
          572,
          572,
          35410,
          294,
          1901,
          51336
        ]
      },
      {
        "avg_logprob": -0.25923049996752257,
        "compression_ratio": 1.6926605504587156,
        "end": 3992.48,
        "id": 871,
        "no_speech_prob": 0.0008040345855988562,
        "seek": 396968,
        "start": 3989.2799999999997,
        "temperature": 0,
        "text": " I can't ever remember which thing i'm at i'm gonna go to",
        "tokens": [
          51344,
          286,
          393,
          380,
          1562,
          1604,
          597,
          551,
          741,
          478,
          412,
          741,
          478,
          799,
          352,
          281,
          51504
        ]
      },
      {
        "avg_logprob": -0.25923049996752257,
        "compression_ratio": 1.6926605504587156,
        "end": 3995.04,
        "id": 872,
        "no_speech_prob": 0.0008040345855988562,
        "seek": 396968,
        "start": 3993.04,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51532,
          1105,
          51632
        ]
      },
      {
        "avg_logprob": -0.25923049996752257,
        "compression_ratio": 1.6926605504587156,
        "end": 3997.52,
        "id": 873,
        "no_speech_prob": 0.0008040345855988562,
        "seek": 396968,
        "start": 3995.52,
        "temperature": 0,
        "text": " Settings",
        "tokens": [
          51656,
          27286,
          51756
        ]
      },
      {
        "avg_logprob": -0.20694400787353515,
        "compression_ratio": 1.673913043478261,
        "end": 3999.52,
        "id": 874,
        "no_speech_prob": 0.00017400163051206619,
        "seek": 399752,
        "start": 3997.52,
        "temperature": 0,
        "text": " Uh developer development",
        "tokens": [
          50364,
          4019,
          10754,
          3250,
          50464
        ]
      },
      {
        "avg_logprob": -0.20694400787353515,
        "compression_ratio": 1.673913043478261,
        "end": 4002.8,
        "id": 875,
        "no_speech_prob": 0.00017400163051206619,
        "seek": 399752,
        "start": 4000.8,
        "temperature": 0,
        "text": " Here we go",
        "tokens": [
          50528,
          1692,
          321,
          352,
          50628
        ]
      },
      {
        "avg_logprob": -0.20694400787353515,
        "compression_ratio": 1.673913043478261,
        "end": 4009.6,
        "id": 876,
        "no_speech_prob": 0.00017400163051206619,
        "seek": 399752,
        "start": 4003.04,
        "temperature": 0,
        "text": " I'm going to say goodbye to the screen everybody. I'm now going to regenerate my access token the client key and client secret",
        "tokens": [
          50640,
          286,
          478,
          516,
          281,
          584,
          12084,
          281,
          264,
          2568,
          2201,
          13,
          286,
          478,
          586,
          516,
          281,
          26358,
          473,
          452,
          2105,
          14862,
          264,
          6423,
          2141,
          293,
          6423,
          4054,
          50968
        ]
      },
      {
        "avg_logprob": -0.20694400787353515,
        "compression_ratio": 1.673913043478261,
        "end": 4011.2,
        "id": 877,
        "no_speech_prob": 0.00017400163051206619,
        "seek": 399752,
        "start": 4009.6,
        "temperature": 0,
        "text": " I don't think change",
        "tokens": [
          50968,
          286,
          500,
          380,
          519,
          1319,
          51048
        ]
      },
      {
        "avg_logprob": -0.20694400787353515,
        "compression_ratio": 1.673913043478261,
        "end": 4014.24,
        "id": 878,
        "no_speech_prob": 0.00017400163051206619,
        "seek": 399752,
        "start": 4011.2,
        "temperature": 0,
        "text": " They're the same. So oh, well you all have those",
        "tokens": [
          51048,
          814,
          434,
          264,
          912,
          13,
          407,
          1954,
          11,
          731,
          291,
          439,
          362,
          729,
          51200
        ]
      },
      {
        "avg_logprob": -0.20694400787353515,
        "compression_ratio": 1.673913043478261,
        "end": 4020.08,
        "id": 879,
        "no_speech_prob": 0.00017400163051206619,
        "seek": 399752,
        "start": 4014.8,
        "temperature": 0,
        "text": " But you cannot have my access token, which is a little unfortunate. Actually, you know what? Maybe I should delete this one",
        "tokens": [
          51228,
          583,
          291,
          2644,
          362,
          452,
          2105,
          14862,
          11,
          597,
          307,
          257,
          707,
          17843,
          13,
          5135,
          11,
          291,
          458,
          437,
          30,
          2704,
          286,
          820,
          12097,
          341,
          472,
          51492
        ]
      },
      {
        "avg_logprob": -0.20694400787353515,
        "compression_ratio": 1.673913043478261,
        "end": 4022.16,
        "id": 880,
        "no_speech_prob": 0.00017400163051206619,
        "seek": 399752,
        "start": 4020.16,
        "temperature": 0,
        "text": " I'm going to delete this one",
        "tokens": [
          51496,
          286,
          478,
          516,
          281,
          12097,
          341,
          472,
          51596
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4025.52,
        "id": 881,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4022.8799999999997,
        "temperature": 0,
        "text": " Um, let me see if I can delete i'm going to delete it and start over",
        "tokens": [
          50400,
          3301,
          11,
          718,
          385,
          536,
          498,
          286,
          393,
          12097,
          741,
          478,
          516,
          281,
          12097,
          309,
          293,
          722,
          670,
          50532
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4027.8399999999997,
        "id": 882,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4025.8399999999997,
        "temperature": 0,
        "text": " sorry that you can't see what i'm doing because",
        "tokens": [
          50548,
          2597,
          300,
          291,
          393,
          380,
          536,
          437,
          741,
          478,
          884,
          570,
          50648
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4030.24,
        "id": 883,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4028.16,
        "temperature": 0,
        "text": " it's actually not so great for everybody to have the",
        "tokens": [
          50664,
          309,
          311,
          767,
          406,
          370,
          869,
          337,
          2201,
          281,
          362,
          264,
          50768
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4031.92,
        "id": 884,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4030.8799999999997,
        "temperature": 0,
        "text": " client",
        "tokens": [
          50800,
          6423,
          50852
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4036.24,
        "id": 885,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4031.92,
        "temperature": 0,
        "text": " Secret client id because you could still write a bot and then and then like authorize with for the access token",
        "tokens": [
          50852,
          7400,
          6423,
          4496,
          570,
          291,
          727,
          920,
          2464,
          257,
          10592,
          293,
          550,
          293,
          550,
          411,
          3793,
          1125,
          365,
          337,
          264,
          2105,
          14862,
          51068
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4038.72,
        "id": 886,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4036.72,
        "temperature": 0,
        "text": " So i'm just going to regenerate everything",
        "tokens": [
          51092,
          407,
          741,
          478,
          445,
          516,
          281,
          26358,
          473,
          1203,
          51192
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4041.68,
        "id": 887,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4039.68,
        "temperature": 0,
        "text": " I'm going to hit submit",
        "tokens": [
          51240,
          286,
          478,
          516,
          281,
          2045,
          10315,
          51340
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4047.3599999999997,
        "id": 888,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4042.3999999999996,
        "temperature": 0,
        "text": " Um, and then i'm going to get those now. I have all three new things. You can't see what i'm doing",
        "tokens": [
          51376,
          3301,
          11,
          293,
          550,
          741,
          478,
          516,
          281,
          483,
          729,
          586,
          13,
          286,
          362,
          439,
          1045,
          777,
          721,
          13,
          509,
          393,
          380,
          536,
          437,
          741,
          478,
          884,
          51624
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4049.68,
        "id": 889,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4048.48,
        "temperature": 0,
        "text": " token",
        "tokens": [
          51680,
          14862,
          51740
        ]
      },
      {
        "avg_logprob": -0.19846963170749038,
        "compression_ratio": 1.881679389312977,
        "end": 4051.68,
        "id": 890,
        "no_speech_prob": 0.00016603522817604244,
        "seek": 402216,
        "start": 4049.68,
        "temperature": 0,
        "text": " That was the client key actually",
        "tokens": [
          51740,
          663,
          390,
          264,
          6423,
          2141,
          767,
          51840
        ]
      },
      {
        "avg_logprob": -0.2157271228619476,
        "compression_ratio": 1.5031446540880504,
        "end": 4053.6,
        "id": 891,
        "no_speech_prob": 0.00021994419512338936,
        "seek": 405168,
        "start": 4051.8399999999997,
        "temperature": 0,
        "text": " client key",
        "tokens": [
          50372,
          6423,
          2141,
          50460
        ]
      },
      {
        "avg_logprob": -0.2157271228619476,
        "compression_ratio": 1.5031446540880504,
        "end": 4055.6,
        "id": 892,
        "no_speech_prob": 0.00021994419512338936,
        "seek": 405168,
        "start": 4053.6,
        "temperature": 0,
        "text": " uh client secret",
        "tokens": [
          50460,
          2232,
          6423,
          4054,
          50560
        ]
      },
      {
        "avg_logprob": -0.2157271228619476,
        "compression_ratio": 1.5031446540880504,
        "end": 4060,
        "id": 893,
        "no_speech_prob": 0.00021994419512338936,
        "seek": 405168,
        "start": 4057.3599999999997,
        "temperature": 0,
        "text": " Sorry that i have to narrate this and access token",
        "tokens": [
          50648,
          4919,
          300,
          741,
          362,
          281,
          6397,
          473,
          341,
          293,
          2105,
          14862,
          50780
        ]
      },
      {
        "avg_logprob": -0.2157271228619476,
        "compression_ratio": 1.5031446540880504,
        "end": 4063.68,
        "id": 894,
        "no_speech_prob": 0.00021994419512338936,
        "seek": 405168,
        "start": 4061.68,
        "temperature": 0,
        "text": " Save",
        "tokens": [
          50864,
          15541,
          50964
        ]
      },
      {
        "avg_logprob": -0.2157271228619476,
        "compression_ratio": 1.5031446540880504,
        "end": 4071.2799999999997,
        "id": 895,
        "no_speech_prob": 0.00021994419512338936,
        "seek": 405168,
        "start": 4063.7599999999998,
        "temperature": 0,
        "text": " Save close close bring that back. Uh, and now let's just run this one more time",
        "tokens": [
          50968,
          15541,
          1998,
          1998,
          1565,
          300,
          646,
          13,
          4019,
          11,
          293,
          586,
          718,
          311,
          445,
          1190,
          341,
          472,
          544,
          565,
          51344
        ]
      },
      {
        "avg_logprob": -0.2157271228619476,
        "compression_ratio": 1.5031446540880504,
        "end": 4078.16,
        "id": 896,
        "no_speech_prob": 0.00021994419512338936,
        "seek": 405168,
        "start": 4073.52,
        "temperature": 0,
        "text": " Great all right. Thank you. I hope you all enjoyed your time hacking my bot",
        "tokens": [
          51456,
          3769,
          439,
          558,
          13,
          1044,
          291,
          13,
          286,
          1454,
          291,
          439,
          4626,
          428,
          565,
          31422,
          452,
          10592,
          51688
        ]
      },
      {
        "avg_logprob": -0.2999378522237142,
        "compression_ratio": 1.408450704225352,
        "end": 4085.7,
        "id": 897,
        "no_speech_prob": 0.0005112519720569253,
        "seek": 407816,
        "start": 4079.04,
        "temperature": 0,
        "text": " Ah shoot I came up i'm such a doofus. All right one more time everybody",
        "tokens": [
          50408,
          2438,
          3076,
          286,
          1361,
          493,
          741,
          478,
          1270,
          257,
          360,
          2670,
          301,
          13,
          1057,
          558,
          472,
          544,
          565,
          2201,
          50741
        ]
      },
      {
        "avg_logprob": -0.2999378522237142,
        "compression_ratio": 1.408450704225352,
        "end": 4095.3599999999997,
        "id": 898,
        "no_speech_prob": 0.0005112519720569253,
        "seek": 407816,
        "start": 4090.24,
        "temperature": 0,
        "text": " All right, i'm the worst I am the worst delete it's all gone",
        "tokens": [
          50968,
          1057,
          558,
          11,
          741,
          478,
          264,
          5855,
          286,
          669,
          264,
          5855,
          12097,
          309,
          311,
          439,
          2780,
          51224
        ]
      },
      {
        "avg_logprob": -0.2999378522237142,
        "compression_ratio": 1.408450704225352,
        "end": 4100.32,
        "id": 899,
        "no_speech_prob": 0.0005112519720569253,
        "seek": 407816,
        "start": 4097.04,
        "temperature": 0,
        "text": " New application coding train example bot",
        "tokens": [
          51308,
          1873,
          3861,
          17720,
          3847,
          1365,
          10592,
          51472
        ]
      },
      {
        "avg_logprob": -0.2999378522237142,
        "compression_ratio": 1.408450704225352,
        "end": 4103.76,
        "id": 900,
        "no_speech_prob": 0.0005112519720569253,
        "seek": 407816,
        "start": 4101.76,
        "temperature": 0,
        "text": " Uh coding train.com",
        "tokens": [
          51544,
          4019,
          17720,
          3847,
          13,
          1112,
          51644
        ]
      },
      {
        "avg_logprob": -0.2999378522237142,
        "compression_ratio": 1.408450704225352,
        "end": 4107.599999999999,
        "id": 901,
        "no_speech_prob": 0.0005112519720569253,
        "seek": 407816,
        "start": 4105.76,
        "temperature": 0,
        "text": " Submit",
        "tokens": [
          51744,
          8511,
          3508,
          51836
        ]
      },
      {
        "avg_logprob": -0.23824085908777573,
        "compression_ratio": 1.6027397260273972,
        "end": 4111.360000000001,
        "id": 902,
        "no_speech_prob": 0.00008750188135309145,
        "seek": 410760,
        "start": 4107.6,
        "temperature": 0,
        "text": " Here we go. I got a new client key everybody new client key",
        "tokens": [
          50364,
          1692,
          321,
          352,
          13,
          286,
          658,
          257,
          777,
          6423,
          2141,
          2201,
          777,
          6423,
          2141,
          50552
        ]
      },
      {
        "avg_logprob": -0.23824085908777573,
        "compression_ratio": 1.6027397260273972,
        "end": 4118.96,
        "id": 903,
        "no_speech_prob": 0.00008750188135309145,
        "seek": 410760,
        "start": 4113.4400000000005,
        "temperature": 0,
        "text": " Uh client key now I got a new client secret starts with f7",
        "tokens": [
          50656,
          4019,
          6423,
          2141,
          586,
          286,
          658,
          257,
          777,
          6423,
          4054,
          3719,
          365,
          283,
          22,
          50932
        ]
      },
      {
        "avg_logprob": -0.23824085908777573,
        "compression_ratio": 1.6027397260273972,
        "end": 4122.240000000001,
        "id": 904,
        "no_speech_prob": 0.00008750188135309145,
        "seek": 410760,
        "start": 4120.240000000001,
        "temperature": 0,
        "text": " the new access token",
        "tokens": [
          50996,
          264,
          777,
          2105,
          14862,
          51096
        ]
      },
      {
        "avg_logprob": -0.23824085908777573,
        "compression_ratio": 1.6027397260273972,
        "end": 4131.92,
        "id": 905,
        "no_speech_prob": 0.00008750188135309145,
        "seek": 410760,
        "start": 4125.92,
        "temperature": 0,
        "text": " And now i'm going to close both the dot env file and i'm also going to get out of that page",
        "tokens": [
          51280,
          400,
          586,
          741,
          478,
          516,
          281,
          1998,
          1293,
          264,
          5893,
          2267,
          3991,
          293,
          741,
          478,
          611,
          516,
          281,
          483,
          484,
          295,
          300,
          3028,
          51580
        ]
      },
      {
        "avg_logprob": -0.23824085908777573,
        "compression_ratio": 1.6027397260273972,
        "end": 4134.64,
        "id": 906,
        "no_speech_prob": 0.00008750188135309145,
        "seek": 410760,
        "start": 4133.120000000001,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51640,
          1105,
          51716
        ]
      },
      {
        "avg_logprob": -0.1756718635559082,
        "compression_ratio": 1.3571428571428572,
        "end": 4140.240000000001,
        "id": 907,
        "no_speech_prob": 0.00017130681953858584,
        "seek": 413464,
        "start": 4134.64,
        "temperature": 0,
        "text": " And I am going to bring this back up now i'm going to make sure it works",
        "tokens": [
          50364,
          400,
          286,
          669,
          516,
          281,
          1565,
          341,
          646,
          493,
          586,
          741,
          478,
          516,
          281,
          652,
          988,
          309,
          1985,
          50644
        ]
      },
      {
        "avg_logprob": -0.1756718635559082,
        "compression_ratio": 1.3571428571428572,
        "end": 4149.84,
        "id": 908,
        "no_speech_prob": 0.00017130681953858584,
        "seek": 413464,
        "start": 4144.4800000000005,
        "temperature": 0,
        "text": " There we go go here now, there we go. All right now we should also do some stuff",
        "tokens": [
          50856,
          821,
          321,
          352,
          352,
          510,
          586,
          11,
          456,
          321,
          352,
          13,
          1057,
          558,
          586,
          321,
          820,
          611,
          360,
          512,
          1507,
          51124
        ]
      },
      {
        "avg_logprob": -0.1756718635559082,
        "compression_ratio": 1.3571428571428572,
        "end": 4152.56,
        "id": 909,
        "no_speech_prob": 0.00017130681953858584,
        "seek": 413464,
        "start": 4150.56,
        "temperature": 0,
        "text": " Um, can I quickly?",
        "tokens": [
          51160,
          3301,
          11,
          393,
          286,
          2661,
          30,
          51260
        ]
      },
      {
        "avg_logprob": -0.1756718635559082,
        "compression_ratio": 1.3571428571428572,
        "end": 4155.280000000001,
        "id": 910,
        "no_speech_prob": 0.00017130681953858584,
        "seek": 413464,
        "start": 4153.280000000001,
        "temperature": 0,
        "text": " Hold on a sec. Um",
        "tokens": [
          51296,
          6962,
          322,
          257,
          907,
          13,
          3301,
          51396
        ]
      },
      {
        "avg_logprob": -0.5419425056094215,
        "compression_ratio": 1.4720812182741116,
        "end": 4161.04,
        "id": 911,
        "no_speech_prob": 0.003075278364121914,
        "seek": 415528,
        "start": 4156,
        "temperature": 0,
        "text": " Most people put the require. Okay, I will fix that. Thank you alco for a comment about where to put the require",
        "tokens": [
          50400,
          4534,
          561,
          829,
          264,
          3651,
          13,
          1033,
          11,
          286,
          486,
          3191,
          300,
          13,
          1044,
          291,
          419,
          1291,
          337,
          257,
          2871,
          466,
          689,
          281,
          829,
          264,
          3651,
          50652
        ]
      },
      {
        "avg_logprob": -0.5419425056094215,
        "compression_ratio": 1.4720812182741116,
        "end": 4163.759999999999,
        "id": 912,
        "no_speech_prob": 0.003075278364121914,
        "seek": 415528,
        "start": 4162.32,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50716,
          1105,
          50788
        ]
      },
      {
        "avg_logprob": -0.5419425056094215,
        "compression_ratio": 1.4720812182741116,
        "end": 4168.48,
        "id": 913,
        "no_speech_prob": 0.003075278364121914,
        "seek": 415528,
        "start": 4163.759999999999,
        "temperature": 0,
        "text": " All right. So now let me just do something real quick. What was I on bots in space?",
        "tokens": [
          50788,
          1057,
          558,
          13,
          407,
          586,
          718,
          385,
          445,
          360,
          746,
          957,
          1702,
          13,
          708,
          390,
          286,
          322,
          35410,
          294,
          1901,
          30,
          51024
        ]
      },
      {
        "avg_logprob": -0.5419425056094215,
        "compression_ratio": 1.4720812182741116,
        "end": 4173.2,
        "id": 914,
        "no_speech_prob": 0.003075278364121914,
        "seek": 415528,
        "start": 4169.679999999999,
        "temperature": 0,
        "text": " Login, um, what was it called coding train bot?",
        "tokens": [
          51084,
          10824,
          259,
          11,
          1105,
          11,
          437,
          390,
          309,
          1219,
          17720,
          3847,
          10592,
          30,
          51260
        ]
      },
      {
        "avg_logprob": -0.5419425056094215,
        "compression_ratio": 1.4720812182741116,
        "end": 4177.92,
        "id": 915,
        "no_speech_prob": 0.003075278364121914,
        "seek": 415528,
        "start": 4175.92,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51396,
          3301,
          51496
        ]
      },
      {
        "avg_logprob": -0.5419425056094215,
        "compression_ratio": 1.4720812182741116,
        "end": 4181.28,
        "id": 916,
        "no_speech_prob": 0.003075278364121914,
        "seek": 415528,
        "start": 4178.48,
        "temperature": 0,
        "text": " Email address daniel at the coding train",
        "tokens": [
          51524,
          49482,
          2985,
          3277,
          1187,
          412,
          264,
          17720,
          3847,
          51664
        ]
      },
      {
        "avg_logprob": -0.26991821737850413,
        "compression_ratio": 1.392156862745098,
        "end": 4186.099999999999,
        "id": 917,
        "no_speech_prob": 0.00014202164311427623,
        "seek": 418128,
        "start": 4181.92,
        "temperature": 0,
        "text": " Um email address daniel at the coding train.com",
        "tokens": [
          50396,
          3301,
          3796,
          2985,
          3277,
          1187,
          412,
          264,
          17720,
          3847,
          13,
          1112,
          50605
        ]
      },
      {
        "avg_logprob": -0.26991821737850413,
        "compression_ratio": 1.392156862745098,
        "end": 4190.8,
        "id": 918,
        "no_speech_prob": 0.00014202164311427623,
        "seek": 418128,
        "start": 4186.88,
        "temperature": 0,
        "text": " So I just want to add a like a header and stuff and I have it on this computer. So",
        "tokens": [
          50644,
          407,
          286,
          445,
          528,
          281,
          909,
          257,
          411,
          257,
          23117,
          293,
          1507,
          293,
          286,
          362,
          309,
          322,
          341,
          3820,
          13,
          407,
          50840
        ]
      },
      {
        "avg_logprob": -0.26991821737850413,
        "compression_ratio": 1.392156862745098,
        "end": 4193.44,
        "id": 919,
        "no_speech_prob": 0.00014202164311427623,
        "seek": 418128,
        "start": 4191.44,
        "temperature": 0,
        "text": " Uh, sorry, you can't see what i'm doing",
        "tokens": [
          50872,
          4019,
          11,
          2597,
          11,
          291,
          393,
          380,
          536,
          437,
          741,
          478,
          884,
          50972
        ]
      },
      {
        "avg_logprob": -0.26991821737850413,
        "compression_ratio": 1.392156862745098,
        "end": 4195.5,
        "id": 920,
        "no_speech_prob": 0.00014202164311427623,
        "seek": 418128,
        "start": 4193.5,
        "temperature": 0,
        "text": " rainbow",
        "tokens": [
          50975,
          18526,
          51075
        ]
      },
      {
        "avg_logprob": -0.26991821737850413,
        "compression_ratio": 1.392156862745098,
        "end": 4200.66,
        "id": 921,
        "no_speech_prob": 0.00014202164311427623,
        "seek": 418128,
        "start": 4195.84,
        "temperature": 0,
        "text": " Uh, oh no i'm signing up ah log in",
        "tokens": [
          51092,
          4019,
          11,
          1954,
          572,
          741,
          478,
          13393,
          493,
          3716,
          3565,
          294,
          51333
        ]
      },
      {
        "avg_logprob": -0.28921701257879084,
        "compression_ratio": 1.3225806451612903,
        "end": 4203.38,
        "id": 922,
        "no_speech_prob": 0.000291367614408955,
        "seek": 420066,
        "start": 4201.38,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50400,
          3301,
          50500
        ]
      },
      {
        "avg_logprob": -0.28921701257879084,
        "compression_ratio": 1.3225806451612903,
        "end": 4217.48,
        "id": 923,
        "no_speech_prob": 0.000291367614408955,
        "seek": 420066,
        "start": 4214.0199999999995,
        "temperature": 0,
        "text": " Um, okay and edit profile",
        "tokens": [
          51032,
          3301,
          11,
          1392,
          293,
          8129,
          7964,
          51205
        ]
      },
      {
        "avg_logprob": -0.28921701257879084,
        "compression_ratio": 1.3225806451612903,
        "end": 4223.24,
        "id": 924,
        "no_speech_prob": 0.000291367614408955,
        "seek": 420066,
        "start": 4219.139999999999,
        "temperature": 0,
        "text": " Somebody i'm getting like a lot spammed here. Oh, no, somebody's just favoring a lot of my statuses",
        "tokens": [
          51288,
          13463,
          741,
          478,
          1242,
          411,
          257,
          688,
          637,
          19859,
          510,
          13,
          876,
          11,
          572,
          11,
          2618,
          311,
          445,
          2294,
          278,
          257,
          688,
          295,
          452,
          6558,
          279,
          51493
        ]
      },
      {
        "avg_logprob": -0.28921701257879084,
        "compression_ratio": 1.3225806451612903,
        "end": 4226.18,
        "id": 925,
        "no_speech_prob": 0.000291367614408955,
        "seek": 420066,
        "start": 4224.18,
        "temperature": 0,
        "text": " Um, i'm going to",
        "tokens": [
          51540,
          3301,
          11,
          741,
          478,
          516,
          281,
          51640
        ]
      },
      {
        "avg_logprob": -0.28921701257879084,
        "compression_ratio": 1.3225806451612903,
        "end": 4228.74,
        "id": 926,
        "no_speech_prob": 0.000291367614408955,
        "seek": 420066,
        "start": 4226.74,
        "temperature": 0,
        "text": " Get an avatar here",
        "tokens": [
          51668,
          3240,
          364,
          36205,
          510,
          51768
        ]
      },
      {
        "avg_logprob": -0.34080613943246696,
        "compression_ratio": 1.3557046979865772,
        "end": 4231.139999999999,
        "id": 927,
        "no_speech_prob": 0.00011774250015150756,
        "seek": 422874,
        "start": 4229.139999999999,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50384,
          3301,
          50484
        ]
      },
      {
        "avg_logprob": -0.34080613943246696,
        "compression_ratio": 1.3557046979865772,
        "end": 4235.86,
        "id": 928,
        "no_speech_prob": 0.00011774250015150756,
        "seek": 422874,
        "start": 4232.099999999999,
        "temperature": 0,
        "text": " Where can I find this? Uh, here we go",
        "tokens": [
          50532,
          2305,
          393,
          286,
          915,
          341,
          30,
          4019,
          11,
          510,
          321,
          352,
          50720
        ]
      },
      {
        "avg_logprob": -0.34080613943246696,
        "compression_ratio": 1.3557046979865772,
        "end": 4240.98,
        "id": 929,
        "no_speech_prob": 0.00011774250015150756,
        "seek": 422874,
        "start": 4238.98,
        "temperature": 0,
        "text": " Like the",
        "tokens": [
          50876,
          1743,
          264,
          50976
        ]
      },
      {
        "avg_logprob": -0.34080613943246696,
        "compression_ratio": 1.3557046979865772,
        "end": 4245.44,
        "id": 930,
        "no_speech_prob": 0.00011774250015150756,
        "seek": 422874,
        "start": 4243.44,
        "temperature": 0,
        "text": " Semicolon all right",
        "tokens": [
          51099,
          318,
          3438,
          38780,
          439,
          558,
          51199
        ]
      },
      {
        "avg_logprob": -0.34080613943246696,
        "compression_ratio": 1.3557046979865772,
        "end": 4250.099999999999,
        "id": 931,
        "no_speech_prob": 0.00011774250015150756,
        "seek": 422874,
        "start": 4248.0199999999995,
        "temperature": 0,
        "text": " Okay, I can play around with the",
        "tokens": [
          51328,
          1033,
          11,
          286,
          393,
          862,
          926,
          365,
          264,
          51432
        ]
      },
      {
        "avg_logprob": -0.34080613943246696,
        "compression_ratio": 1.3557046979865772,
        "end": 4258.0199999999995,
        "id": 932,
        "no_speech_prob": 0.00011774250015150756,
        "seek": 422874,
        "start": 4252.82,
        "temperature": 0,
        "text": " Oh, you know what that's the look at that crazy semi-gold hold on just gonna just gonna change this",
        "tokens": [
          51568,
          876,
          11,
          291,
          458,
          437,
          300,
          311,
          264,
          574,
          412,
          300,
          3219,
          12909,
          12,
          70,
          401,
          67,
          1797,
          322,
          445,
          799,
          445,
          799,
          1319,
          341,
          51828
        ]
      },
      {
        "avg_logprob": -0.23383901205407567,
        "compression_ratio": 1.7754010695187166,
        "end": 4264.34,
        "id": 933,
        "no_speech_prob": 0.00006302678229985759,
        "seek": 425874,
        "start": 4258.74,
        "temperature": 0,
        "text": " There's a different semicolon. I meant to use this is very important. This is exactly what I need to be doing right now",
        "tokens": [
          50364,
          821,
          311,
          257,
          819,
          27515,
          38780,
          13,
          286,
          4140,
          281,
          764,
          341,
          307,
          588,
          1021,
          13,
          639,
          307,
          2293,
          437,
          286,
          643,
          281,
          312,
          884,
          558,
          586,
          50644
        ]
      },
      {
        "avg_logprob": -0.23383901205407567,
        "compression_ratio": 1.7754010695187166,
        "end": 4268.26,
        "id": 934,
        "no_speech_prob": 0.00006302678229985759,
        "seek": 425874,
        "start": 4265.78,
        "temperature": 0,
        "text": " Uh edit profile just hold on",
        "tokens": [
          50716,
          4019,
          8129,
          7964,
          445,
          1797,
          322,
          50840
        ]
      },
      {
        "avg_logprob": -0.23383901205407567,
        "compression_ratio": 1.7754010695187166,
        "end": 4277.3,
        "id": 935,
        "no_speech_prob": 0.00006302678229985759,
        "seek": 425874,
        "start": 4273.54,
        "temperature": 0,
        "text": " It's very very important that I have the correct semicolon, there we go",
        "tokens": [
          51104,
          467,
          311,
          588,
          588,
          1021,
          300,
          286,
          362,
          264,
          3006,
          27515,
          38780,
          11,
          456,
          321,
          352,
          51292
        ]
      },
      {
        "avg_logprob": -0.23383901205407567,
        "compression_ratio": 1.7754010695187166,
        "end": 4282.26,
        "id": 936,
        "no_speech_prob": 0.00006302678229985759,
        "seek": 425874,
        "start": 4280.099999999999,
        "temperature": 0,
        "text": " That was not the correct semicolon character",
        "tokens": [
          51432,
          663,
          390,
          406,
          264,
          3006,
          27515,
          38780,
          2517,
          51540
        ]
      },
      {
        "avg_logprob": -0.23383901205407567,
        "compression_ratio": 1.7754010695187166,
        "end": 4286.98,
        "id": 937,
        "no_speech_prob": 0.00006302678229985759,
        "seek": 425874,
        "start": 4284.0199999999995,
        "temperature": 0,
        "text": " That is the correct semicolon character, thank you very much, okay",
        "tokens": [
          51628,
          663,
          307,
          264,
          3006,
          27515,
          38780,
          2517,
          11,
          1309,
          291,
          588,
          709,
          11,
          1392,
          51776
        ]
      },
      {
        "avg_logprob": -0.2384724409683891,
        "compression_ratio": 0.9433962264150944,
        "end": 4289.86,
        "id": 938,
        "no_speech_prob": 0.0007793455151841044,
        "seek": 428698,
        "start": 4287.86,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50408,
          3301,
          50508
        ]
      },
      {
        "avg_logprob": -0.2384724409683891,
        "compression_ratio": 0.9433962264150944,
        "end": 4293.219999999999,
        "id": 939,
        "no_speech_prob": 0.0007793455151841044,
        "seek": 428698,
        "start": 4291.219999999999,
        "temperature": 0,
        "text": " Now",
        "tokens": [
          50576,
          823,
          50676
        ]
      },
      {
        "avg_logprob": -0.2384724409683891,
        "compression_ratio": 0.9433962264150944,
        "end": 4307.7,
        "id": 940,
        "no_speech_prob": 0.0007793455151841044,
        "seek": 428698,
        "start": 4305.7,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51300,
          1033,
          51400
        ]
      },
      {
        "avg_logprob": -0.2384724409683891,
        "compression_ratio": 0.9433962264150944,
        "end": 4314.099999999999,
        "id": 941,
        "no_speech_prob": 0.0007793455151841044,
        "seek": 428698,
        "start": 4311.78,
        "temperature": 0,
        "text": " Okay, let me get back to the chat here",
        "tokens": [
          51604,
          1033,
          11,
          718,
          385,
          483,
          646,
          281,
          264,
          5081,
          510,
          51720
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4316.18,
        "id": 942,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4314.18,
        "temperature": 0,
        "text": " Okay, so I'm going to go back here",
        "tokens": [
          50368,
          1033,
          11,
          370,
          286,
          478,
          516,
          281,
          352,
          646,
          510,
          50468
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4319.3,
        "id": 943,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4317.3,
        "temperature": 0,
        "text": " And here we go",
        "tokens": [
          50524,
          400,
          510,
          321,
          352,
          50624
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4321.3,
        "id": 944,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4319.54,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50636,
          1033,
          50724
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4323.3,
        "id": 945,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4321.3,
        "temperature": 0,
        "text": " Cycle the camera",
        "tokens": [
          50724,
          10295,
          2160,
          264,
          2799,
          50824
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4326.26,
        "id": 946,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4323.46,
        "temperature": 0,
        "text": " I've got about 45 minutes here so we can keep going",
        "tokens": [
          50832,
          286,
          600,
          658,
          466,
          6905,
          2077,
          510,
          370,
          321,
          393,
          1066,
          516,
          50972
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4331.9400000000005,
        "id": 947,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4330.1,
        "temperature": 0,
        "text": " All right, i'm back again",
        "tokens": [
          51164,
          1057,
          558,
          11,
          741,
          478,
          646,
          797,
          51256
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4335.3,
        "id": 948,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4331.9400000000005,
        "temperature": 0,
        "text": " This is another video. I'm just continuing making this mastodon bot",
        "tokens": [
          51256,
          639,
          307,
          1071,
          960,
          13,
          286,
          478,
          445,
          9289,
          1455,
          341,
          27055,
          378,
          266,
          10592,
          51424
        ]
      },
      {
        "avg_logprob": -0.5502479871114095,
        "compression_ratio": 1.4906542056074767,
        "end": 4342.5,
        "id": 949,
        "no_speech_prob": 0.000579285726416856,
        "seek": 431410,
        "start": 4335.860000000001,
        "temperature": 0,
        "text": " And I got some uh good tips. First of all, I did kind of like a goofy thing here this dot env package",
        "tokens": [
          51452,
          400,
          286,
          658,
          512,
          2232,
          665,
          6082,
          13,
          2386,
          295,
          439,
          11,
          286,
          630,
          733,
          295,
          411,
          257,
          42995,
          551,
          510,
          341,
          5893,
          2267,
          7372,
          51784
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4347.22,
        "id": 950,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4342.5,
        "temperature": 0,
        "text": " So I could practice or tradition convention to just put it at the first thing and I could just call dot env dot",
        "tokens": [
          50364,
          407,
          286,
          727,
          3124,
          420,
          6994,
          10286,
          281,
          445,
          829,
          309,
          412,
          264,
          700,
          551,
          293,
          286,
          727,
          445,
          818,
          5893,
          2267,
          5893,
          50600
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4350.5,
        "id": 951,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4347.62,
        "temperature": 0,
        "text": " Config I don't need to save it in a variable. I can do this just in one line of code",
        "tokens": [
          50620,
          44151,
          286,
          500,
          380,
          643,
          281,
          3155,
          309,
          294,
          257,
          7006,
          13,
          286,
          393,
          360,
          341,
          445,
          294,
          472,
          1622,
          295,
          3089,
          50764
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4353.22,
        "id": 952,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4350.5,
        "temperature": 0,
        "text": " So let me clean that up. That's a little bit nicer now",
        "tokens": [
          50764,
          407,
          718,
          385,
          2541,
          300,
          493,
          13,
          663,
          311,
          257,
          707,
          857,
          22842,
          586,
          50900
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4357.06,
        "id": 953,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4353.62,
        "temperature": 0,
        "text": " um, the other thing that I want to do is",
        "tokens": [
          50920,
          1105,
          11,
          264,
          661,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          51092
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4360.34,
        "id": 954,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4357.86,
        "temperature": 0,
        "text": " I want to um make this bot",
        "tokens": [
          51132,
          286,
          528,
          281,
          1105,
          652,
          341,
          10592,
          51256
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4362.26,
        "id": 955,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4361.22,
        "temperature": 0,
        "text": " post",
        "tokens": [
          51300,
          2183,
          51352
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4367.38,
        "id": 956,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4362.26,
        "temperature": 0,
        "text": " Every so often and so a quick way that I can do that is with the set interval function",
        "tokens": [
          51352,
          2048,
          370,
          2049,
          293,
          370,
          257,
          1702,
          636,
          300,
          286,
          393,
          360,
          300,
          307,
          365,
          264,
          992,
          15035,
          2445,
          51608
        ]
      },
      {
        "avg_logprob": -0.270818037145278,
        "compression_ratio": 1.6872852233676976,
        "end": 4370.82,
        "id": 957,
        "no_speech_prob": 0.0012065776390954852,
        "seek": 434250,
        "start": 4368.02,
        "temperature": 0,
        "text": " So, oh, you know what? I should also do look at this. Let me show you something",
        "tokens": [
          51640,
          407,
          11,
          1954,
          11,
          291,
          458,
          437,
          30,
          286,
          820,
          611,
          360,
          574,
          412,
          341,
          13,
          961,
          385,
          855,
          291,
          746,
          51780
        ]
      },
      {
        "avg_logprob": -0.19340211601667506,
        "compression_ratio": 1.5507246376811594,
        "end": 4373.219999999999,
        "id": 958,
        "no_speech_prob": 0.0003150363627355546,
        "seek": 437082,
        "start": 4371.0599999999995,
        "temperature": 0,
        "text": " So one thing that I often like to do, um",
        "tokens": [
          50376,
          407,
          472,
          551,
          300,
          286,
          2049,
          411,
          281,
          360,
          11,
          1105,
          50484
        ]
      },
      {
        "avg_logprob": -0.19340211601667506,
        "compression_ratio": 1.5507246376811594,
        "end": 4381.219999999999,
        "id": 959,
        "no_speech_prob": 0.0003150363627355546,
        "seek": 437082,
        "start": 4374.099999999999,
        "temperature": 0,
        "text": " So if I run this right now, um, actually I just ran it you can see this is all of the information that I get back",
        "tokens": [
          50528,
          407,
          498,
          286,
          1190,
          341,
          558,
          586,
          11,
          1105,
          11,
          767,
          286,
          445,
          5872,
          309,
          291,
          393,
          536,
          341,
          307,
          439,
          295,
          264,
          1589,
          300,
          286,
          483,
          646,
          50884
        ]
      },
      {
        "avg_logprob": -0.19340211601667506,
        "compression_ratio": 1.5507246376811594,
        "end": 4383.7,
        "id": 960,
        "no_speech_prob": 0.0003150363627355546,
        "seek": 437082,
        "start": 4382.099999999999,
        "temperature": 0,
        "text": " when I",
        "tokens": [
          50928,
          562,
          286,
          51008
        ]
      },
      {
        "avg_logprob": -0.19340211601667506,
        "compression_ratio": 1.5507246376811594,
        "end": 4387.0599999999995,
        "id": 961,
        "no_speech_prob": 0.0003150363627355546,
        "seek": 437082,
        "start": 4383.7,
        "temperature": 0,
        "text": " If this is the response from mastodon after I have tooted",
        "tokens": [
          51008,
          759,
          341,
          307,
          264,
          4134,
          490,
          27055,
          378,
          266,
          934,
          286,
          362,
          281,
          23325,
          51176
        ]
      },
      {
        "avg_logprob": -0.19340211601667506,
        "compression_ratio": 1.5507246376811594,
        "end": 4390.66,
        "id": 962,
        "no_speech_prob": 0.0003150363627355546,
        "seek": 437082,
        "start": 4388.66,
        "temperature": 0,
        "text": " Um awkward i'm gonna get",
        "tokens": [
          51256,
          3301,
          11411,
          741,
          478,
          799,
          483,
          51356
        ]
      },
      {
        "avg_logprob": -0.19340211601667506,
        "compression_ratio": 1.5507246376811594,
        "end": 4397.0599999999995,
        "id": 963,
        "no_speech_prob": 0.0003150363627355546,
        "seek": 437082,
        "start": 4393.7,
        "temperature": 0,
        "text": " I'm way too self-aware of what people are going to like post in the comments",
        "tokens": [
          51508,
          286,
          478,
          636,
          886,
          2698,
          12,
          17074,
          295,
          437,
          561,
          366,
          516,
          281,
          411,
          2183,
          294,
          264,
          3053,
          51676
        ]
      },
      {
        "avg_logprob": -0.36667084496868546,
        "compression_ratio": 1.7423076923076923,
        "end": 4403.620000000001,
        "id": 964,
        "no_speech_prob": 0.0000888799550011754,
        "seek": 439706,
        "start": 4397.620000000001,
        "temperature": 0,
        "text": " Poor matthew's editing. This is the response that I get after I post to mastodon. So I get each",
        "tokens": [
          50392,
          23591,
          3803,
          392,
          1023,
          311,
          10000,
          13,
          639,
          307,
          264,
          4134,
          300,
          286,
          483,
          934,
          286,
          2183,
          281,
          27055,
          378,
          266,
          13,
          407,
          286,
          483,
          1184,
          50692
        ]
      },
      {
        "avg_logprob": -0.36667084496868546,
        "compression_ratio": 1.7423076923076923,
        "end": 4407.46,
        "id": 965,
        "no_speech_prob": 0.0000888799550011754,
        "seek": 439706,
        "start": 4404.18,
        "temperature": 0,
        "text": " Toot has a an id it has a time stamp",
        "tokens": [
          50720,
          1407,
          310,
          575,
          257,
          364,
          4496,
          309,
          575,
          257,
          565,
          9921,
          50884
        ]
      },
      {
        "avg_logprob": -0.36667084496868546,
        "compression_ratio": 1.7423076923076923,
        "end": 4413.22,
        "id": 966,
        "no_speech_prob": 0.0000888799550011754,
        "seek": 439706,
        "start": 4407.700000000001,
        "temperature": 0,
        "text": " It has metadata about whether it's a reply to something it has its content. You can see it's a formatted with html",
        "tokens": [
          50896,
          467,
          575,
          26603,
          466,
          1968,
          309,
          311,
          257,
          16972,
          281,
          746,
          309,
          575,
          1080,
          2701,
          13,
          509,
          393,
          536,
          309,
          311,
          257,
          1254,
          32509,
          365,
          276,
          83,
          15480,
          51172
        ]
      },
      {
        "avg_logprob": -0.36667084496868546,
        "compression_ratio": 1.7423076923076923,
        "end": 4419.780000000001,
        "id": 967,
        "no_speech_prob": 0.0000888799550011754,
        "seek": 439706,
        "start": 4413.700000000001,
        "temperature": 0,
        "text": " So what I actually would like to do is not just console log all of this json data to the to the console",
        "tokens": [
          51196,
          407,
          437,
          286,
          767,
          576,
          411,
          281,
          360,
          307,
          406,
          445,
          11076,
          3565,
          439,
          295,
          341,
          361,
          3015,
          1412,
          281,
          264,
          281,
          264,
          11076,
          51500
        ]
      },
      {
        "avg_logprob": -0.36667084496868546,
        "compression_ratio": 1.7423076923076923,
        "end": 4424.820000000001,
        "id": 968,
        "no_speech_prob": 0.0000888799550011754,
        "seek": 439706,
        "start": 4420.1,
        "temperature": 0,
        "text": " I would like to just pick and choose a few things to console log out as kind of debugging information",
        "tokens": [
          51516,
          286,
          576,
          411,
          281,
          445,
          1888,
          293,
          2826,
          257,
          1326,
          721,
          281,
          11076,
          3565,
          484,
          382,
          733,
          295,
          45592,
          1589,
          51752
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4426.98,
        "id": 969,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4424.82,
        "temperature": 0,
        "text": " And also something that I often like to do",
        "tokens": [
          50364,
          400,
          611,
          746,
          300,
          286,
          2049,
          411,
          281,
          360,
          50472
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4430.66,
        "id": 970,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4427.78,
        "temperature": 0,
        "text": " Just to kind of like help me with this kind of stuff is use",
        "tokens": [
          50512,
          1449,
          281,
          733,
          295,
          411,
          854,
          385,
          365,
          341,
          733,
          295,
          1507,
          307,
          764,
          50656
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4433.78,
        "id": 971,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4431.219999999999,
        "temperature": 0,
        "text": " The built-in node file system package",
        "tokens": [
          50684,
          440,
          3094,
          12,
          259,
          9984,
          3991,
          1185,
          7372,
          50812
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4438.179999999999,
        "id": 972,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4434.74,
        "temperature": 0,
        "text": " So i'm going to require file system. This is not a package I need to install",
        "tokens": [
          50860,
          407,
          741,
          478,
          516,
          281,
          3651,
          3991,
          1185,
          13,
          639,
          307,
          406,
          257,
          7372,
          286,
          643,
          281,
          3625,
          51032
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4441.62,
        "id": 973,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4438.259999999999,
        "temperature": 0,
        "text": " It just comes with node if it's you know, whatever version of node you're using",
        "tokens": [
          51036,
          467,
          445,
          1487,
          365,
          9984,
          498,
          309,
          311,
          291,
          458,
          11,
          2035,
          3037,
          295,
          9984,
          291,
          434,
          1228,
          51204
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4445.38,
        "id": 974,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4442.179999999999,
        "temperature": 0,
        "text": " And i'm actually going to say right here. I'm going to say file system",
        "tokens": [
          51232,
          400,
          741,
          478,
          767,
          516,
          281,
          584,
          558,
          510,
          13,
          286,
          478,
          516,
          281,
          584,
          3991,
          1185,
          51392
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4448.9,
        "id": 975,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4446.9,
        "temperature": 0,
        "text": " dot",
        "tokens": [
          51468,
          5893,
          51568
        ]
      },
      {
        "avg_logprob": -0.4132237521084872,
        "compression_ratio": 1.7053941908713692,
        "end": 4452.5,
        "id": 976,
        "no_speech_prob": 0.0010817068396136165,
        "seek": 442482,
        "start": 4448.9,
        "temperature": 0,
        "text": " right file sync which is a synchronous",
        "tokens": [
          51568,
          558,
          3991,
          20271,
          597,
          307,
          257,
          44743,
          51748
        ]
      },
      {
        "avg_logprob": -0.35872508457728797,
        "compression_ratio": 1.8229665071770336,
        "end": 4455.7,
        "id": 977,
        "no_speech_prob": 0.0009697393979877234,
        "seek": 445250,
        "start": 4452.5,
        "temperature": 0,
        "text": " File writing and then i'm going to say I want to write this data",
        "tokens": [
          50364,
          26196,
          3579,
          293,
          550,
          741,
          478,
          516,
          281,
          584,
          286,
          528,
          281,
          2464,
          341,
          1412,
          50524
        ]
      },
      {
        "avg_logprob": -0.35872508457728797,
        "compression_ratio": 1.8229665071770336,
        "end": 4462.9,
        "id": 978,
        "no_speech_prob": 0.0009697393979877234,
        "seek": 445250,
        "start": 4456.26,
        "temperature": 0,
        "text": " Actually, the path is first and then the thing that I want to write which is probably json dot stringify",
        "tokens": [
          50552,
          5135,
          11,
          264,
          3100,
          307,
          700,
          293,
          550,
          264,
          551,
          300,
          286,
          528,
          281,
          2464,
          597,
          307,
          1391,
          361,
          3015,
          5893,
          6798,
          2505,
          50884
        ]
      },
      {
        "avg_logprob": -0.35872508457728797,
        "compression_ratio": 1.8229665071770336,
        "end": 4465.06,
        "id": 979,
        "no_speech_prob": 0.0009697393979877234,
        "seek": 445250,
        "start": 4463.06,
        "temperature": 0,
        "text": " I want to stringify the data",
        "tokens": [
          50892,
          286,
          528,
          281,
          6798,
          2505,
          264,
          1412,
          50992
        ]
      },
      {
        "avg_logprob": -0.35872508457728797,
        "compression_ratio": 1.8229665071770336,
        "end": 4468.9,
        "id": 980,
        "no_speech_prob": 0.0009697393979877234,
        "seek": 445250,
        "start": 4465.62,
        "temperature": 0,
        "text": " And I want it to have two space two space tabs",
        "tokens": [
          51020,
          400,
          286,
          528,
          309,
          281,
          362,
          732,
          1901,
          732,
          1901,
          20743,
          51184
        ]
      },
      {
        "avg_logprob": -0.35872508457728797,
        "compression_ratio": 1.8229665071770336,
        "end": 4473.46,
        "id": 981,
        "no_speech_prob": 0.0009697393979877234,
        "seek": 445250,
        "start": 4469.62,
        "temperature": 0,
        "text": " And then I need to write this file out so I could just say data dot json",
        "tokens": [
          51220,
          400,
          550,
          286,
          643,
          281,
          2464,
          341,
          3991,
          484,
          370,
          286,
          727,
          445,
          584,
          1412,
          5893,
          361,
          3015,
          51412
        ]
      },
      {
        "avg_logprob": -0.35872508457728797,
        "compression_ratio": 1.8229665071770336,
        "end": 4476.18,
        "id": 982,
        "no_speech_prob": 0.0009697393979877234,
        "seek": 445250,
        "start": 4474.18,
        "temperature": 0,
        "text": " And then if I run this again",
        "tokens": [
          51448,
          400,
          550,
          498,
          286,
          1190,
          341,
          797,
          51548
        ]
      },
      {
        "avg_logprob": -0.35872508457728797,
        "compression_ratio": 1.8229665071770336,
        "end": 4479.94,
        "id": 983,
        "no_speech_prob": 0.0009697393979877234,
        "seek": 445250,
        "start": 4477.94,
        "temperature": 0,
        "text": " We should see now all of a sudden",
        "tokens": [
          51636,
          492,
          820,
          536,
          586,
          439,
          295,
          257,
          3990,
          51736
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4484.339999999999,
        "id": 984,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4480.66,
        "temperature": 0,
        "text": " We should see now all of a sudden I have a new json file that",
        "tokens": [
          50400,
          492,
          820,
          536,
          586,
          439,
          295,
          257,
          3990,
          286,
          362,
          257,
          777,
          361,
          3015,
          3991,
          300,
          50584
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4487.139999999999,
        "id": 985,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4485.46,
        "temperature": 0,
        "text": " appeared in my",
        "tokens": [
          50640,
          8516,
          294,
          452,
          50724
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4489.139999999999,
        "id": 986,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4487.139999999999,
        "temperature": 0,
        "text": " Directory here and I can look at it",
        "tokens": [
          50724,
          49598,
          510,
          293,
          286,
          393,
          574,
          412,
          309,
          50824
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4492.98,
        "id": 987,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4489.299999999999,
        "temperature": 0,
        "text": " And now if I want to kind of like figure out what's the data that I get back?",
        "tokens": [
          50832,
          400,
          586,
          498,
          286,
          528,
          281,
          733,
          295,
          411,
          2573,
          484,
          437,
          311,
          264,
          1412,
          300,
          286,
          483,
          646,
          30,
          51016
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4495.54,
        "id": 988,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4492.98,
        "temperature": 0,
        "text": " I have this as a reference so I can now",
        "tokens": [
          51016,
          286,
          362,
          341,
          382,
          257,
          6408,
          370,
          286,
          393,
          586,
          51144
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4499.7,
        "id": 989,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4496.66,
        "temperature": 0,
        "text": " And I could time stamp the name of the file and all sorts of things like that",
        "tokens": [
          51200,
          400,
          286,
          727,
          565,
          9921,
          264,
          1315,
          295,
          264,
          3991,
          293,
          439,
          7527,
          295,
          721,
          411,
          300,
          51352
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4502.0199999999995,
        "id": 990,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4499.86,
        "temperature": 0,
        "text": " But I can now go and I can just comment this out",
        "tokens": [
          51360,
          583,
          286,
          393,
          586,
          352,
          293,
          286,
          393,
          445,
          2871,
          341,
          484,
          51468
        ]
      },
      {
        "avg_logprob": -0.18047146837250524,
        "compression_ratio": 1.7418032786885247,
        "end": 4506.5,
        "id": 991,
        "no_speech_prob": 0.00048785159015096724,
        "seek": 447994,
        "start": 4503.46,
        "temperature": 0,
        "text": " And I can now I could be more thoughtful about this and I could say",
        "tokens": [
          51540,
          400,
          286,
          393,
          586,
          286,
          727,
          312,
          544,
          21566,
          466,
          341,
          293,
          286,
          727,
          584,
          51692
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4509.96,
        "id": 992,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4506.98,
        "temperature": 0,
        "text": " Uh, you know console dot log, you know success",
        "tokens": [
          50388,
          4019,
          11,
          291,
          458,
          11076,
          5893,
          3565,
          11,
          291,
          458,
          2245,
          50537
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4513.46,
        "id": 993,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4511.86,
        "temperature": 0,
        "text": " Id",
        "tokens": [
          50632,
          11506,
          50712
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4517.62,
        "id": 994,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4513.46,
        "temperature": 0,
        "text": " Uh, and then I could put sorry I need to go back here and I could say it's data dot id",
        "tokens": [
          50712,
          4019,
          11,
          293,
          550,
          286,
          727,
          829,
          2597,
          286,
          643,
          281,
          352,
          646,
          510,
          293,
          286,
          727,
          584,
          309,
          311,
          1412,
          5893,
          4496,
          50920
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4519.46,
        "id": 995,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4518.26,
        "temperature": 0,
        "text": " created at",
        "tokens": [
          50952,
          2942,
          412,
          51012
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4520.58,
        "id": 996,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4519.46,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51012,
          1105,
          51068
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4522.58,
        "id": 997,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4520.58,
        "temperature": 0,
        "text": " So I would go back here and I would say",
        "tokens": [
          51068,
          407,
          286,
          576,
          352,
          646,
          510,
          293,
          286,
          576,
          584,
          51168
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4525.78,
        "id": 998,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4523.78,
        "temperature": 0,
        "text": " Data dot id",
        "tokens": [
          51228,
          11888,
          5893,
          4496,
          51328
        ]
      },
      {
        "avg_logprob": -0.2676963335202064,
        "compression_ratio": 1.66,
        "end": 4531.7,
        "id": 999,
        "no_speech_prob": 0.0012065705377608538,
        "seek": 450650,
        "start": 4526.42,
        "temperature": 0,
        "text": " Plus uh data dot created. Uh at you know what?",
        "tokens": [
          51360,
          7721,
          2232,
          1412,
          5893,
          2942,
          13,
          4019,
          412,
          291,
          458,
          437,
          30,
          51624
        ]
      },
      {
        "avg_logprob": -0.5179722344697412,
        "compression_ratio": 1.5853658536585367,
        "end": 4537.0599999999995,
        "id": 1000,
        "no_speech_prob": 0.0007208344177342951,
        "seek": 453170,
        "start": 4531.7,
        "temperature": 0,
        "text": " You know about what's it called what's the thing called template literals",
        "tokens": [
          50364,
          509,
          458,
          466,
          437,
          311,
          309,
          1219,
          437,
          311,
          264,
          551,
          1219,
          12379,
          2733,
          1124,
          50632
        ]
      },
      {
        "avg_logprob": -0.5179722344697412,
        "compression_ratio": 1.5853658536585367,
        "end": 4544.34,
        "id": 1001,
        "no_speech_prob": 0.0007208344177342951,
        "seek": 453170,
        "start": 4538.58,
        "temperature": 0,
        "text": " My brain is not working today. It was working on friday and I had that spicy food for lunch and it really did something to me",
        "tokens": [
          50708,
          1222,
          3567,
          307,
          406,
          1364,
          965,
          13,
          467,
          390,
          1364,
          322,
          431,
          4708,
          293,
          286,
          632,
          300,
          9127,
          1755,
          337,
          6349,
          293,
          309,
          534,
          630,
          746,
          281,
          385,
          50996
        ]
      },
      {
        "avg_logprob": -0.5179722344697412,
        "compression_ratio": 1.5853658536585367,
        "end": 4546.9,
        "id": 1002,
        "no_speech_prob": 0.0007208344177342951,
        "seek": 453170,
        "start": 4544.9,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51024,
          1105,
          51124
        ]
      },
      {
        "avg_logprob": -0.5179722344697412,
        "compression_ratio": 1.5853658536585367,
        "end": 4550.74,
        "id": 1003,
        "no_speech_prob": 0.0007208344177342951,
        "seek": 453170,
        "start": 4548.74,
        "temperature": 0,
        "text": " Is that what it's called template literals",
        "tokens": [
          51216,
          1119,
          300,
          437,
          309,
          311,
          1219,
          12379,
          2733,
          1124,
          51316
        ]
      },
      {
        "avg_logprob": -0.5179722344697412,
        "compression_ratio": 1.5853658536585367,
        "end": 4555.38,
        "id": 1004,
        "no_speech_prob": 0.0007208344177342951,
        "seek": 453170,
        "start": 4553.38,
        "temperature": 0,
        "text": " JavaScript yes",
        "tokens": [
          51448,
          15778,
          2086,
          51548
        ]
      },
      {
        "avg_logprob": -0.2071340685692903,
        "compression_ratio": 1.6151079136690647,
        "end": 4557.7,
        "id": 1005,
        "no_speech_prob": 0.0005442103720270097,
        "seek": 455538,
        "start": 4555.7,
        "temperature": 0,
        "text": " JavaScript yes",
        "tokens": [
          50380,
          15778,
          2086,
          50480
        ]
      },
      {
        "avg_logprob": -0.2071340685692903,
        "compression_ratio": 1.6151079136690647,
        "end": 4562.18,
        "id": 1006,
        "no_speech_prob": 0.0005442103720270097,
        "seek": 455538,
        "start": 4560.9800000000005,
        "temperature": 0,
        "text": " Actually, this is a good moment",
        "tokens": [
          50644,
          5135,
          11,
          341,
          307,
          257,
          665,
          1623,
          50704
        ]
      },
      {
        "avg_logprob": -0.2071340685692903,
        "compression_ratio": 1.6151079136690647,
        "end": 4566.5,
        "id": 1007,
        "no_speech_prob": 0.0005442103720270097,
        "seek": 455538,
        "start": 4562.18,
        "temperature": 0,
        "text": " I really should just do a separate video on this entirely because it's such a wonderful feature of javascript now",
        "tokens": [
          50704,
          286,
          534,
          820,
          445,
          360,
          257,
          4994,
          960,
          322,
          341,
          7696,
          570,
          309,
          311,
          1270,
          257,
          3715,
          4111,
          295,
          361,
          37331,
          5944,
          586,
          50920
        ]
      },
      {
        "avg_logprob": -0.2071340685692903,
        "compression_ratio": 1.6151079136690647,
        "end": 4571.54,
        "id": 1008,
        "no_speech_prob": 0.0005442103720270097,
        "seek": 455538,
        "start": 4566.58,
        "temperature": 0,
        "text": " But I can actually you know how i'm always doing this console logging some text and then some variable stuff",
        "tokens": [
          50924,
          583,
          286,
          393,
          767,
          291,
          458,
          577,
          741,
          478,
          1009,
          884,
          341,
          11076,
          27991,
          512,
          2487,
          293,
          550,
          512,
          7006,
          1507,
          51172
        ]
      },
      {
        "avg_logprob": -0.2071340685692903,
        "compression_ratio": 1.6151079136690647,
        "end": 4577.4800000000005,
        "id": 1009,
        "no_speech_prob": 0.0005442103720270097,
        "seek": 455538,
        "start": 4571.62,
        "temperature": 0,
        "text": " And i'm joining it with a plus and concatenation. You can use something called template literals, which is a way of embedding expressions",
        "tokens": [
          51176,
          400,
          741,
          478,
          5549,
          309,
          365,
          257,
          1804,
          293,
          1588,
          7186,
          399,
          13,
          509,
          393,
          764,
          746,
          1219,
          12379,
          2733,
          1124,
          11,
          597,
          307,
          257,
          636,
          295,
          12240,
          3584,
          15277,
          51469
        ]
      },
      {
        "avg_logprob": -0.2071340685692903,
        "compression_ratio": 1.6151079136690647,
        "end": 4581.38,
        "id": 1010,
        "no_speech_prob": 0.0005442103720270097,
        "seek": 455538,
        "start": 4578.34,
        "temperature": 0,
        "text": " inside of a string and the way to do that",
        "tokens": [
          51512,
          1854,
          295,
          257,
          6798,
          293,
          264,
          636,
          281,
          360,
          300,
          51664
        ]
      },
      {
        "avg_logprob": -0.2424865894103318,
        "compression_ratio": 1.5958549222797926,
        "end": 4584.5,
        "id": 1011,
        "no_speech_prob": 0.0002034260833170265,
        "seek": 458138,
        "start": 4582.26,
        "temperature": 0,
        "text": " Is with instead of quotes with back ticks",
        "tokens": [
          50408,
          1119,
          365,
          2602,
          295,
          19963,
          365,
          646,
          42475,
          50520
        ]
      },
      {
        "avg_logprob": -0.2424865894103318,
        "compression_ratio": 1.5958549222797926,
        "end": 4589.38,
        "id": 1012,
        "no_speech_prob": 0.0002034260833170265,
        "seek": 458138,
        "start": 4584.74,
        "temperature": 0,
        "text": " So if I put a back tick at the start in the beginning, I no longer need this plus",
        "tokens": [
          50532,
          407,
          498,
          286,
          829,
          257,
          646,
          5204,
          412,
          264,
          722,
          294,
          264,
          2863,
          11,
          286,
          572,
          2854,
          643,
          341,
          1804,
          50764
        ]
      },
      {
        "avg_logprob": -0.2424865894103318,
        "compression_ratio": 1.5958549222797926,
        "end": 4593,
        "id": 1013,
        "no_speech_prob": 0.0002034260833170265,
        "seek": 458138,
        "start": 4589.9400000000005,
        "temperature": 0,
        "text": " I'm, just gonna i'm gonna get rid of all this nonsense",
        "tokens": [
          50792,
          286,
          478,
          11,
          445,
          799,
          741,
          478,
          799,
          483,
          3973,
          295,
          439,
          341,
          14925,
          50945
        ]
      },
      {
        "avg_logprob": -0.2424865894103318,
        "compression_ratio": 1.5958549222797926,
        "end": 4594.88,
        "id": 1014,
        "no_speech_prob": 0.0002034260833170265,
        "seek": 458138,
        "start": 4593.9400000000005,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50992,
          1105,
          51039
        ]
      },
      {
        "avg_logprob": -0.2424865894103318,
        "compression_ratio": 1.5958549222797926,
        "end": 4597.38,
        "id": 1015,
        "no_speech_prob": 0.0002034260833170265,
        "seek": 458138,
        "start": 4594.88,
        "temperature": 0,
        "text": " Success, you know id i'm just gonna do id",
        "tokens": [
          51039,
          23669,
          11,
          291,
          458,
          4496,
          741,
          478,
          445,
          799,
          360,
          4496,
          51164
        ]
      },
      {
        "avg_logprob": -0.2424865894103318,
        "compression_ratio": 1.5958549222797926,
        "end": 4600.74,
        "id": 1016,
        "no_speech_prob": 0.0002034260833170265,
        "seek": 458138,
        "start": 4598.74,
        "temperature": 0,
        "text": " and time stamp",
        "tokens": [
          51232,
          293,
          565,
          9921,
          51332
        ]
      },
      {
        "avg_logprob": -0.2424865894103318,
        "compression_ratio": 1.5958549222797926,
        "end": 4606.26,
        "id": 1017,
        "no_speech_prob": 0.0002034260833170265,
        "seek": 458138,
        "start": 4600.9800000000005,
        "temperature": 0,
        "text": " Colon and so now this is a string and it has basically like I want id",
        "tokens": [
          51344,
          21408,
          293,
          370,
          586,
          341,
          307,
          257,
          6798,
          293,
          309,
          575,
          1936,
          411,
          286,
          528,
          4496,
          51608
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4611.3,
        "id": 1018,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4606.34,
        "temperature": 0,
        "text": " This is what I want to literally see and then what I want to see is the value of this and the way that I",
        "tokens": [
          50368,
          639,
          307,
          437,
          286,
          528,
          281,
          3736,
          536,
          293,
          550,
          437,
          286,
          528,
          281,
          536,
          307,
          264,
          2158,
          295,
          341,
          293,
          264,
          636,
          300,
          286,
          50616
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4614.900000000001,
        "id": 1019,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4611.3,
        "temperature": 0,
        "text": " Do that is with dollar sign curly bracket curly bracket",
        "tokens": [
          50616,
          1144,
          300,
          307,
          365,
          7241,
          1465,
          32066,
          16904,
          32066,
          16904,
          50796
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4620.34,
        "id": 1020,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4614.900000000001,
        "temperature": 0,
        "text": " So now anything inside of here is an expression so I could write four plus seven and it would it would it would it would?",
        "tokens": [
          50796,
          407,
          586,
          1340,
          1854,
          295,
          510,
          307,
          364,
          6114,
          370,
          286,
          727,
          2464,
          1451,
          1804,
          3407,
          293,
          309,
          576,
          309,
          576,
          309,
          576,
          309,
          576,
          30,
          51068
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4623.780000000001,
        "id": 1021,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4620.34,
        "temperature": 0,
        "text": " Put 11 in the string and then I can say time stampy",
        "tokens": [
          51068,
          4935,
          2975,
          294,
          264,
          6798,
          293,
          550,
          286,
          393,
          584,
          565,
          9921,
          88,
          51240
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4626.900000000001,
        "id": 1022,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4624.900000000001,
        "temperature": 0,
        "text": " Uh, I can make this",
        "tokens": [
          51296,
          4019,
          11,
          286,
          393,
          652,
          341,
          51396
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4628.58,
        "id": 1023,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4627.06,
        "temperature": 0,
        "text": " like this",
        "tokens": [
          51404,
          411,
          341,
          51480
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4630.26,
        "id": 1024,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4628.58,
        "temperature": 0,
        "text": " um, and now",
        "tokens": [
          51480,
          1105,
          11,
          293,
          586,
          51564
        ]
      },
      {
        "avg_logprob": -0.20801261493137904,
        "compression_ratio": 1.7758620689655173,
        "end": 4632.34,
        "id": 1025,
        "no_speech_prob": 0.0011513910721987486,
        "seek": 460626,
        "start": 4630.26,
        "temperature": 0,
        "text": " We can run this again one more time",
        "tokens": [
          51564,
          492,
          393,
          1190,
          341,
          797,
          472,
          544,
          565,
          51668
        ]
      },
      {
        "avg_logprob": -0.1586657196935946,
        "compression_ratio": 1.7805755395683454,
        "end": 4637.9400000000005,
        "id": 1026,
        "no_speech_prob": 0.0008040830143727362,
        "seek": 463234,
        "start": 4633.3,
        "temperature": 0,
        "text": " Node bot.js and we can see this is what I get now id and time stamp",
        "tokens": [
          50412,
          38640,
          10592,
          13,
          25530,
          293,
          321,
          393,
          536,
          341,
          307,
          437,
          286,
          483,
          586,
          4496,
          293,
          565,
          9921,
          50644
        ]
      },
      {
        "avg_logprob": -0.1586657196935946,
        "compression_ratio": 1.7805755395683454,
        "end": 4642.34,
        "id": 1027,
        "no_speech_prob": 0.0008040830143727362,
        "seek": 463234,
        "start": 4638.1,
        "temperature": 0,
        "text": " So this is what's going to i'm going to see and maybe it'll be useful for me to also put the content there",
        "tokens": [
          50652,
          407,
          341,
          307,
          437,
          311,
          516,
          281,
          741,
          478,
          516,
          281,
          536,
          293,
          1310,
          309,
          603,
          312,
          4420,
          337,
          385,
          281,
          611,
          829,
          264,
          2701,
          456,
          50864
        ]
      },
      {
        "avg_logprob": -0.1586657196935946,
        "compression_ratio": 1.7805755395683454,
        "end": 4645.860000000001,
        "id": 1028,
        "no_speech_prob": 0.0008040830143727362,
        "seek": 463234,
        "start": 4642.5,
        "temperature": 0,
        "text": " Who knows what I want to log in console.log, but I want to be more thoughtful about that",
        "tokens": [
          50872,
          2102,
          3255,
          437,
          286,
          528,
          281,
          3565,
          294,
          11076,
          13,
          4987,
          11,
          457,
          286,
          528,
          281,
          312,
          544,
          21566,
          466,
          300,
          51040
        ]
      },
      {
        "avg_logprob": -0.1586657196935946,
        "compression_ratio": 1.7805755395683454,
        "end": 4650.34,
        "id": 1029,
        "no_speech_prob": 0.0008040830143727362,
        "seek": 463234,
        "start": 4645.860000000001,
        "temperature": 0,
        "text": " Not just spit out massive amounts of json data. Okay, let's get to the good part",
        "tokens": [
          51040,
          1726,
          445,
          22127,
          484,
          5994,
          11663,
          295,
          361,
          3015,
          1412,
          13,
          1033,
          11,
          718,
          311,
          483,
          281,
          264,
          665,
          644,
          51264
        ]
      },
      {
        "avg_logprob": -0.1586657196935946,
        "compression_ratio": 1.7805755395683454,
        "end": 4652.5,
        "id": 1030,
        "no_speech_prob": 0.0008040830143727362,
        "seek": 463234,
        "start": 4650.9800000000005,
        "temperature": 0,
        "text": " now",
        "tokens": [
          51296,
          586,
          51372
        ]
      },
      {
        "avg_logprob": -0.1586657196935946,
        "compression_ratio": 1.7805755395683454,
        "end": 4657.22,
        "id": 1031,
        "no_speech_prob": 0.0008040830143727362,
        "seek": 463234,
        "start": 4652.5,
        "temperature": 0,
        "text": " What I want to do is my first example of a bot is I want to make a random number bot",
        "tokens": [
          51372,
          708,
          286,
          528,
          281,
          360,
          307,
          452,
          700,
          1365,
          295,
          257,
          10592,
          307,
          286,
          528,
          281,
          652,
          257,
          4974,
          1230,
          10592,
          51608
        ]
      },
      {
        "avg_logprob": -0.1586657196935946,
        "compression_ratio": 1.7805755395683454,
        "end": 4660.9800000000005,
        "id": 1032,
        "no_speech_prob": 0.0008040830143727362,
        "seek": 463234,
        "start": 4657.54,
        "temperature": 0,
        "text": " So I am going to say i'm going to use template literals again",
        "tokens": [
          51624,
          407,
          286,
          669,
          516,
          281,
          584,
          741,
          478,
          516,
          281,
          764,
          12379,
          2733,
          1124,
          797,
          51796
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4664.34,
        "id": 1033,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4662.42,
        "temperature": 0,
        "text": " uh, i'm going to say",
        "tokens": [
          50368,
          2232,
          11,
          741,
          478,
          516,
          281,
          584,
          50464
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4671.7,
        "id": 1034,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4664.34,
        "temperature": 0,
        "text": " The meaning of life is and then i'm going to use an expression i'm going to say, uh, math dot floor",
        "tokens": [
          50464,
          440,
          3620,
          295,
          993,
          307,
          293,
          550,
          741,
          478,
          516,
          281,
          764,
          364,
          6114,
          741,
          478,
          516,
          281,
          584,
          11,
          2232,
          11,
          5221,
          5893,
          4123,
          50832
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4674.42,
        "id": 1035,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4672.42,
        "temperature": 0,
        "text": " You know, let me put this in a separate variable",
        "tokens": [
          50868,
          509,
          458,
          11,
          718,
          385,
          829,
          341,
          294,
          257,
          4994,
          7006,
          50968
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4678.1,
        "id": 1036,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4675.78,
        "temperature": 0,
        "text": " Const num equals math dot floor",
        "tokens": [
          51036,
          8574,
          1031,
          6915,
          5221,
          5893,
          4123,
          51152
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4680.74,
        "id": 1037,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4678.74,
        "temperature": 0,
        "text": " math dot random",
        "tokens": [
          51184,
          5221,
          5893,
          4974,
          51284
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4683,
        "id": 1038,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4680.82,
        "temperature": 0,
        "text": " Times 100. We'll see if we get 42",
        "tokens": [
          51288,
          11366,
          2319,
          13,
          492,
          603,
          536,
          498,
          321,
          483,
          14034,
          51397
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4685.7,
        "id": 1039,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4683.7,
        "temperature": 0,
        "text": " And then i'm going to just put that here",
        "tokens": [
          51432,
          400,
          550,
          741,
          478,
          516,
          281,
          445,
          829,
          300,
          510,
          51532
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4689.9400000000005,
        "id": 1040,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4688.5,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51672,
          3301,
          51744
        ]
      },
      {
        "avg_logprob": -0.23948516448338827,
        "compression_ratio": 1.6470588235294117,
        "end": 4691.9400000000005,
        "id": 1041,
        "no_speech_prob": 0.000011125589480798226,
        "seek": 466234,
        "start": 4689.9400000000005,
        "temperature": 0,
        "text": " and now this",
        "tokens": [
          51744,
          293,
          586,
          341,
          51844
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4694.0199999999995,
        "id": 1042,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4692.0199999999995,
        "temperature": 0.2,
        "text": " My bot should now",
        "tokens": [
          50368,
          1222,
          10592,
          820,
          586,
          50468
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4697.299999999999,
        "id": 1043,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4694.339999999999,
        "temperature": 0.2,
        "text": " Post the meaning of life is this random number",
        "tokens": [
          50484,
          10223,
          264,
          3620,
          295,
          993,
          307,
          341,
          4974,
          1230,
          50632
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4701.86,
        "id": 1044,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4697.46,
        "temperature": 0.2,
        "text": " So math dot random gives me a random number a floating point number between zero and one",
        "tokens": [
          50640,
          407,
          5221,
          5893,
          4974,
          2709,
          385,
          257,
          4974,
          1230,
          257,
          12607,
          935,
          1230,
          1296,
          4018,
          293,
          472,
          50860
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4704.9,
        "id": 1045,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4702.179999999999,
        "temperature": 0.2,
        "text": " I multiply that by 100 so I get a number between zero and 100",
        "tokens": [
          50876,
          286,
          12972,
          300,
          538,
          2319,
          370,
          286,
          483,
          257,
          1230,
          1296,
          4018,
          293,
          2319,
          51012
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4710.66,
        "id": 1046,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4704.9,
        "temperature": 0.2,
        "text": " I mean technically the highest number is 99.999999 and then math dot floor takes off the decimal point",
        "tokens": [
          51012,
          286,
          914,
          12120,
          264,
          6343,
          1230,
          307,
          11803,
          13,
          8494,
          8494,
          8494,
          293,
          550,
          5221,
          5893,
          4123,
          2516,
          766,
          264,
          26601,
          935,
          51300
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4715.219999999999,
        "id": 1047,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4710.74,
        "temperature": 0.2,
        "text": " So I now have a random number between zero and 99. I could add one if I want between one and 100 whatever",
        "tokens": [
          51304,
          407,
          286,
          586,
          362,
          257,
          4974,
          1230,
          1296,
          4018,
          293,
          11803,
          13,
          286,
          727,
          909,
          472,
          498,
          286,
          528,
          1296,
          472,
          293,
          2319,
          2035,
          51528
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4717.219999999999,
        "id": 1048,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4715.219999999999,
        "temperature": 0.2,
        "text": " That's not the point. The point is now",
        "tokens": [
          51528,
          663,
          311,
          406,
          264,
          935,
          13,
          440,
          935,
          307,
          586,
          51628
        ]
      },
      {
        "avg_logprob": -0.2266732273679791,
        "compression_ratio": 1.8718861209964412,
        "end": 4720.339999999999,
        "id": 1049,
        "no_speech_prob": 0.000023923457774799317,
        "seek": 469194,
        "start": 4717.78,
        "temperature": 0.2,
        "text": " And you know what? I really would like to see from the console",
        "tokens": [
          51656,
          400,
          291,
          458,
          437,
          30,
          286,
          534,
          576,
          411,
          281,
          536,
          490,
          264,
          11076,
          51784
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4722.34,
        "id": 1050,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4720.900000000001,
        "temperature": 0,
        "text": " Um what?",
        "tokens": [
          50392,
          3301,
          437,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4724.66,
        "id": 1051,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4722.34,
        "temperature": 0,
        "text": " It posted so i'm also just going to do this",
        "tokens": [
          50464,
          467,
          9437,
          370,
          741,
          478,
          611,
          445,
          516,
          281,
          360,
          341,
          50580
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4726.900000000001,
        "id": 1052,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4725.46,
        "temperature": 0,
        "text": " console log",
        "tokens": [
          50620,
          11076,
          3565,
          50692
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4730.5,
        "id": 1053,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4726.900000000001,
        "temperature": 0,
        "text": " Data dot what was it if I now I can go back to my data dot json",
        "tokens": [
          50692,
          11888,
          5893,
          437,
          390,
          309,
          498,
          286,
          586,
          286,
          393,
          352,
          646,
          281,
          452,
          1412,
          5893,
          361,
          3015,
          50872
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4733.06,
        "id": 1054,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4731.06,
        "temperature": 0,
        "text": " and it's going to be um",
        "tokens": [
          50900,
          293,
          309,
          311,
          516,
          281,
          312,
          1105,
          51000
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4737.14,
        "id": 1055,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4733.860000000001,
        "temperature": 0,
        "text": " Where is the content uh content just data dot content?",
        "tokens": [
          51040,
          2305,
          307,
          264,
          2701,
          2232,
          2701,
          445,
          1412,
          5893,
          2701,
          30,
          51204
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4738.5,
        "id": 1056,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4737.62,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51228,
          1105,
          51272
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4740.5,
        "id": 1057,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4738.5,
        "temperature": 0,
        "text": " So i'm going to say data dot content",
        "tokens": [
          51272,
          407,
          741,
          478,
          516,
          281,
          584,
          1412,
          5893,
          2701,
          51372
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4743.38,
        "id": 1058,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4741.38,
        "temperature": 0,
        "text": " We're getting somewhere",
        "tokens": [
          51416,
          492,
          434,
          1242,
          4079,
          51516
        ]
      },
      {
        "avg_logprob": -0.24359919627507529,
        "compression_ratio": 1.6927374301675977,
        "end": 4745.9400000000005,
        "id": 1059,
        "no_speech_prob": 0.00025714008370414376,
        "seek": 472034,
        "start": 4743.7,
        "temperature": 0,
        "text": " So let's run this one more time",
        "tokens": [
          51532,
          407,
          718,
          311,
          1190,
          341,
          472,
          544,
          565,
          51644
        ]
      },
      {
        "avg_logprob": -0.3873743269178602,
        "compression_ratio": 1.5714285714285714,
        "end": 4752.0199999999995,
        "id": 1060,
        "no_speech_prob": 0.002980997785925865,
        "seek": 474594,
        "start": 4746.259999999999,
        "temperature": 0,
        "text": " Success the meaning of life is 95. Okay, did we get it? We can go here we can double check and",
        "tokens": [
          50380,
          23669,
          264,
          3620,
          295,
          993,
          307,
          13420,
          13,
          1033,
          11,
          630,
          321,
          483,
          309,
          30,
          492,
          393,
          352,
          510,
          321,
          393,
          3834,
          1520,
          293,
          50668
        ]
      },
      {
        "avg_logprob": -0.3873743269178602,
        "compression_ratio": 1.5714285714285714,
        "end": 4758.419999999999,
        "id": 1061,
        "no_speech_prob": 0.002980997785925865,
        "seek": 474594,
        "start": 4753.54,
        "temperature": 0,
        "text": " Somehow I went away from there the meaning of life is 95 great. Okay. Now two more things I want to do",
        "tokens": [
          50744,
          28357,
          286,
          1437,
          1314,
          490,
          456,
          264,
          3620,
          295,
          993,
          307,
          13420,
          869,
          13,
          1033,
          13,
          823,
          732,
          544,
          721,
          286,
          528,
          281,
          360,
          50988
        ]
      },
      {
        "avg_logprob": -0.3873743269178602,
        "compression_ratio": 1.5714285714285714,
        "end": 4760.98,
        "id": 1062,
        "no_speech_prob": 0.002980997785925865,
        "seek": 474594,
        "start": 4758.98,
        "temperature": 0,
        "text": " Make this bot exciting",
        "tokens": [
          51016,
          4387,
          341,
          10592,
          4670,
          51116
        ]
      },
      {
        "avg_logprob": -0.3873743269178602,
        "compression_ratio": 1.5714285714285714,
        "end": 4767.7,
        "id": 1063,
        "no_speech_prob": 0.002980997785925865,
        "seek": 474594,
        "start": 4761.7,
        "temperature": 0,
        "text": " I am now going to use set interval. So the idea here is this is all of my code",
        "tokens": [
          51152,
          286,
          669,
          586,
          516,
          281,
          764,
          992,
          15035,
          13,
          407,
          264,
          1558,
          510,
          307,
          341,
          307,
          439,
          295,
          452,
          3089,
          51452
        ]
      },
      {
        "avg_logprob": -0.3873743269178602,
        "compression_ratio": 1.5714285714285714,
        "end": 4770.98,
        "id": 1064,
        "no_speech_prob": 0.002980997785925865,
        "seek": 474594,
        "start": 4768.66,
        "temperature": 0,
        "text": " to post to mastodon",
        "tokens": [
          51500,
          281,
          2183,
          281,
          27055,
          378,
          266,
          51616
        ]
      },
      {
        "avg_logprob": -0.231596778420841,
        "compression_ratio": 1.6260504201680672,
        "end": 4773.639999999999,
        "id": 1065,
        "no_speech_prob": 0.005384860560297966,
        "seek": 477098,
        "start": 4771.299999999999,
        "temperature": 0,
        "text": " To post to mastodon",
        "tokens": [
          50380,
          1407,
          2183,
          281,
          27055,
          378,
          266,
          50497
        ]
      },
      {
        "avg_logprob": -0.231596778420841,
        "compression_ratio": 1.6260504201680672,
        "end": 4776.339999999999,
        "id": 1066,
        "no_speech_prob": 0.005384860560297966,
        "seek": 477098,
        "start": 4774.5,
        "temperature": 0,
        "text": " And again, if this is new to you",
        "tokens": [
          50540,
          400,
          797,
          11,
          498,
          341,
          307,
          777,
          281,
          291,
          50632
        ]
      },
      {
        "avg_logprob": -0.231596778420841,
        "compression_ratio": 1.6260504201680672,
        "end": 4781.62,
        "id": 1067,
        "no_speech_prob": 0.005384860560297966,
        "seek": 477098,
        "start": 4776.339999999999,
        "temperature": 0,
        "text": " If you've if you've just been watching my p5gs videos this weird syntax this arrow syntax part of es6",
        "tokens": [
          50632,
          759,
          291,
          600,
          498,
          291,
          600,
          445,
          668,
          1976,
          452,
          280,
          20,
          21559,
          2145,
          341,
          3657,
          28431,
          341,
          11610,
          28431,
          644,
          295,
          785,
          21,
          50896
        ]
      },
      {
        "avg_logprob": -0.231596778420841,
        "compression_ratio": 1.6260504201680672,
        "end": 4788.0199999999995,
        "id": 1068,
        "no_speech_prob": 0.005384860560297966,
        "seek": 477098,
        "start": 4781.759999999999,
        "temperature": 0,
        "text": " JavaScript might be unfamiliar to you. I will put a link to a video where I describe what arrow syntax is in this video's description",
        "tokens": [
          50903,
          15778,
          1062,
          312,
          29415,
          281,
          291,
          13,
          286,
          486,
          829,
          257,
          2113,
          281,
          257,
          960,
          689,
          286,
          6786,
          437,
          11610,
          28431,
          307,
          294,
          341,
          960,
          311,
          3855,
          51216
        ]
      },
      {
        "avg_logprob": -0.231596778420841,
        "compression_ratio": 1.6260504201680672,
        "end": 4794.58,
        "id": 1069,
        "no_speech_prob": 0.005384860560297966,
        "seek": 477098,
        "start": 4788.5,
        "temperature": 0,
        "text": " Um, okay. So now what I want to do is all this stuff here is basically just a function called toot",
        "tokens": [
          51240,
          3301,
          11,
          1392,
          13,
          407,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          439,
          341,
          1507,
          510,
          307,
          1936,
          445,
          257,
          2445,
          1219,
          281,
          310,
          51544
        ]
      },
      {
        "avg_logprob": -0.20407073351801658,
        "compression_ratio": 1.6853448275862069,
        "end": 4802.0199999999995,
        "id": 1070,
        "no_speech_prob": 0.00016603786207269877,
        "seek": 479458,
        "start": 4795.38,
        "temperature": 0,
        "text": " Right because what I want to do is this function will pick a random number create the status and post it",
        "tokens": [
          50404,
          1779,
          570,
          437,
          286,
          528,
          281,
          360,
          307,
          341,
          2445,
          486,
          1888,
          257,
          4974,
          1230,
          1884,
          264,
          6558,
          293,
          2183,
          309,
          50736
        ]
      },
      {
        "avg_logprob": -0.20407073351801658,
        "compression_ratio": 1.6853448275862069,
        "end": 4804.98,
        "id": 1071,
        "no_speech_prob": 0.00016603786207269877,
        "seek": 479458,
        "start": 4802.5,
        "temperature": 0,
        "text": " What I want to do is I want to say now set interval",
        "tokens": [
          50760,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          586,
          992,
          15035,
          50884
        ]
      },
      {
        "avg_logprob": -0.20407073351801658,
        "compression_ratio": 1.6853448275862069,
        "end": 4808.82,
        "id": 1072,
        "no_speech_prob": 0.00016603786207269877,
        "seek": 479458,
        "start": 4806.18,
        "temperature": 0,
        "text": " And I want to do this toot every",
        "tokens": [
          50944,
          400,
          286,
          528,
          281,
          360,
          341,
          281,
          310,
          633,
          51076
        ]
      },
      {
        "avg_logprob": -0.20407073351801658,
        "compression_ratio": 1.6853448275862069,
        "end": 4813.3,
        "id": 1073,
        "no_speech_prob": 0.00016603786207269877,
        "seek": 479458,
        "start": 4809.6,
        "temperature": 0,
        "text": " 5 000 milliseconds, which would be every five seconds. Now. This is a bit extreme",
        "tokens": [
          51115,
          1025,
          13711,
          34184,
          11,
          597,
          576,
          312,
          633,
          1732,
          3949,
          13,
          823,
          13,
          639,
          307,
          257,
          857,
          8084,
          51300
        ]
      },
      {
        "avg_logprob": -0.20407073351801658,
        "compression_ratio": 1.6853448275862069,
        "end": 4820.1,
        "id": 1074,
        "no_speech_prob": 0.00016603786207269877,
        "seek": 479458,
        "start": 4813.7,
        "temperature": 0,
        "text": " This is probably this is not really appropriate bot etiquette to have a bot that posts every five seconds. So, you know",
        "tokens": [
          51320,
          639,
          307,
          1391,
          341,
          307,
          406,
          534,
          6854,
          10592,
          42177,
          3007,
          281,
          362,
          257,
          10592,
          300,
          12300,
          633,
          1732,
          3949,
          13,
          407,
          11,
          291,
          458,
          51640
        ]
      },
      {
        "avg_logprob": -0.2756336246218,
        "compression_ratio": 1.6680672268907564,
        "end": 4824.820000000001,
        "id": 1075,
        "no_speech_prob": 0.0001488350098952651,
        "seek": 482010,
        "start": 4820.900000000001,
        "temperature": 0,
        "text": " Probably a much more thoughtful way of doing this if you're gonna have a bot that posts an automated way",
        "tokens": [
          50404,
          9210,
          257,
          709,
          544,
          21566,
          636,
          295,
          884,
          341,
          498,
          291,
          434,
          799,
          362,
          257,
          10592,
          300,
          12300,
          364,
          18473,
          636,
          50600
        ]
      },
      {
        "avg_logprob": -0.2756336246218,
        "compression_ratio": 1.6680672268907564,
        "end": 4827.46,
        "id": 1076,
        "no_speech_prob": 0.0001488350098952651,
        "seek": 482010,
        "start": 4824.820000000001,
        "temperature": 0,
        "text": " Maybe it's a word of the day or a haiku of the day",
        "tokens": [
          50600,
          2704,
          309,
          311,
          257,
          1349,
          295,
          264,
          786,
          420,
          257,
          324,
          24320,
          295,
          264,
          786,
          50732
        ]
      },
      {
        "avg_logprob": -0.2756336246218,
        "compression_ratio": 1.6680672268907564,
        "end": 4829.54,
        "id": 1077,
        "no_speech_prob": 0.0001488350098952651,
        "seek": 482010,
        "start": 4827.54,
        "temperature": 0,
        "text": " Maybe it's just once a day once an hour",
        "tokens": [
          50736,
          2704,
          309,
          311,
          445,
          1564,
          257,
          786,
          1564,
          364,
          1773,
          50836
        ]
      },
      {
        "avg_logprob": -0.2756336246218,
        "compression_ratio": 1.6680672268907564,
        "end": 4834.18,
        "id": 1078,
        "no_speech_prob": 0.0001488350098952651,
        "seek": 482010,
        "start": 4830.18,
        "temperature": 0,
        "text": " Once an hour might be really the maximum there, but just to test it i'm gonna do it every five seconds",
        "tokens": [
          50868,
          3443,
          364,
          1773,
          1062,
          312,
          534,
          264,
          6674,
          456,
          11,
          457,
          445,
          281,
          1500,
          309,
          741,
          478,
          799,
          360,
          309,
          633,
          1732,
          3949,
          51068
        ]
      },
      {
        "avg_logprob": -0.2756336246218,
        "compression_ratio": 1.6680672268907564,
        "end": 4839.46,
        "id": 1079,
        "no_speech_prob": 0.0001488350098952651,
        "seek": 482010,
        "start": 4836.42,
        "temperature": 0,
        "text": " Burps, i'm gonna be burping on a live stream",
        "tokens": [
          51180,
          7031,
          1878,
          11,
          741,
          478,
          799,
          312,
          2779,
          3381,
          322,
          257,
          1621,
          4309,
          51332
        ]
      },
      {
        "avg_logprob": -0.2756336246218,
        "compression_ratio": 1.6680672268907564,
        "end": 4843.22,
        "id": 1080,
        "no_speech_prob": 0.0001488350098952651,
        "seek": 482010,
        "start": 4841.3,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51424,
          3301,
          51520
        ]
      },
      {
        "avg_logprob": -0.2756336246218,
        "compression_ratio": 1.6680672268907564,
        "end": 4846.740000000001,
        "id": 1081,
        "no_speech_prob": 0.0001488350098952651,
        "seek": 482010,
        "start": 4843.22,
        "temperature": 0,
        "text": " And I guess I can take this moment to thank pa7war",
        "tokens": [
          51520,
          400,
          286,
          2041,
          286,
          393,
          747,
          341,
          1623,
          281,
          1309,
          2502,
          22,
          6925,
          51696
        ]
      },
      {
        "avg_logprob": -0.5400838105574898,
        "compression_ratio": 1.9063829787234043,
        "end": 4854.099999999999,
        "id": 1082,
        "no_speech_prob": 0.00040447668288834393,
        "seek": 484674,
        "start": 4847.3,
        "temperature": 0,
        "text": " Um, I'm going to um, I'm going to run this every five seconds, which is reasonable just for testing",
        "tokens": [
          50392,
          3301,
          11,
          286,
          478,
          516,
          281,
          1105,
          11,
          286,
          478,
          516,
          281,
          1190,
          341,
          633,
          1732,
          3949,
          11,
          597,
          307,
          10585,
          445,
          337,
          4997,
          50732
        ]
      },
      {
        "avg_logprob": -0.5400838105574898,
        "compression_ratio": 1.9063829787234043,
        "end": 4858.099999999999,
        "id": 1083,
        "no_speech_prob": 0.00040447668288834393,
        "seek": 484674,
        "start": 4854.66,
        "temperature": 0,
        "text": " Something interesting though about set interval is like what if I make this like every",
        "tokens": [
          50760,
          6595,
          1880,
          1673,
          466,
          992,
          15035,
          307,
          411,
          437,
          498,
          286,
          652,
          341,
          411,
          633,
          50932
        ]
      },
      {
        "avg_logprob": -0.5400838105574898,
        "compression_ratio": 1.9063829787234043,
        "end": 4861.38,
        "id": 1084,
        "no_speech_prob": 0.00040447668288834393,
        "seek": 484674,
        "start": 4859.0599999999995,
        "temperature": 0,
        "text": " 50 seconds if I run this right now",
        "tokens": [
          50980,
          2625,
          3949,
          498,
          286,
          1190,
          341,
          558,
          586,
          51096
        ]
      },
      {
        "avg_logprob": -0.5400838105574898,
        "compression_ratio": 1.9063829787234043,
        "end": 4865.54,
        "id": 1085,
        "no_speech_prob": 0.00040447668288834393,
        "seek": 484674,
        "start": 4863.0599999999995,
        "temperature": 0,
        "text": " I gotta wait 50 seconds for it to do the first time",
        "tokens": [
          51180,
          286,
          3428,
          1699,
          2625,
          3949,
          337,
          309,
          281,
          360,
          264,
          700,
          565,
          51304
        ]
      },
      {
        "avg_logprob": -0.5400838105574898,
        "compression_ratio": 1.9063829787234043,
        "end": 4867.86,
        "id": 1086,
        "no_speech_prob": 0.00040447668288834393,
        "seek": 484674,
        "start": 4865.86,
        "temperature": 0,
        "text": " So and that's not really such a great thing",
        "tokens": [
          51320,
          407,
          293,
          300,
          311,
          406,
          534,
          1270,
          257,
          869,
          551,
          51420
        ]
      },
      {
        "avg_logprob": -0.5400838105574898,
        "compression_ratio": 1.9063829787234043,
        "end": 4871.219999999999,
        "id": 1087,
        "no_speech_prob": 0.00040447668288834393,
        "seek": 484674,
        "start": 4868.0199999999995,
        "temperature": 0,
        "text": " So I am going to actually also just call it once first",
        "tokens": [
          51428,
          407,
          286,
          669,
          516,
          281,
          767,
          611,
          445,
          818,
          309,
          1564,
          700,
          51588
        ]
      },
      {
        "avg_logprob": -0.5400838105574898,
        "compression_ratio": 1.9063829787234043,
        "end": 4875.0599999999995,
        "id": 1088,
        "no_speech_prob": 0.00040447668288834393,
        "seek": 484674,
        "start": 4871.86,
        "temperature": 0,
        "text": " And then do it every five seconds. So I'm going to do it every five seconds",
        "tokens": [
          51620,
          400,
          550,
          360,
          309,
          633,
          1732,
          3949,
          13,
          407,
          286,
          478,
          516,
          281,
          360,
          309,
          633,
          1732,
          3949,
          51780
        ]
      },
      {
        "avg_logprob": -0.23413275170513964,
        "compression_ratio": 1.6984732824427482,
        "end": 4877.780000000001,
        "id": 1089,
        "no_speech_prob": 0.011868725530803204,
        "seek": 487506,
        "start": 4875.06,
        "temperature": 0,
        "text": " First and then do it every five seconds. Okay, here we go",
        "tokens": [
          50364,
          2386,
          293,
          550,
          360,
          309,
          633,
          1732,
          3949,
          13,
          1033,
          11,
          510,
          321,
          352,
          50500
        ]
      },
      {
        "avg_logprob": -0.23413275170513964,
        "compression_ratio": 1.6984732824427482,
        "end": 4883.620000000001,
        "id": 1090,
        "no_speech_prob": 0.011868725530803204,
        "seek": 487506,
        "start": 4879.9400000000005,
        "temperature": 0,
        "text": " Got meaning of life is whoa, it really picked 99. That is awesome",
        "tokens": [
          50608,
          5803,
          3620,
          295,
          993,
          307,
          13310,
          11,
          309,
          534,
          6183,
          11803,
          13,
          663,
          307,
          3476,
          50792
        ]
      },
      {
        "avg_logprob": -0.23413275170513964,
        "compression_ratio": 1.6984732824427482,
        "end": 4890.900000000001,
        "id": 1091,
        "no_speech_prob": 0.011868725530803204,
        "seek": 487506,
        "start": 4884.18,
        "temperature": 0,
        "text": " Uh, and it's 48. Oh, we're getting close to 42. We can see it's doing this every five seconds. I'm gonna quit out of it",
        "tokens": [
          50820,
          4019,
          11,
          293,
          309,
          311,
          11174,
          13,
          876,
          11,
          321,
          434,
          1242,
          1998,
          281,
          14034,
          13,
          492,
          393,
          536,
          309,
          311,
          884,
          341,
          633,
          1732,
          3949,
          13,
          286,
          478,
          799,
          10366,
          484,
          295,
          309,
          51156
        ]
      },
      {
        "avg_logprob": -0.23413275170513964,
        "compression_ratio": 1.6984732824427482,
        "end": 4895.06,
        "id": 1092,
        "no_speech_prob": 0.011868725530803204,
        "seek": 487506,
        "start": 4891.780000000001,
        "temperature": 0,
        "text": " And i'm gonna go back to here. We can see there it is",
        "tokens": [
          51200,
          400,
          741,
          478,
          799,
          352,
          646,
          281,
          510,
          13,
          492,
          393,
          536,
          456,
          309,
          307,
          51364
        ]
      },
      {
        "avg_logprob": -0.23413275170513964,
        "compression_ratio": 1.6984732824427482,
        "end": 4899.38,
        "id": 1093,
        "no_speech_prob": 0.011868725530803204,
        "seek": 487506,
        "start": 4895.06,
        "temperature": 0,
        "text": " These are my posts that I did you can see 10 seconds ago 10 seconds ago now",
        "tokens": [
          51364,
          1981,
          366,
          452,
          12300,
          300,
          286,
          630,
          291,
          393,
          536,
          1266,
          3949,
          2057,
          1266,
          3949,
          2057,
          586,
          51580
        ]
      },
      {
        "avg_logprob": -0.23413275170513964,
        "compression_ratio": 1.6984732824427482,
        "end": 4902.02,
        "id": 1094,
        "no_speech_prob": 0.011868725530803204,
        "seek": 487506,
        "start": 4899.38,
        "temperature": 0,
        "text": " I mean, this is really five seconds ago. All right, so here's the thing",
        "tokens": [
          51580,
          286,
          914,
          11,
          341,
          307,
          534,
          1732,
          3949,
          2057,
          13,
          1057,
          558,
          11,
          370,
          510,
          311,
          264,
          551,
          51712
        ]
      },
      {
        "avg_logprob": -0.20310146602119986,
        "compression_ratio": 1.8111888111888113,
        "end": 4906.9800000000005,
        "id": 1095,
        "no_speech_prob": 0.00029595618252642453,
        "seek": 490202,
        "start": 4902.5,
        "temperature": 0,
        "text": " I want to show you there's so much more remember how I made this",
        "tokens": [
          50388,
          286,
          528,
          281,
          855,
          291,
          456,
          311,
          370,
          709,
          544,
          1604,
          577,
          286,
          1027,
          341,
          50612
        ]
      },
      {
        "avg_logprob": -0.20310146602119986,
        "compression_ratio": 1.8111888111888113,
        "end": 4914.02,
        "id": 1096,
        "no_speech_prob": 0.00029595618252642453,
        "seek": 490202,
        "start": 4908.02,
        "temperature": 0,
        "text": " These parameters all i'm doing is saying this is the status that I want to post automatically from my node program",
        "tokens": [
          50664,
          1981,
          9834,
          439,
          741,
          478,
          884,
          307,
          1566,
          341,
          307,
          264,
          6558,
          300,
          286,
          528,
          281,
          2183,
          6772,
          490,
          452,
          9984,
          1461,
          50964
        ]
      },
      {
        "avg_logprob": -0.20310146602119986,
        "compression_ratio": 1.8111888111888113,
        "end": 4918.18,
        "id": 1097,
        "no_speech_prob": 0.00029595618252642453,
        "seek": 490202,
        "start": 4914.580000000001,
        "temperature": 0,
        "text": " Well, one of the things that I can actually do is I can go back to the documentation",
        "tokens": [
          50992,
          1042,
          11,
          472,
          295,
          264,
          721,
          300,
          286,
          393,
          767,
          360,
          307,
          286,
          393,
          352,
          646,
          281,
          264,
          14333,
          51172
        ]
      },
      {
        "avg_logprob": -0.20310146602119986,
        "compression_ratio": 1.8111888111888113,
        "end": 4922.660000000001,
        "id": 1098,
        "no_speech_prob": 0.00029595618252642453,
        "seek": 490202,
        "start": 4918.26,
        "temperature": 0,
        "text": " There are all these other things so media ids is something I really want to show you in a future video",
        "tokens": [
          51176,
          821,
          366,
          439,
          613,
          661,
          721,
          370,
          3021,
          220,
          3742,
          307,
          746,
          286,
          534,
          528,
          281,
          855,
          291,
          294,
          257,
          2027,
          960,
          51396
        ]
      },
      {
        "avg_logprob": -0.20310146602119986,
        "compression_ratio": 1.8111888111888113,
        "end": 4926.820000000001,
        "id": 1099,
        "no_speech_prob": 0.00029595618252642453,
        "seek": 490202,
        "start": 4922.740000000001,
        "temperature": 0,
        "text": " It's a way I can include an image or other media with the with the post",
        "tokens": [
          51400,
          467,
          311,
          257,
          636,
          286,
          393,
          4090,
          364,
          3256,
          420,
          661,
          3021,
          365,
          264,
          365,
          264,
          2183,
          51604
        ]
      },
      {
        "avg_logprob": -0.20310146602119986,
        "compression_ratio": 1.8111888111888113,
        "end": 4930.740000000001,
        "id": 1100,
        "no_speech_prob": 0.00029595618252642453,
        "seek": 490202,
        "start": 4927.22,
        "temperature": 0,
        "text": " But one thing that I can do that's kind of fun is just this spoiler text thing",
        "tokens": [
          51624,
          583,
          472,
          551,
          300,
          286,
          393,
          360,
          300,
          311,
          733,
          295,
          1019,
          307,
          445,
          341,
          26927,
          2487,
          551,
          51800
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4936.42,
        "id": 1101,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4931.7,
        "temperature": 0,
        "text": " So what spoiler text does it allows me to have sort of two aspects",
        "tokens": [
          50412,
          407,
          437,
          26927,
          2487,
          775,
          309,
          4045,
          385,
          281,
          362,
          1333,
          295,
          732,
          7270,
          50648
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4940.42,
        "id": 1102,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4938.26,
        "temperature": 0,
        "text": " To the post the meaning of life is",
        "tokens": [
          50740,
          1407,
          264,
          2183,
          264,
          3620,
          295,
          993,
          307,
          50848
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4943.219999999999,
        "id": 1103,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4941.3,
        "temperature": 0,
        "text": " and then the status",
        "tokens": [
          50892,
          293,
          550,
          264,
          6558,
          50988
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4944.179999999999,
        "id": 1104,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4943.219999999999,
        "temperature": 0,
        "text": " Can just be none",
        "tokens": [
          50988,
          1664,
          445,
          312,
          6022,
          51036
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4947.0599999999995,
        "id": 1105,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4944.179999999999,
        "temperature": 0,
        "text": " So i'm going to break this up into two parts and I need a comma here",
        "tokens": [
          51036,
          407,
          741,
          478,
          516,
          281,
          1821,
          341,
          493,
          666,
          732,
          3166,
          293,
          286,
          643,
          257,
          22117,
          510,
          51180
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4949.38,
        "id": 1106,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4947.38,
        "temperature": 0,
        "text": " And i'm just going to show you what this looks like",
        "tokens": [
          51196,
          400,
          741,
          478,
          445,
          516,
          281,
          855,
          291,
          437,
          341,
          1542,
          411,
          51296
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4956.26,
        "id": 1107,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4949.7,
        "temperature": 0,
        "text": " So i'm using these parameters different properties of the javascript object that's going to go here into my post call",
        "tokens": [
          51312,
          407,
          741,
          478,
          1228,
          613,
          9834,
          819,
          7221,
          295,
          264,
          361,
          37331,
          5944,
          2657,
          300,
          311,
          516,
          281,
          352,
          510,
          666,
          452,
          2183,
          818,
          51640
        ]
      },
      {
        "avg_logprob": -0.22396794387272426,
        "compression_ratio": 1.7183673469387755,
        "end": 4959.38,
        "id": 1108,
        "no_speech_prob": 0.000041986142605310306,
        "seek": 493074,
        "start": 4956.74,
        "temperature": 0,
        "text": " And i'm going to now run this one more time",
        "tokens": [
          51664,
          400,
          741,
          478,
          516,
          281,
          586,
          1190,
          341,
          472,
          544,
          565,
          51796
        ]
      },
      {
        "avg_logprob": -0.1752572022667227,
        "compression_ratio": 1.728624535315985,
        "end": 4964.42,
        "id": 1109,
        "no_speech_prob": 0.0009253746247850358,
        "seek": 495938,
        "start": 4960.26,
        "temperature": 0,
        "text": " And i'm going to go back to my bot and i'm going to look and you can see look at this the meaning of life",
        "tokens": [
          50408,
          400,
          741,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          10592,
          293,
          741,
          478,
          516,
          281,
          574,
          293,
          291,
          393,
          536,
          574,
          412,
          341,
          264,
          3620,
          295,
          993,
          50616
        ]
      },
      {
        "avg_logprob": -0.1752572022667227,
        "compression_ratio": 1.728624535315985,
        "end": 4968.1,
        "id": 1110,
        "no_speech_prob": 0.0009253746247850358,
        "seek": 495938,
        "start": 4964.5,
        "temperature": 0,
        "text": " But I now have this nice show more button. So spoiler alert",
        "tokens": [
          50620,
          583,
          286,
          586,
          362,
          341,
          1481,
          855,
          544,
          2960,
          13,
          407,
          26927,
          9615,
          50800
        ]
      },
      {
        "avg_logprob": -0.1752572022667227,
        "compression_ratio": 1.728624535315985,
        "end": 4970.74,
        "id": 1111,
        "no_speech_prob": 0.0009253746247850358,
        "seek": 495938,
        "start": 4968.74,
        "temperature": 0,
        "text": " If you click on this, you'll see that it's 52",
        "tokens": [
          50832,
          759,
          291,
          2052,
          322,
          341,
          11,
          291,
          603,
          536,
          300,
          309,
          311,
          18079,
          50932
        ]
      },
      {
        "avg_logprob": -0.1752572022667227,
        "compression_ratio": 1.728624535315985,
        "end": 4973.62,
        "id": 1112,
        "no_speech_prob": 0.0009253746247850358,
        "seek": 495938,
        "start": 4971.22,
        "temperature": 0,
        "text": " Or that it's 23 and again i'm doing this too often",
        "tokens": [
          50956,
          1610,
          300,
          309,
          311,
          6673,
          293,
          797,
          741,
          478,
          884,
          341,
          886,
          2049,
          51076
        ]
      },
      {
        "avg_logprob": -0.1752572022667227,
        "compression_ratio": 1.728624535315985,
        "end": 4980.34,
        "id": 1113,
        "no_speech_prob": 0.0009253746247850358,
        "seek": 495938,
        "start": 4973.7,
        "temperature": 0,
        "text": " So i'm going to absolutely quit this and then if I wanted to do now if I want to have my bot post once a day",
        "tokens": [
          51080,
          407,
          741,
          478,
          516,
          281,
          3122,
          10366,
          341,
          293,
          550,
          498,
          286,
          1415,
          281,
          360,
          586,
          498,
          286,
          528,
          281,
          362,
          452,
          10592,
          2183,
          1564,
          257,
          786,
          51412
        ]
      },
      {
        "avg_logprob": -0.1752572022667227,
        "compression_ratio": 1.728624535315985,
        "end": 4986.900000000001,
        "id": 1114,
        "no_speech_prob": 0.0009253746247850358,
        "seek": 495938,
        "start": 4981.22,
        "temperature": 0,
        "text": " Every 24 hours I can just go right back to my code and I can say get a set interval should be",
        "tokens": [
          51456,
          2048,
          4022,
          2496,
          286,
          393,
          445,
          352,
          558,
          646,
          281,
          452,
          3089,
          293,
          286,
          393,
          584,
          483,
          257,
          992,
          15035,
          820,
          312,
          51740
        ]
      },
      {
        "avg_logprob": -0.2009033273767542,
        "compression_ratio": 1.7,
        "end": 4990.58,
        "id": 1115,
        "no_speech_prob": 0.0002531539066694677,
        "seek": 498690,
        "start": 4987.78,
        "temperature": 0,
        "text": " 24 hours. There's 60 minutes at 24 hours",
        "tokens": [
          50408,
          4022,
          2496,
          13,
          821,
          311,
          4060,
          2077,
          412,
          4022,
          2496,
          50548
        ]
      },
      {
        "avg_logprob": -0.2009033273767542,
        "compression_ratio": 1.7,
        "end": 4998.259999999999,
        "id": 1116,
        "no_speech_prob": 0.0002531539066694677,
        "seek": 498690,
        "start": 4991.139999999999,
        "temperature": 0,
        "text": " 60 minutes an hour 60 seconds an hour and 1000 milliseconds in a second. So now here we go. We now have a bot",
        "tokens": [
          50576,
          4060,
          2077,
          364,
          1773,
          4060,
          3949,
          364,
          1773,
          293,
          9714,
          34184,
          294,
          257,
          1150,
          13,
          407,
          586,
          510,
          321,
          352,
          13,
          492,
          586,
          362,
          257,
          10592,
          50932
        ]
      },
      {
        "avg_logprob": -0.2009033273767542,
        "compression_ratio": 1.7,
        "end": 5003.62,
        "id": 1117,
        "no_speech_prob": 0.0002531539066694677,
        "seek": 498690,
        "start": 4999.379999999999,
        "temperature": 0,
        "text": " A mastodon bot that will post a numeric meaning of life once a day",
        "tokens": [
          50988,
          316,
          27055,
          378,
          266,
          10592,
          300,
          486,
          2183,
          257,
          7866,
          299,
          3620,
          295,
          993,
          1564,
          257,
          786,
          51200
        ]
      },
      {
        "avg_logprob": -0.2009033273767542,
        "compression_ratio": 1.7,
        "end": 5008.339999999999,
        "id": 1118,
        "no_speech_prob": 0.0002531539066694677,
        "seek": 498690,
        "start": 5003.78,
        "temperature": 0,
        "text": " So in theory if I just left this running here and never closed my laptop or never did anything",
        "tokens": [
          51208,
          407,
          294,
          5261,
          498,
          286,
          445,
          1411,
          341,
          2614,
          510,
          293,
          1128,
          5395,
          452,
          10732,
          420,
          1128,
          630,
          1340,
          51436
        ]
      },
      {
        "avg_logprob": -0.2009033273767542,
        "compression_ratio": 1.7,
        "end": 5013.139999999999,
        "id": 1119,
        "no_speech_prob": 0.0002531539066694677,
        "seek": 498690,
        "start": 5008.58,
        "temperature": 0,
        "text": " This would just run forever and once a day post the truth of the matter is you're gonna have to think about well",
        "tokens": [
          51448,
          639,
          576,
          445,
          1190,
          5680,
          293,
          1564,
          257,
          786,
          2183,
          264,
          3494,
          295,
          264,
          1871,
          307,
          291,
          434,
          799,
          362,
          281,
          519,
          466,
          731,
          51676
        ]
      },
      {
        "avg_logprob": -0.19553989834255642,
        "compression_ratio": 1.8154761904761905,
        "end": 5016.660000000001,
        "id": 1120,
        "no_speech_prob": 0.002934838877990842,
        "seek": 501314,
        "start": 5013.3,
        "temperature": 0,
        "text": " Once you've created your bot like where are you going? Where's that bot going to live?",
        "tokens": [
          50372,
          3443,
          291,
          600,
          2942,
          428,
          10592,
          411,
          689,
          366,
          291,
          516,
          30,
          2305,
          311,
          300,
          10592,
          516,
          281,
          1621,
          30,
          50540
        ]
      },
      {
        "avg_logprob": -0.19553989834255642,
        "compression_ratio": 1.8154761904761905,
        "end": 5021.38,
        "id": 1121,
        "no_speech_prob": 0.002934838877990842,
        "seek": 501314,
        "start": 5016.740000000001,
        "temperature": 0,
        "text": " I mean you could have it live on your laptop or computer that's always plugged in and always connected to the internet",
        "tokens": [
          50544,
          286,
          914,
          291,
          727,
          362,
          309,
          1621,
          322,
          428,
          10732,
          420,
          3820,
          300,
          311,
          1009,
          25679,
          294,
          293,
          1009,
          4582,
          281,
          264,
          4705,
          50776
        ]
      },
      {
        "avg_logprob": -0.19553989834255642,
        "compression_ratio": 1.8154761904761905,
        "end": 5027.06,
        "id": 1122,
        "no_speech_prob": 0.002934838877990842,
        "seek": 501314,
        "start": 5021.46,
        "temperature": 0,
        "text": " but more likely you're going to want to host it on a web server on some sort of server or maybe get a raspberry pi",
        "tokens": [
          50780,
          457,
          544,
          3700,
          291,
          434,
          516,
          281,
          528,
          281,
          3975,
          309,
          322,
          257,
          3670,
          7154,
          322,
          512,
          1333,
          295,
          7154,
          420,
          1310,
          483,
          257,
          41468,
          3895,
          51060
        ]
      },
      {
        "avg_logprob": -0.19553989834255642,
        "compression_ratio": 1.8154761904761905,
        "end": 5031.780000000001,
        "id": 1123,
        "no_speech_prob": 0.002934838877990842,
        "seek": 501314,
        "start": 5027.06,
        "temperature": 0,
        "text": " And plug it into the wall and have it always sitting there connected to the internet. I will cover that in future videos",
        "tokens": [
          51060,
          400,
          5452,
          309,
          666,
          264,
          2929,
          293,
          362,
          309,
          1009,
          3798,
          456,
          4582,
          281,
          264,
          4705,
          13,
          286,
          486,
          2060,
          300,
          294,
          2027,
          2145,
          51296
        ]
      },
      {
        "avg_logprob": -0.19553989834255642,
        "compression_ratio": 1.8154761904761905,
        "end": 5036.9800000000005,
        "id": 1124,
        "no_speech_prob": 0.002934838877990842,
        "seek": 501314,
        "start": 5031.9400000000005,
        "temperature": 0,
        "text": " In fact, I have covered that for how to deploy a twitter bot and ultimately it's exactly the same thing",
        "tokens": [
          51304,
          682,
          1186,
          11,
          286,
          362,
          5343,
          300,
          337,
          577,
          281,
          7274,
          257,
          21439,
          10592,
          293,
          6284,
          309,
          311,
          2293,
          264,
          912,
          551,
          51556
        ]
      },
      {
        "avg_logprob": -0.19553989834255642,
        "compression_ratio": 1.8154761904761905,
        "end": 5039.400000000001,
        "id": 1125,
        "no_speech_prob": 0.002934838877990842,
        "seek": 501314,
        "start": 5036.9800000000005,
        "temperature": 0,
        "text": " But just now the code has changed and it's working with mastodon",
        "tokens": [
          51556,
          583,
          445,
          586,
          264,
          3089,
          575,
          3105,
          293,
          309,
          311,
          1364,
          365,
          27055,
          378,
          266,
          51677
        ]
      },
      {
        "avg_logprob": -0.21713196147571912,
        "compression_ratio": 1.6923076923076923,
        "end": 5043.5599999999995,
        "id": 1126,
        "no_speech_prob": 0.00016346218762919307,
        "seek": 503940,
        "start": 5039.639999999999,
        "temperature": 0,
        "text": " Okay, so i'm going to show you a bunch of other kinds of things you can do in bots most notably",
        "tokens": [
          50376,
          1033,
          11,
          370,
          741,
          478,
          516,
          281,
          855,
          291,
          257,
          3840,
          295,
          661,
          3685,
          295,
          721,
          291,
          393,
          360,
          294,
          35410,
          881,
          31357,
          50572
        ]
      },
      {
        "avg_logprob": -0.21713196147571912,
        "compression_ratio": 1.6923076923076923,
        "end": 5046.679999999999,
        "id": 1127,
        "no_speech_prob": 0.00016346218762919307,
        "seek": 503940,
        "start": 5044.28,
        "temperature": 0,
        "text": " Listen the streaming api. Whoops",
        "tokens": [
          50608,
          7501,
          264,
          11791,
          1882,
          72,
          13,
          45263,
          50728
        ]
      },
      {
        "avg_logprob": -0.21713196147571912,
        "compression_ratio": 1.6923076923076923,
        "end": 5057.32,
        "id": 1128,
        "no_speech_prob": 0.00016346218762919307,
        "seek": 503940,
        "start": 5054.2,
        "temperature": 0,
        "text": " Most notably listen using the streaming api",
        "tokens": [
          51104,
          4534,
          31357,
          2140,
          1228,
          264,
          11791,
          1882,
          72,
          51260
        ]
      },
      {
        "avg_logprob": -0.21713196147571912,
        "compression_ratio": 1.6923076923076923,
        "end": 5060.679999999999,
        "id": 1129,
        "no_speech_prob": 0.00016346218762919307,
        "seek": 503940,
        "start": 5057.639999999999,
        "temperature": 0,
        "text": " So the streaming api is a way that I could connect and I could say anybody",
        "tokens": [
          51276,
          407,
          264,
          11791,
          1882,
          72,
          307,
          257,
          636,
          300,
          286,
          727,
          1745,
          293,
          286,
          727,
          584,
          4472,
          51428
        ]
      },
      {
        "avg_logprob": -0.21713196147571912,
        "compression_ratio": 1.6923076923076923,
        "end": 5065.82,
        "id": 1130,
        "no_speech_prob": 0.00016346218762919307,
        "seek": 503940,
        "start": 5060.92,
        "temperature": 0,
        "text": " Anybody ever mentions me I could reply to them so I could have a bot that participates in a conversation",
        "tokens": [
          51440,
          19082,
          1562,
          23844,
          385,
          286,
          727,
          16972,
          281,
          552,
          370,
          286,
          727,
          362,
          257,
          10592,
          300,
          3421,
          1024,
          294,
          257,
          3761,
          51685
        ]
      },
      {
        "avg_logprob": -0.2115091513131411,
        "compression_ratio": 1.9324324324324325,
        "end": 5069.74,
        "id": 1131,
        "no_speech_prob": 0.0028448645025491714,
        "seek": 506582,
        "start": 5066.38,
        "temperature": 0,
        "text": " One thing you should really think about and I'll talk about this again at the beginning of the next video",
        "tokens": [
          50392,
          1485,
          551,
          291,
          820,
          534,
          519,
          466,
          293,
          286,
          603,
          751,
          466,
          341,
          797,
          412,
          264,
          2863,
          295,
          264,
          958,
          960,
          50560
        ]
      },
      {
        "avg_logprob": -0.2115091513131411,
        "compression_ratio": 1.9324324324324325,
        "end": 5071.98,
        "id": 1132,
        "no_speech_prob": 0.0028448645025491714,
        "seek": 506582,
        "start": 5069.98,
        "temperature": 0,
        "text": " I mentioned bot etiquette etiquette",
        "tokens": [
          50572,
          286,
          2835,
          10592,
          42177,
          3007,
          42177,
          3007,
          50672
        ]
      },
      {
        "avg_logprob": -0.2115091513131411,
        "compression_ratio": 1.9324324324324325,
        "end": 5077.099999999999,
        "id": 1133,
        "no_speech_prob": 0.0028448645025491714,
        "seek": 506582,
        "start": 5071.98,
        "temperature": 0,
        "text": " But the idea if you really want to be thoughtful about making a bot that's not suddenly going to spam people",
        "tokens": [
          50672,
          583,
          264,
          1558,
          498,
          291,
          534,
          528,
          281,
          312,
          21566,
          466,
          1455,
          257,
          10592,
          300,
          311,
          406,
          5800,
          516,
          281,
          24028,
          561,
          50928
        ]
      },
      {
        "avg_logprob": -0.2115091513131411,
        "compression_ratio": 1.9324324324324325,
        "end": 5081.179999999999,
        "id": 1134,
        "no_speech_prob": 0.0028448645025491714,
        "seek": 506582,
        "start": 5077.099999999999,
        "temperature": 0,
        "text": " So it's not going to just pick random mastodon users and start at mentioning them",
        "tokens": [
          50928,
          407,
          309,
          311,
          406,
          516,
          281,
          445,
          1888,
          4974,
          27055,
          378,
          266,
          5022,
          293,
          722,
          412,
          18315,
          552,
          51132
        ]
      },
      {
        "avg_logprob": -0.2115091513131411,
        "compression_ratio": 1.9324324324324325,
        "end": 5087.5,
        "id": 1135,
        "no_speech_prob": 0.0028448645025491714,
        "seek": 506582,
        "start": 5081.5,
        "temperature": 0,
        "text": " Or start picking random posts and replying to them. You really want your bot to engage when people opt in to engage",
        "tokens": [
          51148,
          1610,
          722,
          8867,
          4974,
          12300,
          293,
          1085,
          7310,
          281,
          552,
          13,
          509,
          534,
          528,
          428,
          10592,
          281,
          4683,
          562,
          561,
          2427,
          294,
          281,
          4683,
          51448
        ]
      },
      {
        "avg_logprob": -0.2115091513131411,
        "compression_ratio": 1.9324324324324325,
        "end": 5094.299999999999,
        "id": 1136,
        "no_speech_prob": 0.0028448645025491714,
        "seek": 506582,
        "start": 5087.5,
        "temperature": 0,
        "text": " So maybe you only want to uh post messages to people who have chosen to follow the bot or chosen to mention the bot already",
        "tokens": [
          51448,
          407,
          1310,
          291,
          787,
          528,
          281,
          2232,
          2183,
          7897,
          281,
          561,
          567,
          362,
          8614,
          281,
          1524,
          264,
          10592,
          420,
          8614,
          281,
          2152,
          264,
          10592,
          1217,
          51788
        ]
      },
      {
        "avg_logprob": -0.2370806376139323,
        "compression_ratio": 1.5833333333333333,
        "end": 5101.26,
        "id": 1137,
        "no_speech_prob": 0.000552763813175261,
        "seek": 509430,
        "start": 5094.62,
        "temperature": 0,
        "text": " In in a particular post so I just can't think of saying post because I haven't gotten comfortable just when I got comfortable saying tweet",
        "tokens": [
          50380,
          682,
          294,
          257,
          1729,
          2183,
          370,
          286,
          445,
          393,
          380,
          519,
          295,
          1566,
          2183,
          570,
          286,
          2378,
          380,
          5768,
          4619,
          445,
          562,
          286,
          658,
          4619,
          1566,
          15258,
          50712
        ]
      },
      {
        "avg_logprob": -0.2370806376139323,
        "compression_ratio": 1.5833333333333333,
        "end": 5106.320000000001,
        "id": 1138,
        "no_speech_prob": 0.000552763813175261,
        "seek": 509430,
        "start": 5101.5,
        "temperature": 0,
        "text": " I'm now no longer comfortable saying toot, but i'll get there. I'll get there eventually. Okay. See you in the next video",
        "tokens": [
          50724,
          286,
          478,
          586,
          572,
          2854,
          4619,
          1566,
          281,
          310,
          11,
          457,
          741,
          603,
          483,
          456,
          13,
          286,
          603,
          483,
          456,
          4728,
          13,
          1033,
          13,
          3008,
          291,
          294,
          264,
          958,
          960,
          50965
        ]
      },
      {
        "avg_logprob": -0.2370806376139323,
        "compression_ratio": 1.5833333333333333,
        "end": 5119.28,
        "id": 1139,
        "no_speech_prob": 0.000552763813175261,
        "seek": 509430,
        "start": 5112.46,
        "temperature": 0,
        "text": " All right, um, okay, how we doing everybody",
        "tokens": [
          51272,
          1057,
          558,
          11,
          1105,
          11,
          1392,
          11,
          577,
          321,
          884,
          2201,
          51613
        ]
      },
      {
        "avg_logprob": -0.2688432486660509,
        "compression_ratio": 1.508108108108108,
        "end": 5126.860000000001,
        "id": 1140,
        "no_speech_prob": 0.0001686487375991419,
        "seek": 512430,
        "start": 5124.860000000001,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50392,
          1033,
          50492
        ]
      },
      {
        "avg_logprob": -0.2688432486660509,
        "compression_ratio": 1.508108108108108,
        "end": 5131.5,
        "id": 1141,
        "no_speech_prob": 0.0001686487375991419,
        "seek": 512430,
        "start": 5129.5,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50624,
          1033,
          50724
        ]
      },
      {
        "avg_logprob": -0.2688432486660509,
        "compression_ratio": 1.508108108108108,
        "end": 5139.42,
        "id": 1142,
        "no_speech_prob": 0.0001686487375991419,
        "seek": 512430,
        "start": 5132.14,
        "temperature": 0,
        "text": " So I think I want to use the nice work david hall look at all these people following along so nice",
        "tokens": [
          50756,
          407,
          286,
          519,
          286,
          528,
          281,
          764,
          264,
          1481,
          589,
          11753,
          327,
          6500,
          574,
          412,
          439,
          613,
          561,
          3480,
          2051,
          370,
          1481,
          51120
        ]
      },
      {
        "avg_logprob": -0.2688432486660509,
        "compression_ratio": 1.508108108108108,
        "end": 5142.06,
        "id": 1143,
        "no_speech_prob": 0.0001686487375991419,
        "seek": 512430,
        "start": 5140.9400000000005,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51196,
          1105,
          51252
        ]
      },
      {
        "avg_logprob": -0.2688432486660509,
        "compression_ratio": 1.508108108108108,
        "end": 5144.06,
        "id": 1144,
        "no_speech_prob": 0.0001686487375991419,
        "seek": 512430,
        "start": 5142.06,
        "temperature": 0,
        "text": " I should probably turn off. So",
        "tokens": [
          51252,
          286,
          820,
          1391,
          1261,
          766,
          13,
          407,
          51352
        ]
      },
      {
        "avg_logprob": -0.2688432486660509,
        "compression_ratio": 1.508108108108108,
        "end": 5146.54,
        "id": 1145,
        "no_speech_prob": 0.0001686487375991419,
        "seek": 512430,
        "start": 5144.46,
        "temperature": 0,
        "text": " What how much time do I have here?",
        "tokens": [
          51372,
          708,
          577,
          709,
          565,
          360,
          286,
          362,
          510,
          30,
          51476
        ]
      },
      {
        "avg_logprob": -0.2688432486660509,
        "compression_ratio": 1.508108108108108,
        "end": 5152.3,
        "id": 1146,
        "no_speech_prob": 0.0001686487375991419,
        "seek": 512430,
        "start": 5147.5,
        "temperature": 0,
        "text": " Um, I want to let me make a list of stuff that I want to do like if I think about what my twitter bot",
        "tokens": [
          51524,
          3301,
          11,
          286,
          528,
          281,
          718,
          385,
          652,
          257,
          1329,
          295,
          1507,
          300,
          286,
          528,
          281,
          360,
          411,
          498,
          286,
          519,
          466,
          437,
          452,
          21439,
          10592,
          51764
        ]
      },
      {
        "avg_logprob": -0.2601590742144668,
        "compression_ratio": 1.3893129770992367,
        "end": 5154.3,
        "id": 1147,
        "no_speech_prob": 0.00010070582357002422,
        "seek": 515230,
        "start": 5152.3,
        "temperature": 0,
        "text": " examples used to do",
        "tokens": [
          50364,
          5110,
          1143,
          281,
          360,
          50464
        ]
      },
      {
        "avg_logprob": -0.2601590742144668,
        "compression_ratio": 1.3893129770992367,
        "end": 5158.38,
        "id": 1148,
        "no_speech_prob": 0.00010070582357002422,
        "seek": 515230,
        "start": 5156.38,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50568,
          3301,
          50668
        ]
      },
      {
        "avg_logprob": -0.2601590742144668,
        "compression_ratio": 1.3893129770992367,
        "end": 5161.34,
        "id": 1149,
        "no_speech_prob": 0.00010070582357002422,
        "seek": 515230,
        "start": 5159.34,
        "temperature": 0,
        "text": " Sorry, um",
        "tokens": [
          50716,
          4919,
          11,
          1105,
          50816
        ]
      },
      {
        "avg_logprob": -0.2601590742144668,
        "compression_ratio": 1.3893129770992367,
        "end": 5173.9800000000005,
        "id": 1150,
        "no_speech_prob": 0.00010070582357002422,
        "seek": 515230,
        "start": 5167.26,
        "temperature": 0,
        "text": " This is from my program of a to z course last year in week four twitter, so",
        "tokens": [
          51112,
          639,
          307,
          490,
          452,
          1461,
          295,
          257,
          281,
          710,
          1164,
          1036,
          1064,
          294,
          1243,
          1451,
          21439,
          11,
          370,
          51448
        ]
      },
      {
        "avg_logprob": -0.2601590742144668,
        "compression_ratio": 1.3893129770992367,
        "end": 5177.58,
        "id": 1151,
        "no_speech_prob": 0.00010070582357002422,
        "seek": 515230,
        "start": 5175.820000000001,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51540,
          3301,
          51628
        ]
      },
      {
        "avg_logprob": -0.2601590742144668,
        "compression_ratio": 1.3893129770992367,
        "end": 5180.3,
        "id": 1152,
        "no_speech_prob": 0.00010070582357002422,
        "seek": 515230,
        "start": 5177.58,
        "temperature": 0,
        "text": " I guess it's useful to show it's definitely useful to show how to like",
        "tokens": [
          51628,
          286,
          2041,
          309,
          311,
          4420,
          281,
          855,
          309,
          311,
          2138,
          4420,
          281,
          855,
          577,
          281,
          411,
          51764
        ]
      },
      {
        "avg_logprob": -0.2322563758263221,
        "compression_ratio": 1.5609756097560976,
        "end": 5185.26,
        "id": 1153,
        "no_speech_prob": 0.00008888020238373429,
        "seek": 518030,
        "start": 5181.24,
        "temperature": 0,
        "text": " Reblog and reply. I think that's what i'll go for next",
        "tokens": [
          50411,
          1300,
          65,
          4987,
          293,
          16972,
          13,
          286,
          519,
          300,
          311,
          437,
          741,
          603,
          352,
          337,
          958,
          50612
        ]
      },
      {
        "avg_logprob": -0.2322563758263221,
        "compression_ratio": 1.5609756097560976,
        "end": 5189.58,
        "id": 1154,
        "no_speech_prob": 0.00008888020238373429,
        "seek": 518030,
        "start": 5186.78,
        "temperature": 0,
        "text": " And then how to do an image, okay, I think that's makes sense",
        "tokens": [
          50688,
          400,
          550,
          577,
          281,
          360,
          364,
          3256,
          11,
          1392,
          11,
          286,
          519,
          300,
          311,
          1669,
          2020,
          50828
        ]
      },
      {
        "avg_logprob": -0.2322563758263221,
        "compression_ratio": 1.5609756097560976,
        "end": 5192.14,
        "id": 1155,
        "no_speech_prob": 0.00008888020238373429,
        "seek": 518030,
        "start": 5190.78,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50888,
          1105,
          50956
        ]
      },
      {
        "avg_logprob": -0.2322563758263221,
        "compression_ratio": 1.5609756097560976,
        "end": 5194.14,
        "id": 1156,
        "no_speech_prob": 0.00008888020238373429,
        "seek": 518030,
        "start": 5192.14,
        "temperature": 0,
        "text": " So we need the streaming",
        "tokens": [
          50956,
          407,
          321,
          643,
          264,
          11791,
          51056
        ]
      },
      {
        "avg_logprob": -0.2322563758263221,
        "compression_ratio": 1.5609756097560976,
        "end": 5202.9400000000005,
        "id": 1157,
        "no_speech_prob": 0.00008888020238373429,
        "seek": 518030,
        "start": 5197.9800000000005,
        "temperature": 0,
        "text": " So I need to use the stream so I think what I want to do also is duplicate this",
        "tokens": [
          51248,
          407,
          286,
          643,
          281,
          764,
          264,
          4309,
          370,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          611,
          307,
          23976,
          341,
          51496
        ]
      },
      {
        "avg_logprob": -0.2322563758263221,
        "compression_ratio": 1.5609756097560976,
        "end": 5206.46,
        "id": 1158,
        "no_speech_prob": 0.00008888020238373429,
        "seek": 518030,
        "start": 5204.46,
        "temperature": 0,
        "text": " So let me close all these files",
        "tokens": [
          51572,
          407,
          718,
          385,
          1998,
          439,
          613,
          7098,
          51672
        ]
      },
      {
        "avg_logprob": -0.26733367847946454,
        "compression_ratio": 1.226890756302521,
        "end": 5212.24,
        "id": 1159,
        "no_speech_prob": 0.000044693842937704176,
        "seek": 520646,
        "start": 5207.34,
        "temperature": 0,
        "text": " It's four o'clock I don't have a ton of time left, but I would like to get a little further",
        "tokens": [
          50408,
          467,
          311,
          1451,
          277,
          6,
          9023,
          286,
          500,
          380,
          362,
          257,
          2952,
          295,
          565,
          1411,
          11,
          457,
          286,
          576,
          411,
          281,
          483,
          257,
          707,
          3052,
          50653
        ]
      },
      {
        "avg_logprob": -0.26733367847946454,
        "compression_ratio": 1.226890756302521,
        "end": 5216.38,
        "id": 1160,
        "no_speech_prob": 0.000044693842937704176,
        "seek": 520646,
        "start": 5214.38,
        "temperature": 0,
        "text": " Oh, it's just um",
        "tokens": [
          50760,
          876,
          11,
          309,
          311,
          445,
          1105,
          50860
        ]
      },
      {
        "avg_logprob": -0.26733367847946454,
        "compression_ratio": 1.226890756302521,
        "end": 5222.78,
        "id": 1161,
        "no_speech_prob": 0.000044693842937704176,
        "seek": 520646,
        "start": 5220.78,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51080,
          3301,
          51180
        ]
      },
      {
        "avg_logprob": -0.26733367847946454,
        "compression_ratio": 1.226890756302521,
        "end": 5227.74,
        "id": 1162,
        "no_speech_prob": 0.000044693842937704176,
        "seek": 520646,
        "start": 5224.14,
        "temperature": 0,
        "text": " Um, okay, what am I doing here? Um",
        "tokens": [
          51248,
          3301,
          11,
          1392,
          11,
          437,
          669,
          286,
          884,
          510,
          30,
          3301,
          51428
        ]
      },
      {
        "avg_logprob": -0.22069697286568435,
        "compression_ratio": 1.3035714285714286,
        "end": 5230.219999999999,
        "id": 1163,
        "no_speech_prob": 0.00024923073942773044,
        "seek": 522774,
        "start": 5228.219999999999,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50388,
          3301,
          50488
        ]
      },
      {
        "avg_logprob": -0.22069697286568435,
        "compression_ratio": 1.3035714285714286,
        "end": 5238.139999999999,
        "id": 1164,
        "no_speech_prob": 0.00024923073942773044,
        "seek": 522774,
        "start": 5232.78,
        "temperature": 0,
        "text": " Let's make a folder called mastodon, let's put mastodon bot in in there",
        "tokens": [
          50616,
          961,
          311,
          652,
          257,
          10820,
          1219,
          27055,
          378,
          266,
          11,
          718,
          311,
          829,
          27055,
          378,
          266,
          10592,
          294,
          294,
          456,
          50884
        ]
      },
      {
        "avg_logprob": -0.22069697286568435,
        "compression_ratio": 1.3035714285714286,
        "end": 5242.54,
        "id": 1165,
        "no_speech_prob": 0.00024923073942773044,
        "seek": 522774,
        "start": 5240.219999999999,
        "temperature": 0,
        "text": " Let me call it bot",
        "tokens": [
          50988,
          961,
          385,
          818,
          309,
          10592,
          51104
        ]
      },
      {
        "avg_logprob": -0.22069697286568435,
        "compression_ratio": 1.3035714285714286,
        "end": 5248.719999999999,
        "id": 1166,
        "no_speech_prob": 0.00024923073942773044,
        "seek": 522774,
        "start": 5245.0199999999995,
        "temperature": 0,
        "text": " One and then let me just duplicate it",
        "tokens": [
          51228,
          1485,
          293,
          550,
          718,
          385,
          445,
          23976,
          309,
          51413
        ]
      },
      {
        "avg_logprob": -0.22069697286568435,
        "compression_ratio": 1.3035714285714286,
        "end": 5254.94,
        "id": 1167,
        "no_speech_prob": 0.00024923073942773044,
        "seek": 522774,
        "start": 5252.94,
        "temperature": 0,
        "text": " Oh, you know I",
        "tokens": [
          51624,
          876,
          11,
          291,
          458,
          286,
          51724
        ]
      },
      {
        "avg_logprob": -0.29617553844786526,
        "compression_ratio": 1.3602941176470589,
        "end": 5261.28,
        "id": 1168,
        "no_speech_prob": 0.0004173143533989787,
        "seek": 525494,
        "start": 5255.099999999999,
        "temperature": 0,
        "text": " I'll mention this. I totally forgot to put node modules in the git ignore. Um, so now",
        "tokens": [
          50372,
          286,
          603,
          2152,
          341,
          13,
          286,
          3879,
          5298,
          281,
          829,
          9984,
          16679,
          294,
          264,
          18331,
          11200,
          13,
          3301,
          11,
          370,
          586,
          50681
        ]
      },
      {
        "avg_logprob": -0.29617553844786526,
        "compression_ratio": 1.3602941176470589,
        "end": 5272.139999999999,
        "id": 1169,
        "no_speech_prob": 0.0004173143533989787,
        "seek": 525494,
        "start": 5267.66,
        "temperature": 0,
        "text": " Um, let me go here, um close this",
        "tokens": [
          51000,
          3301,
          11,
          718,
          385,
          352,
          510,
          11,
          1105,
          1998,
          341,
          51224
        ]
      },
      {
        "avg_logprob": -0.29617553844786526,
        "compression_ratio": 1.3602941176470589,
        "end": 5279.9,
        "id": 1170,
        "no_speech_prob": 0.0004173143533989787,
        "seek": 525494,
        "start": 5277.9,
        "temperature": 0,
        "text": " And I have both of these",
        "tokens": [
          51512,
          400,
          286,
          362,
          1293,
          295,
          613,
          51612
        ]
      },
      {
        "avg_logprob": -0.29617553844786526,
        "compression_ratio": 1.3602941176470589,
        "end": 5282.379999999999,
        "id": 1171,
        "no_speech_prob": 0.0004173143533989787,
        "seek": 525494,
        "start": 5280.0599999999995,
        "temperature": 0,
        "text": " um, this chain doesn't change this I can",
        "tokens": [
          51620,
          1105,
          11,
          341,
          5021,
          1177,
          380,
          1319,
          341,
          286,
          393,
          51736
        ]
      },
      {
        "avg_logprob": -0.32543480187131646,
        "compression_ratio": 1.2173913043478262,
        "end": 5285.26,
        "id": 1172,
        "no_speech_prob": 0.004754927475005388,
        "seek": 528238,
        "start": 5282.38,
        "temperature": 0,
        "text": " Um, so I can get rid of",
        "tokens": [
          50364,
          3301,
          11,
          370,
          286,
          393,
          483,
          3973,
          295,
          50508
        ]
      },
      {
        "avg_logprob": -0.32543480187131646,
        "compression_ratio": 1.2173913043478262,
        "end": 5295.26,
        "id": 1173,
        "no_speech_prob": 0.004754927475005388,
        "seek": 528238,
        "start": 5293.26,
        "temperature": 0,
        "text": " All right, this is fine",
        "tokens": [
          50908,
          1057,
          558,
          11,
          341,
          307,
          2489,
          51008
        ]
      },
      {
        "avg_logprob": -0.32543480187131646,
        "compression_ratio": 1.2173913043478262,
        "end": 5298.38,
        "id": 1174,
        "no_speech_prob": 0.004754927475005388,
        "seek": 528238,
        "start": 5296.38,
        "temperature": 0,
        "text": " Bot.js",
        "tokens": [
          51064,
          25486,
          13,
          25530,
          51164
        ]
      },
      {
        "avg_logprob": -0.32543480187131646,
        "compression_ratio": 1.2173913043478262,
        "end": 5302.06,
        "id": 1175,
        "no_speech_prob": 0.004754927475005388,
        "seek": 528238,
        "start": 5299.02,
        "temperature": 0,
        "text": " I guess i'll leave the code as is that's bot one",
        "tokens": [
          51196,
          286,
          2041,
          741,
          603,
          1856,
          264,
          3089,
          382,
          307,
          300,
          311,
          10592,
          472,
          51348
        ]
      },
      {
        "avg_logprob": -0.32543480187131646,
        "compression_ratio": 1.2173913043478262,
        "end": 5305.82,
        "id": 1176,
        "no_speech_prob": 0.004754927475005388,
        "seek": 528238,
        "start": 5303.82,
        "temperature": 0,
        "text": " I'm such a doofus",
        "tokens": [
          51436,
          286,
          478,
          1270,
          257,
          360,
          2670,
          301,
          51536
        ]
      },
      {
        "avg_logprob": -0.32543480187131646,
        "compression_ratio": 1.2173913043478262,
        "end": 5308.38,
        "id": 1177,
        "no_speech_prob": 0.004754927475005388,
        "seek": 528238,
        "start": 5306.38,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51564,
          1105,
          51664
        ]
      },
      {
        "avg_logprob": -0.32543480187131646,
        "compression_ratio": 1.2173913043478262,
        "end": 5311.26,
        "id": 1178,
        "no_speech_prob": 0.004754927475005388,
        "seek": 528238,
        "start": 5309.26,
        "temperature": 0,
        "text": " This one is two",
        "tokens": [
          51708,
          639,
          472,
          307,
          732,
          51808
        ]
      },
      {
        "avg_logprob": -0.29769311127839265,
        "compression_ratio": 1.3636363636363635,
        "end": 5315.1,
        "id": 1179,
        "no_speech_prob": 0.00028684979770332575,
        "seek": 531238,
        "start": 5312.54,
        "temperature": 0,
        "text": " This one is one",
        "tokens": [
          50372,
          639,
          472,
          307,
          472,
          50500
        ]
      },
      {
        "avg_logprob": -0.29769311127839265,
        "compression_ratio": 1.3636363636363635,
        "end": 5320.78,
        "id": 1180,
        "no_speech_prob": 0.00028684979770332575,
        "seek": 531238,
        "start": 5317.66,
        "temperature": 0,
        "text": " And here we go, okay",
        "tokens": [
          50628,
          400,
          510,
          321,
          352,
          11,
          1392,
          50784
        ]
      },
      {
        "avg_logprob": -0.29769311127839265,
        "compression_ratio": 1.3636363636363635,
        "end": 5327.9800000000005,
        "id": 1181,
        "no_speech_prob": 0.00028684979770332575,
        "seek": 531238,
        "start": 5323.5,
        "temperature": 0,
        "text": " Um, okay, I think I should have more space here",
        "tokens": [
          50920,
          3301,
          11,
          1392,
          11,
          286,
          519,
          286,
          820,
          362,
          544,
          1901,
          510,
          51144
        ]
      },
      {
        "avg_logprob": -0.29769311127839265,
        "compression_ratio": 1.3636363636363635,
        "end": 5330.78,
        "id": 1182,
        "no_speech_prob": 0.00028684979770332575,
        "seek": 531238,
        "start": 5328.78,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51184,
          1105,
          51284
        ]
      },
      {
        "avg_logprob": -0.29769311127839265,
        "compression_ratio": 1.3636363636363635,
        "end": 5334.46,
        "id": 1183,
        "no_speech_prob": 0.00028684979770332575,
        "seek": 531238,
        "start": 5332.46,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51368,
          1033,
          51468
        ]
      },
      {
        "avg_logprob": -0.29769311127839265,
        "compression_ratio": 1.3636363636363635,
        "end": 5339.34,
        "id": 1184,
        "no_speech_prob": 0.00028684979770332575,
        "seek": 531238,
        "start": 5335.02,
        "temperature": 0,
        "text": " Um, okay, so I think i'm ready for the next phase of this",
        "tokens": [
          51496,
          3301,
          11,
          1392,
          11,
          370,
          286,
          519,
          741,
          478,
          1919,
          337,
          264,
          958,
          5574,
          295,
          341,
          51712
        ]
      },
      {
        "avg_logprob": -0.4872956662564664,
        "compression_ratio": 1.2403846153846154,
        "end": 5344.46,
        "id": 1185,
        "no_speech_prob": 0.00284480769187212,
        "seek": 533934,
        "start": 5340.22,
        "temperature": 0,
        "text": " And oh streaming API, that's what I need to",
        "tokens": [
          50408,
          400,
          1954,
          11791,
          9362,
          11,
          300,
          311,
          437,
          286,
          643,
          281,
          50620
        ]
      },
      {
        "avg_logprob": -0.4872956662564664,
        "compression_ratio": 1.2403846153846154,
        "end": 5356.4800000000005,
        "id": 1186,
        "no_speech_prob": 0.00284480769187212,
        "seek": 533934,
        "start": 5351.18,
        "temperature": 0,
        "text": " Remember how I stream stream dash user. Okay. Okay",
        "tokens": [
          50956,
          5459,
          577,
          286,
          4309,
          4309,
          8240,
          4195,
          13,
          1033,
          13,
          1033,
          51221
        ]
      },
      {
        "avg_logprob": -0.4872956662564664,
        "compression_ratio": 1.2403846153846154,
        "end": 5367.02,
        "id": 1187,
        "no_speech_prob": 0.00284480769187212,
        "seek": 533934,
        "start": 5362.06,
        "temperature": 0,
        "text": " Okay, and I think actually is this",
        "tokens": [
          51500,
          1033,
          11,
          293,
          286,
          519,
          767,
          307,
          341,
          51748
        ]
      },
      {
        "avg_logprob": -0.3528480200931944,
        "compression_ratio": 1.2457627118644068,
        "end": 5375.58,
        "id": 1188,
        "no_speech_prob": 0.00011773914593504742,
        "seek": 536934,
        "start": 5369.66,
        "temperature": 0,
        "text": " Yeah, yeah, there we go. Perfect. Um, okay",
        "tokens": [
          50380,
          865,
          11,
          1338,
          11,
          456,
          321,
          352,
          13,
          10246,
          13,
          3301,
          11,
          1392,
          50676
        ]
      },
      {
        "avg_logprob": -0.3528480200931944,
        "compression_ratio": 1.2457627118644068,
        "end": 5380.38,
        "id": 1189,
        "no_speech_prob": 0.00011773914593504742,
        "seek": 536934,
        "start": 5378.12,
        "temperature": 0,
        "text": " Perfect, okay",
        "tokens": [
          50803,
          10246,
          11,
          1392,
          50916
        ]
      },
      {
        "avg_logprob": -0.3528480200931944,
        "compression_ratio": 1.2457627118644068,
        "end": 5384.62,
        "id": 1190,
        "no_speech_prob": 0.00011773914593504742,
        "seek": 536934,
        "start": 5382.62,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51028,
          3301,
          51128
        ]
      },
      {
        "avg_logprob": -0.3528480200931944,
        "compression_ratio": 1.2457627118644068,
        "end": 5391.66,
        "id": 1191,
        "no_speech_prob": 0.00011773914593504742,
        "seek": 536934,
        "start": 5389.66,
        "temperature": 0,
        "text": " Oh, whoops, ah, come on",
        "tokens": [
          51380,
          876,
          11,
          567,
          3370,
          11,
          3716,
          11,
          808,
          322,
          51480
        ]
      },
      {
        "avg_logprob": -0.3528480200931944,
        "compression_ratio": 1.2457627118644068,
        "end": 5394.46,
        "id": 1192,
        "no_speech_prob": 0.00011773914593504742,
        "seek": 536934,
        "start": 5393.34,
        "temperature": 0,
        "text": " All right",
        "tokens": [
          51564,
          1057,
          558,
          51620
        ]
      },
      {
        "avg_logprob": -0.3528480200931944,
        "compression_ratio": 1.2457627118644068,
        "end": 5396.7,
        "id": 1193,
        "no_speech_prob": 0.00011773914593504742,
        "seek": 536934,
        "start": 5394.46,
        "temperature": 0,
        "text": " I'm ready I can do that. I've got a half an hour here",
        "tokens": [
          51620,
          286,
          478,
          1919,
          286,
          393,
          360,
          300,
          13,
          286,
          600,
          658,
          257,
          1922,
          364,
          1773,
          510,
          51732
        ]
      },
      {
        "avg_logprob": -0.2986057454889471,
        "compression_ratio": 0.813953488372093,
        "end": 5399.66,
        "id": 1194,
        "no_speech_prob": 0.000855878519359976,
        "seek": 539670,
        "start": 5397.66,
        "temperature": 0,
        "text": " I can definitely do this next piece",
        "tokens": [
          50412,
          286,
          393,
          2138,
          360,
          341,
          958,
          2522,
          50512
        ]
      },
      {
        "avg_logprob": -0.41146650314331057,
        "compression_ratio": 0.8297872340425532,
        "end": 5401.66,
        "id": 1195,
        "no_speech_prob": 0.000720812298823148,
        "seek": 539966,
        "start": 5399.66,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50364,
          407,
          50464
        ]
      },
      {
        "avg_logprob": -0.41146650314331057,
        "compression_ratio": 0.8297872340425532,
        "end": 5426.94,
        "id": 1196,
        "no_speech_prob": 0.000720812298823148,
        "seek": 539966,
        "start": 5422.62,
        "temperature": 0,
        "text": " Okay, all right everybody here we go",
        "tokens": [
          51512,
          1033,
          11,
          439,
          558,
          2201,
          510,
          321,
          352,
          51728
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5429.179999999999,
        "id": 1197,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5427.179999999999,
        "temperature": 0,
        "text": " Hello",
        "tokens": [
          50376,
          2425,
          50476
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5431.179999999999,
        "id": 1198,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5429.179999999999,
        "temperature": 0,
        "text": " Hello, all right",
        "tokens": [
          50476,
          2425,
          11,
          439,
          558,
          50576
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5433.5,
        "id": 1199,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5431.5,
        "temperature": 0,
        "text": " I'm still working with mastodon",
        "tokens": [
          50592,
          286,
          478,
          920,
          1364,
          365,
          27055,
          378,
          266,
          50692
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5435.74,
        "id": 1200,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5433.5,
        "temperature": 0,
        "text": " And what i'm going to do in this video now",
        "tokens": [
          50692,
          400,
          437,
          741,
          478,
          516,
          281,
          360,
          294,
          341,
          960,
          586,
          50804
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5443.419999999999,
        "id": 1201,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5436.219999999999,
        "temperature": 0,
        "text": " Is i'm going to take the sample bot that I made and instead of just on a timer every 24 hours every 60 minutes",
        "tokens": [
          50828,
          1119,
          741,
          478,
          516,
          281,
          747,
          264,
          6889,
          10592,
          300,
          286,
          1027,
          293,
          2602,
          295,
          445,
          322,
          257,
          19247,
          633,
          4022,
          2496,
          633,
          4060,
          2077,
          51188
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5445.5,
        "id": 1202,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5443.5,
        "temperature": 0,
        "text": " I happen to post something I toot",
        "tokens": [
          51192,
          286,
          1051,
          281,
          2183,
          746,
          286,
          281,
          310,
          51292
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5449.179999999999,
        "id": 1203,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5445.98,
        "temperature": 0,
        "text": " What i'm going to do is i'm going to use the streaming API",
        "tokens": [
          51316,
          708,
          741,
          478,
          516,
          281,
          360,
          307,
          741,
          478,
          516,
          281,
          764,
          264,
          11791,
          9362,
          51476
        ]
      },
      {
        "avg_logprob": -0.20003400530133927,
        "compression_ratio": 1.7004608294930876,
        "end": 5454.299999999999,
        "id": 1204,
        "no_speech_prob": 0.0003101533220615238,
        "seek": 542694,
        "start": 5449.419999999999,
        "temperature": 0,
        "text": " The streaming API is a way for me to in real time listen for events",
        "tokens": [
          51488,
          440,
          11791,
          9362,
          307,
          257,
          636,
          337,
          385,
          281,
          294,
          957,
          565,
          2140,
          337,
          3931,
          51732
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5457.02,
        "id": 1205,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5454.7,
        "temperature": 0,
        "text": " And the particular kind of events that i'm going to",
        "tokens": [
          50384,
          400,
          264,
          1729,
          733,
          295,
          3931,
          300,
          741,
          478,
          516,
          281,
          50500
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5460.14,
        "id": 1206,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5457.58,
        "temperature": 0,
        "text": " Listen for are what's known as user events",
        "tokens": [
          50528,
          7501,
          337,
          366,
          437,
          311,
          2570,
          382,
          4195,
          3931,
          50656
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5464.400000000001,
        "id": 1207,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5460.46,
        "temperature": 0,
        "text": " So a user event and we'll see all the different kinds is anytime that I might get a notification",
        "tokens": [
          50672,
          407,
          257,
          4195,
          2280,
          293,
          321,
          603,
          536,
          439,
          264,
          819,
          3685,
          307,
          13038,
          300,
          286,
          1062,
          483,
          257,
          11554,
          50869
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5468.9400000000005,
        "id": 1208,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5464.78,
        "temperature": 0,
        "text": " Or somebody that I follow might post something or anytime that I might get anyway",
        "tokens": [
          50888,
          1610,
          2618,
          300,
          286,
          1524,
          1062,
          2183,
          746,
          420,
          13038,
          300,
          286,
          1062,
          483,
          4033,
          51096
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5470.62,
        "id": 1209,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5468.9400000000005,
        "temperature": 0,
        "text": " There's lots of things that come in",
        "tokens": [
          51096,
          821,
          311,
          3195,
          295,
          721,
          300,
          808,
          294,
          51180
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5476.14,
        "id": 1210,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5470.62,
        "temperature": 0,
        "text": " user events and these are the good ones to use because if you're using your user event as a bot you're sort of making",
        "tokens": [
          51180,
          4195,
          3931,
          293,
          613,
          366,
          264,
          665,
          2306,
          281,
          764,
          570,
          498,
          291,
          434,
          1228,
          428,
          4195,
          2280,
          382,
          257,
          10592,
          291,
          434,
          1333,
          295,
          1455,
          51456
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5479.9800000000005,
        "id": 1211,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5476.22,
        "temperature": 0,
        "text": " Sure that your bot only engages with people who are opting in and this is pretty important",
        "tokens": [
          51460,
          4894,
          300,
          428,
          10592,
          787,
          45576,
          365,
          561,
          567,
          366,
          2427,
          278,
          294,
          293,
          341,
          307,
          1238,
          1021,
          51648
        ]
      },
      {
        "avg_logprob": -0.21508623387691747,
        "compression_ratio": 1.8823529411764706,
        "end": 5482.46,
        "id": 1212,
        "no_speech_prob": 0.002050685929134488,
        "seek": 545430,
        "start": 5480.14,
        "temperature": 0,
        "text": " you don't want your bot just randomly spamming people and",
        "tokens": [
          51656,
          291,
          500,
          380,
          528,
          428,
          10592,
          445,
          16979,
          24028,
          2810,
          561,
          293,
          51772
        ]
      },
      {
        "avg_logprob": -0.2186190055234589,
        "compression_ratio": 1.7981072555205047,
        "end": 5487.26,
        "id": 1213,
        "no_speech_prob": 0.00015117948350962251,
        "seek": 548246,
        "start": 5483.16,
        "temperature": 0,
        "text": " Favoriting random things or applying to random people who haven't really asked to engage with your bot",
        "tokens": [
          50399,
          34240,
          1748,
          4974,
          721,
          420,
          9275,
          281,
          4974,
          561,
          567,
          2378,
          380,
          534,
          2351,
          281,
          4683,
          365,
          428,
          10592,
          50604
        ]
      },
      {
        "avg_logprob": -0.2186190055234589,
        "compression_ratio": 1.7981072555205047,
        "end": 5492.54,
        "id": 1214,
        "no_speech_prob": 0.00015117948350962251,
        "seek": 548246,
        "start": 5487.26,
        "temperature": 0,
        "text": " So you're going to want to make sure that your bot follows the the code of conduct in the terms of service of bots in",
        "tokens": [
          50604,
          407,
          291,
          434,
          516,
          281,
          528,
          281,
          652,
          988,
          300,
          428,
          10592,
          10002,
          264,
          264,
          3089,
          295,
          6018,
          294,
          264,
          2115,
          295,
          2643,
          295,
          35410,
          294,
          50868
        ]
      },
      {
        "avg_logprob": -0.2186190055234589,
        "compression_ratio": 1.7981072555205047,
        "end": 5497.82,
        "id": 1215,
        "no_speech_prob": 0.00015117948350962251,
        "seek": 548246,
        "start": 5492.62,
        "temperature": 0,
        "text": " Space i'll show you where you can find that but typically a good way to think about is just like if somebody is at",
        "tokens": [
          50872,
          8705,
          741,
          603,
          855,
          291,
          689,
          291,
          393,
          915,
          300,
          457,
          5850,
          257,
          665,
          636,
          281,
          519,
          466,
          307,
          445,
          411,
          498,
          2618,
          307,
          412,
          51132
        ]
      },
      {
        "avg_logprob": -0.2186190055234589,
        "compression_ratio": 1.7981072555205047,
        "end": 5500.06,
        "id": 1216,
        "no_speech_prob": 0.00015117948350962251,
        "seek": 548246,
        "start": 5497.9,
        "temperature": 0,
        "text": " Mentioning the bot then you're welcome to reply to them",
        "tokens": [
          51136,
          376,
          1251,
          278,
          264,
          10592,
          550,
          291,
          434,
          2928,
          281,
          16972,
          281,
          552,
          51244
        ]
      },
      {
        "avg_logprob": -0.2186190055234589,
        "compression_ratio": 1.7981072555205047,
        "end": 5505.1,
        "id": 1217,
        "no_speech_prob": 0.00015117948350962251,
        "seek": 548246,
        "start": 5500.3,
        "temperature": 0,
        "text": " If somebody follows you then you're also welcome to engage with that person as a as the bot programmer",
        "tokens": [
          51256,
          759,
          2618,
          10002,
          291,
          550,
          291,
          434,
          611,
          2928,
          281,
          4683,
          365,
          300,
          954,
          382,
          257,
          382,
          264,
          10592,
          32116,
          51496
        ]
      },
      {
        "avg_logprob": -0.2186190055234589,
        "compression_ratio": 1.7981072555205047,
        "end": 5507.42,
        "id": 1218,
        "no_speech_prob": 0.00015117948350962251,
        "seek": 548246,
        "start": 5505.26,
        "temperature": 0,
        "text": " Okay, so let's go over and look at the streaming API",
        "tokens": [
          51504,
          1033,
          11,
          370,
          718,
          311,
          352,
          670,
          293,
          574,
          412,
          264,
          11791,
          9362,
          51612
        ]
      },
      {
        "avg_logprob": -0.2186190055234589,
        "compression_ratio": 1.7981072555205047,
        "end": 5510.54,
        "id": 1219,
        "no_speech_prob": 0.00015117948350962251,
        "seek": 548246,
        "start": 5508.7,
        "temperature": 0,
        "text": " And let me actually go",
        "tokens": [
          51676,
          400,
          718,
          385,
          767,
          352,
          51768
        ]
      },
      {
        "avg_logprob": -0.22651900368175287,
        "compression_ratio": 1.5825242718446602,
        "end": 5512.62,
        "id": 1220,
        "no_speech_prob": 0.000020145573216723278,
        "seek": 551054,
        "start": 5510.54,
        "temperature": 0,
        "text": " to bots in space about",
        "tokens": [
          50364,
          281,
          35410,
          294,
          1901,
          466,
          50468
        ]
      },
      {
        "avg_logprob": -0.22651900368175287,
        "compression_ratio": 1.5825242718446602,
        "end": 5516.78,
        "id": 1221,
        "no_speech_prob": 0.000020145573216723278,
        "seek": 551054,
        "start": 5514.78,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50576,
          3301,
          50676
        ]
      },
      {
        "avg_logprob": -0.22651900368175287,
        "compression_ratio": 1.5825242718446602,
        "end": 5519.82,
        "id": 1222,
        "no_speech_prob": 0.000020145573216723278,
        "seek": 551054,
        "start": 5517.9,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50732,
          1033,
          50828
        ]
      },
      {
        "avg_logprob": -0.22651900368175287,
        "compression_ratio": 1.5825242718446602,
        "end": 5524.7,
        "id": 1223,
        "no_speech_prob": 0.000020145573216723278,
        "seek": 551054,
        "start": 5519.82,
        "temperature": 0,
        "text": " so before I before I um start using the streaming API, let me just point out to read the",
        "tokens": [
          50828,
          370,
          949,
          286,
          949,
          286,
          1105,
          722,
          1228,
          264,
          11791,
          9362,
          11,
          718,
          385,
          445,
          935,
          484,
          281,
          1401,
          264,
          51072
        ]
      },
      {
        "avg_logprob": -0.22651900368175287,
        "compression_ratio": 1.5825242718446602,
        "end": 5531.5,
        "id": 1224,
        "no_speech_prob": 0.000020145573216723278,
        "seek": 551054,
        "start": 5525.16,
        "temperature": 0,
        "text": " Information page with the code of conduct and also the terms of service if you're choosing to host your bot on bots in dot",
        "tokens": [
          51095,
          15357,
          3028,
          365,
          264,
          3089,
          295,
          6018,
          293,
          611,
          264,
          2115,
          295,
          2643,
          498,
          291,
          434,
          10875,
          281,
          3975,
          428,
          10592,
          322,
          35410,
          294,
          5893,
          51412
        ]
      },
      {
        "avg_logprob": -0.22651900368175287,
        "compression_ratio": 1.5825242718446602,
        "end": 5534.62,
        "id": 1225,
        "no_speech_prob": 0.000020145573216723278,
        "seek": 551054,
        "start": 5531.5,
        "temperature": 0,
        "text": " Space you're going to want to make sure you follow the rules of the space",
        "tokens": [
          51412,
          8705,
          291,
          434,
          516,
          281,
          528,
          281,
          652,
          988,
          291,
          1524,
          264,
          4474,
          295,
          264,
          1901,
          51568
        ]
      },
      {
        "avg_logprob": -0.22651900368175287,
        "compression_ratio": 1.5825242718446602,
        "end": 5536.78,
        "id": 1226,
        "no_speech_prob": 0.000020145573216723278,
        "seek": 551054,
        "start": 5535.1,
        "temperature": 0,
        "text": " Okay. Now",
        "tokens": [
          51592,
          1033,
          13,
          823,
          51676
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5540.139999999999,
        "id": 1227,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5536.78,
        "temperature": 0,
        "text": " What i'm going to do is I am going to start using the streaming API",
        "tokens": [
          50364,
          708,
          741,
          478,
          516,
          281,
          360,
          307,
          286,
          669,
          516,
          281,
          722,
          1228,
          264,
          11791,
          9362,
          50532
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5542.62,
        "id": 1228,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5540.46,
        "temperature": 0,
        "text": " So the way that I do that and we can find it here",
        "tokens": [
          50548,
          407,
          264,
          636,
          300,
          286,
          360,
          300,
          293,
          321,
          393,
          915,
          309,
          510,
          50656
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5545.44,
        "id": 1229,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5542.86,
        "temperature": 0,
        "text": " Remember, this is the node package that i'm using mastodon-api",
        "tokens": [
          50668,
          5459,
          11,
          341,
          307,
          264,
          9984,
          7372,
          300,
          741,
          478,
          1228,
          27055,
          378,
          266,
          12,
          35891,
          50797
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5551.98,
        "id": 1230,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5546.46,
        "temperature": 0,
        "text": " And this is basically what I want to do. I want to create a listener and whenever there is a message",
        "tokens": [
          50848,
          400,
          341,
          307,
          1936,
          437,
          286,
          528,
          281,
          360,
          13,
          286,
          528,
          281,
          1884,
          257,
          31569,
          293,
          5699,
          456,
          307,
          257,
          3636,
          51124
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5553.34,
        "id": 1231,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5552.46,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51148,
          1105,
          51192
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5556.54,
        "id": 1232,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5553.34,
        "temperature": 0,
        "text": " I want to take a look at and do stuff act upon that message",
        "tokens": [
          51192,
          286,
          528,
          281,
          747,
          257,
          574,
          412,
          293,
          360,
          1507,
          605,
          3564,
          300,
          3636,
          51352
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5561.66,
        "id": 1233,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5556.7,
        "temperature": 0,
        "text": " So let's actually do exactly this i'm going to keep the error one in here as well. I'm just going to copy paste this",
        "tokens": [
          51360,
          407,
          718,
          311,
          767,
          360,
          2293,
          341,
          741,
          478,
          516,
          281,
          1066,
          264,
          6713,
          472,
          294,
          510,
          382,
          731,
          13,
          286,
          478,
          445,
          516,
          281,
          5055,
          9163,
          341,
          51608
        ]
      },
      {
        "avg_logprob": -0.19005069295868618,
        "compression_ratio": 1.8153846153846154,
        "end": 5564.7,
        "id": 1234,
        "no_speech_prob": 0.0002098818658851087,
        "seek": 553678,
        "start": 5562.7,
        "temperature": 0,
        "text": " into my um",
        "tokens": [
          51660,
          666,
          452,
          1105,
          51760
        ]
      },
      {
        "avg_logprob": -0.1752092997233073,
        "compression_ratio": 1.7532467532467533,
        "end": 5567.179999999999,
        "id": 1235,
        "no_speech_prob": 0.0000034465629141777754,
        "seek": 556470,
        "start": 5565.58,
        "temperature": 0,
        "text": " Code",
        "tokens": [
          50408,
          15549,
          50488
        ]
      },
      {
        "avg_logprob": -0.1752092997233073,
        "compression_ratio": 1.7532467532467533,
        "end": 5573.5,
        "id": 1236,
        "no_speech_prob": 0.0000034465629141777754,
        "seek": 556470,
        "start": 5567.179999999999,
        "temperature": 0,
        "text": " I'm going to comment out this auto posting thing that I had before about the meaning of life. I'm just going to put this here",
        "tokens": [
          50488,
          286,
          478,
          516,
          281,
          2871,
          484,
          341,
          8399,
          15978,
          551,
          300,
          286,
          632,
          949,
          466,
          264,
          3620,
          295,
          993,
          13,
          286,
          478,
          445,
          516,
          281,
          829,
          341,
          510,
          50804
        ]
      },
      {
        "avg_logprob": -0.1752092997233073,
        "compression_ratio": 1.7532467532467533,
        "end": 5578.38,
        "id": 1237,
        "no_speech_prob": 0.0000034465629141777754,
        "seek": 556470,
        "start": 5574.94,
        "temperature": 0,
        "text": " And actually what I want to do now is I want to use my little trick",
        "tokens": [
          50876,
          400,
          767,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          286,
          528,
          281,
          764,
          452,
          707,
          4282,
          51048
        ]
      },
      {
        "avg_logprob": -0.1752092997233073,
        "compression_ratio": 1.7532467532467533,
        "end": 5584.3,
        "id": 1238,
        "no_speech_prob": 0.0000034465629141777754,
        "seek": 556470,
        "start": 5578.94,
        "temperature": 0,
        "text": " Instead of just console logging the message if you remember a little trick that I did in a previous video",
        "tokens": [
          51076,
          7156,
          295,
          445,
          11076,
          27991,
          264,
          3636,
          498,
          291,
          1604,
          257,
          707,
          4282,
          300,
          286,
          630,
          294,
          257,
          3894,
          960,
          51344
        ]
      },
      {
        "avg_logprob": -0.1752092997233073,
        "compression_ratio": 1.7532467532467533,
        "end": 5586.94,
        "id": 1239,
        "no_speech_prob": 0.0000034465629141777754,
        "seek": 556470,
        "start": 5584.94,
        "temperature": 0,
        "text": " is I",
        "tokens": [
          51376,
          307,
          286,
          51476
        ]
      },
      {
        "avg_logprob": -0.1752092997233073,
        "compression_ratio": 1.7532467532467533,
        "end": 5589.58,
        "id": 1240,
        "no_speech_prob": 0.0000034465629141777754,
        "seek": 556470,
        "start": 5587.58,
        "temperature": 0,
        "text": " Used write file",
        "tokens": [
          51508,
          43237,
          2464,
          3991,
          51608
        ]
      },
      {
        "avg_logprob": -0.1752092997233073,
        "compression_ratio": 1.7532467532467533,
        "end": 5593.74,
        "id": 1241,
        "no_speech_prob": 0.0000034465629141777754,
        "seek": 556470,
        "start": 5589.66,
        "temperature": 0,
        "text": " So I want to write files out so I can look at what kind of messages i'm getting",
        "tokens": [
          51612,
          407,
          286,
          528,
          281,
          2464,
          7098,
          484,
          370,
          286,
          393,
          574,
          412,
          437,
          733,
          295,
          7897,
          741,
          478,
          1242,
          51816
        ]
      },
      {
        "avg_logprob": -0.22332689194452196,
        "compression_ratio": 1.5911111111111111,
        "end": 5600.46,
        "id": 1242,
        "no_speech_prob": 0.00013341956946533173,
        "seek": 559374,
        "start": 5594.3,
        "temperature": 0,
        "text": " Um, whoops. Ah, where have I gone? Um, and so let me uncomment this out and I do want to",
        "tokens": [
          50392,
          3301,
          11,
          567,
          3370,
          13,
          2438,
          11,
          689,
          362,
          286,
          2780,
          30,
          3301,
          11,
          293,
          370,
          718,
          385,
          8585,
          518,
          341,
          484,
          293,
          286,
          360,
          528,
          281,
          50700
        ]
      },
      {
        "avg_logprob": -0.22332689194452196,
        "compression_ratio": 1.5911111111111111,
        "end": 5609.179999999999,
        "id": 1243,
        "no_speech_prob": 0.00013341956946533173,
        "seek": 559374,
        "start": 5602.139999999999,
        "temperature": 0,
        "text": " Put like a time stamp also here so it would make sense for me to say like, uh data and then actually",
        "tokens": [
          50784,
          4935,
          411,
          257,
          565,
          9921,
          611,
          510,
          370,
          309,
          576,
          652,
          2020,
          337,
          385,
          281,
          584,
          411,
          11,
          2232,
          1412,
          293,
          550,
          767,
          51136
        ]
      },
      {
        "avg_logprob": -0.22332689194452196,
        "compression_ratio": 1.5911111111111111,
        "end": 5615.679999999999,
        "id": 1244,
        "no_speech_prob": 0.00013341956946533173,
        "seek": 559374,
        "start": 5610.38,
        "temperature": 0,
        "text": " The message probably has a time stamp built into it, but I can also like javascript",
        "tokens": [
          51196,
          440,
          3636,
          1391,
          575,
          257,
          565,
          9921,
          3094,
          666,
          309,
          11,
          457,
          286,
          393,
          611,
          411,
          361,
          37331,
          5944,
          51461
        ]
      },
      {
        "avg_logprob": -0.22332689194452196,
        "compression_ratio": 1.5911111111111111,
        "end": 5619.0199999999995,
        "id": 1245,
        "no_speech_prob": 0.00013341956946533173,
        "seek": 559374,
        "start": 5616.46,
        "temperature": 0,
        "text": " Uh time stamp. I think it's just like new date",
        "tokens": [
          51500,
          4019,
          565,
          9921,
          13,
          286,
          519,
          309,
          311,
          445,
          411,
          777,
          4002,
          51628
        ]
      },
      {
        "avg_logprob": -0.22332689194452196,
        "compression_ratio": 1.5911111111111111,
        "end": 5622.3,
        "id": 1246,
        "no_speech_prob": 0.00013341956946533173,
        "seek": 559374,
        "start": 5619.58,
        "temperature": 0,
        "text": " Uh get time. Yeah, so I can say a new",
        "tokens": [
          51656,
          4019,
          483,
          565,
          13,
          865,
          11,
          370,
          286,
          393,
          584,
          257,
          777,
          51792
        ]
      },
      {
        "avg_logprob": -0.18662916819254557,
        "compression_ratio": 1.656,
        "end": 5624.7,
        "id": 1247,
        "no_speech_prob": 0.00006014133759890683,
        "seek": 562230,
        "start": 5623.26,
        "temperature": 0,
        "text": " date",
        "tokens": [
          50412,
          4002,
          50484
        ]
      },
      {
        "avg_logprob": -0.18662916819254557,
        "compression_ratio": 1.656,
        "end": 5630.22,
        "id": 1248,
        "no_speech_prob": 0.00006014133759890683,
        "seek": 562230,
        "start": 5624.7,
        "temperature": 0,
        "text": " Get time. I think this is right. So again, you can put with template literals",
        "tokens": [
          50484,
          3240,
          565,
          13,
          286,
          519,
          341,
          307,
          558,
          13,
          407,
          797,
          11,
          291,
          393,
          829,
          365,
          12379,
          2733,
          1124,
          50760
        ]
      },
      {
        "avg_logprob": -0.18662916819254557,
        "compression_ratio": 1.656,
        "end": 5635.820000000001,
        "id": 1249,
        "no_speech_prob": 0.00006014133759890683,
        "seek": 562230,
        "start": 5630.38,
        "temperature": 0,
        "text": " I can put a whole string to evaluate a whole line of code to evaluate in essence inside that area",
        "tokens": [
          50768,
          286,
          393,
          829,
          257,
          1379,
          6798,
          281,
          13059,
          257,
          1379,
          1622,
          295,
          3089,
          281,
          13059,
          294,
          12801,
          1854,
          300,
          1859,
          51040
        ]
      },
      {
        "avg_logprob": -0.18662916819254557,
        "compression_ratio": 1.656,
        "end": 5637.900000000001,
        "id": 1250,
        "no_speech_prob": 0.00006014133759890683,
        "seek": 562230,
        "start": 5635.900000000001,
        "temperature": 0,
        "text": " Okay, so let's see if this works",
        "tokens": [
          51044,
          1033,
          11,
          370,
          718,
          311,
          536,
          498,
          341,
          1985,
          51144
        ]
      },
      {
        "avg_logprob": -0.18662916819254557,
        "compression_ratio": 1.656,
        "end": 5639.900000000001,
        "id": 1251,
        "no_speech_prob": 0.00006014133759890683,
        "seek": 562230,
        "start": 5637.900000000001,
        "temperature": 0,
        "text": " I don't know what's going to happen",
        "tokens": [
          51144,
          286,
          500,
          380,
          458,
          437,
          311,
          516,
          281,
          1051,
          51244
        ]
      },
      {
        "avg_logprob": -0.18662916819254557,
        "compression_ratio": 1.656,
        "end": 5646.9400000000005,
        "id": 1252,
        "no_speech_prob": 0.00006014133759890683,
        "seek": 562230,
        "start": 5640.54,
        "temperature": 0,
        "text": " Uh, let me see. Am I in the right place? No, I'm sorry. I made a new folder. Um, so i'm going to release these examples separately",
        "tokens": [
          51276,
          4019,
          11,
          718,
          385,
          536,
          13,
          2012,
          286,
          294,
          264,
          558,
          1081,
          30,
          883,
          11,
          286,
          478,
          2597,
          13,
          286,
          1027,
          257,
          777,
          10820,
          13,
          3301,
          11,
          370,
          741,
          478,
          516,
          281,
          4374,
          613,
          5110,
          14759,
          51596
        ]
      },
      {
        "avg_logprob": -0.18662916819254557,
        "compression_ratio": 1.656,
        "end": 5649.58,
        "id": 1253,
        "no_speech_prob": 0.00006014133759890683,
        "seek": 562230,
        "start": 5647.58,
        "temperature": 0,
        "text": " Uh, and i'm going to run this bot",
        "tokens": [
          51628,
          4019,
          11,
          293,
          741,
          478,
          516,
          281,
          1190,
          341,
          10592,
          51728
        ]
      },
      {
        "avg_logprob": -0.2219145478320723,
        "compression_ratio": 1.7269503546099292,
        "end": 5654.86,
        "id": 1254,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 564958,
        "start": 5650.54,
        "temperature": 0,
        "text": " And now okay, so I don't know if it's working because I don't know if i've gotten any notification",
        "tokens": [
          50412,
          400,
          586,
          1392,
          11,
          370,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          1364,
          570,
          286,
          500,
          380,
          458,
          498,
          741,
          600,
          5768,
          604,
          11554,
          50628
        ]
      },
      {
        "avg_logprob": -0.2219145478320723,
        "compression_ratio": 1.7269503546099292,
        "end": 5660.78,
        "id": 1255,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 564958,
        "start": 5654.94,
        "temperature": 0,
        "text": " Maybe somebody watching this live is going to favorite something or at mention my bot that would be nice, right?",
        "tokens": [
          50632,
          2704,
          2618,
          1976,
          341,
          1621,
          307,
          516,
          281,
          2954,
          746,
          420,
          412,
          2152,
          452,
          10592,
          300,
          576,
          312,
          1481,
          11,
          558,
          30,
          50924
        ]
      },
      {
        "avg_logprob": -0.2219145478320723,
        "compression_ratio": 1.7269503546099292,
        "end": 5663.0199999999995,
        "id": 1256,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 564958,
        "start": 5661.0199999999995,
        "temperature": 0,
        "text": " And then something would come in through here",
        "tokens": [
          50936,
          400,
          550,
          746,
          576,
          808,
          294,
          807,
          510,
          51036
        ]
      },
      {
        "avg_logprob": -0.2219145478320723,
        "compression_ratio": 1.7269503546099292,
        "end": 5667.92,
        "id": 1257,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 564958,
        "start": 5663.0199999999995,
        "temperature": 0,
        "text": " I kind of think that maybe there was actually a mistake in the mastodon api's documentation",
        "tokens": [
          51036,
          286,
          733,
          295,
          519,
          300,
          1310,
          456,
          390,
          767,
          257,
          6146,
          294,
          264,
          27055,
          378,
          266,
          1882,
          72,
          311,
          14333,
          51281
        ]
      },
      {
        "avg_logprob": -0.2219145478320723,
        "compression_ratio": 1.7269503546099292,
        "end": 5672.54,
        "id": 1258,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 564958,
        "start": 5668.7,
        "temperature": 0,
        "text": " Because I have a memory when I tried doing this earlier that the event was not message but",
        "tokens": [
          51320,
          1436,
          286,
          362,
          257,
          4675,
          562,
          286,
          3031,
          884,
          341,
          3071,
          300,
          264,
          2280,
          390,
          406,
          3636,
          457,
          51512
        ]
      },
      {
        "avg_logprob": -0.2219145478320723,
        "compression_ratio": 1.7269503546099292,
        "end": 5675.74,
        "id": 1259,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 564958,
        "start": 5673.74,
        "temperature": 0,
        "text": " msg short for message",
        "tokens": [
          51572,
          275,
          82,
          70,
          2099,
          337,
          3636,
          51672
        ]
      },
      {
        "avg_logprob": -0.2219145478320723,
        "compression_ratio": 1.7269503546099292,
        "end": 5679.26,
        "id": 1260,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 564958,
        "start": 5677.26,
        "temperature": 0,
        "text": " Let's be sure about this",
        "tokens": [
          51748,
          961,
          311,
          312,
          988,
          466,
          341,
          51848
        ]
      },
      {
        "avg_logprob": -0.24601512950855298,
        "compression_ratio": 1.577319587628866,
        "end": 5682.0599999999995,
        "id": 1261,
        "no_speech_prob": 0.00003944244235754013,
        "seek": 567958,
        "start": 5680.0599999999995,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50388,
          1105,
          50488
        ]
      },
      {
        "avg_logprob": -0.24601512950855298,
        "compression_ratio": 1.577319587628866,
        "end": 5688.0599999999995,
        "id": 1262,
        "no_speech_prob": 0.00003944244235754013,
        "seek": 567958,
        "start": 5682.3,
        "temperature": 0,
        "text": " Oh, oh wait, no, no, no. Okay. So look at this somebody did somebody did um",
        "tokens": [
          50500,
          876,
          11,
          1954,
          1699,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          1033,
          13,
          407,
          574,
          412,
          341,
          2618,
          630,
          2618,
          630,
          1105,
          50788
        ]
      },
      {
        "avg_logprob": -0.24601512950855298,
        "compression_ratio": 1.577319587628866,
        "end": 5694.22,
        "id": 1263,
        "no_speech_prob": 0.00003944244235754013,
        "seek": 567958,
        "start": 5689.82,
        "temperature": 0,
        "text": " So matthew let's that is correct so you can you can edit out my",
        "tokens": [
          50876,
          407,
          3803,
          392,
          1023,
          718,
          311,
          300,
          307,
          3006,
          370,
          291,
          393,
          291,
          393,
          8129,
          484,
          452,
          51096
        ]
      },
      {
        "avg_logprob": -0.24601512950855298,
        "compression_ratio": 1.577319587628866,
        "end": 5698.86,
        "id": 1264,
        "no_speech_prob": 0.00003944244235754013,
        "seek": 567958,
        "start": 5695.9,
        "temperature": 0,
        "text": " Go from when I was sitting there waiting to edit to now",
        "tokens": [
          51180,
          1037,
          490,
          562,
          286,
          390,
          3798,
          456,
          3806,
          281,
          8129,
          281,
          586,
          51328
        ]
      },
      {
        "avg_logprob": -0.24601512950855298,
        "compression_ratio": 1.577319587628866,
        "end": 5703.5199999999995,
        "id": 1265,
        "no_speech_prob": 0.00003944244235754013,
        "seek": 567958,
        "start": 5699.34,
        "temperature": 0,
        "text": " Oh, I did get a message from somebody but I made some sort of mistake",
        "tokens": [
          51352,
          876,
          11,
          286,
          630,
          483,
          257,
          3636,
          490,
          2618,
          457,
          286,
          1027,
          512,
          1333,
          295,
          6146,
          51561
        ]
      },
      {
        "avg_logprob": -0.24601512950855298,
        "compression_ratio": 1.577319587628866,
        "end": 5707.82,
        "id": 1266,
        "no_speech_prob": 0.00003944244235754013,
        "seek": 567958,
        "start": 5704.22,
        "temperature": 0,
        "text": " Data is not defined. Uh, okay because",
        "tokens": [
          51596,
          11888,
          307,
          406,
          7642,
          13,
          4019,
          11,
          1392,
          570,
          51776
        ]
      },
      {
        "avg_logprob": -0.22687910135509898,
        "compression_ratio": 1.5263157894736843,
        "end": 5715.099999999999,
        "id": 1267,
        "no_speech_prob": 0.000023552456696052104,
        "seek": 570782,
        "start": 5708.78,
        "temperature": 0,
        "text": " Uh, oh, yes, it's called the variable name is msg for message, um, which is why I was thinking that I guess",
        "tokens": [
          50412,
          4019,
          11,
          1954,
          11,
          2086,
          11,
          309,
          311,
          1219,
          264,
          7006,
          1315,
          307,
          275,
          82,
          70,
          337,
          3636,
          11,
          1105,
          11,
          597,
          307,
          983,
          286,
          390,
          1953,
          300,
          286,
          2041,
          50728
        ]
      },
      {
        "avg_logprob": -0.22687910135509898,
        "compression_ratio": 1.5263157894736843,
        "end": 5718.54,
        "id": 1268,
        "no_speech_prob": 0.000023552456696052104,
        "seek": 570782,
        "start": 5715.5,
        "temperature": 0,
        "text": " Um, so it should be msg here. Okay. Let's try this again",
        "tokens": [
          50748,
          3301,
          11,
          370,
          309,
          820,
          312,
          275,
          82,
          70,
          510,
          13,
          1033,
          13,
          961,
          311,
          853,
          341,
          797,
          50900
        ]
      },
      {
        "avg_logprob": -0.22687910135509898,
        "compression_ratio": 1.5263157894736843,
        "end": 5723.9,
        "id": 1269,
        "no_speech_prob": 0.000023552456696052104,
        "seek": 570782,
        "start": 5719.98,
        "temperature": 0,
        "text": " And actually i'm just going to take this out and i'm just going to write",
        "tokens": [
          50972,
          400,
          767,
          741,
          478,
          445,
          516,
          281,
          747,
          341,
          484,
          293,
          741,
          478,
          445,
          516,
          281,
          2464,
          51168
        ]
      },
      {
        "avg_logprob": -0.22687910135509898,
        "compression_ratio": 1.5263157894736843,
        "end": 5727.4,
        "id": 1270,
        "no_speech_prob": 0.000023552456696052104,
        "seek": 570782,
        "start": 5725.4,
        "temperature": 0,
        "text": " Console.log",
        "tokens": [
          51243,
          44152,
          13,
          4987,
          51343
        ]
      },
      {
        "avg_logprob": -0.22687910135509898,
        "compression_ratio": 1.5263157894736843,
        "end": 5732.86,
        "id": 1271,
        "no_speech_prob": 0.000023552456696052104,
        "seek": 570782,
        "start": 5727.82,
        "temperature": 0,
        "text": " User event. All right, everybody. Are you watching? Are you giving me some user events? Here we go",
        "tokens": [
          51364,
          32127,
          2280,
          13,
          1057,
          558,
          11,
          2201,
          13,
          2014,
          291,
          1976,
          30,
          2014,
          291,
          2902,
          385,
          512,
          4195,
          3931,
          30,
          1692,
          321,
          352,
          51616
        ]
      },
      {
        "avg_logprob": -0.4838702160379161,
        "compression_ratio": 1.0303030303030303,
        "end": 5734.86,
        "id": 1272,
        "no_speech_prob": 0.00002318726183148101,
        "seek": 573286,
        "start": 5732.86,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50364,
          407,
          50464
        ]
      },
      {
        "avg_logprob": -0.4838702160379161,
        "compression_ratio": 1.0303030303030303,
        "end": 5738.86,
        "id": 1273,
        "no_speech_prob": 0.00002318726183148101,
        "seek": 573286,
        "start": 5736.86,
        "temperature": 0,
        "text": " Waiting for my user events",
        "tokens": [
          50564,
          37291,
          337,
          452,
          4195,
          3931,
          50664
        ]
      },
      {
        "avg_logprob": -0.4838702160379161,
        "compression_ratio": 1.0303030303030303,
        "end": 5749.04,
        "id": 1274,
        "no_speech_prob": 0.00002318726183148101,
        "seek": 573286,
        "start": 5743.259999999999,
        "temperature": 0,
        "text": " Uh user events, let's get a bunch more",
        "tokens": [
          50884,
          4019,
          4195,
          3931,
          11,
          718,
          311,
          483,
          257,
          3840,
          544,
          51173
        ]
      },
      {
        "avg_logprob": -0.2395531762506544,
        "compression_ratio": 1.610091743119266,
        "end": 5765.42,
        "id": 1275,
        "no_speech_prob": 0.0016743746818974614,
        "seek": 576286,
        "start": 5763.42,
        "temperature": 0,
        "text": " Boop",
        "tokens": [
          50392,
          3286,
          404,
          50492
        ]
      },
      {
        "avg_logprob": -0.2395531762506544,
        "compression_ratio": 1.610091743119266,
        "end": 5768.94,
        "id": 1276,
        "no_speech_prob": 0.0016743746818974614,
        "seek": 576286,
        "start": 5768.0599999999995,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50624,
          1033,
          50668
        ]
      },
      {
        "avg_logprob": -0.2395531762506544,
        "compression_ratio": 1.610091743119266,
        "end": 5771.339999999999,
        "id": 1277,
        "no_speech_prob": 0.0016743746818974614,
        "seek": 576286,
        "start": 5768.94,
        "temperature": 0,
        "text": " I think that was enough user events. Thank you very much",
        "tokens": [
          50668,
          286,
          519,
          300,
          390,
          1547,
          4195,
          3931,
          13,
          1044,
          291,
          588,
          709,
          50788
        ]
      },
      {
        "avg_logprob": -0.2395531762506544,
        "compression_ratio": 1.610091743119266,
        "end": 5775.42,
        "id": 1278,
        "no_speech_prob": 0.0016743746818974614,
        "seek": 576286,
        "start": 5771.74,
        "temperature": 0,
        "text": " Let's go back and we can see here that I have all of these",
        "tokens": [
          50808,
          961,
          311,
          352,
          646,
          293,
          321,
          393,
          536,
          510,
          300,
          286,
          362,
          439,
          295,
          613,
          50992
        ]
      },
      {
        "avg_logprob": -0.2395531762506544,
        "compression_ratio": 1.610091743119266,
        "end": 5780.86,
        "id": 1279,
        "no_speech_prob": 0.0016743746818974614,
        "seek": 576286,
        "start": 5775.5,
        "temperature": 0,
        "text": " Uh data.json files for all of these events so I can kind of click through them and see what kind of events i'm hoping that",
        "tokens": [
          50996,
          4019,
          1412,
          13,
          73,
          3015,
          7098,
          337,
          439,
          295,
          613,
          3931,
          370,
          286,
          393,
          733,
          295,
          2052,
          807,
          552,
          293,
          536,
          437,
          733,
          295,
          3931,
          741,
          478,
          7159,
          300,
          51264
        ]
      },
      {
        "avg_logprob": -0.2395531762506544,
        "compression_ratio": 1.610091743119266,
        "end": 5785.98,
        "id": 1280,
        "no_speech_prob": 0.0016743746818974614,
        "seek": 576286,
        "start": 5781.42,
        "temperature": 0,
        "text": " The kind people of the internet are not spamming me with horribly thing horrible things",
        "tokens": [
          51292,
          440,
          733,
          561,
          295,
          264,
          4705,
          366,
          406,
          24028,
          2810,
          385,
          365,
          45028,
          551,
          9263,
          721,
          51520
        ]
      },
      {
        "avg_logprob": -0.2395531762506544,
        "compression_ratio": 1.610091743119266,
        "end": 5788.46,
        "id": 1281,
        "no_speech_prob": 0.0016743746818974614,
        "seek": 576286,
        "start": 5786.46,
        "temperature": 0,
        "text": " um, and oh, uh",
        "tokens": [
          51544,
          1105,
          11,
          293,
          1954,
          11,
          2232,
          51644
        ]
      },
      {
        "avg_logprob": -0.1607887019281802,
        "compression_ratio": 1.5450236966824644,
        "end": 5791.66,
        "id": 1282,
        "no_speech_prob": 0.0002611862146295607,
        "seek": 578846,
        "start": 5788.62,
        "temperature": 0,
        "text": " By the way, if you want don't want your information appearing up here",
        "tokens": [
          50372,
          3146,
          264,
          636,
          11,
          498,
          291,
          528,
          500,
          380,
          528,
          428,
          1589,
          19870,
          493,
          510,
          50524
        ]
      },
      {
        "avg_logprob": -0.1607887019281802,
        "compression_ratio": 1.5450236966824644,
        "end": 5796.22,
        "id": 1283,
        "no_speech_prob": 0.0002611862146295607,
        "seek": 578846,
        "start": 5791.74,
        "temperature": 0,
        "text": " Maybe don't but these are just people's mastodon accounts so we can see this was a follow event",
        "tokens": [
          50528,
          2704,
          500,
          380,
          457,
          613,
          366,
          445,
          561,
          311,
          27055,
          378,
          266,
          9402,
          370,
          321,
          393,
          536,
          341,
          390,
          257,
          1524,
          2280,
          50752
        ]
      },
      {
        "avg_logprob": -0.1607887019281802,
        "compression_ratio": 1.5450236966824644,
        "end": 5801.1,
        "id": 1284,
        "no_speech_prob": 0.0002611862146295607,
        "seek": 578846,
        "start": 5796.46,
        "temperature": 0,
        "text": " It's an event of notification. It's a type follow. Oh, so let's do this right now. Let's respond to that",
        "tokens": [
          50764,
          467,
          311,
          364,
          2280,
          295,
          11554,
          13,
          467,
          311,
          257,
          2010,
          1524,
          13,
          876,
          11,
          370,
          718,
          311,
          360,
          341,
          558,
          586,
          13,
          961,
          311,
          4196,
          281,
          300,
          50996
        ]
      },
      {
        "avg_logprob": -0.1607887019281802,
        "compression_ratio": 1.5450236966824644,
        "end": 5803.9,
        "id": 1285,
        "no_speech_prob": 0.0002611862146295607,
        "seek": 578846,
        "start": 5801.9,
        "temperature": 0,
        "text": " So what we're gonna do",
        "tokens": [
          51036,
          407,
          437,
          321,
          434,
          799,
          360,
          51136
        ]
      },
      {
        "avg_logprob": -0.1607887019281802,
        "compression_ratio": 1.5450236966824644,
        "end": 5806.14,
        "id": 1286,
        "no_speech_prob": 0.0002611862146295607,
        "seek": 578846,
        "start": 5804.14,
        "temperature": 0,
        "text": " Hold on a sec pause",
        "tokens": [
          51148,
          6962,
          322,
          257,
          907,
          10465,
          51248
        ]
      },
      {
        "avg_logprob": -0.1607887019281802,
        "compression_ratio": 1.5450236966824644,
        "end": 5809.02,
        "id": 1287,
        "no_speech_prob": 0.0002611862146295607,
        "seek": 578846,
        "start": 5807.02,
        "temperature": 0,
        "text": " Blow my nose",
        "tokens": [
          51292,
          46391,
          452,
          6690,
          51392
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5820.46,
        "id": 1288,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5818.46,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50364,
          407,
          50464
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5826.3,
        "id": 1289,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5824.54,
        "temperature": 0,
        "text": " So the first kind of event",
        "tokens": [
          50668,
          407,
          264,
          700,
          733,
          295,
          2280,
          50756
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5832.46,
        "id": 1290,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5826.3,
        "temperature": 0,
        "text": " We got here is a follow event. So if the event is a notification of type follow we could act on that",
        "tokens": [
          50756,
          492,
          658,
          510,
          307,
          257,
          1524,
          2280,
          13,
          407,
          498,
          264,
          2280,
          307,
          257,
          11554,
          295,
          2010,
          1524,
          321,
          727,
          605,
          322,
          300,
          51064
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5836.3,
        "id": 1291,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5832.46,
        "temperature": 0,
        "text": " So let's do that. Um, let's say let's go back to our code",
        "tokens": [
          51064,
          407,
          718,
          311,
          360,
          300,
          13,
          3301,
          11,
          718,
          311,
          584,
          718,
          311,
          352,
          646,
          281,
          527,
          3089,
          51256
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5839.18,
        "id": 1292,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5837.18,
        "temperature": 0,
        "text": " um, and i'm going to say",
        "tokens": [
          51300,
          1105,
          11,
          293,
          741,
          478,
          516,
          281,
          584,
          51400
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5842.14,
        "id": 1293,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5839.42,
        "temperature": 0,
        "text": " Uh right here. I'm going to not write these out anymore",
        "tokens": [
          51412,
          4019,
          558,
          510,
          13,
          286,
          478,
          516,
          281,
          406,
          2464,
          613,
          484,
          3602,
          51548
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5844.7,
        "id": 1294,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5842.7,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51576,
          1105,
          51676
        ]
      },
      {
        "avg_logprob": -0.2084665515206077,
        "compression_ratio": 1.5988372093023255,
        "end": 5846.94,
        "id": 1295,
        "no_speech_prob": 0.0000902800093172118,
        "seek": 581846,
        "start": 5844.94,
        "temperature": 0,
        "text": " If",
        "tokens": [
          51688,
          759,
          51788
        ]
      },
      {
        "avg_logprob": -0.3035026046465028,
        "compression_ratio": 1.5555555555555556,
        "end": 5853.26,
        "id": 1296,
        "no_speech_prob": 0.00009610168490326032,
        "seek": 584846,
        "start": 5848.46,
        "temperature": 0,
        "text": " If message dot what was it again message dot event",
        "tokens": [
          50364,
          759,
          3636,
          5893,
          437,
          390,
          309,
          797,
          3636,
          5893,
          2280,
          50604
        ]
      },
      {
        "avg_logprob": -0.3035026046465028,
        "compression_ratio": 1.5555555555555556,
        "end": 5857.52,
        "id": 1297,
        "no_speech_prob": 0.00009610168490326032,
        "seek": 584846,
        "start": 5855.32,
        "temperature": 0,
        "text": " Equals notification",
        "tokens": [
          50707,
          15624,
          1124,
          11554,
          50817
        ]
      },
      {
        "avg_logprob": -0.3035026046465028,
        "compression_ratio": 1.5555555555555556,
        "end": 5864.72,
        "id": 1298,
        "no_speech_prob": 0.00009610168490326032,
        "seek": 584846,
        "start": 5859.9800000000005,
        "temperature": 0,
        "text": " And I think there's going to be different kinds of notifications so i'm going to say then if message",
        "tokens": [
          50940,
          400,
          286,
          519,
          456,
          311,
          516,
          281,
          312,
          819,
          3685,
          295,
          13426,
          370,
          741,
          478,
          516,
          281,
          584,
          550,
          498,
          3636,
          51177
        ]
      },
      {
        "avg_logprob": -0.3035026046465028,
        "compression_ratio": 1.5555555555555556,
        "end": 5867.66,
        "id": 1299,
        "no_speech_prob": 0.00009610168490326032,
        "seek": 584846,
        "start": 5865.74,
        "temperature": 0,
        "text": " dot",
        "tokens": [
          51228,
          5893,
          51324
        ]
      },
      {
        "avg_logprob": -0.3035026046465028,
        "compression_ratio": 1.5555555555555556,
        "end": 5869.66,
        "id": 1300,
        "no_speech_prob": 0.00009610168490326032,
        "seek": 584846,
        "start": 5867.66,
        "temperature": 0,
        "text": " data dot type",
        "tokens": [
          51324,
          1412,
          5893,
          2010,
          51424
        ]
      },
      {
        "avg_logprob": -0.3035026046465028,
        "compression_ratio": 1.5555555555555556,
        "end": 5874.22,
        "id": 1301,
        "no_speech_prob": 0.00009610168490326032,
        "seek": 584846,
        "start": 5872.46,
        "temperature": 0,
        "text": " Follow",
        "tokens": [
          51564,
          9876,
          51652
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5879.5,
        "id": 1302,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5874.22,
        "temperature": 0,
        "text": " Then what I want to do is, uh, I want to get the username so let me get the user",
        "tokens": [
          50364,
          1396,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          2232,
          11,
          286,
          528,
          281,
          483,
          264,
          30351,
          370,
          718,
          385,
          483,
          264,
          4195,
          50628
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5882.06,
        "id": 1303,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5880.46,
        "temperature": 0,
        "text": " name",
        "tokens": [
          50676,
          1315,
          50756
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5883.9800000000005,
        "id": 1304,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5882.06,
        "temperature": 0,
        "text": " and that would be",
        "tokens": [
          50756,
          293,
          300,
          576,
          312,
          50852
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5888.780000000001,
        "id": 1305,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5883.9800000000005,
        "temperature": 0,
        "text": " Where it would be right there and actually I want the account the username is useful",
        "tokens": [
          50852,
          2305,
          309,
          576,
          312,
          558,
          456,
          293,
          767,
          286,
          528,
          264,
          2696,
          264,
          30351,
          307,
          4420,
          51092
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5894.62,
        "id": 1306,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5888.780000000001,
        "temperature": 0,
        "text": " But you always on mastodon need both the username and the instance the address of the instance the host name",
        "tokens": [
          51092,
          583,
          291,
          1009,
          322,
          27055,
          378,
          266,
          643,
          1293,
          264,
          30351,
          293,
          264,
          5197,
          264,
          2985,
          295,
          264,
          5197,
          264,
          3975,
          1315,
          51384
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5897.1,
        "id": 1307,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5895.1,
        "temperature": 0,
        "text": " So let me grab",
        "tokens": [
          51408,
          407,
          718,
          385,
          4444,
          51508
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5900.12,
        "id": 1308,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5898.12,
        "temperature": 0,
        "text": " account equals",
        "tokens": [
          51559,
          2696,
          6915,
          51659
        ]
      },
      {
        "avg_logprob": -0.2840127944946289,
        "compression_ratio": 1.934782608695652,
        "end": 5902.46,
        "id": 1309,
        "no_speech_prob": 0.00006108820525696501,
        "seek": 587422,
        "start": 5900.12,
        "temperature": 0,
        "text": " message dot data dot account",
        "tokens": [
          51659,
          3636,
          5893,
          1412,
          5893,
          2696,
          51776
        ]
      },
      {
        "avg_logprob": -0.2616737622481126,
        "compression_ratio": 1.9504950495049505,
        "end": 5907.02,
        "id": 1310,
        "no_speech_prob": 0.0005274742725305259,
        "seek": 590246,
        "start": 5903.18,
        "temperature": 0,
        "text": " And then the other thing that I'm pretty sure that I need is the id maybe",
        "tokens": [
          50400,
          400,
          550,
          264,
          661,
          551,
          300,
          286,
          478,
          1238,
          988,
          300,
          286,
          643,
          307,
          264,
          4496,
          1310,
          50592
        ]
      },
      {
        "avg_logprob": -0.2616737622481126,
        "compression_ratio": 1.9504950495049505,
        "end": 5913.1,
        "id": 1311,
        "no_speech_prob": 0.0005274742725305259,
        "seek": 590246,
        "start": 5907.72,
        "temperature": 0,
        "text": " 7670 that's the account id. This is the I don't know what this is the idea of the event, I guess",
        "tokens": [
          50627,
          24733,
          5867,
          300,
          311,
          264,
          2696,
          4496,
          13,
          639,
          307,
          264,
          286,
          500,
          380,
          458,
          437,
          341,
          307,
          264,
          1558,
          295,
          264,
          2280,
          11,
          286,
          2041,
          50896
        ]
      },
      {
        "avg_logprob": -0.2616737622481126,
        "compression_ratio": 1.9504950495049505,
        "end": 5918.86,
        "id": 1312,
        "no_speech_prob": 0.0005274742725305259,
        "seek": 590246,
        "start": 5913.26,
        "temperature": 0,
        "text": " So I want that account id so i'm going to say constant id equals message dot data dot id",
        "tokens": [
          50904,
          407,
          286,
          528,
          300,
          2696,
          4496,
          370,
          741,
          478,
          516,
          281,
          584,
          5754,
          4496,
          6915,
          3636,
          5893,
          1412,
          5893,
          4496,
          51184
        ]
      },
      {
        "avg_logprob": -0.2616737622481126,
        "compression_ratio": 1.9504950495049505,
        "end": 5925.1,
        "id": 1313,
        "no_speech_prob": 0.0005274742725305259,
        "seek": 590246,
        "start": 5920.62,
        "temperature": 0,
        "text": " Oh dot account I forgot about account i'm also message dot data dot account dot id",
        "tokens": [
          51272,
          876,
          5893,
          2696,
          286,
          5298,
          466,
          2696,
          741,
          478,
          611,
          3636,
          5893,
          1412,
          5893,
          2696,
          5893,
          4496,
          51496
        ]
      },
      {
        "avg_logprob": -0.2616737622481126,
        "compression_ratio": 1.9504950495049505,
        "end": 5928.7,
        "id": 1314,
        "no_speech_prob": 0.0005274742725305259,
        "seek": 590246,
        "start": 5926.06,
        "temperature": 0,
        "text": " dot account dot account and then dot",
        "tokens": [
          51544,
          5893,
          2696,
          5893,
          2696,
          293,
          550,
          5893,
          51676
        ]
      },
      {
        "avg_logprob": -0.2616737622481126,
        "compression_ratio": 1.9504950495049505,
        "end": 5931.66,
        "id": 1315,
        "no_speech_prob": 0.0005274742725305259,
        "seek": 590246,
        "start": 5929.66,
        "temperature": 0,
        "text": " account dot id",
        "tokens": [
          51724,
          2696,
          5893,
          4496,
          51824
        ]
      },
      {
        "avg_logprob": -0.2099017916985278,
        "compression_ratio": 1.6363636363636365,
        "end": 5938.46,
        "id": 1316,
        "no_speech_prob": 0.000007411253591271816,
        "seek": 593166,
        "start": 5931.82,
        "temperature": 0,
        "text": " And then I want to send a message. So how do I do that? Just with this nice m dot post",
        "tokens": [
          50372,
          400,
          550,
          286,
          528,
          281,
          2845,
          257,
          3636,
          13,
          407,
          577,
          360,
          286,
          360,
          300,
          30,
          1449,
          365,
          341,
          1481,
          275,
          5893,
          2183,
          50704
        ]
      },
      {
        "avg_logprob": -0.2099017916985278,
        "compression_ratio": 1.6363636363636365,
        "end": 5941.5,
        "id": 1317,
        "no_speech_prob": 0.000007411253591271816,
        "seek": 593166,
        "start": 5938.78,
        "temperature": 0,
        "text": " So here's the thing. Maybe I want to make this",
        "tokens": [
          50720,
          407,
          510,
          311,
          264,
          551,
          13,
          2704,
          286,
          528,
          281,
          652,
          341,
          50856
        ]
      },
      {
        "avg_logprob": -0.2099017916985278,
        "compression_ratio": 1.6363636363636365,
        "end": 5946.7,
        "id": 1318,
        "no_speech_prob": 0.000007411253591271816,
        "seek": 593166,
        "start": 5942.3,
        "temperature": 0,
        "text": " Quote unquote two to function a bit more generic and i'm just going to give it a",
        "tokens": [
          50896,
          2326,
          1370,
          37557,
          732,
          281,
          2445,
          257,
          857,
          544,
          19577,
          293,
          741,
          478,
          445,
          516,
          281,
          976,
          309,
          257,
          51116
        ]
      },
      {
        "avg_logprob": -0.2099017916985278,
        "compression_ratio": 1.6363636363636365,
        "end": 5949.82,
        "id": 1319,
        "no_speech_prob": 0.000007411253591271816,
        "seek": 593166,
        "start": 5947.82,
        "temperature": 0,
        "text": " I'm going to pass in a status",
        "tokens": [
          51172,
          286,
          478,
          516,
          281,
          1320,
          294,
          257,
          6558,
          51272
        ]
      },
      {
        "avg_logprob": -0.2099017916985278,
        "compression_ratio": 1.6363636363636365,
        "end": 5953.42,
        "id": 1320,
        "no_speech_prob": 0.000007411253591271816,
        "seek": 593166,
        "start": 5950.78,
        "temperature": 0,
        "text": " So i'm going to get rid of the random number stuff, which was from before",
        "tokens": [
          51320,
          407,
          741,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          4974,
          1230,
          1507,
          11,
          597,
          390,
          490,
          949,
          51452
        ]
      },
      {
        "avg_logprob": -0.2099017916985278,
        "compression_ratio": 1.6363636363636365,
        "end": 5957.66,
        "id": 1321,
        "no_speech_prob": 0.000007411253591271816,
        "seek": 593166,
        "start": 5953.98,
        "temperature": 0,
        "text": " and then um, i'm i'm going to just put uh",
        "tokens": [
          51480,
          293,
          550,
          1105,
          11,
          741,
          478,
          741,
          478,
          516,
          281,
          445,
          829,
          2232,
          51664
        ]
      },
      {
        "avg_logprob": -0.4463317099581943,
        "compression_ratio": 1.675257731958763,
        "end": 5963.9,
        "id": 1322,
        "no_speech_prob": 0.00024536592536605895,
        "seek": 595766,
        "start": 5957.66,
        "temperature": 0,
        "text": " This is a little confusing but i'm going to take whatever I pass in and then uh, and then here is uh,",
        "tokens": [
          50364,
          639,
          307,
          257,
          707,
          13181,
          457,
          741,
          478,
          516,
          281,
          747,
          2035,
          286,
          1320,
          294,
          293,
          550,
          2232,
          11,
          293,
          550,
          510,
          307,
          2232,
          11,
          50676
        ]
      },
      {
        "avg_logprob": -0.4463317099581943,
        "compression_ratio": 1.675257731958763,
        "end": 5967.98,
        "id": 1323,
        "no_speech_prob": 0.00024536592536605895,
        "seek": 595766,
        "start": 5963.98,
        "temperature": 0,
        "text": " And then i'm going to post that so now I have a function that I can basically say",
        "tokens": [
          50680,
          400,
          550,
          741,
          478,
          516,
          281,
          2183,
          300,
          370,
          586,
          286,
          362,
          257,
          2445,
          300,
          286,
          393,
          1936,
          584,
          50880
        ]
      },
      {
        "avg_logprob": -0.4463317099581943,
        "compression_ratio": 1.675257731958763,
        "end": 5971.099999999999,
        "id": 1324,
        "no_speech_prob": 0.00024536592536605895,
        "seek": 595766,
        "start": 5969.099999999999,
        "temperature": 0,
        "text": " toot",
        "tokens": [
          50936,
          281,
          310,
          51036
        ]
      },
      {
        "avg_logprob": -0.4463317099581943,
        "compression_ratio": 1.675257731958763,
        "end": 5975.98,
        "id": 1325,
        "no_speech_prob": 0.00024536592536605895,
        "seek": 595766,
        "start": 5972.22,
        "temperature": 0,
        "text": " And I can say, uh, i'm going to use at",
        "tokens": [
          51092,
          400,
          286,
          393,
          584,
          11,
          2232,
          11,
          741,
          478,
          516,
          281,
          764,
          412,
          51280
        ]
      },
      {
        "avg_logprob": -0.4463317099581943,
        "compression_ratio": 1.675257731958763,
        "end": 5985.0199999999995,
        "id": 1326,
        "no_speech_prob": 0.00024536592536605895,
        "seek": 595766,
        "start": 5978.78,
        "temperature": 0,
        "text": " Data dot message dot data dot account right at this is me referencing the person that followed me",
        "tokens": [
          51420,
          11888,
          5893,
          3636,
          5893,
          1412,
          5893,
          2696,
          558,
          412,
          341,
          307,
          385,
          40582,
          264,
          954,
          300,
          6263,
          385,
          51732
        ]
      },
      {
        "avg_logprob": -0.3882823035830543,
        "compression_ratio": 1.6930232558139535,
        "end": 5990.9400000000005,
        "id": 1327,
        "no_speech_prob": 0.0007208290044218302,
        "seek": 598502,
        "start": 5985.1,
        "temperature": 0,
        "text": " Uh, you know, thank you for the follow and I should be i'll just say choo choo welcome aboard",
        "tokens": [
          50368,
          4019,
          11,
          291,
          458,
          11,
          1309,
          291,
          337,
          264,
          1524,
          293,
          286,
          820,
          312,
          741,
          603,
          445,
          584,
          1586,
          78,
          1586,
          78,
          2928,
          27488,
          50660
        ]
      },
      {
        "avg_logprob": -0.3882823035830543,
        "compression_ratio": 1.6930232558139535,
        "end": 5993.1,
        "id": 1328,
        "no_speech_prob": 0.0007208290044218302,
        "seek": 598502,
        "start": 5991.1,
        "temperature": 0,
        "text": " Oh, that's a train theme. Welcome aboard",
        "tokens": [
          50668,
          876,
          11,
          300,
          311,
          257,
          3847,
          6314,
          13,
          4027,
          27488,
          50768
        ]
      },
      {
        "avg_logprob": -0.3882823035830543,
        "compression_ratio": 1.6930232558139535,
        "end": 5997.18,
        "id": 1329,
        "no_speech_prob": 0.0007208290044218302,
        "seek": 598502,
        "start": 5994.46,
        "temperature": 0,
        "text": " Okay, so we can see it'll say welcome aboard now. Here's the thing",
        "tokens": [
          50836,
          1033,
          11,
          370,
          321,
          393,
          536,
          309,
          603,
          584,
          2928,
          27488,
          586,
          13,
          1692,
          311,
          264,
          551,
          50972
        ]
      },
      {
        "avg_logprob": -0.3882823035830543,
        "compression_ratio": 1.6930232558139535,
        "end": 6002.860000000001,
        "id": 1330,
        "no_speech_prob": 0.0007208290044218302,
        "seek": 598502,
        "start": 5999.740000000001,
        "temperature": 0,
        "text": " I really should also if I go back to the api",
        "tokens": [
          51100,
          286,
          534,
          820,
          611,
          498,
          286,
          352,
          646,
          281,
          264,
          1882,
          72,
          51256
        ]
      },
      {
        "avg_logprob": -0.3882823035830543,
        "compression_ratio": 1.6930232558139535,
        "end": 6005.42,
        "id": 1331,
        "no_speech_prob": 0.0007208290044218302,
        "seek": 598502,
        "start": 6004.14,
        "temperature": 0,
        "text": " This one",
        "tokens": [
          51320,
          639,
          472,
          51384
        ]
      },
      {
        "avg_logprob": -0.3882823035830543,
        "compression_ratio": 1.6930232558139535,
        "end": 6011.660000000001,
        "id": 1332,
        "no_speech_prob": 0.0007208290044218302,
        "seek": 598502,
        "start": 6005.42,
        "temperature": 0,
        "text": " I should probably say in reply and that's a reply to this stuff because I don't need it's not in reply to me",
        "tokens": [
          51384,
          286,
          820,
          1391,
          584,
          294,
          16972,
          293,
          300,
          311,
          257,
          16972,
          281,
          341,
          1507,
          570,
          286,
          500,
          380,
          643,
          309,
          311,
          406,
          294,
          16972,
          281,
          385,
          51696
        ]
      },
      {
        "avg_logprob": -0.4089881633890086,
        "compression_ratio": 1.7033898305084745,
        "end": 6014.86,
        "id": 1333,
        "no_speech_prob": 0.003429562086239457,
        "seek": 601166,
        "start": 6011.66,
        "temperature": 0,
        "text": " So this is actually fine. I think as long as I just add mention then i'm done",
        "tokens": [
          50364,
          407,
          341,
          307,
          767,
          2489,
          13,
          286,
          519,
          382,
          938,
          382,
          286,
          445,
          909,
          2152,
          550,
          741,
          478,
          1096,
          50524
        ]
      },
      {
        "avg_logprob": -0.4089881633890086,
        "compression_ratio": 1.7033898305084745,
        "end": 6020.54,
        "id": 1334,
        "no_speech_prob": 0.003429562086239457,
        "seek": 601166,
        "start": 6015.42,
        "temperature": 0,
        "text": " So, um, so let me go. I've lost my code. Let me go. I think i'm good. So now",
        "tokens": [
          50552,
          407,
          11,
          1105,
          11,
          370,
          718,
          385,
          352,
          13,
          286,
          600,
          2731,
          452,
          3089,
          13,
          961,
          385,
          352,
          13,
          286,
          519,
          741,
          478,
          665,
          13,
          407,
          586,
          50808
        ]
      },
      {
        "avg_logprob": -0.4089881633890086,
        "compression_ratio": 1.7033898305084745,
        "end": 6024.94,
        "id": 1335,
        "no_speech_prob": 0.003429562086239457,
        "seek": 601166,
        "start": 6022.0599999999995,
        "temperature": 0,
        "text": " I think that I have everything I want. So I am",
        "tokens": [
          50884,
          286,
          519,
          300,
          286,
          362,
          1203,
          286,
          528,
          13,
          407,
          286,
          669,
          51028
        ]
      },
      {
        "avg_logprob": -0.4089881633890086,
        "compression_ratio": 1.7033898305084745,
        "end": 6028.139999999999,
        "id": 1336,
        "no_speech_prob": 0.003429562086239457,
        "seek": 601166,
        "start": 6025.98,
        "temperature": 0,
        "text": " Let me just put the listen on error up here",
        "tokens": [
          51080,
          961,
          385,
          445,
          829,
          264,
          2140,
          322,
          6713,
          493,
          510,
          51188
        ]
      },
      {
        "avg_logprob": -0.4089881633890086,
        "compression_ratio": 1.7033898305084745,
        "end": 6033.74,
        "id": 1337,
        "no_speech_prob": 0.003429562086239457,
        "seek": 601166,
        "start": 6028.46,
        "temperature": 0,
        "text": " So i'm listening for a message if the message is a notification of a follow then I will",
        "tokens": [
          51204,
          407,
          741,
          478,
          4764,
          337,
          257,
          3636,
          498,
          264,
          3636,
          307,
          257,
          11554,
          295,
          257,
          1524,
          550,
          286,
          486,
          51468
        ]
      },
      {
        "avg_logprob": -0.4089881633890086,
        "compression_ratio": 1.7033898305084745,
        "end": 6038.38,
        "id": 1338,
        "no_speech_prob": 0.003429562086239457,
        "seek": 601166,
        "start": 6034.38,
        "temperature": 0,
        "text": " Toot back to the person their their account name and then I will say",
        "tokens": [
          51500,
          1407,
          310,
          646,
          281,
          264,
          954,
          641,
          641,
          2696,
          1315,
          293,
          550,
          286,
          486,
          584,
          51700
        ]
      },
      {
        "avg_logprob": -0.21084082422177652,
        "compression_ratio": 1.7030075187969924,
        "end": 6044.38,
        "id": 1339,
        "no_speech_prob": 0.00030061404686421156,
        "seek": 603838,
        "start": 6038.54,
        "temperature": 0,
        "text": " Uh toot back to the person their their account name and say welcome aboard and let's see how this goes",
        "tokens": [
          50372,
          4019,
          281,
          310,
          646,
          281,
          264,
          954,
          641,
          641,
          2696,
          1315,
          293,
          584,
          2928,
          27488,
          293,
          718,
          311,
          536,
          577,
          341,
          1709,
          50664
        ]
      },
      {
        "avg_logprob": -0.21084082422177652,
        "compression_ratio": 1.7030075187969924,
        "end": 6048.06,
        "id": 1340,
        "no_speech_prob": 0.00030061404686421156,
        "seek": 603838,
        "start": 6045.82,
        "temperature": 0,
        "text": " All right, look forward to all of you now",
        "tokens": [
          50736,
          1057,
          558,
          11,
          574,
          2128,
          281,
          439,
          295,
          291,
          586,
          50848
        ]
      },
      {
        "avg_logprob": -0.21084082422177652,
        "compression_ratio": 1.7030075187969924,
        "end": 6051.9800000000005,
        "id": 1341,
        "no_speech_prob": 0.00030061404686421156,
        "seek": 603838,
        "start": 6048.7,
        "temperature": 0,
        "text": " You can unfollow and follow if you already followed, but let me run it first",
        "tokens": [
          50880,
          509,
          393,
          3971,
          49082,
          293,
          1524,
          498,
          291,
          1217,
          6263,
          11,
          457,
          718,
          385,
          1190,
          309,
          700,
          51044
        ]
      },
      {
        "avg_logprob": -0.21084082422177652,
        "compression_ratio": 1.7030075187969924,
        "end": 6054.14,
        "id": 1342,
        "no_speech_prob": 0.00030061404686421156,
        "seek": 603838,
        "start": 6052.54,
        "temperature": 0,
        "text": " And here we go",
        "tokens": [
          51072,
          400,
          510,
          321,
          352,
          51152
        ]
      },
      {
        "avg_logprob": -0.21084082422177652,
        "compression_ratio": 1.7030075187969924,
        "end": 6057.82,
        "id": 1343,
        "no_speech_prob": 0.00030061404686421156,
        "seek": 603838,
        "start": 6054.14,
        "temperature": 0,
        "text": " Oh, okay. I have a status status. I have a mistake here",
        "tokens": [
          51152,
          876,
          11,
          1392,
          13,
          286,
          362,
          257,
          6558,
          6558,
          13,
          286,
          362,
          257,
          6146,
          510,
          51336
        ]
      },
      {
        "avg_logprob": -0.21084082422177652,
        "compression_ratio": 1.7030075187969924,
        "end": 6062.16,
        "id": 1344,
        "no_speech_prob": 0.00030061404686421156,
        "seek": 603838,
        "start": 6058.46,
        "temperature": 0,
        "text": " So I don't I I i'm not just going to change this variable name to like txt",
        "tokens": [
          51368,
          407,
          286,
          500,
          380,
          286,
          286,
          741,
          478,
          406,
          445,
          516,
          281,
          1319,
          341,
          7006,
          1315,
          281,
          411,
          256,
          734,
          51553
        ]
      },
      {
        "avg_logprob": -0.21084082422177652,
        "compression_ratio": 1.7030075187969924,
        "end": 6066.9400000000005,
        "id": 1345,
        "no_speech_prob": 0.00030061404686421156,
        "seek": 603838,
        "start": 6062.86,
        "temperature": 0,
        "text": " Or content let me make a content because I don't like having the same name everywhere",
        "tokens": [
          51588,
          1610,
          2701,
          718,
          385,
          652,
          257,
          2701,
          570,
          286,
          500,
          380,
          411,
          1419,
          264,
          912,
          1315,
          5315,
          51792
        ]
      },
      {
        "avg_logprob": -0.2785914021153604,
        "compression_ratio": 1.3406593406593406,
        "end": 6070.799999999999,
        "id": 1346,
        "no_speech_prob": 0.000022474065190181136,
        "seek": 606694,
        "start": 6067.259999999999,
        "temperature": 0,
        "text": " It's confusing but there should be no semicolon after there. Okay, here we go",
        "tokens": [
          50380,
          467,
          311,
          13181,
          457,
          456,
          820,
          312,
          572,
          27515,
          38780,
          934,
          456,
          13,
          1033,
          11,
          510,
          321,
          352,
          50557
        ]
      },
      {
        "avg_logprob": -0.2785914021153604,
        "compression_ratio": 1.3406593406593406,
        "end": 6083.74,
        "id": 1347,
        "no_speech_prob": 0.000022474065190181136,
        "seek": 606694,
        "start": 6081.74,
        "temperature": 0,
        "text": " Welcome aboard",
        "tokens": [
          51104,
          4027,
          27488,
          51204
        ]
      },
      {
        "avg_logprob": -0.2785914021153604,
        "compression_ratio": 1.3406593406593406,
        "end": 6090,
        "id": 1348,
        "no_speech_prob": 0.000022474065190181136,
        "seek": 606694,
        "start": 6085.98,
        "temperature": 0,
        "text": " Welcome aboard welcome aboard",
        "tokens": [
          51316,
          4027,
          27488,
          2928,
          27488,
          51517
        ]
      },
      {
        "avg_logprob": -0.2246402136170038,
        "compression_ratio": 1.6150234741784038,
        "end": 6102.7,
        "id": 1349,
        "no_speech_prob": 0.00004469387567951344,
        "seek": 609694,
        "start": 6097.5,
        "temperature": 0.2,
        "text": " Okay, so you can see a bunch came in and now I can go back here",
        "tokens": [
          50392,
          1033,
          11,
          370,
          291,
          393,
          536,
          257,
          3840,
          1361,
          294,
          293,
          586,
          286,
          393,
          352,
          646,
          510,
          50652
        ]
      },
      {
        "avg_logprob": -0.2246402136170038,
        "compression_ratio": 1.6150234741784038,
        "end": 6106.7,
        "id": 1350,
        "no_speech_prob": 0.00004469387567951344,
        "seek": 609694,
        "start": 6103.339999999999,
        "temperature": 0.2,
        "text": " And I can go to here and we can see look at this",
        "tokens": [
          50684,
          400,
          286,
          393,
          352,
          281,
          510,
          293,
          321,
          393,
          536,
          574,
          412,
          341,
          50852
        ]
      },
      {
        "avg_logprob": -0.2246402136170038,
        "compression_ratio": 1.6150234741784038,
        "end": 6113.099999999999,
        "id": 1351,
        "no_speech_prob": 0.00004469387567951344,
        "seek": 609694,
        "start": 6106.78,
        "temperature": 0.2,
        "text": " These are all the people who have now and if I click there we can see where it's it's showing me and going to these",
        "tokens": [
          50856,
          1981,
          366,
          439,
          264,
          561,
          567,
          362,
          586,
          293,
          498,
          286,
          2052,
          456,
          321,
          393,
          536,
          689,
          309,
          311,
          309,
          311,
          4099,
          385,
          293,
          516,
          281,
          613,
          51172
        ]
      },
      {
        "avg_logprob": -0.2246402136170038,
        "compression_ratio": 1.6150234741784038,
        "end": 6115.099999999999,
        "id": 1352,
        "no_speech_prob": 0.00004469387567951344,
        "seek": 609694,
        "start": 6113.099999999999,
        "temperature": 0.2,
        "text": " People's accounts. Yay",
        "tokens": [
          51172,
          3432,
          311,
          9402,
          13,
          13268,
          51272
        ]
      },
      {
        "avg_logprob": -0.2246402136170038,
        "compression_ratio": 1.6150234741784038,
        "end": 6118.62,
        "id": 1353,
        "no_speech_prob": 0.00004469387567951344,
        "seek": 609694,
        "start": 6115.5,
        "temperature": 0.2,
        "text": " So we now have a bot that responds to follows",
        "tokens": [
          51292,
          407,
          321,
          586,
          362,
          257,
          10592,
          300,
          27331,
          281,
          10002,
          51448
        ]
      },
      {
        "avg_logprob": -0.2246402136170038,
        "compression_ratio": 1.6150234741784038,
        "end": 6121.9,
        "id": 1354,
        "no_speech_prob": 0.00004469387567951344,
        "seek": 609694,
        "start": 6119.9,
        "temperature": 0.2,
        "text": " Pause for a second",
        "tokens": [
          51512,
          31973,
          337,
          257,
          1150,
          51612
        ]
      },
      {
        "avg_logprob": -0.2246402136170038,
        "compression_ratio": 1.6150234741784038,
        "end": 6126.219999999999,
        "id": 1355,
        "no_speech_prob": 0.00004469387567951344,
        "seek": 609694,
        "start": 6123.9,
        "temperature": 0.2,
        "text": " Oh, right i'm such a doofus",
        "tokens": [
          51712,
          876,
          11,
          558,
          741,
          478,
          1270,
          257,
          360,
          2670,
          301,
          51828
        ]
      },
      {
        "avg_logprob": -0.2723013909308465,
        "compression_ratio": 1.5145631067961165,
        "end": 6129.9,
        "id": 1356,
        "no_speech_prob": 0.00033533910755068064,
        "seek": 612694,
        "start": 6127.9,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50412,
          286,
          50512
        ]
      },
      {
        "avg_logprob": -0.2723013909308465,
        "compression_ratio": 1.5145631067961165,
        "end": 6132.78,
        "id": 1357,
        "no_speech_prob": 0.00033533910755068064,
        "seek": 612694,
        "start": 6130.46,
        "temperature": 0,
        "text": " Almost said my nose is running allergies, I think",
        "tokens": [
          50540,
          12627,
          848,
          452,
          6690,
          307,
          2614,
          37007,
          11,
          286,
          519,
          50656
        ]
      },
      {
        "avg_logprob": -0.2723013909308465,
        "compression_ratio": 1.5145631067961165,
        "end": 6141.339999999999,
        "id": 1358,
        "no_speech_prob": 0.00033533910755068064,
        "seek": 612694,
        "start": 6139.5,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50992,
          1033,
          51084
        ]
      },
      {
        "avg_logprob": -0.2723013909308465,
        "compression_ratio": 1.5145631067961165,
        "end": 6143.0199999999995,
        "id": 1359,
        "no_speech_prob": 0.00033533910755068064,
        "seek": 612694,
        "start": 6141.339999999999,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51084,
          1105,
          51168
        ]
      },
      {
        "avg_logprob": -0.2723013909308465,
        "compression_ratio": 1.5145631067961165,
        "end": 6145.9,
        "id": 1360,
        "no_speech_prob": 0.00033533910755068064,
        "seek": 612694,
        "start": 6143.0199999999995,
        "temperature": 0,
        "text": " Alka from the chat pointed out something here. What did I do?",
        "tokens": [
          51168,
          967,
          2330,
          490,
          264,
          5081,
          10932,
          484,
          746,
          510,
          13,
          708,
          630,
          286,
          360,
          30,
          51312
        ]
      },
      {
        "avg_logprob": -0.2723013909308465,
        "compression_ratio": 1.5145631067961165,
        "end": 6150.78,
        "id": 1361,
        "no_speech_prob": 0.00033533910755068064,
        "seek": 612694,
        "start": 6145.98,
        "temperature": 0,
        "text": " Oh the whole point of me making this variable was so that I don't have to write this all out here",
        "tokens": [
          51316,
          876,
          264,
          1379,
          935,
          295,
          385,
          1455,
          341,
          7006,
          390,
          370,
          300,
          286,
          500,
          380,
          362,
          281,
          2464,
          341,
          439,
          484,
          510,
          51556
        ]
      },
      {
        "avg_logprob": -0.2723013909308465,
        "compression_ratio": 1.5145631067961165,
        "end": 6155.259999999999,
        "id": 1362,
        "no_speech_prob": 0.00033533910755068064,
        "seek": 612694,
        "start": 6150.78,
        "temperature": 0,
        "text": " I don't know why I did that so, um, I can just do this. This will make it much more readable",
        "tokens": [
          51556,
          286,
          500,
          380,
          458,
          983,
          286,
          630,
          300,
          370,
          11,
          1105,
          11,
          286,
          393,
          445,
          360,
          341,
          13,
          639,
          486,
          652,
          309,
          709,
          544,
          49857,
          51780
        ]
      },
      {
        "avg_logprob": -0.22052011411052105,
        "compression_ratio": 1.8403361344537814,
        "end": 6159.34,
        "id": 1363,
        "no_speech_prob": 0.0008558888221159577,
        "seek": 615526,
        "start": 6155.26,
        "temperature": 0,
        "text": " And actually don't need the id so I can take that out. So this is all I need. So we are done",
        "tokens": [
          50364,
          400,
          767,
          500,
          380,
          643,
          264,
          4496,
          370,
          286,
          393,
          747,
          300,
          484,
          13,
          407,
          341,
          307,
          439,
          286,
          643,
          13,
          407,
          321,
          366,
          1096,
          50568
        ]
      },
      {
        "avg_logprob": -0.22052011411052105,
        "compression_ratio": 1.8403361344537814,
        "end": 6161.9800000000005,
        "id": 1364,
        "no_speech_prob": 0.0008558888221159577,
        "seek": 615526,
        "start": 6159.42,
        "temperature": 0,
        "text": " All right. So this is follow now",
        "tokens": [
          50572,
          1057,
          558,
          13,
          407,
          341,
          307,
          1524,
          586,
          50700
        ]
      },
      {
        "avg_logprob": -0.22052011411052105,
        "compression_ratio": 1.8403361344537814,
        "end": 6169.66,
        "id": 1365,
        "no_speech_prob": 0.0008558888221159577,
        "seek": 615526,
        "start": 6163.42,
        "temperature": 0,
        "text": " I'm going to show you something in the next video. I think i'm going to take a break and in the next video i'm going to look",
        "tokens": [
          50772,
          286,
          478,
          516,
          281,
          855,
          291,
          746,
          294,
          264,
          958,
          960,
          13,
          286,
          519,
          741,
          478,
          516,
          281,
          747,
          257,
          1821,
          293,
          294,
          264,
          958,
          960,
          741,
          478,
          516,
          281,
          574,
          51084
        ]
      },
      {
        "avg_logprob": -0.22052011411052105,
        "compression_ratio": 1.8403361344537814,
        "end": 6170.92,
        "id": 1366,
        "no_speech_prob": 0.0008558888221159577,
        "seek": 615526,
        "start": 6169.820000000001,
        "temperature": 0,
        "text": " for",
        "tokens": [
          51092,
          337,
          51147
        ]
      },
      {
        "avg_logprob": -0.22052011411052105,
        "compression_ratio": 1.8403361344537814,
        "end": 6173.9800000000005,
        "id": 1367,
        "no_speech_prob": 0.0008558888221159577,
        "seek": 615526,
        "start": 6170.92,
        "temperature": 0,
        "text": " Messages that at mention the bot and then i'm going to have that bot",
        "tokens": [
          51147,
          9847,
          1660,
          300,
          412,
          2152,
          264,
          10592,
          293,
          550,
          741,
          478,
          516,
          281,
          362,
          300,
          10592,
          51300
        ]
      },
      {
        "avg_logprob": -0.22052011411052105,
        "compression_ratio": 1.8403361344537814,
        "end": 6178.780000000001,
        "id": 1368,
        "no_speech_prob": 0.0008558888221159577,
        "seek": 615526,
        "start": 6174.38,
        "temperature": 0,
        "text": " Act on those either reply to them or favorite or do something like that. Okay, so that's what i'm going to do next",
        "tokens": [
          51320,
          3251,
          322,
          729,
          2139,
          16972,
          281,
          552,
          420,
          2954,
          420,
          360,
          746,
          411,
          300,
          13,
          1033,
          11,
          370,
          300,
          311,
          437,
          741,
          478,
          516,
          281,
          360,
          958,
          51540
        ]
      },
      {
        "avg_logprob": -0.3144231854063092,
        "compression_ratio": 1.063157894736842,
        "end": 6187.26,
        "id": 1369,
        "no_speech_prob": 0.0003149943659082055,
        "seek": 618526,
        "start": 6185.26,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50364,
          407,
          50464
        ]
      },
      {
        "avg_logprob": -0.3144231854063092,
        "compression_ratio": 1.063157894736842,
        "end": 6201.9800000000005,
        "id": 1370,
        "no_speech_prob": 0.0003149943659082055,
        "seek": 618526,
        "start": 6195.5,
        "temperature": 0,
        "text": " Someone just mentioning, okay. All right. I'm missing a semicolon. There we go. Thank you",
        "tokens": [
          50876,
          8734,
          445,
          18315,
          11,
          1392,
          13,
          1057,
          558,
          13,
          286,
          478,
          5361,
          257,
          27515,
          38780,
          13,
          821,
          321,
          352,
          13,
          1044,
          291,
          51200
        ]
      },
      {
        "avg_logprob": -0.3144231854063092,
        "compression_ratio": 1.063157894736842,
        "end": 6206.14,
        "id": 1371,
        "no_speech_prob": 0.0003149943659082055,
        "seek": 618526,
        "start": 6204.14,
        "temperature": 0,
        "text": " Okay, um",
        "tokens": [
          51308,
          1033,
          11,
          1105,
          51408
        ]
      },
      {
        "avg_logprob": -0.7557863712310791,
        "compression_ratio": 1.2135922330097086,
        "end": 6218.06,
        "id": 1372,
        "no_speech_prob": 0.00029595100204460323,
        "seek": 621526,
        "start": 6216.06,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50404,
          1033,
          50504
        ]
      },
      {
        "avg_logprob": -0.7557863712310791,
        "compression_ratio": 1.2135922330097086,
        "end": 6229.42,
        "id": 1373,
        "no_speech_prob": 0.00029595100204460323,
        "seek": 621526,
        "start": 6226.14,
        "temperature": 0,
        "text": " What's this delete message favorite",
        "tokens": [
          50908,
          708,
          311,
          341,
          12097,
          3636,
          2954,
          51072
        ]
      },
      {
        "avg_logprob": -0.7557863712310791,
        "compression_ratio": 1.2135922330097086,
        "end": 6235.58,
        "id": 1374,
        "no_speech_prob": 0.00029595100204460323,
        "seek": 621526,
        "start": 6231.34,
        "temperature": 0,
        "text": " We know how I get a I want to mention, oh, here we go type mention. Okay, great",
        "tokens": [
          51168,
          492,
          458,
          577,
          286,
          483,
          257,
          286,
          528,
          281,
          2152,
          11,
          1954,
          11,
          510,
          321,
          352,
          2010,
          2152,
          13,
          1033,
          11,
          869,
          51380
        ]
      },
      {
        "avg_logprob": -0.7557863712310791,
        "compression_ratio": 1.2135922330097086,
        "end": 6240.62,
        "id": 1375,
        "no_speech_prob": 0.00029595100204460323,
        "seek": 621526,
        "start": 6238.62,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51532,
          1033,
          51632
        ]
      },
      {
        "avg_logprob": -0.36360716819763184,
        "compression_ratio": 1.3379310344827586,
        "end": 6243.0199999999995,
        "id": 1376,
        "no_speech_prob": 0.000480288959806785,
        "seek": 624062,
        "start": 6241.0199999999995,
        "temperature": 0,
        "text": " Okay, okay",
        "tokens": [
          50384,
          1033,
          11,
          1392,
          50484
        ]
      },
      {
        "avg_logprob": -0.36360716819763184,
        "compression_ratio": 1.3379310344827586,
        "end": 6249.58,
        "id": 1377,
        "no_speech_prob": 0.000480288959806785,
        "seek": 624062,
        "start": 6247.58,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50712,
          1033,
          50812
        ]
      },
      {
        "avg_logprob": -0.36360716819763184,
        "compression_ratio": 1.3379310344827586,
        "end": 6256.8,
        "id": 1378,
        "no_speech_prob": 0.000480288959806785,
        "seek": 624062,
        "start": 6252.7,
        "temperature": 0,
        "text": " Every time I look over the chat, it's a message about c sharp versus c++",
        "tokens": [
          50968,
          2048,
          565,
          286,
          574,
          670,
          264,
          5081,
          11,
          309,
          311,
          257,
          3636,
          466,
          269,
          8199,
          5717,
          269,
          25472,
          51173
        ]
      },
      {
        "avg_logprob": -0.36360716819763184,
        "compression_ratio": 1.3379310344827586,
        "end": 6259.9,
        "id": 1379,
        "no_speech_prob": 0.000480288959806785,
        "seek": 624062,
        "start": 6257.9,
        "temperature": 0,
        "text": " python java",
        "tokens": [
          51228,
          38797,
          361,
          4061,
          51328
        ]
      },
      {
        "avg_logprob": -0.36360716819763184,
        "compression_ratio": 1.3379310344827586,
        "end": 6265.0199999999995,
        "id": 1380,
        "no_speech_prob": 0.000480288959806785,
        "seek": 624062,
        "start": 6260.62,
        "temperature": 0,
        "text": " You think everybody's watching a completely different live stream that it's not me on it",
        "tokens": [
          51364,
          509,
          519,
          2201,
          311,
          1976,
          257,
          2584,
          819,
          1621,
          4309,
          300,
          309,
          311,
          406,
          385,
          322,
          309,
          51584
        ]
      },
      {
        "avg_logprob": -0.36360716819763184,
        "compression_ratio": 1.3379310344827586,
        "end": 6268.14,
        "id": 1381,
        "no_speech_prob": 0.000480288959806785,
        "seek": 624062,
        "start": 6266.14,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51640,
          1033,
          51740
        ]
      },
      {
        "avg_logprob": -0.32330952962239584,
        "compression_ratio": 1.5444444444444445,
        "end": 6272.78,
        "id": 1382,
        "no_speech_prob": 0.000057387209380976856,
        "seek": 627062,
        "start": 6270.78,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50372,
          407,
          50472
        ]
      },
      {
        "avg_logprob": -0.32330952962239584,
        "compression_ratio": 1.5444444444444445,
        "end": 6283.18,
        "id": 1383,
        "no_speech_prob": 0.000057387209380976856,
        "seek": 627062,
        "start": 6275.18,
        "temperature": 0,
        "text": " Okay, i'm back again, oh so many mastodon videos this now what I want to do is look at how I can deal with a",
        "tokens": [
          50592,
          1033,
          11,
          741,
          478,
          646,
          797,
          11,
          1954,
          370,
          867,
          27055,
          378,
          266,
          2145,
          341,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          574,
          412,
          577,
          286,
          393,
          2028,
          365,
          257,
          50992
        ]
      },
      {
        "avg_logprob": -0.32330952962239584,
        "compression_ratio": 1.5444444444444445,
        "end": 6287.34,
        "id": 1384,
        "no_speech_prob": 0.000057387209380976856,
        "seek": 627062,
        "start": 6283.24,
        "temperature": 0,
        "text": " mention a mention is when somebody else toots posts",
        "tokens": [
          50995,
          2152,
          257,
          2152,
          307,
          562,
          2618,
          1646,
          281,
          1971,
          12300,
          51200
        ]
      },
      {
        "avg_logprob": -0.32330952962239584,
        "compression_ratio": 1.5444444444444445,
        "end": 6294.48,
        "id": 1385,
        "no_speech_prob": 0.000057387209380976856,
        "seek": 627062,
        "start": 6287.82,
        "temperature": 0,
        "text": " And mentions me the bot in their message post so and this will come in as a notification",
        "tokens": [
          51224,
          400,
          23844,
          385,
          264,
          10592,
          294,
          641,
          3636,
          2183,
          370,
          293,
          341,
          486,
          808,
          294,
          382,
          257,
          11554,
          51557
        ]
      },
      {
        "avg_logprob": -0.32330952962239584,
        "compression_ratio": 1.5444444444444445,
        "end": 6297.34,
        "id": 1386,
        "no_speech_prob": 0.000057387209380976856,
        "seek": 627062,
        "start": 6295.26,
        "temperature": 0,
        "text": " event type mention before",
        "tokens": [
          51596,
          2280,
          2010,
          2152,
          949,
          51700
        ]
      },
      {
        "avg_logprob": -0.24072245808390827,
        "compression_ratio": 1.5595238095238095,
        "end": 6298.7,
        "id": 1387,
        "no_speech_prob": 0.000011478766282380093,
        "seek": 629734,
        "start": 6297.5,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50372,
          286,
          50432
        ]
      },
      {
        "avg_logprob": -0.24072245808390827,
        "compression_ratio": 1.5595238095238095,
        "end": 6302.14,
        "id": 1388,
        "no_speech_prob": 0.000011478766282380093,
        "seek": 629734,
        "start": 6298.7,
        "temperature": 0,
        "text": " dealt with if I look at my code in the previous video I",
        "tokens": [
          50432,
          15991,
          365,
          498,
          286,
          574,
          412,
          452,
          3089,
          294,
          264,
          3894,
          960,
          286,
          50604
        ]
      },
      {
        "avg_logprob": -0.24072245808390827,
        "compression_ratio": 1.5595238095238095,
        "end": 6307.5,
        "id": 1389,
        "no_speech_prob": 0.000011478766282380093,
        "seek": 629734,
        "start": 6302.7,
        "temperature": 0,
        "text": " Dealt with anything. That is a follow. So now I want to say else if",
        "tokens": [
          50632,
          1346,
          3198,
          365,
          1340,
          13,
          663,
          307,
          257,
          1524,
          13,
          407,
          586,
          286,
          528,
          281,
          584,
          1646,
          498,
          50872
        ]
      },
      {
        "avg_logprob": -0.24072245808390827,
        "compression_ratio": 1.5595238095238095,
        "end": 6310.78,
        "id": 1390,
        "no_speech_prob": 0.000011478766282380093,
        "seek": 629734,
        "start": 6308.54,
        "temperature": 0,
        "text": " message data dot type equals",
        "tokens": [
          50924,
          3636,
          1412,
          5893,
          2010,
          6915,
          51036
        ]
      },
      {
        "avg_logprob": -0.24072245808390827,
        "compression_ratio": 1.5595238095238095,
        "end": 6313.82,
        "id": 1391,
        "no_speech_prob": 0.000011478766282380093,
        "seek": 629734,
        "start": 6311.82,
        "temperature": 0,
        "text": " for a mention",
        "tokens": [
          51088,
          337,
          257,
          2152,
          51188
        ]
      },
      {
        "avg_logprob": -0.24072245808390827,
        "compression_ratio": 1.5595238095238095,
        "end": 6320.06,
        "id": 1392,
        "no_speech_prob": 0.000011478766282380093,
        "seek": 629734,
        "start": 6314.22,
        "temperature": 0,
        "text": " So I want to deal with a mention. So what i'm going to do in this example is if somebody says",
        "tokens": [
          51208,
          407,
          286,
          528,
          281,
          2028,
          365,
          257,
          2152,
          13,
          407,
          437,
          741,
          478,
          516,
          281,
          360,
          294,
          341,
          1365,
          307,
          498,
          2618,
          1619,
          51500
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6323.740000000001,
        "id": 1393,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6320.700000000001,
        "temperature": 0,
        "text": " Um, please like or favorite or something like that",
        "tokens": [
          50396,
          3301,
          11,
          1767,
          411,
          420,
          2954,
          420,
          746,
          411,
          300,
          50548
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6329.42,
        "id": 1394,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6323.820000000001,
        "temperature": 0,
        "text": " I will like or favorite if someone says please boost or reblog I will boost slash reblog",
        "tokens": [
          50552,
          286,
          486,
          411,
          420,
          2954,
          498,
          1580,
          1619,
          1767,
          9194,
          420,
          12970,
          4987,
          286,
          486,
          9194,
          17330,
          12970,
          4987,
          50832
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6332.780000000001,
        "id": 1395,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6329.5,
        "temperature": 0,
        "text": " So i'm basically going to respond i'm not going to i'm not going to toot back",
        "tokens": [
          50836,
          407,
          741,
          478,
          1936,
          516,
          281,
          4196,
          741,
          478,
          406,
          516,
          281,
          741,
          478,
          406,
          516,
          281,
          281,
          310,
          646,
          51000
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6335.580000000001,
        "id": 1396,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6332.9400000000005,
        "temperature": 0,
        "text": " But i'm going to act on the message based on what the content is",
        "tokens": [
          51008,
          583,
          741,
          478,
          516,
          281,
          605,
          322,
          264,
          3636,
          2361,
          322,
          437,
          264,
          2701,
          307,
          51140
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6339.4400000000005,
        "id": 1397,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6335.900000000001,
        "temperature": 0,
        "text": " So the first thing that I would I might want to do is I could use a regular expression",
        "tokens": [
          51156,
          407,
          264,
          700,
          551,
          300,
          286,
          576,
          286,
          1062,
          528,
          281,
          360,
          307,
          286,
          727,
          764,
          257,
          3890,
          6114,
          51333
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6341.9800000000005,
        "id": 1398,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6339.9800000000005,
        "temperature": 0,
        "text": " so for example, I could say",
        "tokens": [
          51360,
          370,
          337,
          1365,
          11,
          286,
          727,
          584,
          51460
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6343.9800000000005,
        "id": 1399,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6341.9800000000005,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51460,
          1105,
          51560
        ]
      },
      {
        "avg_logprob": -0.2102323197226488,
        "compression_ratio": 2.019230769230769,
        "end": 6350,
        "id": 1400,
        "no_speech_prob": 0.00031503327772952616,
        "seek": 632006,
        "start": 6344.46,
        "temperature": 0,
        "text": " Regular expression one is and if you don't know about regular expressions i'd refer you to my session on regular expressions",
        "tokens": [
          51584,
          45659,
          6114,
          472,
          307,
          293,
          498,
          291,
          500,
          380,
          458,
          466,
          3890,
          15277,
          741,
          1116,
          2864,
          291,
          281,
          452,
          5481,
          322,
          3890,
          15277,
          51861
        ]
      },
      {
        "avg_logprob": -0.2309509383307563,
        "compression_ratio": 1.5347222222222223,
        "end": 6352.700000000001,
        "id": 1401,
        "no_speech_prob": 0.000009666086953075137,
        "seek": 635006,
        "start": 6350.38,
        "temperature": 0,
        "text": " um if if uh, like",
        "tokens": [
          50380,
          1105,
          498,
          498,
          2232,
          11,
          411,
          50496
        ]
      },
      {
        "avg_logprob": -0.2309509383307563,
        "compression_ratio": 1.5347222222222223,
        "end": 6355.26,
        "id": 1402,
        "no_speech_prob": 0.000009666086953075137,
        "seek": 635006,
        "start": 6353.42,
        "temperature": 0,
        "text": " or",
        "tokens": [
          50532,
          420,
          50624
        ]
      },
      {
        "avg_logprob": -0.2309509383307563,
        "compression_ratio": 1.5347222222222223,
        "end": 6360.14,
        "id": 1403,
        "no_speech_prob": 0.000009666086953075137,
        "seek": 635006,
        "start": 6355.26,
        "temperature": 0,
        "text": " Favorite or maybe the heart emoji. How do I get emoji?",
        "tokens": [
          50624,
          43697,
          420,
          1310,
          264,
          1917,
          31595,
          13,
          1012,
          360,
          286,
          483,
          31595,
          30,
          50868
        ]
      },
      {
        "avg_logprob": -0.2309509383307563,
        "compression_ratio": 1.5347222222222223,
        "end": 6363.9800000000005,
        "id": 1404,
        "no_speech_prob": 0.000009666086953075137,
        "seek": 635006,
        "start": 6361.9800000000005,
        "temperature": 0,
        "text": " Hold on there's a way to do the emoji keyboard",
        "tokens": [
          50960,
          6962,
          322,
          456,
          311,
          257,
          636,
          281,
          360,
          264,
          31595,
          10186,
          51060
        ]
      },
      {
        "avg_logprob": -0.2309509383307563,
        "compression_ratio": 1.5347222222222223,
        "end": 6367.34,
        "id": 1405,
        "no_speech_prob": 0.000009666086953075137,
        "seek": 635006,
        "start": 6365.34,
        "temperature": 0,
        "text": " No",
        "tokens": [
          51128,
          883,
          51228
        ]
      },
      {
        "avg_logprob": -0.2309509383307563,
        "compression_ratio": 1.5347222222222223,
        "end": 6376.700000000001,
        "id": 1406,
        "no_speech_prob": 0.000009666086953075137,
        "seek": 635006,
        "start": 6370.9400000000005,
        "temperature": 0,
        "text": " How do I get it on that with the touch bar, can I just get the touch bar to no, oh that's weird",
        "tokens": [
          51408,
          1012,
          360,
          286,
          483,
          309,
          322,
          300,
          365,
          264,
          2557,
          2159,
          11,
          393,
          286,
          445,
          483,
          264,
          2557,
          2159,
          281,
          572,
          11,
          1954,
          300,
          311,
          3657,
          51696
        ]
      },
      {
        "avg_logprob": -0.5180516137017144,
        "compression_ratio": 1.2222222222222223,
        "end": 6378.94,
        "id": 1407,
        "no_speech_prob": 0.00007602424011565745,
        "seek": 637670,
        "start": 6376.94,
        "temperature": 0,
        "text": " Um, hold on",
        "tokens": [
          50376,
          3301,
          11,
          1797,
          322,
          50476
        ]
      },
      {
        "avg_logprob": -0.5180516137017144,
        "compression_ratio": 1.2222222222222223,
        "end": 6391.9,
        "id": 1408,
        "no_speech_prob": 0.00007602424011565745,
        "seek": 637670,
        "start": 6384.78,
        "temperature": 0,
        "text": " Um emoji touch bar mac, how do I like make it happen?",
        "tokens": [
          50768,
          3301,
          31595,
          2557,
          2159,
          7912,
          11,
          577,
          360,
          286,
          411,
          652,
          309,
          1051,
          30,
          51124
        ]
      },
      {
        "avg_logprob": -0.5180516137017144,
        "compression_ratio": 1.2222222222222223,
        "end": 6399.34,
        "id": 1409,
        "no_speech_prob": 0.00007602424011565745,
        "seek": 637670,
        "start": 6397.34,
        "temperature": 0,
        "text": " This is really good useful",
        "tokens": [
          51396,
          639,
          307,
          534,
          665,
          4420,
          51496
        ]
      },
      {
        "avg_logprob": -0.5180516137017144,
        "compression_ratio": 1.2222222222222223,
        "end": 6403.9,
        "id": 1410,
        "no_speech_prob": 0.00007602424011565745,
        "seek": 637670,
        "start": 6401.66,
        "temperature": 0,
        "text": " Oh if I do something like this will it just pop up",
        "tokens": [
          51612,
          876,
          498,
          286,
          360,
          746,
          411,
          341,
          486,
          309,
          445,
          1665,
          493,
          51724
        ]
      },
      {
        "avg_logprob": -0.5966862723940894,
        "compression_ratio": 0.9859154929577465,
        "end": 6407.36,
        "id": 1411,
        "no_speech_prob": 0.0004955307813361287,
        "seek": 640390,
        "start": 6403.9,
        "temperature": 0,
        "text": " No, because it's got to be like in email or something",
        "tokens": [
          50364,
          883,
          11,
          570,
          309,
          311,
          658,
          281,
          312,
          411,
          294,
          3796,
          420,
          746,
          50537
        ]
      },
      {
        "avg_logprob": -0.5966862723940894,
        "compression_ratio": 0.9859154929577465,
        "end": 6418.0599999999995,
        "id": 1412,
        "no_speech_prob": 0.0004955307813361287,
        "seek": 640390,
        "start": 6416.0599999999995,
        "temperature": 0,
        "text": " Stupid touch bar",
        "tokens": [
          50972,
          37659,
          2557,
          2159,
          51072
        ]
      },
      {
        "avg_logprob": -0.2994689332677963,
        "compression_ratio": 1.1810344827586208,
        "end": 6435.9,
        "id": 1413,
        "no_speech_prob": 0.0004305536567699164,
        "seek": 643390,
        "start": 6433.9,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50364,
          3301,
          50464
        ]
      },
      {
        "avg_logprob": -0.2994689332677963,
        "compression_ratio": 1.1810344827586208,
        "end": 6441.42,
        "id": 1414,
        "no_speech_prob": 0.0004305536567699164,
        "seek": 643390,
        "start": 6438.78,
        "temperature": 0,
        "text": " Mac emoji keyboard",
        "tokens": [
          50608,
          5707,
          31595,
          10186,
          50740
        ]
      },
      {
        "avg_logprob": -0.2994689332677963,
        "compression_ratio": 1.1810344827586208,
        "end": 6451.82,
        "id": 1415,
        "no_speech_prob": 0.0004305536567699164,
        "seek": 643390,
        "start": 6447.339999999999,
        "temperature": 0,
        "text": " Command control space bar. That's what I was looking for. No",
        "tokens": [
          51036,
          17901,
          1969,
          1901,
          2159,
          13,
          663,
          311,
          437,
          286,
          390,
          1237,
          337,
          13,
          883,
          51260
        ]
      },
      {
        "avg_logprob": -0.2994689332677963,
        "compression_ratio": 1.1810344827586208,
        "end": 6456.7,
        "id": 1416,
        "no_speech_prob": 0.0004305536567699164,
        "seek": 643390,
        "start": 6454.7,
        "temperature": 0,
        "text": " Hey, there we go, okay",
        "tokens": [
          51404,
          1911,
          11,
          456,
          321,
          352,
          11,
          1392,
          51504
        ]
      },
      {
        "avg_logprob": -0.2994689332677963,
        "compression_ratio": 1.1810344827586208,
        "end": 6460.299999999999,
        "id": 1417,
        "no_speech_prob": 0.0004305536567699164,
        "seek": 643390,
        "start": 6458.299999999999,
        "temperature": 0,
        "text": " There we go",
        "tokens": [
          51584,
          821,
          321,
          352,
          51684
        ]
      },
      {
        "avg_logprob": -0.2994689332677963,
        "compression_ratio": 1.1810344827586208,
        "end": 6462.86,
        "id": 1418,
        "no_speech_prob": 0.0004305536567699164,
        "seek": 643390,
        "start": 6460.86,
        "temperature": 0,
        "text": " Oh, yeah, all right",
        "tokens": [
          51712,
          876,
          11,
          1338,
          11,
          439,
          558,
          51812
        ]
      },
      {
        "avg_logprob": -0.42110604355015707,
        "compression_ratio": 1.671641791044776,
        "end": 6471.5,
        "id": 1419,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 646390,
        "start": 6464.54,
        "temperature": 0,
        "text": " All right, I can make this regular expression I can say, um, like or favorite or uh,",
        "tokens": [
          50396,
          1057,
          558,
          11,
          286,
          393,
          652,
          341,
          3890,
          6114,
          286,
          393,
          584,
          11,
          1105,
          11,
          411,
          420,
          2954,
          420,
          2232,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.42110604355015707,
        "compression_ratio": 1.671641791044776,
        "end": 6475.099999999999,
        "id": 1420,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 646390,
        "start": 6472.54,
        "temperature": 0,
        "text": " Like maybe if somebody, uh uses a heart",
        "tokens": [
          50796,
          1743,
          1310,
          498,
          2618,
          11,
          2232,
          4960,
          257,
          1917,
          50924
        ]
      },
      {
        "avg_logprob": -0.42110604355015707,
        "compression_ratio": 1.671641791044776,
        "end": 6479.42,
        "id": 1421,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 646390,
        "start": 6475.98,
        "temperature": 0,
        "text": " I don't know. Is this the regular heart? This is the regular heart I think",
        "tokens": [
          50968,
          286,
          500,
          380,
          458,
          13,
          1119,
          341,
          264,
          3890,
          1917,
          30,
          639,
          307,
          264,
          3890,
          1917,
          286,
          519,
          51140
        ]
      },
      {
        "avg_logprob": -0.42110604355015707,
        "compression_ratio": 1.671641791044776,
        "end": 6481.98,
        "id": 1422,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 646390,
        "start": 6480.46,
        "temperature": 0,
        "text": " I think",
        "tokens": [
          51192,
          286,
          519,
          51268
        ]
      },
      {
        "avg_logprob": -0.42110604355015707,
        "compression_ratio": 1.671641791044776,
        "end": 6486.46,
        "id": 1423,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 646390,
        "start": 6481.98,
        "temperature": 0,
        "text": " So now I basically want to look. So what is the content? So I need to um",
        "tokens": [
          51268,
          407,
          586,
          286,
          1936,
          528,
          281,
          574,
          13,
          407,
          437,
          307,
          264,
          2701,
          30,
          407,
          286,
          643,
          281,
          1105,
          51492
        ]
      },
      {
        "avg_logprob": -0.42110604355015707,
        "compression_ratio": 1.671641791044776,
        "end": 6491.259999999999,
        "id": 1424,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 646390,
        "start": 6487.259999999999,
        "temperature": 0,
        "text": " Look at this is the mention. I want to look at the data",
        "tokens": [
          51532,
          2053,
          412,
          341,
          307,
          264,
          2152,
          13,
          286,
          528,
          281,
          574,
          412,
          264,
          1412,
          51732
        ]
      },
      {
        "avg_logprob": -0.5228778469947076,
        "compression_ratio": 1.65,
        "end": 6496.62,
        "id": 1425,
        "no_speech_prob": 0.00016603790572844446,
        "seek": 649126,
        "start": 6491.26,
        "temperature": 0,
        "text": " Data dot status dot content. Okay, so I need to say",
        "tokens": [
          50364,
          11888,
          5893,
          6558,
          5893,
          2701,
          13,
          1033,
          11,
          370,
          286,
          643,
          281,
          584,
          50632
        ]
      },
      {
        "avg_logprob": -0.5228778469947076,
        "compression_ratio": 1.65,
        "end": 6500.9400000000005,
        "id": 1426,
        "no_speech_prob": 0.00016603790572844446,
        "seek": 649126,
        "start": 6498.9400000000005,
        "temperature": 0,
        "text": " Content equals",
        "tokens": [
          50748,
          30078,
          6915,
          50848
        ]
      },
      {
        "avg_logprob": -0.5228778469947076,
        "compression_ratio": 1.65,
        "end": 6503.26,
        "id": 1427,
        "no_speech_prob": 0.00016603790572844446,
        "seek": 649126,
        "start": 6501.26,
        "temperature": 0,
        "text": " equals data",
        "tokens": [
          50864,
          6915,
          1412,
          50964
        ]
      },
      {
        "avg_logprob": -0.5228778469947076,
        "compression_ratio": 1.65,
        "end": 6505.900000000001,
        "id": 1428,
        "no_speech_prob": 0.00016603790572844446,
        "seek": 649126,
        "start": 6503.58,
        "temperature": 0,
        "text": " dot status dot content",
        "tokens": [
          50980,
          5893,
          6558,
          5893,
          2701,
          51096
        ]
      },
      {
        "avg_logprob": -0.5228778469947076,
        "compression_ratio": 1.65,
        "end": 6511.74,
        "id": 1429,
        "no_speech_prob": 0.00016603790572844446,
        "seek": 649126,
        "start": 6506.54,
        "temperature": 0,
        "text": " And I want to say uh if regular expression test content",
        "tokens": [
          51128,
          400,
          286,
          528,
          281,
          584,
          2232,
          498,
          3890,
          6114,
          1500,
          2701,
          51388
        ]
      },
      {
        "avg_logprob": -0.5228778469947076,
        "compression_ratio": 1.65,
        "end": 6516.06,
        "id": 1430,
        "no_speech_prob": 0.00016603790572844446,
        "seek": 649126,
        "start": 6512.14,
        "temperature": 0,
        "text": " So i'm pretty sure this is a function that if I have a regular expression",
        "tokens": [
          51408,
          407,
          741,
          478,
          1238,
          988,
          341,
          307,
          257,
          2445,
          300,
          498,
          286,
          362,
          257,
          3890,
          6114,
          51604
        ]
      },
      {
        "avg_logprob": -0.4580081715303309,
        "compression_ratio": 1.6368421052631579,
        "end": 6521.42,
        "id": 1431,
        "no_speech_prob": 0.0011513918871060014,
        "seek": 651606,
        "start": 6516.06,
        "temperature": 0,
        "text": " If the regular expression is matched somewhere within that string content, this will return true",
        "tokens": [
          50364,
          759,
          264,
          3890,
          6114,
          307,
          21447,
          4079,
          1951,
          300,
          6798,
          2701,
          11,
          341,
          486,
          2736,
          2074,
          50632
        ]
      },
      {
        "avg_logprob": -0.4580081715303309,
        "compression_ratio": 1.6368421052631579,
        "end": 6524.9400000000005,
        "id": 1432,
        "no_speech_prob": 0.0011513918871060014,
        "seek": 651606,
        "start": 6522.38,
        "temperature": 0,
        "text": " So if that's the case, I want to say",
        "tokens": [
          50680,
          407,
          498,
          300,
          311,
          264,
          1389,
          11,
          286,
          528,
          281,
          584,
          50808
        ]
      },
      {
        "avg_logprob": -0.4580081715303309,
        "compression_ratio": 1.6368421052631579,
        "end": 6528.22,
        "id": 1433,
        "no_speech_prob": 0.0011513918871060014,
        "seek": 651606,
        "start": 6526.22,
        "temperature": 0,
        "text": " um m dot post",
        "tokens": [
          50872,
          1105,
          275,
          5893,
          2183,
          50972
        ]
      },
      {
        "avg_logprob": -0.4580081715303309,
        "compression_ratio": 1.6368421052631579,
        "end": 6531.42,
        "id": 1434,
        "no_speech_prob": 0.0011513918871060014,
        "seek": 651606,
        "start": 6529.42,
        "temperature": 0,
        "text": " m dot post",
        "tokens": [
          51032,
          275,
          5893,
          2183,
          51132
        ]
      },
      {
        "avg_logprob": -0.4580081715303309,
        "compression_ratio": 1.6368421052631579,
        "end": 6536.620000000001,
        "id": 1435,
        "no_speech_prob": 0.0011513918871060014,
        "seek": 651606,
        "start": 6531.580000000001,
        "temperature": 0,
        "text": " And then what so I need to go back and look at the api documentation because I want to favorite it",
        "tokens": [
          51140,
          400,
          550,
          437,
          370,
          286,
          643,
          281,
          352,
          646,
          293,
          574,
          412,
          264,
          1882,
          72,
          14333,
          570,
          286,
          528,
          281,
          2954,
          309,
          51392
        ]
      },
      {
        "avg_logprob": -0.4580081715303309,
        "compression_ratio": 1.6368421052631579,
        "end": 6539.900000000001,
        "id": 1436,
        "no_speech_prob": 0.0011513918871060014,
        "seek": 651606,
        "start": 6537.18,
        "temperature": 0,
        "text": " So if I go back here and say look at favorite",
        "tokens": [
          51420,
          407,
          498,
          286,
          352,
          646,
          510,
          293,
          584,
          574,
          412,
          2954,
          51556
        ]
      },
      {
        "avg_logprob": -0.4580081715303309,
        "compression_ratio": 1.6368421052631579,
        "end": 6543.660000000001,
        "id": 1437,
        "no_speech_prob": 0.0011513918871060014,
        "seek": 651606,
        "start": 6541.660000000001,
        "temperature": 0,
        "text": " The the",
        "tokens": [
          51644,
          440,
          264,
          51744
        ]
      },
      {
        "avg_logprob": -0.5940860250721807,
        "compression_ratio": 1.7216494845360826,
        "end": 6551.26,
        "id": 1438,
        "no_speech_prob": 0.0015978269511833787,
        "seek": 654366,
        "start": 6543.82,
        "temperature": 0,
        "text": " The the uh, the path to favorite is statuses the id and favorite so I need to say",
        "tokens": [
          50372,
          440,
          264,
          2232,
          11,
          264,
          3100,
          281,
          2954,
          307,
          6558,
          279,
          264,
          4496,
          293,
          2954,
          370,
          286,
          643,
          281,
          584,
          50744
        ]
      },
      {
        "avg_logprob": -0.5940860250721807,
        "compression_ratio": 1.7216494845360826,
        "end": 6553.9,
        "id": 1439,
        "no_speech_prob": 0.0015978269511833787,
        "seek": 654366,
        "start": 6551.9,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50776,
          1105,
          50876
        ]
      },
      {
        "avg_logprob": -0.5940860250721807,
        "compression_ratio": 1.7216494845360826,
        "end": 6558.62,
        "id": 1440,
        "no_speech_prob": 0.0015978269511833787,
        "seek": 654366,
        "start": 6554.22,
        "temperature": 0,
        "text": " Post to and so this is what I was doing when I want to post something I would actually just say",
        "tokens": [
          50892,
          10223,
          281,
          293,
          370,
          341,
          307,
          437,
          286,
          390,
          884,
          562,
          286,
          528,
          281,
          2183,
          746,
          286,
          576,
          767,
          445,
          584,
          51112
        ]
      },
      {
        "avg_logprob": -0.5940860250721807,
        "compression_ratio": 1.7216494845360826,
        "end": 6561.74,
        "id": 1441,
        "no_speech_prob": 0.0015978269511833787,
        "seek": 654366,
        "start": 6559.74,
        "temperature": 0,
        "text": " statuses",
        "tokens": [
          51168,
          6558,
          279,
          51268
        ]
      },
      {
        "avg_logprob": -0.5940860250721807,
        "compression_ratio": 1.7216494845360826,
        "end": 6567.66,
        "id": 1442,
        "no_speech_prob": 0.0015978269511833787,
        "seek": 654366,
        "start": 6561.74,
        "temperature": 0,
        "text": " Slash and I want to make this a template literal once again. I need to put the id in here",
        "tokens": [
          51268,
          6187,
          1299,
          293,
          286,
          528,
          281,
          652,
          341,
          257,
          12379,
          20411,
          1564,
          797,
          13,
          286,
          643,
          281,
          829,
          264,
          4496,
          294,
          510,
          51564
        ]
      },
      {
        "avg_logprob": -0.5940860250721807,
        "compression_ratio": 1.7216494845360826,
        "end": 6573.5,
        "id": 1443,
        "no_speech_prob": 0.0015978269511833787,
        "seek": 654366,
        "start": 6569.099999999999,
        "temperature": 0,
        "text": " Favorite okay. So this is a function that I can use to",
        "tokens": [
          51636,
          43697,
          1392,
          13,
          407,
          341,
          307,
          257,
          2445,
          300,
          286,
          393,
          764,
          281,
          51856
        ]
      },
      {
        "avg_logprob": -0.22710846131106457,
        "compression_ratio": 1.654054054054054,
        "end": 6577.58,
        "id": 1444,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 657366,
        "start": 6574.139999999999,
        "temperature": 0,
        "text": " If it matches favorite it and then I need to get the id",
        "tokens": [
          50388,
          759,
          309,
          10676,
          2954,
          309,
          293,
          550,
          286,
          643,
          281,
          483,
          264,
          4496,
          50560
        ]
      },
      {
        "avg_logprob": -0.22710846131106457,
        "compression_ratio": 1.654054054054054,
        "end": 6580.38,
        "id": 1445,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 657366,
        "start": 6578.0599999999995,
        "temperature": 0,
        "text": " So the id is under data",
        "tokens": [
          50584,
          407,
          264,
          4496,
          307,
          833,
          1412,
          50700
        ]
      },
      {
        "avg_logprob": -0.22710846131106457,
        "compression_ratio": 1.654054054054054,
        "end": 6584.62,
        "id": 1446,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 657366,
        "start": 6580.94,
        "temperature": 0,
        "text": " status id that's perfect data status id",
        "tokens": [
          50728,
          6558,
          4496,
          300,
          311,
          2176,
          1412,
          6558,
          4496,
          50912
        ]
      },
      {
        "avg_logprob": -0.22710846131106457,
        "compression_ratio": 1.654054054054054,
        "end": 6589.98,
        "id": 1447,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 657366,
        "start": 6585.9,
        "temperature": 0,
        "text": " And then there are any parameters that I need here so I can just go straight to",
        "tokens": [
          50976,
          400,
          550,
          456,
          366,
          604,
          9834,
          300,
          286,
          643,
          510,
          370,
          286,
          393,
          445,
          352,
          2997,
          281,
          51180
        ]
      },
      {
        "avg_logprob": -0.22710846131106457,
        "compression_ratio": 1.654054054054054,
        "end": 6593.099999999999,
        "id": 1448,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 657366,
        "start": 6591.099999999999,
        "temperature": 0,
        "text": " the callback error",
        "tokens": [
          51236,
          264,
          818,
          3207,
          6713,
          51336
        ]
      },
      {
        "avg_logprob": -0.22710846131106457,
        "compression_ratio": 1.654054054054054,
        "end": 6597.34,
        "id": 1449,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 657366,
        "start": 6595.34,
        "temperature": 0,
        "text": " Data",
        "tokens": [
          51448,
          11888,
          51548
        ]
      },
      {
        "avg_logprob": -0.22710846131106457,
        "compression_ratio": 1.654054054054054,
        "end": 6603.099999999999,
        "id": 1450,
        "no_speech_prob": 0.00002796917215164285,
        "seek": 657366,
        "start": 6597.34,
        "temperature": 0,
        "text": " And I can make a little function here and I can say, you know if error console log",
        "tokens": [
          51548,
          400,
          286,
          393,
          652,
          257,
          707,
          2445,
          510,
          293,
          286,
          393,
          584,
          11,
          291,
          458,
          498,
          6713,
          11076,
          3565,
          51836
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6605.66,
        "id": 1451,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6603.66,
        "temperature": 0,
        "text": " console error error",
        "tokens": [
          50364,
          11076,
          6713,
          6713,
          50464
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6607.98,
        "id": 1452,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6606.38,
        "temperature": 0,
        "text": " else",
        "tokens": [
          50500,
          1646,
          50580
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6609.98,
        "id": 1453,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6607.98,
        "temperature": 0,
        "text": " console log",
        "tokens": [
          50580,
          11076,
          3565,
          50680
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6613.98,
        "id": 1454,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6612.22,
        "temperature": 0,
        "text": " Uh favorited",
        "tokens": [
          50792,
          4019,
          2294,
          1226,
          50880
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6617.74,
        "id": 1455,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6613.98,
        "temperature": 0,
        "text": " And presumably this is going to look a lot like this I would imagine",
        "tokens": [
          50880,
          400,
          26742,
          341,
          307,
          516,
          281,
          574,
          257,
          688,
          411,
          341,
          286,
          576,
          3811,
          51068
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6619.26,
        "id": 1456,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6618.28,
        "temperature": 0,
        "text": " favorited",
        "tokens": [
          51095,
          2294,
          1226,
          51144
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6621.98,
        "id": 1457,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6619.26,
        "temperature": 0,
        "text": " Um id so let me just do data dot id",
        "tokens": [
          51144,
          3301,
          4496,
          370,
          718,
          385,
          445,
          360,
          1412,
          5893,
          4496,
          51280
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6624.3,
        "id": 1458,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6622.78,
        "temperature": 0,
        "text": " I'm, i'm guessing",
        "tokens": [
          51320,
          286,
          478,
          11,
          741,
          478,
          17939,
          51396
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6627.26,
        "id": 1459,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6624.3,
        "temperature": 0,
        "text": " So just to like have a little more information in here",
        "tokens": [
          51396,
          407,
          445,
          281,
          411,
          362,
          257,
          707,
          544,
          1589,
          294,
          510,
          51544
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6628.86,
        "id": 1460,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6627.88,
        "temperature": 0,
        "text": " favorited",
        "tokens": [
          51575,
          2294,
          1226,
          51624
        ]
      },
      {
        "avg_logprob": -0.29826960986173606,
        "compression_ratio": 1.5337423312883436,
        "end": 6630.86,
        "id": 1461,
        "no_speech_prob": 0.0001823524507926777,
        "seek": 660366,
        "start": 6628.86,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51624,
          1105,
          51724
        ]
      },
      {
        "avg_logprob": -0.2537038803100586,
        "compression_ratio": 1.5932203389830508,
        "end": 6635.839999999999,
        "id": 1462,
        "no_speech_prob": 0.00021654214651789516,
        "seek": 663086,
        "start": 6631.82,
        "temperature": 0,
        "text": " Uh data dot and by the way, this is message",
        "tokens": [
          50412,
          4019,
          1412,
          5893,
          293,
          538,
          264,
          636,
          11,
          341,
          307,
          3636,
          50613
        ]
      },
      {
        "avg_logprob": -0.2537038803100586,
        "compression_ratio": 1.5932203389830508,
        "end": 6639.98,
        "id": 1463,
        "no_speech_prob": 0.00021654214651789516,
        "seek": 663086,
        "start": 6637.08,
        "temperature": 0,
        "text": " message dot data message dot data",
        "tokens": [
          50675,
          3636,
          5893,
          1412,
          3636,
          5893,
          1412,
          50820
        ]
      },
      {
        "avg_logprob": -0.2537038803100586,
        "compression_ratio": 1.5932203389830508,
        "end": 6646.0599999999995,
        "id": 1464,
        "no_speech_prob": 0.00021654214651789516,
        "seek": 663086,
        "start": 6640.94,
        "temperature": 0,
        "text": " And this is favorited data dot id. Okay, so let's see here",
        "tokens": [
          50868,
          400,
          341,
          307,
          2294,
          1226,
          1412,
          5893,
          4496,
          13,
          1033,
          11,
          370,
          718,
          311,
          536,
          510,
          51124
        ]
      },
      {
        "avg_logprob": -0.2537038803100586,
        "compression_ratio": 1.5932203389830508,
        "end": 6653.0199999999995,
        "id": 1465,
        "no_speech_prob": 0.00021654214651789516,
        "seek": 663086,
        "start": 6647.179999999999,
        "temperature": 0,
        "text": " What's go what's wrong? Something is terribly wrong. I have i'm out of whack in terms of my brackets and things",
        "tokens": [
          51180,
          708,
          311,
          352,
          437,
          311,
          2085,
          30,
          6595,
          307,
          22903,
          2085,
          13,
          286,
          362,
          741,
          478,
          484,
          295,
          42877,
          294,
          2115,
          295,
          452,
          26179,
          293,
          721,
          51472
        ]
      },
      {
        "avg_logprob": -0.2537038803100586,
        "compression_ratio": 1.5932203389830508,
        "end": 6656.7,
        "id": 1466,
        "no_speech_prob": 0.00021654214651789516,
        "seek": 663086,
        "start": 6654.0599999999995,
        "temperature": 0,
        "text": " So, oh this also needs a end tick",
        "tokens": [
          51524,
          407,
          11,
          1954,
          341,
          611,
          2203,
          257,
          917,
          5204,
          51656
        ]
      },
      {
        "avg_logprob": -0.18930530548095703,
        "compression_ratio": 1.6255707762557077,
        "end": 6661.66,
        "id": 1467,
        "no_speech_prob": 0.0066927457228302956,
        "seek": 665670,
        "start": 6657.34,
        "temperature": 0,
        "text": " There we go and now a semicolon, okay, so apologies that this is hard to see here",
        "tokens": [
          50396,
          821,
          321,
          352,
          293,
          586,
          257,
          27515,
          38780,
          11,
          1392,
          11,
          370,
          34929,
          300,
          341,
          307,
          1152,
          281,
          536,
          510,
          50612
        ]
      },
      {
        "avg_logprob": -0.18930530548095703,
        "compression_ratio": 1.6255707762557077,
        "end": 6666.7,
        "id": 1468,
        "no_speech_prob": 0.0066927457228302956,
        "seek": 665670,
        "start": 6661.66,
        "temperature": 0,
        "text": " Let me see if I can remove this over give myself a little bit more space so we can look at this code. Ah",
        "tokens": [
          50612,
          961,
          385,
          536,
          498,
          286,
          393,
          4159,
          341,
          670,
          976,
          2059,
          257,
          707,
          857,
          544,
          1901,
          370,
          321,
          393,
          574,
          412,
          341,
          3089,
          13,
          2438,
          50864
        ]
      },
      {
        "avg_logprob": -0.18930530548095703,
        "compression_ratio": 1.6255707762557077,
        "end": 6672.22,
        "id": 1469,
        "no_speech_prob": 0.0066927457228302956,
        "seek": 665670,
        "start": 6670.62,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51060,
          1033,
          51140
        ]
      },
      {
        "avg_logprob": -0.18930530548095703,
        "compression_ratio": 1.6255707762557077,
        "end": 6675.179999999999,
        "id": 1470,
        "no_speech_prob": 0.0066927457228302956,
        "seek": 665670,
        "start": 6672.22,
        "temperature": 0,
        "text": " Let me just make the font a little bit smaller. There we go. Okay",
        "tokens": [
          51140,
          961,
          385,
          445,
          652,
          264,
          10703,
          257,
          707,
          857,
          4356,
          13,
          821,
          321,
          352,
          13,
          1033,
          51288
        ]
      },
      {
        "avg_logprob": -0.18930530548095703,
        "compression_ratio": 1.6255707762557077,
        "end": 6678.22,
        "id": 1471,
        "no_speech_prob": 0.0066927457228302956,
        "seek": 665670,
        "start": 6676.22,
        "temperature": 0,
        "text": " So what we're looking at here is",
        "tokens": [
          51340,
          407,
          437,
          321,
          434,
          1237,
          412,
          510,
          307,
          51440
        ]
      },
      {
        "avg_logprob": -0.18930530548095703,
        "compression_ratio": 1.6255707762557077,
        "end": 6682.38,
        "id": 1472,
        "no_speech_prob": 0.0066927457228302956,
        "seek": 665670,
        "start": 6678.7,
        "temperature": 0,
        "text": " If if it's a follow we're just going to say thanks for the follow",
        "tokens": [
          51464,
          759,
          498,
          309,
          311,
          257,
          1524,
          321,
          434,
          445,
          516,
          281,
          584,
          3231,
          337,
          264,
          1524,
          51648
        ]
      },
      {
        "avg_logprob": -0.22438600328233507,
        "compression_ratio": 1.680952380952381,
        "end": 6688.9400000000005,
        "id": 1473,
        "no_speech_prob": 0.0006771874614059925,
        "seek": 668238,
        "start": 6682.86,
        "temperature": 0,
        "text": " If it's a mention we're going to see did the mention use the word like favorite or heart if it did",
        "tokens": [
          50388,
          759,
          309,
          311,
          257,
          2152,
          321,
          434,
          516,
          281,
          536,
          630,
          264,
          2152,
          764,
          264,
          1349,
          411,
          2954,
          420,
          1917,
          498,
          309,
          630,
          50692
        ]
      },
      {
        "avg_logprob": -0.22438600328233507,
        "compression_ratio": 1.680952380952381,
        "end": 6695.9800000000005,
        "id": 1474,
        "no_speech_prob": 0.0006771874614059925,
        "seek": 668238,
        "start": 6689.64,
        "temperature": 0,
        "text": " Favorite it and then give me some information about whether it worked or not. So probably I also should do something like say",
        "tokens": [
          50727,
          43697,
          309,
          293,
          550,
          976,
          385,
          512,
          1589,
          466,
          1968,
          309,
          2732,
          420,
          406,
          13,
          407,
          1391,
          286,
          611,
          820,
          360,
          746,
          411,
          584,
          51044
        ]
      },
      {
        "avg_logprob": -0.22438600328233507,
        "compression_ratio": 1.680952380952381,
        "end": 6698.52,
        "id": 1475,
        "no_speech_prob": 0.0006771874614059925,
        "seek": 668238,
        "start": 6696.52,
        "temperature": 0,
        "text": " console dot log",
        "tokens": [
          51071,
          11076,
          5893,
          3565,
          51171
        ]
      },
      {
        "avg_logprob": -0.22438600328233507,
        "compression_ratio": 1.680952380952381,
        "end": 6700.62,
        "id": 1476,
        "no_speech_prob": 0.0006771874614059925,
        "seek": 668238,
        "start": 6699.26,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51208,
          3301,
          51276
        ]
      },
      {
        "avg_logprob": -0.22438600328233507,
        "compression_ratio": 1.680952380952381,
        "end": 6707.66,
        "id": 1477,
        "no_speech_prob": 0.0006771874614059925,
        "seek": 668238,
        "start": 6700.62,
        "temperature": 0,
        "text": " Just in case them just so I can see what the the message has i'm going to say console dot log a mention",
        "tokens": [
          51276,
          1449,
          294,
          1389,
          552,
          445,
          370,
          286,
          393,
          536,
          437,
          264,
          264,
          3636,
          575,
          741,
          478,
          516,
          281,
          584,
          11076,
          5893,
          3565,
          257,
          2152,
          51628
        ]
      },
      {
        "avg_logprob": -0.22438600328233507,
        "compression_ratio": 1.680952380952381,
        "end": 6711.1,
        "id": 1478,
        "no_speech_prob": 0.0006771874614059925,
        "seek": 668238,
        "start": 6709.1,
        "temperature": 0,
        "text": " Uh id",
        "tokens": [
          51700,
          4019,
          4496,
          51800
        ]
      },
      {
        "avg_logprob": -0.24405092942087273,
        "compression_ratio": 1.4619883040935673,
        "end": 6714.62,
        "id": 1479,
        "no_speech_prob": 0.00001777848956407979,
        "seek": 671238,
        "start": 6712.62,
        "temperature": 0,
        "text": " Uh and then add content",
        "tokens": [
          50376,
          4019,
          293,
          550,
          909,
          2701,
          50476
        ]
      },
      {
        "avg_logprob": -0.24405092942087273,
        "compression_ratio": 1.4619883040935673,
        "end": 6717.900000000001,
        "id": 1480,
        "no_speech_prob": 0.00001777848956407979,
        "seek": 671238,
        "start": 6715.900000000001,
        "temperature": 0,
        "text": " Okay, we are going to run this",
        "tokens": [
          50540,
          1033,
          11,
          321,
          366,
          516,
          281,
          1190,
          341,
          50640
        ]
      },
      {
        "avg_logprob": -0.24405092942087273,
        "compression_ratio": 1.4619883040935673,
        "end": 6721.66,
        "id": 1481,
        "no_speech_prob": 0.00001777848956407979,
        "seek": 671238,
        "start": 6719.1,
        "temperature": 0,
        "text": " Okay, what did I lose something weird happened here?",
        "tokens": [
          50700,
          1033,
          11,
          437,
          630,
          286,
          3624,
          746,
          3657,
          2011,
          510,
          30,
          50828
        ]
      },
      {
        "avg_logprob": -0.24405092942087273,
        "compression_ratio": 1.4619883040935673,
        "end": 6724.38,
        "id": 1482,
        "no_speech_prob": 0.00001777848956407979,
        "seek": 671238,
        "start": 6722.38,
        "temperature": 0,
        "text": " Uh, I also need this. Oh",
        "tokens": [
          50864,
          4019,
          11,
          286,
          611,
          643,
          341,
          13,
          876,
          50964
        ]
      },
      {
        "avg_logprob": -0.24405092942087273,
        "compression_ratio": 1.4619883040935673,
        "end": 6731.26,
        "id": 1483,
        "no_speech_prob": 0.00001777848956407979,
        "seek": 671238,
        "start": 6725.42,
        "temperature": 0,
        "text": " Oh boy template literal come back. Oh, I tried to reformat all this stuff",
        "tokens": [
          51016,
          876,
          3237,
          12379,
          20411,
          808,
          646,
          13,
          876,
          11,
          286,
          3031,
          281,
          8290,
          267,
          439,
          341,
          1507,
          51308
        ]
      },
      {
        "avg_logprob": -0.24405092942087273,
        "compression_ratio": 1.4619883040935673,
        "end": 6735.5,
        "id": 1484,
        "no_speech_prob": 0.00001777848956407979,
        "seek": 671238,
        "start": 6733.5,
        "temperature": 0,
        "text": " Oh so sad hold on",
        "tokens": [
          51420,
          876,
          370,
          4227,
          1797,
          322,
          51520
        ]
      },
      {
        "avg_logprob": -0.24405092942087273,
        "compression_ratio": 1.4619883040935673,
        "end": 6739.66,
        "id": 1485,
        "no_speech_prob": 0.00001777848956407979,
        "seek": 671238,
        "start": 6737.66,
        "temperature": 0,
        "text": " We're gonna get this back",
        "tokens": [
          51628,
          492,
          434,
          799,
          483,
          341,
          646,
          51728
        ]
      },
      {
        "avg_logprob": -0.18246438368311468,
        "compression_ratio": 1.740909090909091,
        "end": 6741.82,
        "id": 1486,
        "no_speech_prob": 0.000041986208088928834,
        "seek": 673966,
        "start": 6739.82,
        "temperature": 0,
        "text": " There we go, okay, we're good again",
        "tokens": [
          50372,
          821,
          321,
          352,
          11,
          1392,
          11,
          321,
          434,
          665,
          797,
          50472
        ]
      },
      {
        "avg_logprob": -0.18246438368311468,
        "compression_ratio": 1.740909090909091,
        "end": 6743.9,
        "id": 1487,
        "no_speech_prob": 0.000041986208088928834,
        "seek": 673966,
        "start": 6741.9,
        "temperature": 0,
        "text": " There we go. Here's our code. We got it",
        "tokens": [
          50476,
          821,
          321,
          352,
          13,
          1692,
          311,
          527,
          3089,
          13,
          492,
          658,
          309,
          50576
        ]
      },
      {
        "avg_logprob": -0.18246438368311468,
        "compression_ratio": 1.740909090909091,
        "end": 6750.38,
        "id": 1488,
        "no_speech_prob": 0.000041986208088928834,
        "seek": 673966,
        "start": 6743.98,
        "temperature": 0,
        "text": " If you mention me check to see if you said like favorite or heart and if so, I am going to favorite it. All right",
        "tokens": [
          50580,
          759,
          291,
          2152,
          385,
          1520,
          281,
          536,
          498,
          291,
          848,
          411,
          2954,
          420,
          1917,
          293,
          498,
          370,
          11,
          286,
          669,
          516,
          281,
          2954,
          309,
          13,
          1057,
          558,
          50900
        ]
      },
      {
        "avg_logprob": -0.18246438368311468,
        "compression_ratio": 1.740909090909091,
        "end": 6753.98,
        "id": 1489,
        "no_speech_prob": 0.000041986208088928834,
        "seek": 673966,
        "start": 6751.18,
        "temperature": 0,
        "text": " Here we go. Let's run this bot. See if we have any errors",
        "tokens": [
          50940,
          1692,
          321,
          352,
          13,
          961,
          311,
          1190,
          341,
          10592,
          13,
          3008,
          498,
          321,
          362,
          604,
          13603,
          51080
        ]
      },
      {
        "avg_logprob": -0.18246438368311468,
        "compression_ratio": 1.740909090909091,
        "end": 6761.5,
        "id": 1490,
        "no_speech_prob": 0.000041986208088928834,
        "seek": 673966,
        "start": 6755.66,
        "temperature": 0,
        "text": " Okay, it's starting all right better start mentioning me try mentioning me with uh",
        "tokens": [
          51164,
          1033,
          11,
          309,
          311,
          2891,
          439,
          558,
          1101,
          722,
          18315,
          385,
          853,
          18315,
          385,
          365,
          2232,
          51456
        ]
      },
      {
        "avg_logprob": -0.18246438368311468,
        "compression_ratio": 1.740909090909091,
        "end": 6766.22,
        "id": 1491,
        "no_speech_prob": 0.000041986208088928834,
        "seek": 673966,
        "start": 6762.3,
        "temperature": 0,
        "text": " With a heart with a like with saying favorite or not",
        "tokens": [
          51496,
          2022,
          257,
          1917,
          365,
          257,
          411,
          365,
          1566,
          2954,
          420,
          406,
          51692
        ]
      },
      {
        "avg_logprob": -0.43595858089259415,
        "compression_ratio": 1.329192546583851,
        "end": 6768.54,
        "id": 1492,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 676622,
        "start": 6766.54,
        "temperature": 0,
        "text": " I will just wait",
        "tokens": [
          50380,
          286,
          486,
          445,
          1699,
          50480
        ]
      },
      {
        "avg_logprob": -0.43595858089259415,
        "compression_ratio": 1.329192546583851,
        "end": 6776.860000000001,
        "id": 1493,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 676622,
        "start": 6772.14,
        "temperature": 0,
        "text": " Whoa, what's going on? This isn't right. Ah, something bad is happening",
        "tokens": [
          50660,
          7521,
          11,
          437,
          311,
          516,
          322,
          30,
          639,
          1943,
          380,
          558,
          13,
          2438,
          11,
          746,
          1578,
          307,
          2737,
          50896
        ]
      },
      {
        "avg_logprob": -0.43595858089259415,
        "compression_ratio": 1.329192546583851,
        "end": 6785.02,
        "id": 1494,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 676622,
        "start": 6781.9800000000005,
        "temperature": 0,
        "text": " So, okay my console logging is crazy",
        "tokens": [
          51152,
          407,
          11,
          1392,
          452,
          11076,
          27991,
          307,
          3219,
          51304
        ]
      },
      {
        "avg_logprob": -0.43595858089259415,
        "compression_ratio": 1.329192546583851,
        "end": 6790.7,
        "id": 1495,
        "no_speech_prob": 0.0001398217718815431,
        "seek": 676622,
        "start": 6786.22,
        "temperature": 0,
        "text": " Oh what happened here? Did I put a break point in by accident? I did not mean to do that",
        "tokens": [
          51364,
          876,
          437,
          2011,
          510,
          30,
          2589,
          286,
          829,
          257,
          1821,
          935,
          294,
          538,
          6398,
          30,
          286,
          630,
          406,
          914,
          281,
          360,
          300,
          51588
        ]
      },
      {
        "avg_logprob": -0.3195537061107402,
        "compression_ratio": 1.2521008403361344,
        "end": 6798.54,
        "id": 1496,
        "no_speech_prob": 0.00005475968646351248,
        "seek": 679622,
        "start": 6796.54,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50380,
          407,
          50480
        ]
      },
      {
        "avg_logprob": -0.3195537061107402,
        "compression_ratio": 1.2521008403361344,
        "end": 6807.58,
        "id": 1497,
        "no_speech_prob": 0.00005475968646351248,
        "seek": 679622,
        "start": 6803.58,
        "temperature": 0,
        "text": " And what is going on, okay, hold on, all right, I got some weird errors here",
        "tokens": [
          50732,
          400,
          437,
          307,
          516,
          322,
          11,
          1392,
          11,
          1797,
          322,
          11,
          439,
          558,
          11,
          286,
          658,
          512,
          3657,
          13603,
          510,
          50932
        ]
      },
      {
        "avg_logprob": -0.3195537061107402,
        "compression_ratio": 1.2521008403361344,
        "end": 6811.820000000001,
        "id": 1498,
        "no_speech_prob": 0.00005475968646351248,
        "seek": 679622,
        "start": 6809.820000000001,
        "temperature": 0,
        "text": " Uh, am I getting an error",
        "tokens": [
          51044,
          4019,
          11,
          669,
          286,
          1242,
          364,
          6713,
          51144
        ]
      },
      {
        "avg_logprob": -0.3195537061107402,
        "compression_ratio": 1.2521008403361344,
        "end": 6819.1,
        "id": 1499,
        "no_speech_prob": 0.00005475968646351248,
        "seek": 679622,
        "start": 6816.76,
        "temperature": 0,
        "text": " Favorited undefined. Hold on",
        "tokens": [
          51391,
          34240,
          1226,
          674,
          5666,
          2001,
          13,
          6962,
          322,
          51508
        ]
      },
      {
        "avg_logprob": -0.3195537061107402,
        "compression_ratio": 1.2521008403361344,
        "end": 6823.900000000001,
        "id": 1500,
        "no_speech_prob": 0.00005475968646351248,
        "seek": 679622,
        "start": 6821.900000000001,
        "temperature": 0,
        "text": " Stop everybody",
        "tokens": [
          51648,
          5535,
          2201,
          51748
        ]
      },
      {
        "avg_logprob": -0.22800638509351154,
        "compression_ratio": 1.3603603603603605,
        "end": 6828.54,
        "id": 1501,
        "no_speech_prob": 0.00004539734436548315,
        "seek": 682622,
        "start": 6826.54,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50380,
          407,
          50480
        ]
      },
      {
        "avg_logprob": -0.22800638509351154,
        "compression_ratio": 1.3603603603603605,
        "end": 6833.02,
        "id": 1502,
        "no_speech_prob": 0.00004539734436548315,
        "seek": 682622,
        "start": 6831.02,
        "temperature": 0,
        "text": " Well, first let me see if this is working",
        "tokens": [
          50604,
          1042,
          11,
          700,
          718,
          385,
          536,
          498,
          341,
          307,
          1364,
          50704
        ]
      },
      {
        "avg_logprob": -0.22800638509351154,
        "compression_ratio": 1.3603603603603605,
        "end": 6843.66,
        "id": 1503,
        "no_speech_prob": 0.00004539734436548315,
        "seek": 682622,
        "start": 6841.66,
        "temperature": 0,
        "text": " Okay, so it doesn't look like",
        "tokens": [
          51136,
          1033,
          11,
          370,
          309,
          1177,
          380,
          574,
          411,
          51236
        ]
      },
      {
        "avg_logprob": -0.22800638509351154,
        "compression_ratio": 1.3603603603603605,
        "end": 6853.18,
        "id": 1504,
        "no_speech_prob": 0.00004539734436548315,
        "seek": 682622,
        "start": 6846.9400000000005,
        "temperature": 0,
        "text": " It doesn't look like I am favoriting this so something definitely went wrong",
        "tokens": [
          51400,
          467,
          1177,
          380,
          574,
          411,
          286,
          669,
          2294,
          1748,
          341,
          370,
          746,
          2138,
          1437,
          2085,
          51712
        ]
      },
      {
        "avg_logprob": -0.28281315005555446,
        "compression_ratio": 1.3697478991596639,
        "end": 6860.22,
        "id": 1505,
        "no_speech_prob": 0.00012339424574747682,
        "seek": 685622,
        "start": 6856.3,
        "temperature": 0,
        "text": " And what is this crazy console log it's coming out here",
        "tokens": [
          50368,
          400,
          437,
          307,
          341,
          3219,
          11076,
          3565,
          309,
          311,
          1348,
          484,
          510,
          50564
        ]
      },
      {
        "avg_logprob": -0.28281315005555446,
        "compression_ratio": 1.3697478991596639,
        "end": 6867.02,
        "id": 1506,
        "no_speech_prob": 0.00012339424574747682,
        "seek": 685622,
        "start": 6863.66,
        "temperature": 0,
        "text": " Uh, we got to debug this without me with with some actual",
        "tokens": [
          50736,
          4019,
          11,
          321,
          658,
          281,
          24083,
          341,
          1553,
          385,
          365,
          365,
          512,
          3539,
          50904
        ]
      },
      {
        "avg_logprob": -0.28281315005555446,
        "compression_ratio": 1.3697478991596639,
        "end": 6874.780000000001,
        "id": 1507,
        "no_speech_prob": 0.00012339424574747682,
        "seek": 685622,
        "start": 6871.740000000001,
        "temperature": 0,
        "text": " Mention id content is that coming out?",
        "tokens": [
          51140,
          376,
          1251,
          4496,
          2701,
          307,
          300,
          1348,
          484,
          30,
          51292
        ]
      },
      {
        "avg_logprob": -0.28281315005555446,
        "compression_ratio": 1.3697478991596639,
        "end": 6880.280000000001,
        "id": 1508,
        "no_speech_prob": 0.00012339424574747682,
        "seek": 685622,
        "start": 6878.280000000001,
        "temperature": 0,
        "text": " Mention",
        "tokens": [
          51467,
          376,
          1251,
          51567
        ]
      },
      {
        "avg_logprob": -0.28281315005555446,
        "compression_ratio": 1.3697478991596639,
        "end": 6883.1,
        "id": 1509,
        "no_speech_prob": 0.00012339424574747682,
        "seek": 685622,
        "start": 6881.1,
        "temperature": 0,
        "text": " Id",
        "tokens": [
          51608,
          11506,
          51708
        ]
      },
      {
        "avg_logprob": -0.2978951454162598,
        "compression_ratio": 1.3381294964028776,
        "end": 6891.120000000001,
        "id": 1510,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 688310,
        "start": 6883.320000000001,
        "temperature": 0,
        "text": " Content then i'm getting favorited undefined and what is this insanity?",
        "tokens": [
          50375,
          30078,
          550,
          741,
          478,
          1242,
          2294,
          1226,
          674,
          5666,
          2001,
          293,
          437,
          307,
          341,
          47505,
          30,
          50765
        ]
      },
      {
        "avg_logprob": -0.2978951454162598,
        "compression_ratio": 1.3381294964028776,
        "end": 6899.58,
        "id": 1511,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 688310,
        "start": 6896.06,
        "temperature": 0,
        "text": " Oh, it's oh something horrible happened",
        "tokens": [
          51012,
          876,
          11,
          309,
          311,
          1954,
          746,
          9263,
          2011,
          51188
        ]
      },
      {
        "avg_logprob": -0.2978951454162598,
        "compression_ratio": 1.3381294964028776,
        "end": 6906.4800000000005,
        "id": 1512,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 688310,
        "start": 6901.42,
        "temperature": 0,
        "text": " Because when I got my when I auto hold on oh, this is so annoying. Hold on",
        "tokens": [
          51280,
          1436,
          562,
          286,
          658,
          452,
          562,
          286,
          8399,
          1797,
          322,
          1954,
          11,
          341,
          307,
          370,
          11304,
          13,
          6962,
          322,
          51533
        ]
      },
      {
        "avg_logprob": -0.2484936056465938,
        "compression_ratio": 1.1744186046511629,
        "end": 6915.18,
        "id": 1513,
        "no_speech_prob": 0.00006401974678738043,
        "seek": 691310,
        "start": 6913.18,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50368,
          407,
          50468
        ]
      },
      {
        "avg_logprob": -0.2484936056465938,
        "compression_ratio": 1.1744186046511629,
        "end": 6919.58,
        "id": 1514,
        "no_speech_prob": 0.00006401974678738043,
        "seek": 691310,
        "start": 6917.58,
        "temperature": 0,
        "text": " This is ridiculously annoying",
        "tokens": [
          50588,
          639,
          307,
          41358,
          11304,
          50688
        ]
      },
      {
        "avg_logprob": -0.2484936056465938,
        "compression_ratio": 1.1744186046511629,
        "end": 6928.22,
        "id": 1515,
        "no_speech_prob": 0.00006401974678738043,
        "seek": 691310,
        "start": 6926.22,
        "temperature": 0,
        "text": " This shouldn't ever be happening",
        "tokens": [
          51020,
          639,
          4659,
          380,
          1562,
          312,
          2737,
          51120
        ]
      },
      {
        "avg_logprob": -0.2484936056465938,
        "compression_ratio": 1.1744186046511629,
        "end": 6941.9800000000005,
        "id": 1516,
        "no_speech_prob": 0.00006401974678738043,
        "seek": 691310,
        "start": 6936.620000000001,
        "temperature": 0,
        "text": " How is this oh because this is a no",
        "tokens": [
          51540,
          1012,
          307,
          341,
          1954,
          570,
          341,
          307,
          257,
          572,
          51808
        ]
      },
      {
        "avg_logprob": -0.37888071613927043,
        "compression_ratio": 1.1123595505617978,
        "end": 6945.1,
        "id": 1517,
        "no_speech_prob": 0.000045397624489851296,
        "seek": 694310,
        "start": 6943.1,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50364,
          3301,
          50464
        ]
      },
      {
        "avg_logprob": -0.37888071613927043,
        "compression_ratio": 1.1123595505617978,
        "end": 6952.46,
        "id": 1518,
        "no_speech_prob": 0.000045397624489851296,
        "seek": 694310,
        "start": 6950.46,
        "temperature": 0,
        "text": " It's favorite in the docs with the u",
        "tokens": [
          50732,
          467,
          311,
          2954,
          294,
          264,
          45623,
          365,
          264,
          344,
          50832
        ]
      },
      {
        "avg_logprob": -0.37888071613927043,
        "compression_ratio": 1.1123595505617978,
        "end": 6963.660000000001,
        "id": 1519,
        "no_speech_prob": 0.000045397624489851296,
        "seek": 694310,
        "start": 6957.42,
        "temperature": 0,
        "text": " Yeah, but why is this happening just run this one more time",
        "tokens": [
          51080,
          865,
          11,
          457,
          983,
          307,
          341,
          2737,
          445,
          1190,
          341,
          472,
          544,
          565,
          51392
        ]
      },
      {
        "avg_logprob": -0.26804972803869914,
        "compression_ratio": 1.275229357798165,
        "end": 6966.0599999999995,
        "id": 1520,
        "no_speech_prob": 0.00009314468479715288,
        "seek": 696366,
        "start": 6964.0599999999995,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50384,
          407,
          50484
        ]
      },
      {
        "avg_logprob": -0.26804972803869914,
        "compression_ratio": 1.275229357798165,
        "end": 6973.26,
        "id": 1521,
        "no_speech_prob": 0.00009314468479715288,
        "seek": 696366,
        "start": 6971.26,
        "temperature": 0,
        "text": " I'm waiting for somebody to mention me again",
        "tokens": [
          50744,
          286,
          478,
          3806,
          337,
          2618,
          281,
          2152,
          385,
          797,
          50844
        ]
      },
      {
        "avg_logprob": -0.26804972803869914,
        "compression_ratio": 1.275229357798165,
        "end": 6985.74,
        "id": 1522,
        "no_speech_prob": 0.00009314468479715288,
        "seek": 696366,
        "start": 6982.3,
        "temperature": 0,
        "text": " Uh, oh I did I for a second I thought I froze",
        "tokens": [
          51296,
          4019,
          11,
          1954,
          286,
          630,
          286,
          337,
          257,
          1150,
          286,
          1194,
          286,
          46077,
          51468
        ]
      },
      {
        "avg_logprob": -0.26804972803869914,
        "compression_ratio": 1.275229357798165,
        "end": 6990.22,
        "id": 1523,
        "no_speech_prob": 0.00009314468479715288,
        "seek": 696366,
        "start": 6987.82,
        "temperature": 0,
        "text": " It's nice that the stream didn't freeze today",
        "tokens": [
          51572,
          467,
          311,
          1481,
          300,
          264,
          4309,
          994,
          380,
          15959,
          965,
          51692
        ]
      },
      {
        "avg_logprob": -0.31709595882531366,
        "compression_ratio": 1.5308641975308641,
        "end": 6998.46,
        "id": 1524,
        "no_speech_prob": 0.0001022996220854111,
        "seek": 699022,
        "start": 6990.9400000000005,
        "temperature": 0,
        "text": " All right, all right, um mention, okay your mention this mentioned me oh there was a heart there",
        "tokens": [
          50400,
          1057,
          558,
          11,
          439,
          558,
          11,
          1105,
          2152,
          11,
          1392,
          428,
          2152,
          341,
          2835,
          385,
          1954,
          456,
          390,
          257,
          1917,
          456,
          50776
        ]
      },
      {
        "avg_logprob": -0.31709595882531366,
        "compression_ratio": 1.5308641975308641,
        "end": 7007.1,
        "id": 1525,
        "no_speech_prob": 0.0001022996220854111,
        "seek": 699022,
        "start": 7002.3,
        "temperature": 0,
        "text": " Try mentioning me with um with like with just the word like",
        "tokens": [
          50968,
          6526,
          18315,
          385,
          365,
          1105,
          365,
          411,
          365,
          445,
          264,
          1349,
          411,
          51208
        ]
      },
      {
        "avg_logprob": -0.31709595882531366,
        "compression_ratio": 1.5308641975308641,
        "end": 7015.66,
        "id": 1526,
        "no_speech_prob": 0.0001022996220854111,
        "seek": 699022,
        "start": 7009.02,
        "temperature": 0,
        "text": " Line 38. Oh, so favorites what's wrong? It's I need to be with a u that's interesting. Okay",
        "tokens": [
          51304,
          14670,
          12843,
          13,
          876,
          11,
          370,
          16907,
          437,
          311,
          2085,
          30,
          467,
          311,
          286,
          643,
          281,
          312,
          365,
          257,
          344,
          300,
          311,
          1880,
          13,
          1033,
          51636
        ]
      },
      {
        "avg_logprob": -0.4489203190457994,
        "compression_ratio": 1.4893617021276595,
        "end": 7021.42,
        "id": 1527,
        "no_speech_prob": 0.0005357770132832229,
        "seek": 701566,
        "start": 7015.98,
        "temperature": 0,
        "text": " I love kittens. I didn't use love favorite. Oh, and I didn't use I for um",
        "tokens": [
          50380,
          286,
          959,
          47363,
          13,
          286,
          994,
          380,
          764,
          959,
          2954,
          13,
          876,
          11,
          293,
          286,
          994,
          380,
          764,
          286,
          337,
          1105,
          50652
        ]
      },
      {
        "avg_logprob": -0.4489203190457994,
        "compression_ratio": 1.4893617021276595,
        "end": 7027.5,
        "id": 1528,
        "no_speech_prob": 0.0005357770132832229,
        "seek": 701566,
        "start": 7022.22,
        "temperature": 0,
        "text": " Okay, great. So this one tried to I like turtles, but it's not going to work. Okay, great",
        "tokens": [
          50692,
          1033,
          11,
          869,
          13,
          407,
          341,
          472,
          3031,
          281,
          286,
          411,
          32422,
          11,
          457,
          309,
          311,
          406,
          516,
          281,
          589,
          13,
          1033,
          11,
          869,
          50956
        ]
      },
      {
        "avg_logprob": -0.4489203190457994,
        "compression_ratio": 1.4893617021276595,
        "end": 7035.5,
        "id": 1529,
        "no_speech_prob": 0.0005357770132832229,
        "seek": 701566,
        "start": 7033.5,
        "temperature": 0,
        "text": " Okay, all right",
        "tokens": [
          51256,
          1033,
          11,
          439,
          558,
          51356
        ]
      },
      {
        "avg_logprob": -0.4489203190457994,
        "compression_ratio": 1.4893617021276595,
        "end": 7042.78,
        "id": 1530,
        "no_speech_prob": 0.0005357770132832229,
        "seek": 701566,
        "start": 7040.62,
        "temperature": 0,
        "text": " Okay, so by the way, uh weirdo",
        "tokens": [
          51612,
          1033,
          11,
          370,
          538,
          264,
          636,
          11,
          2232,
          3657,
          78,
          51720
        ]
      },
      {
        "avg_logprob": -0.18515284729003906,
        "compression_ratio": 1.7324414715719063,
        "end": 7047.82,
        "id": 1531,
        "no_speech_prob": 0.0014779118355363607,
        "seek": 704278,
        "start": 7043.5,
        "temperature": 0,
        "text": " Okay, so by the way, uh weird awkward edit point because it didn't work",
        "tokens": [
          50400,
          1033,
          11,
          370,
          538,
          264,
          636,
          11,
          2232,
          3657,
          11411,
          8129,
          935,
          570,
          309,
          994,
          380,
          589,
          50616
        ]
      },
      {
        "avg_logprob": -0.18515284729003906,
        "compression_ratio": 1.7324414715719063,
        "end": 7055.099999999999,
        "id": 1532,
        "no_speech_prob": 0.0014779118355363607,
        "seek": 704278,
        "start": 7048.46,
        "temperature": 0,
        "text": " Some weird stuff happened, but I am now discovered through the thankful helpful people in the chat that I have a few errors here",
        "tokens": [
          50648,
          2188,
          3657,
          1507,
          2011,
          11,
          457,
          286,
          669,
          586,
          6941,
          807,
          264,
          13611,
          4961,
          561,
          294,
          264,
          5081,
          300,
          286,
          362,
          257,
          1326,
          13603,
          510,
          50980
        ]
      },
      {
        "avg_logprob": -0.18515284729003906,
        "compression_ratio": 1.7324414715719063,
        "end": 7061.099999999999,
        "id": 1533,
        "no_speech_prob": 0.0014779118355363607,
        "seek": 704278,
        "start": 7055.34,
        "temperature": 0,
        "text": " So number one is let's go back to the api for a second and we can see here that I didn't pay close attention",
        "tokens": [
          50992,
          407,
          1230,
          472,
          307,
          718,
          311,
          352,
          646,
          281,
          264,
          1882,
          72,
          337,
          257,
          1150,
          293,
          321,
          393,
          536,
          510,
          300,
          286,
          994,
          380,
          1689,
          1998,
          3202,
          51280
        ]
      },
      {
        "avg_logprob": -0.18515284729003906,
        "compression_ratio": 1.7324414715719063,
        "end": 7066.94,
        "id": 1534,
        "no_speech_prob": 0.0014779118355363607,
        "seek": 704278,
        "start": 7061.42,
        "temperature": 0,
        "text": " It's actually spelled with a u here id favorite. So this seems kind of important that I spell it correctly",
        "tokens": [
          51296,
          467,
          311,
          767,
          34388,
          365,
          257,
          344,
          510,
          4496,
          2954,
          13,
          407,
          341,
          2544,
          733,
          295,
          1021,
          300,
          286,
          9827,
          309,
          8944,
          51572
        ]
      },
      {
        "avg_logprob": -0.18515284729003906,
        "compression_ratio": 1.7324414715719063,
        "end": 7072.0599999999995,
        "id": 1535,
        "no_speech_prob": 0.0014779118355363607,
        "seek": 704278,
        "start": 7067.179999999999,
        "temperature": 0,
        "text": " So let me fix that here. Oh, but that's not actually the important place. The important place is here",
        "tokens": [
          51584,
          407,
          718,
          385,
          3191,
          300,
          510,
          13,
          876,
          11,
          457,
          300,
          311,
          406,
          767,
          264,
          1021,
          1081,
          13,
          440,
          1021,
          1081,
          307,
          510,
          51828
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7074.94,
        "id": 1536,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7072.94,
        "temperature": 0,
        "text": " and then a couple other things I want to",
        "tokens": [
          50372,
          293,
          550,
          257,
          1916,
          661,
          721,
          286,
          528,
          281,
          50472
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7077.82,
        "id": 1537,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7075.82,
        "temperature": 0,
        "text": " Use a flag for I",
        "tokens": [
          50516,
          8278,
          257,
          7166,
          337,
          286,
          50616
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7079.82,
        "id": 1538,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7078.46,
        "temperature": 0,
        "text": " for um",
        "tokens": [
          50648,
          337,
          1105,
          50716
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7081.639999999999,
        "id": 1539,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7079.82,
        "temperature": 0,
        "text": " for a case",
        "tokens": [
          50716,
          337,
          257,
          1389,
          50807
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7085.9,
        "id": 1540,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7081.639999999999,
        "temperature": 0,
        "text": " Insensitivity in other words you can and also the u should be optional here. That doesn't really matter",
        "tokens": [
          50807,
          9442,
          694,
          270,
          4253,
          294,
          661,
          2283,
          291,
          393,
          293,
          611,
          264,
          344,
          820,
          312,
          17312,
          510,
          13,
          663,
          1177,
          380,
          534,
          1871,
          51020
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7088.54,
        "id": 1541,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7085.98,
        "temperature": 0,
        "text": " So u is optional so you can say like favorite",
        "tokens": [
          51024,
          407,
          344,
          307,
          17312,
          370,
          291,
          393,
          584,
          411,
          2954,
          51152
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7093.98,
        "id": 1542,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7088.54,
        "temperature": 0,
        "text": " I don't still not sure if this is the right kind of heart that normally but now this should fix that",
        "tokens": [
          51152,
          286,
          500,
          380,
          920,
          406,
          988,
          498,
          341,
          307,
          264,
          558,
          733,
          295,
          1917,
          300,
          5646,
          457,
          586,
          341,
          820,
          3191,
          300,
          51424
        ]
      },
      {
        "avg_logprob": -0.21540449315851384,
        "compression_ratio": 1.707112970711297,
        "end": 7098.94,
        "id": 1543,
        "no_speech_prob": 7.811457294337742e-7,
        "seek": 707278,
        "start": 7094.62,
        "temperature": 0,
        "text": " That I should now actually be favoriting things. So we're going to try this again",
        "tokens": [
          51456,
          663,
          286,
          820,
          586,
          767,
          312,
          2294,
          1748,
          721,
          13,
          407,
          321,
          434,
          516,
          281,
          853,
          341,
          797,
          51672
        ]
      },
      {
        "avg_logprob": -0.2519741588168674,
        "compression_ratio": 1.3409090909090908,
        "end": 7105.28,
        "id": 1544,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 709894,
        "start": 7099.66,
        "temperature": 0,
        "text": " I'm going to go back to here and i'm going to run this bot again and i'm going to wait",
        "tokens": [
          50400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          510,
          293,
          741,
          478,
          516,
          281,
          1190,
          341,
          10592,
          797,
          293,
          741,
          478,
          516,
          281,
          1699,
          50681
        ]
      },
      {
        "avg_logprob": -0.2519741588168674,
        "compression_ratio": 1.3409090909090908,
        "end": 7118.299999999999,
        "id": 1545,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 709894,
        "start": 7116.299999999999,
        "temperature": 0,
        "text": " Oh line 38 someone's telling me",
        "tokens": [
          51232,
          876,
          1622,
          12843,
          1580,
          311,
          3585,
          385,
          51332
        ]
      },
      {
        "avg_logprob": -0.6530995491223458,
        "compression_ratio": 1.0909090909090908,
        "end": 7120.3,
        "id": 1546,
        "no_speech_prob": 0.0002653018746059388,
        "seek": 711830,
        "start": 7118.3,
        "temperature": 0,
        "text": " What's wrong with line 38",
        "tokens": [
          50364,
          708,
          311,
          2085,
          365,
          1622,
          12843,
          50464
        ]
      },
      {
        "avg_logprob": -0.6530995491223458,
        "compression_ratio": 1.0909090909090908,
        "end": 7136.14,
        "id": 1547,
        "no_speech_prob": 0.0002653018746059388,
        "seek": 711830,
        "start": 7132.54,
        "temperature": 0,
        "text": " No, um, I want the id of the thing of",
        "tokens": [
          51076,
          883,
          11,
          1105,
          11,
          286,
          528,
          264,
          4496,
          295,
          264,
          551,
          295,
          51256
        ]
      },
      {
        "avg_logprob": -0.6530995491223458,
        "compression_ratio": 1.0909090909090908,
        "end": 7141.34,
        "id": 1548,
        "no_speech_prob": 0.0002653018746059388,
        "seek": 711830,
        "start": 7138.3,
        "temperature": 0,
        "text": " Of this event. Oh, I see what you mean. Yeah",
        "tokens": [
          51364,
          2720,
          341,
          2280,
          13,
          876,
          11,
          286,
          536,
          437,
          291,
          914,
          13,
          865,
          51516
        ]
      },
      {
        "avg_logprob": -0.876243860581342,
        "compression_ratio": 1.9328859060402686,
        "end": 7144.3,
        "id": 1549,
        "no_speech_prob": 0.0015731024323031306,
        "seek": 714134,
        "start": 7142.3,
        "temperature": 0,
        "text": " Oh look",
        "tokens": [
          50412,
          876,
          574,
          50512
        ]
      },
      {
        "avg_logprob": -0.876243860581342,
        "compression_ratio": 1.9328859060402686,
        "end": 7149.1,
        "id": 1550,
        "no_speech_prob": 0.0015731024323031306,
        "seek": 714134,
        "start": 7147.1,
        "temperature": 0,
        "text": " So this appears to be working",
        "tokens": [
          50652,
          407,
          341,
          7038,
          281,
          312,
          1364,
          50752
        ]
      },
      {
        "avg_logprob": -0.876243860581342,
        "compression_ratio": 1.9328859060402686,
        "end": 7158.3,
        "id": 1551,
        "no_speech_prob": 0.0015731024323031306,
        "seek": 714134,
        "start": 7151.900000000001,
        "temperature": 0,
        "text": " Okay, so we can see oh oh my god, why are my settings not being retained on this computer?",
        "tokens": [
          50892,
          1033,
          11,
          370,
          321,
          393,
          536,
          1954,
          1954,
          452,
          3044,
          11,
          983,
          366,
          452,
          6257,
          406,
          885,
          33438,
          322,
          341,
          3820,
          30,
          51212
        ]
      },
      {
        "avg_logprob": -0.876243860581342,
        "compression_ratio": 1.9328859060402686,
        "end": 7161.66,
        "id": 1552,
        "no_speech_prob": 0.0015731024323031306,
        "seek": 714134,
        "start": 7159.18,
        "temperature": 0,
        "text": " So I'm going to go back to here and I'm going to run this again",
        "tokens": [
          51256,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          510,
          293,
          286,
          478,
          516,
          281,
          1190,
          341,
          797,
          51380
        ]
      },
      {
        "avg_logprob": -0.876243860581342,
        "compression_ratio": 1.9328859060402686,
        "end": 7166.14,
        "id": 1553,
        "no_speech_prob": 0.0015731024323031306,
        "seek": 714134,
        "start": 7162.22,
        "temperature": 0,
        "text": " And I'm going to run this again. So I'm going to run this again. So I'm going to run this again",
        "tokens": [
          51408,
          400,
          286,
          478,
          516,
          281,
          1190,
          341,
          797,
          13,
          407,
          286,
          478,
          516,
          281,
          1190,
          341,
          797,
          13,
          407,
          286,
          478,
          516,
          281,
          1190,
          341,
          797,
          51604
        ]
      },
      {
        "avg_logprob": -0.2755125716880516,
        "compression_ratio": 1.3805970149253732,
        "end": 7170.8,
        "id": 1554,
        "no_speech_prob": 0.00045120445429347456,
        "seek": 716614,
        "start": 7166.22,
        "temperature": 0,
        "text": " Oh my god, why are my settings not being retained on this computer?",
        "tokens": [
          50368,
          876,
          452,
          3044,
          11,
          983,
          366,
          452,
          6257,
          406,
          885,
          33438,
          322,
          341,
          3820,
          30,
          50597
        ]
      },
      {
        "avg_logprob": -0.2755125716880516,
        "compression_ratio": 1.3805970149253732,
        "end": 7182.4800000000005,
        "id": 1555,
        "no_speech_prob": 0.00045120445429347456,
        "seek": 716614,
        "start": 7175.18,
        "temperature": 0,
        "text": " All right, just give me a second here where is that thing where it doesn't oh, yes, here we go. Okay",
        "tokens": [
          50816,
          1057,
          558,
          11,
          445,
          976,
          385,
          257,
          1150,
          510,
          689,
          307,
          300,
          551,
          689,
          309,
          1177,
          380,
          1954,
          11,
          2086,
          11,
          510,
          321,
          352,
          13,
          1033,
          51181
        ]
      },
      {
        "avg_logprob": -0.2755125716880516,
        "compression_ratio": 1.3805970149253732,
        "end": 7193.9800000000005,
        "id": 1556,
        "no_speech_prob": 0.00045120445429347456,
        "seek": 716614,
        "start": 7191.9800000000005,
        "temperature": 0,
        "text": " All right, so um",
        "tokens": [
          51656,
          1057,
          558,
          11,
          370,
          1105,
          51756
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7199.259999999999,
        "id": 1557,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7194.62,
        "temperature": 0,
        "text": " Okay, i'm back a lot of people mentioned me let's go take a look at the actual timeline",
        "tokens": [
          50396,
          1033,
          11,
          741,
          478,
          646,
          257,
          688,
          295,
          561,
          2835,
          385,
          718,
          311,
          352,
          747,
          257,
          574,
          412,
          264,
          3539,
          12933,
          50628
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7203.419999999999,
        "id": 1558,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7199.74,
        "temperature": 0,
        "text": " Um, we and we can see that it is favoriting and we are getting an id out",
        "tokens": [
          50652,
          3301,
          11,
          321,
          293,
          321,
          393,
          536,
          300,
          309,
          307,
          2294,
          1748,
          293,
          321,
          366,
          1242,
          364,
          4496,
          484,
          50836
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7207.66,
        "id": 1559,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7203.98,
        "temperature": 0,
        "text": " Um, you can see that this id is different than this id and some people are asking about that",
        "tokens": [
          50864,
          3301,
          11,
          291,
          393,
          536,
          300,
          341,
          4496,
          307,
          819,
          813,
          341,
          4496,
          293,
          512,
          561,
          366,
          3365,
          466,
          300,
          51048
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7209.9,
        "id": 1560,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7207.66,
        "temperature": 0,
        "text": " I will I will let me mention that in the chat in a second",
        "tokens": [
          51048,
          286,
          486,
          286,
          486,
          718,
          385,
          2152,
          300,
          294,
          264,
          5081,
          294,
          257,
          1150,
          51160
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7212.379999999999,
        "id": 1561,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7210.379999999999,
        "temperature": 0,
        "text": " um in a second, but let me go here so",
        "tokens": [
          51184,
          1105,
          294,
          257,
          1150,
          11,
          457,
          718,
          385,
          352,
          510,
          370,
          51284
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7213.82,
        "id": 1562,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7212.86,
        "temperature": 0,
        "text": " uh",
        "tokens": [
          51308,
          2232,
          51356
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7216.62,
        "id": 1563,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7213.82,
        "temperature": 0,
        "text": " You're my favorite. Hmm. How come it didn't?",
        "tokens": [
          51356,
          509,
          434,
          452,
          2954,
          13,
          8239,
          13,
          1012,
          808,
          309,
          994,
          380,
          30,
          51496
        ]
      },
      {
        "avg_logprob": -0.1915140432469985,
        "compression_ratio": 1.7969348659003832,
        "end": 7221.839999999999,
        "id": 1564,
        "no_speech_prob": 0.00010720746649894863,
        "seek": 719398,
        "start": 7218.459999999999,
        "temperature": 0,
        "text": " Ah, there we go. I just had to refresh so we can see this got favorited",
        "tokens": [
          51588,
          2438,
          11,
          456,
          321,
          352,
          13,
          286,
          445,
          632,
          281,
          15134,
          370,
          321,
          393,
          536,
          341,
          658,
          2294,
          1226,
          51757
        ]
      },
      {
        "avg_logprob": -0.24158397797615297,
        "compression_ratio": 1.8341708542713568,
        "end": 7224.96,
        "id": 1565,
        "no_speech_prob": 0.0026729584205895662,
        "seek": 722184,
        "start": 7222.400000000001,
        "temperature": 0,
        "text": " Because it has favorite in it this got favorited because it has a heart",
        "tokens": [
          50392,
          1436,
          309,
          575,
          2954,
          294,
          309,
          341,
          658,
          2294,
          1226,
          570,
          309,
          575,
          257,
          1917,
          50520
        ]
      },
      {
        "avg_logprob": -0.24158397797615297,
        "compression_ratio": 1.8341708542713568,
        "end": 7230.24,
        "id": 1566,
        "no_speech_prob": 0.0026729584205895662,
        "seek": 722184,
        "start": 7225.84,
        "temperature": 0,
        "text": " Uh, this got favorited because it has the word like i'm looking for one that doesn't have",
        "tokens": [
          50564,
          4019,
          11,
          341,
          658,
          2294,
          1226,
          570,
          309,
          575,
          264,
          1349,
          411,
          741,
          478,
          1237,
          337,
          472,
          300,
          1177,
          380,
          362,
          50784
        ]
      },
      {
        "avg_logprob": -0.24158397797615297,
        "compression_ratio": 1.8341708542713568,
        "end": 7234.16,
        "id": 1567,
        "no_speech_prob": 0.0026729584205895662,
        "seek": 722184,
        "start": 7230.88,
        "temperature": 0,
        "text": " This must have been from a while ago when it wasn't working, but we can see here now",
        "tokens": [
          50816,
          639,
          1633,
          362,
          668,
          490,
          257,
          1339,
          2057,
          562,
          309,
          2067,
          380,
          1364,
          11,
          457,
          321,
          393,
          536,
          510,
          586,
          50980
        ]
      },
      {
        "avg_logprob": -0.24158397797615297,
        "compression_ratio": 1.8341708542713568,
        "end": 7236.88,
        "id": 1568,
        "no_speech_prob": 0.0026729584205895662,
        "seek": 722184,
        "start": 7234.72,
        "temperature": 0,
        "text": " um, please like please clap",
        "tokens": [
          51008,
          1105,
          11,
          1767,
          411,
          1767,
          20760,
          51116
        ]
      },
      {
        "avg_logprob": -0.24158397797615297,
        "compression_ratio": 1.8341708542713568,
        "end": 7239.52,
        "id": 1569,
        "no_speech_prob": 0.0026729584205895662,
        "seek": 722184,
        "start": 7238.08,
        "temperature": 0,
        "text": " so, please",
        "tokens": [
          51176,
          370,
          11,
          1767,
          51248
        ]
      },
      {
        "avg_logprob": -0.24158397797615297,
        "compression_ratio": 1.8341708542713568,
        "end": 7243.860000000001,
        "id": 1570,
        "no_speech_prob": 0.0026729584205895662,
        "seek": 722184,
        "start": 7239.52,
        "temperature": 0,
        "text": " Uh mention me without using like favorite or heart to make sure that also works",
        "tokens": [
          51248,
          4019,
          2152,
          385,
          1553,
          1228,
          411,
          2954,
          420,
          1917,
          281,
          652,
          988,
          300,
          611,
          1985,
          51465
        ]
      },
      {
        "avg_logprob": -0.37840274284625874,
        "compression_ratio": 1.0657894736842106,
        "end": 7254.4800000000005,
        "id": 1571,
        "no_speech_prob": 0.0006878284621052444,
        "seek": 725184,
        "start": 7252.4800000000005,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50396,
          407,
          50496
        ]
      },
      {
        "avg_logprob": -0.37840274284625874,
        "compression_ratio": 1.0657894736842106,
        "end": 7262.58,
        "id": 1572,
        "no_speech_prob": 0.0006878284621052444,
        "seek": 725184,
        "start": 7259.84,
        "temperature": 0,
        "text": " I'm just going to wait this will add we'll add this waiting part out",
        "tokens": [
          50764,
          286,
          478,
          445,
          516,
          281,
          1699,
          341,
          486,
          909,
          321,
          603,
          909,
          341,
          3806,
          644,
          484,
          50901
        ]
      },
      {
        "avg_logprob": -0.37840274284625874,
        "compression_ratio": 1.0657894736842106,
        "end": 7268.8,
        "id": 1573,
        "no_speech_prob": 0.0006878284621052444,
        "seek": 725184,
        "start": 7266.8,
        "temperature": 0,
        "text": " It's 4 30",
        "tokens": [
          51112,
          467,
          311,
          1017,
          2217,
          51212
        ]
      },
      {
        "avg_logprob": -0.3133507051329682,
        "compression_ratio": 1.4050632911392404,
        "end": 7270.8,
        "id": 1574,
        "no_speech_prob": 0.00046551963896490633,
        "seek": 726880,
        "start": 7268.8,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50364,
          407,
          50464
        ]
      },
      {
        "avg_logprob": -0.3133507051329682,
        "compression_ratio": 1.4050632911392404,
        "end": 7283.4400000000005,
        "id": 1575,
        "no_speech_prob": 0.00046551963896490633,
        "seek": 726880,
        "start": 7280.400000000001,
        "temperature": 0,
        "text": " Okay, i'm back and we can see here that k weakman",
        "tokens": [
          50944,
          1033,
          11,
          741,
          478,
          646,
          293,
          321,
          393,
          536,
          510,
          300,
          350,
          5336,
          1601,
          51096
        ]
      },
      {
        "avg_logprob": -0.3133507051329682,
        "compression_ratio": 1.4050632911392404,
        "end": 7289.28,
        "id": 1576,
        "no_speech_prob": 0.00046551963896490633,
        "seek": 726880,
        "start": 7284,
        "temperature": 0,
        "text": " Um wrote coding train bot choo choo. And if even if I refresh this page, it was not favorited",
        "tokens": [
          51124,
          3301,
          4114,
          17720,
          3847,
          10592,
          1586,
          78,
          1586,
          78,
          13,
          400,
          498,
          754,
          498,
          286,
          15134,
          341,
          3028,
          11,
          309,
          390,
          406,
          2294,
          1226,
          51388
        ]
      },
      {
        "avg_logprob": -0.3133507051329682,
        "compression_ratio": 1.4050632911392404,
        "end": 7295.4400000000005,
        "id": 1577,
        "no_speech_prob": 0.00046551963896490633,
        "seek": 726880,
        "start": 7289.4400000000005,
        "temperature": 0,
        "text": " So it is working only now it should be only if uh, if I go back to the code",
        "tokens": [
          51396,
          407,
          309,
          307,
          1364,
          787,
          586,
          309,
          820,
          312,
          787,
          498,
          2232,
          11,
          498,
          286,
          352,
          646,
          281,
          264,
          3089,
          51696
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7300.08,
        "id": 1578,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7296,
        "temperature": 0,
        "text": " Only if this regular expression matches will I favorite?",
        "tokens": [
          50392,
          5686,
          498,
          341,
          3890,
          6114,
          10676,
          486,
          286,
          2954,
          30,
          50596
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7300.5599999999995,
        "id": 1579,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7300.16,
        "temperature": 0,
        "text": " All right",
        "tokens": [
          50600,
          1057,
          558,
          50620
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7301.12,
        "id": 1580,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7300.5599999999995,
        "temperature": 0,
        "text": " and by the way",
        "tokens": [
          50620,
          293,
          538,
          264,
          636,
          50648
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7304.799999999999,
        "id": 1581,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7301.12,
        "temperature": 0,
        "text": " We could really quickly now just also like there's probably a nicer way to do this",
        "tokens": [
          50648,
          492,
          727,
          534,
          2661,
          586,
          445,
          611,
          411,
          456,
          311,
          1391,
          257,
          22842,
          636,
          281,
          360,
          341,
          50832
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7309.599999999999,
        "id": 1582,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7305.04,
        "temperature": 0,
        "text": " But i'm just going to really quickly like copy paste this whole thing and i'm going to say",
        "tokens": [
          50844,
          583,
          741,
          478,
          445,
          516,
          281,
          534,
          2661,
          411,
          5055,
          9163,
          341,
          1379,
          551,
          293,
          741,
          478,
          516,
          281,
          584,
          51072
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7312.799999999999,
        "id": 1583,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7310.799999999999,
        "temperature": 0,
        "text": " boost or",
        "tokens": [
          51132,
          9194,
          420,
          51232
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7315.5199999999995,
        "id": 1584,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7313.419999999999,
        "temperature": 0,
        "text": " Reblog or um",
        "tokens": [
          51263,
          1300,
          65,
          4987,
          420,
          1105,
          51368
        ]
      },
      {
        "avg_logprob": -0.2619272522304369,
        "compression_ratio": 1.5662100456621004,
        "end": 7321.839999999999,
        "id": 1585,
        "no_speech_prob": 0.000007646525773452595,
        "seek": 729544,
        "start": 7316.24,
        "temperature": 0,
        "text": " Or retweet even or let's get another emoji in here control option",
        "tokens": [
          51404,
          1610,
          1533,
          10354,
          754,
          420,
          718,
          311,
          483,
          1071,
          31595,
          294,
          510,
          1969,
          3614,
          51684
        ]
      },
      {
        "avg_logprob": -0.2459021742625903,
        "compression_ratio": 1.68944099378882,
        "end": 7325.14,
        "id": 1586,
        "no_speech_prob": 0.0003799793485086411,
        "seek": 732184,
        "start": 7322.24,
        "temperature": 0,
        "text": " Uh, let's see if you use a train emoji",
        "tokens": [
          50384,
          4019,
          11,
          718,
          311,
          536,
          498,
          291,
          764,
          257,
          3847,
          31595,
          50529
        ]
      },
      {
        "avg_logprob": -0.2459021742625903,
        "compression_ratio": 1.68944099378882,
        "end": 7331.2,
        "id": 1587,
        "no_speech_prob": 0.0003799793485086411,
        "seek": 732184,
        "start": 7326.96,
        "temperature": 0,
        "text": " Or if you use the train emoji then we will uh reblog",
        "tokens": [
          50620,
          1610,
          498,
          291,
          764,
          264,
          3847,
          31595,
          550,
          321,
          486,
          2232,
          12970,
          4987,
          50832
        ]
      },
      {
        "avg_logprob": -0.2459021742625903,
        "compression_ratio": 1.68944099378882,
        "end": 7335.46,
        "id": 1588,
        "no_speech_prob": 0.0003799793485086411,
        "seek": 732184,
        "start": 7331.84,
        "temperature": 0,
        "text": " So now if I if I quickly run this again, i'll make this regex2",
        "tokens": [
          50864,
          407,
          586,
          498,
          286,
          498,
          286,
          2661,
          1190,
          341,
          797,
          11,
          741,
          603,
          652,
          341,
          319,
          432,
          87,
          17,
          51045
        ]
      },
      {
        "avg_logprob": -0.2459021742625903,
        "compression_ratio": 1.68944099378882,
        "end": 7339.52,
        "id": 1589,
        "no_speech_prob": 0.0003799793485086411,
        "seek": 732184,
        "start": 7336.64,
        "temperature": 0,
        "text": " um if regex2 and I don't need to",
        "tokens": [
          51104,
          1105,
          498,
          319,
          432,
          87,
          17,
          293,
          286,
          500,
          380,
          643,
          281,
          51248
        ]
      },
      {
        "avg_logprob": -0.2459021742625903,
        "compression_ratio": 1.68944099378882,
        "end": 7342.72,
        "id": 1590,
        "no_speech_prob": 0.0003799793485086411,
        "seek": 732184,
        "start": 7340.72,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51308,
          1105,
          51408
        ]
      },
      {
        "avg_logprob": -0.2459021742625903,
        "compression_ratio": 1.68944099378882,
        "end": 7345.84,
        "id": 1591,
        "no_speech_prob": 0.0003799793485086411,
        "seek": 732184,
        "start": 7342.8,
        "temperature": 0,
        "text": " I don't need to get the content or the id anymore",
        "tokens": [
          51412,
          286,
          500,
          380,
          643,
          281,
          483,
          264,
          2701,
          420,
          264,
          4496,
          3602,
          51564
        ]
      },
      {
        "avg_logprob": -0.2459021742625903,
        "compression_ratio": 1.68944099378882,
        "end": 7348.4800000000005,
        "id": 1592,
        "no_speech_prob": 0.0003799793485086411,
        "seek": 732184,
        "start": 7346.4800000000005,
        "temperature": 0,
        "text": " Um, and I don't need this again",
        "tokens": [
          51596,
          3301,
          11,
          293,
          286,
          500,
          380,
          643,
          341,
          797,
          51696
        ]
      },
      {
        "avg_logprob": -0.28435856280940597,
        "compression_ratio": 1.7186147186147187,
        "end": 7352.08,
        "id": 1593,
        "no_speech_prob": 0.0018675492610782385,
        "seek": 734848,
        "start": 7348.799999999999,
        "temperature": 0,
        "text": " Um, so now this is just and I probably it probably makes sense for me to actually",
        "tokens": [
          50380,
          3301,
          11,
          370,
          586,
          341,
          307,
          445,
          293,
          286,
          1391,
          309,
          1391,
          1669,
          2020,
          337,
          385,
          281,
          767,
          50544
        ]
      },
      {
        "avg_logprob": -0.28435856280940597,
        "compression_ratio": 1.7186147186147187,
        "end": 7360.879999999999,
        "id": 1594,
        "no_speech_prob": 0.0018675492610782385,
        "seek": 734848,
        "start": 7352.879999999999,
        "temperature": 0,
        "text": " Put this up. Actually, you know, they could both happen. So here now I this will boost anyone that says boost reblog retweet",
        "tokens": [
          50584,
          4935,
          341,
          493,
          13,
          5135,
          11,
          291,
          458,
          11,
          436,
          727,
          1293,
          1051,
          13,
          407,
          510,
          586,
          286,
          341,
          486,
          9194,
          2878,
          300,
          1619,
          9194,
          12970,
          4987,
          1533,
          10354,
          50984
        ]
      },
      {
        "avg_logprob": -0.28435856280940597,
        "compression_ratio": 1.7186147186147187,
        "end": 7366.339999999999,
        "id": 1595,
        "no_speech_prob": 0.0018675492610782385,
        "seek": 734848,
        "start": 7361.04,
        "temperature": 0,
        "text": " Or the train and and miller mentioning this is a mistake here. So this data.id",
        "tokens": [
          50992,
          1610,
          264,
          3847,
          293,
          293,
          1728,
          260,
          18315,
          341,
          307,
          257,
          6146,
          510,
          13,
          407,
          341,
          1412,
          13,
          327,
          51257
        ]
      },
      {
        "avg_logprob": -0.28435856280940597,
        "compression_ratio": 1.7186147186147187,
        "end": 7370.08,
        "id": 1596,
        "no_speech_prob": 0.0018675492610782385,
        "seek": 734848,
        "start": 7367.2,
        "temperature": 0,
        "text": " This is actually um, this is the id",
        "tokens": [
          51300,
          639,
          307,
          767,
          1105,
          11,
          341,
          307,
          264,
          4496,
          51444
        ]
      },
      {
        "avg_logprob": -0.28435856280940597,
        "compression_ratio": 1.7186147186147187,
        "end": 7376,
        "id": 1597,
        "no_speech_prob": 0.0018675492610782385,
        "seek": 734848,
        "start": 7370.639999999999,
        "temperature": 0,
        "text": " Of this the actual favorited action which everything every action has an id",
        "tokens": [
          51472,
          2720,
          341,
          264,
          3539,
          2294,
          1226,
          3069,
          597,
          1203,
          633,
          3069,
          575,
          364,
          4496,
          51740
        ]
      },
      {
        "avg_logprob": -0.21322356737576997,
        "compression_ratio": 1.6425531914893616,
        "end": 7378.32,
        "id": 1598,
        "no_speech_prob": 0.00005307458559400402,
        "seek": 737600,
        "start": 7376.32,
        "temperature": 0,
        "text": " So if I if somebody",
        "tokens": [
          50380,
          407,
          498,
          286,
          498,
          2618,
          50480
        ]
      },
      {
        "avg_logprob": -0.21322356737576997,
        "compression_ratio": 1.6425531914893616,
        "end": 7381.52,
        "id": 1599,
        "no_speech_prob": 0.00005307458559400402,
        "seek": 737600,
        "start": 7378.4,
        "temperature": 0,
        "text": " Message that mention has an id which I captured up here",
        "tokens": [
          50484,
          45947,
          300,
          2152,
          575,
          364,
          4496,
          597,
          286,
          11828,
          493,
          510,
          50640
        ]
      },
      {
        "avg_logprob": -0.21322356737576997,
        "compression_ratio": 1.6425531914893616,
        "end": 7386.24,
        "id": 1600,
        "no_speech_prob": 0.00005307458559400402,
        "seek": 737600,
        "start": 7381.92,
        "temperature": 0,
        "text": " So but this is the id of the actual act of favoriting it. So I don't know debugging wise",
        "tokens": [
          50660,
          407,
          457,
          341,
          307,
          264,
          4496,
          295,
          264,
          3539,
          605,
          295,
          2294,
          1748,
          309,
          13,
          407,
          286,
          500,
          380,
          458,
          45592,
          10829,
          50876
        ]
      },
      {
        "avg_logprob": -0.21322356737576997,
        "compression_ratio": 1.6425531914893616,
        "end": 7389.2,
        "id": 1601,
        "no_speech_prob": 0.00005307458559400402,
        "seek": 737600,
        "start": 7386.24,
        "temperature": 0,
        "text": " I don't know what's more important to display. I could display both of them",
        "tokens": [
          50876,
          286,
          500,
          380,
          458,
          437,
          311,
          544,
          1021,
          281,
          4674,
          13,
          286,
          727,
          4674,
          1293,
          295,
          552,
          51024
        ]
      },
      {
        "avg_logprob": -0.21322356737576997,
        "compression_ratio": 1.6425531914893616,
        "end": 7394.42,
        "id": 1602,
        "no_speech_prob": 0.00005307458559400402,
        "seek": 737600,
        "start": 7390.72,
        "temperature": 0,
        "text": " Um, but you'll see those are two different things and this should say reblogged",
        "tokens": [
          51100,
          3301,
          11,
          457,
          291,
          603,
          536,
          729,
          366,
          732,
          819,
          721,
          293,
          341,
          820,
          584,
          12970,
          4987,
          3004,
          51285
        ]
      },
      {
        "avg_logprob": -0.21322356737576997,
        "compression_ratio": 1.6425531914893616,
        "end": 7399.04,
        "id": 1603,
        "no_speech_prob": 0.00005307458559400402,
        "seek": 737600,
        "start": 7395.92,
        "temperature": 0,
        "text": " And this should say favorited so let's now",
        "tokens": [
          51360,
          400,
          341,
          820,
          584,
          2294,
          1226,
          370,
          718,
          311,
          586,
          51516
        ]
      },
      {
        "avg_logprob": -0.21322356737576997,
        "compression_ratio": 1.6425531914893616,
        "end": 7405.04,
        "id": 1604,
        "no_speech_prob": 0.00005307458559400402,
        "seek": 737600,
        "start": 7403.04,
        "temperature": 0,
        "text": " Do this and here we go",
        "tokens": [
          51716,
          1144,
          341,
          293,
          510,
          321,
          352,
          51816
        ]
      },
      {
        "avg_logprob": -0.2834168076515198,
        "compression_ratio": 0.9152542372881356,
        "end": 7410.18,
        "id": 1605,
        "no_speech_prob": 0.00003071681203437038,
        "seek": 740600,
        "start": 7406,
        "temperature": 0,
        "text": " Everybody you can now ask to be favorited or reblogged",
        "tokens": [
          50379,
          7646,
          291,
          393,
          586,
          1029,
          281,
          312,
          2294,
          1226,
          420,
          12970,
          4987,
          3004,
          50573
        ]
      },
      {
        "avg_logprob": -0.25557507043597344,
        "compression_ratio": 1.5310734463276836,
        "end": 7438.72,
        "id": 1606,
        "no_speech_prob": 0.000035912868042942137,
        "seek": 743600,
        "start": 7436.72,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50400,
          407,
          50500
        ]
      },
      {
        "avg_logprob": -0.25557507043597344,
        "compression_ratio": 1.5310734463276836,
        "end": 7448.96,
        "id": 1607,
        "no_speech_prob": 0.000035912868042942137,
        "seek": 743600,
        "start": 7444.16,
        "temperature": 0,
        "text": " All right, a lot of mentions came in you can see some things are being favorited and reblogged",
        "tokens": [
          50772,
          1057,
          558,
          11,
          257,
          688,
          295,
          23844,
          1361,
          294,
          291,
          393,
          536,
          512,
          721,
          366,
          885,
          2294,
          1226,
          293,
          12970,
          4987,
          3004,
          51012
        ]
      },
      {
        "avg_logprob": -0.25557507043597344,
        "compression_ratio": 1.5310734463276836,
        "end": 7452.34,
        "id": 1608,
        "no_speech_prob": 0.000035912868042942137,
        "seek": 743600,
        "start": 7449.2,
        "temperature": 0,
        "text": " Some things are just being reblogged. Let's go take a look at the timeline",
        "tokens": [
          51024,
          2188,
          721,
          366,
          445,
          885,
          12970,
          4987,
          3004,
          13,
          961,
          311,
          352,
          747,
          257,
          574,
          412,
          264,
          12933,
          51181
        ]
      },
      {
        "avg_logprob": -0.25557507043597344,
        "compression_ratio": 1.5310734463276836,
        "end": 7454.48,
        "id": 1609,
        "no_speech_prob": 0.000035912868042942137,
        "seek": 743600,
        "start": 7453.2,
        "temperature": 0,
        "text": " and",
        "tokens": [
          51224,
          293,
          51288
        ]
      },
      {
        "avg_logprob": -0.25557507043597344,
        "compression_ratio": 1.5310734463276836,
        "end": 7456.24,
        "id": 1610,
        "no_speech_prob": 0.000035912868042942137,
        "seek": 743600,
        "start": 7454.48,
        "temperature": 0,
        "text": " uh",
        "tokens": [
          51288,
          2232,
          51376
        ]
      },
      {
        "avg_logprob": -0.25557507043597344,
        "compression_ratio": 1.5310734463276836,
        "end": 7458.48,
        "id": 1611,
        "no_speech_prob": 0.000035912868042942137,
        "seek": 743600,
        "start": 7456.24,
        "temperature": 0,
        "text": " Let's look at this. Uh, did you know?",
        "tokens": [
          51376,
          961,
          311,
          574,
          412,
          341,
          13,
          4019,
          11,
          630,
          291,
          458,
          30,
          51488
        ]
      },
      {
        "avg_logprob": -0.25557507043597344,
        "compression_ratio": 1.5310734463276836,
        "end": 7463.2,
        "id": 1612,
        "no_speech_prob": 0.000035912868042942137,
        "seek": 743600,
        "start": 7459.2,
        "temperature": 0,
        "text": " Hmm. I don't oh, yeah, I love trains this got boosted",
        "tokens": [
          51524,
          8239,
          13,
          286,
          500,
          380,
          1954,
          11,
          1338,
          11,
          286,
          959,
          16329,
          341,
          658,
          9194,
          292,
          51724
        ]
      },
      {
        "avg_logprob": -0.30636361750160773,
        "compression_ratio": 1.6491228070175439,
        "end": 7466.099999999999,
        "id": 1613,
        "no_speech_prob": 0.00013135059271007776,
        "seek": 746320,
        "start": 7463.84,
        "temperature": 0,
        "text": " Uh coding train bot that got boosted",
        "tokens": [
          50396,
          4019,
          17720,
          3847,
          10592,
          300,
          658,
          9194,
          292,
          50509
        ]
      },
      {
        "avg_logprob": -0.30636361750160773,
        "compression_ratio": 1.6491228070175439,
        "end": 7468.32,
        "id": 1614,
        "no_speech_prob": 0.00013135059271007776,
        "seek": 746320,
        "start": 7466.639999999999,
        "temperature": 0,
        "text": " Uh, and this one",
        "tokens": [
          50536,
          4019,
          11,
          293,
          341,
          472,
          50620
        ]
      },
      {
        "avg_logprob": -0.30636361750160773,
        "compression_ratio": 1.6491228070175439,
        "end": 7474.4,
        "id": 1615,
        "no_speech_prob": 0.00013135059271007776,
        "seek": 746320,
        "start": 7468.32,
        "temperature": 0,
        "text": " Reblog this I want the followers like it too, and we got both a reblog and a like hooray",
        "tokens": [
          50620,
          1300,
          65,
          4987,
          341,
          286,
          528,
          264,
          13071,
          411,
          309,
          886,
          11,
          293,
          321,
          658,
          1293,
          257,
          12970,
          4987,
          293,
          257,
          411,
          43330,
          320,
          50924
        ]
      },
      {
        "avg_logprob": -0.30636361750160773,
        "compression_ratio": 1.6491228070175439,
        "end": 7478.5599999999995,
        "id": 1616,
        "no_speech_prob": 0.00013135059271007776,
        "seek": 746320,
        "start": 7475.12,
        "temperature": 0,
        "text": " Okay, so this works. We now have a bot that",
        "tokens": [
          50960,
          1033,
          11,
          370,
          341,
          1985,
          13,
          492,
          586,
          362,
          257,
          10592,
          300,
          51132
        ]
      },
      {
        "avg_logprob": -0.30636361750160773,
        "compression_ratio": 1.6491228070175439,
        "end": 7480.88,
        "id": 1617,
        "no_speech_prob": 0.00013135059271007776,
        "seek": 746320,
        "start": 7479.5199999999995,
        "temperature": 0,
        "text": " that both",
        "tokens": [
          51180,
          300,
          1293,
          51248
        ]
      },
      {
        "avg_logprob": -0.30636361750160773,
        "compression_ratio": 1.6491228070175439,
        "end": 7484.48,
        "id": 1618,
        "no_speech_prob": 0.00013135059271007776,
        "seek": 746320,
        "start": 7480.88,
        "temperature": 0,
        "text": " that just checks for follows mentions and",
        "tokens": [
          51248,
          300,
          445,
          13834,
          337,
          10002,
          23844,
          293,
          51428
        ]
      },
      {
        "avg_logprob": -0.30636361750160773,
        "compression_ratio": 1.6491228070175439,
        "end": 7488.8,
        "id": 1619,
        "no_speech_prob": 0.00013135059271007776,
        "seek": 746320,
        "start": 7485.92,
        "temperature": 0,
        "text": " Follows and mentions if somebody follows it",
        "tokens": [
          51500,
          9876,
          82,
          293,
          23844,
          498,
          2618,
          10002,
          309,
          51644
        ]
      },
      {
        "avg_logprob": -0.22241934791940157,
        "compression_ratio": 1.7087719298245614,
        "end": 7493.68,
        "id": 1620,
        "no_speech_prob": 0.0016229291213676333,
        "seek": 748880,
        "start": 7489.28,
        "temperature": 0,
        "text": " Uh toots back welcome aboard to that account and if somebody",
        "tokens": [
          50388,
          4019,
          281,
          1971,
          646,
          2928,
          27488,
          281,
          300,
          2696,
          293,
          498,
          2618,
          50608
        ]
      },
      {
        "avg_logprob": -0.22241934791940157,
        "compression_ratio": 1.7087719298245614,
        "end": 7498.16,
        "id": 1621,
        "no_speech_prob": 0.0016229291213676333,
        "seek": 748880,
        "start": 7494.08,
        "temperature": 0,
        "text": " Uh mentions and uses any of these keywords and either favorites or reblogs",
        "tokens": [
          50628,
          4019,
          23844,
          293,
          4960,
          604,
          295,
          613,
          21009,
          293,
          2139,
          16907,
          420,
          12970,
          4987,
          82,
          50832
        ]
      },
      {
        "avg_logprob": -0.22241934791940157,
        "compression_ratio": 1.7087719298245614,
        "end": 7500.72,
        "id": 1622,
        "no_speech_prob": 0.0016229291213676333,
        "seek": 748880,
        "start": 7498.24,
        "temperature": 0,
        "text": " So the thing that I didn't do which I which I should add to this",
        "tokens": [
          50836,
          407,
          264,
          551,
          300,
          286,
          994,
          380,
          360,
          597,
          286,
          597,
          286,
          820,
          909,
          281,
          341,
          50960
        ]
      },
      {
        "avg_logprob": -0.22241934791940157,
        "compression_ratio": 1.7087719298245614,
        "end": 7505.52,
        "id": 1623,
        "no_speech_prob": 0.0016229291213676333,
        "seek": 748880,
        "start": 7500.8,
        "temperature": 0,
        "text": " I guess i'll do it. I don't know if it really makes sense to just keep doing more videos about this, but",
        "tokens": [
          50964,
          286,
          2041,
          741,
          603,
          360,
          309,
          13,
          286,
          500,
          380,
          458,
          498,
          309,
          534,
          1669,
          2020,
          281,
          445,
          1066,
          884,
          544,
          2145,
          466,
          341,
          11,
          457,
          51200
        ]
      },
      {
        "avg_logprob": -0.22241934791940157,
        "compression_ratio": 1.7087719298245614,
        "end": 7510.24,
        "id": 1624,
        "no_speech_prob": 0.0016229291213676333,
        "seek": 748880,
        "start": 7506.72,
        "temperature": 0,
        "text": " I'll do another video where i'll add this but you might want to try this as an exercise",
        "tokens": [
          51260,
          286,
          603,
          360,
          1071,
          960,
          689,
          741,
          603,
          909,
          341,
          457,
          291,
          1062,
          528,
          281,
          853,
          341,
          382,
          364,
          5380,
          51436
        ]
      },
      {
        "avg_logprob": -0.22241934791940157,
        "compression_ratio": 1.7087719298245614,
        "end": 7515.52,
        "id": 1625,
        "no_speech_prob": 0.0016229291213676333,
        "seek": 748880,
        "start": 7510.72,
        "temperature": 0,
        "text": " What how what about actually replying? What about posting an actual reply back to the person?",
        "tokens": [
          51460,
          708,
          577,
          437,
          466,
          767,
          1085,
          7310,
          30,
          708,
          466,
          15978,
          364,
          3539,
          16972,
          646,
          281,
          264,
          954,
          30,
          51700
        ]
      },
      {
        "avg_logprob": -0.22808965851988974,
        "compression_ratio": 1.4793814432989691,
        "end": 7518.88,
        "id": 1626,
        "no_speech_prob": 0.000003726625664057792,
        "seek": 751552,
        "start": 7515.52,
        "temperature": 0,
        "text": " So if the person asks, what is the meaning of life then?",
        "tokens": [
          50364,
          407,
          498,
          264,
          954,
          8962,
          11,
          437,
          307,
          264,
          3620,
          295,
          993,
          550,
          30,
          50532
        ]
      },
      {
        "avg_logprob": -0.22808965851988974,
        "compression_ratio": 1.4793814432989691,
        "end": 7523.92,
        "id": 1627,
        "no_speech_prob": 0.000003726625664057792,
        "seek": 751552,
        "start": 7519.120000000001,
        "temperature": 0,
        "text": " Uh, the bot replies with a random number or something like that. Okay, so give that a try",
        "tokens": [
          50544,
          4019,
          11,
          264,
          10592,
          42289,
          365,
          257,
          4974,
          1230,
          420,
          746,
          411,
          300,
          13,
          1033,
          11,
          370,
          976,
          300,
          257,
          853,
          50784
        ]
      },
      {
        "avg_logprob": -0.22808965851988974,
        "compression_ratio": 1.4793814432989691,
        "end": 7527.22,
        "id": 1628,
        "no_speech_prob": 0.000003726625664057792,
        "seek": 751552,
        "start": 7524.240000000001,
        "temperature": 0,
        "text": " I'll add that but i'll do that in the next video. Okay. Goodbye",
        "tokens": [
          50800,
          286,
          603,
          909,
          300,
          457,
          741,
          603,
          360,
          300,
          294,
          264,
          958,
          960,
          13,
          1033,
          13,
          15528,
          50949
        ]
      },
      {
        "avg_logprob": -0.22808965851988974,
        "compression_ratio": 1.4793814432989691,
        "end": 7539.620000000001,
        "id": 1629,
        "no_speech_prob": 0.000003726625664057792,
        "seek": 751552,
        "start": 7535.84,
        "temperature": 0,
        "text": " All right, i'm gonna go but i'm gonna just finish off this last little piece",
        "tokens": [
          51380,
          1057,
          558,
          11,
          741,
          478,
          799,
          352,
          457,
          741,
          478,
          799,
          445,
          2413,
          766,
          341,
          1036,
          707,
          2522,
          51569
        ]
      },
      {
        "avg_logprob": -0.5904630359850431,
        "compression_ratio": 0.8367346938775511,
        "end": 7549.68,
        "id": 1630,
        "no_speech_prob": 0.00010554349137237296,
        "seek": 754552,
        "start": 7545.84,
        "temperature": 0,
        "text": " Okay, so let's see",
        "tokens": [
          50380,
          1033,
          11,
          370,
          718,
          311,
          536,
          50572
        ]
      },
      {
        "avg_logprob": -0.5904630359850431,
        "compression_ratio": 0.8367346938775511,
        "end": 7559.76,
        "id": 1631,
        "no_speech_prob": 0.00010554349137237296,
        "seek": 754552,
        "start": 7557.76,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50976,
          3301,
          51076
        ]
      },
      {
        "avg_logprob": -0.5904630359850431,
        "compression_ratio": 0.8367346938775511,
        "end": 7570.4800000000005,
        "id": 1632,
        "no_speech_prob": 0.00010554349137237296,
        "seek": 754552,
        "start": 7568.4800000000005,
        "temperature": 0,
        "text": " It really should go",
        "tokens": [
          51512,
          467,
          534,
          820,
          352,
          51612
        ]
      },
      {
        "avg_logprob": -0.1703568329045802,
        "compression_ratio": 1.5235602094240839,
        "end": 7576.16,
        "id": 1633,
        "no_speech_prob": 0.00010390940587967634,
        "seek": 757048,
        "start": 7570.48,
        "temperature": 0,
        "text": " I'm, just so amazed that this hasn't crashed. I was really expecting the stream to crash especially because of the weird beeping happened",
        "tokens": [
          50364,
          286,
          478,
          11,
          445,
          370,
          20507,
          300,
          341,
          6132,
          380,
          24190,
          13,
          286,
          390,
          534,
          9650,
          264,
          4309,
          281,
          8252,
          2318,
          570,
          295,
          264,
          3657,
          34800,
          2011,
          50648
        ]
      },
      {
        "avg_logprob": -0.1703568329045802,
        "compression_ratio": 1.5235602094240839,
        "end": 7578.5599999999995,
        "id": 1634,
        "no_speech_prob": 0.00010390940587967634,
        "seek": 757048,
        "start": 7577.12,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50696,
          2102,
          3255,
          30,
          50768
        ]
      },
      {
        "avg_logprob": -0.1703568329045802,
        "compression_ratio": 1.5235602094240839,
        "end": 7580.5599999999995,
        "id": 1635,
        "no_speech_prob": 0.00010390940587967634,
        "seek": 757048,
        "start": 7578.5599999999995,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50768,
          2102,
          3255,
          30,
          50868
        ]
      },
      {
        "avg_logprob": -0.1703568329045802,
        "compression_ratio": 1.5235602094240839,
        "end": 7582.799999999999,
        "id": 1636,
        "no_speech_prob": 0.00010390940587967634,
        "seek": 757048,
        "start": 7580.799999999999,
        "temperature": 0,
        "text": " All right, um",
        "tokens": [
          50880,
          1057,
          558,
          11,
          1105,
          50980
        ]
      },
      {
        "avg_logprob": -0.1703568329045802,
        "compression_ratio": 1.5235602094240839,
        "end": 7589.54,
        "id": 1637,
        "no_speech_prob": 0.00010390940587967634,
        "seek": 757048,
        "start": 7583.759999999999,
        "temperature": 0,
        "text": " I'm getting a lot of mentions. All right, let's um, let's just finish this off. Let's do this last one",
        "tokens": [
          51028,
          286,
          478,
          1242,
          257,
          688,
          295,
          23844,
          13,
          1057,
          558,
          11,
          718,
          311,
          1105,
          11,
          718,
          311,
          445,
          2413,
          341,
          766,
          13,
          961,
          311,
          360,
          341,
          1036,
          472,
          51317
        ]
      },
      {
        "avg_logprob": -0.1703568329045802,
        "compression_ratio": 1.5235602094240839,
        "end": 7598.719999999999,
        "id": 1638,
        "no_speech_prob": 0.00010390940587967634,
        "seek": 757048,
        "start": 7596.719999999999,
        "temperature": 0,
        "text": " That's awesome",
        "tokens": [
          51676,
          663,
          311,
          3476,
          51776
        ]
      },
      {
        "avg_logprob": -0.3860927309308733,
        "compression_ratio": 1.2301587301587302,
        "end": 7602.879999999999,
        "id": 1639,
        "no_speech_prob": 0.00008092672214843333,
        "seek": 760048,
        "start": 7600.879999999999,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50384,
          3301,
          50484
        ]
      },
      {
        "avg_logprob": -0.3860927309308733,
        "compression_ratio": 1.2301587301587302,
        "end": 7605.679999999999,
        "id": 1640,
        "no_speech_prob": 0.00008092672214843333,
        "seek": 760048,
        "start": 7603.04,
        "temperature": 0,
        "text": " Okay, thank you chernykh for this",
        "tokens": [
          50492,
          1033,
          11,
          1309,
          291,
          417,
          1248,
          88,
          21021,
          337,
          341,
          50624
        ]
      },
      {
        "avg_logprob": -0.3860927309308733,
        "compression_ratio": 1.2301587301587302,
        "end": 7608.879999999999,
        "id": 1641,
        "no_speech_prob": 0.00008092672214843333,
        "seek": 760048,
        "start": 7606.879999999999,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50684,
          1105,
          50784
        ]
      },
      {
        "avg_logprob": -0.3860927309308733,
        "compression_ratio": 1.2301587301587302,
        "end": 7611.04,
        "id": 1642,
        "no_speech_prob": 0.00008092672214843333,
        "seek": 760048,
        "start": 7609.04,
        "temperature": 0,
        "text": " All right",
        "tokens": [
          50792,
          1057,
          558,
          50892
        ]
      },
      {
        "avg_logprob": -0.3860927309308733,
        "compression_ratio": 1.2301587301587302,
        "end": 7613.679999999999,
        "id": 1643,
        "no_speech_prob": 0.00008092672214843333,
        "seek": 760048,
        "start": 7611.679999999999,
        "temperature": 0,
        "text": " Um, here we go",
        "tokens": [
          50924,
          3301,
          11,
          510,
          321,
          352,
          51024
        ]
      },
      {
        "avg_logprob": -0.3860927309308733,
        "compression_ratio": 1.2301587301587302,
        "end": 7618.24,
        "id": 1644,
        "no_speech_prob": 0.00008092672214843333,
        "seek": 760048,
        "start": 7616.08,
        "temperature": 0,
        "text": " Hello welcome to video number",
        "tokens": [
          51144,
          2425,
          2928,
          281,
          960,
          1230,
          51252
        ]
      },
      {
        "avg_logprob": -0.3860927309308733,
        "compression_ratio": 1.2301587301587302,
        "end": 7624.5599999999995,
        "id": 1645,
        "no_speech_prob": 0.00008092672214843333,
        "seek": 760048,
        "start": 7619.98,
        "temperature": 0,
        "text": " 7629 about mastodon bots. I have been on a journey a journey",
        "tokens": [
          51339,
          24733,
          11871,
          466,
          27055,
          378,
          266,
          35410,
          13,
          286,
          362,
          668,
          322,
          257,
          4671,
          257,
          4671,
          51568
        ]
      },
      {
        "avg_logprob": -0.23887469371159872,
        "compression_ratio": 1.6923076923076923,
        "end": 7632.8,
        "id": 1646,
        "no_speech_prob": 0.0014778884360566735,
        "seek": 762456,
        "start": 7625.52,
        "temperature": 0,
        "text": " Along the tracks of mastodon and I have I started from nowhere and I have arrived to the point where I have a bot",
        "tokens": [
          50412,
          17457,
          264,
          10218,
          295,
          27055,
          378,
          266,
          293,
          286,
          362,
          286,
          1409,
          490,
          11159,
          293,
          286,
          362,
          6678,
          281,
          264,
          935,
          689,
          286,
          362,
          257,
          10592,
          50776
        ]
      },
      {
        "avg_logprob": -0.23887469371159872,
        "compression_ratio": 1.6923076923076923,
        "end": 7637.200000000001,
        "id": 1647,
        "no_speech_prob": 0.0014778884360566735,
        "seek": 762456,
        "start": 7633.200000000001,
        "temperature": 0,
        "text": " It's called coding train bot and what this bot does if you follow the bot",
        "tokens": [
          50796,
          467,
          311,
          1219,
          17720,
          3847,
          10592,
          293,
          437,
          341,
          10592,
          775,
          498,
          291,
          1524,
          264,
          10592,
          50996
        ]
      },
      {
        "avg_logprob": -0.23887469371159872,
        "compression_ratio": 1.6923076923076923,
        "end": 7644.88,
        "id": 1648,
        "no_speech_prob": 0.0014778884360566735,
        "seek": 762456,
        "start": 7637.280000000001,
        "temperature": 0,
        "text": " It says welcome aboard and if you toot at the bot and use a certain keyword it will favorite or read toot",
        "tokens": [
          51000,
          467,
          1619,
          2928,
          27488,
          293,
          498,
          291,
          281,
          310,
          412,
          264,
          10592,
          293,
          764,
          257,
          1629,
          20428,
          309,
          486,
          2954,
          420,
          1401,
          281,
          310,
          51380
        ]
      },
      {
        "avg_logprob": -0.23887469371159872,
        "compression_ratio": 1.6923076923076923,
        "end": 7647.52,
        "id": 1649,
        "no_speech_prob": 0.0014778884360566735,
        "seek": 762456,
        "start": 7645.52,
        "temperature": 0,
        "text": " boost whatever it is your",
        "tokens": [
          51412,
          9194,
          2035,
          309,
          307,
          428,
          51512
        ]
      },
      {
        "avg_logprob": -0.23887469371159872,
        "compression_ratio": 1.6923076923076923,
        "end": 7650.96,
        "id": 1650,
        "no_speech_prob": 0.0014778884360566735,
        "seek": 762456,
        "start": 7648.080000000001,
        "temperature": 0,
        "text": " Particular post and I want to add one more thing to it",
        "tokens": [
          51540,
          4100,
          14646,
          2183,
          293,
          286,
          528,
          281,
          909,
          472,
          544,
          551,
          281,
          309,
          51684
        ]
      },
      {
        "avg_logprob": -0.19403032425346725,
        "compression_ratio": 1.812807881773399,
        "end": 7654.96,
        "id": 1651,
        "no_speech_prob": 0.000029773045753245242,
        "seek": 765096,
        "start": 7651.52,
        "temperature": 0,
        "text": " So I want to be able to respond to a question",
        "tokens": [
          50392,
          407,
          286,
          528,
          281,
          312,
          1075,
          281,
          4196,
          281,
          257,
          1168,
          50564
        ]
      },
      {
        "avg_logprob": -0.19403032425346725,
        "compression_ratio": 1.812807881773399,
        "end": 7661.6,
        "id": 1652,
        "no_speech_prob": 0.000029773045753245242,
        "seek": 765096,
        "start": 7655.52,
        "temperature": 0,
        "text": " So let's just say i'm going to look for any post at me that ends with a question mark",
        "tokens": [
          50592,
          407,
          718,
          311,
          445,
          584,
          741,
          478,
          516,
          281,
          574,
          337,
          604,
          2183,
          412,
          385,
          300,
          5314,
          365,
          257,
          1168,
          1491,
          50896
        ]
      },
      {
        "avg_logprob": -0.19403032425346725,
        "compression_ratio": 1.812807881773399,
        "end": 7665.76,
        "id": 1653,
        "no_speech_prob": 0.000029773045753245242,
        "seek": 765096,
        "start": 7661.6,
        "temperature": 0,
        "text": " This is gonna be tricky because there's the html tags in it. I'm just going to look for a question mark",
        "tokens": [
          50896,
          639,
          307,
          799,
          312,
          12414,
          570,
          456,
          311,
          264,
          276,
          83,
          15480,
          18632,
          294,
          309,
          13,
          286,
          478,
          445,
          516,
          281,
          574,
          337,
          257,
          1168,
          1491,
          51104
        ]
      },
      {
        "avg_logprob": -0.19403032425346725,
        "compression_ratio": 1.812807881773399,
        "end": 7669.44,
        "id": 1654,
        "no_speech_prob": 0.000029773045753245242,
        "seek": 765096,
        "start": 7665.84,
        "temperature": 0,
        "text": " I'll let you make this fancier. So let's add one more",
        "tokens": [
          51108,
          286,
          603,
          718,
          291,
          652,
          341,
          3429,
          27674,
          13,
          407,
          718,
          311,
          909,
          472,
          544,
          51288
        ]
      },
      {
        "avg_logprob": -0.19403032425346725,
        "compression_ratio": 1.812807881773399,
        "end": 7672,
        "id": 1655,
        "no_speech_prob": 0.000029773045753245242,
        "seek": 765096,
        "start": 7670,
        "temperature": 0,
        "text": " check",
        "tokens": [
          51316,
          1520,
          51416
        ]
      },
      {
        "avg_logprob": -0.19403032425346725,
        "compression_ratio": 1.812807881773399,
        "end": 7674.16,
        "id": 1656,
        "no_speech_prob": 0.000029773045753245242,
        "seek": 765096,
        "start": 7672.16,
        "temperature": 0,
        "text": " I'm going to",
        "tokens": [
          51424,
          286,
          478,
          516,
          281,
          51524
        ]
      },
      {
        "avg_logprob": -0.19403032425346725,
        "compression_ratio": 1.812807881773399,
        "end": 7680.32,
        "id": 1657,
        "no_speech_prob": 0.000029773045753245242,
        "seek": 765096,
        "start": 7675.04,
        "temperature": 0,
        "text": " Constant regex3. I'm just going to look for a question mark",
        "tokens": [
          51568,
          37413,
          319,
          432,
          87,
          18,
          13,
          286,
          478,
          445,
          516,
          281,
          574,
          337,
          257,
          1168,
          1491,
          51832
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7686.24,
        "id": 1658,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7681.12,
        "temperature": 0,
        "text": " So oh question mark is a meta character. So I think I might have to do this backslash question mark",
        "tokens": [
          50372,
          407,
          1954,
          1168,
          1491,
          307,
          257,
          19616,
          2517,
          13,
          407,
          286,
          519,
          286,
          1062,
          362,
          281,
          360,
          341,
          646,
          10418,
          1299,
          1168,
          1491,
          50628
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7688.32,
        "id": 1659,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7686.88,
        "temperature": 0,
        "text": " or",
        "tokens": [
          50660,
          420,
          50732
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7691.04,
        "id": 1660,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7688.32,
        "temperature": 0,
        "text": " so I want to look for a question mark if",
        "tokens": [
          50732,
          370,
          286,
          528,
          281,
          574,
          337,
          257,
          1168,
          1491,
          498,
          50868
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7694.94,
        "id": 1661,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7692.94,
        "temperature": 0,
        "text": " Regex3",
        "tokens": [
          50963,
          1300,
          432,
          87,
          18,
          51063
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7698.08,
        "id": 1662,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7696.08,
        "temperature": 0,
        "text": " Matches the content",
        "tokens": [
          51120,
          26178,
          279,
          264,
          2701,
          51220
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7701.28,
        "id": 1663,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7698.4,
        "temperature": 0,
        "text": " And by the way, this is by this is either way the how",
        "tokens": [
          51236,
          400,
          538,
          264,
          636,
          11,
          341,
          307,
          538,
          341,
          307,
          2139,
          636,
          264,
          577,
          51380
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7705.6,
        "id": 1664,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7702,
        "temperature": 0,
        "text": " This is like the very basics of making a chat bot, which is just doing like",
        "tokens": [
          51416,
          639,
          307,
          411,
          264,
          588,
          14688,
          295,
          1455,
          257,
          5081,
          10592,
          11,
          597,
          307,
          445,
          884,
          411,
          51596
        ]
      },
      {
        "avg_logprob": -0.2145402989488967,
        "compression_ratio": 1.6231155778894473,
        "end": 7708.16,
        "id": 1665,
        "no_speech_prob": 0.00003480787927401252,
        "seek": 768096,
        "start": 7706.32,
        "temperature": 0,
        "text": " basic pattern matching",
        "tokens": [
          51632,
          3875,
          5102,
          14324,
          51724
        ]
      },
      {
        "avg_logprob": -0.25074235655420973,
        "compression_ratio": 1.7797619047619047,
        "end": 7712.18,
        "id": 1666,
        "no_speech_prob": 0.004198622889816761,
        "seek": 770816,
        "start": 7708.16,
        "temperature": 0,
        "text": " You know now chat chatbot systems use machine learning and try to category",
        "tokens": [
          50364,
          509,
          458,
          586,
          5081,
          5081,
          18870,
          3652,
          764,
          3479,
          2539,
          293,
          853,
          281,
          7719,
          50565
        ]
      },
      {
        "avg_logprob": -0.25074235655420973,
        "compression_ratio": 1.7797619047619047,
        "end": 7716.32,
        "id": 1667,
        "no_speech_prob": 0.004198622889816761,
        "seek": 770816,
        "start": 7712.46,
        "temperature": 0,
        "text": " Categorize what people are saying into intents and do all sorts of text analysis",
        "tokens": [
          50579,
          383,
          2968,
          284,
          1125,
          437,
          561,
          366,
          1566,
          666,
          560,
          791,
          293,
          360,
          439,
          7527,
          295,
          2487,
          5215,
          50772
        ]
      },
      {
        "avg_logprob": -0.25074235655420973,
        "compression_ratio": 1.7797619047619047,
        "end": 7722.08,
        "id": 1668,
        "no_speech_prob": 0.004198622889816761,
        "seek": 770816,
        "start": 7716.4,
        "temperature": 0,
        "text": " but at a core level you could just use regular expressions to try to match what somebody's saying and",
        "tokens": [
          50776,
          457,
          412,
          257,
          4965,
          1496,
          291,
          727,
          445,
          764,
          3890,
          15277,
          281,
          853,
          281,
          2995,
          437,
          2618,
          311,
          1566,
          293,
          51060
        ]
      },
      {
        "avg_logprob": -0.25074235655420973,
        "compression_ratio": 1.7797619047619047,
        "end": 7727.2,
        "id": 1669,
        "no_speech_prob": 0.004198622889816761,
        "seek": 770816,
        "start": 7722.24,
        "temperature": 0,
        "text": " Respond accordingly and if you I do have a set of videos about rive script, which is a pattern matching",
        "tokens": [
          51068,
          22480,
          684,
          19717,
          293,
          498,
          291,
          286,
          360,
          362,
          257,
          992,
          295,
          2145,
          466,
          367,
          488,
          5755,
          11,
          597,
          307,
          257,
          5102,
          14324,
          51316
        ]
      },
      {
        "avg_logprob": -0.25074235655420973,
        "compression_ratio": 1.7797619047619047,
        "end": 7733.2,
        "id": 1670,
        "no_speech_prob": 0.004198622889816761,
        "seek": 770816,
        "start": 7727.82,
        "temperature": 0,
        "text": " Utility that you can use in any programming a number of programming languages, but you can use it in javascript to build your own chatbot",
        "tokens": [
          51347,
          12555,
          1140,
          300,
          291,
          393,
          764,
          294,
          604,
          9410,
          257,
          1230,
          295,
          9410,
          8650,
          11,
          457,
          291,
          393,
          764,
          309,
          294,
          361,
          37331,
          5944,
          281,
          1322,
          428,
          1065,
          5081,
          18870,
          51616
        ]
      },
      {
        "avg_logprob": -0.25074235655420973,
        "compression_ratio": 1.7797619047619047,
        "end": 7737.92,
        "id": 1671,
        "no_speech_prob": 0.004198622889816761,
        "seek": 770816,
        "start": 7733.2,
        "temperature": 0,
        "text": " So this is you know interesting to think about what what what do you want your bot to actually do?",
        "tokens": [
          51616,
          407,
          341,
          307,
          291,
          458,
          1880,
          281,
          519,
          466,
          437,
          437,
          437,
          360,
          291,
          528,
          428,
          10592,
          281,
          767,
          360,
          30,
          51852
        ]
      },
      {
        "avg_logprob": -0.199075718720754,
        "compression_ratio": 1.75,
        "end": 7742.48,
        "id": 1672,
        "no_speech_prob": 0.000026688308935263194,
        "seek": 773816,
        "start": 7738.88,
        "temperature": 0,
        "text": " But in this case, i'm just going to use regular expressions. I'm going to look for a question mark",
        "tokens": [
          50400,
          583,
          294,
          341,
          1389,
          11,
          741,
          478,
          445,
          516,
          281,
          764,
          3890,
          15277,
          13,
          286,
          478,
          516,
          281,
          574,
          337,
          257,
          1168,
          1491,
          50580
        ]
      },
      {
        "avg_logprob": -0.199075718720754,
        "compression_ratio": 1.75,
        "end": 7744.639999999999,
        "id": 1673,
        "no_speech_prob": 0.000026688308935263194,
        "seek": 773816,
        "start": 7742.639999999999,
        "temperature": 0,
        "text": " So, let me just actually make sure this works",
        "tokens": [
          50588,
          407,
          11,
          718,
          385,
          445,
          767,
          652,
          988,
          341,
          1985,
          50688
        ]
      },
      {
        "avg_logprob": -0.199075718720754,
        "compression_ratio": 1.75,
        "end": 7747.36,
        "id": 1674,
        "no_speech_prob": 0.000026688308935263194,
        "seek": 773816,
        "start": 7745.36,
        "temperature": 0,
        "text": " I'm going to say I got a question",
        "tokens": [
          50724,
          286,
          478,
          516,
          281,
          584,
          286,
          658,
          257,
          1168,
          50824
        ]
      },
      {
        "avg_logprob": -0.199075718720754,
        "compression_ratio": 1.75,
        "end": 7754.08,
        "id": 1675,
        "no_speech_prob": 0.000026688308935263194,
        "seek": 773816,
        "start": 7748.8,
        "temperature": 0,
        "text": " And let me look at the content so I think i'm gonna not always",
        "tokens": [
          50896,
          400,
          718,
          385,
          574,
          412,
          264,
          2701,
          370,
          286,
          519,
          741,
          478,
          799,
          406,
          1009,
          51160
        ]
      },
      {
        "avg_logprob": -0.199075718720754,
        "compression_ratio": 1.75,
        "end": 7762.24,
        "id": 1676,
        "no_speech_prob": 0.000026688308935263194,
        "seek": 773816,
        "start": 7755.28,
        "temperature": 0,
        "text": " Console log the content anymore. I know that's working. So I just want to now I want to just look at it console log",
        "tokens": [
          51220,
          44152,
          3565,
          264,
          2701,
          3602,
          13,
          286,
          458,
          300,
          311,
          1364,
          13,
          407,
          286,
          445,
          528,
          281,
          586,
          286,
          528,
          281,
          445,
          574,
          412,
          309,
          11076,
          3565,
          51568
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7768.32,
        "id": 1677,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7762.719999999999,
        "temperature": 0,
        "text": " Uh data, what was it called? Did I put it in a variable content? So i'm just going to look at the content",
        "tokens": [
          50388,
          4019,
          1412,
          11,
          437,
          390,
          309,
          1219,
          30,
          2589,
          286,
          829,
          309,
          294,
          257,
          7006,
          2701,
          30,
          407,
          741,
          478,
          445,
          516,
          281,
          574,
          412,
          264,
          2701,
          50668
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7771.28,
        "id": 1678,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7769.28,
        "temperature": 0,
        "text": " So I am now going to run this",
        "tokens": [
          50716,
          407,
          286,
          669,
          586,
          516,
          281,
          1190,
          341,
          50816
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7773.44,
        "id": 1679,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7771.76,
        "temperature": 0,
        "text": " You know, by the way, if you're doing this on your own",
        "tokens": [
          50840,
          509,
          458,
          11,
          538,
          264,
          636,
          11,
          498,
          291,
          434,
          884,
          341,
          322,
          428,
          1065,
          50924
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7777.36,
        "id": 1680,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7773.44,
        "temperature": 0,
        "text": " You're going to want to have a second mastodon account where you can then test it",
        "tokens": [
          50924,
          509,
          434,
          516,
          281,
          528,
          281,
          362,
          257,
          1150,
          27055,
          378,
          266,
          2696,
          689,
          291,
          393,
          550,
          1500,
          309,
          51120
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7781.28,
        "id": 1681,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7777.599999999999,
        "temperature": 0,
        "text": " I am a weird crazy person who does this sort of stuff on a live stream",
        "tokens": [
          51132,
          286,
          669,
          257,
          3657,
          3219,
          954,
          567,
          775,
          341,
          1333,
          295,
          1507,
          322,
          257,
          1621,
          4309,
          51316
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7784.88,
        "id": 1682,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7781.36,
        "temperature": 0,
        "text": " Apparently, I just assume that the people out in the world watching will",
        "tokens": [
          51320,
          16755,
          11,
          286,
          445,
          6552,
          300,
          264,
          561,
          484,
          294,
          264,
          1002,
          1976,
          486,
          51496
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7787.2,
        "id": 1683,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7785.5,
        "temperature": 0,
        "text": " interact and hopefully",
        "tokens": [
          51527,
          4648,
          293,
          4696,
          51612
        ]
      },
      {
        "avg_logprob": -0.20051648794126906,
        "compression_ratio": 1.6309963099630995,
        "end": 7788.08,
        "id": 1684,
        "no_speech_prob": 0.0011694729328155518,
        "seek": 776224,
        "start": 7787.2,
        "temperature": 0,
        "text": " uh",
        "tokens": [
          51612,
          2232,
          51656
        ]
      },
      {
        "avg_logprob": -0.2237388904278095,
        "compression_ratio": 1.7478260869565216,
        "end": 7793.44,
        "id": 1685,
        "no_speech_prob": 0.18948112428188324,
        "seek": 778808,
        "start": 7788.08,
        "temperature": 0,
        "text": " Be kind. Okay. Now let us run it again. Let's see if we can get some mentions",
        "tokens": [
          50364,
          879,
          733,
          13,
          1033,
          13,
          823,
          718,
          505,
          1190,
          309,
          797,
          13,
          961,
          311,
          536,
          498,
          321,
          393,
          483,
          512,
          23844,
          50632
        ]
      },
      {
        "avg_logprob": -0.2237388904278095,
        "compression_ratio": 1.7478260869565216,
        "end": 7797.04,
        "id": 1686,
        "no_speech_prob": 0.18948112428188324,
        "seek": 778808,
        "start": 7794.08,
        "temperature": 0,
        "text": " with a question mark in them and see if um",
        "tokens": [
          50664,
          365,
          257,
          1168,
          1491,
          294,
          552,
          293,
          536,
          498,
          1105,
          50812
        ]
      },
      {
        "avg_logprob": -0.2237388904278095,
        "compression_ratio": 1.7478260869565216,
        "end": 7801.94,
        "id": 1687,
        "no_speech_prob": 0.18948112428188324,
        "seek": 778808,
        "start": 7797.92,
        "temperature": 0,
        "text": " Oh, there we go. Okay, so I got a question. Okay. Ooh, that's interesting",
        "tokens": [
          50856,
          876,
          11,
          456,
          321,
          352,
          13,
          1033,
          11,
          370,
          286,
          658,
          257,
          1168,
          13,
          1033,
          13,
          7951,
          11,
          300,
          311,
          1880,
          51057
        ]
      },
      {
        "avg_logprob": -0.2237388904278095,
        "compression_ratio": 1.7478260869565216,
        "end": 7807.6,
        "id": 1688,
        "no_speech_prob": 0.18948112428188324,
        "seek": 778808,
        "start": 7803.76,
        "temperature": 0,
        "text": " Uh, oh I got a question no, that's not what somebody said to me why with a question mark",
        "tokens": [
          51148,
          4019,
          11,
          1954,
          286,
          658,
          257,
          1168,
          572,
          11,
          300,
          311,
          406,
          437,
          2618,
          848,
          281,
          385,
          983,
          365,
          257,
          1168,
          1491,
          51340
        ]
      },
      {
        "avg_logprob": -0.2237388904278095,
        "compression_ratio": 1.7478260869565216,
        "end": 7813.6,
        "id": 1689,
        "no_speech_prob": 0.18948112428188324,
        "seek": 778808,
        "start": 7807.6,
        "temperature": 0,
        "text": " Okay, so that seems to be working. So i'm gonna assume that that's good. Thank you for that. And now what I want to do",
        "tokens": [
          51340,
          1033,
          11,
          370,
          300,
          2544,
          281,
          312,
          1364,
          13,
          407,
          741,
          478,
          799,
          6552,
          300,
          300,
          311,
          665,
          13,
          1044,
          291,
          337,
          300,
          13,
          400,
          586,
          437,
          286,
          528,
          281,
          360,
          51640
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7821.76,
        "id": 1690,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7813.92,
        "temperature": 0,
        "text": " Is I want to say I want to I want to do um, I want to create sorry a um,",
        "tokens": [
          50380,
          1119,
          286,
          528,
          281,
          584,
          286,
          528,
          281,
          286,
          528,
          281,
          360,
          1105,
          11,
          286,
          528,
          281,
          1884,
          2597,
          257,
          1105,
          11,
          50772
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7824.4800000000005,
        "id": 1691,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7822.4800000000005,
        "temperature": 0,
        "text": " reply, so i'm going to say",
        "tokens": [
          50808,
          16972,
          11,
          370,
          741,
          478,
          516,
          281,
          584,
          50908
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7826.88,
        "id": 1692,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7824.88,
        "temperature": 0,
        "text": " a reply equals",
        "tokens": [
          50928,
          257,
          16972,
          6915,
          51028
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7828.08,
        "id": 1693,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7827.120000000001,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51040,
          1105,
          51088
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7831.200000000001,
        "id": 1694,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7828.08,
        "temperature": 0,
        "text": " The meaning of life is and i'm going to use this",
        "tokens": [
          51088,
          440,
          3620,
          295,
          993,
          307,
          293,
          741,
          478,
          516,
          281,
          764,
          341,
          51244
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7834.72,
        "id": 1695,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7832.240000000001,
        "temperature": 0,
        "text": " This oh I had this from before by accident luckily",
        "tokens": [
          51296,
          639,
          1954,
          286,
          632,
          341,
          490,
          949,
          538,
          6398,
          22880,
          51420
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7838.08,
        "id": 1696,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7836.08,
        "temperature": 0,
        "text": " uh is",
        "tokens": [
          51488,
          2232,
          307,
          51588
        ]
      },
      {
        "avg_logprob": -0.2967980702718099,
        "compression_ratio": 1.5833333333333333,
        "end": 7840.240000000001,
        "id": 1697,
        "no_speech_prob": 0.0018386156298220158,
        "seek": 781360,
        "start": 7838.400000000001,
        "temperature": 0,
        "text": " Numb",
        "tokens": [
          51604,
          426,
          2860,
          51696
        ]
      },
      {
        "avg_logprob": -0.18154390079458965,
        "compression_ratio": 1.7813953488372094,
        "end": 7846.8,
        "id": 1698,
        "no_speech_prob": 0.0018386474112048745,
        "seek": 784024,
        "start": 7840.24,
        "temperature": 0,
        "text": " But I and then I want to just send that reply but here's the thing a couple things one is I want to mention that person",
        "tokens": [
          50364,
          583,
          286,
          293,
          550,
          286,
          528,
          281,
          445,
          2845,
          300,
          16972,
          457,
          510,
          311,
          264,
          551,
          257,
          1916,
          721,
          472,
          307,
          286,
          528,
          281,
          2152,
          300,
          954,
          50692
        ]
      },
      {
        "avg_logprob": -0.18154390079458965,
        "compression_ratio": 1.7813953488372094,
        "end": 7849.2,
        "id": 1699,
        "no_speech_prob": 0.0018386474112048745,
        "seek": 784024,
        "start": 7847.36,
        "temperature": 0,
        "text": " So I did that before",
        "tokens": [
          50720,
          407,
          286,
          630,
          300,
          949,
          50812
        ]
      },
      {
        "avg_logprob": -0.18154390079458965,
        "compression_ratio": 1.7813953488372094,
        "end": 7854.48,
        "id": 1700,
        "no_speech_prob": 0.0018386474112048745,
        "seek": 784024,
        "start": 7849.2,
        "temperature": 0,
        "text": " When somebody followed me so I can do at and then the account which I should still have",
        "tokens": [
          50812,
          1133,
          2618,
          6263,
          385,
          370,
          286,
          393,
          360,
          412,
          293,
          550,
          264,
          2696,
          597,
          286,
          820,
          920,
          362,
          51076
        ]
      },
      {
        "avg_logprob": -0.18154390079458965,
        "compression_ratio": 1.7813953488372094,
        "end": 7860.5599999999995,
        "id": 1701,
        "no_speech_prob": 0.0018386474112048745,
        "seek": 784024,
        "start": 7855.599999999999,
        "temperature": 0,
        "text": " I didn't actually save the account. So if somebody mentions me, where do I get the account?",
        "tokens": [
          51132,
          286,
          994,
          380,
          767,
          3155,
          264,
          2696,
          13,
          407,
          498,
          2618,
          23844,
          385,
          11,
          689,
          360,
          286,
          483,
          264,
          2696,
          30,
          51380
        ]
      },
      {
        "avg_logprob": -0.18154390079458965,
        "compression_ratio": 1.7813953488372094,
        "end": 7864.24,
        "id": 1702,
        "no_speech_prob": 0.0018386474112048745,
        "seek": 784024,
        "start": 7861.76,
        "temperature": 0,
        "text": " Data account accounts the same thing",
        "tokens": [
          51440,
          11888,
          2696,
          9402,
          264,
          912,
          551,
          51564
        ]
      },
      {
        "avg_logprob": -0.18154390079458965,
        "compression_ratio": 1.7813953488372094,
        "end": 7866.8,
        "id": 1703,
        "no_speech_prob": 0.0018386474112048745,
        "seek": 784024,
        "start": 7864.8,
        "temperature": 0,
        "text": " So I can actually go back",
        "tokens": [
          51592,
          407,
          286,
          393,
          767,
          352,
          646,
          51692
        ]
      },
      {
        "avg_logprob": -0.19479656219482422,
        "compression_ratio": 1.6195121951219513,
        "end": 7870.08,
        "id": 1704,
        "no_speech_prob": 0.00012148140376666561,
        "seek": 786680,
        "start": 7866.96,
        "temperature": 0,
        "text": " Message data account. I actually I think I kind of like always want this",
        "tokens": [
          50372,
          45947,
          1412,
          2696,
          13,
          286,
          767,
          286,
          519,
          286,
          733,
          295,
          411,
          1009,
          528,
          341,
          50528
        ]
      },
      {
        "avg_logprob": -0.19479656219482422,
        "compression_ratio": 1.6195121951219513,
        "end": 7872.400000000001,
        "id": 1705,
        "no_speech_prob": 0.00012148140376666561,
        "seek": 786680,
        "start": 7870.72,
        "temperature": 0,
        "text": " so",
        "tokens": [
          50560,
          370,
          50644
        ]
      },
      {
        "avg_logprob": -0.19479656219482422,
        "compression_ratio": 1.6195121951219513,
        "end": 7874.88,
        "id": 1706,
        "no_speech_prob": 0.00012148140376666561,
        "seek": 786680,
        "start": 7872.400000000001,
        "temperature": 0,
        "text": " Whether it is a follow or a mention to whoops",
        "tokens": [
          50644,
          8503,
          309,
          307,
          257,
          1524,
          420,
          257,
          2152,
          281,
          567,
          3370,
          50768
        ]
      },
      {
        "avg_logprob": -0.19479656219482422,
        "compression_ratio": 1.6195121951219513,
        "end": 7879.04,
        "id": 1707,
        "no_speech_prob": 0.00012148140376666561,
        "seek": 786680,
        "start": 7875.68,
        "temperature": 0,
        "text": " So i'm going to put this out here. So I have access to that account",
        "tokens": [
          50808,
          407,
          741,
          478,
          516,
          281,
          829,
          341,
          484,
          510,
          13,
          407,
          286,
          362,
          2105,
          281,
          300,
          2696,
          50976
        ]
      },
      {
        "avg_logprob": -0.19479656219482422,
        "compression_ratio": 1.6195121951219513,
        "end": 7884.56,
        "id": 1708,
        "no_speech_prob": 0.00012148140376666561,
        "seek": 786680,
        "start": 7879.12,
        "temperature": 0,
        "text": " Sorry that the font got smaller here. We can still read it. So I want to first mention",
        "tokens": [
          50980,
          4919,
          300,
          264,
          10703,
          658,
          4356,
          510,
          13,
          492,
          393,
          920,
          1401,
          309,
          13,
          407,
          286,
          528,
          281,
          700,
          2152,
          51252
        ]
      },
      {
        "avg_logprob": -0.19479656219482422,
        "compression_ratio": 1.6195121951219513,
        "end": 7888.72,
        "id": 1709,
        "no_speech_prob": 0.00012148140376666561,
        "seek": 786680,
        "start": 7886.72,
        "temperature": 0,
        "text": " That account",
        "tokens": [
          51360,
          663,
          2696,
          51460
        ]
      },
      {
        "avg_logprob": -0.19479656219482422,
        "compression_ratio": 1.6195121951219513,
        "end": 7891.4400000000005,
        "id": 1710,
        "no_speech_prob": 0.00012148140376666561,
        "seek": 786680,
        "start": 7889.4400000000005,
        "temperature": 0,
        "text": " And then say that but but here's the thing",
        "tokens": [
          51496,
          400,
          550,
          584,
          300,
          457,
          457,
          510,
          311,
          264,
          551,
          51596
        ]
      },
      {
        "avg_logprob": -0.2317877639958888,
        "compression_ratio": 1.6149732620320856,
        "end": 7899.219999999999,
        "id": 1711,
        "no_speech_prob": 0.000007183256457210518,
        "seek": 789144,
        "start": 7892.32,
        "temperature": 0,
        "text": " You can mention but it's not going to actually understand it as a threaded reply unless I include",
        "tokens": [
          50408,
          509,
          393,
          2152,
          457,
          309,
          311,
          406,
          516,
          281,
          767,
          1223,
          309,
          382,
          257,
          47493,
          16972,
          5969,
          286,
          4090,
          50753
        ]
      },
      {
        "avg_logprob": -0.2317877639958888,
        "compression_ratio": 1.6149732620320856,
        "end": 7901.599999999999,
        "id": 1712,
        "no_speech_prob": 0.000007183256457210518,
        "seek": 789144,
        "start": 7899.599999999999,
        "temperature": 0,
        "text": " in reply to id",
        "tokens": [
          50772,
          294,
          16972,
          281,
          4496,
          50872
        ]
      },
      {
        "avg_logprob": -0.2317877639958888,
        "compression_ratio": 1.6149732620320856,
        "end": 7904.719999999999,
        "id": 1713,
        "no_speech_prob": 0.000007183256457210518,
        "seek": 789144,
        "start": 7902,
        "temperature": 0,
        "text": " So I actually also need to get the id",
        "tokens": [
          50892,
          407,
          286,
          767,
          611,
          643,
          281,
          483,
          264,
          4496,
          51028
        ]
      },
      {
        "avg_logprob": -0.2317877639958888,
        "compression_ratio": 1.6149732620320856,
        "end": 7911.44,
        "id": 1714,
        "no_speech_prob": 0.000007183256457210518,
        "seek": 789144,
        "start": 7905.28,
        "temperature": 0,
        "text": " Which I have here message data status id. So what i'm going to do is i'm going to",
        "tokens": [
          51056,
          3013,
          286,
          362,
          510,
          3636,
          1412,
          6558,
          4496,
          13,
          407,
          437,
          741,
          478,
          516,
          281,
          360,
          307,
          741,
          478,
          516,
          281,
          51364
        ]
      },
      {
        "avg_logprob": -0.2317877639958888,
        "compression_ratio": 1.6149732620320856,
        "end": 7915.44,
        "id": 1715,
        "no_speech_prob": 0.000007183256457210518,
        "seek": 789144,
        "start": 7912.379999999999,
        "temperature": 0,
        "text": " overload this function with a second argument id",
        "tokens": [
          51411,
          28777,
          341,
          2445,
          365,
          257,
          1150,
          6770,
          4496,
          51564
        ]
      },
      {
        "avg_logprob": -0.2317877639958888,
        "compression_ratio": 1.6149732620320856,
        "end": 7918.24,
        "id": 1716,
        "no_speech_prob": 0.000007183256457210518,
        "seek": 789144,
        "start": 7916.24,
        "temperature": 0,
        "text": " and i'm going to say",
        "tokens": [
          51604,
          293,
          741,
          478,
          516,
          281,
          584,
          51704
        ]
      },
      {
        "avg_logprob": -0.20348558823267618,
        "compression_ratio": 1.7272727272727273,
        "end": 7925.04,
        "id": 1717,
        "no_speech_prob": 0.00013765317271463573,
        "seek": 791824,
        "start": 7919.04,
        "temperature": 0,
        "text": " In reply to we got to look at the documentation. I don't remember what it is, but if I look here",
        "tokens": [
          50404,
          682,
          16972,
          281,
          321,
          658,
          281,
          574,
          412,
          264,
          14333,
          13,
          286,
          500,
          380,
          1604,
          437,
          309,
          307,
          11,
          457,
          498,
          286,
          574,
          510,
          50704
        ]
      },
      {
        "avg_logprob": -0.20348558823267618,
        "compression_ratio": 1.7272727272727273,
        "end": 7928,
        "id": 1718,
        "no_speech_prob": 0.00013765317271463573,
        "seek": 791824,
        "start": 7926,
        "temperature": 0,
        "text": " Oh, it's actually under over here",
        "tokens": [
          50752,
          876,
          11,
          309,
          311,
          767,
          833,
          670,
          510,
          50852
        ]
      },
      {
        "avg_logprob": -0.20348558823267618,
        "compression_ratio": 1.7272727272727273,
        "end": 7930.4,
        "id": 1719,
        "no_speech_prob": 0.00013765317271463573,
        "seek": 791824,
        "start": 7928.96,
        "temperature": 0,
        "text": " in reply",
        "tokens": [
          50900,
          294,
          16972,
          50972
        ]
      },
      {
        "avg_logprob": -0.20348558823267618,
        "compression_ratio": 1.7272727272727273,
        "end": 7932.4,
        "id": 1720,
        "no_speech_prob": 0.00013765317271463573,
        "seek": 791824,
        "start": 7930.4,
        "temperature": 0,
        "text": " to or reply to",
        "tokens": [
          50972,
          281,
          420,
          16972,
          281,
          51072
        ]
      },
      {
        "avg_logprob": -0.20348558823267618,
        "compression_ratio": 1.7272727272727273,
        "end": 7935.04,
        "id": 1721,
        "no_speech_prob": 0.00013765317271463573,
        "seek": 791824,
        "start": 7933.04,
        "temperature": 0,
        "text": " Um, oh no, i'm in the wrong place",
        "tokens": [
          51104,
          3301,
          11,
          1954,
          572,
          11,
          741,
          478,
          294,
          264,
          2085,
          1081,
          51204
        ]
      },
      {
        "avg_logprob": -0.20348558823267618,
        "compression_ratio": 1.7272727272727273,
        "end": 7937.28,
        "id": 1722,
        "no_speech_prob": 0.00013765317271463573,
        "seek": 791824,
        "start": 7935.12,
        "temperature": 0,
        "text": " Oh, i'm totally in the wrong. I was in the right place before",
        "tokens": [
          51208,
          876,
          11,
          741,
          478,
          3879,
          294,
          264,
          2085,
          13,
          286,
          390,
          294,
          264,
          558,
          1081,
          949,
          51316
        ]
      },
      {
        "avg_logprob": -0.20348558823267618,
        "compression_ratio": 1.7272727272727273,
        "end": 7941.599999999999,
        "id": 1723,
        "no_speech_prob": 0.00013765317271463573,
        "seek": 791824,
        "start": 7937.84,
        "temperature": 0,
        "text": " In reply, there we go. I'm looking for in reply to id",
        "tokens": [
          51344,
          682,
          16972,
          11,
          456,
          321,
          352,
          13,
          286,
          478,
          1237,
          337,
          294,
          16972,
          281,
          4496,
          51532
        ]
      },
      {
        "avg_logprob": -0.2111491606785701,
        "compression_ratio": 1.7313432835820894,
        "end": 7948.320000000001,
        "id": 1724,
        "no_speech_prob": 0.028869876638054848,
        "seek": 794160,
        "start": 7942.240000000001,
        "temperature": 0,
        "text": " So I want to grab this and I want to put this here and then I want to put in the id",
        "tokens": [
          50396,
          407,
          286,
          528,
          281,
          4444,
          341,
          293,
          286,
          528,
          281,
          829,
          341,
          510,
          293,
          550,
          286,
          528,
          281,
          829,
          294,
          264,
          4496,
          50700
        ]
      },
      {
        "avg_logprob": -0.2111491606785701,
        "compression_ratio": 1.7313432835820894,
        "end": 7951.6,
        "id": 1725,
        "no_speech_prob": 0.028869876638054848,
        "seek": 794160,
        "start": 7949.6,
        "temperature": 0,
        "text": " and I guess what I want to do is",
        "tokens": [
          50764,
          293,
          286,
          2041,
          437,
          286,
          528,
          281,
          360,
          307,
          50864
        ]
      },
      {
        "avg_logprob": -0.2111491606785701,
        "compression_ratio": 1.7313432835820894,
        "end": 7954.88,
        "id": 1726,
        "no_speech_prob": 0.028869876638054848,
        "seek": 794160,
        "start": 7952.160000000001,
        "temperature": 0,
        "text": " The thing is, um, i'm going to do it this this is a little goofy",
        "tokens": [
          50892,
          440,
          551,
          307,
          11,
          1105,
          11,
          741,
          478,
          516,
          281,
          360,
          309,
          341,
          341,
          307,
          257,
          707,
          42995,
          51028
        ]
      },
      {
        "avg_logprob": -0.2111491606785701,
        "compression_ratio": 1.7313432835820894,
        "end": 7958.4800000000005,
        "id": 1727,
        "no_speech_prob": 0.028869876638054848,
        "seek": 794160,
        "start": 7954.96,
        "temperature": 0,
        "text": " This probably could use some fancy ternary operator or something, but i'm just going to say",
        "tokens": [
          51032,
          639,
          1391,
          727,
          764,
          512,
          10247,
          256,
          1248,
          822,
          12973,
          420,
          746,
          11,
          457,
          741,
          478,
          445,
          516,
          281,
          584,
          51208
        ]
      },
      {
        "avg_logprob": -0.2111491606785701,
        "compression_ratio": 1.7313432835820894,
        "end": 7962.54,
        "id": 1728,
        "no_speech_prob": 0.028869876638054848,
        "seek": 794160,
        "start": 7961.120000000001,
        "temperature": 0,
        "text": " If id",
        "tokens": [
          51340,
          759,
          4496,
          51411
        ]
      },
      {
        "avg_logprob": -0.2111491606785701,
        "compression_ratio": 1.7313432835820894,
        "end": 7967.200000000001,
        "id": 1729,
        "no_speech_prob": 0.028869876638054848,
        "seek": 794160,
        "start": 7962.54,
        "temperature": 0,
        "text": " Exists, then i'm going to add it params dot in reply to id equals id",
        "tokens": [
          51411,
          2111,
          1751,
          11,
          550,
          741,
          478,
          516,
          281,
          909,
          309,
          971,
          4070,
          5893,
          294,
          16972,
          281,
          4496,
          6915,
          4496,
          51644
        ]
      },
      {
        "avg_logprob": -0.2085459357813785,
        "compression_ratio": 1.722943722943723,
        "end": 7972.16,
        "id": 1730,
        "no_speech_prob": 0.0007553995819762349,
        "seek": 796720,
        "start": 7967.36,
        "temperature": 0,
        "text": " So it's not going to it's all it based on whether or not if I send into this function",
        "tokens": [
          50372,
          407,
          309,
          311,
          406,
          516,
          281,
          309,
          311,
          439,
          309,
          2361,
          322,
          1968,
          420,
          406,
          498,
          286,
          2845,
          666,
          341,
          2445,
          50612
        ]
      },
      {
        "avg_logprob": -0.2085459357813785,
        "compression_ratio": 1.722943722943723,
        "end": 7976.08,
        "id": 1731,
        "no_speech_prob": 0.0007553995819762349,
        "seek": 796720,
        "start": 7972.4,
        "temperature": 0,
        "text": " I'm always going to send in this function some content that I want to toot",
        "tokens": [
          50624,
          286,
          478,
          1009,
          516,
          281,
          2845,
          294,
          341,
          2445,
          512,
          2701,
          300,
          286,
          528,
          281,
          281,
          310,
          50808
        ]
      },
      {
        "avg_logprob": -0.2085459357813785,
        "compression_ratio": 1.722943722943723,
        "end": 7980,
        "id": 1732,
        "no_speech_prob": 0.0007553995819762349,
        "seek": 796720,
        "start": 7976.48,
        "temperature": 0,
        "text": " But if there's an id I also want to add that in so now",
        "tokens": [
          50828,
          583,
          498,
          456,
          311,
          364,
          4496,
          286,
          611,
          528,
          281,
          909,
          300,
          294,
          370,
          586,
          51004
        ]
      },
      {
        "avg_logprob": -0.2085459357813785,
        "compression_ratio": 1.722943722943723,
        "end": 7988.24,
        "id": 1733,
        "no_speech_prob": 0.0007553995819762349,
        "seek": 796720,
        "start": 7981.2,
        "temperature": 0,
        "text": " We should be good. If somebody asks a question. We are now replying with at that person. Oh, and this should have an at",
        "tokens": [
          51064,
          492,
          820,
          312,
          665,
          13,
          759,
          2618,
          8962,
          257,
          1168,
          13,
          492,
          366,
          586,
          1085,
          7310,
          365,
          412,
          300,
          954,
          13,
          876,
          11,
          293,
          341,
          820,
          362,
          364,
          412,
          51416
        ]
      },
      {
        "avg_logprob": -0.2085459357813785,
        "compression_ratio": 1.722943722943723,
        "end": 7992.08,
        "id": 1734,
        "no_speech_prob": 0.0007553995819762349,
        "seek": 796720,
        "start": 7990.08,
        "temperature": 0,
        "text": " At that person did I do that up here?",
        "tokens": [
          51508,
          1711,
          300,
          954,
          630,
          286,
          360,
          300,
          493,
          510,
          30,
          51608
        ]
      },
      {
        "avg_logprob": -0.2085459357813785,
        "compression_ratio": 1.722943722943723,
        "end": 7993.84,
        "id": 1735,
        "no_speech_prob": 0.0007553995819762349,
        "seek": 796720,
        "start": 7992.88,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51648,
          1105,
          51696
        ]
      },
      {
        "avg_logprob": -0.2085459357813785,
        "compression_ratio": 1.722943722943723,
        "end": 7995.84,
        "id": 1736,
        "no_speech_prob": 0.0007553995819762349,
        "seek": 796720,
        "start": 7993.84,
        "temperature": 0,
        "text": " When I yes at account",
        "tokens": [
          51696,
          1133,
          286,
          2086,
          412,
          2696,
          51796
        ]
      },
      {
        "avg_logprob": -0.1784107296965843,
        "compression_ratio": 1.2583333333333333,
        "end": 7999.68,
        "id": 1737,
        "no_speech_prob": 0.00000880104835232487,
        "seek": 799584,
        "start": 7995.92,
        "temperature": 0,
        "text": " So at account the meaning of life is and then the number okay, here we go",
        "tokens": [
          50368,
          407,
          412,
          2696,
          264,
          3620,
          295,
          993,
          307,
          293,
          550,
          264,
          1230,
          1392,
          11,
          510,
          321,
          352,
          50556
        ]
      },
      {
        "avg_logprob": -0.1784107296965843,
        "compression_ratio": 1.2583333333333333,
        "end": 8003.2,
        "id": 1738,
        "no_speech_prob": 0.00000880104835232487,
        "seek": 799584,
        "start": 8000.24,
        "temperature": 0,
        "text": " Uh, let's actually run this you can now ask me your questions",
        "tokens": [
          50584,
          4019,
          11,
          718,
          311,
          767,
          1190,
          341,
          291,
          393,
          586,
          1029,
          385,
          428,
          1651,
          50732
        ]
      },
      {
        "avg_logprob": -0.1784107296965843,
        "compression_ratio": 1.2583333333333333,
        "end": 8006.56,
        "id": 1739,
        "no_speech_prob": 0.00000880104835232487,
        "seek": 799584,
        "start": 8004.56,
        "temperature": 0,
        "text": " And I will wait",
        "tokens": [
          50800,
          400,
          286,
          486,
          1699,
          50900
        ]
      },
      {
        "avg_logprob": -0.2780084867735167,
        "compression_ratio": 1.1979166666666667,
        "end": 8009.52,
        "id": 1740,
        "no_speech_prob": 0.0028008718509227037,
        "seek": 800656,
        "start": 8007.52,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50412,
          407,
          50512
        ]
      },
      {
        "avg_logprob": -0.2780084867735167,
        "compression_ratio": 1.1979166666666667,
        "end": 8032.160000000001,
        "id": 1741,
        "no_speech_prob": 0.0028008718509227037,
        "seek": 800656,
        "start": 8025.04,
        "temperature": 0,
        "text": " All right, i'm back and a bunch of people or at least two I got two, uh mentions so if I go back now and look at",
        "tokens": [
          51288,
          1057,
          558,
          11,
          741,
          478,
          646,
          293,
          257,
          3840,
          295,
          561,
          420,
          412,
          1935,
          732,
          286,
          658,
          732,
          11,
          2232,
          23844,
          370,
          498,
          286,
          352,
          646,
          586,
          293,
          574,
          412,
          51644
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8034.5599999999995,
        "id": 1742,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8033.04,
        "temperature": 0,
        "text": " My bot account",
        "tokens": [
          50408,
          1222,
          10592,
          2696,
          50484
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8036.5599999999995,
        "id": 1743,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8034.5599999999995,
        "temperature": 0,
        "text": " Hopefully it's not too spammy",
        "tokens": [
          50484,
          10429,
          309,
          311,
          406,
          886,
          24028,
          2226,
          50584
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8041.28,
        "id": 1744,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8036.88,
        "temperature": 0,
        "text": " Are you for real and then we look at this we can see the meaning of life is 40",
        "tokens": [
          50600,
          2014,
          291,
          337,
          957,
          293,
          550,
          321,
          574,
          412,
          341,
          321,
          393,
          536,
          264,
          3620,
          295,
          993,
          307,
          3356,
          50820
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8044.32,
        "id": 1745,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8041.599999999999,
        "temperature": 0,
        "text": " Uh, and this one has a question like this",
        "tokens": [
          50836,
          4019,
          11,
          293,
          341,
          472,
          575,
          257,
          1168,
          411,
          341,
          50972
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8051.28,
        "id": 1746,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8045.04,
        "temperature": 0,
        "text": " um, uh, yes, you can see the meaning of life is 65 and i'm just curious if somebody I was looking for one that also has",
        "tokens": [
          51008,
          1105,
          11,
          2232,
          11,
          2086,
          11,
          291,
          393,
          536,
          264,
          3620,
          295,
          993,
          307,
          11624,
          293,
          741,
          478,
          445,
          6369,
          498,
          2618,
          286,
          390,
          1237,
          337,
          472,
          300,
          611,
          575,
          51320
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8052.96,
        "id": 1747,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8051.36,
        "temperature": 0,
        "text": " the",
        "tokens": [
          51324,
          264,
          51404
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8054.96,
        "id": 1748,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8052.96,
        "temperature": 0,
        "text": " So this one for example",
        "tokens": [
          51404,
          407,
          341,
          472,
          337,
          1365,
          51504
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8058.16,
        "id": 1749,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8055.44,
        "temperature": 0,
        "text": " Some fake dan shiffman. This one was both",
        "tokens": [
          51528,
          2188,
          7592,
          3277,
          402,
          3661,
          1601,
          13,
          639,
          472,
          390,
          1293,
          51664
        ]
      },
      {
        "avg_logprob": -0.2413796932897835,
        "compression_ratio": 1.634703196347032,
        "end": 8060.46,
        "id": 1750,
        "no_speech_prob": 0.006192842964082956,
        "seek": 803216,
        "start": 8059.04,
        "temperature": 0,
        "text": " uh",
        "tokens": [
          51708,
          2232,
          51779
        ]
      },
      {
        "avg_logprob": -0.2477146680237817,
        "compression_ratio": 1.6442687747035574,
        "end": 8067.82,
        "id": 1751,
        "no_speech_prob": 0.00031503650825470686,
        "seek": 806046,
        "start": 8060.52,
        "temperature": 0,
        "text": " Favorited and boosted and replied to so this bot will actually do all of the things it is now a bot. Oh, look at this",
        "tokens": [
          50367,
          34240,
          1226,
          293,
          9194,
          292,
          293,
          20345,
          281,
          370,
          341,
          10592,
          486,
          767,
          360,
          439,
          295,
          264,
          721,
          309,
          307,
          586,
          257,
          10592,
          13,
          876,
          11,
          574,
          412,
          341,
          50732
        ]
      },
      {
        "avg_logprob": -0.2477146680237817,
        "compression_ratio": 1.6442687747035574,
        "end": 8070.62,
        "id": 1752,
        "no_speech_prob": 0.00031503650825470686,
        "seek": 806046,
        "start": 8068.54,
        "temperature": 0,
        "text": " Uh, i'm just going to favorite this manually",
        "tokens": [
          50768,
          4019,
          11,
          741,
          478,
          445,
          516,
          281,
          2954,
          341,
          16945,
          50872
        ]
      },
      {
        "avg_logprob": -0.2477146680237817,
        "compression_ratio": 1.6442687747035574,
        "end": 8075.9800000000005,
        "id": 1753,
        "no_speech_prob": 0.00031503650825470686,
        "seek": 806046,
        "start": 8071.02,
        "temperature": 0,
        "text": " Um, by the way, everyone should look at alka's panable lisa jue table. Um, it's wonderful",
        "tokens": [
          50892,
          3301,
          11,
          538,
          264,
          636,
          11,
          1518,
          820,
          574,
          412,
          419,
          2330,
          311,
          2462,
          712,
          287,
          3837,
          361,
          622,
          3199,
          13,
          3301,
          11,
          309,
          311,
          3715,
          51140
        ]
      },
      {
        "avg_logprob": -0.2477146680237817,
        "compression_ratio": 1.6442687747035574,
        "end": 8079.74,
        "id": 1754,
        "no_speech_prob": 0.00031503650825470686,
        "seek": 806046,
        "start": 8076.22,
        "temperature": 0,
        "text": " Uh, I am will be releasing my lisa jue coding challenge video very soon",
        "tokens": [
          51152,
          4019,
          11,
          286,
          669,
          486,
          312,
          16327,
          452,
          287,
          3837,
          361,
          622,
          17720,
          3430,
          960,
          588,
          2321,
          51328
        ]
      },
      {
        "avg_logprob": -0.2477146680237817,
        "compression_ratio": 1.6442687747035574,
        "end": 8081.42,
        "id": 1755,
        "no_speech_prob": 0.00031503650825470686,
        "seek": 806046,
        "start": 8080.3,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51356,
          1105,
          51412
        ]
      },
      {
        "avg_logprob": -0.2477146680237817,
        "compression_ratio": 1.6442687747035574,
        "end": 8085.82,
        "id": 1756,
        "no_speech_prob": 0.00031503650825470686,
        "seek": 806046,
        "start": 8081.42,
        "temperature": 0,
        "text": " And here you go. So this is it. Uh, we have now finished this up. We now have made a bot",
        "tokens": [
          51412,
          400,
          510,
          291,
          352,
          13,
          407,
          341,
          307,
          309,
          13,
          4019,
          11,
          321,
          362,
          586,
          4335,
          341,
          493,
          13,
          492,
          586,
          362,
          1027,
          257,
          10592,
          51632
        ]
      },
      {
        "avg_logprob": -0.2035168068749564,
        "compression_ratio": 1.7689243027888446,
        "end": 8093.34,
        "id": 1757,
        "no_speech_prob": 0.013222034089267254,
        "seek": 808582,
        "start": 8085.9,
        "temperature": 0,
        "text": " We've seen how a bot can post periodically with set interval something and you might come up with an idea of what you want to do",
        "tokens": [
          50368,
          492,
          600,
          1612,
          577,
          257,
          10592,
          393,
          2183,
          38916,
          365,
          992,
          15035,
          746,
          293,
          291,
          1062,
          808,
          493,
          365,
          364,
          1558,
          295,
          437,
          291,
          528,
          281,
          360,
          50740
        ]
      },
      {
        "avg_logprob": -0.2035168068749564,
        "compression_ratio": 1.7689243027888446,
        "end": 8098.299999999999,
        "id": 1758,
        "no_speech_prob": 0.013222034089267254,
        "seek": 808582,
        "start": 8093.58,
        "temperature": 0,
        "text": " We have now seen how a bot can favorite or boost things and reply to things",
        "tokens": [
          50752,
          492,
          362,
          586,
          1612,
          577,
          257,
          10592,
          393,
          2954,
          420,
          9194,
          721,
          293,
          16972,
          281,
          721,
          50988
        ]
      },
      {
        "avg_logprob": -0.2035168068749564,
        "compression_ratio": 1.7689243027888446,
        "end": 8104,
        "id": 1759,
        "no_speech_prob": 0.013222034089267254,
        "seek": 808582,
        "start": 8098.54,
        "temperature": 0,
        "text": " So now it's time for you to be creative what kinds of replies what kinds of activity?",
        "tokens": [
          51000,
          407,
          586,
          309,
          311,
          565,
          337,
          291,
          281,
          312,
          5880,
          437,
          3685,
          295,
          42289,
          437,
          3685,
          295,
          5191,
          30,
          51273
        ]
      },
      {
        "avg_logprob": -0.2035168068749564,
        "compression_ratio": 1.7689243027888446,
        "end": 8107.42,
        "id": 1760,
        "no_speech_prob": 0.013222034089267254,
        "seek": 808582,
        "start": 8104.46,
        "temperature": 0,
        "text": " Maybe you have a bot that uh makes up a poem",
        "tokens": [
          51296,
          2704,
          291,
          362,
          257,
          10592,
          300,
          2232,
          1669,
          493,
          257,
          13065,
          51444
        ]
      },
      {
        "avg_logprob": -0.2035168068749564,
        "compression_ratio": 1.7689243027888446,
        "end": 8112.219999999999,
        "id": 1761,
        "no_speech_prob": 0.013222034089267254,
        "seek": 808582,
        "start": 8107.9,
        "temperature": 0,
        "text": " I haven't shown you how to generate an image and post it so I will show you that i've got to make a video to",
        "tokens": [
          51468,
          286,
          2378,
          380,
          4898,
          291,
          577,
          281,
          8460,
          364,
          3256,
          293,
          2183,
          309,
          370,
          286,
          486,
          855,
          291,
          300,
          741,
          600,
          658,
          281,
          652,
          257,
          960,
          281,
          51684
        ]
      },
      {
        "avg_logprob": -0.18318807813856336,
        "compression_ratio": 1.5258215962441315,
        "end": 8113.1,
        "id": 1762,
        "no_speech_prob": 0.000035355293221073225,
        "seek": 811222,
        "start": 8112.22,
        "temperature": 0,
        "text": " Show you how to do that",
        "tokens": [
          50364,
          6895,
          291,
          577,
          281,
          360,
          300,
          50408
        ]
      },
      {
        "avg_logprob": -0.18318807813856336,
        "compression_ratio": 1.5258215962441315,
        "end": 8119.740000000001,
        "id": 1763,
        "no_speech_prob": 0.000035355293221073225,
        "seek": 811222,
        "start": 8113.1,
        "temperature": 0,
        "text": " But there's all sorts of wonderful possibilities of how you can make your automated bot using on mastodon at bots in dot space",
        "tokens": [
          50408,
          583,
          456,
          311,
          439,
          7527,
          295,
          3715,
          12178,
          295,
          577,
          291,
          393,
          652,
          428,
          18473,
          10592,
          1228,
          322,
          27055,
          378,
          266,
          412,
          35410,
          294,
          5893,
          1901,
          50740
        ]
      },
      {
        "avg_logprob": -0.18318807813856336,
        "compression_ratio": 1.5258215962441315,
        "end": 8122.06,
        "id": 1764,
        "no_speech_prob": 0.000035355293221073225,
        "seek": 811222,
        "start": 8120.06,
        "temperature": 0,
        "text": " Okay, so choo-choo everybody",
        "tokens": [
          50756,
          1033,
          11,
          370,
          1586,
          78,
          12,
          339,
          1986,
          2201,
          50856
        ]
      },
      {
        "avg_logprob": -0.18318807813856336,
        "compression_ratio": 1.5258215962441315,
        "end": 8129.18,
        "id": 1765,
        "no_speech_prob": 0.000035355293221073225,
        "seek": 811222,
        "start": 8122.62,
        "temperature": 0,
        "text": " See you in a future video. I hope you enjoyed this series about making a mastodon bot more to come in the future",
        "tokens": [
          50884,
          3008,
          291,
          294,
          257,
          2027,
          960,
          13,
          286,
          1454,
          291,
          4626,
          341,
          2638,
          466,
          1455,
          257,
          27055,
          378,
          266,
          10592,
          544,
          281,
          808,
          294,
          264,
          2027,
          51212
        ]
      },
      {
        "avg_logprob": -0.18318807813856336,
        "compression_ratio": 1.5258215962441315,
        "end": 8131.18,
        "id": 1766,
        "no_speech_prob": 0.000035355293221073225,
        "seek": 811222,
        "start": 8129.18,
        "temperature": 0,
        "text": " I i'm sure goodbye",
        "tokens": [
          51212,
          286,
          741,
          478,
          988,
          12084,
          51312
        ]
      },
      {
        "avg_logprob": -0.18318807813856336,
        "compression_ratio": 1.5258215962441315,
        "end": 8135.740000000001,
        "id": 1767,
        "no_speech_prob": 0.000035355293221073225,
        "seek": 811222,
        "start": 8133.740000000001,
        "temperature": 0,
        "text": " All right, um",
        "tokens": [
          51440,
          1057,
          558,
          11,
          1105,
          51540
        ]
      },
      {
        "avg_logprob": -0.2908527692159017,
        "compression_ratio": 1.4892086330935252,
        "end": 8137.74,
        "id": 1768,
        "no_speech_prob": 0.00036257816827856004,
        "seek": 813574,
        "start": 8135.74,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50364,
          3301,
          50464
        ]
      },
      {
        "avg_logprob": -0.2908527692159017,
        "compression_ratio": 1.4892086330935252,
        "end": 8146.139999999999,
        "id": 1769,
        "no_speech_prob": 0.00036257816827856004,
        "seek": 813574,
        "start": 8143.74,
        "temperature": 0,
        "text": " Come on come back",
        "tokens": [
          50764,
          2492,
          322,
          808,
          646,
          50884
        ]
      },
      {
        "avg_logprob": -0.2908527692159017,
        "compression_ratio": 1.4892086330935252,
        "end": 8152.86,
        "id": 1770,
        "no_speech_prob": 0.00036257816827856004,
        "seek": 813574,
        "start": 8149.58,
        "temperature": 0,
        "text": " Yeah, an undefined one would probably that probably would be fine",
        "tokens": [
          51056,
          865,
          11,
          364,
          674,
          5666,
          2001,
          472,
          576,
          1391,
          300,
          1391,
          576,
          312,
          2489,
          51220
        ]
      },
      {
        "avg_logprob": -0.2908527692159017,
        "compression_ratio": 1.4892086330935252,
        "end": 8156.7,
        "id": 1771,
        "no_speech_prob": 0.00036257816827856004,
        "seek": 813574,
        "start": 8154.54,
        "temperature": 0,
        "text": " Um a me I am certainly made a good point",
        "tokens": [
          51304,
          3301,
          257,
          385,
          286,
          669,
          3297,
          1027,
          257,
          665,
          935,
          51412
        ]
      },
      {
        "avg_logprob": -0.2908527692159017,
        "compression_ratio": 1.4892086330935252,
        "end": 8161.82,
        "id": 1772,
        "no_speech_prob": 0.00036257816827856004,
        "seek": 813574,
        "start": 8157.26,
        "temperature": 0,
        "text": " I imagine an undefined and reply to id would be allowed to mean there isn't one",
        "tokens": [
          51440,
          286,
          3811,
          364,
          674,
          5666,
          2001,
          293,
          16972,
          281,
          4496,
          576,
          312,
          4350,
          281,
          914,
          456,
          1943,
          380,
          472,
          51668
        ]
      },
      {
        "avg_logprob": -0.20715982913970948,
        "compression_ratio": 1.5310734463276836,
        "end": 8165.58,
        "id": 1773,
        "no_speech_prob": 0.00023781978234183043,
        "seek": 816182,
        "start": 8162.299999999999,
        "temperature": 0,
        "text": " So I probably didn't need that extra step, but I did do it. All right",
        "tokens": [
          50388,
          407,
          286,
          1391,
          994,
          380,
          643,
          300,
          2857,
          1823,
          11,
          457,
          286,
          630,
          360,
          309,
          13,
          1057,
          558,
          50552
        ]
      },
      {
        "avg_logprob": -0.20715982913970948,
        "compression_ratio": 1.5310734463276836,
        "end": 8171.5,
        "id": 1774,
        "no_speech_prob": 0.00023781978234183043,
        "seek": 816182,
        "start": 8166.299999999999,
        "temperature": 0,
        "text": " so, um, I this bot is I wonder if I should deploy this bot somewhere",
        "tokens": [
          50588,
          370,
          11,
          1105,
          11,
          286,
          341,
          10592,
          307,
          286,
          2441,
          498,
          286,
          820,
          7274,
          341,
          10592,
          4079,
          50848
        ]
      },
      {
        "avg_logprob": -0.20715982913970948,
        "compression_ratio": 1.5310734463276836,
        "end": 8174.219999999999,
        "id": 1775,
        "no_speech_prob": 0.00023781978234183043,
        "seek": 816182,
        "start": 8172.219999999999,
        "temperature": 0,
        "text": " um so that um",
        "tokens": [
          50884,
          1105,
          370,
          300,
          1105,
          50984
        ]
      },
      {
        "avg_logprob": -0.20715982913970948,
        "compression_ratio": 1.5310734463276836,
        "end": 8179.759999999999,
        "id": 1776,
        "no_speech_prob": 0.00023781978234183043,
        "seek": 816182,
        "start": 8175.0199999999995,
        "temperature": 0,
        "text": " People who watch the videos can interact with it, but um, it did hit 42",
        "tokens": [
          51024,
          3432,
          567,
          1159,
          264,
          2145,
          393,
          4648,
          365,
          309,
          11,
          457,
          1105,
          11,
          309,
          630,
          2045,
          14034,
          51261
        ]
      },
      {
        "avg_logprob": -0.20715982913970948,
        "compression_ratio": 1.5310734463276836,
        "end": 8183.34,
        "id": 1777,
        "no_speech_prob": 0.00023781978234183043,
        "seek": 816182,
        "start": 8181.34,
        "temperature": 0,
        "text": " Where where where where where?",
        "tokens": [
          51340,
          2305,
          689,
          689,
          689,
          689,
          30,
          51440
        ]
      },
      {
        "avg_logprob": -0.20715982913970948,
        "compression_ratio": 1.5310734463276836,
        "end": 8188.299999999999,
        "id": 1778,
        "no_speech_prob": 0.00023781978234183043,
        "seek": 816182,
        "start": 8186.299999999999,
        "temperature": 0,
        "text": " Oh, there we go",
        "tokens": [
          51588,
          876,
          11,
          456,
          321,
          352,
          51688
        ]
      },
      {
        "avg_logprob": -0.7619310525747446,
        "compression_ratio": 1.1511627906976745,
        "end": 8197.119999999999,
        "id": 1779,
        "no_speech_prob": 0.00007483450463041663,
        "seek": 819182,
        "start": 8192.06,
        "temperature": 0,
        "text": " So, can I desktop",
        "tokens": [
          50376,
          407,
          11,
          393,
          286,
          14502,
          50629
        ]
      },
      {
        "avg_logprob": -0.7619310525747446,
        "compression_ratio": 1.1511627906976745,
        "end": 8204.86,
        "id": 1780,
        "no_speech_prob": 0.00007483450463041663,
        "seek": 819182,
        "start": 8202.86,
        "temperature": 0,
        "text": " There we go",
        "tokens": [
          50916,
          821,
          321,
          352,
          51016
        ]
      },
      {
        "avg_logprob": -0.7619310525747446,
        "compression_ratio": 1.1511627906976745,
        "end": 8209.66,
        "id": 1781,
        "no_speech_prob": 0.00007483450463041663,
        "seek": 819182,
        "start": 8207.66,
        "temperature": 0,
        "text": " There we go",
        "tokens": [
          51156,
          821,
          321,
          352,
          51256
        ]
      },
      {
        "avg_logprob": -0.7619310525747446,
        "compression_ratio": 1.1511627906976745,
        "end": 8212.86,
        "id": 1782,
        "no_speech_prob": 0.00007483450463041663,
        "seek": 819182,
        "start": 8210.86,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          51316,
          1033,
          51416
        ]
      },
      {
        "avg_logprob": -0.7619310525747446,
        "compression_ratio": 1.1511627906976745,
        "end": 8216.539999999999,
        "id": 1783,
        "no_speech_prob": 0.00007483450463041663,
        "seek": 819182,
        "start": 8212.94,
        "temperature": 0,
        "text": " Um, all right everyone this by the way, if is my uh,",
        "tokens": [
          51420,
          3301,
          11,
          439,
          558,
          1518,
          341,
          538,
          264,
          636,
          11,
          498,
          307,
          452,
          2232,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.31319508185753453,
        "compression_ratio": 1.5032258064516129,
        "end": 8218.460000000001,
        "id": 1784,
        "no_speech_prob": 0.0034830900840461254,
        "seek": 821654,
        "start": 8216.78,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50376,
          1033,
          50460
        ]
      },
      {
        "avg_logprob": -0.31319508185753453,
        "compression_ratio": 1.5032258064516129,
        "end": 8221.900000000001,
        "id": 1785,
        "no_speech_prob": 0.0034830900840461254,
        "seek": 821654,
        "start": 8218.460000000001,
        "temperature": 0,
        "text": " um, all right everyone this by the way, if is my um,",
        "tokens": [
          50460,
          1105,
          11,
          439,
          558,
          1518,
          341,
          538,
          264,
          636,
          11,
          498,
          307,
          452,
          1105,
          11,
          50632
        ]
      },
      {
        "avg_logprob": -0.31319508185753453,
        "compression_ratio": 1.5032258064516129,
        "end": 8225.02,
        "id": 1786,
        "no_speech_prob": 0.0034830900840461254,
        "seek": 821654,
        "start": 8223.02,
        "temperature": 0,
        "text": " I am now on",
        "tokens": [
          50688,
          286,
          669,
          586,
          322,
          50788
        ]
      },
      {
        "avg_logprob": -0.31319508185753453,
        "compression_ratio": 1.5032258064516129,
        "end": 8226.76,
        "id": 1787,
        "no_speech_prob": 0.0034830900840461254,
        "seek": 821654,
        "start": 8225.080000000002,
        "temperature": 0,
        "text": " mastodon at",
        "tokens": [
          50791,
          27055,
          378,
          266,
          412,
          50875
        ]
      },
      {
        "avg_logprob": -0.31319508185753453,
        "compression_ratio": 1.5032258064516129,
        "end": 8229.02,
        "id": 1788,
        "no_speech_prob": 0.0034830900840461254,
        "seek": 821654,
        "start": 8226.76,
        "temperature": 0,
        "text": " shifman at choo-choo dot space",
        "tokens": [
          50875,
          402,
          351,
          1601,
          412,
          1586,
          78,
          12,
          339,
          1986,
          5893,
          1901,
          50988
        ]
      },
      {
        "avg_logprob": -0.31319508185753453,
        "compression_ratio": 1.5032258064516129,
        "end": 8232.380000000001,
        "id": 1789,
        "no_speech_prob": 0.0034830900840461254,
        "seek": 821654,
        "start": 8230.060000000001,
        "temperature": 0,
        "text": " again, unfortunately right now I am",
        "tokens": [
          51040,
          797,
          11,
          7015,
          558,
          586,
          286,
          669,
          51156
        ]
      },
      {
        "avg_logprob": -0.31319508185753453,
        "compression_ratio": 1.5032258064516129,
        "end": 8239.42,
        "id": 1790,
        "no_speech_prob": 0.0034830900840461254,
        "seek": 821654,
        "start": 8233.18,
        "temperature": 0,
        "text": " Leaving choo-choo dot space closed for uh, youtube members or patrons and I would um",
        "tokens": [
          51196,
          41253,
          1586,
          78,
          12,
          339,
          1986,
          5893,
          1901,
          5395,
          337,
          2232,
          11,
          12487,
          2679,
          420,
          27559,
          293,
          286,
          576,
          1105,
          51508
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8241.42,
        "id": 1791,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8239.42,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50364,
          3301,
          50464
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8245.1,
        "id": 1792,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8243.1,
        "temperature": 0,
        "text": " Gladly open that up. Sorry, um",
        "tokens": [
          50548,
          28301,
          356,
          1269,
          300,
          493,
          13,
          4919,
          11,
          1105,
          50648
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8248.94,
        "id": 1793,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8245.82,
        "temperature": 0,
        "text": " Open that up if um, if it makes sense to do that at some point",
        "tokens": [
          50684,
          7238,
          300,
          493,
          498,
          1105,
          11,
          498,
          309,
          1669,
          2020,
          281,
          360,
          300,
          412,
          512,
          935,
          50840
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8254.54,
        "id": 1794,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8249.34,
        "temperature": 0,
        "text": " All right. Anyone have any questions they want to ask? I think i'm finished for today. It's almost five o'clock",
        "tokens": [
          50860,
          1057,
          558,
          13,
          14643,
          362,
          604,
          1651,
          436,
          528,
          281,
          1029,
          30,
          286,
          519,
          741,
          478,
          4335,
          337,
          965,
          13,
          467,
          311,
          1920,
          1732,
          277,
          6,
          9023,
          51120
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8259.5,
        "id": 1795,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8255.34,
        "temperature": 0,
        "text": " Um, you could deploy it on the same box choo-choo dot space instances on exactly. That's what i'll do",
        "tokens": [
          51160,
          3301,
          11,
          291,
          727,
          7274,
          309,
          322,
          264,
          912,
          2424,
          1586,
          78,
          12,
          339,
          1986,
          5893,
          1901,
          14519,
          322,
          2293,
          13,
          663,
          311,
          437,
          741,
          603,
          360,
          51368
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8261.74,
        "id": 1796,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8259.74,
        "temperature": 0,
        "text": " Maybe I should do that real quick right now",
        "tokens": [
          51380,
          2704,
          286,
          820,
          360,
          300,
          957,
          1702,
          558,
          586,
          51480
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8265.18,
        "id": 1797,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8262.94,
        "temperature": 0,
        "text": " I'm afraid to log into that instance ever",
        "tokens": [
          51540,
          286,
          478,
          4638,
          281,
          3565,
          666,
          300,
          5197,
          1562,
          51652
        ]
      },
      {
        "avg_logprob": -0.24538803100585938,
        "compression_ratio": 1.5229007633587786,
        "end": 8267.82,
        "id": 1798,
        "no_speech_prob": 0.00021318270592018962,
        "seek": 823942,
        "start": 8265.82,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51684,
          1105,
          51784
        ]
      },
      {
        "avg_logprob": -0.21214993794759116,
        "compression_ratio": 1.6682692307692308,
        "end": 8269.98,
        "id": 1799,
        "no_speech_prob": 0.0005702913040295243,
        "seek": 826782,
        "start": 8267.98,
        "temperature": 0,
        "text": " All right, um",
        "tokens": [
          50372,
          1057,
          558,
          11,
          1105,
          50472
        ]
      },
      {
        "avg_logprob": -0.21214993794759116,
        "compression_ratio": 1.6682692307692308,
        "end": 8273.26,
        "id": 1800,
        "no_speech_prob": 0.0005702913040295243,
        "seek": 826782,
        "start": 8269.98,
        "temperature": 0,
        "text": " Anybody any anything else to say to do to wonder?",
        "tokens": [
          50472,
          19082,
          604,
          1340,
          1646,
          281,
          584,
          281,
          360,
          281,
          2441,
          30,
          50636
        ]
      },
      {
        "avg_logprob": -0.21214993794759116,
        "compression_ratio": 1.6682692307692308,
        "end": 8276.539999999999,
        "id": 1801,
        "no_speech_prob": 0.0005702913040295243,
        "seek": 826782,
        "start": 8274.22,
        "temperature": 0,
        "text": " Um, oh, let me mention let me do something right now",
        "tokens": [
          50684,
          3301,
          11,
          1954,
          11,
          718,
          385,
          2152,
          718,
          385,
          360,
          746,
          558,
          586,
          50800
        ]
      },
      {
        "avg_logprob": -0.21214993794759116,
        "compression_ratio": 1.6682692307692308,
        "end": 8283.119999999999,
        "id": 1802,
        "no_speech_prob": 0.0005702913040295243,
        "seek": 826782,
        "start": 8278.619999999999,
        "temperature": 0,
        "text": " Because I have so many videos now i'm gonna go here most recently",
        "tokens": [
          50904,
          1436,
          286,
          362,
          370,
          867,
          2145,
          586,
          741,
          478,
          799,
          352,
          510,
          881,
          3938,
          51129
        ]
      },
      {
        "avg_logprob": -0.21214993794759116,
        "compression_ratio": 1.6682692307692308,
        "end": 8291.26,
        "id": 1803,
        "no_speech_prob": 0.0005702913040295243,
        "seek": 826782,
        "start": 8285.02,
        "temperature": 0,
        "text": " This style transfer video posted let me go here and post the next one",
        "tokens": [
          51224,
          639,
          3758,
          5003,
          960,
          9437,
          718,
          385,
          352,
          510,
          293,
          2183,
          264,
          958,
          472,
          51536
        ]
      },
      {
        "avg_logprob": -0.21214993794759116,
        "compression_ratio": 1.6682692307692308,
        "end": 8297.26,
        "id": 1804,
        "no_speech_prob": 0.0005702913040295243,
        "seek": 826782,
        "start": 8293.18,
        "temperature": 0,
        "text": " So I would love people to try out the style transfer thing and see if you're able to follow it",
        "tokens": [
          51632,
          407,
          286,
          576,
          959,
          561,
          281,
          853,
          484,
          264,
          3758,
          5003,
          551,
          293,
          536,
          498,
          291,
          434,
          1075,
          281,
          1524,
          309,
          51836
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8300.94,
        "id": 1805,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8298.779999999999,
        "temperature": 0,
        "text": " um, so, um the",
        "tokens": [
          50412,
          1105,
          11,
          370,
          11,
          1105,
          264,
          50520
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8304.619999999999,
        "id": 1806,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8301.9,
        "temperature": 0,
        "text": " second style transfer video part two",
        "tokens": [
          50568,
          1150,
          3758,
          5003,
          960,
          644,
          732,
          50704
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8307.9,
        "id": 1807,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8305.82,
        "temperature": 0,
        "text": " Um, let me just check this to make sure",
        "tokens": [
          50764,
          3301,
          11,
          718,
          385,
          445,
          1520,
          341,
          281,
          652,
          988,
          50868
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8311.02,
        "id": 1808,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8309.02,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50924,
          1105,
          51024
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8314.14,
        "id": 1809,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8312.14,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          51080,
          3301,
          51180
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8317.34,
        "id": 1810,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8315.1,
        "temperature": 0,
        "text": " I'm going to post that one now",
        "tokens": [
          51228,
          286,
          478,
          516,
          281,
          2183,
          300,
          472,
          586,
          51340
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8320.619999999999,
        "id": 1811,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8318.86,
        "temperature": 0,
        "text": " So in a moment",
        "tokens": [
          51416,
          407,
          294,
          257,
          1623,
          51504
        ]
      },
      {
        "avg_logprob": -0.27527065553526947,
        "compression_ratio": 1.4285714285714286,
        "end": 8324.06,
        "id": 1812,
        "no_speech_prob": 0.000004565934432321228,
        "seek": 829782,
        "start": 8320.619999999999,
        "temperature": 0,
        "text": " I'm releasing I don't have the youtube premiere thing unlocked in my account",
        "tokens": [
          51504,
          286,
          478,
          16327,
          286,
          500,
          380,
          362,
          264,
          12487,
          28372,
          551,
          30180,
          294,
          452,
          2696,
          51676
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8326.06,
        "id": 1813,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8324.06,
        "temperature": 0,
        "text": " I really want to get that unlocked in my account",
        "tokens": [
          50364,
          286,
          534,
          528,
          281,
          483,
          300,
          30180,
          294,
          452,
          2696,
          50464
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8330.699999999999,
        "id": 1814,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8326.38,
        "temperature": 0,
        "text": " Because I think it'll be fun to interact live the first time a video is posted even though it's like the second time",
        "tokens": [
          50480,
          1436,
          286,
          519,
          309,
          603,
          312,
          1019,
          281,
          4648,
          1621,
          264,
          700,
          565,
          257,
          960,
          307,
          9437,
          754,
          1673,
          309,
          311,
          411,
          264,
          1150,
          565,
          50696
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8335.019999999999,
        "id": 1815,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8330.699999999999,
        "temperature": 0,
        "text": " It's already additional live stream, but you know, so i'm going to set part two public",
        "tokens": [
          50696,
          467,
          311,
          1217,
          4497,
          1621,
          4309,
          11,
          457,
          291,
          458,
          11,
          370,
          741,
          478,
          516,
          281,
          992,
          644,
          732,
          1908,
          50912
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8337.1,
        "id": 1816,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8335.98,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50960,
          1105,
          51016
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8339.1,
        "id": 1817,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8337.1,
        "temperature": 0,
        "text": " And i'm gonna say actions",
        "tokens": [
          51016,
          400,
          741,
          478,
          799,
          584,
          5909,
          51116
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8341.019999999999,
        "id": 1818,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8339.8,
        "temperature": 0,
        "text": " public",
        "tokens": [
          51151,
          1908,
          51212
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8343.019999999999,
        "id": 1819,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8341.019999999999,
        "temperature": 0,
        "text": " I understand that I can't undo",
        "tokens": [
          51212,
          286,
          1223,
          300,
          286,
          393,
          380,
          23779,
          51312
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8345.34,
        "id": 1820,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8343.34,
        "temperature": 0,
        "text": " and now",
        "tokens": [
          51328,
          293,
          586,
          51428
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8348.699999999999,
        "id": 1821,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8345.34,
        "temperature": 0,
        "text": " We should see here just released on the channel",
        "tokens": [
          51428,
          492,
          820,
          536,
          510,
          445,
          4736,
          322,
          264,
          2269,
          51596
        ]
      },
      {
        "avg_logprob": -0.2218012259556697,
        "compression_ratio": 1.6016597510373445,
        "end": 8351.58,
        "id": 1822,
        "no_speech_prob": 0.006289736367762089,
        "seek": 832406,
        "start": 8349.58,
        "temperature": 0,
        "text": " um pending",
        "tokens": [
          51640,
          1105,
          32110,
          51740
        ]
      },
      {
        "avg_logprob": -0.3496240418532799,
        "compression_ratio": 1.502415458937198,
        "end": 8356.22,
        "id": 1823,
        "no_speech_prob": 0.00010554215987212956,
        "seek": 835406,
        "start": 8354.22,
        "temperature": 0.4,
        "text": " Um",
        "tokens": [
          50372,
          220,
          40937,
          50472
        ]
      },
      {
        "avg_logprob": -0.3496240418532799,
        "compression_ratio": 1.502415458937198,
        "end": 8359.019999999999,
        "id": 1824,
        "no_speech_prob": 0.00010554215987212956,
        "seek": 835406,
        "start": 8356.3,
        "temperature": 0.4,
        "text": " Nope come on youtube",
        "tokens": [
          50476,
          12172,
          808,
          322,
          12487,
          50612
        ]
      },
      {
        "avg_logprob": -0.3496240418532799,
        "compression_ratio": 1.502415458937198,
        "end": 8365.58,
        "id": 1825,
        "no_speech_prob": 0.00010554215987212956,
        "seek": 835406,
        "start": 8361.5,
        "temperature": 0.4,
        "text": " Uh, etan asks, will you explain how style transfer works in more technical terms?",
        "tokens": [
          50736,
          4019,
          11,
          1030,
          282,
          8962,
          11,
          486,
          291,
          2903,
          577,
          3758,
          5003,
          1985,
          294,
          544,
          6191,
          2115,
          30,
          50940
        ]
      },
      {
        "avg_logprob": -0.3496240418532799,
        "compression_ratio": 1.502415458937198,
        "end": 8370.939999999999,
        "id": 1826,
        "no_speech_prob": 0.00010554215987212956,
        "seek": 835406,
        "start": 8365.98,
        "temperature": 0.4,
        "text": " Um, if you were interested in that you should check out. Um, let me let me show you where to find this",
        "tokens": [
          50960,
          3301,
          11,
          498,
          291,
          645,
          3102,
          294,
          300,
          291,
          820,
          1520,
          484,
          13,
          3301,
          11,
          718,
          385,
          718,
          385,
          855,
          291,
          689,
          281,
          915,
          341,
          51208
        ]
      },
      {
        "avg_logprob": -0.3496240418532799,
        "compression_ratio": 1.502415458937198,
        "end": 8381.6,
        "id": 1827,
        "no_speech_prob": 0.00010554215987212956,
        "seek": 835406,
        "start": 8374.539999999999,
        "temperature": 0.4,
        "text": " I don't know why it's like taking a million years to set this video to public. It's kind of ridiculous",
        "tokens": [
          51388,
          286,
          500,
          380,
          458,
          983,
          309,
          311,
          411,
          1940,
          257,
          2752,
          285,
          313,
          924,
          281,
          992,
          341,
          960,
          281,
          1908,
          13,
          467,
          311,
          733,
          295,
          11083,
          51741
        ]
      },
      {
        "avg_logprob": -0.5892687877976751,
        "compression_ratio": 1.4484536082474226,
        "end": 8385.84,
        "id": 1828,
        "no_speech_prob": 0.0001313492248300463,
        "seek": 838160,
        "start": 8381.84,
        "temperature": 0.4,
        "text": " I don't know why it's taking a million years to set this video to public. It's kind of ridiculous",
        "tokens": [
          50376,
          286,
          500,
          380,
          458,
          983,
          309,
          311,
          1940,
          257,
          2459,
          924,
          281,
          992,
          341,
          960,
          281,
          1908,
          13,
          467,
          311,
          733,
          295,
          11083,
          50576
        ]
      },
      {
        "avg_logprob": -0.5892687877976751,
        "compression_ratio": 1.4484536082474226,
        "end": 8391.84,
        "id": 1829,
        "no_speech_prob": 0.0001313492248300463,
        "seek": 838160,
        "start": 8387.84,
        "temperature": 0.4,
        "text": " Oh, it was successful so now um",
        "tokens": [
          50676,
          876,
          11,
          309,
          390,
          4406,
          370,
          586,
          1105,
          50876
        ]
      },
      {
        "avg_logprob": -0.5892687877976751,
        "compression_ratio": 1.4484536082474226,
        "end": 8395.52,
        "id": 1830,
        "no_speech_prob": 0.0001313492248300463,
        "seek": 838160,
        "start": 8393.92,
        "temperature": 0.4,
        "text": " Part two should",
        "tokens": [
          50980,
          4100,
          732,
          820,
          51060
        ]
      },
      {
        "avg_logprob": -0.5892687877976751,
        "compression_ratio": 1.4484536082474226,
        "end": 8399.44,
        "id": 1831,
        "no_speech_prob": 0.0001313492248300463,
        "seek": 838160,
        "start": 8395.52,
        "temperature": 0.4,
        "text": " Well, hold on. Let me just it'll it'll appear eventually i'm gonna go to playlists",
        "tokens": [
          51060,
          1042,
          11,
          1797,
          322,
          13,
          961,
          385,
          445,
          309,
          603,
          309,
          603,
          4204,
          4728,
          741,
          478,
          799,
          352,
          281,
          862,
          36693,
          51256
        ]
      },
      {
        "avg_logprob": -0.5892687877976751,
        "compression_ratio": 1.4484536082474226,
        "end": 8403.36,
        "id": 1832,
        "no_speech_prob": 0.0001313492248300463,
        "seek": 838160,
        "start": 8400.4,
        "temperature": 0.4,
        "text": " On my channel and i'm going to go to this one",
        "tokens": [
          51304,
          1282,
          452,
          2269,
          293,
          741,
          478,
          516,
          281,
          352,
          281,
          341,
          472,
          51452
        ]
      },
      {
        "avg_logprob": -0.5892687877976751,
        "compression_ratio": 1.4484536082474226,
        "end": 8407.68,
        "id": 1833,
        "no_speech_prob": 0.0001313492248300463,
        "seek": 838160,
        "start": 8405.68,
        "temperature": 0.4,
        "text": " Um and",
        "tokens": [
          51568,
          3301,
          293,
          51668
        ]
      },
      {
        "avg_logprob": -0.29231530093075186,
        "compression_ratio": 1.8974358974358974,
        "end": 8411.76,
        "id": 1834,
        "no_speech_prob": 0.14606009423732758,
        "seek": 840768,
        "start": 8408.64,
        "temperature": 0,
        "text": " The machine learning videos using the spell platform",
        "tokens": [
          50412,
          440,
          3479,
          2539,
          2145,
          1228,
          264,
          9827,
          3663,
          50568
        ]
      },
      {
        "avg_logprob": -0.29231530093075186,
        "compression_ratio": 1.8974358974358974,
        "end": 8413.84,
        "id": 1835,
        "no_speech_prob": 0.14606009423732758,
        "seek": 840768,
        "start": 8412.800000000001,
        "temperature": 0,
        "text": " and",
        "tokens": [
          50620,
          293,
          50672
        ]
      },
      {
        "avg_logprob": -0.29231530093075186,
        "compression_ratio": 1.8974358974358974,
        "end": 8418.800000000001,
        "id": 1836,
        "no_speech_prob": 0.14606009423732758,
        "seek": 840768,
        "start": 8413.84,
        "temperature": 0,
        "text": " This is my introduction to the spell platform. This is the style transfer video",
        "tokens": [
          50672,
          639,
          307,
          452,
          9339,
          281,
          264,
          9827,
          3663,
          13,
          639,
          307,
          264,
          3758,
          5003,
          960,
          50920
        ]
      },
      {
        "avg_logprob": -0.29231530093075186,
        "compression_ratio": 1.8974358974358974,
        "end": 8425.6,
        "id": 1837,
        "no_speech_prob": 0.14606009423732758,
        "seek": 840768,
        "start": 8419.36,
        "temperature": 0,
        "text": " Of how to train your model style transfer model and this is the style transfer video of how to actually run the style transfer model",
        "tokens": [
          50948,
          2720,
          577,
          281,
          3847,
          428,
          2316,
          3758,
          5003,
          2316,
          293,
          341,
          307,
          264,
          3758,
          5003,
          960,
          295,
          577,
          281,
          767,
          1190,
          264,
          3758,
          5003,
          2316,
          51260
        ]
      },
      {
        "avg_logprob": -0.29231530093075186,
        "compression_ratio": 1.8974358974358974,
        "end": 8426.960000000001,
        "id": 1838,
        "no_speech_prob": 0.14606009423732758,
        "seek": 840768,
        "start": 8425.68,
        "temperature": 0,
        "text": " in the browser",
        "tokens": [
          51264,
          294,
          264,
          11185,
          51328
        ]
      },
      {
        "avg_logprob": -0.29231530093075186,
        "compression_ratio": 1.8974358974358974,
        "end": 8433.44,
        "id": 1839,
        "no_speech_prob": 0.14606009423732758,
        "seek": 840768,
        "start": 8426.960000000001,
        "temperature": 0,
        "text": " With ml5js which runs on top of tensorflow.js but um etan in the chat had asked about",
        "tokens": [
          51328,
          2022,
          23271,
          20,
          25530,
          597,
          6676,
          322,
          1192,
          295,
          40863,
          10565,
          13,
          25530,
          457,
          1105,
          1030,
          282,
          294,
          264,
          5081,
          632,
          2351,
          466,
          51652
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8435.36,
        "id": 1840,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8433.68,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50376,
          3301,
          50460
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8441.52,
        "id": 1841,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8435.36,
        "temperature": 0,
        "text": " Explaining style transfer in more detail. I would refer you to so both of these you can see this is about 50 minutes",
        "tokens": [
          50460,
          12514,
          3686,
          3758,
          5003,
          294,
          544,
          2607,
          13,
          286,
          576,
          2864,
          291,
          281,
          370,
          1293,
          295,
          613,
          291,
          393,
          536,
          341,
          307,
          466,
          2625,
          2077,
          50768
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8445.36,
        "id": 1842,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8441.84,
        "temperature": 0,
        "text": " These are edited out of the one hour 26 minute live stream",
        "tokens": [
          50784,
          1981,
          366,
          23016,
          484,
          295,
          264,
          472,
          1773,
          7551,
          3456,
          1621,
          4309,
          50960
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8449.300000000001,
        "id": 1843,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8445.68,
        "temperature": 0,
        "text": " Just to give people sort of streamlined versions of the videos. They just want to follow the tutorials",
        "tokens": [
          50976,
          1449,
          281,
          976,
          561,
          1333,
          295,
          48155,
          9606,
          295,
          264,
          2145,
          13,
          814,
          445,
          528,
          281,
          1524,
          264,
          17616,
          51157
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8451.84,
        "id": 1844,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8449.84,
        "temperature": 0,
        "text": " but if I go to the live stream",
        "tokens": [
          51184,
          457,
          498,
          286,
          352,
          281,
          264,
          1621,
          4309,
          51284
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8454.4,
        "id": 1845,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8452.560000000001,
        "temperature": 0,
        "text": " and",
        "tokens": [
          51320,
          293,
          51412
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8455.92,
        "id": 1846,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8454.4,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51412,
          1105,
          51488
        ]
      },
      {
        "avg_logprob": -0.22219047161063762,
        "compression_ratio": 1.6200873362445414,
        "end": 8459.52,
        "id": 1847,
        "no_speech_prob": 0.004007003270089626,
        "seek": 843344,
        "start": 8455.92,
        "temperature": 0,
        "text": " If I go to the description, sorry, this is like i'm",
        "tokens": [
          51488,
          759,
          286,
          352,
          281,
          264,
          3855,
          11,
          2597,
          11,
          341,
          307,
          411,
          741,
          478,
          51668
        ]
      },
      {
        "avg_logprob": -0.22700094669423204,
        "compression_ratio": 1.5412844036697249,
        "end": 8461.52,
        "id": 1848,
        "no_speech_prob": 0.0026315904688090086,
        "seek": 845952,
        "start": 8459.92,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50384,
          3301,
          50464
        ]
      },
      {
        "avg_logprob": -0.22700094669423204,
        "compression_ratio": 1.5412844036697249,
        "end": 8466.960000000001,
        "id": 1849,
        "no_speech_prob": 0.0026315904688090086,
        "seek": 845952,
        "start": 8461.52,
        "temperature": 0,
        "text": " Oh, this is working now. Never forget the this dot t-shirt. I'll refactor that later. I've got some new t-shirts",
        "tokens": [
          50464,
          876,
          11,
          341,
          307,
          1364,
          586,
          13,
          7344,
          2870,
          264,
          341,
          5893,
          256,
          12,
          15313,
          13,
          286,
          603,
          1895,
          15104,
          300,
          1780,
          13,
          286,
          600,
          658,
          512,
          777,
          256,
          12,
          25892,
          50736
        ]
      },
      {
        "avg_logprob": -0.22700094669423204,
        "compression_ratio": 1.5412844036697249,
        "end": 8469.84,
        "id": 1850,
        "no_speech_prob": 0.0026315904688090086,
        "seek": 845952,
        "start": 8468.08,
        "temperature": 0,
        "text": " and things um",
        "tokens": [
          50792,
          293,
          721,
          1105,
          50880
        ]
      },
      {
        "avg_logprob": -0.22700094669423204,
        "compression_ratio": 1.5412844036697249,
        "end": 8471.84,
        "id": 1851,
        "no_speech_prob": 0.0026315904688090086,
        "seek": 845952,
        "start": 8469.84,
        "temperature": 0,
        "text": " if I go to",
        "tokens": [
          50880,
          498,
          286,
          352,
          281,
          50980
        ]
      },
      {
        "avg_logprob": -0.22700094669423204,
        "compression_ratio": 1.5412844036697249,
        "end": 8477.12,
        "id": 1852,
        "no_speech_prob": 0.0026315904688090086,
        "seek": 845952,
        "start": 8472.08,
        "temperature": 0,
        "text": " The description is what i'm looking for show more. Yes this at 4 minutes and 28 seconds",
        "tokens": [
          50992,
          440,
          3855,
          307,
          437,
          741,
          478,
          1237,
          337,
          855,
          544,
          13,
          1079,
          341,
          412,
          1017,
          2077,
          293,
          7562,
          3949,
          51244
        ]
      },
      {
        "avg_logprob": -0.22700094669423204,
        "compression_ratio": 1.5412844036697249,
        "end": 8487.28,
        "id": 1853,
        "no_speech_prob": 0.0026315904688090086,
        "seek": 845952,
        "start": 8480.560000000001,
        "temperature": 0,
        "text": " Um, this is where yaning begins her presentation and in this presentation I can just put it quickly on like",
        "tokens": [
          51416,
          3301,
          11,
          341,
          307,
          689,
          17700,
          278,
          7338,
          720,
          5860,
          293,
          294,
          341,
          5860,
          286,
          393,
          445,
          829,
          309,
          2661,
          322,
          411,
          51752
        ]
      },
      {
        "avg_logprob": -0.27657480109227844,
        "compression_ratio": 1.641711229946524,
        "end": 8491.92,
        "id": 1854,
        "no_speech_prob": 0.0003625816316343844,
        "seek": 848728,
        "start": 8488.16,
        "temperature": 0,
        "text": " Uh speed hold on uh speed two times",
        "tokens": [
          50408,
          4019,
          3073,
          1797,
          322,
          2232,
          3073,
          732,
          1413,
          50596
        ]
      },
      {
        "avg_logprob": -0.27657480109227844,
        "compression_ratio": 1.641711229946524,
        "end": 8498.960000000001,
        "id": 1855,
        "no_speech_prob": 0.0003625816316343844,
        "seek": 848728,
        "start": 8497.2,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50860,
          3301,
          50948
        ]
      },
      {
        "avg_logprob": -0.27657480109227844,
        "compression_ratio": 1.641711229946524,
        "end": 8502.800000000001,
        "id": 1856,
        "no_speech_prob": 0.0003625816316343844,
        "seek": 848728,
        "start": 8498.960000000001,
        "temperature": 0,
        "text": " So this is where she gives her presentation where she talks through the details behind",
        "tokens": [
          50948,
          407,
          341,
          307,
          689,
          750,
          2709,
          720,
          5860,
          689,
          750,
          6686,
          807,
          264,
          4365,
          2261,
          51140
        ]
      },
      {
        "avg_logprob": -0.27657480109227844,
        "compression_ratio": 1.641711229946524,
        "end": 8509.2,
        "id": 1857,
        "no_speech_prob": 0.0003625816316343844,
        "seek": 848728,
        "start": 8503.12,
        "temperature": 0,
        "text": " What where style transfer comes from and how it technically works and how the training so all of the number one and two",
        "tokens": [
          51156,
          708,
          689,
          3758,
          5003,
          1487,
          490,
          293,
          577,
          309,
          12120,
          1985,
          293,
          577,
          264,
          3097,
          370,
          439,
          295,
          264,
          1230,
          472,
          293,
          732,
          51460
        ]
      },
      {
        "avg_logprob": -0.27657480109227844,
        "compression_ratio": 1.641711229946524,
        "end": 8511.6,
        "id": 1858,
        "no_speech_prob": 0.0003625816316343844,
        "seek": 848728,
        "start": 8509.28,
        "temperature": 0,
        "text": " What is style transfer and how does it work? You'll find here",
        "tokens": [
          51464,
          708,
          307,
          3758,
          5003,
          293,
          577,
          775,
          309,
          589,
          30,
          509,
          603,
          915,
          510,
          51580
        ]
      },
      {
        "avg_logprob": -0.2308521133532627,
        "compression_ratio": 1.7674418604651163,
        "end": 8519.6,
        "id": 1859,
        "no_speech_prob": 0.035675931721925735,
        "seek": 851160,
        "start": 8512.16,
        "temperature": 0,
        "text": " Numbers three and four have been edited into shorter videos. Okay, so that's where you can find that information and please i'm really curious",
        "tokens": [
          50392,
          22592,
          1616,
          1045,
          293,
          1451,
          362,
          668,
          23016,
          666,
          11639,
          2145,
          13,
          1033,
          11,
          370,
          300,
          311,
          689,
          291,
          393,
          915,
          300,
          1589,
          293,
          1767,
          741,
          478,
          534,
          6369,
          50764
        ]
      },
      {
        "avg_logprob": -0.2308521133532627,
        "compression_ratio": 1.7674418604651163,
        "end": 8522.32,
        "id": 1860,
        "no_speech_prob": 0.035675931721925735,
        "seek": 851160,
        "start": 8519.6,
        "temperature": 0,
        "text": " This is like high degree of difficulty stuff to like",
        "tokens": [
          50764,
          639,
          307,
          411,
          1090,
          4314,
          295,
          10360,
          1507,
          281,
          411,
          50900
        ]
      },
      {
        "avg_logprob": -0.2308521133532627,
        "compression_ratio": 1.7674418604651163,
        "end": 8527.68,
        "id": 1861,
        "no_speech_prob": 0.035675931721925735,
        "seek": 851160,
        "start": 8522.640000000001,
        "temperature": 0,
        "text": " Train a model to deploy train that model into the cloud to then get the train model to run it in the browser",
        "tokens": [
          50916,
          28029,
          257,
          2316,
          281,
          7274,
          3847,
          300,
          2316,
          666,
          264,
          4588,
          281,
          550,
          483,
          264,
          3847,
          2316,
          281,
          1190,
          309,
          294,
          264,
          11185,
          51168
        ]
      },
      {
        "avg_logprob": -0.2308521133532627,
        "compression_ratio": 1.7674418604651163,
        "end": 8530.960000000001,
        "id": 1862,
        "no_speech_prob": 0.035675931721925735,
        "seek": 851160,
        "start": 8527.76,
        "temperature": 0,
        "text": " If you're able to get it to work, please share with me and let me know",
        "tokens": [
          51172,
          759,
          291,
          434,
          1075,
          281,
          483,
          309,
          281,
          589,
          11,
          1767,
          2073,
          365,
          385,
          293,
          718,
          385,
          458,
          51332
        ]
      },
      {
        "avg_logprob": -0.2308521133532627,
        "compression_ratio": 1.7674418604651163,
        "end": 8533.92,
        "id": 1863,
        "no_speech_prob": 0.035675931721925735,
        "seek": 851160,
        "start": 8531.68,
        "temperature": 0,
        "text": " I know twitter or mastodon. I guess i'm unaware",
        "tokens": [
          51368,
          286,
          458,
          21439,
          420,
          27055,
          378,
          266,
          13,
          286,
          2041,
          741,
          478,
          32065,
          51480
        ]
      },
      {
        "avg_logprob": -0.2308521133532627,
        "compression_ratio": 1.7674418604651163,
        "end": 8535.28,
        "id": 1864,
        "no_speech_prob": 0.035675931721925735,
        "seek": 851160,
        "start": 8534.56,
        "temperature": 0,
        "text": " um",
        "tokens": [
          51512,
          1105,
          51548
        ]
      },
      {
        "avg_logprob": -0.2308521133532627,
        "compression_ratio": 1.7674418604651163,
        "end": 8539.92,
        "id": 1865,
        "no_speech_prob": 0.035675931721925735,
        "seek": 851160,
        "start": 8535.28,
        "temperature": 0,
        "text": " And um, if you're not able to get it to work, uh, let me know try to try to send a message post a comment",
        "tokens": [
          51548,
          400,
          1105,
          11,
          498,
          291,
          434,
          406,
          1075,
          281,
          483,
          309,
          281,
          589,
          11,
          2232,
          11,
          718,
          385,
          458,
          853,
          281,
          853,
          281,
          2845,
          257,
          3636,
          2183,
          257,
          2871,
          51780
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8542.32,
        "id": 1866,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8539.92,
        "temperature": 0,
        "text": " We'll see if we can help you out, um to get it to work",
        "tokens": [
          50364,
          492,
          603,
          536,
          498,
          321,
          393,
          854,
          291,
          484,
          11,
          1105,
          281,
          483,
          309,
          281,
          589,
          50484
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8544.960000000001,
        "id": 1867,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8542.960000000001,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50516,
          1033,
          50616
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8547.2,
        "id": 1868,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8545.44,
        "temperature": 0,
        "text": " Um",
        "tokens": [
          50640,
          3301,
          50728
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8551.92,
        "id": 1869,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8547.2,
        "temperature": 0,
        "text": " So that's it for today. Thank you everyone for watching. I will be back up on friday",
        "tokens": [
          50728,
          407,
          300,
          311,
          309,
          337,
          965,
          13,
          1044,
          291,
          1518,
          337,
          1976,
          13,
          286,
          486,
          312,
          646,
          493,
          322,
          431,
          4708,
          50964
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8554.64,
        "id": 1870,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8552.64,
        "temperature": 0,
        "text": " on friday",
        "tokens": [
          51000,
          322,
          431,
          4708,
          51100
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8558.64,
        "id": 1871,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8554.88,
        "temperature": 0,
        "text": " You will see if I go to youtube coding train",
        "tokens": [
          51112,
          509,
          486,
          536,
          498,
          286,
          352,
          281,
          12487,
          17720,
          3847,
          51300
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8563.94,
        "id": 1872,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8561.04,
        "temperature": 0,
        "text": " You will see that on friday we will be doing another",
        "tokens": [
          51420,
          509,
          486,
          536,
          300,
          322,
          431,
          4708,
          321,
          486,
          312,
          884,
          1071,
          51565
        ]
      },
      {
        "avg_logprob": -0.2184103528658549,
        "compression_ratio": 1.5922330097087378,
        "end": 8569.44,
        "id": 1873,
        "no_speech_prob": 0.0005274589057080448,
        "seek": 853992,
        "start": 8564.88,
        "temperature": 0,
        "text": " Neural network machine learning training live stream this time at 11 a.m",
        "tokens": [
          51612,
          1734,
          1807,
          3209,
          3479,
          2539,
          3097,
          1621,
          4309,
          341,
          565,
          412,
          2975,
          257,
          13,
          76,
          51840
        ]
      },
      {
        "avg_logprob": -0.22207856378635438,
        "compression_ratio": 1.6974169741697418,
        "end": 8573.44,
        "id": 1874,
        "no_speech_prob": 0.000026273239200236276,
        "seek": 856992,
        "start": 8570.72,
        "temperature": 0,
        "text": " Eastern I think that's what we set it for. Um",
        "tokens": [
          50404,
          12901,
          286,
          519,
          300,
          311,
          437,
          321,
          992,
          309,
          337,
          13,
          3301,
          50540
        ]
      },
      {
        "avg_logprob": -0.22207856378635438,
        "compression_ratio": 1.6974169741697418,
        "end": 8577.76,
        "id": 1875,
        "no_speech_prob": 0.000026273239200236276,
        "seek": 856992,
        "start": 8574.32,
        "temperature": 0,
        "text": " Text generation. So we're going to use something called a long short-term memory network",
        "tokens": [
          50584,
          18643,
          5125,
          13,
          407,
          321,
          434,
          516,
          281,
          764,
          746,
          1219,
          257,
          938,
          2099,
          12,
          7039,
          4675,
          3209,
          50756
        ]
      },
      {
        "avg_logprob": -0.22207856378635438,
        "compression_ratio": 1.6974169741697418,
        "end": 8581.92,
        "id": 1876,
        "no_speech_prob": 0.000026273239200236276,
        "seek": 856992,
        "start": 8578.24,
        "temperature": 0,
        "text": " Training it on the cloud with a you can train it on a corpus of text",
        "tokens": [
          50780,
          20620,
          309,
          322,
          264,
          4588,
          365,
          257,
          291,
          393,
          3847,
          309,
          322,
          257,
          1181,
          31624,
          295,
          2487,
          50964
        ]
      },
      {
        "avg_logprob": -0.22207856378635438,
        "compression_ratio": 1.6974169741697418,
        "end": 8588,
        "id": 1877,
        "no_speech_prob": 0.000026273239200236276,
        "seek": 856992,
        "start": 8582.24,
        "temperature": 0,
        "text": " And then run the model to have that that model generate new text in the same vein as what it's been trained on",
        "tokens": [
          50980,
          400,
          550,
          1190,
          264,
          2316,
          281,
          362,
          300,
          300,
          2316,
          8460,
          777,
          2487,
          294,
          264,
          912,
          30669,
          382,
          437,
          309,
          311,
          668,
          8895,
          322,
          51268
        ]
      },
      {
        "avg_logprob": -0.22207856378635438,
        "compression_ratio": 1.6974169741697418,
        "end": 8594.72,
        "id": 1878,
        "no_speech_prob": 0.000026273239200236276,
        "seek": 856992,
        "start": 8588.08,
        "temperature": 0,
        "text": " So that will be something that I will show and I guess nabil hassein will be here on friday to show how to do that",
        "tokens": [
          51272,
          407,
          300,
          486,
          312,
          746,
          300,
          286,
          486,
          855,
          293,
          286,
          2041,
          297,
          5177,
          575,
          33042,
          486,
          312,
          510,
          322,
          431,
          4708,
          281,
          855,
          577,
          281,
          360,
          300,
          51604
        ]
      },
      {
        "avg_logprob": -0.22207856378635438,
        "compression_ratio": 1.6974169741697418,
        "end": 8597.36,
        "id": 1879,
        "no_speech_prob": 0.000026273239200236276,
        "seek": 856992,
        "start": 8595.36,
        "temperature": 0,
        "text": " All right. Thank you everybody",
        "tokens": [
          51636,
          1057,
          558,
          13,
          1044,
          291,
          2201,
          51736
        ]
      },
      {
        "avg_logprob": -0.24401028951009116,
        "compression_ratio": 1.6740088105726871,
        "end": 8599.92,
        "id": 1880,
        "no_speech_prob": 0.00017951044719666243,
        "seek": 859736,
        "start": 8597.92,
        "temperature": 0,
        "text": " I will leave you",
        "tokens": [
          50392,
          286,
          486,
          1856,
          291,
          50492
        ]
      },
      {
        "avg_logprob": -0.24401028951009116,
        "compression_ratio": 1.6740088105726871,
        "end": 8604.16,
        "id": 1881,
        "no_speech_prob": 0.00017951044719666243,
        "seek": 859736,
        "start": 8602.16,
        "temperature": 0,
        "text": " Thanks for tuning in to today's",
        "tokens": [
          50604,
          2561,
          337,
          15164,
          294,
          281,
          965,
          311,
          50704
        ]
      },
      {
        "avg_logprob": -0.24401028951009116,
        "compression_ratio": 1.6740088105726871,
        "end": 8605.68,
        "id": 1882,
        "no_speech_prob": 0.00017951044719666243,
        "seek": 859736,
        "start": 8604.7,
        "temperature": 0,
        "text": " special",
        "tokens": [
          50731,
          2121,
          50780
        ]
      },
      {
        "avg_logprob": -0.24401028951009116,
        "compression_ratio": 1.6740088105726871,
        "end": 8611.76,
        "id": 1883,
        "no_speech_prob": 0.00017951044719666243,
        "seek": 859736,
        "start": 8605.68,
        "temperature": 0,
        "text": " Coding train about mastodon and all that stuff. Hopefully you found this useful and interesting stay tuned",
        "tokens": [
          50780,
          383,
          8616,
          3847,
          466,
          27055,
          378,
          266,
          293,
          439,
          300,
          1507,
          13,
          10429,
          291,
          1352,
          341,
          4420,
          293,
          1880,
          1754,
          10870,
          51084
        ]
      },
      {
        "avg_logprob": -0.24401028951009116,
        "compression_ratio": 1.6740088105726871,
        "end": 8616.880000000001,
        "id": 1884,
        "no_speech_prob": 0.00017951044719666243,
        "seek": 859736,
        "start": 8612.24,
        "temperature": 0,
        "text": " Hopefully maybe even tomorrow. Um, the lisa jue coding challenge will come out",
        "tokens": [
          51108,
          10429,
          1310,
          754,
          4153,
          13,
          3301,
          11,
          264,
          287,
          3837,
          361,
          622,
          17720,
          3430,
          486,
          808,
          484,
          51340
        ]
      },
      {
        "avg_logprob": -0.24401028951009116,
        "compression_ratio": 1.6740088105726871,
        "end": 8621.2,
        "id": 1885,
        "no_speech_prob": 0.00017951044719666243,
        "seek": 859736,
        "start": 8617.52,
        "temperature": 0,
        "text": " Um, and as always thanks for your support. Thanks for watching",
        "tokens": [
          51372,
          3301,
          11,
          293,
          382,
          1009,
          3231,
          337,
          428,
          1406,
          13,
          2561,
          337,
          1976,
          51556
        ]
      },
      {
        "avg_logprob": -0.24401028951009116,
        "compression_ratio": 1.6740088105726871,
        "end": 8625.6,
        "id": 1886,
        "no_speech_prob": 0.00017951044719666243,
        "seek": 859736,
        "start": 8621.76,
        "temperature": 0,
        "text": " I hope you're finding this enjoyable and interesting and useful and if not",
        "tokens": [
          51584,
          286,
          1454,
          291,
          434,
          5006,
          341,
          20305,
          293,
          1880,
          293,
          4420,
          293,
          498,
          406,
          51776
        ]
      },
      {
        "avg_logprob": -0.23909207048087283,
        "compression_ratio": 1.6730769230769231,
        "end": 8630.82,
        "id": 1887,
        "no_speech_prob": 0.0035374013241380453,
        "seek": 862560,
        "start": 8626.32,
        "temperature": 0,
        "text": " That's okay, too. I would completely understand I always i'm here for your feedback",
        "tokens": [
          50400,
          663,
          311,
          1392,
          11,
          886,
          13,
          286,
          576,
          2584,
          1223,
          286,
          1009,
          741,
          478,
          510,
          337,
          428,
          5824,
          50625
        ]
      },
      {
        "avg_logprob": -0.23909207048087283,
        "compression_ratio": 1.6730769230769231,
        "end": 8636.08,
        "id": 1888,
        "no_speech_prob": 0.0035374013241380453,
        "seek": 862560,
        "start": 8631.44,
        "temperature": 0,
        "text": " And i'm hoping have a wonderful week and I will see you on friday for sure. Okay",
        "tokens": [
          50656,
          400,
          741,
          478,
          7159,
          362,
          257,
          3715,
          1243,
          293,
          286,
          486,
          536,
          291,
          322,
          431,
          4708,
          337,
          988,
          13,
          1033,
          50888
        ]
      },
      {
        "avg_logprob": -0.23909207048087283,
        "compression_ratio": 1.6730769230769231,
        "end": 8644.5,
        "id": 1889,
        "no_speech_prob": 0.0035374013241380453,
        "seek": 862560,
        "start": 8640.16,
        "temperature": 0,
        "text": " Ah, you know what I need I need a second ukulele i'm just gonna buy another ukulele",
        "tokens": [
          51092,
          2438,
          11,
          291,
          458,
          437,
          286,
          643,
          286,
          643,
          257,
          1150,
          26769,
          2271,
          306,
          741,
          478,
          445,
          799,
          2256,
          1071,
          26769,
          2271,
          306,
          51309
        ]
      },
      {
        "avg_logprob": -0.23909207048087283,
        "compression_ratio": 1.6730769230769231,
        "end": 8647.92,
        "id": 1890,
        "no_speech_prob": 0.0035374013241380453,
        "seek": 862560,
        "start": 8644.720000000001,
        "temperature": 0,
        "text": " Because I can't bring it back and forth from home to here from home to here",
        "tokens": [
          51320,
          1436,
          286,
          393,
          380,
          1565,
          309,
          646,
          293,
          5220,
          490,
          1280,
          281,
          510,
          490,
          1280,
          281,
          510,
          51480
        ]
      },
      {
        "avg_logprob": -0.23909207048087283,
        "compression_ratio": 1.6730769230769231,
        "end": 8653.44,
        "id": 1891,
        "no_speech_prob": 0.0035374013241380453,
        "seek": 862560,
        "start": 8648.48,
        "temperature": 0,
        "text": " And I should I need to play the ukulele more on this live stream. So somebody recommend now that I know that I",
        "tokens": [
          51508,
          400,
          286,
          820,
          286,
          643,
          281,
          862,
          264,
          26769,
          2271,
          306,
          544,
          322,
          341,
          1621,
          4309,
          13,
          407,
          2618,
          2748,
          586,
          300,
          286,
          458,
          300,
          286,
          51756
        ]
      },
      {
        "avg_logprob": -0.24514007568359375,
        "compression_ratio": 1.5046296296296295,
        "end": 8659.44,
        "id": 1892,
        "no_speech_prob": 0.0002736913156695664,
        "seek": 865344,
        "start": 8654.08,
        "temperature": 0,
        "text": " I'm, I love the ukulele. Um, I don't know. I bought like the cheapest one. They had at the guitar center",
        "tokens": [
          50396,
          286,
          478,
          11,
          286,
          959,
          264,
          26769,
          2271,
          306,
          13,
          3301,
          11,
          286,
          500,
          380,
          458,
          13,
          286,
          4243,
          411,
          264,
          29167,
          472,
          13,
          814,
          632,
          412,
          264,
          7531,
          3056,
          50664
        ]
      },
      {
        "avg_logprob": -0.24514007568359375,
        "compression_ratio": 1.5046296296296295,
        "end": 8663.84,
        "id": 1893,
        "no_speech_prob": 0.0002736913156695664,
        "seek": 865344,
        "start": 8659.84,
        "temperature": 0,
        "text": " So i'll take recommendations. Could I get like a coding train themed rainbow like",
        "tokens": [
          50684,
          407,
          741,
          603,
          747,
          10434,
          13,
          7497,
          286,
          483,
          411,
          257,
          17720,
          3847,
          33920,
          18526,
          411,
          50884
        ]
      },
      {
        "avg_logprob": -0.24514007568359375,
        "compression_ratio": 1.5046296296296295,
        "end": 8666.54,
        "id": 1894,
        "no_speech_prob": 0.0002736913156695664,
        "seek": 865344,
        "start": 8664.54,
        "temperature": 0,
        "text": " Ukulele, maybe that's a thing",
        "tokens": [
          50919,
          9816,
          2271,
          306,
          11,
          1310,
          300,
          311,
          257,
          551,
          51019
        ]
      },
      {
        "avg_logprob": -0.24514007568359375,
        "compression_ratio": 1.5046296296296295,
        "end": 8668.720000000001,
        "id": 1895,
        "no_speech_prob": 0.0002736913156695664,
        "seek": 865344,
        "start": 8666.720000000001,
        "temperature": 0,
        "text": " Um, all right",
        "tokens": [
          51028,
          3301,
          11,
          439,
          558,
          51128
        ]
      },
      {
        "avg_logprob": -0.24514007568359375,
        "compression_ratio": 1.5046296296296295,
        "end": 8672.42,
        "id": 1896,
        "no_speech_prob": 0.0002736913156695664,
        "seek": 865344,
        "start": 8669.04,
        "temperature": 0,
        "text": " Was it aki mcu hack the bot? That's great to hear. Goodbye everybody",
        "tokens": [
          51144,
          3027,
          309,
          257,
          2984,
          275,
          12032,
          10339,
          264,
          10592,
          30,
          663,
          311,
          869,
          281,
          1568,
          13,
          15528,
          2201,
          51313
        ]
      },
      {
        "avg_logprob": -0.24514007568359375,
        "compression_ratio": 1.5046296296296295,
        "end": 8681.6,
        "id": 1897,
        "no_speech_prob": 0.0002736913156695664,
        "seek": 865344,
        "start": 8679.6,
        "temperature": 0,
        "text": " I feel like doing a twirl",
        "tokens": [
          51672,
          286,
          841,
          411,
          884,
          257,
          683,
          1648,
          51772
        ]
      },
      {
        "avg_logprob": -0.37643590726350484,
        "compression_ratio": 1.0208333333333333,
        "end": 8686.4,
        "id": 1898,
        "no_speech_prob": 0.00048015560605563223,
        "seek": 868344,
        "start": 8684.4,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50412,
          407,
          50512
        ]
      },
      {
        "avg_logprob": -0.37643590726350484,
        "compression_ratio": 1.0208333333333333,
        "end": 8698.74,
        "id": 1899,
        "no_speech_prob": 0.00048015560605563223,
        "seek": 868344,
        "start": 8696.24,
        "temperature": 0,
        "text": " Yeah, no green no green in the ukulele, please",
        "tokens": [
          51004,
          865,
          11,
          572,
          3092,
          572,
          3092,
          294,
          264,
          26769,
          2271,
          306,
          11,
          1767,
          51129
        ]
      },
      {
        "avg_logprob": -0.4487309753894806,
        "compression_ratio": 0.2727272727272727,
        "end": 8716.4,
        "id": 1900,
        "no_speech_prob": 0.1670605093240738,
        "seek": 871344,
        "start": 8713.44,
        "temperature": 0,
        "text": " You",
        "tokens": [
          50412,
          509,
          50512
        ]
      }
    ],
    "transcription": " You I'm muted. I'm muted. Of course. Okay. I'm back. Ah Also, it happens to me I'm not muted anymore. Hello. Welcome to the coding train. It is me Dan on a Monday I think it's Monday at least But I had this very spicy lunch This is what I was talking about a second ago before I realized I was muted And it's my head is like a little bit in the clouds right now Yes, everybody in the chat is saying no audio. But as soon as Shortly, you're gonna catch up to me. I have I have something to say I'm very worried about this live stream today. So if you happen to tune in on Friday, you might recall that the Streams froze the computer would freeze. I had to restart a bunch of times And so I Tried to do a few things on the computer. For example, I it's not this computer by the way So this laptop here is not the machine. That is the problem the machine. That is the problem is How can I show this to you? This is gonna be very awkward let's try this Yes Sure. Okay the machine that is the problem is This one on the floor over there it is affectionately known as It doesn't have an affectionate name. It's a it's a Mac Pro. It looks like a little trash can it has it has served me well over the years But recently it started to overheat I believe so I did something which is called to reset I Didn't know about this. Thank you to Austin Austin Reset Mac SMC I tried to do this Also, this microphone is in like a weird place It's going wrong today So I tried to I did this I also upgraded the machine to Mojave because why not Wipe some stuff off the machine and as you can see I am live streaming from that machine and it has not crashed yet But I wish I had pressed the button start streaming just like five minutes earlier because the machine started beeping So it does this weird beeping. I've never heard. I wish I have recorded this. It sounds a little like this I've never heard a Mac computer do this before it does it and then it just stops And then I thought maybe then it would freeze I don't know so anybody has any idea what that could possibly be please let me know I did install some monitoring stuff and for example It does say the CPU is currently 148 degrees that's I believe in Fahrenheit and the Tell me like a GPU temperature somewhere here System, I don't I installed something. I think some people recommend some other things that might even be better Activity monitor, so I don't know We're gonna go Patrick in the chat writes won't help if it's overheating. It's likely a hardware issue dust I was hoping that maybe it was like an issue with the fan But like somehow like it didn't know how to turn the fan on and off properly and upgrading would fix that in my fantasies So anyway, I'm here I am going to Do this live stream today up until the moment the computer crashes if it does not crash Great if it does crash I might come back just to say that the machine crashed But then I think if it does crash I'm going to spend the rest of my time trying to find a different computer Today, so I'm sorry to go on and on about this. I keep looking over to see if I'm still live Let me check the slack channel And yeah, all right so Welcome To the coding train what you are about to watch today is a person me do some coding tutorials and today's topic will be Decentralized social networks like mastodon and making a bot for them Kind of trying to use the soundboard again, it's been a while all right, so I'm gonna jump right into this I've got to situate myself here first which is to go to This YouTube channel called the coding train go to playlists Created playlists, I think I'm looking for session six five four There we go This is not what I'm looking for this is what I'm looking for okay Setting up a Twitter All right, so what I am going to do today is Does the new machine have to be a Mac no it doesn't have to be a Mac it has to be a machine That I can use that will do all the things that I need Notably take inputs from multiple cameras from the laptop HDMI out Audio inputs, and it will stream and run open broadcast studio. That's all that the machine needs to do And you know so far. It's kind of working ask Louie Rossman about the Mac stuff says Jason yeah, okay? All right, so I'm gonna jump right in I'm gonna open up a few URLs Enjoy mess that's what I'm looking for here This is the order and then I need one more what I want activity pub And I also would like a mastodon on github Which is here, okay Okay Need a marker I need to make sure the whiteboard camera is working which it is And we shall begin Josh is writing probably not enough RAM for streaming. Maybe you're not referring to this oh, yeah, I see this computer has This computer is let me just give you all the specs here. It is a 2000 late 2013 Mac Pro The processor is a 3.5 gigahertz 6 core Intel Gian the on e5 is 16 gigabytes of some sort of DDR 3 1866 1866 megahertz RAM its graphics card is an AMD fire pro d500 3,000 72 megabytes and I even have I even have Right over here. I'm going to show you something Remarkable I thought would fix all my problems We should use this today though I Have this black magic design eGPU. This is an external GPU Unfortunately it only takes Thunderbolt 3 Which is not a thing apparently I can Use with that Mac Pro from late 2013, but I thought maybe if I use an external GPU it would Would solve a lot of my problems all right? Okay Welcome everyone I Hello, this is a first video in a new series about making a Mastodon bot And you might be asking yourself, okay? Why are you making what is Mastodon? Why are you making a Mastodon bot, and why should I care? I'm not really sure why you should care But I'm gonna try to answer those other questions that you yourself can decide so this playlist is essentially a replacement For session for Twitter API and bots with node.js so I am I'm gonna not redo 15.1 and 15.2 if you have never used node before or don't know what npm is you can go back and watch those two videos But I'm gonna start here basically with setting up setting up a Twitter setting up a Mastodon And so what is Mastodon? Why are we here so the Twitter API? Which I use to create these set of tutorials recently changed quite a bit, so it is much harder to sign up for a new account Authorized for automation making a bot that posts in an automatic way to Twitter They also changed something about the API called the streaming API the way you could connect to Twitter and listen for certain events They change the API and that is no longer available So while I encourage you to still experiment with Twitter as a platform if you so like if today is your first day Wanting to like learn some stuff about node and social networking and making up no social networks and making a bot that post Mastodon is going to be a more pleasurable easygoing experience for you That's going to allow you to express your creativity in a much more immediate way, and then there's another reason It has to do with this idea called decentralization so Twitter I don't know if you've noticed it's kind of an awful place to be for the most part I don't want to get too far down that discussion, but is there is there another way? Is there another way that we can communicate with each other in a less centralized? governed and owned by large corporations kind of way and one way to do that is with a concept called Decentralization and Mastodon is an open source. I don't know maybe I should go somewhere where it actually says what it is Well you can read follow friends discover new ones publish anything you want link pictures text video all in a platform that is community-owned And ad free no this is not like some sort of sponsored video. I'm experimenting with this platform because it interests me and Maybe it'll interest you it is an open source project You can see it's on github here and the decentralization runs with a protocol called activity pub So let me try to give you an understanding of what I mean by all this stuff, okay? So what is Twitter ultimately? Just give me a second a little coughing fit here What is Twitter, I don't know if anyone should really answer that question, but I Will give you a little framework so Twitter Is a company they run probably a lot of servers you can sign you can be sitting on your Laptop or your you know phone That's a phone apparently and you can sign up for an account on Twitter You could give yourself a Twitter username like at Shiffman And then you could post messages like the heart emoji And you can read other messages that other people are sending in to Twitter this Is what you would refer to as a centralized platform The software that runs Twitter is on a particular server It's proprietary the way Twitter is governed and how where what certain posts are allowed and aren't allowed are all Run by this same company and all of your data all of the tweets You've ever posted all of your user information your password stuff all of that is stored on this Decentralized server the web in its origins if you go back and look at the history of the web Didn't really start as this idea of a centralized platform The web didn't start with this idea of a centralized platform The idea was many different nodes all interconnected being able to share and publish with each other And so there is this is coming slowly entering the zeitgeist now this idea of decentralized platforms Probably if you're not familiar with that you probably familiar with something called Bitcoin right which runs on something called blockchain Which is a protocol for decentralized financial transactions, which I am NOT gonna make any videos about at least anytime soon, but Mastodon is a D open-source decentralized social social network. I have so much trouble saying that word Do you like trains? Mastodon Mastodon is an open-source Decentralized social network and It probably resembles Twitter the most but there's some nuance to that so how is it different? How does it work? Well number one is there is no single server for example I have actually set up my own server known as an internet server For example, I have actually set up my own server known as an instance and I'm not going to show you in this series how to set up your own Mastodon in instance But if that's of interest I certainly can provide some resources to do that and I could do a video about setting one up My instance is at a particular domain choo-choo dot space This is my Mastodon instance, so we'll call it choo-choo There are other Mastodon in instances for example Mastodon dot social There is also let me let me erase some of this stuff here choo-choo Mastodon dot social There are some other ones that I have seen for example. There is This dot social which is an instance for people interested in data visualization. I presume there is another instance called bots in Dot space which I'm going to use in this series to make a bot that runs on this bot in space So the idea here is I've set up this instance Let's say you want to sign up for an account with this particular instance you would go I'll show it to you say you would go there and you would sign up and so my Username I'm a client my like picture of my like laptop over here, which is strangely. It's a weird bizarre angle I am Shiffman At choo-choo Dot space So this is my local This is my local Mastodon instance when I want to sign on when I want to post something I post it I sign on through this server I post it through this server my account is with this server, but there is this concept called Federation Sounds like something I'm Star Trek And it kind of is which Federation and I know I kind of getting close to writing off the top is a way for all of these instances To communicate with each other in a decentralized fashion So if I post something saying like hello, I ate oatmeal for breakfast this morning This post that I make through here will get propagated throughout the entire network of Mastodon instances so there is both when you're browsing Mastodon, there's both this idea of a local timeline as Well as a federated or you can think of it as global timeline And I'll show you this in a second I could browse and just look at all the posts. I think they're called toots all the toots For people who are at this instance are all the toots from people all throughout the federated universe of instances by the way the protocol That is used for all of this for the for all the communication to propagate throughout the network. I think I mentioned this already It's called activity pub So the software that runs a particular server is completely open source It took me a while to get it up and running, but I have it up and running here So what I'm going to do is I'm going to show you my account here I'm going to show you bots in space which is an instance designed for people who want to make bots I'm going to sign up and create a bot on bots in space and interact with it here and then just show you how the global network of stuff works, so The only prerequisites really for you going to the next video is to have node installed on your computer And you can go back and watch my two sort of intro to node for Twitter bots videos and the same concepts there will apply Although I'm going to use different node packages What else do I want to say about this? Yeah, okay Coming back over here Okay, so ah so this is the github repository where is the open source mastodon project is I encourage you to check that out This is some more information about activity pub which is the protocol for decentralized social networking lots of other services Also use activity pub there are the you know this idea of decentralized the decentralized web is not limited to just the web Decentralized web is not limited to mastodon one simple example of that and then here now you can see whoops here is my Mastodon instance you can see that if I go to choo-choo dot space I am there It looks like I am on some kind of social network thing where I can say hey whoops hey I am live on YouTube right now and Can you make a little train? And a little I know you're just gonna have to watch me do this I have to pick my emojis very carefully and thoughtfully Rainbows really like clouds or anything no. I don't know okay. That'll be enough I'm gonna post that you can see there. It is and it is there on the local timeline So this is the local timeline you can see kweek on there look ma. I'm on the live stream now. Here's the thing because my instance Is something I just set up and it's running off of a digital ocean server. I it's like $10 a month It's like two gigabytes of RAM. I just signed up for it digital ocean is a hosting provider Not a sponsor, but could be a digital ocean you're listening I'm not the signups are not open so to get an invite code to sign up on the choo-choo space Instance you can be if you're a member of the YouTube channel or a patron of the channel you can you can sign up there But I'm just you know I don't I don't want to mention it Let me go back Matthea who will be watching this later. I don't want to go on and on if I don't want to like mention the Patron membership stuff during the that's important for the live stream context, but because I might open it up later So let me just kind of re-say what I was saying before I'm afraid to go to the global timeline, but maybe I'll maybe I will let me just quickly peek Okay, it's not terrible Okay Let me go back what was I saying You could see the I don't know I don't know where I was I'm just gonna do that whole little section again Sorry for the live people who this will be annoying to Okay, so here we are and what I can do is I can go to the global timeline I can go to the global timeline and I can go to the global timeline Okay So here we are and what I can do now is I just first of all let me just show you a couple links Which will all be in this videos description This is the github open source repository for the mastodon software that I'm running currently on my server Over here. I just I think I mentioned this did I show I'm so confused did I show help me out for a second in the chat Did I show these earlier like I'm confused because I tried to do this video last week and then I got messed up Did I already earlier today? Show the github repository and this page and I'm now repeating myself like when I was doing my intro that I went to the whiteboard Does anybody remember? Let me know in the slack channel or we're here. Oh, I made that digital ocean joke I'm gonna have to make that again because they could be a sponsor for real Yes, one of the first things okay All right, so I'm just gonna like come over here to my instance whoops no no no no You showed activity hub, but not the repo okay great. Thank you, so I'm not gonna show activity hub again So I'll just come over here Okay. Oh welcome new member or Nico Finkernadine And please the first thing you should do is tell me how to pronounce your name and You can go and check the community tab and there's a link there with an invite code to join this Mastodon instance If you're so interested Okay. Thank you everybody for the comments. All right Okay, so now we're over here this is the join mastodon org website you can find out a lot of information I would encourage you to click on this how it works. What is it? On video which is on YouTube which will explain all that much better than I did Get started you can find a different instance that you might like to join This is the github open source repository With with the software that's running now and now Here is my instance The choo-choo People are notifying me and saying hi and look k weekman says look ma. I'm on the live stream. Okay, excellent Please use caution when posting now So this is what it looks like You can see it looks like some other social network service that you might sign up for the difference is I am actually running the software for it on my own server. This is server I happen to sign up through digital ocean, which is a web hosting company that is not a sponsor, but could be a sponsor Hello digital ocean But and you could set up your own And so what but here's what i'm going to do what you can look at other instances like bots in space This is the instance and you could sign up in the next video I'm, actually going to sign up for an account here so I can make a bot that posts on it. You can see Here's some bots already that are posting things the cyber painting bearded mire in the north pole inspired by hubert robert Okay, the sequel is here get ready for guards to To the north pole inspired by hubert robert Okay, so again, these are things that you can do on other services, but mastodon being open source It's a really friendly and easy place to get started with in terms of the api Which i'm sure will rapidly change and who knows how quickly this video will go out of date, but that's the current Spotlight, so let's go ahead and get started So let's go ahead and get started with the first one So let's go ahead and create a new bot and we're going to create a new bot And who knows how quickly this video will go out of date, but that's the current Uh spot so, um, if you want to sign up for an account before the next video I'm going to do it in the next video I would uh recommend bots in space for a bot account and then you can also go i'm just going to open a new Incognito window actually, you know what? I don't have to this is one of the things that I like you can be logged in Multiple mastodon accounts. So if I go here get started Um, i'm gonna you can see here are a whole bunch of servers. So like for example, I am a musician And I speak deutsch Um, then we can see here are some mastodon instances that I might want to sign up for so let's find one for the coding train besides choo-choo.space um, I am a A gamer developer. Should we say developer? I don't know. I guess that's the closest. I don't think i'm a developer and I speak english And we can see here are some um Here are some ones. Let's just cut that whole extra part here because I don't know what is going on Okay, thank you very much. Um, let me So if you want to sign up for a mastodon account not on choo-choo.space or um Or bots in space a new one for yourself You can come you can go to join mastodon.org and you can go look here You can look for something like oh, you're an artist. Yes, and you speak, uh, english. Oh viz.social There we go a social space for anyone in data visualization creative coding, etc And now we can see this is viz.social and you could sign up here Now once again, even if you sign up at a certain instance That's just your name and address and your local instance But through federation through activity pub through decentralization you are still participating in the broader world. That is a mastodon Okay, so what's going to happen next in the next video? I am going to sign up for a bots in space account I'm going to show you how to get your api keys I'm going to write a little node program that posts that toots to it automatically and and then i'm going to show you lots more Ways and things and how the api works and different ways to post images and replies and favorite things and all that kind of stuff Okay, so, uh, I hope you enjoyed this exploration of the open source project mastodon and I look forward to hearing what you think in the comments Um Amr is writing his hair is darker than I remember. Is it my hair? I got a haircut. Nobody noticed my haircut I went to a very nice barber shop over the weekend in uh prospect heights brooklyn And I had a lovely experience with a lovely barber Uh talked my ear off my ear is still on Um It was very nice, okay, um any questions Uh Did that like for those of you who have never heard of mastodon or decentralization Before today, did you get something from that? Was that helpful? Interesting? Useful. I can't believe this hasn't crashed yet I almost want it to crash because I want to just I feel like it's just on the edge of crashing all the time Okay All right, so let me let me get set up here For the next piece of this I Have a lot more space I could work with here. Yeah Um, so we're gonna go to choo choo dot space and bots bots in dot space I think I can close these things out Um Make that a little bit bigger Make this a little bit bigger A little local timeline. There we go. Okay Um, okay All right, um, I think I am ready now to get started Oh, I need to have iterm And let's go to Uh Desktop make directory mastodon bot Okay Oh another new member. This is so nice of all of you uh Andras Yirmati Where are you from? I wonder Andras. Thank you for joining. Okay So, um, so let me just for the live stream If you for anybody who's watching right now, if you go to choo choo dot space Um, you're going to see this message Sign up on another server registrations are reserved for coding train youtube members and patrons I'm doing this not because I want to have a closed thing I mean might make sense for this to be a member benefits. I don't know Um, mostly i'm doing this because I just set the instance up and again, it's on a digital ocean server I just picked a droplet. I didn't pick the five dollar a month. I picked a ten dollar a month To give me a little bit more juice Um, but I I just i'm not sure about the sustainability of this and what's going to cost So at the moment you can you can certainly participate and communicate on mastodon through the fact that it's decentralized But you'll want to sign up with a personal account somewhere else or join The youtube channel, um, and then you'll get an invite code and maybe i'll open this up later Um as well as and look we got 22 users so far And then as well as bots in space which is open it's currently an open one You'll notice that the main one mastodon.social for example Also is registration on the server are currently closed due to high demand. Please sign up on mastodon.cloud instead So I don't know, you know, I think that um I think it's what I like about mastodon is that there are these, you know instances these little subgroups within the larger universe So affinity groups maybe in a way so I do like the idea of opening up the choo-choo dot space But also you might find one that's you know, maybe uh coding train is not your sole purpose in life And you might find a different space that's well suited to you. Okay Which isn't to say that's joining the anyway, okay All right Okay, people are really sending me crazy stuff right now How did you do that? All right, this is really funny what's going on, uh so far I don't mind No, I don't mind this at all. In fact, I'd rather enjoy it, but please use discretion don't try to don't ruin my video with nonsense, okay um, all right, so Hi, thank you marius for your nice Uh comment, okay Um, so i'm back here i'm gonna go here, okay Okay Okay, we're back for another mastodon video and in this video i'm going to sign up for a bots in dot space account Bots in space. I feel like I need some space music. Hold on. This is going to be totally worth it Oh, yeah, this is pretty good Okay Okay, now I can really hear that And crazy feedback Well, hold on you know, I need to do is I need to mute this, okay, there we go. All right. Sorry everybody Okay Hello, welcome to the second mastodon video in the first video. I'm going to be doing a video on The first mastodon video. I'm going to be doing a video on the first mastodon video Okay Hello, welcome to the second mastodon video in the first video I talked a bit about what mastodon is or at least my impressions of it the idea of decentralization And in this video the reason why i'm doing this is I want to find a platform to write crazy weird experimental avant-garde art bots And so i'm going to use this platform Bots in space It Sounds that this was going to you know, this idea seemed better when I thought of playing this music and didn't really turn out But so the first thing i'm going to want to do is sign up for an account here with bots in space and i'm going to say um sign up with uh coding train bot And I am going to use the email address daniel at the coding Train.com i'm going to use the password. Ooh suggested password I don't think I should use this because then you will all see it. I'm going to use the password I love blueberries are heart heart rainbow Sure, you'll all be able to guess my password really easily Um, what is what do you what is this nonsense go away a message with confirmation link has been sent to your email address Hold on a second Talk amongst yourselves. I am now going to attempt To uh I didn't get an email. Is it in my spam? It's not in my spam. Well, I did get some private messages from some nice people in my spam Oh, this is such a fail Ah, okay, oh it came through So my confirmation came through and that's who you can edit this stuff out. I guess verify email address. Ah, my email address has been verified Okay, I got the email. I verified my email address. I should be able to log in now coding Train bot if I could remember what my password is I'll log in. Oh, no, that's that's not the password Oh, no, wait. Oh, I have to use my email Daniel oh great. Thanks for showing all my emails here. Oh auto fill whatever. Okay. Hold on Okay, so I click the uh Verify my email. I have now put in my username and password I'm gonna click log in and now welcome to mastodon. I'm gonna save this just why not? Um, this is my full handle at coding train bot at bots in space Um, i'm not gonna skip through this little tutorial here But first thing i'm gonna do very important is i'm gonna go to edit profile And i'm just gonna go down here. I would want to put other stuff here And maybe i'll do that eventually but I want to go here and I want to click This is a bot account because uh, one of the nice things about mastodon It has a feature for you to indicate that a particular account is a bot which is you know A really nice thing to do in terms of transparency Okay, the other thing that I want to do is I want to go down under development So i'm gonna hit save changes right down here in the bottom. There's a little option under development I'm going to want to click that and I want to create a new application So i'm going to create a new application. It is coding train example bot The website will just be the coding train.com I want to what do I want to be able to do so? So You have a lot of options in terms of what permissions you can give your bot like maybe the bot Can only read certain things or only write certain things But i'm actually going to keep the global the the red sort of global right checked and the red global read checked So that everything and follow so this bot can basically do everything it can read all the posts It can write all as many posts at once and it can follow so i'm going to hit submit And then i'm going to click here And now now the thing is this is stuff that I really do not want to share with anybody So at some point i'm going to regenerate this which i'm going to do right now. I'm actually going to uh, Oops, just here. I am back. I'm going to regenerate that access token. So, uh, and I don't really mind if Who's going to be able to like type this quick enough and hack my bot? But um here I come back, but um, this is not something you want to share. Okay Yeah, there we go, okay, so now uh Where am I? Oh, okay. You're gonna see it again Now you saw it again. Oh, whatever I failed. Hold on. Let me go back. Let me do that again Uh, all right So what i'm going to do is i'm going to quickly just turn the screen off no, that's me I'm going to turn the screen off. There we go. I'm going to regenerate that access token Um, i'm going to go back To i'm going to copy this stuff somewhere secret. Actually, i'm not going to worry about that now I'm going to go back to mastodon then i'm going to put the screen back there I am Um so that uh, you can't hack my bot at this moment. All right, so what's next? I want there's a lot of different ways you could write a mastodon bot I'm sure you could come up with some way that I can't even think of right now. I'm going to use node.js Which is a javascript framework for executing javascript code um and uh, I am going to do all this from the command line, so I you You're going to want to have node installed and you're going also You're going to want to have some shell access to your computer to be able to do this And i'll link to different workflow videos about how to get that stuff set up if you don't have that already So what i'm going to do is i'm in a directory. I'm on coding train desktop mastodon bot The first thing i'm going to do is i'm just going to type npm init What this does is it starts up my node project? This is going to create a package.json file which has all the configuration information for my node project I could just manually make that file or copy it from another project But it's nice that this tool will step me through it. So package name mastodon bot sounds good This is version. I don't know 0.0.1. The description is example code for mastodon bot on coding train Entry point i'm gonna have a file called bot.js. I'm not going to worry about testing right now. I don't have a git repository bot mastodon Uh education will be some key words. The author is me Um, I guess a license will be mit and this looks all looks good to me So now if I open this up in visual studio code We can see it has created a It has created a package.json file with all of that information in it that I just typed I pause for a second Um, okay I feel like this is a little bit big Actually, I like that that's bigger and then now I can go um to preferences And change this And go here, yeah, that's better, okay. Um Okay Okay, the next thing that I want to do is create my javascript file that is going to run the bot So i'm just going to click new file and i'm going to say bot.js and just to test things out I'm going to say console.log mastodon bot starting dot dot dot so This is where all of my code for the bot is going to go And the very first thing that i'm going to do is just test this code by executing it and the way that I do That is going back to terminal. And by the way, yes There whoops It's not the right command How do I do that no Yeah, there we go um And by the way, yes, there is actually a terminal directly in Um in visual code studio and I could actually just run it right here And by saying like node bot.js and maybe I should do that. This is so tiny though Um, I don't know why i'm just not used to using this terminal yet So i'm going to stick with my using a separate iterm and i'm going to run node bot.js And we can see all it's doing is console logging that mastodon bot starting Okay, how am I going to connect to mastodon? So in order to do this i'm going to use a node package that will communicate with the mastodon api directly So let's find that Um, sure. Let's look at notifications Um, let's let's node mastodon api And let's see so what comes up mastodon-api-npm Um, this one looks pretty good. Let's go over to github And see all right. So this is actually the one this is the one that i'm going to choose to use Um, it was last updated eight days ago. I've used this before in making a practice example So this one is going to work fine for me And so now the next thing that I need to do Is I need to run npm install because if i'm going to use this package to communicate with my bot I need to make sure I have it installed. So this npm install dash dash save mastodon-api And yes, I could use yarn, which is another package manager for node, but i'm still i'm like an npm person Whenever there's the thing that's people are using instead of yarn, that's when i'll use yarn npm install save the dash dash save by the way is a Argument so that it automatically gets added to the package.json file And there we go. So if I go over here we can see if I look in package.json There is now also a dependency Mastodon-api. So that is now a project dependency and the first thing that I want to do to be able to use this Is and actually documentation here documentation people um One let's actually just go over to examples and click on uh streaming and this is what I want Oh, no, I don't. Oh my goodness. All right. Never mind. Hold on I have my own examples. Um, I think it's just require Um, you no longer have to use alka, okay Hold on then Breaking news alka in the chat is telling me that you no longer have to use dash dash save So maybe it it adds it automatically whether or not use dash dash save or not. That's a nice little extra tip for today Okay, what I want to do, uh now is uh require it And again, i'm not using i'm in a sort of still i'm using require so i'm gonna say const uh mastodon Equal let's just call it const m maybe no, let's I don't know mastodon equals require Mastodon dash api so I am now requiring it which meaning that's basically i'm importing it And then what I want to do is I want to connect and there's a lot of ways that you can Connect live in your code because maybe you're making an app and you want people to be authenticated with different accounts I don't need to do any of that. I just want to um Uh do this New uh constant m constant m equals new mastodon And i'm gonna do this And uh, i'm gonna need to put in my access token. I'm gonna need uh, I don't i'm not too worried about this and I need to uh put in my particular um Instance which is bots in space So this is the this is the since I am now going to run my bot through bots in space the api URL for making api queries is at bots in space bots in dot space slash api slash v1 Now maybe someday there'll be a v2 of the api a v3, but this should always work Um, and now I just need to get that access token Which i'm throwing caution to the wind by the time you watch this video the access token will have changed But just to show you um, i'm going to go back to here. I'm going to go to settings That's fine. I'm going to go to um Uh, where am I development a coding train example bot i'm going to grab the access token i'm going to paste it here Uh, and then I think do you know, I'm pretty sure I need also the client uh secret Which is this thing and uh Client key which is this thing And then now I should be all set and connected. So the next thing that I can do if i'm looking through this api Um, oh, yeah, this is actually what I wanted to do Yeah, um is I can so now ah Okay I'm just pausing for a second because i'm seeing the chat. Um typo and secret Um Um, oh I see that siraj is in the chat. Hello siraj and petros My son's middle name is petros I wrote secret. Okay. Thank you Uh, i'm being told that I wrote secret So that should be secret. Thank you very much. All right. So here's the thing. Uh, we got to talk about something There are uh, three there are three core ways to engage with the mastodon api Sad to erase my beautifully decentralized diagram There are three ways to engage with the mastodon api And this is very similar to how twitter used to work and twitter doesn't work this way anymore But luckily for us mastodon does there is the get A get request is basically saying hey I would like to get a whole bunch of stuff like get me this list of user accounts get me this list of Posts tooth statuses tweets, whatever you want to call them search for every toot that has the word mango in it That's what get is for there is also post I really should have written these in all capital letters post is for posting something to Mastodon like for example, I want to post a new status or I want to follow or favorite or reblog something All of those are posts and then There is what is really The exciting thing the streaming api the streaming api is a way for you to essentially have almost like a socket connection like A an attached connection to to mastodon where you're just listening for events So every time somebody follows somebody you'll get an event or every time somebody Posts the status you'll get an event So this is what's really powerful in the way that you can kind of engage with the service in a in a real-time Synchronous way and unfortunately, this is a thing that twitter recently removed from their api And there's other ways to do the same exact thing, but it's a bit roundabout plus Good luck getting your bot approved from twitter or something that you can use there, okay So this in this video to test the first idea out. I just want to do a post So what I want to do is a post Okay So coming back over here We can see this is what I have to do a post With a some path now, what is the path? So now we need to look up mastodon api documentation And we should be able to on this page here look under posts And we can see I can this is a post for following something for blocking unblocking for muting But I want to post a status Hold on there we go Sorry about that. This is where it is. I want to post a new status. So remember what is my api? url it's this one so ultimately the end point that I want to go to is V1 statuses, but I don't do it here The path I can put right here statuses Then I need some parameters and i'm going to put a new status And I need some parameters and i'm going to put a callback Which I will use my fancy es6 arrow syntax that I have covered in other videos I'll come back to that in a second. So params, let's make that a separate variable It's a javascript object So these params, this is super important. What are the parameters? Well, we can go back to the api documentation And we can look here. They are I can say this is the status the text that I want to pose in reply to well Is it in reply to somebody a different an id of a different status media id is for images all sorts of stuff here language Is it sensitive content? There's all sorts of things, but basically i'm just going to say Status And there we go, why why did you format yourself like this what kind of crazy indentation is that this isn't right I'm gonna have to deal with that later. Okay, so now And then in the callback, what do I get I probably it's probably like error first callbacks i'm guessing Error data i'm going to do this. So let's just do say like if error console dot error error And then otherwise Uh console dot log data. Okay So now here we go. I have my code Right. I started the bot I connected Here's all my secret information Credit card number and social security number is embedded in there somewhere Here's my status that I want to post and there we go. And hopefully nobody's already hacked my account And posted stuff. So let's go look over here Okay, wait, no i'm in the wrong account where did I got to go to bots in space Uh, and I got to go to my profile Which isn't anything yet somewhere. It'll show up here Where's my profile? Is this me? That's local who knows okay, let's run this code Uh node bot.js, okay, we got an error mastodon is not defined. Why is mastodon not defined? Because I used a capital down here and I didn't use a capital up here. So this mastodon Importing the whole library is now a function that I can call to connect. So let's try this again Oh that seemed to have worked except it didn't console log anything How do I tell if I That didn't seem to work hold on time out for a second I did path of status not statuses. Okay, so So that didn't work. All right. So how am I going that didn't seem to work? Thank you to wilbur in the chat who just told me that I actually put the wrong path here to the api So if I go back to the api documentation, you can see the path the endpoint is statuses plural So let's try this one more time statuses And now let me run this again Ah, look and we can see we got all this metadata back because it was successful It was successful and it was successful and it was successful All this metadata back because it was successful if I go back here if I go to bots in space Look at that. There we are Okay We did it We successfully made our first mastodon bot that is posting just from Just from the node Directly to mastodon. Okay, so there's a few things that I want to show you next I would like to show you number one is how to effectively hide your you can open source your bot but still hide your Your client secret client code all that sort of stuff. So I want to show you that And also we'll just look at some of the other parameters for um some of the other parameters for posting I'm getting a lot of notifications That sound you're hearing is the mastodon notification Where are we three? How did it get to be 326? Jeez louise. Oh, no, but I have to I started at 230. I thought I started at two Okay I like this All right, I got to do a couple things number one, I'm sorry all of you who like your four spaces of indentation Um, I don't know where that happened How that got changed Um in my where did that get changed but I can't tolerate it Um Where where are these things? Let's hold on Setting is closer to the top. Okay Font size. Ah, there we go There we go, it just went right past it There we go, it just went right past it Okay You know user settings I don't I want to user everything Okay How come that doesn't do I actually have to change something no no What why why Why is it here? Oh director like I skipped you guys are behind me Why why I can't I can't continue This setting is overridden based on the file contents when editor detection is on oops I want to turn that off then. Oh, I see because Um, that makes sense that you would have this editor Editor detection, hold on come on two One let's see auto surround So Is it because it like detected for space And now if I take out all the for space you can't detect it and it will go back to two Spaces four. Ah, how do I change this? How do I change that to four from two two look at that four When you open the code file at the bottom right you have to change it No I'm change view. Ah Ah, ah, ah, ah, okay. Oh my god. Everything's okay now. Woof Oh, that was rough. That was really deep. That was really bad Okay Okay, woof woof sweating like crazy All right, all right everybody Woof woof. All right, so here's there's a couple options. Um Um, okay dot so i've never actually used dot env the dot env package before um I what I always do is um, but so and then so I would make a dot env file and then I would get ignore it when I Yeah, okay, so let me try doing that, okay Okay Okay All right, um, okay Okay, oh wait, actually let me recycle the camera All right Okay, I am back i'm going to do some I made a mastodon bot all it did so far was tweet Tweeted who did ah toot tweet Blog post who knows what all this stuff is. All I know is that it said choo-choo So I would like to show you some more things to uh, you know, to do So the first thing that I want to do is actually I don't want to have all of this, uh, all of these secret keys and everything right here in my code because i'm going to upload this as an example For other people to use I want to be able to hide that stuff away, but still use it And there's actually a wonderful node package. Thank you to To the people who have been using it for a long time. It's called the chewy node package And it's a really cool package. It's a really cool node package. It's a really cool Package for other people to use I want to be able to hide that stuff away, but still use it And there's actually a wonderful node package. Thank you to alka for the um suggestion called Dot env so i'm going to say npm install dot env Install this node package And what this allows me to do is create environment variables for a particular project and that way I can upload the code without the Values of those environment variables, but anybody who's using that code could set the own values set their own values of that those environment variables So what i'm going to need to do is create a new file. I'm going to call it dot env So it's kind of like as you can see it right here. It's like a hidden file dot env. It even has this crazy settings thing And then in this oh look, there's all these extensions I could use probably to like format it in all sorts of fancy ways But i'm not going to be fancy what i'm going to do and i'm looking over here because thankfully Alka gave me some suggestions i'm going to say things like auth token equals client secret equals Um, and i'm going to say client, uh id equals I think those are my three things so they're in the code Uh client key is this I'm going to put this back in here client key. Okay, I guess client key is what I meant Um, do I need to does it need to be in quotes? Maybe somebody can tell me maybe it shouldn't be in quotes actually um I'm going to get the client secret Um, i'm going to go back to the env file and put that in here right now I'm using single quotes which may or may not be correct. Then i'm going to go back to my code I'm going to get the access token And i'm going to call it access token just to be consistent with my naming uh and now If I do this I can now go to my bot and I can also say Constant uh, uh env equals require Uh, and then I want to require a dot env and then um Wait time out for a second acquire dot env dot Config oh and I need to all config. Okay Um No quotes, okay And sample one. Yep. Yeah. Yeah. Okay. I will do that. Um without quotes, okay Um Okay, um Okay, actually just for consistency sake maybe i'll make this capital letters I don't know then i'm going to say then I need to call env dot config And then I'm going to say Uh, I'm going to say process dot env dot uh client key So I should this Will now is that right process dot env? Let me take a look. I have the documentation over here Um, and then I should be able to now I should be able to say Process dot env dot Let me take a look I have the documentation over here Um, yeah, I think that's right. So I should be able to grab those environment variables whoops Just like this, uh, then the client secret Then I should be able to grab this one and say Access token Who knows if i've made some mistakes, but let's try running this now. Let's choo-choo um Uh choo-choo choo-choo Let's say choo-choo twice And let's uh run this All right. I think this might have worked And we can see Oh, this is the wrong page again Choo-choo choo-choo. Okay, we can see that work. So the all of this stuff is now hidden inside my uh environment file and what i'm also going to do now, um is i'm going to make a Um, i'm going to make another file called dot env sample and then i'm going to copy this into there Whoops Except I don't know how to use this computer thingy. Oh Hold on let me do that again. I hate computers. What about delete delete Go away Okay I'm going to copy this into here And then i'm going to take out all this stuff Um, i'm going to make uh, because eventually i'll put this on git Um, i'm going to make a file called dot git ignore And then i'm going to say a dot env So basically what i've done is i'm saying hey, this is my file dot env That's my file that i'm only ever going to have locally on my computer But when I publish this i'm going to publish a sample one Which has information basically about what you need to put in there And then i'm going to make sure that the actual dot env file is not included if I ever check this into a git repository Uploaded on github so to speak. All right, let's make sure this works Still working, um, we can go here and i've said Somebody definitely hacked my bot so i'm going to reach is great because I had my keys up on the screen Well done whoever you are and um, I am going to uh, take a break and uh Regenerate my access keys so that nobody else can hack my bot keep them hidden in my environment file and then I am going to Before something bad happens. I'm going to just close out of this window and i'm going to come back and show you more about um Writing mastodon bots and i'm going to i'm going to show you this fun thing called spoiler text Um, and how to have the bot post to mastodon periodically every so often. Okay, so see you in the next video All right, so I am going to now go to uh, choo choo not choo choo dot space no no bots in space I can't ever remember which thing i'm at i'm gonna go to um Settings Uh developer development Here we go I'm going to say goodbye to the screen everybody. I'm now going to regenerate my access token the client key and client secret I don't think change They're the same. So oh, well you all have those But you cannot have my access token, which is a little unfortunate. Actually, you know what? Maybe I should delete this one I'm going to delete this one Um, let me see if I can delete i'm going to delete it and start over sorry that you can't see what i'm doing because it's actually not so great for everybody to have the client Secret client id because you could still write a bot and then and then like authorize with for the access token So i'm just going to regenerate everything I'm going to hit submit Um, and then i'm going to get those now. I have all three new things. You can't see what i'm doing token That was the client key actually client key uh client secret Sorry that i have to narrate this and access token Save Save close close bring that back. Uh, and now let's just run this one more time Great all right. Thank you. I hope you all enjoyed your time hacking my bot Ah shoot I came up i'm such a doofus. All right one more time everybody All right, i'm the worst I am the worst delete it's all gone New application coding train example bot Uh coding train.com Submit Here we go. I got a new client key everybody new client key Uh client key now I got a new client secret starts with f7 the new access token And now i'm going to close both the dot env file and i'm also going to get out of that page um And I am going to bring this back up now i'm going to make sure it works There we go go here now, there we go. All right now we should also do some stuff Um, can I quickly? Hold on a sec. Um Most people put the require. Okay, I will fix that. Thank you alco for a comment about where to put the require um All right. So now let me just do something real quick. What was I on bots in space? Login, um, what was it called coding train bot? Um Email address daniel at the coding train Um email address daniel at the coding train.com So I just want to add a like a header and stuff and I have it on this computer. So Uh, sorry, you can't see what i'm doing rainbow Uh, oh no i'm signing up ah log in Um Um, okay and edit profile Somebody i'm getting like a lot spammed here. Oh, no, somebody's just favoring a lot of my statuses Um, i'm going to Get an avatar here Um Where can I find this? Uh, here we go Like the Semicolon all right Okay, I can play around with the Oh, you know what that's the look at that crazy semi-gold hold on just gonna just gonna change this There's a different semicolon. I meant to use this is very important. This is exactly what I need to be doing right now Uh edit profile just hold on It's very very important that I have the correct semicolon, there we go That was not the correct semicolon character That is the correct semicolon character, thank you very much, okay Um Now Okay Okay, let me get back to the chat here Okay, so I'm going to go back here And here we go Okay Cycle the camera I've got about 45 minutes here so we can keep going All right, i'm back again This is another video. I'm just continuing making this mastodon bot And I got some uh good tips. First of all, I did kind of like a goofy thing here this dot env package So I could practice or tradition convention to just put it at the first thing and I could just call dot env dot Config I don't need to save it in a variable. I can do this just in one line of code So let me clean that up. That's a little bit nicer now um, the other thing that I want to do is I want to um make this bot post Every so often and so a quick way that I can do that is with the set interval function So, oh, you know what? I should also do look at this. Let me show you something So one thing that I often like to do, um So if I run this right now, um, actually I just ran it you can see this is all of the information that I get back when I If this is the response from mastodon after I have tooted Um awkward i'm gonna get I'm way too self-aware of what people are going to like post in the comments Poor matthew's editing. This is the response that I get after I post to mastodon. So I get each Toot has a an id it has a time stamp It has metadata about whether it's a reply to something it has its content. You can see it's a formatted with html So what I actually would like to do is not just console log all of this json data to the to the console I would like to just pick and choose a few things to console log out as kind of debugging information And also something that I often like to do Just to kind of like help me with this kind of stuff is use The built-in node file system package So i'm going to require file system. This is not a package I need to install It just comes with node if it's you know, whatever version of node you're using And i'm actually going to say right here. I'm going to say file system dot right file sync which is a synchronous File writing and then i'm going to say I want to write this data Actually, the path is first and then the thing that I want to write which is probably json dot stringify I want to stringify the data And I want it to have two space two space tabs And then I need to write this file out so I could just say data dot json And then if I run this again We should see now all of a sudden We should see now all of a sudden I have a new json file that appeared in my Directory here and I can look at it And now if I want to kind of like figure out what's the data that I get back? I have this as a reference so I can now And I could time stamp the name of the file and all sorts of things like that But I can now go and I can just comment this out And I can now I could be more thoughtful about this and I could say Uh, you know console dot log, you know success Id Uh, and then I could put sorry I need to go back here and I could say it's data dot id created at um So I would go back here and I would say Data dot id Plus uh data dot created. Uh at you know what? You know about what's it called what's the thing called template literals My brain is not working today. It was working on friday and I had that spicy food for lunch and it really did something to me um Is that what it's called template literals JavaScript yes JavaScript yes Actually, this is a good moment I really should just do a separate video on this entirely because it's such a wonderful feature of javascript now But I can actually you know how i'm always doing this console logging some text and then some variable stuff And i'm joining it with a plus and concatenation. You can use something called template literals, which is a way of embedding expressions inside of a string and the way to do that Is with instead of quotes with back ticks So if I put a back tick at the start in the beginning, I no longer need this plus I'm, just gonna i'm gonna get rid of all this nonsense um Success, you know id i'm just gonna do id and time stamp Colon and so now this is a string and it has basically like I want id This is what I want to literally see and then what I want to see is the value of this and the way that I Do that is with dollar sign curly bracket curly bracket So now anything inside of here is an expression so I could write four plus seven and it would it would it would it would? Put 11 in the string and then I can say time stampy Uh, I can make this like this um, and now We can run this again one more time Node bot.js and we can see this is what I get now id and time stamp So this is what's going to i'm going to see and maybe it'll be useful for me to also put the content there Who knows what I want to log in console.log, but I want to be more thoughtful about that Not just spit out massive amounts of json data. Okay, let's get to the good part now What I want to do is my first example of a bot is I want to make a random number bot So I am going to say i'm going to use template literals again uh, i'm going to say The meaning of life is and then i'm going to use an expression i'm going to say, uh, math dot floor You know, let me put this in a separate variable Const num equals math dot floor math dot random Times 100. We'll see if we get 42 And then i'm going to just put that here Um and now this My bot should now Post the meaning of life is this random number So math dot random gives me a random number a floating point number between zero and one I multiply that by 100 so I get a number between zero and 100 I mean technically the highest number is 99.999999 and then math dot floor takes off the decimal point So I now have a random number between zero and 99. I could add one if I want between one and 100 whatever That's not the point. The point is now And you know what? I really would like to see from the console Um what? It posted so i'm also just going to do this console log Data dot what was it if I now I can go back to my data dot json and it's going to be um Where is the content uh content just data dot content? um So i'm going to say data dot content We're getting somewhere So let's run this one more time Success the meaning of life is 95. Okay, did we get it? We can go here we can double check and Somehow I went away from there the meaning of life is 95 great. Okay. Now two more things I want to do Make this bot exciting I am now going to use set interval. So the idea here is this is all of my code to post to mastodon To post to mastodon And again, if this is new to you If you've if you've just been watching my p5gs videos this weird syntax this arrow syntax part of es6 JavaScript might be unfamiliar to you. I will put a link to a video where I describe what arrow syntax is in this video's description Um, okay. So now what I want to do is all this stuff here is basically just a function called toot Right because what I want to do is this function will pick a random number create the status and post it What I want to do is I want to say now set interval And I want to do this toot every 5 000 milliseconds, which would be every five seconds. Now. This is a bit extreme This is probably this is not really appropriate bot etiquette to have a bot that posts every five seconds. So, you know Probably a much more thoughtful way of doing this if you're gonna have a bot that posts an automated way Maybe it's a word of the day or a haiku of the day Maybe it's just once a day once an hour Once an hour might be really the maximum there, but just to test it i'm gonna do it every five seconds Burps, i'm gonna be burping on a live stream Um And I guess I can take this moment to thank pa7war Um, I'm going to um, I'm going to run this every five seconds, which is reasonable just for testing Something interesting though about set interval is like what if I make this like every 50 seconds if I run this right now I gotta wait 50 seconds for it to do the first time So and that's not really such a great thing So I am going to actually also just call it once first And then do it every five seconds. So I'm going to do it every five seconds First and then do it every five seconds. Okay, here we go Got meaning of life is whoa, it really picked 99. That is awesome Uh, and it's 48. Oh, we're getting close to 42. We can see it's doing this every five seconds. I'm gonna quit out of it And i'm gonna go back to here. We can see there it is These are my posts that I did you can see 10 seconds ago 10 seconds ago now I mean, this is really five seconds ago. All right, so here's the thing I want to show you there's so much more remember how I made this These parameters all i'm doing is saying this is the status that I want to post automatically from my node program Well, one of the things that I can actually do is I can go back to the documentation There are all these other things so media ids is something I really want to show you in a future video It's a way I can include an image or other media with the with the post But one thing that I can do that's kind of fun is just this spoiler text thing So what spoiler text does it allows me to have sort of two aspects To the post the meaning of life is and then the status Can just be none So i'm going to break this up into two parts and I need a comma here And i'm just going to show you what this looks like So i'm using these parameters different properties of the javascript object that's going to go here into my post call And i'm going to now run this one more time And i'm going to go back to my bot and i'm going to look and you can see look at this the meaning of life But I now have this nice show more button. So spoiler alert If you click on this, you'll see that it's 52 Or that it's 23 and again i'm doing this too often So i'm going to absolutely quit this and then if I wanted to do now if I want to have my bot post once a day Every 24 hours I can just go right back to my code and I can say get a set interval should be 24 hours. There's 60 minutes at 24 hours 60 minutes an hour 60 seconds an hour and 1000 milliseconds in a second. So now here we go. We now have a bot A mastodon bot that will post a numeric meaning of life once a day So in theory if I just left this running here and never closed my laptop or never did anything This would just run forever and once a day post the truth of the matter is you're gonna have to think about well Once you've created your bot like where are you going? Where's that bot going to live? I mean you could have it live on your laptop or computer that's always plugged in and always connected to the internet but more likely you're going to want to host it on a web server on some sort of server or maybe get a raspberry pi And plug it into the wall and have it always sitting there connected to the internet. I will cover that in future videos In fact, I have covered that for how to deploy a twitter bot and ultimately it's exactly the same thing But just now the code has changed and it's working with mastodon Okay, so i'm going to show you a bunch of other kinds of things you can do in bots most notably Listen the streaming api. Whoops Most notably listen using the streaming api So the streaming api is a way that I could connect and I could say anybody Anybody ever mentions me I could reply to them so I could have a bot that participates in a conversation One thing you should really think about and I'll talk about this again at the beginning of the next video I mentioned bot etiquette etiquette But the idea if you really want to be thoughtful about making a bot that's not suddenly going to spam people So it's not going to just pick random mastodon users and start at mentioning them Or start picking random posts and replying to them. You really want your bot to engage when people opt in to engage So maybe you only want to uh post messages to people who have chosen to follow the bot or chosen to mention the bot already In in a particular post so I just can't think of saying post because I haven't gotten comfortable just when I got comfortable saying tweet I'm now no longer comfortable saying toot, but i'll get there. I'll get there eventually. Okay. See you in the next video All right, um, okay, how we doing everybody Okay Okay So I think I want to use the nice work david hall look at all these people following along so nice um I should probably turn off. So What how much time do I have here? Um, I want to let me make a list of stuff that I want to do like if I think about what my twitter bot examples used to do Um Sorry, um This is from my program of a to z course last year in week four twitter, so Um I guess it's useful to show it's definitely useful to show how to like Reblog and reply. I think that's what i'll go for next And then how to do an image, okay, I think that's makes sense um So we need the streaming So I need to use the stream so I think what I want to do also is duplicate this So let me close all these files It's four o'clock I don't have a ton of time left, but I would like to get a little further Oh, it's just um Um Um, okay, what am I doing here? Um Um Let's make a folder called mastodon, let's put mastodon bot in in there Let me call it bot One and then let me just duplicate it Oh, you know I I'll mention this. I totally forgot to put node modules in the git ignore. Um, so now Um, let me go here, um close this And I have both of these um, this chain doesn't change this I can Um, so I can get rid of All right, this is fine Bot.js I guess i'll leave the code as is that's bot one I'm such a doofus um This one is two This one is one And here we go, okay Um, okay, I think I should have more space here um Okay Um, okay, so I think i'm ready for the next phase of this And oh streaming API, that's what I need to Remember how I stream stream dash user. Okay. Okay Okay, and I think actually is this Yeah, yeah, there we go. Perfect. Um, okay Perfect, okay Um Oh, whoops, ah, come on All right I'm ready I can do that. I've got a half an hour here I can definitely do this next piece So Okay, all right everybody here we go Hello Hello, all right I'm still working with mastodon And what i'm going to do in this video now Is i'm going to take the sample bot that I made and instead of just on a timer every 24 hours every 60 minutes I happen to post something I toot What i'm going to do is i'm going to use the streaming API The streaming API is a way for me to in real time listen for events And the particular kind of events that i'm going to Listen for are what's known as user events So a user event and we'll see all the different kinds is anytime that I might get a notification Or somebody that I follow might post something or anytime that I might get anyway There's lots of things that come in user events and these are the good ones to use because if you're using your user event as a bot you're sort of making Sure that your bot only engages with people who are opting in and this is pretty important you don't want your bot just randomly spamming people and Favoriting random things or applying to random people who haven't really asked to engage with your bot So you're going to want to make sure that your bot follows the the code of conduct in the terms of service of bots in Space i'll show you where you can find that but typically a good way to think about is just like if somebody is at Mentioning the bot then you're welcome to reply to them If somebody follows you then you're also welcome to engage with that person as a as the bot programmer Okay, so let's go over and look at the streaming API And let me actually go to bots in space about Um Okay so before I before I um start using the streaming API, let me just point out to read the Information page with the code of conduct and also the terms of service if you're choosing to host your bot on bots in dot Space you're going to want to make sure you follow the rules of the space Okay. Now What i'm going to do is I am going to start using the streaming API So the way that I do that and we can find it here Remember, this is the node package that i'm using mastodon-api And this is basically what I want to do. I want to create a listener and whenever there is a message um I want to take a look at and do stuff act upon that message So let's actually do exactly this i'm going to keep the error one in here as well. I'm just going to copy paste this into my um Code I'm going to comment out this auto posting thing that I had before about the meaning of life. I'm just going to put this here And actually what I want to do now is I want to use my little trick Instead of just console logging the message if you remember a little trick that I did in a previous video is I Used write file So I want to write files out so I can look at what kind of messages i'm getting Um, whoops. Ah, where have I gone? Um, and so let me uncomment this out and I do want to Put like a time stamp also here so it would make sense for me to say like, uh data and then actually The message probably has a time stamp built into it, but I can also like javascript Uh time stamp. I think it's just like new date Uh get time. Yeah, so I can say a new date Get time. I think this is right. So again, you can put with template literals I can put a whole string to evaluate a whole line of code to evaluate in essence inside that area Okay, so let's see if this works I don't know what's going to happen Uh, let me see. Am I in the right place? No, I'm sorry. I made a new folder. Um, so i'm going to release these examples separately Uh, and i'm going to run this bot And now okay, so I don't know if it's working because I don't know if i've gotten any notification Maybe somebody watching this live is going to favorite something or at mention my bot that would be nice, right? And then something would come in through here I kind of think that maybe there was actually a mistake in the mastodon api's documentation Because I have a memory when I tried doing this earlier that the event was not message but msg short for message Let's be sure about this um Oh, oh wait, no, no, no. Okay. So look at this somebody did somebody did um So matthew let's that is correct so you can you can edit out my Go from when I was sitting there waiting to edit to now Oh, I did get a message from somebody but I made some sort of mistake Data is not defined. Uh, okay because Uh, oh, yes, it's called the variable name is msg for message, um, which is why I was thinking that I guess Um, so it should be msg here. Okay. Let's try this again And actually i'm just going to take this out and i'm just going to write Console.log User event. All right, everybody. Are you watching? Are you giving me some user events? Here we go So Waiting for my user events Uh user events, let's get a bunch more Boop Okay I think that was enough user events. Thank you very much Let's go back and we can see here that I have all of these Uh data.json files for all of these events so I can kind of click through them and see what kind of events i'm hoping that The kind people of the internet are not spamming me with horribly thing horrible things um, and oh, uh By the way, if you want don't want your information appearing up here Maybe don't but these are just people's mastodon accounts so we can see this was a follow event It's an event of notification. It's a type follow. Oh, so let's do this right now. Let's respond to that So what we're gonna do Hold on a sec pause Blow my nose So So the first kind of event We got here is a follow event. So if the event is a notification of type follow we could act on that So let's do that. Um, let's say let's go back to our code um, and i'm going to say Uh right here. I'm going to not write these out anymore um If If message dot what was it again message dot event Equals notification And I think there's going to be different kinds of notifications so i'm going to say then if message dot data dot type Follow Then what I want to do is, uh, I want to get the username so let me get the user name and that would be Where it would be right there and actually I want the account the username is useful But you always on mastodon need both the username and the instance the address of the instance the host name So let me grab account equals message dot data dot account And then the other thing that I'm pretty sure that I need is the id maybe 7670 that's the account id. This is the I don't know what this is the idea of the event, I guess So I want that account id so i'm going to say constant id equals message dot data dot id Oh dot account I forgot about account i'm also message dot data dot account dot id dot account dot account and then dot account dot id And then I want to send a message. So how do I do that? Just with this nice m dot post So here's the thing. Maybe I want to make this Quote unquote two to function a bit more generic and i'm just going to give it a I'm going to pass in a status So i'm going to get rid of the random number stuff, which was from before and then um, i'm i'm going to just put uh This is a little confusing but i'm going to take whatever I pass in and then uh, and then here is uh, And then i'm going to post that so now I have a function that I can basically say toot And I can say, uh, i'm going to use at Data dot message dot data dot account right at this is me referencing the person that followed me Uh, you know, thank you for the follow and I should be i'll just say choo choo welcome aboard Oh, that's a train theme. Welcome aboard Okay, so we can see it'll say welcome aboard now. Here's the thing I really should also if I go back to the api This one I should probably say in reply and that's a reply to this stuff because I don't need it's not in reply to me So this is actually fine. I think as long as I just add mention then i'm done So, um, so let me go. I've lost my code. Let me go. I think i'm good. So now I think that I have everything I want. So I am Let me just put the listen on error up here So i'm listening for a message if the message is a notification of a follow then I will Toot back to the person their their account name and then I will say Uh toot back to the person their their account name and say welcome aboard and let's see how this goes All right, look forward to all of you now You can unfollow and follow if you already followed, but let me run it first And here we go Oh, okay. I have a status status. I have a mistake here So I don't I I i'm not just going to change this variable name to like txt Or content let me make a content because I don't like having the same name everywhere It's confusing but there should be no semicolon after there. Okay, here we go Welcome aboard Welcome aboard welcome aboard Okay, so you can see a bunch came in and now I can go back here And I can go to here and we can see look at this These are all the people who have now and if I click there we can see where it's it's showing me and going to these People's accounts. Yay So we now have a bot that responds to follows Pause for a second Oh, right i'm such a doofus I Almost said my nose is running allergies, I think Okay um Alka from the chat pointed out something here. What did I do? Oh the whole point of me making this variable was so that I don't have to write this all out here I don't know why I did that so, um, I can just do this. This will make it much more readable And actually don't need the id so I can take that out. So this is all I need. So we are done All right. So this is follow now I'm going to show you something in the next video. I think i'm going to take a break and in the next video i'm going to look for Messages that at mention the bot and then i'm going to have that bot Act on those either reply to them or favorite or do something like that. Okay, so that's what i'm going to do next So Someone just mentioning, okay. All right. I'm missing a semicolon. There we go. Thank you Okay, um Okay What's this delete message favorite We know how I get a I want to mention, oh, here we go type mention. Okay, great Okay Okay, okay Okay Every time I look over the chat, it's a message about c sharp versus c++ python java You think everybody's watching a completely different live stream that it's not me on it Okay So Okay, i'm back again, oh so many mastodon videos this now what I want to do is look at how I can deal with a mention a mention is when somebody else toots posts And mentions me the bot in their message post so and this will come in as a notification event type mention before I dealt with if I look at my code in the previous video I Dealt with anything. That is a follow. So now I want to say else if message data dot type equals for a mention So I want to deal with a mention. So what i'm going to do in this example is if somebody says Um, please like or favorite or something like that I will like or favorite if someone says please boost or reblog I will boost slash reblog So i'm basically going to respond i'm not going to i'm not going to toot back But i'm going to act on the message based on what the content is So the first thing that I would I might want to do is I could use a regular expression so for example, I could say um Regular expression one is and if you don't know about regular expressions i'd refer you to my session on regular expressions um if if uh, like or Favorite or maybe the heart emoji. How do I get emoji? Hold on there's a way to do the emoji keyboard No How do I get it on that with the touch bar, can I just get the touch bar to no, oh that's weird Um, hold on Um emoji touch bar mac, how do I like make it happen? This is really good useful Oh if I do something like this will it just pop up No, because it's got to be like in email or something Stupid touch bar Um Mac emoji keyboard Command control space bar. That's what I was looking for. No Hey, there we go, okay There we go Oh, yeah, all right All right, I can make this regular expression I can say, um, like or favorite or uh, Like maybe if somebody, uh uses a heart I don't know. Is this the regular heart? This is the regular heart I think I think So now I basically want to look. So what is the content? So I need to um Look at this is the mention. I want to look at the data Data dot status dot content. Okay, so I need to say Content equals equals data dot status dot content And I want to say uh if regular expression test content So i'm pretty sure this is a function that if I have a regular expression If the regular expression is matched somewhere within that string content, this will return true So if that's the case, I want to say um m dot post m dot post And then what so I need to go back and look at the api documentation because I want to favorite it So if I go back here and say look at favorite The the The the uh, the path to favorite is statuses the id and favorite so I need to say um Post to and so this is what I was doing when I want to post something I would actually just say statuses Slash and I want to make this a template literal once again. I need to put the id in here Favorite okay. So this is a function that I can use to If it matches favorite it and then I need to get the id So the id is under data status id that's perfect data status id And then there are any parameters that I need here so I can just go straight to the callback error Data And I can make a little function here and I can say, you know if error console log console error error else console log Uh favorited And presumably this is going to look a lot like this I would imagine favorited Um id so let me just do data dot id I'm, i'm guessing So just to like have a little more information in here favorited um Uh data dot and by the way, this is message message dot data message dot data And this is favorited data dot id. Okay, so let's see here What's go what's wrong? Something is terribly wrong. I have i'm out of whack in terms of my brackets and things So, oh this also needs a end tick There we go and now a semicolon, okay, so apologies that this is hard to see here Let me see if I can remove this over give myself a little bit more space so we can look at this code. Ah Okay Let me just make the font a little bit smaller. There we go. Okay So what we're looking at here is If if it's a follow we're just going to say thanks for the follow If it's a mention we're going to see did the mention use the word like favorite or heart if it did Favorite it and then give me some information about whether it worked or not. So probably I also should do something like say console dot log Um Just in case them just so I can see what the the message has i'm going to say console dot log a mention Uh id Uh and then add content Okay, we are going to run this Okay, what did I lose something weird happened here? Uh, I also need this. Oh Oh boy template literal come back. Oh, I tried to reformat all this stuff Oh so sad hold on We're gonna get this back There we go, okay, we're good again There we go. Here's our code. We got it If you mention me check to see if you said like favorite or heart and if so, I am going to favorite it. All right Here we go. Let's run this bot. See if we have any errors Okay, it's starting all right better start mentioning me try mentioning me with uh With a heart with a like with saying favorite or not I will just wait Whoa, what's going on? This isn't right. Ah, something bad is happening So, okay my console logging is crazy Oh what happened here? Did I put a break point in by accident? I did not mean to do that So And what is going on, okay, hold on, all right, I got some weird errors here Uh, am I getting an error Favorited undefined. Hold on Stop everybody So Well, first let me see if this is working Okay, so it doesn't look like It doesn't look like I am favoriting this so something definitely went wrong And what is this crazy console log it's coming out here Uh, we got to debug this without me with with some actual Mention id content is that coming out? Mention Id Content then i'm getting favorited undefined and what is this insanity? Oh, it's oh something horrible happened Because when I got my when I auto hold on oh, this is so annoying. Hold on So This is ridiculously annoying This shouldn't ever be happening How is this oh because this is a no Um It's favorite in the docs with the u Yeah, but why is this happening just run this one more time So I'm waiting for somebody to mention me again Uh, oh I did I for a second I thought I froze It's nice that the stream didn't freeze today All right, all right, um mention, okay your mention this mentioned me oh there was a heart there Try mentioning me with um with like with just the word like Line 38. Oh, so favorites what's wrong? It's I need to be with a u that's interesting. Okay I love kittens. I didn't use love favorite. Oh, and I didn't use I for um Okay, great. So this one tried to I like turtles, but it's not going to work. Okay, great Okay, all right Okay, so by the way, uh weirdo Okay, so by the way, uh weird awkward edit point because it didn't work Some weird stuff happened, but I am now discovered through the thankful helpful people in the chat that I have a few errors here So number one is let's go back to the api for a second and we can see here that I didn't pay close attention It's actually spelled with a u here id favorite. So this seems kind of important that I spell it correctly So let me fix that here. Oh, but that's not actually the important place. The important place is here and then a couple other things I want to Use a flag for I for um for a case Insensitivity in other words you can and also the u should be optional here. That doesn't really matter So u is optional so you can say like favorite I don't still not sure if this is the right kind of heart that normally but now this should fix that That I should now actually be favoriting things. So we're going to try this again I'm going to go back to here and i'm going to run this bot again and i'm going to wait Oh line 38 someone's telling me What's wrong with line 38 No, um, I want the id of the thing of Of this event. Oh, I see what you mean. Yeah Oh look So this appears to be working Okay, so we can see oh oh my god, why are my settings not being retained on this computer? So I'm going to go back to here and I'm going to run this again And I'm going to run this again. So I'm going to run this again. So I'm going to run this again Oh my god, why are my settings not being retained on this computer? All right, just give me a second here where is that thing where it doesn't oh, yes, here we go. Okay All right, so um Okay, i'm back a lot of people mentioned me let's go take a look at the actual timeline Um, we and we can see that it is favoriting and we are getting an id out Um, you can see that this id is different than this id and some people are asking about that I will I will let me mention that in the chat in a second um in a second, but let me go here so uh You're my favorite. Hmm. How come it didn't? Ah, there we go. I just had to refresh so we can see this got favorited Because it has favorite in it this got favorited because it has a heart Uh, this got favorited because it has the word like i'm looking for one that doesn't have This must have been from a while ago when it wasn't working, but we can see here now um, please like please clap so, please Uh mention me without using like favorite or heart to make sure that also works So I'm just going to wait this will add we'll add this waiting part out It's 4 30 So Okay, i'm back and we can see here that k weakman Um wrote coding train bot choo choo. And if even if I refresh this page, it was not favorited So it is working only now it should be only if uh, if I go back to the code Only if this regular expression matches will I favorite? All right and by the way We could really quickly now just also like there's probably a nicer way to do this But i'm just going to really quickly like copy paste this whole thing and i'm going to say boost or Reblog or um Or retweet even or let's get another emoji in here control option Uh, let's see if you use a train emoji Or if you use the train emoji then we will uh reblog So now if I if I quickly run this again, i'll make this regex2 um if regex2 and I don't need to um I don't need to get the content or the id anymore Um, and I don't need this again Um, so now this is just and I probably it probably makes sense for me to actually Put this up. Actually, you know, they could both happen. So here now I this will boost anyone that says boost reblog retweet Or the train and and miller mentioning this is a mistake here. So this data.id This is actually um, this is the id Of this the actual favorited action which everything every action has an id So if I if somebody Message that mention has an id which I captured up here So but this is the id of the actual act of favoriting it. So I don't know debugging wise I don't know what's more important to display. I could display both of them Um, but you'll see those are two different things and this should say reblogged And this should say favorited so let's now Do this and here we go Everybody you can now ask to be favorited or reblogged So All right, a lot of mentions came in you can see some things are being favorited and reblogged Some things are just being reblogged. Let's go take a look at the timeline and uh Let's look at this. Uh, did you know? Hmm. I don't oh, yeah, I love trains this got boosted Uh coding train bot that got boosted Uh, and this one Reblog this I want the followers like it too, and we got both a reblog and a like hooray Okay, so this works. We now have a bot that that both that just checks for follows mentions and Follows and mentions if somebody follows it Uh toots back welcome aboard to that account and if somebody Uh mentions and uses any of these keywords and either favorites or reblogs So the thing that I didn't do which I which I should add to this I guess i'll do it. I don't know if it really makes sense to just keep doing more videos about this, but I'll do another video where i'll add this but you might want to try this as an exercise What how what about actually replying? What about posting an actual reply back to the person? So if the person asks, what is the meaning of life then? Uh, the bot replies with a random number or something like that. Okay, so give that a try I'll add that but i'll do that in the next video. Okay. Goodbye All right, i'm gonna go but i'm gonna just finish off this last little piece Okay, so let's see Um It really should go I'm, just so amazed that this hasn't crashed. I was really expecting the stream to crash especially because of the weird beeping happened Who knows? Who knows? All right, um I'm getting a lot of mentions. All right, let's um, let's just finish this off. Let's do this last one That's awesome Um Okay, thank you chernykh for this um All right Um, here we go Hello welcome to video number 7629 about mastodon bots. I have been on a journey a journey Along the tracks of mastodon and I have I started from nowhere and I have arrived to the point where I have a bot It's called coding train bot and what this bot does if you follow the bot It says welcome aboard and if you toot at the bot and use a certain keyword it will favorite or read toot boost whatever it is your Particular post and I want to add one more thing to it So I want to be able to respond to a question So let's just say i'm going to look for any post at me that ends with a question mark This is gonna be tricky because there's the html tags in it. I'm just going to look for a question mark I'll let you make this fancier. So let's add one more check I'm going to Constant regex3. I'm just going to look for a question mark So oh question mark is a meta character. So I think I might have to do this backslash question mark or so I want to look for a question mark if Regex3 Matches the content And by the way, this is by this is either way the how This is like the very basics of making a chat bot, which is just doing like basic pattern matching You know now chat chatbot systems use machine learning and try to category Categorize what people are saying into intents and do all sorts of text analysis but at a core level you could just use regular expressions to try to match what somebody's saying and Respond accordingly and if you I do have a set of videos about rive script, which is a pattern matching Utility that you can use in any programming a number of programming languages, but you can use it in javascript to build your own chatbot So this is you know interesting to think about what what what do you want your bot to actually do? But in this case, i'm just going to use regular expressions. I'm going to look for a question mark So, let me just actually make sure this works I'm going to say I got a question And let me look at the content so I think i'm gonna not always Console log the content anymore. I know that's working. So I just want to now I want to just look at it console log Uh data, what was it called? Did I put it in a variable content? So i'm just going to look at the content So I am now going to run this You know, by the way, if you're doing this on your own You're going to want to have a second mastodon account where you can then test it I am a weird crazy person who does this sort of stuff on a live stream Apparently, I just assume that the people out in the world watching will interact and hopefully uh Be kind. Okay. Now let us run it again. Let's see if we can get some mentions with a question mark in them and see if um Oh, there we go. Okay, so I got a question. Okay. Ooh, that's interesting Uh, oh I got a question no, that's not what somebody said to me why with a question mark Okay, so that seems to be working. So i'm gonna assume that that's good. Thank you for that. And now what I want to do Is I want to say I want to I want to do um, I want to create sorry a um, reply, so i'm going to say a reply equals um The meaning of life is and i'm going to use this This oh I had this from before by accident luckily uh is Numb But I and then I want to just send that reply but here's the thing a couple things one is I want to mention that person So I did that before When somebody followed me so I can do at and then the account which I should still have I didn't actually save the account. So if somebody mentions me, where do I get the account? Data account accounts the same thing So I can actually go back Message data account. I actually I think I kind of like always want this so Whether it is a follow or a mention to whoops So i'm going to put this out here. So I have access to that account Sorry that the font got smaller here. We can still read it. So I want to first mention That account And then say that but but here's the thing You can mention but it's not going to actually understand it as a threaded reply unless I include in reply to id So I actually also need to get the id Which I have here message data status id. So what i'm going to do is i'm going to overload this function with a second argument id and i'm going to say In reply to we got to look at the documentation. I don't remember what it is, but if I look here Oh, it's actually under over here in reply to or reply to Um, oh no, i'm in the wrong place Oh, i'm totally in the wrong. I was in the right place before In reply, there we go. I'm looking for in reply to id So I want to grab this and I want to put this here and then I want to put in the id and I guess what I want to do is The thing is, um, i'm going to do it this this is a little goofy This probably could use some fancy ternary operator or something, but i'm just going to say If id Exists, then i'm going to add it params dot in reply to id equals id So it's not going to it's all it based on whether or not if I send into this function I'm always going to send in this function some content that I want to toot But if there's an id I also want to add that in so now We should be good. If somebody asks a question. We are now replying with at that person. Oh, and this should have an at At that person did I do that up here? um When I yes at account So at account the meaning of life is and then the number okay, here we go Uh, let's actually run this you can now ask me your questions And I will wait So All right, i'm back and a bunch of people or at least two I got two, uh mentions so if I go back now and look at My bot account Hopefully it's not too spammy Are you for real and then we look at this we can see the meaning of life is 40 Uh, and this one has a question like this um, uh, yes, you can see the meaning of life is 65 and i'm just curious if somebody I was looking for one that also has the So this one for example Some fake dan shiffman. This one was both uh Favorited and boosted and replied to so this bot will actually do all of the things it is now a bot. Oh, look at this Uh, i'm just going to favorite this manually Um, by the way, everyone should look at alka's panable lisa jue table. Um, it's wonderful Uh, I am will be releasing my lisa jue coding challenge video very soon um And here you go. So this is it. Uh, we have now finished this up. We now have made a bot We've seen how a bot can post periodically with set interval something and you might come up with an idea of what you want to do We have now seen how a bot can favorite or boost things and reply to things So now it's time for you to be creative what kinds of replies what kinds of activity? Maybe you have a bot that uh makes up a poem I haven't shown you how to generate an image and post it so I will show you that i've got to make a video to Show you how to do that But there's all sorts of wonderful possibilities of how you can make your automated bot using on mastodon at bots in dot space Okay, so choo-choo everybody See you in a future video. I hope you enjoyed this series about making a mastodon bot more to come in the future I i'm sure goodbye All right, um Um Come on come back Yeah, an undefined one would probably that probably would be fine Um a me I am certainly made a good point I imagine an undefined and reply to id would be allowed to mean there isn't one So I probably didn't need that extra step, but I did do it. All right so, um, I this bot is I wonder if I should deploy this bot somewhere um so that um People who watch the videos can interact with it, but um, it did hit 42 Where where where where where? Oh, there we go So, can I desktop There we go There we go Okay Um, all right everyone this by the way, if is my uh, Okay um, all right everyone this by the way, if is my um, I am now on mastodon at shifman at choo-choo dot space again, unfortunately right now I am Leaving choo-choo dot space closed for uh, youtube members or patrons and I would um Um Gladly open that up. Sorry, um Open that up if um, if it makes sense to do that at some point All right. Anyone have any questions they want to ask? I think i'm finished for today. It's almost five o'clock Um, you could deploy it on the same box choo-choo dot space instances on exactly. That's what i'll do Maybe I should do that real quick right now I'm afraid to log into that instance ever um All right, um Anybody any anything else to say to do to wonder? Um, oh, let me mention let me do something right now Because I have so many videos now i'm gonna go here most recently This style transfer video posted let me go here and post the next one So I would love people to try out the style transfer thing and see if you're able to follow it um, so, um the second style transfer video part two Um, let me just check this to make sure um Um I'm going to post that one now So in a moment I'm releasing I don't have the youtube premiere thing unlocked in my account I really want to get that unlocked in my account Because I think it'll be fun to interact live the first time a video is posted even though it's like the second time It's already additional live stream, but you know, so i'm going to set part two public um And i'm gonna say actions public I understand that I can't undo and now We should see here just released on the channel um pending Um Nope come on youtube Uh, etan asks, will you explain how style transfer works in more technical terms? Um, if you were interested in that you should check out. Um, let me let me show you where to find this I don't know why it's like taking a million years to set this video to public. It's kind of ridiculous I don't know why it's taking a million years to set this video to public. It's kind of ridiculous Oh, it was successful so now um Part two should Well, hold on. Let me just it'll it'll appear eventually i'm gonna go to playlists On my channel and i'm going to go to this one Um and The machine learning videos using the spell platform and This is my introduction to the spell platform. This is the style transfer video Of how to train your model style transfer model and this is the style transfer video of how to actually run the style transfer model in the browser With ml5js which runs on top of tensorflow.js but um etan in the chat had asked about Um Explaining style transfer in more detail. I would refer you to so both of these you can see this is about 50 minutes These are edited out of the one hour 26 minute live stream Just to give people sort of streamlined versions of the videos. They just want to follow the tutorials but if I go to the live stream and um If I go to the description, sorry, this is like i'm Um Oh, this is working now. Never forget the this dot t-shirt. I'll refactor that later. I've got some new t-shirts and things um if I go to The description is what i'm looking for show more. Yes this at 4 minutes and 28 seconds Um, this is where yaning begins her presentation and in this presentation I can just put it quickly on like Uh speed hold on uh speed two times Um So this is where she gives her presentation where she talks through the details behind What where style transfer comes from and how it technically works and how the training so all of the number one and two What is style transfer and how does it work? You'll find here Numbers three and four have been edited into shorter videos. Okay, so that's where you can find that information and please i'm really curious This is like high degree of difficulty stuff to like Train a model to deploy train that model into the cloud to then get the train model to run it in the browser If you're able to get it to work, please share with me and let me know I know twitter or mastodon. I guess i'm unaware um And um, if you're not able to get it to work, uh, let me know try to try to send a message post a comment We'll see if we can help you out, um to get it to work Okay Um So that's it for today. Thank you everyone for watching. I will be back up on friday on friday You will see if I go to youtube coding train You will see that on friday we will be doing another Neural network machine learning training live stream this time at 11 a.m Eastern I think that's what we set it for. Um Text generation. So we're going to use something called a long short-term memory network Training it on the cloud with a you can train it on a corpus of text And then run the model to have that that model generate new text in the same vein as what it's been trained on So that will be something that I will show and I guess nabil hassein will be here on friday to show how to do that All right. Thank you everybody I will leave you Thanks for tuning in to today's special Coding train about mastodon and all that stuff. Hopefully you found this useful and interesting stay tuned Hopefully maybe even tomorrow. Um, the lisa jue coding challenge will come out Um, and as always thanks for your support. Thanks for watching I hope you're finding this enjoyable and interesting and useful and if not That's okay, too. I would completely understand I always i'm here for your feedback And i'm hoping have a wonderful week and I will see you on friday for sure. Okay Ah, you know what I need I need a second ukulele i'm just gonna buy another ukulele Because I can't bring it back and forth from home to here from home to here And I should I need to play the ukulele more on this live stream. So somebody recommend now that I know that I I'm, I love the ukulele. Um, I don't know. I bought like the cheapest one. They had at the guitar center So i'll take recommendations. Could I get like a coding train themed rainbow like Ukulele, maybe that's a thing Um, all right Was it aki mcu hack the bot? That's great to hear. Goodbye everybody I feel like doing a twirl So Yeah, no green no green in the ukulele, please You",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:49.555892Z",
  "started_at": "2023-09-26T21:18:05.775604Z",
  "completed_at": "2023-09-26T21:42:52.238635Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=4L4JyWyb3oI",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1486.463031
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/smn2v4jbiv4lu4waqemzryzieu/cancel",
    "get": "https://api.replicate.com/v1/predictions/smn2v4jbiv4lu4waqemzryzieu"
  }
}