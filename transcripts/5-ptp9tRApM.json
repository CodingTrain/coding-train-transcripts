{
  "id": "m6tyfejbv7jtgj2xuiagxmkyii",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/5-ptp9tRApM.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/118581 [00:00<?, ?frames/s]\n  2%|▏         | 2744/118581 [00:05<03:41, 523.45frames/s]\n  5%|▍         | 5542/118581 [00:10<03:44, 503.74frames/s]\n  7%|▋         | 8458/118581 [00:18<04:07, 445.64frames/s]\n 10%|▉         | 11442/118581 [00:24<03:58, 450.14frames/s]\n 12%|█▏        | 14346/118581 [00:32<04:05, 424.74frames/s]\n 15%|█▍        | 17206/118581 [00:39<04:07, 409.53frames/s]\n 17%|█▋        | 20094/118581 [00:46<03:53, 421.65frames/s]\n 19%|█▉        | 22992/118581 [00:54<03:59, 399.60frames/s]\n 22%|██▏       | 25588/118581 [01:01<04:01, 385.13frames/s]\n 24%|██▍       | 28548/118581 [01:10<04:06, 365.00frames/s]\n 26%|██▋       | 31320/118581 [01:20<04:23, 331.35frames/s]\n 29%|██▉       | 34228/118581 [01:29<04:12, 333.84frames/s]\n 31%|███▏      | 37060/118581 [01:37<04:04, 333.43frames/s]\n 34%|███▍      | 40056/118581 [01:47<03:59, 327.28frames/s]\n 36%|███▋      | 43052/118581 [01:54<03:32, 356.06frames/s]\n 39%|███▉      | 46052/118581 [02:02<03:21, 359.99frames/s]\n 41%|████      | 48572/118581 [02:07<03:00, 388.68frames/s]\n 43%|████▎     | 51392/118581 [02:14<02:49, 395.55frames/s]\n 46%|████▌     | 54164/118581 [02:23<02:57, 362.39frames/s]\n 48%|████▊     | 57008/118581 [02:32<02:54, 351.97frames/s]\n 51%|█████     | 60000/118581 [02:40<02:47, 349.38frames/s]\n 53%|█████▎    | 62610/118581 [02:45<02:24, 386.26frames/s]\n 55%|█████▌    | 65390/118581 [02:50<02:06, 420.28frames/s]\n 58%|█████▊    | 68238/118581 [02:58<02:03, 406.87frames/s]\n 60%|█████▉    | 71050/118581 [03:06<02:00, 393.42frames/s]\n 62%|██████▏   | 73990/118581 [03:15<02:02, 365.43frames/s]\n 65%|██████▍   | 76878/118581 [03:24<01:58, 352.28frames/s]\n 67%|██████▋   | 79854/118581 [03:32<01:47, 359.25frames/s]\n 69%|██████▉   | 82358/118581 [03:39<01:42, 353.80frames/s]\n 72%|███████▏  | 85106/118581 [03:47<01:35, 350.96frames/s]\n 74%|███████▍  | 87928/118581 [03:56<01:29, 341.66frames/s]\n 77%|███████▋  | 90828/118581 [04:04<01:18, 351.41frames/s]\n 79%|███████▉  | 93572/118581 [04:11<01:11, 351.84frames/s]\n 81%|████████▏ | 96552/118581 [04:19<01:00, 363.89frames/s]\n 84%|████████▍ | 99480/118581 [04:27<00:51, 367.94frames/s]\n 86%|████████▋ | 102320/118581 [04:36<00:46, 346.52frames/s]\n 89%|████████▊ | 105156/118581 [04:43<00:36, 368.00frames/s]\n 91%|█████████ | 108028/118581 [04:52<00:30, 346.58frames/s]\n 94%|█████████▎| 110918/118581 [05:01<00:22, 342.71frames/s]\n 96%|█████████▌| 113798/118581 [05:11<00:14, 325.39frames/s]\n 98%|█████████▊| 116506/118581 [05:21<00:06, 307.55frames/s]\n 99%|█████████▉| 117630/118581 [05:25<00:03, 299.39frames/s]\n100%|██████████| 118581/118581 [05:26<00:00, 336.74frames/s]\n100%|██████████| 118581/118581 [05:26<00:00, 363.51frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 2.84,
        "id": 0,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Let's review what we did in the previous video.",
        "tokens": [
          50364,
          961,
          311,
          3131,
          437,
          321,
          630,
          294,
          264,
          3894,
          960,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 4.6000000000000005,
        "id": 1,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 2.84,
        "temperature": 0,
        "text": " So this video is entirely dependent,",
        "tokens": [
          50506,
          407,
          341,
          960,
          307,
          7696,
          12334,
          11,
          50594
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 9.6,
        "id": 2,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 4.6000000000000005,
        "temperature": 0,
        "text": " this is part two of graphing a CSV data file.",
        "tokens": [
          50594,
          341,
          307,
          644,
          732,
          295,
          1295,
          79,
          571,
          257,
          48814,
          1412,
          3991,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 10.98,
        "id": 3,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 9.96,
        "temperature": 0,
        "text": " So in the previous video,",
        "tokens": [
          50862,
          407,
          294,
          264,
          3894,
          960,
          11,
          50913
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 14.38,
        "id": 4,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 10.98,
        "temperature": 0,
        "text": " we went and got global world temperatures,",
        "tokens": [
          50913,
          321,
          1437,
          293,
          658,
          4338,
          1002,
          12633,
          11,
          51083
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 18.04,
        "id": 5,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 14.38,
        "temperature": 0,
        "text": " the average world temperature from 1880 to present.",
        "tokens": [
          51083,
          264,
          4274,
          1002,
          4292,
          490,
          2443,
          4702,
          281,
          1974,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 19.28,
        "id": 6,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 18.04,
        "temperature": 0,
        "text": " We got that as a CSV,",
        "tokens": [
          51266,
          492,
          658,
          300,
          382,
          257,
          48814,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 22.7,
        "id": 7,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 19.28,
        "temperature": 0,
        "text": " commerce separated values file from NASA.",
        "tokens": [
          51328,
          395,
          17141,
          12005,
          4190,
          3991,
          490,
          12077,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 25.68,
        "id": 8,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 22.7,
        "temperature": 0,
        "text": " We parsed it using some simple string parsing techniques",
        "tokens": [
          51499,
          492,
          21156,
          292,
          309,
          1228,
          512,
          2199,
          6798,
          21156,
          278,
          7512,
          51648
        ]
      },
      {
        "avg_logprob": -0.24428734955964265,
        "compression_ratio": 1.6541666666666666,
        "end": 27.44,
        "id": 9,
        "no_speech_prob": 0.0007321527227759361,
        "seek": 0,
        "start": 25.68,
        "temperature": 0,
        "text": " with the split function.",
        "tokens": [
          51648,
          365,
          264,
          7472,
          2445,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 30.040000000000003,
        "id": 10,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 27.44,
        "temperature": 0,
        "text": " Now we're able to console log that data,",
        "tokens": [
          50364,
          823,
          321,
          434,
          1075,
          281,
          11076,
          3565,
          300,
          1412,
          11,
          50494
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 31.64,
        "id": 11,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 30.040000000000003,
        "temperature": 0,
        "text": " but instead of console logging that data,",
        "tokens": [
          50494,
          457,
          2602,
          295,
          11076,
          27991,
          300,
          1412,
          11,
          50574
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 32.64,
        "id": 12,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 31.64,
        "temperature": 0,
        "text": " I want to graph it.",
        "tokens": [
          50574,
          286,
          528,
          281,
          4295,
          309,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 34.760000000000005,
        "id": 13,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 32.64,
        "temperature": 0,
        "text": " There are so many different approaches we could take.",
        "tokens": [
          50624,
          821,
          366,
          370,
          867,
          819,
          11587,
          321,
          727,
          747,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 39.34,
        "id": 14,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 34.760000000000005,
        "temperature": 0,
        "text": " There are many JavaScript libraries for making charts.",
        "tokens": [
          50730,
          821,
          366,
          867,
          15778,
          15148,
          337,
          1455,
          17767,
          13,
          50959
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 42.84,
        "id": 15,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 40.68,
        "temperature": 0,
        "text": " Probably one of the most famous ones is D3,",
        "tokens": [
          51026,
          9210,
          472,
          295,
          264,
          881,
          4618,
          2306,
          307,
          413,
          18,
          11,
          51134
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 45.120000000000005,
        "id": 16,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 42.84,
        "temperature": 0,
        "text": " a data visualization library for JavaScript.",
        "tokens": [
          51134,
          257,
          1412,
          25801,
          6405,
          337,
          15778,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 47.56,
        "id": 17,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 45.120000000000005,
        "temperature": 0,
        "text": " We could also draw our own chart",
        "tokens": [
          51248,
          492,
          727,
          611,
          2642,
          527,
          1065,
          6927,
          51370
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 50.96,
        "id": 18,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 47.56,
        "temperature": 0,
        "text": " just by using HTML5 canvas and drawing functions,",
        "tokens": [
          51370,
          445,
          538,
          1228,
          17995,
          20,
          16267,
          293,
          6316,
          6828,
          11,
          51540
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 53.2,
        "id": 19,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 50.96,
        "temperature": 0,
        "text": " or using something like P5.js,",
        "tokens": [
          51540,
          420,
          1228,
          746,
          411,
          430,
          20,
          13,
          25530,
          11,
          51652
        ]
      },
      {
        "avg_logprob": -0.21442311497057898,
        "compression_ratio": 1.6546762589928057,
        "end": 55.42,
        "id": 20,
        "no_speech_prob": 0.00018235386232845485,
        "seek": 2744,
        "start": 53.2,
        "temperature": 0,
        "text": " which is a creative coding JavaScript library",
        "tokens": [
          51652,
          597,
          307,
          257,
          5880,
          17720,
          15778,
          6405,
          51763
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 58.14,
        "id": 21,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 55.42,
        "temperature": 0,
        "text": " that I use a ton to draw all sorts of kinds",
        "tokens": [
          50364,
          300,
          286,
          764,
          257,
          2952,
          281,
          2642,
          439,
          7527,
          295,
          3685,
          50500
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 59.68,
        "id": 22,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 58.14,
        "temperature": 0,
        "text": " of interactive animations,",
        "tokens": [
          50500,
          295,
          15141,
          22868,
          11,
          50577
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 62.06,
        "id": 23,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 59.68,
        "temperature": 0,
        "text": " and I could draw something based on the data there.",
        "tokens": [
          50577,
          293,
          286,
          727,
          2642,
          746,
          2361,
          322,
          264,
          1412,
          456,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 63.42,
        "id": 24,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 62.06,
        "temperature": 0,
        "text": " But I want to show you just kind of",
        "tokens": [
          50696,
          583,
          286,
          528,
          281,
          855,
          291,
          445,
          733,
          295,
          50764
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 65.7,
        "id": 25,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 63.42,
        "temperature": 0,
        "text": " what might be the quickest path right now",
        "tokens": [
          50764,
          437,
          1062,
          312,
          264,
          49403,
          3100,
          558,
          586,
          50878
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 68.1,
        "id": 26,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 65.7,
        "temperature": 0,
        "text": " to going from data to chart in the browser.",
        "tokens": [
          50878,
          281,
          516,
          490,
          1412,
          281,
          6927,
          294,
          264,
          11185,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 70.18,
        "id": 27,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 68.1,
        "temperature": 0,
        "text": " And so a simple tool, a library,",
        "tokens": [
          50998,
          400,
          370,
          257,
          2199,
          2290,
          11,
          257,
          6405,
          11,
          51102
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 72.82000000000001,
        "id": 28,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 70.18,
        "temperature": 0,
        "text": " JavaScript library for doing this is chart.js.",
        "tokens": [
          51102,
          15778,
          6405,
          337,
          884,
          341,
          307,
          6927,
          13,
          25530,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 75.38,
        "id": 29,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 72.82000000000001,
        "temperature": 0,
        "text": " Chart.js is a library you can import right there",
        "tokens": [
          51234,
          49762,
          13,
          25530,
          307,
          257,
          6405,
          291,
          393,
          974,
          558,
          456,
          51362
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 77.06,
        "id": 30,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 75.38,
        "temperature": 0,
        "text": " into your client-side JavaScript",
        "tokens": [
          51362,
          666,
          428,
          6423,
          12,
          1812,
          15778,
          51446
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 79.5,
        "id": 31,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 77.06,
        "temperature": 0,
        "text": " with creating a chart object.",
        "tokens": [
          51446,
          365,
          4084,
          257,
          6927,
          2657,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 81.52000000000001,
        "id": 32,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 79.5,
        "temperature": 0,
        "text": " You can just configure it, you can give it the data,",
        "tokens": [
          51568,
          509,
          393,
          445,
          22162,
          309,
          11,
          291,
          393,
          976,
          309,
          264,
          1412,
          11,
          51669
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 82.66,
        "id": 33,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 81.52000000000001,
        "temperature": 0,
        "text": " give it some colors,",
        "tokens": [
          51669,
          976,
          309,
          512,
          4577,
          11,
          51726
        ]
      },
      {
        "avg_logprob": -0.21695411436019404,
        "compression_ratio": 1.7827476038338659,
        "end": 84.58,
        "id": 34,
        "no_speech_prob": 0.0022871659602969885,
        "seek": 5542,
        "start": 82.66,
        "temperature": 0,
        "text": " tell it whether you want a line or a bar chart,",
        "tokens": [
          51726,
          980,
          309,
          1968,
          291,
          528,
          257,
          1622,
          420,
          257,
          2159,
          6927,
          11,
          51822
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 86.89999999999999,
        "id": 35,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 84.58,
        "temperature": 0,
        "text": " and poof, you'll see the chart",
        "tokens": [
          50364,
          293,
          714,
          2670,
          11,
          291,
          603,
          536,
          264,
          6927,
          50480
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 88.9,
        "id": 36,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 86.89999999999999,
        "temperature": 0,
        "text": " on the webpage in a canvas.",
        "tokens": [
          50480,
          322,
          264,
          37852,
          294,
          257,
          16267,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 90.5,
        "id": 37,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 88.9,
        "temperature": 0,
        "text": " So I'm going to show you step-by-step",
        "tokens": [
          50580,
          407,
          286,
          478,
          516,
          281,
          855,
          291,
          1823,
          12,
          2322,
          12,
          16792,
          50660
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 93.66,
        "id": 38,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 90.5,
        "temperature": 0,
        "text": " how to import the library, add a canvas,",
        "tokens": [
          50660,
          577,
          281,
          974,
          264,
          6405,
          11,
          909,
          257,
          16267,
          11,
          50818
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 97.24,
        "id": 39,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 93.66,
        "temperature": 0,
        "text": " draw the chart, and then draw the chart using your own data.",
        "tokens": [
          50818,
          2642,
          264,
          6927,
          11,
          293,
          550,
          2642,
          264,
          6927,
          1228,
          428,
          1065,
          1412,
          13,
          50997
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 99.98,
        "id": 40,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 97.24,
        "temperature": 0,
        "text": " So here we are, the chart.js website.",
        "tokens": [
          50997,
          407,
          510,
          321,
          366,
          11,
          264,
          6927,
          13,
          25530,
          3144,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 102.74,
        "id": 41,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 99.98,
        "temperature": 0,
        "text": " There's a lot of examples, a lot of documentation,",
        "tokens": [
          51134,
          821,
          311,
          257,
          688,
          295,
          5110,
          11,
          257,
          688,
          295,
          14333,
          11,
          51272
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 104.18,
        "id": 42,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 102.74,
        "temperature": 0,
        "text": " the source code on GitHub.",
        "tokens": [
          51272,
          264,
          4009,
          3089,
          322,
          23331,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 105.66,
        "id": 43,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 104.18,
        "temperature": 0,
        "text": " I encourage you to check out more",
        "tokens": [
          51344,
          286,
          5373,
          291,
          281,
          1520,
          484,
          544,
          51418
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 107.25999999999999,
        "id": 44,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 105.66,
        "temperature": 0,
        "text": " about the JavaScript library.",
        "tokens": [
          51418,
          466,
          264,
          15778,
          6405,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 111.14,
        "id": 45,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 107.25999999999999,
        "temperature": 0,
        "text": " I'm going to move to this get started page,",
        "tokens": [
          51498,
          286,
          478,
          516,
          281,
          1286,
          281,
          341,
          483,
          1409,
          3028,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.1833074249490334,
        "compression_ratio": 1.6985294117647058,
        "end": 114.42,
        "id": 46,
        "no_speech_prob": 0.00004908646224066615,
        "seek": 8458,
        "start": 111.14,
        "temperature": 0,
        "text": " which will give me the basic techniques",
        "tokens": [
          51692,
          597,
          486,
          976,
          385,
          264,
          3875,
          7512,
          51856
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 116.10000000000001,
        "id": 47,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 115.26,
        "temperature": 0,
        "text": " for using chart.js.",
        "tokens": [
          50406,
          337,
          1228,
          6927,
          13,
          25530,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 118.62,
        "id": 48,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 116.10000000000001,
        "temperature": 0,
        "text": " So first thing is, how do I even import the library?",
        "tokens": [
          50448,
          407,
          700,
          551,
          307,
          11,
          577,
          360,
          286,
          754,
          974,
          264,
          6405,
          30,
          50574
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 119.74000000000001,
        "id": 49,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 118.62,
        "temperature": 0,
        "text": " And this is crucial.",
        "tokens": [
          50574,
          400,
          341,
          307,
          11462,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 122.34,
        "id": 50,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 119.74000000000001,
        "temperature": 0,
        "text": " I'm going to use a chart.js CDN.",
        "tokens": [
          50630,
          286,
          478,
          516,
          281,
          764,
          257,
          6927,
          13,
          25530,
          6743,
          45,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 124.94,
        "id": 51,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 122.34,
        "temperature": 0,
        "text": " So CDN stands for Content Delivery Network,",
        "tokens": [
          50760,
          407,
          6743,
          45,
          7382,
          337,
          30078,
          5831,
          8549,
          12640,
          11,
          50890
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 126.98,
        "id": 52,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 124.94,
        "temperature": 0,
        "text": " meaning I'm going to load the library via URL.",
        "tokens": [
          50890,
          3620,
          286,
          478,
          516,
          281,
          3677,
          264,
          6405,
          5766,
          12905,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 128.38,
        "id": 53,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 126.98,
        "temperature": 0,
        "text": " It's hosted somewhere on the internet.",
        "tokens": [
          50992,
          467,
          311,
          19204,
          4079,
          322,
          264,
          4705,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 131.5,
        "id": 54,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 128.38,
        "temperature": 0,
        "text": " So let's click on this and see where that takes us.",
        "tokens": [
          51062,
          407,
          718,
          311,
          2052,
          322,
          341,
          293,
          536,
          689,
          300,
          2516,
          505,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 133.82,
        "id": 55,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 131.5,
        "temperature": 0,
        "text": " It takes us to jsdeliver.",
        "tokens": [
          51218,
          467,
          2516,
          505,
          281,
          42713,
          18105,
          1837,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 136.1,
        "id": 56,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 133.82,
        "temperature": 0,
        "text": " Then all I need to do is go down here.",
        "tokens": [
          51334,
          1396,
          439,
          286,
          643,
          281,
          360,
          307,
          352,
          760,
          510,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 138.92000000000002,
        "id": 57,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 136.1,
        "temperature": 0,
        "text": " We can see this is the most recent version,",
        "tokens": [
          51448,
          492,
          393,
          536,
          341,
          307,
          264,
          881,
          5162,
          3037,
          11,
          51589
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 141.1,
        "id": 58,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 138.92000000000002,
        "temperature": 0,
        "text": " 2.8.0 of the library.",
        "tokens": [
          51589,
          568,
          13,
          23,
          13,
          15,
          295,
          264,
          6405,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.20760135650634765,
        "compression_ratio": 1.6870748299319729,
        "end": 143.46,
        "id": 59,
        "no_speech_prob": 0.0016229536850005388,
        "seek": 11442,
        "start": 141.1,
        "temperature": 0,
        "text": " If I click on this, it's going to open up a new webpage.",
        "tokens": [
          51698,
          759,
          286,
          2052,
          322,
          341,
          11,
          309,
          311,
          516,
          281,
          1269,
          493,
          257,
          777,
          37852,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 146.26000000000002,
        "id": 60,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 143.46,
        "temperature": 0,
        "text": " And look, that's actually, wah, that's the JavaScript library.",
        "tokens": [
          50364,
          400,
          574,
          11,
          300,
          311,
          767,
          11,
          31979,
          11,
          300,
          311,
          264,
          15778,
          6405,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 148.22,
        "id": 61,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 146.26000000000002,
        "temperature": 0,
        "text": " All the code for the JavaScript library itself.",
        "tokens": [
          50504,
          1057,
          264,
          3089,
          337,
          264,
          15778,
          6405,
          2564,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 150.58,
        "id": 62,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 148.22,
        "temperature": 0,
        "text": " It's actually been minified, meaning",
        "tokens": [
          50602,
          467,
          311,
          767,
          668,
          923,
          2587,
          11,
          3620,
          50720
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 153.46,
        "id": 63,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 150.58,
        "temperature": 0,
        "text": " the raw source of the library has line breaks,",
        "tokens": [
          50720,
          264,
          8936,
          4009,
          295,
          264,
          6405,
          575,
          1622,
          9857,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 155.5,
        "id": 64,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 153.46,
        "temperature": 0,
        "text": " and big variable names, and all that kind of stuff.",
        "tokens": [
          50864,
          293,
          955,
          7006,
          5288,
          11,
          293,
          439,
          300,
          733,
          295,
          1507,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 158.3,
        "id": 65,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 155.5,
        "temperature": 0,
        "text": " But I'm just going to, all I need is this URL right here.",
        "tokens": [
          50966,
          583,
          286,
          478,
          445,
          516,
          281,
          11,
          439,
          286,
          643,
          307,
          341,
          12905,
          558,
          510,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 160.58,
        "id": 66,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 158.3,
        "temperature": 0,
        "text": " I'm going to go back into my code.",
        "tokens": [
          51106,
          286,
          478,
          516,
          281,
          352,
          646,
          666,
          452,
          3089,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 162.78,
        "id": 67,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 160.58,
        "temperature": 0,
        "text": " I'm going to go into the header.",
        "tokens": [
          51220,
          286,
          478,
          516,
          281,
          352,
          666,
          264,
          23117,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 164.18,
        "id": 68,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 162.78,
        "temperature": 0,
        "text": " And I'm going to say script.",
        "tokens": [
          51330,
          400,
          286,
          478,
          516,
          281,
          584,
          5755,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 165.98000000000002,
        "id": 69,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 164.18,
        "temperature": 0,
        "text": " I'm going to say source equals.",
        "tokens": [
          51400,
          286,
          478,
          516,
          281,
          584,
          4009,
          6915,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 169.18,
        "id": 70,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 165.98000000000002,
        "temperature": 0,
        "text": " And what I want is the URL to the JavaScript library",
        "tokens": [
          51490,
          400,
          437,
          286,
          528,
          307,
          264,
          12905,
          281,
          264,
          15778,
          6405,
          51650
        ]
      },
      {
        "avg_logprob": -0.2523227076376638,
        "compression_ratio": 1.8953068592057762,
        "end": 172.06,
        "id": 71,
        "no_speech_prob": 0.00018814089708030224,
        "seek": 14346,
        "start": 169.18,
        "temperature": 0,
        "text": " I want to use, chart.js, which is now,",
        "tokens": [
          51650,
          286,
          528,
          281,
          764,
          11,
          6927,
          13,
          25530,
          11,
          597,
          307,
          586,
          11,
          51794
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 173.46,
        "id": 72,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 172.06,
        "temperature": 0,
        "text": " I'm going to paste that right in.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          9163,
          300,
          558,
          294,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 176.22,
        "id": 73,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 173.46,
        "temperature": 0,
        "text": " And as soon as I close this, Visual Studio Code",
        "tokens": [
          50434,
          400,
          382,
          2321,
          382,
          286,
          1998,
          341,
          11,
          23187,
          13500,
          15549,
          50572
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 177.42000000000002,
        "id": 74,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 176.22,
        "temperature": 0,
        "text": " is doing a nice thing for me.",
        "tokens": [
          50572,
          307,
          884,
          257,
          1481,
          551,
          337,
          385,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 179.26,
        "id": 75,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 177.42000000000002,
        "temperature": 0,
        "text": " It's closing the script tag automatically.",
        "tokens": [
          50632,
          467,
          311,
          10377,
          264,
          5755,
          6162,
          6772,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 181.22,
        "id": 76,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 179.26,
        "temperature": 0,
        "text": " But otherwise, we would have to type that in.",
        "tokens": [
          50724,
          583,
          5911,
          11,
          321,
          576,
          362,
          281,
          2010,
          300,
          294,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 186.06,
        "id": 77,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 181.22,
        "temperature": 0,
        "text": " So open script tag, source equals this, and the URL,",
        "tokens": [
          50822,
          407,
          1269,
          5755,
          6162,
          11,
          4009,
          6915,
          341,
          11,
          293,
          264,
          12905,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 187.14000000000001,
        "id": 78,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 186.06,
        "temperature": 0,
        "text": " and then close script tag.",
        "tokens": [
          51064,
          293,
          550,
          1998,
          5755,
          6162,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 190.46,
        "id": 79,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 187.14000000000001,
        "temperature": 0,
        "text": " So now I have chart.js loaded.",
        "tokens": [
          51118,
          407,
          586,
          286,
          362,
          6927,
          13,
          25530,
          13210,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 192.9,
        "id": 80,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 190.46,
        "temperature": 0,
        "text": " The next thing I need is I need to have",
        "tokens": [
          51284,
          440,
          958,
          551,
          286,
          643,
          307,
          286,
          643,
          281,
          362,
          51406
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 197.46,
        "id": 81,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 192.9,
        "temperature": 0,
        "text": " a canvas in my HTML itself.",
        "tokens": [
          51406,
          257,
          16267,
          294,
          452,
          17995,
          2564,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.21641851806640625,
        "compression_ratio": 1.6693548387096775,
        "end": 200.94,
        "id": 82,
        "no_speech_prob": 0.000053910720453131944,
        "seek": 17206,
        "start": 197.46,
        "temperature": 0,
        "text": " So I need to add a canvas element.",
        "tokens": [
          51634,
          407,
          286,
          643,
          281,
          909,
          257,
          16267,
          4478,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 204.54,
        "id": 83,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 200.94,
        "temperature": 0,
        "text": " I'm going to give it an ID like chart.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          976,
          309,
          364,
          7348,
          411,
          6927,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 207.14,
        "id": 84,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 204.54,
        "temperature": 0,
        "text": " And I think I also need to give it a width.",
        "tokens": [
          50544,
          400,
          286,
          519,
          286,
          611,
          643,
          281,
          976,
          309,
          257,
          11402,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 209.3,
        "id": 85,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 207.14,
        "temperature": 0,
        "text": " Let's just try 400 and a height.",
        "tokens": [
          50674,
          961,
          311,
          445,
          853,
          8423,
          293,
          257,
          6681,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 210.9,
        "id": 86,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 209.3,
        "temperature": 0,
        "text": " 400, and those should be in quotes.",
        "tokens": [
          50782,
          8423,
          11,
          293,
          729,
          820,
          312,
          294,
          19963,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 212.9,
        "id": 87,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 210.9,
        "temperature": 0,
        "text": " Thank you, Visual Studio Code, for correcting me",
        "tokens": [
          50862,
          1044,
          291,
          11,
          23187,
          13500,
          15549,
          11,
          337,
          47032,
          385,
          50962
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 214.5,
        "id": 88,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 212.9,
        "temperature": 0,
        "text": " when I hit Save.",
        "tokens": [
          50962,
          562,
          286,
          2045,
          15541,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 215.66,
        "id": 89,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 214.5,
        "temperature": 0,
        "text": " So there you go.",
        "tokens": [
          51042,
          407,
          456,
          291,
          352,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 217.4,
        "id": 90,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 215.66,
        "temperature": 0,
        "text": " So you can now see I've added a canvas.",
        "tokens": [
          51100,
          407,
          291,
          393,
          586,
          536,
          286,
          600,
          3869,
          257,
          16267,
          13,
          51187
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 218.66,
        "id": 91,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 217.4,
        "temperature": 0,
        "text": " I gave it an ID.",
        "tokens": [
          51187,
          286,
          2729,
          309,
          364,
          7348,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 220.3,
        "id": 92,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 218.66,
        "temperature": 0,
        "text": " And I gave it a width and a height.",
        "tokens": [
          51250,
          400,
          286,
          2729,
          309,
          257,
          11402,
          293,
          257,
          6681,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 224.46,
        "id": 93,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 220.3,
        "temperature": 0,
        "text": " So somehow, I need to tell this data",
        "tokens": [
          51332,
          407,
          6063,
          11,
          286,
          643,
          281,
          980,
          341,
          1412,
          51540
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 227.3,
        "id": 94,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 224.46,
        "temperature": 0,
        "text": " to graph itself on that canvas.",
        "tokens": [
          51540,
          281,
          4295,
          2564,
          322,
          300,
          16267,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.19001581971074494,
        "compression_ratio": 1.647940074906367,
        "end": 229.92,
        "id": 95,
        "no_speech_prob": 0.00002840966044459492,
        "seek": 20094,
        "start": 227.3,
        "temperature": 0,
        "text": " Let's go back to that getting started page.",
        "tokens": [
          51682,
          961,
          311,
          352,
          646,
          281,
          300,
          1242,
          1409,
          3028,
          13,
          51813
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 231.83999999999997,
        "id": 96,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 229.92,
        "temperature": 0,
        "text": " And look, we've got some code.",
        "tokens": [
          50364,
          400,
          574,
          11,
          321,
          600,
          658,
          512,
          3089,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 233.64,
        "id": 97,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 231.83999999999997,
        "temperature": 0,
        "text": " It's given us some code here.",
        "tokens": [
          50460,
          467,
          311,
          2212,
          505,
          512,
          3089,
          510,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 237.95999999999998,
        "id": 98,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 233.64,
        "temperature": 0,
        "text": " This is code for some sort of bar chart with some data.",
        "tokens": [
          50550,
          639,
          307,
          3089,
          337,
          512,
          1333,
          295,
          2159,
          6927,
          365,
          512,
          1412,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 240.16,
        "id": 99,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 237.95999999999998,
        "temperature": 0,
        "text": " So one way that we could actually",
        "tokens": [
          50766,
          407,
          472,
          636,
          300,
          321,
          727,
          767,
          50876
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 242.79999999999998,
        "id": 100,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 240.16,
        "temperature": 0,
        "text": " start working with this is just let's just copy, paste,",
        "tokens": [
          50876,
          722,
          1364,
          365,
          341,
          307,
          445,
          718,
          311,
          445,
          5055,
          11,
          9163,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 243.88,
        "id": 101,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 242.79999999999998,
        "temperature": 0,
        "text": " and take this code.",
        "tokens": [
          51008,
          293,
          747,
          341,
          3089,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 245.72,
        "id": 102,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 243.88,
        "temperature": 0,
        "text": " So when you're working with a new library,",
        "tokens": [
          51062,
          407,
          562,
          291,
          434,
          1364,
          365,
          257,
          777,
          6405,
          11,
          51154
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 246.92,
        "id": 103,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 245.72,
        "temperature": 0,
        "text": " you can try a variety of things.",
        "tokens": [
          51154,
          291,
          393,
          853,
          257,
          5673,
          295,
          721,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 248.22,
        "id": 104,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 246.92,
        "temperature": 0,
        "text": " You could read through the documentation.",
        "tokens": [
          51214,
          509,
          727,
          1401,
          807,
          264,
          14333,
          13,
          51279
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 249.39999999999998,
        "id": 105,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 248.22,
        "temperature": 0,
        "text": " You could find an example.",
        "tokens": [
          51279,
          509,
          727,
          915,
          364,
          1365,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 251.35999999999999,
        "id": 106,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 249.39999999999998,
        "temperature": 0,
        "text": " For me, this getting started example",
        "tokens": [
          51338,
          1171,
          385,
          11,
          341,
          1242,
          1409,
          1365,
          51436
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 252.92,
        "id": 107,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 251.35999999999999,
        "temperature": 0,
        "text": " is going to be perfect to work with.",
        "tokens": [
          51436,
          307,
          516,
          281,
          312,
          2176,
          281,
          589,
          365,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 254.23999999999998,
        "id": 108,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 252.92,
        "temperature": 0,
        "text": " So I'm just going to take this.",
        "tokens": [
          51514,
          407,
          286,
          478,
          445,
          516,
          281,
          747,
          341,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.23070144653320312,
        "compression_ratio": 1.7758007117437722,
        "end": 255.88,
        "id": 109,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 22992,
        "start": 254.23999999999998,
        "temperature": 0,
        "text": " I'm going to copy it.",
        "tokens": [
          51580,
          286,
          478,
          516,
          281,
          5055,
          309,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 259.92,
        "id": 110,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 255.88,
        "temperature": 0,
        "text": " And I'm going to paste it here at the top of my scripts tag.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          9163,
          309,
          510,
          412,
          264,
          1192,
          295,
          452,
          23294,
          6162,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 261.2,
        "id": 111,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 259.92,
        "temperature": 0,
        "text": " OK, so there it is.",
        "tokens": [
          50566,
          2264,
          11,
          370,
          456,
          309,
          307,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 267.64,
        "id": 112,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 261.2,
        "temperature": 0,
        "text": " So in theory, when I refresh the page, I should see a chart.",
        "tokens": [
          50630,
          407,
          294,
          5261,
          11,
          562,
          286,
          15134,
          264,
          3028,
          11,
          286,
          820,
          536,
          257,
          6927,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 269.6,
        "id": 113,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 267.64,
        "temperature": 0,
        "text": " No, no, what happened?",
        "tokens": [
          50952,
          883,
          11,
          572,
          11,
          437,
          2011,
          30,
          51050
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 271.8,
        "id": 114,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 269.6,
        "temperature": 0,
        "text": " So we've now encountered something",
        "tokens": [
          51050,
          407,
          321,
          600,
          586,
          20381,
          746,
          51160
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 275.12,
        "id": 115,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 271.8,
        "temperature": 0,
        "text": " that has to do with the asynchronous events that",
        "tokens": [
          51160,
          300,
          575,
          281,
          360,
          365,
          264,
          49174,
          3931,
          300,
          51326
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 276.92,
        "id": 116,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 275.12,
        "temperature": 0,
        "text": " happen when you load a web page.",
        "tokens": [
          51326,
          1051,
          562,
          291,
          3677,
          257,
          3670,
          3028,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 279.71999999999997,
        "id": 117,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 276.92,
        "temperature": 0,
        "text": " So it's saying, cannot read property get context",
        "tokens": [
          51416,
          407,
          309,
          311,
          1566,
          11,
          2644,
          1401,
          4707,
          483,
          4319,
          51556
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 282.15999999999997,
        "id": 118,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 279.71999999999997,
        "temperature": 0,
        "text": " of null at index 13.",
        "tokens": [
          51556,
          295,
          18184,
          412,
          8186,
          3705,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 284.08,
        "id": 119,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 282.15999999999997,
        "temperature": 0,
        "text": " Let's go to index line 13.",
        "tokens": [
          51678,
          961,
          311,
          352,
          281,
          8186,
          1622,
          3705,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.23264097198238218,
        "compression_ratio": 1.546875,
        "end": 285.48,
        "id": 120,
        "no_speech_prob": 0.00012931544915772974,
        "seek": 25588,
        "start": 284.08,
        "temperature": 0,
        "text": " Document, oh, OK.",
        "tokens": [
          51774,
          37684,
          11,
          1954,
          11,
          2264,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 287.12,
        "id": 121,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 285.48,
        "temperature": 0,
        "text": " Actually, this is a different problem.",
        "tokens": [
          50364,
          5135,
          11,
          341,
          307,
          257,
          819,
          1154,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 289.76,
        "id": 122,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 287.12,
        "temperature": 0,
        "text": " I didn't name my canvas my chart.",
        "tokens": [
          50446,
          286,
          994,
          380,
          1315,
          452,
          16267,
          452,
          6927,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 290.84000000000003,
        "id": 123,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 289.76,
        "temperature": 0,
        "text": " I named it chart.",
        "tokens": [
          50578,
          286,
          4926,
          309,
          6927,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 293.52000000000004,
        "id": 124,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 290.84000000000003,
        "temperature": 0,
        "text": " So let's see if this fixes the error.",
        "tokens": [
          50632,
          407,
          718,
          311,
          536,
          498,
          341,
          32539,
          264,
          6713,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 295.84000000000003,
        "id": 125,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 293.52000000000004,
        "temperature": 0,
        "text": " There is a different error that I thought was happening.",
        "tokens": [
          50766,
          821,
          307,
          257,
          819,
          6713,
          300,
          286,
          1194,
          390,
          2737,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 297.12,
        "id": 126,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 295.84000000000003,
        "temperature": 0,
        "text": " But this is clearly an error.",
        "tokens": [
          50882,
          583,
          341,
          307,
          4448,
          364,
          6713,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 300.52000000000004,
        "id": 127,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 297.12,
        "temperature": 0,
        "text": " The ID of my chart is just chart, not my chart.",
        "tokens": [
          50946,
          440,
          7348,
          295,
          452,
          6927,
          307,
          445,
          6927,
          11,
          406,
          452,
          6927,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 301.96000000000004,
        "id": 128,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 300.52000000000004,
        "temperature": 0,
        "text": " Oh, there it is.",
        "tokens": [
          51116,
          876,
          11,
          456,
          309,
          307,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 303.40000000000003,
        "id": 129,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 301.96000000000004,
        "temperature": 0,
        "text": " So look, there's the chart.",
        "tokens": [
          51188,
          407,
          574,
          11,
          456,
          311,
          264,
          6927,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 304.84000000000003,
        "id": 130,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 303.40000000000003,
        "temperature": 0,
        "text": " Beautiful.",
        "tokens": [
          51260,
          14724,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 307.56,
        "id": 131,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 304.84000000000003,
        "temperature": 0,
        "text": " So I have this chart.",
        "tokens": [
          51332,
          407,
          286,
          362,
          341,
          6927,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 309.74,
        "id": 132,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 307.56,
        "temperature": 0,
        "text": " It's counting votes for different colors.",
        "tokens": [
          51468,
          467,
          311,
          13251,
          12068,
          337,
          819,
          4577,
          13,
          51577
        ]
      },
      {
        "avg_logprob": -0.2192361831665039,
        "compression_ratio": 1.8174273858921162,
        "end": 313.20000000000005,
        "id": 133,
        "no_speech_prob": 0.000009516245881968644,
        "seek": 28548,
        "start": 309.74,
        "temperature": 0,
        "text": " It's got a scale on the y-axis, a scale on the x-axis.",
        "tokens": [
          51577,
          467,
          311,
          658,
          257,
          4373,
          322,
          264,
          288,
          12,
          24633,
          11,
          257,
          4373,
          322,
          264,
          2031,
          12,
          24633,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 315.65999999999997,
        "id": 134,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 313.2,
        "temperature": 0,
        "text": " And I see my data console logged.",
        "tokens": [
          50364,
          400,
          286,
          536,
          452,
          1412,
          11076,
          27231,
          13,
          50487
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 318.52,
        "id": 135,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 315.65999999999997,
        "temperature": 0,
        "text": " How do I get my data onto the chart?",
        "tokens": [
          50487,
          1012,
          360,
          286,
          483,
          452,
          1412,
          3911,
          264,
          6927,
          30,
          50630
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 320.02,
        "id": 136,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 318.52,
        "temperature": 0,
        "text": " Well, let's look at the code and see",
        "tokens": [
          50630,
          1042,
          11,
          718,
          311,
          574,
          412,
          264,
          3089,
          293,
          536,
          50705
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 322.71999999999997,
        "id": 137,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 320.02,
        "temperature": 0,
        "text": " if we can just do some detective work and figure it out.",
        "tokens": [
          50705,
          498,
          321,
          393,
          445,
          360,
          512,
          25571,
          589,
          293,
          2573,
          309,
          484,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 325.12,
        "id": 138,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 322.71999999999997,
        "temperature": 0,
        "text": " And if we get stuck, we can refer to the chart.js",
        "tokens": [
          50840,
          400,
          498,
          321,
          483,
          5541,
          11,
          321,
          393,
          2864,
          281,
          264,
          6927,
          13,
          25530,
          50960
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 327.48,
        "id": 139,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 325.12,
        "temperature": 0,
        "text": " documentation.",
        "tokens": [
          50960,
          14333,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 328.94,
        "id": 140,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 327.48,
        "temperature": 0,
        "text": " So we can see here label.",
        "tokens": [
          51078,
          407,
          321,
          393,
          536,
          510,
          7645,
          13,
          51151
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 337.36,
        "id": 141,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 328.94,
        "temperature": 0,
        "text": " Well, the label that I want is global average temperature.",
        "tokens": [
          51151,
          1042,
          11,
          264,
          7645,
          300,
          286,
          528,
          307,
          4338,
          4274,
          4292,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 340.2,
        "id": 142,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 337.36,
        "temperature": 0,
        "text": " And again, I might need to be a bit more",
        "tokens": [
          51572,
          400,
          797,
          11,
          286,
          1062,
          643,
          281,
          312,
          257,
          857,
          544,
          51714
        ]
      },
      {
        "avg_logprob": -0.24207731393667367,
        "compression_ratio": 1.6422764227642277,
        "end": 342.28,
        "id": 143,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 31320,
        "start": 340.2,
        "temperature": 0,
        "text": " thoughtful about the accuracy of that statement.",
        "tokens": [
          51714,
          21566,
          466,
          264,
          14170,
          295,
          300,
          5629,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 346,
        "id": 144,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 342.32,
        "temperature": 0,
        "text": " What is it truly if I look at the NASA data set?",
        "tokens": [
          50366,
          708,
          307,
          309,
          4908,
          498,
          286,
          574,
          412,
          264,
          12077,
          1412,
          992,
          30,
          50550
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 348.03999999999996,
        "id": 145,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 346,
        "temperature": 0,
        "text": " But global average temperature will do for now.",
        "tokens": [
          50550,
          583,
          4338,
          4274,
          4292,
          486,
          360,
          337,
          586,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 349.35999999999996,
        "id": 146,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 348.03999999999996,
        "temperature": 0,
        "text": " So let's just change that.",
        "tokens": [
          50652,
          407,
          718,
          311,
          445,
          1319,
          300,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 350.96,
        "id": 147,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 349.35999999999996,
        "temperature": 0,
        "text": " And we can see, look, it's showing us",
        "tokens": [
          50718,
          400,
          321,
          393,
          536,
          11,
          574,
          11,
          309,
          311,
          4099,
          505,
          50798
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 352.71999999999997,
        "id": 148,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 350.96,
        "temperature": 0,
        "text": " the global average temperature.",
        "tokens": [
          50798,
          264,
          4338,
          4274,
          4292,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 355.32,
        "id": 149,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 352.71999999999997,
        "temperature": 0,
        "text": " Oh, but these labels, red, blue, yellow,",
        "tokens": [
          50886,
          876,
          11,
          457,
          613,
          16949,
          11,
          2182,
          11,
          3344,
          11,
          5566,
          11,
          51016
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 357.32,
        "id": 150,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 355.32,
        "temperature": 0,
        "text": " where did those come from?",
        "tokens": [
          51016,
          689,
          630,
          729,
          808,
          490,
          30,
          51116
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 360.88,
        "id": 151,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 357.32,
        "temperature": 0,
        "text": " Those are here labels.",
        "tokens": [
          51116,
          3950,
          366,
          510,
          16949,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 363.64,
        "id": 152,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 360.88,
        "temperature": 0,
        "text": " So I don't want these labels.",
        "tokens": [
          51294,
          407,
          286,
          500,
          380,
          528,
          613,
          16949,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 369,
        "id": 153,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 363.64,
        "temperature": 0,
        "text": " What I want are the years to be the labels, the years",
        "tokens": [
          51432,
          708,
          286,
          528,
          366,
          264,
          924,
          281,
          312,
          264,
          16949,
          11,
          264,
          924,
          51700
        ]
      },
      {
        "avg_logprob": -0.21681278507883955,
        "compression_ratio": 1.7245762711864407,
        "end": 370.59999999999997,
        "id": 154,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 34228,
        "start": 369,
        "temperature": 0,
        "text": " that I'm parsing to be the labels that",
        "tokens": [
          51700,
          300,
          286,
          478,
          21156,
          278,
          281,
          312,
          264,
          16949,
          300,
          51780
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 372.48,
        "id": 155,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 370.6,
        "temperature": 0,
        "text": " go across the x-axis.",
        "tokens": [
          50364,
          352,
          2108,
          264,
          2031,
          12,
          24633,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 375.88,
        "id": 156,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 372.48,
        "temperature": 0,
        "text": " So what if I were to say, first of all,",
        "tokens": [
          50458,
          407,
          437,
          498,
          286,
          645,
          281,
          584,
          11,
          700,
          295,
          439,
          11,
          50628
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 379.28000000000003,
        "id": 157,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 375.88,
        "temperature": 0,
        "text": " this example is using older JavaScript syntax.",
        "tokens": [
          50628,
          341,
          1365,
          307,
          1228,
          4906,
          15778,
          28431,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 380.6,
        "id": 158,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 379.28000000000003,
        "temperature": 0,
        "text": " By the time you're watching this,",
        "tokens": [
          50798,
          3146,
          264,
          565,
          291,
          434,
          1976,
          341,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 382.02000000000004,
        "id": 159,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 380.6,
        "temperature": 0,
        "text": " it's probably something different.",
        "tokens": [
          50864,
          309,
          311,
          1391,
          746,
          819,
          13,
          50935
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 384.84000000000003,
        "id": 160,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 382.02000000000004,
        "temperature": 0,
        "text": " But I'm going to say const instead of var.",
        "tokens": [
          50935,
          583,
          286,
          478,
          516,
          281,
          584,
          1817,
          2602,
          295,
          1374,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 387.92,
        "id": 161,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 384.84000000000003,
        "temperature": 0,
        "text": " And I'm going to say const here instead of var,",
        "tokens": [
          51076,
          400,
          286,
          478,
          516,
          281,
          584,
          1817,
          510,
          2602,
          295,
          1374,
          11,
          51230
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 390.16,
        "id": 162,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 387.92,
        "temperature": 0,
        "text": " just to update my variable declarations.",
        "tokens": [
          51230,
          445,
          281,
          5623,
          452,
          7006,
          16694,
          763,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 391.84000000000003,
        "id": 163,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 390.16,
        "temperature": 0,
        "text": " If you're wondering what const is, I have",
        "tokens": [
          51342,
          759,
          291,
          434,
          6359,
          437,
          1817,
          307,
          11,
          286,
          362,
          51426
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 393.88,
        "id": 164,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 391.84000000000003,
        "temperature": 0,
        "text": " some other videos about that.",
        "tokens": [
          51426,
          512,
          661,
          2145,
          466,
          300,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 396.76000000000005,
        "id": 165,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 393.88,
        "temperature": 0,
        "text": " Then I am going to create another variable that's",
        "tokens": [
          51528,
          1396,
          286,
          669,
          516,
          281,
          1884,
          1071,
          7006,
          300,
          311,
          51672
        ]
      },
      {
        "avg_logprob": -0.2683967813088076,
        "compression_ratio": 1.750915750915751,
        "end": 400.56,
        "id": 166,
        "no_speech_prob": 0.0009547275258228183,
        "seek": 37060,
        "start": 396.76000000000005,
        "temperature": 0,
        "text": " just going to call it x labels for the x-axis.",
        "tokens": [
          51672,
          445,
          516,
          281,
          818,
          309,
          2031,
          16949,
          337,
          264,
          2031,
          12,
          24633,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 403.72,
        "id": 167,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 400.56,
        "temperature": 0,
        "text": " And set it equal to a blank array.",
        "tokens": [
          50364,
          400,
          992,
          309,
          2681,
          281,
          257,
          8247,
          10225,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 410.72,
        "id": 168,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 403.72,
        "temperature": 0,
        "text": " And I'm going to put that variable referenced here.",
        "tokens": [
          50522,
          400,
          286,
          478,
          516,
          281,
          829,
          300,
          7006,
          32734,
          510,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 414.24,
        "id": 169,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 410.72,
        "temperature": 0,
        "text": " So the actual labels of my chart are pointing",
        "tokens": [
          50872,
          407,
          264,
          3539,
          16949,
          295,
          452,
          6927,
          366,
          12166,
          51048
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 416.76,
        "id": 170,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 414.24,
        "temperature": 0,
        "text": " to an array called x labels.",
        "tokens": [
          51048,
          281,
          364,
          10225,
          1219,
          2031,
          16949,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 418.36,
        "id": 171,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 416.76,
        "temperature": 0,
        "text": " And there's no reason why I couldn't,",
        "tokens": [
          51174,
          400,
          456,
          311,
          572,
          1778,
          983,
          286,
          2809,
          380,
          11,
          51254
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 424.76,
        "id": 172,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 418.36,
        "temperature": 0,
        "text": " as I'm reading each year, just add each year",
        "tokens": [
          51254,
          382,
          286,
          478,
          3760,
          1184,
          1064,
          11,
          445,
          909,
          1184,
          1064,
          51574
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 426.72,
        "id": 173,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 424.76,
        "temperature": 0,
        "text": " to that array x labels.",
        "tokens": [
          51574,
          281,
          300,
          10225,
          2031,
          16949,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 428.64,
        "id": 174,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 426.72,
        "temperature": 0,
        "text": " So now I have my data parsing.",
        "tokens": [
          51672,
          407,
          586,
          286,
          362,
          452,
          1412,
          21156,
          278,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.18587019005600286,
        "compression_ratio": 1.6331658291457287,
        "end": 430.52,
        "id": 175,
        "no_speech_prob": 0.000050644655857468024,
        "seek": 40056,
        "start": 428.64,
        "temperature": 0,
        "text": " I have my chart creation.",
        "tokens": [
          51768,
          286,
          362,
          452,
          6927,
          8016,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 433.4,
        "id": 176,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 431.47999999999996,
        "temperature": 0,
        "text": " So what I want to do is parse all the data",
        "tokens": [
          50412,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          48377,
          439,
          264,
          1412,
          50508
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 436.35999999999996,
        "id": 177,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 433.4,
        "temperature": 0,
        "text": " and start adding the labels to the chart that's",
        "tokens": [
          50508,
          293,
          722,
          5127,
          264,
          16949,
          281,
          264,
          6927,
          300,
          311,
          50656
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 437.47999999999996,
        "id": 178,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 436.35999999999996,
        "temperature": 0,
        "text": " being drawn on the canvas.",
        "tokens": [
          50656,
          885,
          10117,
          322,
          264,
          16267,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 440.68,
        "id": 179,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 437.47999999999996,
        "temperature": 0,
        "text": " Let's see what happens there.",
        "tokens": [
          50712,
          961,
          311,
          536,
          437,
          2314,
          456,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 441.32,
        "id": 180,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 440.68,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50872,
          2264,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 443.56,
        "id": 181,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 441.32,
        "temperature": 0,
        "text": " Don't see any labels.",
        "tokens": [
          50904,
          1468,
          380,
          536,
          604,
          16949,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 445.26,
        "id": 182,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 443.56,
        "temperature": 0,
        "text": " Now I have the other problem that I",
        "tokens": [
          51016,
          823,
          286,
          362,
          264,
          661,
          1154,
          300,
          286,
          51101
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 450.32,
        "id": 183,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 445.26,
        "temperature": 0,
        "text": " was thinking would happen, which is I am making the chart first",
        "tokens": [
          51101,
          390,
          1953,
          576,
          1051,
          11,
          597,
          307,
          286,
          669,
          1455,
          264,
          6927,
          700,
          51354
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 452.64,
        "id": 184,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 450.32,
        "temperature": 0,
        "text": " and then loading the data.",
        "tokens": [
          51354,
          293,
          550,
          15114,
          264,
          1412,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 453.91999999999996,
        "id": 185,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 452.64,
        "temperature": 0,
        "text": " So this is a problem.",
        "tokens": [
          51470,
          407,
          341,
          307,
          257,
          1154,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 456.91999999999996,
        "id": 186,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 453.91999999999996,
        "temperature": 0,
        "text": " Weirdly, by the way, if I just kind of like resize the window,",
        "tokens": [
          51534,
          32033,
          356,
          11,
          538,
          264,
          636,
          11,
          498,
          286,
          445,
          733,
          295,
          411,
          50069,
          264,
          4910,
          11,
          51684
        ]
      },
      {
        "avg_logprob": -0.2659821119464812,
        "compression_ratio": 1.648,
        "end": 458.15999999999997,
        "id": 187,
        "no_speech_prob": 0.000021782627300126478,
        "seek": 43052,
        "start": 456.91999999999996,
        "temperature": 0,
        "text": " suddenly the data appears.",
        "tokens": [
          51684,
          5800,
          264,
          1412,
          7038,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.24545126869564965,
        "compression_ratio": 1.5416666666666667,
        "end": 464.88,
        "id": 188,
        "no_speech_prob": 0.00003426843250053935,
        "seek": 46052,
        "start": 460.68,
        "temperature": 0,
        "text": " But it should appear when I first load the page.",
        "tokens": [
          50372,
          583,
          309,
          820,
          4204,
          562,
          286,
          700,
          3677,
          264,
          3028,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.24545126869564965,
        "compression_ratio": 1.5416666666666667,
        "end": 467.41999999999996,
        "id": 189,
        "no_speech_prob": 0.00003426843250053935,
        "seek": 46052,
        "start": 464.88,
        "temperature": 0,
        "text": " So I've got to do this in a different order.",
        "tokens": [
          50582,
          407,
          286,
          600,
          658,
          281,
          360,
          341,
          294,
          257,
          819,
          1668,
          13,
          50709
        ]
      },
      {
        "avg_logprob": -0.24545126869564965,
        "compression_ratio": 1.5416666666666667,
        "end": 470,
        "id": 190,
        "no_speech_prob": 0.00003426843250053935,
        "seek": 46052,
        "start": 467.41999999999996,
        "temperature": 0,
        "text": " I have this get data function that",
        "tokens": [
          50709,
          286,
          362,
          341,
          483,
          1412,
          2445,
          300,
          50838
        ]
      },
      {
        "avg_logprob": -0.24545126869564965,
        "compression_ratio": 1.5416666666666667,
        "end": 474.35999999999996,
        "id": 191,
        "no_speech_prob": 0.00003426843250053935,
        "seek": 46052,
        "start": 470,
        "temperature": 0,
        "text": " gets the data asynchronously using await fetch,",
        "tokens": [
          50838,
          2170,
          264,
          1412,
          42642,
          5098,
          1228,
          19670,
          23673,
          11,
          51056
        ]
      },
      {
        "avg_logprob": -0.24545126869564965,
        "compression_ratio": 1.5416666666666667,
        "end": 476.59999999999997,
        "id": 192,
        "no_speech_prob": 0.00003426843250053935,
        "seek": 46052,
        "start": 474.35999999999996,
        "temperature": 0,
        "text": " await response.text.",
        "tokens": [
          51056,
          19670,
          4134,
          13,
          25111,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.24545126869564965,
        "compression_ratio": 1.5416666666666667,
        "end": 478.68,
        "id": 193,
        "no_speech_prob": 0.00003426843250053935,
        "seek": 46052,
        "start": 476.59999999999997,
        "temperature": 0,
        "text": " What I want to do now, then, is go up",
        "tokens": [
          51168,
          708,
          286,
          528,
          281,
          360,
          586,
          11,
          550,
          11,
          307,
          352,
          493,
          51272
        ]
      },
      {
        "avg_logprob": -0.24545126869564965,
        "compression_ratio": 1.5416666666666667,
        "end": 485.71999999999997,
        "id": 194,
        "no_speech_prob": 0.00003426843250053935,
        "seek": 46052,
        "start": 478.68,
        "temperature": 0,
        "text": " and put this creation of the chart into a separate function.",
        "tokens": [
          51272,
          293,
          829,
          341,
          8016,
          295,
          264,
          6927,
          666,
          257,
          4994,
          2445,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 491.56,
        "id": 195,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 485.72,
        "temperature": 0,
        "text": " So I'm going to say function chart it.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          584,
          2445,
          6927,
          309,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 494.6,
        "id": 196,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 491.56,
        "temperature": 0,
        "text": " And all of that's going to be in a function.",
        "tokens": [
          50656,
          400,
          439,
          295,
          300,
          311,
          516,
          281,
          312,
          294,
          257,
          2445,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 498.68,
        "id": 197,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 494.6,
        "temperature": 0,
        "text": " Now, this example that was provided on the chart.js",
        "tokens": [
          50808,
          823,
          11,
          341,
          1365,
          300,
          390,
          5649,
          322,
          264,
          6927,
          13,
          25530,
          51012
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 501.48,
        "id": 198,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 498.68,
        "temperature": 0,
        "text": " getting started page has a lot of really useful,",
        "tokens": [
          51012,
          1242,
          1409,
          3028,
          575,
          257,
          688,
          295,
          534,
          4420,
          11,
          51152
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 504.08000000000004,
        "id": 199,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 501.48,
        "temperature": 0,
        "text": " but for me right now, extra stuff in it.",
        "tokens": [
          51152,
          457,
          337,
          385,
          558,
          586,
          11,
          2857,
          1507,
          294,
          309,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 506.82000000000005,
        "id": 200,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 504.08000000000004,
        "temperature": 0,
        "text": " So there are a lot of configuration options,",
        "tokens": [
          51282,
          407,
          456,
          366,
          257,
          688,
          295,
          11694,
          3956,
          11,
          51419
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 509.20000000000005,
        "id": 201,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 506.82000000000005,
        "temperature": 0,
        "text": " how you can have the chart appear.",
        "tokens": [
          51419,
          577,
          291,
          393,
          362,
          264,
          6927,
          4204,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 511.48,
        "id": 202,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 509.20000000000005,
        "temperature": 0,
        "text": " I'm actually going to just remove those right now.",
        "tokens": [
          51538,
          286,
          478,
          767,
          516,
          281,
          445,
          4159,
          729,
          558,
          586,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.20188212187393853,
        "compression_ratio": 1.6585365853658536,
        "end": 513.9200000000001,
        "id": 203,
        "no_speech_prob": 0.00003883107638102956,
        "seek": 48572,
        "start": 511.48,
        "temperature": 0,
        "text": " As an exercise for you that I'll suggest at the end",
        "tokens": [
          51652,
          1018,
          364,
          5380,
          337,
          291,
          300,
          286,
          603,
          3402,
          412,
          264,
          917,
          51774
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 516.1999999999999,
        "id": 204,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 513.92,
        "temperature": 0,
        "text": " is maybe find different ways of drawing the chart",
        "tokens": [
          50364,
          307,
          1310,
          915,
          819,
          2098,
          295,
          6316,
          264,
          6927,
          50478
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 518.1999999999999,
        "id": 205,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 516.1999999999999,
        "temperature": 0,
        "text": " by looking up in the documentation.",
        "tokens": [
          50478,
          538,
          1237,
          493,
          294,
          264,
          14333,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 521.4799999999999,
        "id": 206,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 518.1999999999999,
        "temperature": 0,
        "text": " And then also, I'm just going to stick with one color.",
        "tokens": [
          50578,
          400,
          550,
          611,
          11,
          286,
          478,
          445,
          516,
          281,
          2897,
          365,
          472,
          2017,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 524.7199999999999,
        "id": 207,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 521.4799999999999,
        "temperature": 0,
        "text": " So I'm going to take all of that out right now.",
        "tokens": [
          50742,
          407,
          286,
          478,
          516,
          281,
          747,
          439,
          295,
          300,
          484,
          558,
          586,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 526.64,
        "id": 208,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 524.7199999999999,
        "temperature": 0,
        "text": " I probably could take out the color entirely.",
        "tokens": [
          50904,
          286,
          1391,
          727,
          747,
          484,
          264,
          2017,
          7696,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 527.56,
        "id": 209,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 526.64,
        "temperature": 0,
        "text": " I'm going to hit Save.",
        "tokens": [
          51000,
          286,
          478,
          516,
          281,
          2045,
          15541,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 530.36,
        "id": 210,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 527.56,
        "temperature": 0,
        "text": " So you can see at least now in my charted function,",
        "tokens": [
          51046,
          407,
          291,
          393,
          536,
          412,
          1935,
          586,
          294,
          452,
          6927,
          292,
          2445,
          11,
          51186
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 533,
        "id": 211,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 530.36,
        "temperature": 0,
        "text": " there's a little bit less stuff going on.",
        "tokens": [
          51186,
          456,
          311,
          257,
          707,
          857,
          1570,
          1507,
          516,
          322,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 536,
        "id": 212,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 533,
        "temperature": 0,
        "text": " So now I could call this charted function.",
        "tokens": [
          51318,
          407,
          586,
          286,
          727,
          818,
          341,
          6927,
          292,
          2445,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 537.92,
        "id": 213,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 536,
        "temperature": 0,
        "text": " And if we go back, this is the same thing.",
        "tokens": [
          51468,
          400,
          498,
          321,
          352,
          646,
          11,
          341,
          307,
          264,
          912,
          551,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 539.36,
        "id": 214,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 537.92,
        "temperature": 0,
        "text": " I've got the same problem.",
        "tokens": [
          51564,
          286,
          600,
          658,
          264,
          912,
          1154,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.22513290300761182,
        "compression_ratio": 1.7377622377622377,
        "end": 541.64,
        "id": 215,
        "no_speech_prob": 0.0002453688648529351,
        "seek": 51392,
        "start": 539.36,
        "temperature": 0,
        "text": " But oh, x labels is not defined.",
        "tokens": [
          51636,
          583,
          1954,
          11,
          2031,
          16949,
          307,
          406,
          7642,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 544.68,
        "id": 216,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 541.64,
        "temperature": 0,
        "text": " So I somehow, oh, the x labels variable",
        "tokens": [
          50364,
          407,
          286,
          6063,
          11,
          1954,
          11,
          264,
          2031,
          16949,
          7006,
          50516
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 546,
        "id": 217,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 544.68,
        "temperature": 0,
        "text": " needs to be a global variable.",
        "tokens": [
          50516,
          2203,
          281,
          312,
          257,
          4338,
          7006,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 548.38,
        "id": 218,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 546,
        "temperature": 0,
        "text": " I actually don't like something about what I'm doing here.",
        "tokens": [
          50582,
          286,
          767,
          500,
          380,
          411,
          746,
          466,
          437,
          286,
          478,
          884,
          510,
          13,
          50701
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 550.68,
        "id": 219,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 548.38,
        "temperature": 0,
        "text": " So I'm going to do some refactoring as we get to the end",
        "tokens": [
          50701,
          407,
          286,
          478,
          516,
          281,
          360,
          512,
          1895,
          578,
          3662,
          382,
          321,
          483,
          281,
          264,
          917,
          50816
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 553.64,
        "id": 220,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 550.68,
        "temperature": 0,
        "text": " to clean up how I'm going to communicate",
        "tokens": [
          50816,
          281,
          2541,
          493,
          577,
          286,
          478,
          516,
          281,
          7890,
          50964
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 556,
        "id": 221,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 553.64,
        "temperature": 0,
        "text": " between getting the data and drawing the chart.",
        "tokens": [
          50964,
          1296,
          1242,
          264,
          1412,
          293,
          6316,
          264,
          6927,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 558.72,
        "id": 222,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 556,
        "temperature": 0,
        "text": " But for right now, I'm going to make x labels a global",
        "tokens": [
          51082,
          583,
          337,
          558,
          586,
          11,
          286,
          478,
          516,
          281,
          652,
          2031,
          16949,
          257,
          4338,
          51218
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 560.04,
        "id": 223,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 558.72,
        "temperature": 0,
        "text": " variable.",
        "tokens": [
          51218,
          7006,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 562.4,
        "id": 224,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 560.04,
        "temperature": 0,
        "text": " I'm going to call the charted function",
        "tokens": [
          51284,
          286,
          478,
          516,
          281,
          818,
          264,
          6927,
          292,
          2445,
          51402
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 568.8,
        "id": 225,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 562.4,
        "temperature": 0,
        "text": " and call the get data function.",
        "tokens": [
          51402,
          293,
          818,
          264,
          483,
          1412,
          2445,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.22140982055664063,
        "compression_ratio": 1.8669527896995708,
        "end": 570.08,
        "id": 226,
        "no_speech_prob": 0.000022827960492577404,
        "seek": 54164,
        "start": 568.8,
        "temperature": 0,
        "text": " Still the same problem.",
        "tokens": [
          51722,
          8291,
          264,
          912,
          1154,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 572.76,
        "id": 227,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 570.08,
        "temperature": 0,
        "text": " Well, you would think, OK, what if I call",
        "tokens": [
          50364,
          1042,
          11,
          291,
          576,
          519,
          11,
          2264,
          11,
          437,
          498,
          286,
          818,
          50498
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 575.8000000000001,
        "id": 228,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 572.76,
        "temperature": 0,
        "text": " get data before charted?",
        "tokens": [
          50498,
          483,
          1412,
          949,
          6927,
          292,
          30,
          50650
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 577.88,
        "id": 229,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 575.8000000000001,
        "temperature": 0,
        "text": " Still the same problem because remember, get data",
        "tokens": [
          50650,
          8291,
          264,
          912,
          1154,
          570,
          1604,
          11,
          483,
          1412,
          50754
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 579.08,
        "id": 230,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 577.88,
        "temperature": 0,
        "text": " is asynchronous.",
        "tokens": [
          50754,
          307,
          49174,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 581,
        "id": 231,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 579.08,
        "temperature": 0,
        "text": " So the solution that I want to employ here",
        "tokens": [
          50814,
          407,
          264,
          3827,
          300,
          286,
          528,
          281,
          3188,
          510,
          50910
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 583.88,
        "id": 232,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 581,
        "temperature": 0,
        "text": " is make charted an asynchronous function",
        "tokens": [
          50910,
          307,
          652,
          6927,
          292,
          364,
          49174,
          2445,
          51054
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 587.48,
        "id": 233,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 583.88,
        "temperature": 0,
        "text": " and then actually call get data at the beginning of it.",
        "tokens": [
          51054,
          293,
          550,
          767,
          818,
          483,
          1412,
          412,
          264,
          2863,
          295,
          309,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 591.5200000000001,
        "id": 234,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 587.48,
        "temperature": 0,
        "text": " So if I say await get data, now charted",
        "tokens": [
          51234,
          407,
          498,
          286,
          584,
          19670,
          483,
          1412,
          11,
          586,
          6927,
          292,
          51436
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 593.72,
        "id": 235,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 591.5200000000001,
        "temperature": 0,
        "text": " is going to wait till the data is done before it",
        "tokens": [
          51436,
          307,
          516,
          281,
          1699,
          4288,
          264,
          1412,
          307,
          1096,
          949,
          309,
          51546
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 595.24,
        "id": 236,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 593.72,
        "temperature": 0,
        "text": " does the rest of this stuff.",
        "tokens": [
          51546,
          775,
          264,
          1472,
          295,
          341,
          1507,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 597.2800000000001,
        "id": 237,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 595.24,
        "temperature": 0,
        "text": " And if we go back, we can see, there we go.",
        "tokens": [
          51622,
          400,
          498,
          321,
          352,
          646,
          11,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.22501949672281307,
        "compression_ratio": 1.75,
        "end": 600,
        "id": 238,
        "no_speech_prob": 0.00013765440962743014,
        "seek": 57008,
        "start": 597.2800000000001,
        "temperature": 0,
        "text": " You can see all those labels are applied there.",
        "tokens": [
          51724,
          509,
          393,
          536,
          439,
          729,
          16949,
          366,
          6456,
          456,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.20867865136329164,
        "compression_ratio": 1.684782608695652,
        "end": 602.24,
        "id": 239,
        "no_speech_prob": 0.000014064034076000098,
        "seek": 60000,
        "start": 600,
        "temperature": 0,
        "text": " Now, this is not real data.",
        "tokens": [
          50364,
          823,
          11,
          341,
          307,
          406,
          957,
          1412,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.20867865136329164,
        "compression_ratio": 1.684782608695652,
        "end": 606.36,
        "id": 240,
        "no_speech_prob": 0.000014064034076000098,
        "seek": 60000,
        "start": 602.24,
        "temperature": 0,
        "text": " This is still the data that's right here.",
        "tokens": [
          50476,
          639,
          307,
          920,
          264,
          1412,
          300,
          311,
          558,
          510,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.20867865136329164,
        "compression_ratio": 1.684782608695652,
        "end": 610.48,
        "id": 241,
        "no_speech_prob": 0.000014064034076000098,
        "seek": 60000,
        "start": 606.36,
        "temperature": 0,
        "text": " So what I want to do now is let me do constant y temps.",
        "tokens": [
          50682,
          407,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          718,
          385,
          360,
          5754,
          288,
          8827,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.20867865136329164,
        "compression_ratio": 1.684782608695652,
        "end": 613.24,
        "id": 242,
        "no_speech_prob": 0.000014064034076000098,
        "seek": 60000,
        "start": 610.48,
        "temperature": 0,
        "text": " So this is the temperatures for the y-axis.",
        "tokens": [
          50888,
          407,
          341,
          307,
          264,
          12633,
          337,
          264,
          288,
          12,
          24633,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.20867865136329164,
        "compression_ratio": 1.684782608695652,
        "end": 618.76,
        "id": 243,
        "no_speech_prob": 0.000014064034076000098,
        "seek": 60000,
        "start": 613.24,
        "temperature": 0,
        "text": " And then I'm going to say under data,",
        "tokens": [
          51026,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          833,
          1412,
          11,
          51302
        ]
      },
      {
        "avg_logprob": -0.20867865136329164,
        "compression_ratio": 1.684782608695652,
        "end": 623.32,
        "id": 244,
        "no_speech_prob": 0.000014064034076000098,
        "seek": 60000,
        "start": 618.76,
        "temperature": 0,
        "text": " I'm going to say y temps instead of that dummy data.",
        "tokens": [
          51302,
          286,
          478,
          516,
          281,
          584,
          288,
          8827,
          2602,
          295,
          300,
          35064,
          1412,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.20867865136329164,
        "compression_ratio": 1.684782608695652,
        "end": 626.1,
        "id": 245,
        "no_speech_prob": 0.000014064034076000098,
        "seek": 60000,
        "start": 623.32,
        "temperature": 0,
        "text": " And then here, when I'm reading each temperature,",
        "tokens": [
          51530,
          400,
          550,
          510,
          11,
          562,
          286,
          478,
          3760,
          1184,
          4292,
          11,
          51669
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 631.66,
        "id": 246,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 626.1,
        "temperature": 0,
        "text": " I'm going to say y temps dot push temp.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          288,
          8827,
          5893,
          2944,
          18274,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 633.62,
        "id": 247,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 631.66,
        "temperature": 0,
        "text": " So now, let's take a look at this.",
        "tokens": [
          50642,
          407,
          586,
          11,
          718,
          311,
          747,
          257,
          574,
          412,
          341,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 634.74,
        "id": 248,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 633.62,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50740,
          821,
          321,
          352,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 639.98,
        "id": 249,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 634.74,
        "temperature": 0,
        "text": " Now we see the global temperature from 1880",
        "tokens": [
          50796,
          823,
          321,
          536,
          264,
          4338,
          4292,
          490,
          2443,
          4702,
          51058
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 641.1800000000001,
        "id": 250,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 639.98,
        "temperature": 0,
        "text": " all the way to 2018.",
        "tokens": [
          51058,
          439,
          264,
          636,
          281,
          6096,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 642.58,
        "id": 251,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 641.1800000000001,
        "temperature": 0,
        "text": " Now, what's going on here?",
        "tokens": [
          51118,
          823,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 644.26,
        "id": 252,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 642.58,
        "temperature": 0,
        "text": " Negative 0.20.",
        "tokens": [
          51188,
          43230,
          1958,
          13,
          2009,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 645.4200000000001,
        "id": 253,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 644.26,
        "temperature": 0,
        "text": " What are these temperatures?",
        "tokens": [
          51272,
          708,
          366,
          613,
          12633,
          30,
          51330
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 648.82,
        "id": 254,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 645.4200000000001,
        "temperature": 0,
        "text": " Remember, these are the difference",
        "tokens": [
          51330,
          5459,
          11,
          613,
          366,
          264,
          2649,
          51500
        ]
      },
      {
        "avg_logprob": -0.23211286544799806,
        "compression_ratio": 1.5192307692307692,
        "end": 653.9,
        "id": 255,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 62610,
        "start": 648.82,
        "temperature": 0,
        "text": " from the global mean between the period of 1951 and 1980.",
        "tokens": [
          51500,
          490,
          264,
          4338,
          914,
          1296,
          264,
          2896,
          295,
          10858,
          16,
          293,
          13626,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 656.8199999999999,
        "id": 256,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 653.9,
        "temperature": 0,
        "text": " And that global mean can be found on this web page.",
        "tokens": [
          50364,
          400,
          300,
          4338,
          914,
          393,
          312,
          1352,
          322,
          341,
          3670,
          3028,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 659.6999999999999,
        "id": 257,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 656.8199999999999,
        "temperature": 0,
        "text": " Here it is, 14 degrees Celsius.",
        "tokens": [
          50510,
          1692,
          309,
          307,
          11,
          3499,
          5310,
          22658,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 662.5,
        "id": 258,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 659.6999999999999,
        "temperature": 0,
        "text": " So if I wanted to be accurate about what I'm doing here,",
        "tokens": [
          50654,
          407,
          498,
          286,
          1415,
          281,
          312,
          8559,
          466,
          437,
          286,
          478,
          884,
          510,
          11,
          50794
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 668.78,
        "id": 259,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 662.5,
        "temperature": 0,
        "text": " I'm going to say I want the temperature",
        "tokens": [
          50794,
          286,
          478,
          516,
          281,
          584,
          286,
          528,
          264,
          4292,
          51108
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 671.5,
        "id": 260,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 668.78,
        "temperature": 0,
        "text": " to be temp plus 14.",
        "tokens": [
          51108,
          281,
          312,
          18274,
          1804,
          3499,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 673.06,
        "id": 261,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 671.5,
        "temperature": 0,
        "text": " I just want to add 14 Celsius.",
        "tokens": [
          51244,
          286,
          445,
          528,
          281,
          909,
          3499,
          22658,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 674.74,
        "id": 262,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 673.06,
        "temperature": 0,
        "text": " I think this is going to cause a problem.",
        "tokens": [
          51322,
          286,
          519,
          341,
          307,
          516,
          281,
          3082,
          257,
          1154,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 676.5,
        "id": 263,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 674.74,
        "temperature": 0,
        "text": " Let's see what happens here.",
        "tokens": [
          51406,
          961,
          311,
          536,
          437,
          2314,
          510,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 680.38,
        "id": 264,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 676.5,
        "temperature": 0,
        "text": " Let's go back to my graph.",
        "tokens": [
          51494,
          961,
          311,
          352,
          646,
          281,
          452,
          4295,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.1992921999522618,
        "compression_ratio": 1.5844155844155845,
        "end": 682.38,
        "id": 265,
        "no_speech_prob": 0.000016187575965886936,
        "seek": 65390,
        "start": 680.38,
        "temperature": 0,
        "text": " I don't see anything different here.",
        "tokens": [
          51688,
          286,
          500,
          380,
          536,
          1340,
          819,
          510,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 685.42,
        "id": 266,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 682.38,
        "temperature": 0,
        "text": " Push temp plus 14.",
        "tokens": [
          50364,
          18229,
          18274,
          1804,
          3499,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 689.58,
        "id": 267,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 685.42,
        "temperature": 0,
        "text": " Well, I think what's going on here, if I'm right,",
        "tokens": [
          50516,
          1042,
          11,
          286,
          519,
          437,
          311,
          516,
          322,
          510,
          11,
          498,
          286,
          478,
          558,
          11,
          50724
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 692.7,
        "id": 268,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 689.58,
        "temperature": 0,
        "text": " we'll find out in a second, is that any time you're",
        "tokens": [
          50724,
          321,
          603,
          915,
          484,
          294,
          257,
          1150,
          11,
          307,
          300,
          604,
          565,
          291,
          434,
          50880
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 695.9,
        "id": 269,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 692.7,
        "temperature": 0,
        "text": " doing parsing from a text file, your stuff is still text.",
        "tokens": [
          50880,
          884,
          21156,
          278,
          490,
          257,
          2487,
          3991,
          11,
          428,
          1507,
          307,
          920,
          2487,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 697.1,
        "id": 270,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 695.9,
        "temperature": 0,
        "text": " It's a string.",
        "tokens": [
          51040,
          467,
          311,
          257,
          6798,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 699.82,
        "id": 271,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 697.1,
        "temperature": 0,
        "text": " It doesn't know how to add 14 to a string.",
        "tokens": [
          51100,
          467,
          1177,
          380,
          458,
          577,
          281,
          909,
          3499,
          281,
          257,
          6798,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 701.3,
        "id": 272,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 699.82,
        "temperature": 0,
        "text": " I can actually use a function called",
        "tokens": [
          51236,
          286,
          393,
          767,
          764,
          257,
          2445,
          1219,
          51310
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 706.3,
        "id": 273,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 701.3,
        "temperature": 0,
        "text": " parse float, which is a global JavaScript function that's",
        "tokens": [
          51310,
          48377,
          15706,
          11,
          597,
          307,
          257,
          4338,
          15778,
          2445,
          300,
          311,
          51560
        ]
      },
      {
        "avg_logprob": -0.17745638308317765,
        "compression_ratio": 1.5748987854251013,
        "end": 710.5,
        "id": 274,
        "no_speech_prob": 0.00008220175368478522,
        "seek": 68238,
        "start": 706.3,
        "temperature": 0,
        "text": " available that takes a string and turns it into a number.",
        "tokens": [
          51560,
          2435,
          300,
          2516,
          257,
          6798,
          293,
          4523,
          309,
          666,
          257,
          1230,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 715.06,
        "id": 275,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 710.54,
        "temperature": 0,
        "text": " So now I can actually add the number 14 to the number temp.",
        "tokens": [
          50366,
          407,
          586,
          286,
          393,
          767,
          909,
          264,
          1230,
          3499,
          281,
          264,
          1230,
          18274,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 717.14,
        "id": 276,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 715.06,
        "temperature": 0,
        "text": " So now we should see, there we go.",
        "tokens": [
          50592,
          407,
          586,
          321,
          820,
          536,
          11,
          456,
          321,
          352,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 721.5,
        "id": 277,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 717.14,
        "temperature": 0,
        "text": " We can see this is the actual average temperature",
        "tokens": [
          50696,
          492,
          393,
          536,
          341,
          307,
          264,
          3539,
          4274,
          4292,
          50914
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 724.06,
        "id": 278,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 721.5,
        "temperature": 0,
        "text": " from 1880 to 2018.",
        "tokens": [
          50914,
          490,
          2443,
          4702,
          281,
          6096,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 725.1,
        "id": 279,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 724.06,
        "temperature": 0,
        "text": " This is a bar chart.",
        "tokens": [
          51042,
          639,
          307,
          257,
          2159,
          6927,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 727.74,
        "id": 280,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 725.1,
        "temperature": 0,
        "text": " I don't think the bar chart is the best way to describe this.",
        "tokens": [
          51094,
          286,
          500,
          380,
          519,
          264,
          2159,
          6927,
          307,
          264,
          1151,
          636,
          281,
          6786,
          341,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 730.34,
        "id": 281,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 727.74,
        "temperature": 0,
        "text": " It's also kind of funny to me that this one is",
        "tokens": [
          51226,
          467,
          311,
          611,
          733,
          295,
          4074,
          281,
          385,
          300,
          341,
          472,
          307,
          51356
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 731.3,
        "id": 282,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 730.34,
        "temperature": 0,
        "text": " colored differently.",
        "tokens": [
          51356,
          14332,
          7614,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 734.74,
        "id": 283,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 731.3,
        "temperature": 0,
        "text": " I think that's because I removed the color thing.",
        "tokens": [
          51404,
          286,
          519,
          300,
          311,
          570,
          286,
          7261,
          264,
          2017,
          551,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 736.7,
        "id": 284,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 734.74,
        "temperature": 0,
        "text": " So let's see if we can fix that.",
        "tokens": [
          51576,
          407,
          718,
          311,
          536,
          498,
          321,
          393,
          3191,
          300,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 738.58,
        "id": 285,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 736.7,
        "temperature": 0,
        "text": " So I have a feeling that if I get rid of the,",
        "tokens": [
          51674,
          407,
          286,
          362,
          257,
          2633,
          300,
          498,
          286,
          483,
          3973,
          295,
          264,
          11,
          51768
        ]
      },
      {
        "avg_logprob": -0.21263029915945872,
        "compression_ratio": 1.686131386861314,
        "end": 739.9,
        "id": 286,
        "no_speech_prob": 0.000017231557649211027,
        "seek": 71050,
        "start": 738.58,
        "temperature": 0,
        "text": " I'm just guessing.",
        "tokens": [
          51768,
          286,
          478,
          445,
          17939,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 742.06,
        "id": 287,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 739.9,
        "temperature": 0,
        "text": " But I have a feeling the chart.js works",
        "tokens": [
          50364,
          583,
          286,
          362,
          257,
          2633,
          264,
          6927,
          13,
          25530,
          1985,
          50472
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 745.78,
        "id": 288,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 742.06,
        "temperature": 0,
        "text": " if I get rid of the color as an array.",
        "tokens": [
          50472,
          498,
          286,
          483,
          3973,
          295,
          264,
          2017,
          382,
          364,
          10225,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 748.42,
        "id": 289,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 745.78,
        "temperature": 0,
        "text": " Yes, it applies the color to everything.",
        "tokens": [
          50658,
          1079,
          11,
          309,
          13165,
          264,
          2017,
          281,
          1203,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 755.02,
        "id": 290,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 748.42,
        "temperature": 0,
        "text": " And then I can also change this from type to bar to line.",
        "tokens": [
          50790,
          400,
          550,
          286,
          393,
          611,
          1319,
          341,
          490,
          2010,
          281,
          2159,
          281,
          1622,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 756.06,
        "id": 291,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 755.02,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51120,
          400,
          456,
          321,
          352,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 758.4599999999999,
        "id": 292,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 756.06,
        "temperature": 0,
        "text": " Now, I don't necessarily want the fill below it.",
        "tokens": [
          51172,
          823,
          11,
          286,
          500,
          380,
          4725,
          528,
          264,
          2836,
          2507,
          309,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 760.4599999999999,
        "id": 293,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 758.4599999999999,
        "temperature": 0,
        "text": " This is a good example of where I need to look up",
        "tokens": [
          51292,
          639,
          307,
          257,
          665,
          1365,
          295,
          689,
          286,
          643,
          281,
          574,
          493,
          51392
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 762.9399999999999,
        "id": 294,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 760.4599999999999,
        "temperature": 0,
        "text": " in the documentation, because I have no idea how to turn",
        "tokens": [
          51392,
          294,
          264,
          14333,
          11,
          570,
          286,
          362,
          572,
          1558,
          577,
          281,
          1261,
          51516
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 765.34,
        "id": 295,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 762.9399999999999,
        "temperature": 0,
        "text": " the fill below the line off.",
        "tokens": [
          51516,
          264,
          2836,
          2507,
          264,
          1622,
          766,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 767.72,
        "id": 296,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 765.34,
        "temperature": 0,
        "text": " It's probably some parameter that either goes in options",
        "tokens": [
          51636,
          467,
          311,
          1391,
          512,
          13075,
          300,
          2139,
          1709,
          294,
          3956,
          51755
        ]
      },
      {
        "avg_logprob": -0.22587727055405127,
        "compression_ratio": 1.6415770609318996,
        "end": 768.78,
        "id": 297,
        "no_speech_prob": 0.0002199524751631543,
        "seek": 73990,
        "start": 767.72,
        "temperature": 0,
        "text": " or with the data set.",
        "tokens": [
          51755,
          420,
          365,
          264,
          1412,
          992,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 771.9,
        "id": 298,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 768.78,
        "temperature": 0,
        "text": " Let's see if I can find that on the chart.js website.",
        "tokens": [
          50364,
          961,
          311,
          536,
          498,
          286,
          393,
          915,
          300,
          322,
          264,
          6927,
          13,
          25530,
          3144,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 774.9399999999999,
        "id": 299,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 771.9,
        "temperature": 0,
        "text": " Here along the side is all of the different things.",
        "tokens": [
          50520,
          1692,
          2051,
          264,
          1252,
          307,
          439,
          295,
          264,
          819,
          721,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 779.38,
        "id": 300,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 774.9399999999999,
        "temperature": 0,
        "text": " I think I imagine if I go into line, it's showing me line.",
        "tokens": [
          50672,
          286,
          519,
          286,
          3811,
          498,
          286,
          352,
          666,
          1622,
          11,
          309,
          311,
          4099,
          385,
          1622,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 782.26,
        "id": 301,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 779.38,
        "temperature": 0,
        "text": " Example usage, data set properties, fill.",
        "tokens": [
          50894,
          24755,
          781,
          14924,
          11,
          1412,
          992,
          7221,
          11,
          2836,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 783.14,
        "id": 302,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 782.26,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51038,
          821,
          321,
          352,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 786.62,
        "id": 303,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 783.14,
        "temperature": 0,
        "text": " Fill, these are all these different things I could try.",
        "tokens": [
          51082,
          25315,
          11,
          613,
          366,
          439,
          613,
          819,
          721,
          286,
          727,
          853,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 790.3,
        "id": 304,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 786.62,
        "temperature": 0,
        "text": " Fill, Boolean, or string, default is true.",
        "tokens": [
          51256,
          25315,
          11,
          23351,
          28499,
          11,
          420,
          6798,
          11,
          7576,
          307,
          2074,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 795.06,
        "id": 305,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 790.3,
        "temperature": 0,
        "text": " So I think that means if I add a fill false here",
        "tokens": [
          51440,
          407,
          286,
          519,
          300,
          1355,
          498,
          286,
          909,
          257,
          2836,
          7908,
          510,
          51678
        ]
      },
      {
        "avg_logprob": -0.24833677622897565,
        "compression_ratio": 1.653225806451613,
        "end": 798.54,
        "id": 306,
        "no_speech_prob": 0.00007484596426365897,
        "seek": 76878,
        "start": 795.06,
        "temperature": 0,
        "text": " as another option in the data sets object,",
        "tokens": [
          51678,
          382,
          1071,
          3614,
          294,
          264,
          1412,
          6352,
          2657,
          11,
          51852
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 802.9399999999999,
        "id": 307,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 799.3,
        "temperature": 0,
        "text": " then if I go back here, we can say, yes, no more fill.",
        "tokens": [
          50402,
          550,
          498,
          286,
          352,
          646,
          510,
          11,
          321,
          393,
          584,
          11,
          2086,
          11,
          572,
          544,
          2836,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 803.9,
        "id": 308,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 802.9399999999999,
        "temperature": 0,
        "text": " That looks great.",
        "tokens": [
          50584,
          663,
          1542,
          869,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 806.78,
        "id": 309,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 803.9,
        "temperature": 0,
        "text": " I probably want to think about what this label",
        "tokens": [
          50632,
          286,
          1391,
          528,
          281,
          519,
          466,
          437,
          341,
          7645,
          50776
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 808.38,
        "id": 310,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 806.78,
        "temperature": 0,
        "text": " is to be more accurate.",
        "tokens": [
          50776,
          307,
          281,
          312,
          544,
          8559,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 809.6999999999999,
        "id": 311,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 808.38,
        "temperature": 0,
        "text": " This is pretty important.",
        "tokens": [
          50856,
          639,
          307,
          1238,
          1021,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 813.06,
        "id": 312,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 809.6999999999999,
        "temperature": 0,
        "text": " So how about I say exactly what the data is.",
        "tokens": [
          50922,
          407,
          577,
          466,
          286,
          584,
          2293,
          437,
          264,
          1412,
          307,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 815.74,
        "id": 313,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 813.06,
        "temperature": 0,
        "text": " So here's the exact data I got.",
        "tokens": [
          51090,
          407,
          510,
          311,
          264,
          1900,
          1412,
          286,
          658,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 818.06,
        "id": 314,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 815.74,
        "temperature": 0,
        "text": " The zonal annual means, the combined land surface, air",
        "tokens": [
          51224,
          440,
          710,
          21523,
          9784,
          1355,
          11,
          264,
          9354,
          2117,
          3753,
          11,
          1988,
          51340
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 819.9,
        "id": 315,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 818.06,
        "temperature": 0,
        "text": " and sea water surface temperature.",
        "tokens": [
          51340,
          293,
          4158,
          1281,
          3753,
          4292,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2577992733393874,
        "compression_ratio": 1.6255506607929515,
        "end": 823.5799999999999,
        "id": 316,
        "no_speech_prob": 0.000018631732018548064,
        "seek": 79854,
        "start": 819.9,
        "temperature": 0,
        "text": " So land ocean temperature index.",
        "tokens": [
          51432,
          407,
          2117,
          7810,
          4292,
          8186,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 832.6600000000001,
        "id": 317,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 823.58,
        "temperature": 0,
        "text": " So let's change the label to this in Celsius.",
        "tokens": [
          50364,
          407,
          718,
          311,
          1319,
          264,
          7645,
          281,
          341,
          294,
          22658,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 834.5,
        "id": 318,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 832.6600000000001,
        "temperature": 0,
        "text": " And then I have to type that degree symbol.",
        "tokens": [
          50818,
          400,
          550,
          286,
          362,
          281,
          2010,
          300,
          4314,
          5986,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 836.98,
        "id": 319,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 834.5,
        "temperature": 0,
        "text": " Does anyone know how to type the degree symbol?",
        "tokens": [
          50910,
          4402,
          2878,
          458,
          577,
          281,
          2010,
          264,
          4314,
          5986,
          30,
          51034
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 840.22,
        "id": 320,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 836.98,
        "temperature": 0,
        "text": " Apparently, it's option shift 8 to type the degree symbol.",
        "tokens": [
          51034,
          16755,
          11,
          309,
          311,
          3614,
          5513,
          1649,
          281,
          2010,
          264,
          4314,
          5986,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 841.5400000000001,
        "id": 321,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 840.22,
        "temperature": 0,
        "text": " I have not actually tried this.",
        "tokens": [
          51196,
          286,
          362,
          406,
          767,
          3031,
          341,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 842.5400000000001,
        "id": 322,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 841.5400000000001,
        "temperature": 0,
        "text": " Let's see if it works.",
        "tokens": [
          51262,
          961,
          311,
          536,
          498,
          309,
          1985,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 843.7,
        "id": 323,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 842.5400000000001,
        "temperature": 0,
        "text": " Yes, there we go.",
        "tokens": [
          51312,
          1079,
          11,
          456,
          321,
          352,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 846.1,
        "id": 324,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 843.7,
        "temperature": 0,
        "text": " We've got Celsius.",
        "tokens": [
          51370,
          492,
          600,
          658,
          22658,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 848.22,
        "id": 325,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 846.1,
        "temperature": 0,
        "text": " And let me go back and we can see.",
        "tokens": [
          51490,
          400,
          718,
          385,
          352,
          646,
          293,
          321,
          393,
          536,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 848.7800000000001,
        "id": 326,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 848.22,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51596,
          821,
          321,
          352,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.2900392598119275,
        "compression_ratio": 1.6926605504587156,
        "end": 851.0600000000001,
        "id": 327,
        "no_speech_prob": 0.00007141891546780244,
        "seek": 82358,
        "start": 848.7800000000001,
        "temperature": 0,
        "text": " So now I have my label up there.",
        "tokens": [
          51624,
          407,
          586,
          286,
          362,
          452,
          7645,
          493,
          456,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 852.6199999999999,
        "id": 328,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 851.06,
        "temperature": 0,
        "text": " What I want to do, let me refactor",
        "tokens": [
          50364,
          708,
          286,
          528,
          281,
          360,
          11,
          718,
          385,
          1895,
          15104,
          50442
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 853.8199999999999,
        "id": 329,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 852.6199999999999,
        "temperature": 0,
        "text": " this code a little bit.",
        "tokens": [
          50442,
          341,
          3089,
          257,
          707,
          857,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 856.8199999999999,
        "id": 330,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 853.8199999999999,
        "temperature": 0,
        "text": " So I don't really love the use of these global variables here.",
        "tokens": [
          50502,
          407,
          286,
          500,
          380,
          534,
          959,
          264,
          764,
          295,
          613,
          4338,
          9102,
          510,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 859.3,
        "id": 331,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 856.8199999999999,
        "temperature": 0,
        "text": " I think what would make more sense,",
        "tokens": [
          50652,
          286,
          519,
          437,
          576,
          652,
          544,
          2020,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 861.5799999999999,
        "id": 332,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 859.3,
        "temperature": 0,
        "text": " and there's so many different ways we could do this.",
        "tokens": [
          50776,
          293,
          456,
          311,
          370,
          867,
          819,
          2098,
          321,
          727,
          360,
          341,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 865.38,
        "id": 333,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 861.5799999999999,
        "temperature": 0,
        "text": " But let me just do one way to make it a little simpler.",
        "tokens": [
          50890,
          583,
          718,
          385,
          445,
          360,
          472,
          636,
          281,
          652,
          309,
          257,
          707,
          18587,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 868.3399999999999,
        "id": 334,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 865.38,
        "temperature": 0,
        "text": " Let me actually have a local variable here,",
        "tokens": [
          51080,
          961,
          385,
          767,
          362,
          257,
          2654,
          7006,
          510,
          11,
          51228
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 873.5,
        "id": 335,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 868.3399999999999,
        "temperature": 0,
        "text": " which are both, I'm going to call these x's and y's.",
        "tokens": [
          51228,
          597,
          366,
          1293,
          11,
          286,
          478,
          516,
          281,
          818,
          613,
          2031,
          311,
          293,
          288,
          311,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 877.2199999999999,
        "id": 336,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 873.5,
        "temperature": 0,
        "text": " And then I'm just going to push the x's here,",
        "tokens": [
          51486,
          400,
          550,
          286,
          478,
          445,
          516,
          281,
          2944,
          264,
          2031,
          311,
          510,
          11,
          51672
        ]
      },
      {
        "avg_logprob": -0.21384927309476412,
        "compression_ratio": 1.691699604743083,
        "end": 879.28,
        "id": 337,
        "no_speech_prob": 0.0016229592729359865,
        "seek": 85106,
        "start": 877.2199999999999,
        "temperature": 0,
        "text": " push the y's here.",
        "tokens": [
          51672,
          2944,
          264,
          288,
          311,
          510,
          13,
          51775
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 881.28,
        "id": 338,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 879.28,
        "temperature": 0,
        "text": " And then when this is done, I'm going",
        "tokens": [
          50364,
          400,
          550,
          562,
          341,
          307,
          1096,
          11,
          286,
          478,
          516,
          50464
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 884.8,
        "id": 339,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 881.28,
        "temperature": 0,
        "text": " to return an object with x's and y's in it.",
        "tokens": [
          50464,
          281,
          2736,
          364,
          2657,
          365,
          2031,
          311,
          293,
          288,
          311,
          294,
          309,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 886.6,
        "id": 340,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 884.8,
        "temperature": 0,
        "text": " So the get data function is actually",
        "tokens": [
          50640,
          407,
          264,
          483,
          1412,
          2445,
          307,
          767,
          50730
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 889.92,
        "id": 341,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 886.6,
        "temperature": 0,
        "text": " going to return an object with both of those arrays.",
        "tokens": [
          50730,
          516,
          281,
          2736,
          364,
          2657,
          365,
          1293,
          295,
          729,
          41011,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 892.12,
        "id": 342,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 889.92,
        "temperature": 0,
        "text": " And so then what I can say here is",
        "tokens": [
          50896,
          400,
          370,
          550,
          437,
          286,
          393,
          584,
          510,
          307,
          51006
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 896.92,
        "id": 343,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 892.12,
        "temperature": 0,
        "text": " I can say the data equals await get data.",
        "tokens": [
          51006,
          286,
          393,
          584,
          264,
          1412,
          6915,
          19670,
          483,
          1412,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 900.6,
        "id": 344,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 896.92,
        "temperature": 0,
        "text": " And then here under labels, I want data x's.",
        "tokens": [
          51246,
          400,
          550,
          510,
          833,
          16949,
          11,
          286,
          528,
          1412,
          2031,
          311,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 905.9599999999999,
        "id": 345,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 900.6,
        "temperature": 0,
        "text": " And here under the data set, I want data y's.",
        "tokens": [
          51430,
          400,
          510,
          833,
          264,
          1412,
          992,
          11,
          286,
          528,
          1412,
          288,
          311,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.18405175613144698,
        "compression_ratio": 1.861244019138756,
        "end": 908.28,
        "id": 346,
        "no_speech_prob": 0.00034599032369442284,
        "seek": 87928,
        "start": 905.9599999999999,
        "temperature": 0,
        "text": " So again, I'm not sure this is the best solution.",
        "tokens": [
          51698,
          407,
          797,
          11,
          286,
          478,
          406,
          988,
          341,
          307,
          264,
          1151,
          3827,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 912.4399999999999,
        "id": 347,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 908.28,
        "temperature": 0,
        "text": " But at least now, the chart it function and the get data",
        "tokens": [
          50364,
          583,
          412,
          1935,
          586,
          11,
          264,
          6927,
          309,
          2445,
          293,
          264,
          483,
          1412,
          50572
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 915.18,
        "id": 348,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 912.4399999999999,
        "temperature": 0,
        "text": " function operate independently without sharing",
        "tokens": [
          50572,
          2445,
          9651,
          21761,
          1553,
          5414,
          50709
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 918,
        "id": 349,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 915.18,
        "temperature": 0,
        "text": " a global variable, which could cause some problems later",
        "tokens": [
          50709,
          257,
          4338,
          7006,
          11,
          597,
          727,
          3082,
          512,
          2740,
          1780,
          50850
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 919.1999999999999,
        "id": 350,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 918,
        "temperature": 0,
        "text": " down the road.",
        "tokens": [
          50850,
          760,
          264,
          3060,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 922.4399999999999,
        "id": 351,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 919.1999999999999,
        "temperature": 0,
        "text": " And we can see this still works just fine.",
        "tokens": [
          50910,
          400,
          321,
          393,
          536,
          341,
          920,
          1985,
          445,
          2489,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 926.3199999999999,
        "id": 352,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 922.4399999999999,
        "temperature": 0,
        "text": " It might be nice to also just add the degree symbol here.",
        "tokens": [
          51072,
          467,
          1062,
          312,
          1481,
          281,
          611,
          445,
          909,
          264,
          4314,
          5986,
          510,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 928.16,
        "id": 353,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 926.3199999999999,
        "temperature": 0,
        "text": " I have no idea if that's possible.",
        "tokens": [
          51266,
          286,
          362,
          572,
          1558,
          498,
          300,
          311,
          1944,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 930.52,
        "id": 354,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 928.16,
        "temperature": 0,
        "text": " It's making these labels automatically.",
        "tokens": [
          51358,
          467,
          311,
          1455,
          613,
          16949,
          6772,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 932.56,
        "id": 355,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 930.52,
        "temperature": 0,
        "text": " So looking again at the documentation,",
        "tokens": [
          51476,
          407,
          1237,
          797,
          412,
          264,
          14333,
          11,
          51578
        ]
      },
      {
        "avg_logprob": -0.2016688397056178,
        "compression_ratio": 1.6129032258064515,
        "end": 935.72,
        "id": 356,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 90828,
        "start": 932.56,
        "temperature": 0,
        "text": " and I did just take a little break to find this in advance.",
        "tokens": [
          51578,
          293,
          286,
          630,
          445,
          747,
          257,
          707,
          1821,
          281,
          915,
          341,
          294,
          7295,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 940.72,
        "id": 357,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 935.72,
        "temperature": 0,
        "text": " But under here, under axes, under labeling",
        "tokens": [
          50364,
          583,
          833,
          510,
          11,
          833,
          35387,
          11,
          833,
          40244,
          50614
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 941.5600000000001,
        "id": 358,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 940.72,
        "temperature": 0,
        "text": " is what I want to do.",
        "tokens": [
          50614,
          307,
          437,
          286,
          528,
          281,
          360,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 946.76,
        "id": 359,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 941.5600000000001,
        "temperature": 0,
        "text": " I want to change the way the labeling of the y-axis works.",
        "tokens": [
          50656,
          286,
          528,
          281,
          1319,
          264,
          636,
          264,
          40244,
          295,
          264,
          288,
          12,
          24633,
          1985,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 950.96,
        "id": 360,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 946.76,
        "temperature": 0,
        "text": " So if I click here, we can see there are, ah,",
        "tokens": [
          50916,
          407,
          498,
          286,
          2052,
          510,
          11,
          321,
          393,
          536,
          456,
          366,
          11,
          3716,
          11,
          51126
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 952.96,
        "id": 361,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 950.96,
        "temperature": 0,
        "text": " we can see these are all the possibilities.",
        "tokens": [
          51126,
          321,
          393,
          536,
          613,
          366,
          439,
          264,
          12178,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 956.62,
        "id": 362,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 952.96,
        "temperature": 0,
        "text": " But actually, this is what I want, custom tick format.",
        "tokens": [
          51226,
          583,
          767,
          11,
          341,
          307,
          437,
          286,
          528,
          11,
          2375,
          5204,
          7877,
          13,
          51409
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 961.5600000000001,
        "id": 363,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 956.62,
        "temperature": 0,
        "text": " So each one of these labels on the left",
        "tokens": [
          51409,
          407,
          1184,
          472,
          295,
          613,
          16949,
          322,
          264,
          1411,
          51656
        ]
      },
      {
        "avg_logprob": -0.23287981206720526,
        "compression_ratio": 1.8697916666666667,
        "end": 965.52,
        "id": 364,
        "no_speech_prob": 0.00004006360177299939,
        "seek": 93572,
        "start": 961.5600000000001,
        "temperature": 0,
        "text": " is a tick, like tick, tick, tick, tick, like that.",
        "tokens": [
          51656,
          307,
          257,
          5204,
          11,
          411,
          5204,
          11,
          5204,
          11,
          5204,
          11,
          5204,
          11,
          411,
          300,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 971.16,
        "id": 365,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 966.3199999999999,
        "temperature": 0,
        "text": " And so what I want to do is I need to add these options back.",
        "tokens": [
          50404,
          400,
          370,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          643,
          281,
          909,
          613,
          3956,
          646,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 972.84,
        "id": 366,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 971.16,
        "temperature": 0,
        "text": " This is something I removed earlier.",
        "tokens": [
          50646,
          639,
          307,
          746,
          286,
          7261,
          3071,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 976.56,
        "id": 367,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 972.84,
        "temperature": 0,
        "text": " So let me add the options back.",
        "tokens": [
          50730,
          407,
          718,
          385,
          909,
          264,
          3956,
          646,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 981.42,
        "id": 368,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 976.56,
        "temperature": 0,
        "text": " Under y-axis, under ticks, this is a callback function.",
        "tokens": [
          50916,
          6974,
          288,
          12,
          24633,
          11,
          833,
          42475,
          11,
          341,
          307,
          257,
          818,
          3207,
          2445,
          13,
          51159
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 982.6,
        "id": 369,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 981.42,
        "temperature": 0,
        "text": " This is kind of crazy.",
        "tokens": [
          51159,
          639,
          307,
          733,
          295,
          3219,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 984.96,
        "id": 370,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 982.6,
        "temperature": 0,
        "text": " So this is an example for including a dollar sign.",
        "tokens": [
          51218,
          407,
          341,
          307,
          364,
          1365,
          337,
          3009,
          257,
          7241,
          1465,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 987.34,
        "id": 371,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 984.96,
        "temperature": 0,
        "text": " It's basically saying, here's a function that defines",
        "tokens": [
          51336,
          467,
          311,
          1936,
          1566,
          11,
          510,
          311,
          257,
          2445,
          300,
          23122,
          51455
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 990.04,
        "id": 372,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 987.34,
        "temperature": 0,
        "text": " how to label the y-axis.",
        "tokens": [
          51455,
          577,
          281,
          7645,
          264,
          288,
          12,
          24633,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.2316031082816746,
        "compression_ratio": 1.6906779661016949,
        "end": 994.8,
        "id": 373,
        "no_speech_prob": 0.000033737203921191394,
        "seek": 96552,
        "start": 990.04,
        "temperature": 0,
        "text": " Take the value and turn it into dollar sign plus the value.",
        "tokens": [
          51590,
          3664,
          264,
          2158,
          293,
          1261,
          309,
          666,
          7241,
          1465,
          1804,
          264,
          2158,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 997.28,
        "id": 374,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 994.8,
        "temperature": 0,
        "text": " So what I want to do is take the value",
        "tokens": [
          50364,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          747,
          264,
          2158,
          50488
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1002.64,
        "id": 375,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 997.28,
        "temperature": 0,
        "text": " and turn it into value plus degrees.",
        "tokens": [
          50488,
          293,
          1261,
          309,
          666,
          2158,
          1804,
          5310,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1004.52,
        "id": 376,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1002.64,
        "temperature": 0,
        "text": " And I get rid of this comment.",
        "tokens": [
          50756,
          400,
          286,
          483,
          3973,
          295,
          341,
          2871,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1007.4799999999999,
        "id": 377,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1004.52,
        "temperature": 0,
        "text": " And now I have that configured as part of my chart.",
        "tokens": [
          50850,
          400,
          586,
          286,
          362,
          300,
          30538,
          382,
          644,
          295,
          452,
          6927,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1009.3199999999999,
        "id": 378,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1007.4799999999999,
        "temperature": 0,
        "text": " And here we are.",
        "tokens": [
          50998,
          400,
          510,
          321,
          366,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1010.24,
        "id": 379,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1009.3199999999999,
        "temperature": 0,
        "text": " Look, there you go.",
        "tokens": [
          51090,
          2053,
          11,
          456,
          291,
          352,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1012.24,
        "id": 380,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1010.24,
        "temperature": 0,
        "text": " Now you can see the degree symbol is there.",
        "tokens": [
          51136,
          823,
          291,
          393,
          536,
          264,
          4314,
          5986,
          307,
          456,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1013.92,
        "id": 381,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1012.24,
        "temperature": 0,
        "text": " So let me just spread this back out again.",
        "tokens": [
          51236,
          407,
          718,
          385,
          445,
          3974,
          341,
          646,
          484,
          797,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1017.4399999999999,
        "id": 382,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1013.92,
        "temperature": 0,
        "text": " I feel like this whole, the canvas size is weird.",
        "tokens": [
          51320,
          286,
          841,
          411,
          341,
          1379,
          11,
          264,
          16267,
          2744,
          307,
          3657,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1019.8399999999999,
        "id": 383,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1017.4399999999999,
        "temperature": 0,
        "text": " So I'm going to make this like 800 by 400.",
        "tokens": [
          51496,
          407,
          286,
          478,
          516,
          281,
          652,
          341,
          411,
          13083,
          538,
          8423,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1020.4799999999999,
        "id": 384,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1019.8399999999999,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51616,
          821,
          321,
          352,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1022.3599999999999,
        "id": 385,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1020.4799999999999,
        "temperature": 0,
        "text": " And then I'm going to get rid of the console.",
        "tokens": [
          51648,
          400,
          550,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          11076,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.22222581590924945,
        "compression_ratio": 1.654275092936803,
        "end": 1023.1999999999999,
        "id": 386,
        "no_speech_prob": 0.00016603819676674902,
        "seek": 99480,
        "start": 1022.3599999999999,
        "temperature": 0,
        "text": " And voila.",
        "tokens": [
          51742,
          400,
          45565,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1027.68,
        "id": 387,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1023.2,
        "temperature": 0,
        "text": " We have our finished chart that shows the combined land,",
        "tokens": [
          50364,
          492,
          362,
          527,
          4335,
          6927,
          300,
          3110,
          264,
          9354,
          2117,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1030.56,
        "id": 388,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1027.68,
        "temperature": 0,
        "text": " surface, air, and sea surface water temperature in Celsius",
        "tokens": [
          50588,
          3753,
          11,
          1988,
          11,
          293,
          4158,
          3753,
          1281,
          4292,
          294,
          22658,
          50732
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1035.28,
        "id": 389,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1030.56,
        "temperature": 0,
        "text": " averaged from 1880 all the way to 2018.",
        "tokens": [
          50732,
          18247,
          2980,
          490,
          2443,
          4702,
          439,
          264,
          636,
          281,
          6096,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1036.64,
        "id": 390,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1035.28,
        "temperature": 0,
        "text": " And you can see here, by the way,",
        "tokens": [
          50968,
          400,
          291,
          393,
          536,
          510,
          11,
          538,
          264,
          636,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1041.32,
        "id": 391,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1036.64,
        "temperature": 0,
        "text": " some very, very good evidence that the Earth is warming.",
        "tokens": [
          51036,
          512,
          588,
          11,
          588,
          665,
          4467,
          300,
          264,
          4755,
          307,
          17983,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1045.04,
        "id": 392,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1041.32,
        "temperature": 0,
        "text": " The average temperature over time since 1880 to now",
        "tokens": [
          51270,
          440,
          4274,
          4292,
          670,
          565,
          1670,
          2443,
          4702,
          281,
          586,
          51456
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1046.52,
        "id": 393,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1045.04,
        "temperature": 0,
        "text": " is going up.",
        "tokens": [
          51456,
          307,
          516,
          493,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.2393341812432981,
        "compression_ratio": 1.5720338983050848,
        "end": 1051.56,
        "id": 394,
        "no_speech_prob": 0.00004683877341449261,
        "seek": 102320,
        "start": 1046.52,
        "temperature": 0,
        "text": " To recap, we have seen how to load tabular data in the form",
        "tokens": [
          51530,
          1407,
          20928,
          11,
          321,
          362,
          1612,
          577,
          281,
          3677,
          4421,
          1040,
          1412,
          294,
          264,
          1254,
          51782
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1053.72,
        "id": 395,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1051.56,
        "temperature": 0,
        "text": " of a comma-separated values file.",
        "tokens": [
          50364,
          295,
          257,
          22117,
          12,
          405,
          2181,
          770,
          4190,
          3991,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1056,
        "id": 396,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1053.72,
        "temperature": 0,
        "text": " We've seen a little bit about how to parse that file",
        "tokens": [
          50472,
          492,
          600,
          1612,
          257,
          707,
          857,
          466,
          577,
          281,
          48377,
          300,
          3991,
          50586
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1057.6799999999998,
        "id": 397,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1056,
        "temperature": 0,
        "text": " manually, although ultimately, we",
        "tokens": [
          50586,
          16945,
          11,
          4878,
          6284,
          11,
          321,
          50670
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1060.08,
        "id": 398,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1057.6799999999998,
        "temperature": 0,
        "text": " might want to use a parsing engine that's",
        "tokens": [
          50670,
          1062,
          528,
          281,
          764,
          257,
          21156,
          278,
          2848,
          300,
          311,
          50790
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1062.6,
        "id": 399,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1060.08,
        "temperature": 0,
        "text": " going to be able to handle all sorts of errors or things",
        "tokens": [
          50790,
          516,
          281,
          312,
          1075,
          281,
          4813,
          439,
          7527,
          295,
          13603,
          420,
          721,
          50916
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1063.84,
        "id": 400,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1062.6,
        "temperature": 0,
        "text": " that might come up.",
        "tokens": [
          50916,
          300,
          1062,
          808,
          493,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1065.8,
        "id": 401,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1063.84,
        "temperature": 0,
        "text": " Once we have that data, we've seen",
        "tokens": [
          50978,
          3443,
          321,
          362,
          300,
          1412,
          11,
          321,
          600,
          1612,
          51076
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1068.56,
        "id": 402,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1065.8,
        "temperature": 0,
        "text": " how to repackage that data for a different library to use it,",
        "tokens": [
          51076,
          577,
          281,
          1085,
          501,
          609,
          300,
          1412,
          337,
          257,
          819,
          6405,
          281,
          764,
          309,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1072.04,
        "id": 403,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1068.56,
        "temperature": 0,
        "text": " in this case, chart.js, to apply a chart with that data",
        "tokens": [
          51214,
          294,
          341,
          1389,
          11,
          6927,
          13,
          25530,
          11,
          281,
          3079,
          257,
          6927,
          365,
          300,
          1412,
          51388
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1073.08,
        "id": 404,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1072.04,
        "temperature": 0,
        "text": " to the canvas.",
        "tokens": [
          51388,
          281,
          264,
          16267,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1076.44,
        "id": 405,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1073.08,
        "temperature": 0,
        "text": " And we've seen how to adjust a little bit of the sort",
        "tokens": [
          51440,
          400,
          321,
          600,
          1612,
          577,
          281,
          4369,
          257,
          707,
          857,
          295,
          264,
          1333,
          51608
        ]
      },
      {
        "avg_logprob": -0.2035490152787189,
        "compression_ratio": 1.7887323943661972,
        "end": 1080.28,
        "id": 406,
        "no_speech_prob": 0.0006263326504267752,
        "seek": 105156,
        "start": 1076.44,
        "temperature": 0,
        "text": " of styles and layout and format of that chart.",
        "tokens": [
          51608,
          295,
          13273,
          293,
          13333,
          293,
          7877,
          295,
          300,
          6927,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1082.04,
        "id": 407,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1080.28,
        "temperature": 0,
        "text": " So what should you do here?",
        "tokens": [
          50364,
          407,
          437,
          820,
          291,
          360,
          510,
          30,
          50452
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1084.28,
        "id": 408,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1082.04,
        "temperature": 0,
        "text": " So you've got a number of couple of different options.",
        "tokens": [
          50452,
          407,
          291,
          600,
          658,
          257,
          1230,
          295,
          1916,
          295,
          819,
          3956,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1087.84,
        "id": 409,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1084.28,
        "temperature": 0,
        "text": " One exercise is just do exactly the same thing as I have here,",
        "tokens": [
          50564,
          1485,
          5380,
          307,
          445,
          360,
          2293,
          264,
          912,
          551,
          382,
          286,
          362,
          510,
          11,
          50742
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1089.16,
        "id": 410,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1087.84,
        "temperature": 0,
        "text": " but do it with your own data.",
        "tokens": [
          50742,
          457,
          360,
          309,
          365,
          428,
          1065,
          1412,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1093.36,
        "id": 411,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1089.16,
        "temperature": 0,
        "text": " What's some CSV data that you can find?",
        "tokens": [
          50808,
          708,
          311,
          512,
          48814,
          1412,
          300,
          291,
          393,
          915,
          30,
          51018
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1095.92,
        "id": 412,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1093.36,
        "temperature": 0,
        "text": " Another thing that might be fun to try is go and get",
        "tokens": [
          51018,
          3996,
          551,
          300,
          1062,
          312,
          1019,
          281,
          853,
          307,
          352,
          293,
          483,
          51146
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1097.76,
        "id": 413,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1095.92,
        "temperature": 0,
        "text": " p5 to p5.js library.",
        "tokens": [
          51146,
          280,
          20,
          281,
          280,
          20,
          13,
          25530,
          6405,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1100.68,
        "id": 414,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1097.76,
        "temperature": 0,
        "text": " Could you draw your own line graph without chart.js,",
        "tokens": [
          51238,
          7497,
          291,
          2642,
          428,
          1065,
          1622,
          4295,
          1553,
          6927,
          13,
          25530,
          11,
          51384
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1104.48,
        "id": 415,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1100.68,
        "temperature": 0,
        "text": " but using this raw drawing functionality of p5.js?",
        "tokens": [
          51384,
          457,
          1228,
          341,
          8936,
          6316,
          14980,
          295,
          280,
          20,
          13,
          25530,
          30,
          51574
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1106.32,
        "id": 416,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1104.48,
        "temperature": 0,
        "text": " I will include a solution to that",
        "tokens": [
          51574,
          286,
          486,
          4090,
          257,
          3827,
          281,
          300,
          51666
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1107.72,
        "id": 417,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1106.32,
        "temperature": 0,
        "text": " in this video's description.",
        "tokens": [
          51666,
          294,
          341,
          960,
          311,
          3855,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.23932387981008976,
        "compression_ratio": 1.6734693877551021,
        "end": 1109.18,
        "id": 418,
        "no_speech_prob": 0.00009610206325305626,
        "seek": 108028,
        "start": 1107.72,
        "temperature": 0,
        "text": " Another exercise that you might try",
        "tokens": [
          51736,
          3996,
          5380,
          300,
          291,
          1062,
          853,
          51809
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1112.7,
        "id": 419,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1109.18,
        "temperature": 0,
        "text": " is actually graph multiple lines on the same chart.",
        "tokens": [
          50364,
          307,
          767,
          4295,
          3866,
          3876,
          322,
          264,
          912,
          6927,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1114.94,
        "id": 420,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1112.7,
        "temperature": 0,
        "text": " In many cases, you want to look at data in comparison",
        "tokens": [
          50540,
          682,
          867,
          3331,
          11,
          291,
          528,
          281,
          574,
          412,
          1412,
          294,
          9660,
          50652
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1115.74,
        "id": 421,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1114.94,
        "temperature": 0,
        "text": " to other data.",
        "tokens": [
          50652,
          281,
          661,
          1412,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1117.66,
        "id": 422,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1115.74,
        "temperature": 0,
        "text": " So for example, in that same data file,",
        "tokens": [
          50692,
          407,
          337,
          1365,
          11,
          294,
          300,
          912,
          1412,
          3991,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1120.26,
        "id": 423,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1117.66,
        "temperature": 0,
        "text": " you get the average temperatures for the northern hemisphere",
        "tokens": [
          50788,
          291,
          483,
          264,
          4274,
          12633,
          337,
          264,
          14197,
          38453,
          50918
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1121.66,
        "id": 424,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1120.26,
        "temperature": 0,
        "text": " and for the southern hemisphere.",
        "tokens": [
          50918,
          293,
          337,
          264,
          13456,
          38453,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1124.54,
        "id": 425,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1121.66,
        "temperature": 0,
        "text": " So you could graph all three, the global temperature,",
        "tokens": [
          50988,
          407,
          291,
          727,
          4295,
          439,
          1045,
          11,
          264,
          4338,
          4292,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1126.24,
        "id": 426,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1124.54,
        "temperature": 0,
        "text": " northern hemisphere, southern hemisphere,",
        "tokens": [
          51132,
          14197,
          38453,
          11,
          13456,
          38453,
          11,
          51217
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1128.9,
        "id": 427,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1126.24,
        "temperature": 0,
        "text": " all together on that chart with different colors for each line.",
        "tokens": [
          51217,
          439,
          1214,
          322,
          300,
          6927,
          365,
          819,
          4577,
          337,
          1184,
          1622,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1131.42,
        "id": 428,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1128.9,
        "temperature": 0,
        "text": " And I'll include a solution to that also as an exercise.",
        "tokens": [
          51350,
          400,
          286,
          603,
          4090,
          257,
          3827,
          281,
          300,
          611,
          382,
          364,
          5380,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1133.02,
        "id": 429,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1131.42,
        "temperature": 0,
        "text": " So thank you for watching this video.",
        "tokens": [
          51476,
          407,
          1309,
          291,
          337,
          1976,
          341,
          960,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1135.74,
        "id": 430,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1133.02,
        "temperature": 0,
        "text": " This concludes the second part of the first module.",
        "tokens": [
          51556,
          639,
          24643,
          264,
          1150,
          644,
          295,
          264,
          700,
          10088,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2959814903720113,
        "compression_ratio": 1.8632218844984803,
        "end": 1137.98,
        "id": 431,
        "no_speech_prob": 0.025177719071507454,
        "seek": 110918,
        "start": 1135.74,
        "temperature": 0,
        "text": " We've learned about the fetch function with images.",
        "tokens": [
          51692,
          492,
          600,
          3264,
          466,
          264,
          23673,
          2445,
          365,
          5267,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1141.06,
        "id": 432,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1137.98,
        "temperature": 0,
        "text": " And now we've learned about the fetch function with CSVs",
        "tokens": [
          50364,
          400,
          586,
          321,
          600,
          3264,
          466,
          264,
          23673,
          2445,
          365,
          48814,
          82,
          50518
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1144.38,
        "id": 433,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1141.06,
        "temperature": 0,
        "text": " and also graphing the data with chart.js.",
        "tokens": [
          50518,
          293,
          611,
          1295,
          79,
          571,
          264,
          1412,
          365,
          6927,
          13,
          25530,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1146.54,
        "id": 434,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1144.38,
        "temperature": 0,
        "text": " In the next project, we're going to look",
        "tokens": [
          50684,
          682,
          264,
          958,
          1716,
          11,
          321,
          434,
          516,
          281,
          574,
          50792
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1149.94,
        "id": 435,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1146.54,
        "temperature": 0,
        "text": " at how to get data from a web API, something that's",
        "tokens": [
          50792,
          412,
          577,
          281,
          483,
          1412,
          490,
          257,
          3670,
          9362,
          11,
          746,
          300,
          311,
          50962
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1154.1200000000001,
        "id": 436,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1149.94,
        "temperature": 0,
        "text": " not a local file, and data that changes every so often.",
        "tokens": [
          50962,
          406,
          257,
          2654,
          3991,
          11,
          293,
          1412,
          300,
          2962,
          633,
          370,
          2049,
          13,
          51171
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1156.24,
        "id": 437,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1154.1200000000001,
        "temperature": 0,
        "text": " And the data set, the example that I'm going to use",
        "tokens": [
          51171,
          400,
          264,
          1412,
          992,
          11,
          264,
          1365,
          300,
          286,
          478,
          516,
          281,
          764,
          51277
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1158.5,
        "id": 438,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1156.24,
        "temperature": 0,
        "text": " is the location, latitude, and longitude",
        "tokens": [
          51277,
          307,
          264,
          4914,
          11,
          45436,
          11,
          293,
          938,
          4377,
          51390
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1160.02,
        "id": 439,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1158.5,
        "temperature": 0,
        "text": " of the International Space Station,",
        "tokens": [
          51390,
          295,
          264,
          9157,
          8705,
          14467,
          11,
          51466
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1161.8,
        "id": 440,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1160.02,
        "temperature": 0,
        "text": " where it is above the Earth.",
        "tokens": [
          51466,
          689,
          309,
          307,
          3673,
          264,
          4755,
          13,
          51555
        ]
      },
      {
        "avg_logprob": -0.22529950286402847,
        "compression_ratio": 1.7007299270072993,
        "end": 1165.06,
        "id": 441,
        "no_speech_prob": 0.0003982102498412132,
        "seek": 113798,
        "start": 1161.8,
        "temperature": 0,
        "text": " Then I'm going to show you how to draw its location on a map",
        "tokens": [
          51555,
          1396,
          286,
          478,
          516,
          281,
          855,
          291,
          577,
          281,
          2642,
          1080,
          4914,
          322,
          257,
          4471,
          51718
        ]
      },
      {
        "avg_logprob": -0.2581072338556839,
        "compression_ratio": 1.3517241379310345,
        "end": 1168.26,
        "id": 442,
        "no_speech_prob": 0.000014285457837104332,
        "seek": 116506,
        "start": 1165.06,
        "temperature": 0,
        "text": " and refresh its location every so often",
        "tokens": [
          50364,
          293,
          15134,
          1080,
          4914,
          633,
          370,
          2049,
          50524
        ]
      },
      {
        "avg_logprob": -0.2581072338556839,
        "compression_ratio": 1.3517241379310345,
        "end": 1170.1,
        "id": 443,
        "no_speech_prob": 0.000014285457837104332,
        "seek": 116506,
        "start": 1168.26,
        "temperature": 0,
        "text": " so that it moves in real time.",
        "tokens": [
          50524,
          370,
          300,
          309,
          6067,
          294,
          957,
          565,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.2581072338556839,
        "compression_ratio": 1.3517241379310345,
        "end": 1173.3,
        "id": 444,
        "no_speech_prob": 0.000014285457837104332,
        "seek": 116506,
        "start": 1170.1,
        "temperature": 0,
        "text": " So that's the last part of this first module",
        "tokens": [
          50616,
          407,
          300,
          311,
          264,
          1036,
          644,
          295,
          341,
          700,
          10088,
          50776
        ]
      },
      {
        "avg_logprob": -0.2581072338556839,
        "compression_ratio": 1.3517241379310345,
        "end": 1174.62,
        "id": 445,
        "no_speech_prob": 0.000014285457837104332,
        "seek": 116506,
        "start": 1173.3,
        "temperature": 0,
        "text": " of working with data and APIs.",
        "tokens": [
          50776,
          295,
          1364,
          365,
          1412,
          293,
          21445,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.2581072338556839,
        "compression_ratio": 1.3517241379310345,
        "end": 1175.58,
        "id": 446,
        "no_speech_prob": 0.000014285457837104332,
        "seek": 116506,
        "start": 1174.62,
        "temperature": 0,
        "text": " And I'll see you in that video.",
        "tokens": [
          50842,
          400,
          286,
          603,
          536,
          291,
          294,
          300,
          960,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.2581072338556839,
        "compression_ratio": 1.3517241379310345,
        "end": 1176.3,
        "id": 447,
        "no_speech_prob": 0.000014285457837104332,
        "seek": 116506,
        "start": 1175.58,
        "temperature": 0,
        "text": " Thanks very much.",
        "tokens": [
          50890,
          2561,
          588,
          709,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.7998806635538737,
        "compression_ratio": 0.5555555555555556,
        "end": 1177.8999999999999,
        "id": 448,
        "no_speech_prob": 0.7784523367881775,
        "seek": 117630,
        "start": 1176.3,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50366,
          1044,
          291,
          13,
          50444
        ]
      }
    ],
    "transcription": " Let's review what we did in the previous video. So this video is entirely dependent, this is part two of graphing a CSV data file. So in the previous video, we went and got global world temperatures, the average world temperature from 1880 to present. We got that as a CSV, commerce separated values file from NASA. We parsed it using some simple string parsing techniques with the split function. Now we're able to console log that data, but instead of console logging that data, I want to graph it. There are so many different approaches we could take. There are many JavaScript libraries for making charts. Probably one of the most famous ones is D3, a data visualization library for JavaScript. We could also draw our own chart just by using HTML5 canvas and drawing functions, or using something like P5.js, which is a creative coding JavaScript library that I use a ton to draw all sorts of kinds of interactive animations, and I could draw something based on the data there. But I want to show you just kind of what might be the quickest path right now to going from data to chart in the browser. And so a simple tool, a library, JavaScript library for doing this is chart.js. Chart.js is a library you can import right there into your client-side JavaScript with creating a chart object. You can just configure it, you can give it the data, give it some colors, tell it whether you want a line or a bar chart, and poof, you'll see the chart on the webpage in a canvas. So I'm going to show you step-by-step how to import the library, add a canvas, draw the chart, and then draw the chart using your own data. So here we are, the chart.js website. There's a lot of examples, a lot of documentation, the source code on GitHub. I encourage you to check out more about the JavaScript library. I'm going to move to this get started page, which will give me the basic techniques for using chart.js. So first thing is, how do I even import the library? And this is crucial. I'm going to use a chart.js CDN. So CDN stands for Content Delivery Network, meaning I'm going to load the library via URL. It's hosted somewhere on the internet. So let's click on this and see where that takes us. It takes us to jsdeliver. Then all I need to do is go down here. We can see this is the most recent version, 2.8.0 of the library. If I click on this, it's going to open up a new webpage. And look, that's actually, wah, that's the JavaScript library. All the code for the JavaScript library itself. It's actually been minified, meaning the raw source of the library has line breaks, and big variable names, and all that kind of stuff. But I'm just going to, all I need is this URL right here. I'm going to go back into my code. I'm going to go into the header. And I'm going to say script. I'm going to say source equals. And what I want is the URL to the JavaScript library I want to use, chart.js, which is now, I'm going to paste that right in. And as soon as I close this, Visual Studio Code is doing a nice thing for me. It's closing the script tag automatically. But otherwise, we would have to type that in. So open script tag, source equals this, and the URL, and then close script tag. So now I have chart.js loaded. The next thing I need is I need to have a canvas in my HTML itself. So I need to add a canvas element. I'm going to give it an ID like chart. And I think I also need to give it a width. Let's just try 400 and a height. 400, and those should be in quotes. Thank you, Visual Studio Code, for correcting me when I hit Save. So there you go. So you can now see I've added a canvas. I gave it an ID. And I gave it a width and a height. So somehow, I need to tell this data to graph itself on that canvas. Let's go back to that getting started page. And look, we've got some code. It's given us some code here. This is code for some sort of bar chart with some data. So one way that we could actually start working with this is just let's just copy, paste, and take this code. So when you're working with a new library, you can try a variety of things. You could read through the documentation. You could find an example. For me, this getting started example is going to be perfect to work with. So I'm just going to take this. I'm going to copy it. And I'm going to paste it here at the top of my scripts tag. OK, so there it is. So in theory, when I refresh the page, I should see a chart. No, no, what happened? So we've now encountered something that has to do with the asynchronous events that happen when you load a web page. So it's saying, cannot read property get context of null at index 13. Let's go to index line 13. Document, oh, OK. Actually, this is a different problem. I didn't name my canvas my chart. I named it chart. So let's see if this fixes the error. There is a different error that I thought was happening. But this is clearly an error. The ID of my chart is just chart, not my chart. Oh, there it is. So look, there's the chart. Beautiful. So I have this chart. It's counting votes for different colors. It's got a scale on the y-axis, a scale on the x-axis. And I see my data console logged. How do I get my data onto the chart? Well, let's look at the code and see if we can just do some detective work and figure it out. And if we get stuck, we can refer to the chart.js documentation. So we can see here label. Well, the label that I want is global average temperature. And again, I might need to be a bit more thoughtful about the accuracy of that statement. What is it truly if I look at the NASA data set? But global average temperature will do for now. So let's just change that. And we can see, look, it's showing us the global average temperature. Oh, but these labels, red, blue, yellow, where did those come from? Those are here labels. So I don't want these labels. What I want are the years to be the labels, the years that I'm parsing to be the labels that go across the x-axis. So what if I were to say, first of all, this example is using older JavaScript syntax. By the time you're watching this, it's probably something different. But I'm going to say const instead of var. And I'm going to say const here instead of var, just to update my variable declarations. If you're wondering what const is, I have some other videos about that. Then I am going to create another variable that's just going to call it x labels for the x-axis. And set it equal to a blank array. And I'm going to put that variable referenced here. So the actual labels of my chart are pointing to an array called x labels. And there's no reason why I couldn't, as I'm reading each year, just add each year to that array x labels. So now I have my data parsing. I have my chart creation. So what I want to do is parse all the data and start adding the labels to the chart that's being drawn on the canvas. Let's see what happens there. OK. Don't see any labels. Now I have the other problem that I was thinking would happen, which is I am making the chart first and then loading the data. So this is a problem. Weirdly, by the way, if I just kind of like resize the window, suddenly the data appears. But it should appear when I first load the page. So I've got to do this in a different order. I have this get data function that gets the data asynchronously using await fetch, await response.text. What I want to do now, then, is go up and put this creation of the chart into a separate function. So I'm going to say function chart it. And all of that's going to be in a function. Now, this example that was provided on the chart.js getting started page has a lot of really useful, but for me right now, extra stuff in it. So there are a lot of configuration options, how you can have the chart appear. I'm actually going to just remove those right now. As an exercise for you that I'll suggest at the end is maybe find different ways of drawing the chart by looking up in the documentation. And then also, I'm just going to stick with one color. So I'm going to take all of that out right now. I probably could take out the color entirely. I'm going to hit Save. So you can see at least now in my charted function, there's a little bit less stuff going on. So now I could call this charted function. And if we go back, this is the same thing. I've got the same problem. But oh, x labels is not defined. So I somehow, oh, the x labels variable needs to be a global variable. I actually don't like something about what I'm doing here. So I'm going to do some refactoring as we get to the end to clean up how I'm going to communicate between getting the data and drawing the chart. But for right now, I'm going to make x labels a global variable. I'm going to call the charted function and call the get data function. Still the same problem. Well, you would think, OK, what if I call get data before charted? Still the same problem because remember, get data is asynchronous. So the solution that I want to employ here is make charted an asynchronous function and then actually call get data at the beginning of it. So if I say await get data, now charted is going to wait till the data is done before it does the rest of this stuff. And if we go back, we can see, there we go. You can see all those labels are applied there. Now, this is not real data. This is still the data that's right here. So what I want to do now is let me do constant y temps. So this is the temperatures for the y-axis. And then I'm going to say under data, I'm going to say y temps instead of that dummy data. And then here, when I'm reading each temperature, I'm going to say y temps dot push temp. So now, let's take a look at this. There we go. Now we see the global temperature from 1880 all the way to 2018. Now, what's going on here? Negative 0.20. What are these temperatures? Remember, these are the difference from the global mean between the period of 1951 and 1980. And that global mean can be found on this web page. Here it is, 14 degrees Celsius. So if I wanted to be accurate about what I'm doing here, I'm going to say I want the temperature to be temp plus 14. I just want to add 14 Celsius. I think this is going to cause a problem. Let's see what happens here. Let's go back to my graph. I don't see anything different here. Push temp plus 14. Well, I think what's going on here, if I'm right, we'll find out in a second, is that any time you're doing parsing from a text file, your stuff is still text. It's a string. It doesn't know how to add 14 to a string. I can actually use a function called parse float, which is a global JavaScript function that's available that takes a string and turns it into a number. So now I can actually add the number 14 to the number temp. So now we should see, there we go. We can see this is the actual average temperature from 1880 to 2018. This is a bar chart. I don't think the bar chart is the best way to describe this. It's also kind of funny to me that this one is colored differently. I think that's because I removed the color thing. So let's see if we can fix that. So I have a feeling that if I get rid of the, I'm just guessing. But I have a feeling the chart.js works if I get rid of the color as an array. Yes, it applies the color to everything. And then I can also change this from type to bar to line. And there we go. Now, I don't necessarily want the fill below it. This is a good example of where I need to look up in the documentation, because I have no idea how to turn the fill below the line off. It's probably some parameter that either goes in options or with the data set. Let's see if I can find that on the chart.js website. Here along the side is all of the different things. I think I imagine if I go into line, it's showing me line. Example usage, data set properties, fill. There we go. Fill, these are all these different things I could try. Fill, Boolean, or string, default is true. So I think that means if I add a fill false here as another option in the data sets object, then if I go back here, we can say, yes, no more fill. That looks great. I probably want to think about what this label is to be more accurate. This is pretty important. So how about I say exactly what the data is. So here's the exact data I got. The zonal annual means, the combined land surface, air and sea water surface temperature. So land ocean temperature index. So let's change the label to this in Celsius. And then I have to type that degree symbol. Does anyone know how to type the degree symbol? Apparently, it's option shift 8 to type the degree symbol. I have not actually tried this. Let's see if it works. Yes, there we go. We've got Celsius. And let me go back and we can see. There we go. So now I have my label up there. What I want to do, let me refactor this code a little bit. So I don't really love the use of these global variables here. I think what would make more sense, and there's so many different ways we could do this. But let me just do one way to make it a little simpler. Let me actually have a local variable here, which are both, I'm going to call these x's and y's. And then I'm just going to push the x's here, push the y's here. And then when this is done, I'm going to return an object with x's and y's in it. So the get data function is actually going to return an object with both of those arrays. And so then what I can say here is I can say the data equals await get data. And then here under labels, I want data x's. And here under the data set, I want data y's. So again, I'm not sure this is the best solution. But at least now, the chart it function and the get data function operate independently without sharing a global variable, which could cause some problems later down the road. And we can see this still works just fine. It might be nice to also just add the degree symbol here. I have no idea if that's possible. It's making these labels automatically. So looking again at the documentation, and I did just take a little break to find this in advance. But under here, under axes, under labeling is what I want to do. I want to change the way the labeling of the y-axis works. So if I click here, we can see there are, ah, we can see these are all the possibilities. But actually, this is what I want, custom tick format. So each one of these labels on the left is a tick, like tick, tick, tick, tick, like that. And so what I want to do is I need to add these options back. This is something I removed earlier. So let me add the options back. Under y-axis, under ticks, this is a callback function. This is kind of crazy. So this is an example for including a dollar sign. It's basically saying, here's a function that defines how to label the y-axis. Take the value and turn it into dollar sign plus the value. So what I want to do is take the value and turn it into value plus degrees. And I get rid of this comment. And now I have that configured as part of my chart. And here we are. Look, there you go. Now you can see the degree symbol is there. So let me just spread this back out again. I feel like this whole, the canvas size is weird. So I'm going to make this like 800 by 400. There we go. And then I'm going to get rid of the console. And voila. We have our finished chart that shows the combined land, surface, air, and sea surface water temperature in Celsius averaged from 1880 all the way to 2018. And you can see here, by the way, some very, very good evidence that the Earth is warming. The average temperature over time since 1880 to now is going up. To recap, we have seen how to load tabular data in the form of a comma-separated values file. We've seen a little bit about how to parse that file manually, although ultimately, we might want to use a parsing engine that's going to be able to handle all sorts of errors or things that might come up. Once we have that data, we've seen how to repackage that data for a different library to use it, in this case, chart.js, to apply a chart with that data to the canvas. And we've seen how to adjust a little bit of the sort of styles and layout and format of that chart. So what should you do here? So you've got a number of couple of different options. One exercise is just do exactly the same thing as I have here, but do it with your own data. What's some CSV data that you can find? Another thing that might be fun to try is go and get p5 to p5.js library. Could you draw your own line graph without chart.js, but using this raw drawing functionality of p5.js? I will include a solution to that in this video's description. Another exercise that you might try is actually graph multiple lines on the same chart. In many cases, you want to look at data in comparison to other data. So for example, in that same data file, you get the average temperatures for the northern hemisphere and for the southern hemisphere. So you could graph all three, the global temperature, northern hemisphere, southern hemisphere, all together on that chart with different colors for each line. And I'll include a solution to that also as an exercise. So thank you for watching this video. This concludes the second part of the first module. We've learned about the fetch function with images. And now we've learned about the fetch function with CSVs and also graphing the data with chart.js. In the next project, we're going to look at how to get data from a web API, something that's not a local file, and data that changes every so often. And the data set, the example that I'm going to use is the location, latitude, and longitude of the International Space Station, where it is above the Earth. Then I'm going to show you how to draw its location on a map and refresh its location every so often so that it moves in real time. So that's the last part of this first module of working with data and APIs. And I'll see you in that video. Thanks very much. Thank you.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:32.695048Z",
  "started_at": "2023-09-26T21:14:04.972089Z",
  "completed_at": "2023-09-26T21:19:35.823077Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=5-ptp9tRApM",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 330.850988
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/m6tyfejbv7jtgj2xuiagxmkyii/cancel",
    "get": "https://api.replicate.com/v1/predictions/m6tyfejbv7jtgj2xuiagxmkyii"
  }
}