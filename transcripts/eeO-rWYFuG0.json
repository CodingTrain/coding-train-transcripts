{
  "id": "q4inmobbsog5jkzsrjdvogjzgu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/eeO-rWYFuG0.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/126342 [00:00<?, ?frames/s]\n  2%|▏         | 2892/126342 [00:08<06:08, 334.79frames/s]\n  5%|▍         | 5848/126342 [00:17<06:09, 326.16frames/s]\n  7%|▋         | 8732/126342 [00:24<05:27, 358.64frames/s]\n  9%|▉         | 11548/126342 [00:33<05:31, 346.80frames/s]\n 11%|█▏        | 14404/126342 [00:40<05:12, 358.69frames/s]\n 14%|█▎        | 17172/126342 [00:51<05:38, 322.83frames/s]\n 16%|█▌        | 19908/126342 [00:58<05:10, 342.24frames/s]\n 16%|█▌        | 19908/126342 [01:08<05:10, 342.24frames/s]\n 18%|█▊        | 22868/126342 [01:09<05:28, 314.65frames/s]\n 20%|██        | 25644/126342 [01:17<05:15, 319.67frames/s]\n 23%|██▎       | 28644/126342 [01:26<04:57, 327.87frames/s]\n 25%|██▍       | 31468/126342 [01:33<04:32, 348.79frames/s]\n 27%|██▋       | 34404/126342 [01:41<04:19, 354.08frames/s]\n 30%|██▉       | 37404/126342 [01:48<04:04, 364.18frames/s]\n 32%|███▏      | 40240/126342 [01:58<04:10, 343.94frames/s]\n 34%|███▍      | 43032/126342 [02:05<03:52, 358.23frames/s]\n 36%|███▋      | 45984/126342 [02:11<03:27, 386.60frames/s]\n 38%|███▊      | 48600/126342 [02:20<03:36, 359.22frames/s]\n 41%|████      | 51194/126342 [02:25<03:15, 383.48frames/s]\n 43%|████▎     | 54134/126342 [02:33<03:06, 388.14frames/s]\n 45%|████▌     | 56918/126342 [02:42<03:15, 355.44frames/s]\n 47%|████▋     | 59782/126342 [02:52<03:18, 334.81frames/s]\n 50%|████▉     | 62726/126342 [02:58<02:54, 363.67frames/s]\n 52%|█████▏    | 65576/126342 [03:07<02:53, 350.56frames/s]\n 54%|█████▍    | 68444/126342 [03:14<02:40, 360.58frames/s]\n 57%|█████▋    | 71384/126342 [03:23<02:33, 358.81frames/s]\n 59%|█████▉    | 74368/126342 [03:33<02:36, 331.21frames/s]\n 61%|██████    | 77330/126342 [03:40<02:18, 353.03frames/s]\n 64%|██████▎   | 80288/126342 [03:48<02:06, 364.88frames/s]\n 66%|██████▌   | 83220/126342 [03:58<02:05, 342.64frames/s]\n 68%|██████▊   | 86202/126342 [04:06<01:54, 351.73frames/s]\n 70%|███████   | 88960/126342 [04:14<01:48, 343.34frames/s]\n 72%|███████▏  | 91582/126342 [04:21<01:39, 350.77frames/s]\n 75%|███████▍  | 94150/126342 [04:28<01:29, 358.69frames/s]\n 76%|███████▋  | 96438/126342 [04:34<01:21, 366.18frames/s]\n 78%|███████▊  | 99062/126342 [04:38<01:05, 415.40frames/s]\n 81%|████████  | 102062/126342 [04:46<00:59, 406.83frames/s]\n 83%|████████▎ | 105062/126342 [04:52<00:48, 434.67frames/s]\n 85%|████████▌ | 107902/126342 [05:00<00:45, 400.98frames/s]\n 88%|████████▊ | 110782/126342 [05:09<00:41, 379.47frames/s]\n 90%|█████████ | 113754/126342 [05:18<00:34, 363.54frames/s]\n 92%|█████████▏| 116554/126342 [05:25<00:26, 371.62frames/s]\n 95%|█████████▍| 119526/126342 [05:34<00:19, 351.94frames/s]\n 97%|█████████▋| 122450/126342 [05:44<00:11, 333.89frames/s]\n 99%|█████████▉| 125402/126342 [05:57<00:03, 292.30frames/s]\n 99%|█████████▉| 125402/126342 [06:08<00:03, 292.30frames/s]\n100%|██████████| 126342/126342 [06:38<00:00, 119.90frames/s]\n100%|██████████| 126342/126342 [06:38<00:00, 316.90frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 2.52,
        "id": 0,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Okay, it is time now.",
        "tokens": [
          50364,
          1033,
          11,
          309,
          307,
          565,
          586,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 7.04,
        "id": 1,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 2.52,
        "temperature": 0,
        "text": " I am going to build a image classifier",
        "tokens": [
          50490,
          286,
          669,
          516,
          281,
          1322,
          257,
          3256,
          1508,
          9902,
          50716
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 7.96,
        "id": 2,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 7.04,
        "temperature": 0,
        "text": " using my own images.",
        "tokens": [
          50716,
          1228,
          452,
          1065,
          5267,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 10.52,
        "id": 3,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 7.96,
        "temperature": 0,
        "text": " I am going to teach this example",
        "tokens": [
          50762,
          286,
          669,
          516,
          281,
          2924,
          341,
          1365,
          50890
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 12.6,
        "id": 4,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 10.52,
        "temperature": 0,
        "text": " to not say acoustic guitar or electric guitar,",
        "tokens": [
          50890,
          281,
          406,
          584,
          26753,
          7531,
          420,
          5210,
          7531,
          11,
          50994
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 13.96,
        "id": 5,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 12.6,
        "temperature": 0,
        "text": " but to say ukulele.",
        "tokens": [
          50994,
          457,
          281,
          584,
          26769,
          2271,
          306,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 18.400000000000002,
        "id": 6,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 13.96,
        "temperature": 0,
        "text": " I'm going to teach this example not to say syringe,",
        "tokens": [
          51062,
          286,
          478,
          516,
          281,
          2924,
          341,
          1365,
          406,
          281,
          584,
          943,
          38895,
          11,
          51284
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 20.240000000000002,
        "id": 7,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 18.400000000000002,
        "temperature": 0,
        "text": " but to say train whistle, okay?",
        "tokens": [
          51284,
          457,
          281,
          584,
          3847,
          23470,
          11,
          1392,
          30,
          51376
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 21.080000000000002,
        "id": 8,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 20.240000000000002,
        "temperature": 0,
        "text": " This is what we're going to do,",
        "tokens": [
          51376,
          639,
          307,
          437,
          321,
          434,
          516,
          281,
          360,
          11,
          51418
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 24.44,
        "id": 9,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 21.080000000000002,
        "temperature": 0,
        "text": " and the process that I'm going to use is transfer learning.",
        "tokens": [
          51418,
          293,
          264,
          1399,
          300,
          286,
          478,
          516,
          281,
          764,
          307,
          5003,
          2539,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 27.240000000000002,
        "id": 10,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 24.44,
        "temperature": 0,
        "text": " I described this process in the previous video.",
        "tokens": [
          51586,
          286,
          7619,
          341,
          1399,
          294,
          264,
          3894,
          960,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.22508948189871653,
        "compression_ratio": 1.8252032520325203,
        "end": 28.92,
        "id": 11,
        "no_speech_prob": 0.005138821434229612,
        "seek": 0,
        "start": 27.240000000000002,
        "temperature": 0,
        "text": " You can go back and watch that if you want,",
        "tokens": [
          51726,
          509,
          393,
          352,
          646,
          293,
          1159,
          300,
          498,
          291,
          528,
          11,
          51810
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 30.44,
        "id": 12,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 28.92,
        "temperature": 0,
        "text": " or you can just keep following with me.",
        "tokens": [
          50364,
          420,
          291,
          393,
          445,
          1066,
          3480,
          365,
          385,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 31.64,
        "id": 13,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 30.44,
        "temperature": 0,
        "text": " I'm going to write the code for this.",
        "tokens": [
          50440,
          286,
          478,
          516,
          281,
          2464,
          264,
          3089,
          337,
          341,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 33.92,
        "id": 14,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 31.64,
        "temperature": 0,
        "text": " One thing that I want to mention is,",
        "tokens": [
          50500,
          1485,
          551,
          300,
          286,
          528,
          281,
          2152,
          307,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 34.760000000000005,
        "id": 15,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 33.92,
        "temperature": 0,
        "text": " you might be wondering,",
        "tokens": [
          50614,
          291,
          1062,
          312,
          6359,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 37.72,
        "id": 16,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 34.760000000000005,
        "temperature": 0,
        "text": " oh, why is it called a feature extractor?",
        "tokens": [
          50656,
          1954,
          11,
          983,
          307,
          309,
          1219,
          257,
          4111,
          8947,
          284,
          30,
          50804
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 40.08,
        "id": 17,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 37.72,
        "temperature": 0,
        "text": " How does this stuff happen?",
        "tokens": [
          50804,
          1012,
          775,
          341,
          1507,
          1051,
          30,
          50922
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 42.52,
        "id": 18,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 40.08,
        "temperature": 0,
        "text": " So I want to first mention and thank Gene Kogan",
        "tokens": [
          50922,
          407,
          286,
          528,
          281,
          700,
          2152,
          293,
          1309,
          18083,
          591,
          21576,
          51044
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 44.64,
        "id": 19,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 42.52,
        "temperature": 0,
        "text": " for making the image classification",
        "tokens": [
          51044,
          337,
          1455,
          264,
          3256,
          21538,
          51150
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 47.56,
        "id": 20,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 44.64,
        "temperature": 0,
        "text": " and regression transfer learning with MobileNet examples.",
        "tokens": [
          51150,
          293,
          24590,
          5003,
          2539,
          365,
          22625,
          31890,
          5110,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 51.06,
        "id": 21,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 47.56,
        "temperature": 0,
        "text": " You can find these native TensorFlow.js versions",
        "tokens": [
          51296,
          509,
          393,
          915,
          613,
          8470,
          37624,
          13,
          25530,
          9606,
          51471
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 54.400000000000006,
        "id": 22,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 51.06,
        "temperature": 0,
        "text": " of what I'm doing right now here at the ML4A,",
        "tokens": [
          51471,
          295,
          437,
          286,
          478,
          884,
          558,
          586,
          510,
          412,
          264,
          21601,
          19,
          32,
          11,
          51638
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 56.64,
        "id": 23,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 54.400000000000006,
        "temperature": 0,
        "text": " Machine Learning for Artists website.",
        "tokens": [
          51638,
          22155,
          15205,
          337,
          5735,
          1751,
          3144,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.2542084707340724,
        "compression_ratio": 1.633846153846154,
        "end": 58.480000000000004,
        "id": 24,
        "no_speech_prob": 0.00008887823059922084,
        "seek": 2892,
        "start": 56.64,
        "temperature": 0,
        "text": " It's a wonderful website with tons of resources",
        "tokens": [
          51750,
          467,
          311,
          257,
          3715,
          3144,
          365,
          9131,
          295,
          3593,
          51842
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 59.559999999999995,
        "id": 25,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 58.48,
        "temperature": 0,
        "text": " about machine learning,",
        "tokens": [
          50364,
          466,
          3479,
          2539,
          11,
          50418
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 60.919999999999995,
        "id": 26,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 59.559999999999995,
        "temperature": 0,
        "text": " and also, it's an interesting,",
        "tokens": [
          50418,
          293,
          611,
          11,
          309,
          311,
          364,
          1880,
          11,
          50486
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 63.239999999999995,
        "id": 27,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 60.919999999999995,
        "temperature": 0,
        "text": " the whole discussion here in terms of,",
        "tokens": [
          50486,
          264,
          1379,
          5017,
          510,
          294,
          2115,
          295,
          11,
          50602
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 65.03999999999999,
        "id": 28,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 63.239999999999995,
        "temperature": 0,
        "text": " how should the ML5 API work,",
        "tokens": [
          50602,
          577,
          820,
          264,
          21601,
          20,
          9362,
          589,
          11,
          50692
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 66.32,
        "id": 29,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 65.03999999999999,
        "temperature": 0,
        "text": " or what should things be called?",
        "tokens": [
          50692,
          420,
          437,
          820,
          721,
          312,
          1219,
          30,
          50756
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 68.67999999999999,
        "id": 30,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 66.32,
        "temperature": 0,
        "text": " So if you're curious about how open source projects",
        "tokens": [
          50756,
          407,
          498,
          291,
          434,
          6369,
          466,
          577,
          1269,
          4009,
          4455,
          50874
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 71.44,
        "id": 31,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 68.67999999999999,
        "temperature": 0,
        "text": " choose their names of things,",
        "tokens": [
          50874,
          2826,
          641,
          5288,
          295,
          721,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 74.28,
        "id": 32,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 71.44,
        "temperature": 0,
        "text": " I might reference this particular thread.",
        "tokens": [
          51012,
          286,
          1062,
          6408,
          341,
          1729,
          7207,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 77.24,
        "id": 33,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 74.28,
        "temperature": 0,
        "text": " But the important piece for us",
        "tokens": [
          51154,
          583,
          264,
          1021,
          2522,
          337,
          505,
          51302
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 79.75999999999999,
        "id": 34,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 77.24,
        "temperature": 0,
        "text": " is to be at the ML5 website",
        "tokens": [
          51302,
          307,
          281,
          312,
          412,
          264,
          21601,
          20,
          3144,
          51428
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 83.08,
        "id": 35,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 79.75999999999999,
        "temperature": 0,
        "text": " on the feature extractor documentation page.",
        "tokens": [
          51428,
          322,
          264,
          4111,
          8947,
          284,
          14333,
          3028,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 84.8,
        "id": 36,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 83.08,
        "temperature": 0,
        "text": " I'm going to need to make heavy use of this page",
        "tokens": [
          51594,
          286,
          478,
          516,
          281,
          643,
          281,
          652,
          4676,
          764,
          295,
          341,
          3028,
          51680
        ]
      },
      {
        "avg_logprob": -0.2489286862886869,
        "compression_ratio": 1.6182432432432432,
        "end": 87.32,
        "id": 37,
        "no_speech_prob": 0.00005307481478666887,
        "seek": 5848,
        "start": 84.8,
        "temperature": 0,
        "text": " to look up what the names of all the functions",
        "tokens": [
          51680,
          281,
          574,
          493,
          437,
          264,
          5288,
          295,
          439,
          264,
          6828,
          51806
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 88.67999999999999,
        "id": 38,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 87.32,
        "temperature": 0,
        "text": " I need to type are in.",
        "tokens": [
          50364,
          286,
          643,
          281,
          2010,
          366,
          294,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 90.11999999999999,
        "id": 39,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 88.67999999999999,
        "temperature": 0,
        "text": " And then, of course, I should mention,",
        "tokens": [
          50432,
          400,
          550,
          11,
          295,
          1164,
          11,
          286,
          820,
          2152,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 92.19999999999999,
        "id": 40,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 90.11999999999999,
        "temperature": 0,
        "text": " if I just go down here to under examples,",
        "tokens": [
          50504,
          498,
          286,
          445,
          352,
          760,
          510,
          281,
          833,
          5110,
          11,
          50608
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 93.96,
        "id": 41,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 92.19999999999999,
        "temperature": 0,
        "text": " classifier with feature extractor,",
        "tokens": [
          50608,
          1508,
          9902,
          365,
          4111,
          8947,
          284,
          11,
          50696
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 95.67999999999999,
        "id": 42,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 93.96,
        "temperature": 0,
        "text": " this is basically what I'm going to build.",
        "tokens": [
          50696,
          341,
          307,
          1936,
          437,
          286,
          478,
          516,
          281,
          1322,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 100.52,
        "id": 43,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 95.67999999999999,
        "temperature": 0,
        "text": " But the point of this video is I'm going to build it up,",
        "tokens": [
          50782,
          583,
          264,
          935,
          295,
          341,
          960,
          307,
          286,
          478,
          516,
          281,
          1322,
          309,
          493,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 103.24,
        "id": 44,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 100.52,
        "temperature": 0,
        "text": " but you could just look at this example instead if you want.",
        "tokens": [
          51024,
          457,
          291,
          727,
          445,
          574,
          412,
          341,
          1365,
          2602,
          498,
          291,
          528,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 106.24,
        "id": 45,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 103.24,
        "temperature": 0,
        "text": " But anyway, all right, so let's go back to,",
        "tokens": [
          51160,
          583,
          4033,
          11,
          439,
          558,
          11,
          370,
          718,
          311,
          352,
          646,
          281,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 109.58,
        "id": 46,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 106.24,
        "temperature": 0,
        "text": " let's go back to the feature extractor documentation page.",
        "tokens": [
          51310,
          718,
          311,
          352,
          646,
          281,
          264,
          4111,
          8947,
          284,
          14333,
          3028,
          13,
          51477
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 112.67999999999999,
        "id": 47,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 109.58,
        "temperature": 0,
        "text": " What I've got here is the code that I wrote",
        "tokens": [
          51477,
          708,
          286,
          600,
          658,
          510,
          307,
          264,
          3089,
          300,
          286,
          4114,
          51632
        ]
      },
      {
        "avg_logprob": -0.21824136922057247,
        "compression_ratio": 1.7625899280575539,
        "end": 115.47999999999999,
        "id": 48,
        "no_speech_prob": 0.0000630274589639157,
        "seek": 8732,
        "start": 112.67999999999999,
        "temperature": 0,
        "text": " from a previous video, a couple videos ago,",
        "tokens": [
          51632,
          490,
          257,
          3894,
          960,
          11,
          257,
          1916,
          2145,
          2057,
          11,
          51772
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 116.8,
        "id": 49,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 115.48,
        "temperature": 0,
        "text": " using the MobileNet model",
        "tokens": [
          50364,
          1228,
          264,
          22625,
          31890,
          2316,
          50430
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 119.2,
        "id": 50,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 116.8,
        "temperature": 0,
        "text": " to classify images from the webcam.",
        "tokens": [
          50430,
          281,
          33872,
          5267,
          490,
          264,
          39490,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 121.5,
        "id": 51,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 119.2,
        "temperature": 0,
        "text": " Okay, so if I go to the code,",
        "tokens": [
          50550,
          1033,
          11,
          370,
          498,
          286,
          352,
          281,
          264,
          3089,
          11,
          50665
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 123.32000000000001,
        "id": 52,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 121.5,
        "temperature": 0,
        "text": " the main thing that I need to change",
        "tokens": [
          50665,
          264,
          2135,
          551,
          300,
          286,
          643,
          281,
          1319,
          50756
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 126.80000000000001,
        "id": 53,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 123.32000000000001,
        "temperature": 0,
        "text": " is I no longer want to make an ML5 image classifier.",
        "tokens": [
          50756,
          307,
          286,
          572,
          2854,
          528,
          281,
          652,
          364,
          21601,
          20,
          3256,
          1508,
          9902,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 131.8,
        "id": 54,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 126.80000000000001,
        "temperature": 0,
        "text": " I want to make an ML5 feature extractor.",
        "tokens": [
          50930,
          286,
          528,
          281,
          652,
          364,
          21601,
          20,
          4111,
          8947,
          284,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 135.2,
        "id": 55,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 132.88,
        "temperature": 0,
        "text": " And there, and the difference here also",
        "tokens": [
          51234,
          400,
          456,
          11,
          293,
          264,
          2649,
          510,
          611,
          51350
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 138.16,
        "id": 56,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 135.2,
        "temperature": 0,
        "text": " is I'm not going to reference the video yet.",
        "tokens": [
          51350,
          307,
          286,
          478,
          406,
          516,
          281,
          6408,
          264,
          960,
          1939,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 140.64000000000001,
        "id": 57,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 138.16,
        "temperature": 0,
        "text": " So I'm just going to make a feature extractor",
        "tokens": [
          51498,
          407,
          286,
          478,
          445,
          516,
          281,
          652,
          257,
          4111,
          8947,
          284,
          51622
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 142.16,
        "id": 58,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 140.64000000000001,
        "temperature": 0,
        "text": " built on top of MobileNet,",
        "tokens": [
          51622,
          3094,
          322,
          1192,
          295,
          22625,
          31890,
          11,
          51698
        ]
      },
      {
        "avg_logprob": -0.1663563681430504,
        "compression_ratio": 1.759656652360515,
        "end": 144.04000000000002,
        "id": 59,
        "no_speech_prob": 0.00000165368908255914,
        "seek": 11548,
        "start": 142.16,
        "temperature": 0,
        "text": " and this callback model ready",
        "tokens": [
          51698,
          293,
          341,
          818,
          3207,
          2316,
          1919,
          51792
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 145.88,
        "id": 60,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 144.04,
        "temperature": 0,
        "text": " means the model has been loaded,",
        "tokens": [
          50364,
          1355,
          264,
          2316,
          575,
          668,
          13210,
          11,
          50456
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 147.64,
        "id": 61,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 145.88,
        "temperature": 0,
        "text": " the MobileNet model was downloaded",
        "tokens": [
          50456,
          264,
          22625,
          31890,
          2316,
          390,
          21748,
          50544
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 149.67999999999998,
        "id": 62,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 147.64,
        "temperature": 0,
        "text": " from wherever it needed to download it from,",
        "tokens": [
          50544,
          490,
          8660,
          309,
          2978,
          281,
          5484,
          309,
          490,
          11,
          50646
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 153,
        "id": 63,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 149.67999999999998,
        "temperature": 0,
        "text": " and it's there and ready to go, okay?",
        "tokens": [
          50646,
          293,
          309,
          311,
          456,
          293,
          1919,
          281,
          352,
          11,
          1392,
          30,
          50812
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 154.79999999999998,
        "id": 64,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 153,
        "temperature": 0,
        "text": " So this should say model is ready,",
        "tokens": [
          50812,
          407,
          341,
          820,
          584,
          2316,
          307,
          1919,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 156.5,
        "id": 65,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 154.79999999999998,
        "temperature": 0,
        "text": " I'm going to get rid of this predict function.",
        "tokens": [
          50902,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          341,
          6069,
          2445,
          13,
          50987
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 158.28,
        "id": 66,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 156.5,
        "temperature": 0,
        "text": " So now if we just refresh this,",
        "tokens": [
          50987,
          407,
          586,
          498,
          321,
          445,
          15134,
          341,
          11,
          51076
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 159.92,
        "id": 67,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 158.28,
        "temperature": 0,
        "text": " I mean, a lot of stuff's going to break here,",
        "tokens": [
          51076,
          286,
          914,
          11,
          257,
          688,
          295,
          1507,
          311,
          516,
          281,
          1821,
          510,
          11,
          51158
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 162.07999999999998,
        "id": 68,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 159.92,
        "temperature": 0,
        "text": " but I see model is ready, and the video appears.",
        "tokens": [
          51158,
          457,
          286,
          536,
          2316,
          307,
          1919,
          11,
          293,
          264,
          960,
          7038,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 163.28,
        "id": 69,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 162.07999999999998,
        "temperature": 0,
        "text": " Now there's no labels anymore",
        "tokens": [
          51266,
          823,
          456,
          311,
          572,
          16949,
          3602,
          51326
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 165,
        "id": 70,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 163.28,
        "temperature": 0,
        "text": " because I got rid of the image classifier.",
        "tokens": [
          51326,
          570,
          286,
          658,
          3973,
          295,
          264,
          3256,
          1508,
          9902,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 166.92,
        "id": 71,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 165,
        "temperature": 0,
        "text": " I have a feature extractor now.",
        "tokens": [
          51412,
          286,
          362,
          257,
          4111,
          8947,
          284,
          586,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 168.6,
        "id": 72,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 166.92,
        "temperature": 0,
        "text": " But I want an image classifier.",
        "tokens": [
          51508,
          583,
          286,
          528,
          364,
          3256,
          1508,
          9902,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.18642402887344361,
        "compression_ratio": 1.7973421926910298,
        "end": 171.72,
        "id": 73,
        "no_speech_prob": 0.000013211936675361358,
        "seek": 14404,
        "start": 168.6,
        "temperature": 0,
        "text": " So what I do is I'm going to add a variable.",
        "tokens": [
          51592,
          407,
          437,
          286,
          360,
          307,
          286,
          478,
          516,
          281,
          909,
          257,
          7006,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 174.04,
        "id": 74,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 171.92,
        "temperature": 0,
        "text": " I'm going to write a variable called classifier.",
        "tokens": [
          50374,
          286,
          478,
          516,
          281,
          2464,
          257,
          7006,
          1219,
          1508,
          9902,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 176.28,
        "id": 75,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 174.04,
        "temperature": 0,
        "text": " So MobileNet, the variable MobileNet",
        "tokens": [
          50480,
          407,
          22625,
          31890,
          11,
          264,
          7006,
          22625,
          31890,
          50592
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 178.8,
        "id": 76,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 176.28,
        "temperature": 0,
        "text": " is now referring to the feature extractor,",
        "tokens": [
          50592,
          307,
          586,
          13761,
          281,
          264,
          4111,
          8947,
          284,
          11,
          50718
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 183.04,
        "id": 77,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 178.8,
        "temperature": 0,
        "text": " and the classifier equals MobileNet,",
        "tokens": [
          50718,
          293,
          264,
          1508,
          9902,
          6915,
          22625,
          31890,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 185.78,
        "id": 78,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 183.04,
        "temperature": 0,
        "text": " the feature extractor dot classification.",
        "tokens": [
          50930,
          264,
          4111,
          8947,
          284,
          5893,
          21538,
          13,
          51067
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 190.56,
        "id": 79,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 186.64,
        "temperature": 0,
        "text": " So I want to make a class, classification.",
        "tokens": [
          51110,
          407,
          286,
          528,
          281,
          652,
          257,
          1508,
          11,
          21538,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 194.04,
        "id": 80,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 190.56,
        "temperature": 0,
        "text": " I want to make a classification object",
        "tokens": [
          51306,
          286,
          528,
          281,
          652,
          257,
          21538,
          2657,
          51480
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 196.96,
        "id": 81,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 194.04,
        "temperature": 0,
        "text": " from the feature extractor, and I need to give that,",
        "tokens": [
          51480,
          490,
          264,
          4111,
          8947,
          284,
          11,
          293,
          286,
          643,
          281,
          976,
          300,
          11,
          51626
        ]
      },
      {
        "avg_logprob": -0.2239657861215097,
        "compression_ratio": 2.105820105820106,
        "end": 199.07999999999998,
        "id": 82,
        "no_speech_prob": 0.00003071813262067735,
        "seek": 17172,
        "start": 196.96,
        "temperature": 0,
        "text": " I want to say, and I want to use images from the video.",
        "tokens": [
          51626,
          286,
          528,
          281,
          584,
          11,
          293,
          286,
          528,
          281,
          764,
          5267,
          490,
          264,
          960,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 201.12,
        "id": 83,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 199.52,
        "temperature": 0,
        "text": " And again, if I were doing this",
        "tokens": [
          50386,
          400,
          797,
          11,
          498,
          286,
          645,
          884,
          341,
          50466
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 204.14000000000001,
        "id": 84,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 201.12,
        "temperature": 0,
        "text": " with a database of JPEGs that I'm loading or something else,",
        "tokens": [
          50466,
          365,
          257,
          8149,
          295,
          508,
          5208,
          33715,
          300,
          286,
          478,
          15114,
          420,
          746,
          1646,
          11,
          50617
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 205.32000000000002,
        "id": 85,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 204.14000000000001,
        "temperature": 0,
        "text": " I would do it in a different way,",
        "tokens": [
          50617,
          286,
          576,
          360,
          309,
          294,
          257,
          819,
          636,
          11,
          50676
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 207.12,
        "id": 86,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 205.32000000000002,
        "temperature": 0,
        "text": " but I'm going to use the video in this example.",
        "tokens": [
          50676,
          457,
          286,
          478,
          516,
          281,
          764,
          264,
          960,
          294,
          341,
          1365,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 208.36,
        "id": 87,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 207.12,
        "temperature": 0,
        "text": " So I'm going to say video,",
        "tokens": [
          50766,
          407,
          286,
          478,
          516,
          281,
          584,
          960,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 210.18,
        "id": 88,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 208.36,
        "temperature": 0,
        "text": " and then I'm going to say video ready,",
        "tokens": [
          50828,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          960,
          1919,
          11,
          50919
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 211.86,
        "id": 89,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 210.18,
        "temperature": 0,
        "text": " because I want to have a callback also",
        "tokens": [
          50919,
          570,
          286,
          528,
          281,
          362,
          257,
          818,
          3207,
          611,
          51003
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 214.18,
        "id": 90,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 211.86,
        "temperature": 0,
        "text": " to know that the video is ready.",
        "tokens": [
          51003,
          281,
          458,
          300,
          264,
          960,
          307,
          1919,
          13,
          51119
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 217.48000000000002,
        "id": 91,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 214.18,
        "temperature": 0,
        "text": " I don't really need that callback, but it's sort of useful.",
        "tokens": [
          51119,
          286,
          500,
          380,
          534,
          643,
          300,
          818,
          3207,
          11,
          457,
          309,
          311,
          1333,
          295,
          4420,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 220.68,
        "id": 92,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 217.48000000000002,
        "temperature": 0,
        "text": " I'm going to write that up here, video ready,",
        "tokens": [
          51284,
          286,
          478,
          516,
          281,
          2464,
          300,
          493,
          510,
          11,
          960,
          1919,
          11,
          51444
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 222.56,
        "id": 93,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 220.68,
        "temperature": 0,
        "text": " and I'm going to say a video is ready.",
        "tokens": [
          51444,
          293,
          286,
          478,
          516,
          281,
          584,
          257,
          960,
          307,
          1919,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 224.28,
        "id": 94,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 222.56,
        "temperature": 0,
        "text": " So let's refresh this again,",
        "tokens": [
          51538,
          407,
          718,
          311,
          15134,
          341,
          797,
          11,
          51624
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 227.28,
        "id": 95,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 224.28,
        "temperature": 0,
        "text": " and we should see my image pop up.",
        "tokens": [
          51624,
          293,
          321,
          820,
          536,
          452,
          3256,
          1665,
          493,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.19550429942996003,
        "compression_ratio": 1.9401408450704225,
        "end": 228.68,
        "id": 96,
        "no_speech_prob": 0.000006048911018297076,
        "seek": 19908,
        "start": 227.28,
        "temperature": 0,
        "text": " Model's ready, video's ready.",
        "tokens": [
          51774,
          17105,
          311,
          1919,
          11,
          960,
          311,
          1919,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 234.16,
        "id": 97,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 229.16,
        "temperature": 0,
        "text": " Now, we are ready to train our own labels.",
        "tokens": [
          50388,
          823,
          11,
          321,
          366,
          1919,
          281,
          3847,
          527,
          1065,
          16949,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 237.8,
        "id": 98,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 235.4,
        "temperature": 0,
        "text": " We have the feature extractor, we have the classifier,",
        "tokens": [
          50700,
          492,
          362,
          264,
          4111,
          8947,
          284,
          11,
          321,
          362,
          264,
          1508,
          9902,
          11,
          50820
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 241.44,
        "id": 99,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 237.8,
        "temperature": 0,
        "text": " we can give it images of a ukulele.",
        "tokens": [
          50820,
          321,
          393,
          976,
          309,
          5267,
          295,
          257,
          26769,
          2271,
          306,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 243.1,
        "id": 100,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 241.44,
        "temperature": 0,
        "text": " I don't know if I wrote this on the board",
        "tokens": [
          51002,
          286,
          500,
          380,
          458,
          498,
          286,
          4114,
          341,
          322,
          264,
          3150,
          51085
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 244.42000000000002,
        "id": 101,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 243.1,
        "temperature": 0,
        "text": " just now or earlier or when,",
        "tokens": [
          51085,
          445,
          586,
          420,
          3071,
          420,
          562,
          11,
          51151
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 246,
        "id": 102,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 244.42000000000002,
        "temperature": 0,
        "text": " but I used to have ukulele spelled wrong.",
        "tokens": [
          51151,
          457,
          286,
          1143,
          281,
          362,
          26769,
          2271,
          306,
          34388,
          2085,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 249.76000000000002,
        "id": 103,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 246,
        "temperature": 0,
        "text": " It's spelled U-K-U-L-E-L-E.",
        "tokens": [
          51230,
          467,
          311,
          34388,
          624,
          12,
          42,
          12,
          52,
          12,
          43,
          12,
          36,
          12,
          43,
          12,
          36,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 250.8,
        "id": 104,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 249.76000000000002,
        "temperature": 0,
        "text": " I don't know why, but I feel like",
        "tokens": [
          51418,
          286,
          500,
          380,
          458,
          983,
          11,
          457,
          286,
          841,
          411,
          51470
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 253.48000000000002,
        "id": 105,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 250.8,
        "temperature": 0,
        "text": " that's very important to say right now.",
        "tokens": [
          51470,
          300,
          311,
          588,
          1021,
          281,
          584,
          558,
          586,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.21870707726293756,
        "compression_ratio": 1.5836909871244635,
        "end": 256.44,
        "id": 106,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 22868,
        "start": 253.48000000000002,
        "temperature": 0,
        "text": " So how do I do that?",
        "tokens": [
          51604,
          407,
          577,
          360,
          286,
          360,
          300,
          30,
          51752
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 260.74,
        "id": 107,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 256.44,
        "temperature": 0,
        "text": " Well, I could look up in the feature extractor page.",
        "tokens": [
          50364,
          1042,
          11,
          286,
          727,
          574,
          493,
          294,
          264,
          4111,
          8947,
          284,
          3028,
          13,
          50579
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 265.12,
        "id": 108,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 260.74,
        "temperature": 0,
        "text": " There's a function called add image, and it's right here.",
        "tokens": [
          50579,
          821,
          311,
          257,
          2445,
          1219,
          909,
          3256,
          11,
          293,
          309,
          311,
          558,
          510,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 267.5,
        "id": 109,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 265.12,
        "temperature": 0,
        "text": " So I know some of this API",
        "tokens": [
          50798,
          407,
          286,
          458,
          512,
          295,
          341,
          9362,
          50917
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 269.08,
        "id": 110,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 267.5,
        "temperature": 0,
        "text": " from having practiced this a little bit,",
        "tokens": [
          50917,
          490,
          1419,
          19268,
          341,
          257,
          707,
          857,
          11,
          50996
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 271,
        "id": 111,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 269.08,
        "temperature": 0,
        "text": " but this is what I'm looking for, add image.",
        "tokens": [
          50996,
          457,
          341,
          307,
          437,
          286,
          478,
          1237,
          337,
          11,
          909,
          3256,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 272.78,
        "id": 112,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 271,
        "temperature": 0,
        "text": " What image, add image and a label.",
        "tokens": [
          51092,
          708,
          3256,
          11,
          909,
          3256,
          293,
          257,
          7645,
          13,
          51181
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 276.15999999999997,
        "id": 113,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 272.78,
        "temperature": 0,
        "text": " So I can say, oh, but when do I want to add an image?",
        "tokens": [
          51181,
          407,
          286,
          393,
          584,
          11,
          1954,
          11,
          457,
          562,
          360,
          286,
          528,
          281,
          909,
          364,
          3256,
          30,
          51350
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 279.56,
        "id": 114,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 276.15999999999997,
        "temperature": 0,
        "text": " I want to make a button that every time I press the button,",
        "tokens": [
          51350,
          286,
          528,
          281,
          652,
          257,
          2960,
          300,
          633,
          565,
          286,
          1886,
          264,
          2960,
          11,
          51520
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 282.92,
        "id": 115,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 281.04,
        "temperature": 0,
        "text": " I'm saying that's a ukulele image.",
        "tokens": [
          51594,
          286,
          478,
          1566,
          300,
          311,
          257,
          26769,
          2271,
          306,
          3256,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.2233439894283519,
        "compression_ratio": 1.678030303030303,
        "end": 286.04,
        "id": 116,
        "no_speech_prob": 0.0000014144748092803638,
        "seek": 25644,
        "start": 282.92,
        "temperature": 0,
        "text": " So let's first create a uke button.",
        "tokens": [
          51688,
          407,
          718,
          311,
          700,
          1884,
          257,
          344,
          330,
          2960,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 288.86,
        "id": 117,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 286.8,
        "temperature": 0,
        "text": " And then I'm going to say in setup,",
        "tokens": [
          50382,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          294,
          8657,
          11,
          50485
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 295.16,
        "id": 118,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 290.16,
        "temperature": 0,
        "text": " uke button equals create button ukulele.",
        "tokens": [
          50550,
          344,
          330,
          2960,
          6915,
          1884,
          2960,
          26769,
          2271,
          306,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 299.68,
        "id": 119,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 297.8,
        "temperature": 0,
        "text": " But if it's uke, it's just U-K-E.",
        "tokens": [
          50932,
          583,
          498,
          309,
          311,
          344,
          330,
          11,
          309,
          311,
          445,
          624,
          12,
          42,
          12,
          36,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 300.68,
        "id": 120,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 299.68,
        "temperature": 0,
        "text": " Boy, it's confusing.",
        "tokens": [
          51026,
          9486,
          11,
          309,
          311,
          13181,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 302.08,
        "id": 121,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 300.68,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          51076,
          823,
          510,
          311,
          264,
          551,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 306.1,
        "id": 122,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 302.08,
        "temperature": 0,
        "text": " I am creating this example in a very basic,",
        "tokens": [
          51146,
          286,
          669,
          4084,
          341,
          1365,
          294,
          257,
          588,
          3875,
          11,
          51347
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 308.5,
        "id": 123,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 306.1,
        "temperature": 0,
        "text": " what I hope is beginner-friendly way.",
        "tokens": [
          51347,
          437,
          286,
          1454,
          307,
          22080,
          12,
          22864,
          636,
          13,
          51467
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 311.76,
        "id": 124,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 308.5,
        "temperature": 0,
        "text": " There are so many ways you can build an interface",
        "tokens": [
          51467,
          821,
          366,
          370,
          867,
          2098,
          291,
          393,
          1322,
          364,
          9226,
          51630
        ]
      },
      {
        "avg_logprob": -0.24172366914295015,
        "compression_ratio": 1.4727272727272727,
        "end": 314.68,
        "id": 125,
        "no_speech_prob": 0.0000022252795588428853,
        "seek": 28644,
        "start": 311.76,
        "temperature": 0,
        "text": " and style your page and handle events.",
        "tokens": [
          51630,
          293,
          3758,
          428,
          3028,
          293,
          4813,
          3931,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 317.40000000000003,
        "id": 126,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 314.96,
        "temperature": 0,
        "text": " I'm just going to use sort of simple P5 functions",
        "tokens": [
          50378,
          286,
          478,
          445,
          516,
          281,
          764,
          1333,
          295,
          2199,
          430,
          20,
          6828,
          50500
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 319.16,
        "id": 127,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 317.40000000000003,
        "temperature": 0,
        "text": " that place a button on the page",
        "tokens": [
          50500,
          300,
          1081,
          257,
          2960,
          322,
          264,
          3028,
          50588
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 322.36,
        "id": 128,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 319.16,
        "temperature": 0,
        "text": " and a simple callback function for when I press the button.",
        "tokens": [
          50588,
          293,
          257,
          2199,
          818,
          3207,
          2445,
          337,
          562,
          286,
          1886,
          264,
          2960,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 326.68,
        "id": 129,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 324.52,
        "temperature": 0,
        "text": " So then I'm going to say uke pressed mouse pressed.",
        "tokens": [
          50856,
          407,
          550,
          286,
          478,
          516,
          281,
          584,
          344,
          330,
          17355,
          9719,
          17355,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 329.32,
        "id": 130,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 326.68,
        "temperature": 0,
        "text": " And this is where, and I could put the function name here",
        "tokens": [
          50964,
          400,
          341,
          307,
          689,
          11,
          293,
          286,
          727,
          829,
          264,
          2445,
          1315,
          510,
          51096
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 330.40000000000003,
        "id": 131,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 329.32,
        "temperature": 0,
        "text": " and write the function somewhere else,",
        "tokens": [
          51096,
          293,
          2464,
          264,
          2445,
          4079,
          1646,
          11,
          51150
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 332.28000000000003,
        "id": 132,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 330.40000000000003,
        "temperature": 0,
        "text": " which I do in some videos to be kind of,",
        "tokens": [
          51150,
          597,
          286,
          360,
          294,
          512,
          2145,
          281,
          312,
          733,
          295,
          11,
          51244
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 335.12,
        "id": 133,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 332.28000000000003,
        "temperature": 0,
        "text": " but I'm just going to put an anonymous function in here.",
        "tokens": [
          51244,
          457,
          286,
          478,
          445,
          516,
          281,
          829,
          364,
          24932,
          2445,
          294,
          510,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 337.04,
        "id": 134,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 335.12,
        "temperature": 0,
        "text": " The idea of this anonymous function",
        "tokens": [
          51386,
          440,
          1558,
          295,
          341,
          24932,
          2445,
          51482
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 339.28000000000003,
        "id": 135,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 337.04,
        "temperature": 0,
        "text": " is when I press the button,",
        "tokens": [
          51482,
          307,
          562,
          286,
          1886,
          264,
          2960,
          11,
          51594
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 340.9,
        "id": 136,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 339.28000000000003,
        "temperature": 0,
        "text": " this function should be executed.",
        "tokens": [
          51594,
          341,
          2445,
          820,
          312,
          17577,
          13,
          51675
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 342.36,
        "id": 137,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 340.9,
        "temperature": 0,
        "text": " So the code I'm writing in here",
        "tokens": [
          51675,
          407,
          264,
          3089,
          286,
          478,
          3579,
          294,
          510,
          51748
        ]
      },
      {
        "avg_logprob": -0.2215259451615183,
        "compression_ratio": 2.003610108303249,
        "end": 344.04,
        "id": 138,
        "no_speech_prob": 0.000006962227416806854,
        "seek": 31468,
        "start": 342.36,
        "temperature": 0,
        "text": " will happen when I press the button.",
        "tokens": [
          51748,
          486,
          1051,
          562,
          286,
          1886,
          264,
          2960,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 345.36,
        "id": 139,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 344.04,
        "temperature": 0,
        "text": " And what do I want to do there?",
        "tokens": [
          50364,
          400,
          437,
          360,
          286,
          528,
          281,
          360,
          456,
          30,
          50430
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 348.32,
        "id": 140,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 345.36,
        "temperature": 0,
        "text": " I want to say classifier add image,",
        "tokens": [
          50430,
          286,
          528,
          281,
          584,
          1508,
          9902,
          909,
          3256,
          11,
          50578
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 353,
        "id": 141,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 349.72,
        "temperature": 0,
        "text": " and I want to give it a label, ukulele.",
        "tokens": [
          50648,
          293,
          286,
          528,
          281,
          976,
          309,
          257,
          7645,
          11,
          26769,
          2271,
          306,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 355.16,
        "id": 142,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 353,
        "temperature": 0,
        "text": " I hope that's spelled right.",
        "tokens": [
          50812,
          286,
          1454,
          300,
          311,
          34388,
          558,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 358.24,
        "id": 143,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 355.16,
        "temperature": 0,
        "text": " So now whenever I press the button, it's a ukulele.",
        "tokens": [
          50920,
          407,
          586,
          5699,
          286,
          1886,
          264,
          2960,
          11,
          309,
          311,
          257,
          26769,
          2271,
          306,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 360.24,
        "id": 144,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 358.24,
        "temperature": 0,
        "text": " And you know, let's add a train whistle one",
        "tokens": [
          51074,
          400,
          291,
          458,
          11,
          718,
          311,
          909,
          257,
          3847,
          23470,
          472,
          51174
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 361.32000000000005,
        "id": 145,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 360.24,
        "temperature": 0,
        "text": " while we're at it.",
        "tokens": [
          51174,
          1339,
          321,
          434,
          412,
          309,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 366.14000000000004,
        "id": 146,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 363.12,
        "temperature": 0,
        "text": " Let's say a whistle button,",
        "tokens": [
          51318,
          961,
          311,
          584,
          257,
          23470,
          2960,
          11,
          51469
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 369.28000000000003,
        "id": 147,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 367.14000000000004,
        "temperature": 0,
        "text": " and let's do exactly the same thing,",
        "tokens": [
          51519,
          293,
          718,
          311,
          360,
          2293,
          264,
          912,
          551,
          11,
          51626
        ]
      },
      {
        "avg_logprob": -0.26691468838041865,
        "compression_ratio": 1.6411483253588517,
        "end": 373.16,
        "id": 148,
        "no_speech_prob": 0.00001451045955036534,
        "seek": 34404,
        "start": 370.42,
        "temperature": 0,
        "text": " but with a whistle button.",
        "tokens": [
          51683,
          457,
          365,
          257,
          23470,
          2960,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 377.16,
        "id": 149,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 375.04,
        "temperature": 0,
        "text": " Whistle button.",
        "tokens": [
          50414,
          506,
          16088,
          2960,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 378.6,
        "id": 150,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 377.16,
        "temperature": 0,
        "text": " Ha ha!",
        "tokens": [
          50520,
          4064,
          324,
          0,
          50592
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 380.88,
        "id": 151,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 378.6,
        "temperature": 0,
        "text": " Create button, I'm going to have the button say whistle.",
        "tokens": [
          50592,
          20248,
          2960,
          11,
          286,
          478,
          516,
          281,
          362,
          264,
          2960,
          584,
          23470,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 383.40000000000003,
        "id": 152,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 380.88,
        "temperature": 0,
        "text": " I cannot spell anything.",
        "tokens": [
          50706,
          286,
          2644,
          9827,
          1340,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 386.40000000000003,
        "id": 153,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 383.40000000000003,
        "temperature": 0,
        "text": " Whistle button, and then add image whistle.",
        "tokens": [
          50832,
          506,
          16088,
          2960,
          11,
          293,
          550,
          909,
          3256,
          23470,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 388.52000000000004,
        "id": 154,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 386.40000000000003,
        "temperature": 0,
        "text": " So you can see here I have two buttons.",
        "tokens": [
          50982,
          407,
          291,
          393,
          536,
          510,
          286,
          362,
          732,
          9905,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 393.52000000000004,
        "id": 155,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 388.52000000000004,
        "temperature": 0,
        "text": " Ukulele, adds an image, assign the label ukulele.",
        "tokens": [
          51088,
          9816,
          2271,
          306,
          11,
          10860,
          364,
          3256,
          11,
          6269,
          264,
          7645,
          26769,
          2271,
          306,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 396.52000000000004,
        "id": 156,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 393.92,
        "temperature": 0,
        "text": " Whistle adds an image, assign the label whistle.",
        "tokens": [
          51358,
          506,
          16088,
          10860,
          364,
          3256,
          11,
          6269,
          264,
          7645,
          23470,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 399.08000000000004,
        "id": 157,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 396.52000000000004,
        "temperature": 0,
        "text": " Now, there's not really much point to me running this code.",
        "tokens": [
          51488,
          823,
          11,
          456,
          311,
          406,
          534,
          709,
          935,
          281,
          385,
          2614,
          341,
          3089,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 400.88,
        "id": 158,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 399.08000000000004,
        "temperature": 0,
        "text": " I should just make sure I have no errors.",
        "tokens": [
          51616,
          286,
          820,
          445,
          652,
          988,
          286,
          362,
          572,
          13603,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.25738504690717356,
        "compression_ratio": 1.8418803418803418,
        "end": 402.40000000000003,
        "id": 159,
        "no_speech_prob": 0.00002282794230268337,
        "seek": 37404,
        "start": 400.88,
        "temperature": 0,
        "text": " But we can see the buttons are there now.",
        "tokens": [
          51706,
          583,
          321,
          393,
          536,
          264,
          9905,
          366,
          456,
          586,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 405.32,
        "id": 160,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 402.4,
        "temperature": 0,
        "text": " The image comes up, but nothing's going to happen.",
        "tokens": [
          50364,
          440,
          3256,
          1487,
          493,
          11,
          457,
          1825,
          311,
          516,
          281,
          1051,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 406.91999999999996,
        "id": 161,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 405.32,
        "temperature": 0,
        "text": " Like I can keep pressing this ukulele button,",
        "tokens": [
          50510,
          1743,
          286,
          393,
          1066,
          12417,
          341,
          26769,
          2271,
          306,
          2960,
          11,
          50590
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 408.47999999999996,
        "id": 162,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 406.91999999999996,
        "temperature": 0,
        "text": " I can keep pressing this whistle button.",
        "tokens": [
          50590,
          286,
          393,
          1066,
          12417,
          341,
          23470,
          2960,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 411.71999999999997,
        "id": 163,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 408.47999999999996,
        "temperature": 0,
        "text": " Nothing's happening because I'm not giving myself",
        "tokens": [
          50668,
          6693,
          311,
          2737,
          570,
          286,
          478,
          406,
          2902,
          2059,
          50830
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 412.96,
        "id": 164,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 411.71999999999997,
        "temperature": 0,
        "text": " any feedback.",
        "tokens": [
          50830,
          604,
          5824,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 415.88,
        "id": 165,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 412.96,
        "temperature": 0,
        "text": " So right now I just have to hope it's working.",
        "tokens": [
          50892,
          407,
          558,
          586,
          286,
          445,
          362,
          281,
          1454,
          309,
          311,
          1364,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 419.44,
        "id": 166,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 415.88,
        "temperature": 0,
        "text": " But the thing that I need to do next, right,",
        "tokens": [
          51038,
          583,
          264,
          551,
          300,
          286,
          643,
          281,
          360,
          958,
          11,
          558,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 421.67999999999995,
        "id": 167,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 419.44,
        "temperature": 0,
        "text": " is actually apply a training step.",
        "tokens": [
          51216,
          307,
          767,
          3079,
          257,
          3097,
          1823,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 423,
        "id": 168,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 421.67999999999995,
        "temperature": 0,
        "text": " Now one thing that was interesting,",
        "tokens": [
          51328,
          823,
          472,
          551,
          300,
          390,
          1880,
          11,
          51394
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 426.97999999999996,
        "id": 169,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 423,
        "temperature": 0,
        "text": " I showed in the previous video, the teachable machine.",
        "tokens": [
          51394,
          286,
          4712,
          294,
          264,
          3894,
          960,
          11,
          264,
          2924,
          712,
          3479,
          13,
          51593
        ]
      },
      {
        "avg_logprob": -0.23994455029887538,
        "compression_ratio": 1.6962962962962962,
        "end": 430.32,
        "id": 170,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 40240,
        "start": 428.47999999999996,
        "temperature": 0,
        "text": " This project that I'm basically making",
        "tokens": [
          51668,
          639,
          1716,
          300,
          286,
          478,
          1936,
          1455,
          51760
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 432.04,
        "id": 171,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 430.32,
        "temperature": 0,
        "text": " is exactly the same thing.",
        "tokens": [
          50364,
          307,
          2293,
          264,
          912,
          551,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 434.12,
        "id": 172,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 432.04,
        "temperature": 0,
        "text": " Train green, train purple, train orange.",
        "tokens": [
          50450,
          28029,
          3092,
          11,
          3847,
          9656,
          11,
          3847,
          7671,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 437.4,
        "id": 173,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 434.12,
        "temperature": 0,
        "text": " My buttons are train ukulele, train whistle.",
        "tokens": [
          50554,
          1222,
          9905,
          366,
          3847,
          26769,
          2271,
          306,
          11,
          3847,
          23470,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 440,
        "id": 174,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 437.4,
        "temperature": 0,
        "text": " But it just started to work immediately.",
        "tokens": [
          50718,
          583,
          309,
          445,
          1409,
          281,
          589,
          4258,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 441.92,
        "id": 175,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 440,
        "temperature": 0,
        "text": " That's because there's a slightly different algorithm",
        "tokens": [
          50848,
          663,
          311,
          570,
          456,
          311,
          257,
          4748,
          819,
          9284,
          50944
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 442.88,
        "id": 176,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 441.92,
        "temperature": 0,
        "text": " at play here.",
        "tokens": [
          50944,
          412,
          862,
          510,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 447.15999999999997,
        "id": 177,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 442.88,
        "temperature": 0,
        "text": " The algorithm that I'm using requires, in ML5,",
        "tokens": [
          50992,
          440,
          9284,
          300,
          286,
          478,
          1228,
          7029,
          11,
          294,
          21601,
          20,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 450.8,
        "id": 178,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 447.15999999999997,
        "temperature": 0,
        "text": " requires an additional step, a training step.",
        "tokens": [
          51206,
          7029,
          364,
          4497,
          1823,
          11,
          257,
          3097,
          1823,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 453.48,
        "id": 179,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 450.8,
        "temperature": 0,
        "text": " I'm going to write this here, training.",
        "tokens": [
          51388,
          286,
          478,
          516,
          281,
          2464,
          341,
          510,
          11,
          3097,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 458.15999999999997,
        "id": 180,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 453.48,
        "temperature": 0,
        "text": " So basically the process is, add a bunch of images.",
        "tokens": [
          51522,
          407,
          1936,
          264,
          1399,
          307,
          11,
          909,
          257,
          3840,
          295,
          5267,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.22724655384325798,
        "compression_ratio": 1.7224334600760456,
        "end": 459.84,
        "id": 181,
        "no_speech_prob": 0.000016187570508918725,
        "seek": 43032,
        "start": 458.15999999999997,
        "temperature": 0,
        "text": " Say hey, this is a ukulele, this is a ukulele,",
        "tokens": [
          51756,
          6463,
          4177,
          11,
          341,
          307,
          257,
          26769,
          2271,
          306,
          11,
          341,
          307,
          257,
          26769,
          2271,
          306,
          11,
          51840
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 461.64,
        "id": 182,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 460.47999999999996,
        "temperature": 0,
        "text": " this is a whistle, this is a whistle,",
        "tokens": [
          50396,
          341,
          307,
          257,
          23470,
          11,
          341,
          307,
          257,
          23470,
          11,
          50454
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 463.76,
        "id": 183,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 461.64,
        "temperature": 0,
        "text": " this is a ukulele, this is a whistle, this is a ukulele.",
        "tokens": [
          50454,
          341,
          307,
          257,
          26769,
          2271,
          306,
          11,
          341,
          307,
          257,
          23470,
          11,
          341,
          307,
          257,
          26769,
          2271,
          306,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 465.71999999999997,
        "id": 184,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 463.76,
        "temperature": 0,
        "text": " Once I've added all those images,",
        "tokens": [
          50560,
          3443,
          286,
          600,
          3869,
          439,
          729,
          5267,
          11,
          50658
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 469.79999999999995,
        "id": 185,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 465.71999999999997,
        "temperature": 0,
        "text": " then I explicitly, I say I'm done with all these images.",
        "tokens": [
          50658,
          550,
          286,
          20803,
          11,
          286,
          584,
          286,
          478,
          1096,
          365,
          439,
          613,
          5267,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 472.08,
        "id": 186,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 469.79999999999995,
        "temperature": 0,
        "text": " I'm going to let the model retrain itself,",
        "tokens": [
          50862,
          286,
          478,
          516,
          281,
          718,
          264,
          2316,
          1533,
          7146,
          2564,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 474.47999999999996,
        "id": 187,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 472.08,
        "temperature": 0,
        "text": " train itself using the features",
        "tokens": [
          50976,
          3847,
          2564,
          1228,
          264,
          4122,
          51096
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 476.12,
        "id": 188,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 474.47999999999996,
        "temperature": 0,
        "text": " that it extracted of those images,",
        "tokens": [
          51096,
          300,
          309,
          34086,
          295,
          729,
          5267,
          11,
          51178
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 478.91999999999996,
        "id": 189,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 476.12,
        "temperature": 0,
        "text": " and map those features basically to these labels.",
        "tokens": [
          51178,
          293,
          4471,
          729,
          4122,
          1936,
          281,
          613,
          16949,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 481.96,
        "id": 190,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 478.91999999999996,
        "temperature": 0,
        "text": " And by map, I really mean there's like another",
        "tokens": [
          51318,
          400,
          538,
          4471,
          11,
          286,
          534,
          914,
          456,
          311,
          411,
          1071,
          51470
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 483.84,
        "id": 191,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 481.96,
        "temperature": 0,
        "text": " machine learning model right here.",
        "tokens": [
          51470,
          3479,
          2539,
          2316,
          558,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23057929017490014,
        "compression_ratio": 1.9665271966527196,
        "end": 486,
        "id": 192,
        "no_speech_prob": 0.0000016797305306681665,
        "seek": 45984,
        "start": 483.84,
        "temperature": 0,
        "text": " It's actually like a neural network model.",
        "tokens": [
          51564,
          467,
          311,
          767,
          411,
          257,
          18161,
          3209,
          2316,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 490.2,
        "id": 193,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 486.84,
        "temperature": 0,
        "text": " And so that mapping between the features",
        "tokens": [
          50406,
          400,
          370,
          300,
          18350,
          1296,
          264,
          4122,
          50574
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 492.84,
        "id": 194,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 490.2,
        "temperature": 0,
        "text": " and the new labels happens with another neural network here.",
        "tokens": [
          50574,
          293,
          264,
          777,
          16949,
          2314,
          365,
          1071,
          18161,
          3209,
          510,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 497.6,
        "id": 195,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 492.84,
        "temperature": 0,
        "text": " But ML5 and TensorFlow.js is handling all of that for us.",
        "tokens": [
          50706,
          583,
          21601,
          20,
          293,
          37624,
          13,
          25530,
          307,
          13175,
          439,
          295,
          300,
          337,
          505,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 501,
        "id": 196,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 497.6,
        "temperature": 0,
        "text": " Okay, now let me come back over here",
        "tokens": [
          50944,
          1033,
          11,
          586,
          718,
          385,
          808,
          646,
          670,
          510,
          51114
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 502.44,
        "id": 197,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 501,
        "temperature": 0,
        "text": " and add the training step.",
        "tokens": [
          51114,
          293,
          909,
          264,
          3097,
          1823,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 504.36,
        "id": 198,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 502.44,
        "temperature": 0,
        "text": " So I certainly need one more button.",
        "tokens": [
          51186,
          407,
          286,
          3297,
          643,
          472,
          544,
          2960,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 508.02,
        "id": 199,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 505.56,
        "temperature": 0,
        "text": " Train, choo choo button.",
        "tokens": [
          51342,
          28029,
          11,
          1586,
          78,
          1586,
          78,
          2960,
          13,
          51465
        ]
      },
      {
        "avg_logprob": -0.3332609239515367,
        "compression_ratio": 1.5288461538461537,
        "end": 511.94,
        "id": 200,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 48600,
        "start": 510.34,
        "temperature": 0,
        "text": " So I'm going to add that button.",
        "tokens": [
          51581,
          407,
          286,
          478,
          516,
          281,
          909,
          300,
          2960,
          13,
          51661
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 516.94,
        "id": 201,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 511.94,
        "temperature": 0,
        "text": " Create button, train button, train.",
        "tokens": [
          50364,
          20248,
          2960,
          11,
          3847,
          2960,
          11,
          3847,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 521.5,
        "id": 202,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 518.38,
        "temperature": 0,
        "text": " I'm going to say train, train button.",
        "tokens": [
          50686,
          286,
          478,
          516,
          281,
          584,
          3847,
          11,
          3847,
          2960,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 522.46,
        "id": 203,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 521.5,
        "temperature": 0,
        "text": " Oh okay, now here.",
        "tokens": [
          50842,
          876,
          1392,
          11,
          586,
          510,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 523.9,
        "id": 204,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 522.46,
        "temperature": 0,
        "text": " Now what am I doing in here?",
        "tokens": [
          50890,
          823,
          437,
          669,
          286,
          884,
          294,
          510,
          30,
          50962
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 525.12,
        "id": 205,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 523.9,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          50962,
          2438,
          11,
          1392,
          13,
          51023
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 530.12,
        "id": 206,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 525.12,
        "temperature": 0,
        "text": " What I'm doing in here is I'm going to say classifier.train.",
        "tokens": [
          51023,
          708,
          286,
          478,
          884,
          294,
          510,
          307,
          286,
          478,
          516,
          281,
          584,
          1508,
          9902,
          13,
          83,
          7146,
          13,
          51273
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 534.58,
        "id": 207,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 531.62,
        "temperature": 0,
        "text": " So I'm going to say, hey, classifier train yourself.",
        "tokens": [
          51348,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          4177,
          11,
          1508,
          9902,
          3847,
          1803,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 536.26,
        "id": 208,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 534.58,
        "temperature": 0,
        "text": " Now I could just leave it at this",
        "tokens": [
          51496,
          823,
          286,
          727,
          445,
          1856,
          309,
          412,
          341,
          51580
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 538.86,
        "id": 209,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 536.26,
        "temperature": 0,
        "text": " and kind of say like, hey, great, I'm done.",
        "tokens": [
          51580,
          293,
          733,
          295,
          584,
          411,
          11,
          4177,
          11,
          869,
          11,
          286,
          478,
          1096,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.2691777012929195,
        "compression_ratio": 1.8223350253807107,
        "end": 541.34,
        "id": 210,
        "no_speech_prob": 0.000023552600396214984,
        "seek": 51194,
        "start": 538.86,
        "temperature": 0,
        "text": " But something that I should do here",
        "tokens": [
          51710,
          583,
          746,
          300,
          286,
          820,
          360,
          510,
          51834
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 544.7,
        "id": 211,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 541.34,
        "temperature": 0,
        "text": " is I can actually put a callback inside of here.",
        "tokens": [
          50364,
          307,
          286,
          393,
          767,
          829,
          257,
          818,
          3207,
          1854,
          295,
          510,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 546.9,
        "id": 212,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 544.7,
        "temperature": 0,
        "text": " Now this is getting pretty awkward.",
        "tokens": [
          50532,
          823,
          341,
          307,
          1242,
          1238,
          11411,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 547.9,
        "id": 213,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 546.9,
        "temperature": 0,
        "text": " I'm going to allow it.",
        "tokens": [
          50642,
          286,
          478,
          516,
          281,
          2089,
          309,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 548.74,
        "id": 214,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 547.9,
        "temperature": 0,
        "text": " And you know what, actually though,",
        "tokens": [
          50692,
          400,
          291,
          458,
          437,
          11,
          767,
          1673,
          11,
          50734
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 550.7800000000001,
        "id": 215,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 548.74,
        "temperature": 0,
        "text": " I'm going to make a separate function just for,",
        "tokens": [
          50734,
          286,
          478,
          516,
          281,
          652,
          257,
          4994,
          2445,
          445,
          337,
          11,
          50836
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 552.5400000000001,
        "id": 216,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 550.7800000000001,
        "temperature": 0,
        "text": " because I might want to do a bunch of things.",
        "tokens": [
          50836,
          570,
          286,
          1062,
          528,
          281,
          360,
          257,
          3840,
          295,
          721,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 557.1,
        "id": 217,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 552.5400000000001,
        "temperature": 0,
        "text": " I'm going to say, I'm going to call it like while training.",
        "tokens": [
          50924,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          478,
          516,
          281,
          818,
          309,
          411,
          1339,
          3097,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 558.9,
        "id": 218,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 557.1,
        "temperature": 0,
        "text": " So I just want to put this in a separate function",
        "tokens": [
          51152,
          407,
          286,
          445,
          528,
          281,
          829,
          341,
          294,
          257,
          4994,
          2445,
          51242
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 562.34,
        "id": 219,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 558.9,
        "temperature": 0,
        "text": " so I can just for, so I can look at it on its own.",
        "tokens": [
          51242,
          370,
          286,
          393,
          445,
          337,
          11,
          370,
          286,
          393,
          574,
          412,
          309,
          322,
          1080,
          1065,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 564.1,
        "id": 220,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 562.34,
        "temperature": 0,
        "text": " What did I call it, while training?",
        "tokens": [
          51414,
          708,
          630,
          286,
          818,
          309,
          11,
          1339,
          3097,
          30,
          51502
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 567.4200000000001,
        "id": 221,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 565.4200000000001,
        "temperature": 0,
        "text": " So this function while training",
        "tokens": [
          51568,
          407,
          341,
          2445,
          1339,
          3097,
          51668
        ]
      },
      {
        "avg_logprob": -0.20169116026603134,
        "compression_ratio": 1.9169811320754717,
        "end": 569.1800000000001,
        "id": 222,
        "no_speech_prob": 0.000029773078495054506,
        "seek": 54134,
        "start": 567.4200000000001,
        "temperature": 0,
        "text": " is a function that's going to kind of run",
        "tokens": [
          51668,
          307,
          257,
          2445,
          300,
          311,
          516,
          281,
          733,
          295,
          1190,
          51756
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 571.9399999999999,
        "id": 223,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 569.18,
        "temperature": 0,
        "text": " over and over again during the training process.",
        "tokens": [
          50364,
          670,
          293,
          670,
          797,
          1830,
          264,
          3097,
          1399,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 573.7399999999999,
        "id": 224,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 571.9399999999999,
        "temperature": 0,
        "text": " And it's going to report back to me",
        "tokens": [
          50502,
          400,
          309,
          311,
          516,
          281,
          2275,
          646,
          281,
          385,
          50592
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 575.6999999999999,
        "id": 225,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 573.7399999999999,
        "temperature": 0,
        "text": " information about the training process.",
        "tokens": [
          50592,
          1589,
          466,
          264,
          3097,
          1399,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 577.78,
        "id": 226,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 575.6999999999999,
        "temperature": 0,
        "text": " And the information it's going to report to me",
        "tokens": [
          50690,
          400,
          264,
          1589,
          309,
          311,
          516,
          281,
          2275,
          281,
          385,
          50794
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 580.66,
        "id": 227,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 577.78,
        "temperature": 0,
        "text": " is something called loss, loss.",
        "tokens": [
          50794,
          307,
          746,
          1219,
          4470,
          11,
          4470,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 582.2199999999999,
        "id": 228,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 580.66,
        "temperature": 0,
        "text": " Let's just actually run this.",
        "tokens": [
          50938,
          961,
          311,
          445,
          767,
          1190,
          341,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 585.7399999999999,
        "id": 229,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 584.14,
        "temperature": 0,
        "text": " And then I'm going to explain what loss is.",
        "tokens": [
          51112,
          400,
          550,
          286,
          478,
          516,
          281,
          2903,
          437,
          4470,
          307,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 588.14,
        "id": 230,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 585.7399999999999,
        "temperature": 0,
        "text": " Let's see if I can get this to work so far.",
        "tokens": [
          51192,
          961,
          311,
          536,
          498,
          286,
          393,
          483,
          341,
          281,
          589,
          370,
          1400,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 589.3399999999999,
        "id": 231,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 588.14,
        "temperature": 0,
        "text": " So I'm going to refresh.",
        "tokens": [
          51312,
          407,
          286,
          478,
          516,
          281,
          15134,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 592.0999999999999,
        "id": 232,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 590.3,
        "temperature": 0,
        "text": " My model's ready, my video is ready.",
        "tokens": [
          51420,
          1222,
          2316,
          311,
          1919,
          11,
          452,
          960,
          307,
          1919,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 594.02,
        "id": 233,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 592.0999999999999,
        "temperature": 0,
        "text": " I have a ukulele.",
        "tokens": [
          51510,
          286,
          362,
          257,
          26769,
          2271,
          306,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 595.9399999999999,
        "id": 234,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 594.02,
        "temperature": 0,
        "text": " I can press ukulele, ukulele, ukulele.",
        "tokens": [
          51606,
          286,
          393,
          1886,
          26769,
          2271,
          306,
          11,
          26769,
          2271,
          306,
          11,
          26769,
          2271,
          306,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.1752755516453793,
        "compression_ratio": 1.951219512195122,
        "end": 597.8199999999999,
        "id": 235,
        "no_speech_prob": 0.000003500852926663356,
        "seek": 56918,
        "start": 595.9399999999999,
        "temperature": 0,
        "text": " I'm going to show it a lot of ukuleles.",
        "tokens": [
          51702,
          286,
          478,
          516,
          281,
          855,
          309,
          257,
          688,
          295,
          26769,
          2271,
          904,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 599.74,
        "id": 236,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 597.82,
        "temperature": 0,
        "text": " Here's a lot of examples of ukuleles.",
        "tokens": [
          50364,
          1692,
          311,
          257,
          688,
          295,
          5110,
          295,
          26769,
          2271,
          904,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 602.86,
        "id": 237,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 600.6600000000001,
        "temperature": 0,
        "text": " Now I'm going to hold up my train whistle.",
        "tokens": [
          50506,
          823,
          286,
          478,
          516,
          281,
          1797,
          493,
          452,
          3847,
          23470,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 605.46,
        "id": 238,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 602.86,
        "temperature": 0,
        "text": " Here's a lot of examples of train whistles.",
        "tokens": [
          50616,
          1692,
          311,
          257,
          688,
          295,
          5110,
          295,
          3847,
          49282,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 607.36,
        "id": 239,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 605.46,
        "temperature": 0,
        "text": " Now I'm going to hit the button train.",
        "tokens": [
          50746,
          823,
          286,
          478,
          516,
          281,
          2045,
          264,
          2960,
          3847,
          13,
          50841
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 612.74,
        "id": 240,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 608.46,
        "temperature": 0,
        "text": " And yes, we see this number here in the console.",
        "tokens": [
          50896,
          400,
          2086,
          11,
          321,
          536,
          341,
          1230,
          510,
          294,
          264,
          11076,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 614.62,
        "id": 241,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 612.74,
        "temperature": 0,
        "text": " It's training and training and training.",
        "tokens": [
          51110,
          467,
          311,
          3097,
          293,
          3097,
          293,
          3097,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 618.6400000000001,
        "id": 242,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 614.62,
        "temperature": 0,
        "text": " While training, console log this value loss.",
        "tokens": [
          51204,
          3987,
          3097,
          11,
          11076,
          3565,
          341,
          2158,
          4470,
          13,
          51405
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 621.62,
        "id": 243,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 619.62,
        "temperature": 0,
        "text": " What is the loss?",
        "tokens": [
          51454,
          708,
          307,
          264,
          4470,
          30,
          51554
        ]
      },
      {
        "avg_logprob": -0.21431074409841377,
        "compression_ratio": 1.8415841584158417,
        "end": 627.2600000000001,
        "id": 244,
        "no_speech_prob": 8.186362379092316e-7,
        "seek": 59782,
        "start": 622.46,
        "temperature": 0,
        "text": " So loss is a really important term in machine learning,",
        "tokens": [
          51596,
          407,
          4470,
          307,
          257,
          534,
          1021,
          1433,
          294,
          3479,
          2539,
          11,
          51836
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 628.8199999999999,
        "id": 245,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 627.66,
        "temperature": 0,
        "text": " data science.",
        "tokens": [
          50384,
          1412,
          3497,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 631.1,
        "id": 246,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 628.8199999999999,
        "temperature": 0,
        "text": " Often also called cost.",
        "tokens": [
          50442,
          20043,
          611,
          1219,
          2063,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 633.98,
        "id": 247,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 631.1,
        "temperature": 0,
        "text": " And by this I mean loss function or cost function.",
        "tokens": [
          50556,
          400,
          538,
          341,
          286,
          914,
          4470,
          2445,
          420,
          2063,
          2445,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 636.02,
        "id": 248,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 633.98,
        "temperature": 0,
        "text": " And what the loss function or cost function",
        "tokens": [
          50700,
          400,
          437,
          264,
          4470,
          2445,
          420,
          2063,
          2445,
          50802
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 638.8199999999999,
        "id": 249,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 636.02,
        "temperature": 0,
        "text": " is calculating is the error.",
        "tokens": [
          50802,
          307,
          28258,
          307,
          264,
          6713,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 640.34,
        "id": 250,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 638.8199999999999,
        "temperature": 0,
        "text": " So what do I mean by error?",
        "tokens": [
          50942,
          407,
          437,
          360,
          286,
          914,
          538,
          6713,
          30,
          51018
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 644.98,
        "id": 251,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 640.34,
        "temperature": 0,
        "text": " So basically if I say to the machine learning model",
        "tokens": [
          51018,
          407,
          1936,
          498,
          286,
          584,
          281,
          264,
          3479,
          2539,
          2316,
          51250
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 647.8199999999999,
        "id": 252,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 644.98,
        "temperature": 0,
        "text": " that's training, hey, here's a ukulele.",
        "tokens": [
          51250,
          300,
          311,
          3097,
          11,
          4177,
          11,
          510,
          311,
          257,
          26769,
          2271,
          306,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 651.06,
        "id": 253,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 648.98,
        "temperature": 0,
        "text": " This is a ukulele, but just pretend you don't know",
        "tokens": [
          51450,
          639,
          307,
          257,
          26769,
          2271,
          306,
          11,
          457,
          445,
          11865,
          291,
          500,
          380,
          458,
          51554
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 652.34,
        "id": 254,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 651.06,
        "temperature": 0,
        "text": " what it is for a second.",
        "tokens": [
          51554,
          437,
          309,
          307,
          337,
          257,
          1150,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 653.5,
        "id": 255,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 652.34,
        "temperature": 0,
        "text": " What do you think it is?",
        "tokens": [
          51618,
          708,
          360,
          291,
          519,
          309,
          307,
          30,
          51676
        ]
      },
      {
        "avg_logprob": -0.25440812287507236,
        "compression_ratio": 1.7692307692307692,
        "end": 655.76,
        "id": 256,
        "no_speech_prob": 0.000049086571380030364,
        "seek": 62726,
        "start": 653.5,
        "temperature": 0,
        "text": " And if it comes back and says, I think it's a ukulele,",
        "tokens": [
          51676,
          400,
          498,
          309,
          1487,
          646,
          293,
          1619,
          11,
          286,
          519,
          309,
          311,
          257,
          26769,
          2271,
          306,
          11,
          51789
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 658.68,
        "id": 257,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 655.76,
        "temperature": 0,
        "text": " guess what, the error is zero.",
        "tokens": [
          50364,
          2041,
          437,
          11,
          264,
          6713,
          307,
          4018,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 661.8199999999999,
        "id": 258,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 658.68,
        "temperature": 0,
        "text": " If it comes back and says, I think it's a train whistle,",
        "tokens": [
          50510,
          759,
          309,
          1487,
          646,
          293,
          1619,
          11,
          286,
          519,
          309,
          311,
          257,
          3847,
          23470,
          11,
          50667
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 664.6,
        "id": 259,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 661.8199999999999,
        "temperature": 0,
        "text": " then the error is not zero, it's something else.",
        "tokens": [
          50667,
          550,
          264,
          6713,
          307,
          406,
          4018,
          11,
          309,
          311,
          746,
          1646,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 666.3199999999999,
        "id": 260,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 664.6,
        "temperature": 0,
        "text": " But something that I haven't really mentioned",
        "tokens": [
          50806,
          583,
          746,
          300,
          286,
          2378,
          380,
          534,
          2835,
          50892
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 669.56,
        "id": 261,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 666.3199999999999,
        "temperature": 0,
        "text": " because we're kind of living above the fray here,",
        "tokens": [
          50892,
          570,
          321,
          434,
          733,
          295,
          2647,
          3673,
          264,
          431,
          320,
          510,
          11,
          51054
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 671.46,
        "id": 262,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 669.56,
        "temperature": 0,
        "text": " we're talking in terms of labels.",
        "tokens": [
          51054,
          321,
          434,
          1417,
          294,
          2115,
          295,
          16949,
          13,
          51149
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 673.56,
        "id": 263,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 671.46,
        "temperature": 0,
        "text": " The machine learning model underneath the hood",
        "tokens": [
          51149,
          440,
          3479,
          2539,
          2316,
          7223,
          264,
          13376,
          51254
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 675.64,
        "id": 264,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 673.56,
        "temperature": 0,
        "text": " is just working with numbers.",
        "tokens": [
          51254,
          307,
          445,
          1364,
          365,
          3547,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 678.14,
        "id": 265,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 675.64,
        "temperature": 0,
        "text": " The labels are only a thing for us, the human being,",
        "tokens": [
          51358,
          440,
          16949,
          366,
          787,
          257,
          551,
          337,
          505,
          11,
          264,
          1952,
          885,
          11,
          51483
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 680.36,
        "id": 266,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 678.14,
        "temperature": 0,
        "text": " to use at sort of the end of the process.",
        "tokens": [
          51483,
          281,
          764,
          412,
          1333,
          295,
          264,
          917,
          295,
          264,
          1399,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 682.3199999999999,
        "id": 267,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 680.36,
        "temperature": 0,
        "text": " So when it's actually calculating an error,",
        "tokens": [
          51594,
          407,
          562,
          309,
          311,
          767,
          28258,
          364,
          6713,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.1848400455631622,
        "compression_ratio": 1.7290969899665551,
        "end": 684.4399999999999,
        "id": 268,
        "no_speech_prob": 0.000022125650502857752,
        "seek": 65576,
        "start": 682.3199999999999,
        "temperature": 0,
        "text": " even if it guesses it's a ukulele,",
        "tokens": [
          51692,
          754,
          498,
          309,
          42703,
          309,
          311,
          257,
          26769,
          2271,
          306,
          11,
          51798
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 687.8000000000001,
        "id": 269,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 684.44,
        "temperature": 0,
        "text": " it's calculating an error based on the numeric probability",
        "tokens": [
          50364,
          309,
          311,
          28258,
          364,
          6713,
          2361,
          322,
          264,
          7866,
          299,
          8482,
          50532
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 688.6400000000001,
        "id": 270,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 687.8000000000001,
        "temperature": 0,
        "text": " that it guessed.",
        "tokens": [
          50532,
          300,
          309,
          21852,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 691.0400000000001,
        "id": 271,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 688.6400000000001,
        "temperature": 0,
        "text": " So the machine learning model might think,",
        "tokens": [
          50574,
          407,
          264,
          3479,
          2539,
          2316,
          1062,
          519,
          11,
          50694
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 695.6400000000001,
        "id": 272,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 691.0400000000001,
        "temperature": 0,
        "text": " okay, that's 80% likely to be a ukulele.",
        "tokens": [
          50694,
          1392,
          11,
          300,
          311,
          4688,
          4,
          3700,
          281,
          312,
          257,
          26769,
          2271,
          306,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 697.32,
        "id": 273,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 695.6400000000001,
        "temperature": 0,
        "text": " So that might be the right answer,",
        "tokens": [
          50924,
          407,
          300,
          1062,
          312,
          264,
          558,
          1867,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 700.24,
        "id": 274,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 697.32,
        "temperature": 0,
        "text": " but we know the right answer is it's 100% a ukulele.",
        "tokens": [
          51008,
          457,
          321,
          458,
          264,
          558,
          1867,
          307,
          309,
          311,
          2319,
          4,
          257,
          26769,
          2271,
          306,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 701.44,
        "id": 275,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 700.24,
        "temperature": 0,
        "text": " So the error is actually the difference",
        "tokens": [
          51154,
          407,
          264,
          6713,
          307,
          767,
          264,
          2649,
          51214
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 703.8800000000001,
        "id": 276,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 701.44,
        "temperature": 0,
        "text": " between 100%, 80%, or 0.2.",
        "tokens": [
          51214,
          1296,
          2319,
          8923,
          4688,
          8923,
          420,
          1958,
          13,
          17,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 706.12,
        "id": 277,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 703.8800000000001,
        "temperature": 0,
        "text": " So this idea of the aggregate error",
        "tokens": [
          51336,
          407,
          341,
          1558,
          295,
          264,
          26118,
          6713,
          51448
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 708.6400000000001,
        "id": 278,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 706.12,
        "temperature": 0,
        "text": " of all of the training images over time,",
        "tokens": [
          51448,
          295,
          439,
          295,
          264,
          3097,
          5267,
          670,
          565,
          11,
          51574
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 712.0400000000001,
        "id": 279,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 708.6400000000001,
        "temperature": 0,
        "text": " ML5 and TensorFlow Digest is calculating that for you",
        "tokens": [
          51574,
          21601,
          20,
          293,
          37624,
          10976,
          377,
          307,
          28258,
          300,
          337,
          291,
          51744
        ]
      },
      {
        "avg_logprob": -0.2205643092884737,
        "compression_ratio": 1.7210144927536233,
        "end": 713.84,
        "id": 280,
        "no_speech_prob": 0.000002482478748788708,
        "seek": 68444,
        "start": 712.0400000000001,
        "temperature": 0,
        "text": " during that training process,",
        "tokens": [
          51744,
          1830,
          300,
          3097,
          1399,
          11,
          51834
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 715.8000000000001,
        "id": 281,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 713.84,
        "temperature": 0,
        "text": " and we're seeing that here.",
        "tokens": [
          50364,
          293,
          321,
          434,
          2577,
          300,
          510,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 719.24,
        "id": 282,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 715.8000000000001,
        "temperature": 0,
        "text": " There's a clock tick-tocking,",
        "tokens": [
          50462,
          821,
          311,
          257,
          7830,
          5204,
          12,
          1353,
          25723,
          11,
          50634
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 721.5600000000001,
        "id": 283,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 719.24,
        "temperature": 0,
        "text": " because I have a clock sound effect for some unknown reason.",
        "tokens": [
          50634,
          570,
          286,
          362,
          257,
          7830,
          1626,
          1802,
          337,
          512,
          9841,
          1778,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 723.88,
        "id": 284,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 721.5600000000001,
        "temperature": 0,
        "text": " We can see that that loss is getting very, very low.",
        "tokens": [
          50750,
          492,
          393,
          536,
          300,
          300,
          4470,
          307,
          1242,
          588,
          11,
          588,
          2295,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 725.7,
        "id": 285,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 723.88,
        "temperature": 0,
        "text": " So you want the error to be low.",
        "tokens": [
          50866,
          407,
          291,
          528,
          264,
          6713,
          281,
          312,
          2295,
          13,
          50957
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 730.5600000000001,
        "id": 286,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 725.7,
        "temperature": 0,
        "text": " The error started kind of high, it was like 6.92,",
        "tokens": [
          50957,
          440,
          6713,
          1409,
          733,
          295,
          1090,
          11,
          309,
          390,
          411,
          1386,
          13,
          21821,
          11,
          51200
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 731.88,
        "id": 287,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 730.5600000000001,
        "temperature": 0,
        "text": " and then it got lower and lower and lower",
        "tokens": [
          51200,
          293,
          550,
          309,
          658,
          3126,
          293,
          3126,
          293,
          3126,
          51266
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 733.76,
        "id": 288,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 731.88,
        "temperature": 0,
        "text": " as it was training, and one thing you'll notice",
        "tokens": [
          51266,
          382,
          309,
          390,
          3097,
          11,
          293,
          472,
          551,
          291,
          603,
          3449,
          51360
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 735.2,
        "id": 289,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 733.76,
        "temperature": 0,
        "text": " is eventually it stopped.",
        "tokens": [
          51360,
          307,
          4728,
          309,
          5936,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 738.4000000000001,
        "id": 290,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 735.2,
        "temperature": 0,
        "text": " Now, it's an arbitrary decision, when do you stop training?",
        "tokens": [
          51432,
          823,
          11,
          309,
          311,
          364,
          23211,
          3537,
          11,
          562,
          360,
          291,
          1590,
          3097,
          30,
          51592
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 740.5600000000001,
        "id": 291,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 738.4000000000001,
        "temperature": 0,
        "text": " ML5 has kind of default settings,",
        "tokens": [
          51592,
          21601,
          20,
          575,
          733,
          295,
          7576,
          6257,
          11,
          51700
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 741.64,
        "id": 292,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 740.5600000000001,
        "temperature": 0,
        "text": " it's going to train for a while",
        "tokens": [
          51700,
          309,
          311,
          516,
          281,
          3847,
          337,
          257,
          1339,
          51754
        ]
      },
      {
        "avg_logprob": -0.2674455462761645,
        "compression_ratio": 1.7563291139240507,
        "end": 743.6800000000001,
        "id": 293,
        "no_speech_prob": 0.000054759479098720476,
        "seek": 71384,
        "start": 741.64,
        "temperature": 0,
        "text": " until the loss is a certain amount or something like that,",
        "tokens": [
          51754,
          1826,
          264,
          4470,
          307,
          257,
          1629,
          2372,
          420,
          746,
          411,
          300,
          11,
          51856
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 745.3599999999999,
        "id": 294,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 744.52,
        "temperature": 0,
        "text": " but you can see when it's finished,",
        "tokens": [
          50406,
          457,
          291,
          393,
          536,
          562,
          309,
          311,
          4335,
          11,
          50448
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 750.12,
        "id": 295,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 745.3599999999999,
        "temperature": 0,
        "text": " it gives you the loss as null, the loss as null.",
        "tokens": [
          50448,
          309,
          2709,
          291,
          264,
          4470,
          382,
          18184,
          11,
          264,
          4470,
          382,
          18184,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 752.28,
        "id": 296,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 750.12,
        "temperature": 0,
        "text": " So I can actually say here,",
        "tokens": [
          50686,
          407,
          286,
          393,
          767,
          584,
          510,
          11,
          50794
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 757.28,
        "id": 297,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 752.28,
        "temperature": 0,
        "text": " if loss equals null, console.log,",
        "tokens": [
          50794,
          498,
          4470,
          6915,
          18184,
          11,
          11076,
          13,
          4987,
          11,
          51044
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 762.64,
        "id": 298,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 760.3,
        "temperature": 0,
        "text": " training, oh, I'm going to say like,",
        "tokens": [
          51195,
          3097,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          584,
          411,
          11,
          51312
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 764.26,
        "id": 299,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 762.64,
        "temperature": 0,
        "text": " training complete,",
        "tokens": [
          51312,
          3097,
          3566,
          11,
          51393
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 768.92,
        "id": 300,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 766,
        "temperature": 0,
        "text": " else, I can console.log the loss,",
        "tokens": [
          51480,
          1646,
          11,
          286,
          393,
          11076,
          13,
          4987,
          264,
          4470,
          11,
          51626
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 770.06,
        "id": 301,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 768.92,
        "temperature": 0,
        "text": " and then guess what?",
        "tokens": [
          51626,
          293,
          550,
          2041,
          437,
          30,
          51683
        ]
      },
      {
        "avg_logprob": -0.2827549934387207,
        "compression_ratio": 1.707182320441989,
        "end": 773.3,
        "id": 302,
        "no_speech_prob": 0.000014064024071558379,
        "seek": 74368,
        "start": 770.06,
        "temperature": 0,
        "text": " When the training's complete, what do I want to do?",
        "tokens": [
          51683,
          1133,
          264,
          3097,
          311,
          3566,
          11,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51845
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 776.78,
        "id": 303,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 773.9399999999999,
        "temperature": 0,
        "text": " I want to classify, so I'm going to say,",
        "tokens": [
          50396,
          286,
          528,
          281,
          33872,
          11,
          370,
          286,
          478,
          516,
          281,
          584,
          11,
          50538
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 781.78,
        "id": 304,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 776.78,
        "temperature": 0,
        "text": " classifier.classify.gotResults,",
        "tokens": [
          50538,
          1508,
          9902,
          13,
          11665,
          2505,
          13,
          13178,
          33274,
          33361,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 784.4599999999999,
        "id": 305,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 781.8599999999999,
        "temperature": 0,
        "text": " and I already have the gotResults function, right?",
        "tokens": [
          50792,
          293,
          286,
          1217,
          362,
          264,
          658,
          33274,
          33361,
          2445,
          11,
          558,
          30,
          50922
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 788.42,
        "id": 306,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 784.4599999999999,
        "temperature": 0,
        "text": " The same got, I'm getting results just like I got results",
        "tokens": [
          50922,
          440,
          912,
          658,
          11,
          286,
          478,
          1242,
          3542,
          445,
          411,
          286,
          658,
          3542,
          51120
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 790.6999999999999,
        "id": 307,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 788.42,
        "temperature": 0,
        "text": " from the raw MobileNet model,",
        "tokens": [
          51120,
          490,
          264,
          8936,
          22625,
          31890,
          2316,
          11,
          51234
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 795.3399999999999,
        "id": 308,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 790.6999999999999,
        "temperature": 0,
        "text": " but now I'm getting the results from my new",
        "tokens": [
          51234,
          457,
          586,
          286,
          478,
          1242,
          264,
          3542,
          490,
          452,
          777,
          51466
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 797.9399999999999,
        "id": 309,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 795.3399999999999,
        "temperature": 0,
        "text": " transfer learn trains custom trained model.",
        "tokens": [
          51466,
          5003,
          1466,
          16329,
          2375,
          8895,
          2316,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 801.0999999999999,
        "id": 310,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 797.9399999999999,
        "temperature": 0,
        "text": " So I say classifier.classify.gotResults,",
        "tokens": [
          51596,
          407,
          286,
          584,
          1508,
          9902,
          13,
          11665,
          2505,
          13,
          13178,
          33274,
          33361,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.2750198130022016,
        "compression_ratio": 1.813397129186603,
        "end": 802.88,
        "id": 311,
        "no_speech_prob": 0.0000037266386243572924,
        "seek": 77330,
        "start": 801.0999999999999,
        "temperature": 0,
        "text": " I get the results if there's an error,",
        "tokens": [
          51754,
          286,
          483,
          264,
          3542,
          498,
          456,
          311,
          364,
          6713,
          11,
          51843
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 805.6,
        "id": 312,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 803.46,
        "temperature": 0,
        "text": " otherwise I can give the class name to the label",
        "tokens": [
          50393,
          5911,
          286,
          393,
          976,
          264,
          1508,
          1315,
          281,
          264,
          7645,
          50500
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 806.64,
        "id": 313,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 805.6,
        "temperature": 0,
        "text": " to get drawn on the screen,",
        "tokens": [
          50500,
          281,
          483,
          10117,
          322,
          264,
          2568,
          11,
          50552
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 808.64,
        "id": 314,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 806.64,
        "temperature": 0,
        "text": " and then what do I want to do again?",
        "tokens": [
          50552,
          293,
          550,
          437,
          360,
          286,
          528,
          281,
          360,
          797,
          30,
          50652
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 810.88,
        "id": 315,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 808.64,
        "temperature": 0,
        "text": " I want to say classifier.classify.",
        "tokens": [
          50652,
          286,
          528,
          281,
          584,
          1508,
          9902,
          13,
          11665,
          2505,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 815.48,
        "id": 316,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 810.88,
        "temperature": 0,
        "text": " So before it was called predict, now it's called classify.",
        "tokens": [
          50764,
          407,
          949,
          309,
          390,
          1219,
          6069,
          11,
          586,
          309,
          311,
          1219,
          33872,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 817.96,
        "id": 317,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 815.48,
        "temperature": 0,
        "text": " I'm not sure why, maybe at some point we,",
        "tokens": [
          50994,
          286,
          478,
          406,
          988,
          983,
          11,
          1310,
          412,
          512,
          935,
          321,
          11,
          51118
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 819.6,
        "id": 318,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 817.96,
        "temperature": 0,
        "text": " check the code that goes along with this video",
        "tokens": [
          51118,
          1520,
          264,
          3089,
          300,
          1709,
          2051,
          365,
          341,
          960,
          51200
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 821.88,
        "id": 319,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 819.6,
        "temperature": 0,
        "text": " to see if that's changed, but that's what it is right now.",
        "tokens": [
          51200,
          281,
          536,
          498,
          300,
          311,
          3105,
          11,
          457,
          300,
          311,
          437,
          309,
          307,
          558,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 824.2,
        "id": 320,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 821.88,
        "temperature": 0,
        "text": " Okay, so I think we're actually done with this example,",
        "tokens": [
          51314,
          1033,
          11,
          370,
          286,
          519,
          321,
          434,
          767,
          1096,
          365,
          341,
          1365,
          11,
          51430
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 827.16,
        "id": 321,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 824.2,
        "temperature": 0,
        "text": " sort of, let's try.",
        "tokens": [
          51430,
          1333,
          295,
          11,
          718,
          311,
          853,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.25199204021030003,
        "compression_ratio": 1.7345454545454546,
        "end": 832.2,
        "id": 322,
        "no_speech_prob": 0.000006540433787449729,
        "seek": 80288,
        "start": 829.36,
        "temperature": 0,
        "text": " Okay, model is ready, video is ready, oh boy.",
        "tokens": [
          51688,
          1033,
          11,
          2316,
          307,
          1919,
          11,
          960,
          307,
          1919,
          11,
          1954,
          3237,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 834.76,
        "id": 323,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 832.24,
        "temperature": 0,
        "text": " What's the chance that this is going to work?",
        "tokens": [
          50366,
          708,
          311,
          264,
          2931,
          300,
          341,
          307,
          516,
          281,
          589,
          30,
          50492
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 839.08,
        "id": 324,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 834.76,
        "temperature": 0,
        "text": " Stop and guess, I give it like 10 to one this works.",
        "tokens": [
          50492,
          5535,
          293,
          2041,
          11,
          286,
          976,
          309,
          411,
          1266,
          281,
          472,
          341,
          1985,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 841.76,
        "id": 325,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 839.08,
        "temperature": 0,
        "text": " Okay, I'm going to step out of the frame,",
        "tokens": [
          50708,
          1033,
          11,
          286,
          478,
          516,
          281,
          1823,
          484,
          295,
          264,
          3920,
          11,
          50842
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 845.6,
        "id": 326,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 841.76,
        "temperature": 0,
        "text": " and I'm going to train it with a bunch of images",
        "tokens": [
          50842,
          293,
          286,
          478,
          516,
          281,
          3847,
          309,
          365,
          257,
          3840,
          295,
          5267,
          51034
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 847.8000000000001,
        "id": 327,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 845.6,
        "temperature": 0,
        "text": " of a ukulele, I'm going to move the ukulele around",
        "tokens": [
          51034,
          295,
          257,
          26769,
          2271,
          306,
          11,
          286,
          478,
          516,
          281,
          1286,
          264,
          26769,
          2271,
          306,
          926,
          51144
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 851.08,
        "id": 328,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 847.8000000000001,
        "temperature": 0,
        "text": " to give it a lot of different examples, further back.",
        "tokens": [
          51144,
          281,
          976,
          309,
          257,
          688,
          295,
          819,
          5110,
          11,
          3052,
          646,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 854.88,
        "id": 329,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 852.5600000000001,
        "temperature": 0,
        "text": " Now, and again, I should probably add something",
        "tokens": [
          51382,
          823,
          11,
          293,
          797,
          11,
          286,
          820,
          1391,
          909,
          746,
          51498
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 856.5600000000001,
        "id": 330,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 854.88,
        "temperature": 0,
        "text": " that shows me how many training examples,",
        "tokens": [
          51498,
          300,
          3110,
          385,
          577,
          867,
          3097,
          5110,
          11,
          51582
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 858.76,
        "id": 331,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 856.5600000000001,
        "temperature": 0,
        "text": " because I probably want to give around the same number",
        "tokens": [
          51582,
          570,
          286,
          1391,
          528,
          281,
          976,
          926,
          264,
          912,
          1230,
          51692
        ]
      },
      {
        "avg_logprob": -0.24660513741629464,
        "compression_ratio": 1.8072727272727274,
        "end": 862.0200000000001,
        "id": 332,
        "no_speech_prob": 0.00005738730760640465,
        "seek": 83220,
        "start": 858.76,
        "temperature": 0,
        "text": " of training examples for the whistle as with the ukulele.",
        "tokens": [
          51692,
          295,
          3097,
          5110,
          337,
          264,
          23470,
          382,
          365,
          264,
          26769,
          2271,
          306,
          13,
          51855
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 864.3,
        "id": 333,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 862.84,
        "temperature": 0,
        "text": " I'm going to train this, whistle, whistle, whistle,",
        "tokens": [
          50405,
          286,
          478,
          516,
          281,
          3847,
          341,
          11,
          23470,
          11,
          23470,
          11,
          23470,
          11,
          50478
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 866.5,
        "id": 334,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 864.3,
        "temperature": 0,
        "text": " whistle, whistle, now I'm going to hit train.",
        "tokens": [
          50478,
          23470,
          11,
          23470,
          11,
          586,
          286,
          478,
          516,
          281,
          2045,
          3847,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 870.18,
        "id": 335,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 868.06,
        "temperature": 0,
        "text": " When it's done, we should start seeing labels.",
        "tokens": [
          50666,
          1133,
          309,
          311,
          1096,
          11,
          321,
          820,
          722,
          2577,
          16949,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 872.96,
        "id": 336,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 870.18,
        "temperature": 0,
        "text": " Training complete, hmm, I don't see any labels.",
        "tokens": [
          50772,
          20620,
          3566,
          11,
          16478,
          11,
          286,
          500,
          380,
          536,
          604,
          16949,
          13,
          50911
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 879.06,
        "id": 337,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 875.5,
        "temperature": 0,
        "text": " No labels, it's so sad, what did I do wrong?",
        "tokens": [
          51038,
          883,
          16949,
          11,
          309,
          311,
          370,
          4227,
          11,
          437,
          630,
          286,
          360,
          2085,
          30,
          51216
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 881.22,
        "id": 338,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 879.06,
        "temperature": 0,
        "text": " Okay, so something's wrong, I got to figure this out,",
        "tokens": [
          51216,
          1033,
          11,
          370,
          746,
          311,
          2085,
          11,
          286,
          658,
          281,
          2573,
          341,
          484,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 882.6999999999999,
        "id": 339,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 881.22,
        "temperature": 0,
        "text": " I got to debug this.",
        "tokens": [
          51324,
          286,
          658,
          281,
          24083,
          341,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 886.64,
        "id": 340,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 882.6999999999999,
        "temperature": 0,
        "text": " All right, I really should put console.log results in,",
        "tokens": [
          51398,
          1057,
          558,
          11,
          286,
          534,
          820,
          829,
          11076,
          13,
          4987,
          3542,
          294,
          11,
          51595
        ]
      },
      {
        "avg_logprob": -0.2655971646308899,
        "compression_ratio": 1.7941176470588236,
        "end": 889.6,
        "id": 341,
        "no_speech_prob": 0.000022474045181297697,
        "seek": 86202,
        "start": 887.5799999999999,
        "temperature": 0,
        "text": " because I don't even know if this function is being called.",
        "tokens": [
          51642,
          570,
          286,
          500,
          380,
          754,
          458,
          498,
          341,
          2445,
          307,
          885,
          1219,
          13,
          51743
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 893.0600000000001,
        "id": 342,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 889.6,
        "temperature": 0,
        "text": " Let's make sure.classify is the right name of the function.",
        "tokens": [
          50364,
          961,
          311,
          652,
          988,
          2411,
          11665,
          2505,
          307,
          264,
          558,
          1315,
          295,
          264,
          2445,
          13,
          50537
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 897.12,
        "id": 343,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 894,
        "temperature": 0,
        "text": " Classify, callback, yeah.",
        "tokens": [
          50584,
          9471,
          2505,
          11,
          818,
          3207,
          11,
          1338,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 902.48,
        "id": 344,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 898.32,
        "temperature": 0,
        "text": " Oh no, no, no, yeah, callback, callback,",
        "tokens": [
          50800,
          876,
          572,
          11,
          572,
          11,
          572,
          11,
          1338,
          11,
          818,
          3207,
          11,
          818,
          3207,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 905.4,
        "id": 345,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 902.48,
        "temperature": 0,
        "text": " and then the callback is a function,",
        "tokens": [
          51008,
          293,
          550,
          264,
          818,
          3207,
          307,
          257,
          2445,
          11,
          51154
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 906.44,
        "id": 346,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 905.4,
        "temperature": 0,
        "text": " otherwise you can blah, blah, blah.",
        "tokens": [
          51154,
          5911,
          291,
          393,
          12288,
          11,
          12288,
          11,
          12288,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 910.88,
        "id": 347,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 906.44,
        "temperature": 0,
        "text": " So I think this is right, everything looks right to me.",
        "tokens": [
          51206,
          407,
          286,
          519,
          341,
          307,
          558,
          11,
          1203,
          1542,
          558,
          281,
          385,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 913.88,
        "id": 348,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 910.88,
        "temperature": 0,
        "text": " Am I just not drawing the label properly?",
        "tokens": [
          51428,
          2012,
          286,
          445,
          406,
          6316,
          264,
          7645,
          6108,
          30,
          51578
        ]
      },
      {
        "avg_logprob": -0.26666909343791456,
        "compression_ratio": 1.6734693877551021,
        "end": 915.82,
        "id": 349,
        "no_speech_prob": 0.00010391050454927608,
        "seek": 88960,
        "start": 913.88,
        "temperature": 0,
        "text": " No, there, there it is, label.",
        "tokens": [
          51578,
          883,
          11,
          456,
          11,
          456,
          309,
          307,
          11,
          7645,
          13,
          51675
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 921.1400000000001,
        "id": 350,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 916.6600000000001,
        "temperature": 0,
        "text": " This is me not paying close attention.",
        "tokens": [
          50406,
          639,
          307,
          385,
          406,
          6229,
          1998,
          3202,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 924.82,
        "id": 351,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 921.1400000000001,
        "temperature": 0,
        "text": " This is interesting, and this is now a question",
        "tokens": [
          50630,
          639,
          307,
          1880,
          11,
          293,
          341,
          307,
          586,
          257,
          1168,
          50814
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 929.82,
        "id": 352,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 924.82,
        "temperature": 0,
        "text": " for the ml5 library itself, but the thing",
        "tokens": [
          50814,
          337,
          264,
          23271,
          20,
          6405,
          2564,
          11,
          457,
          264,
          551,
          51064
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 931.96,
        "id": 353,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 929.82,
        "temperature": 0,
        "text": " that comes in the gotResults function",
        "tokens": [
          51064,
          300,
          1487,
          294,
          264,
          658,
          33274,
          33361,
          2445,
          51171
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 934.2,
        "id": 354,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 931.96,
        "temperature": 0,
        "text": " is actually just the label that it guesses.",
        "tokens": [
          51171,
          307,
          767,
          445,
          264,
          7645,
          300,
          309,
          42703,
          13,
          51283
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 936.7,
        "id": 355,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 934.2,
        "temperature": 0,
        "text": " So there's not like the class name and the probability,",
        "tokens": [
          51283,
          407,
          456,
          311,
          406,
          411,
          264,
          1508,
          1315,
          293,
          264,
          8482,
          11,
          51408
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 938.44,
        "id": 356,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 936.7,
        "temperature": 0,
        "text": " all that stuff that came with MobileNet,",
        "tokens": [
          51408,
          439,
          300,
          1507,
          300,
          1361,
          365,
          22625,
          31890,
          11,
          51495
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 940.1800000000001,
        "id": 357,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 938.44,
        "temperature": 0,
        "text": " it's not giving us all of that information,",
        "tokens": [
          51495,
          309,
          311,
          406,
          2902,
          505,
          439,
          295,
          300,
          1589,
          11,
          51582
        ]
      },
      {
        "avg_logprob": -0.277558959356629,
        "compression_ratio": 1.669603524229075,
        "end": 941.5,
        "id": 358,
        "no_speech_prob": 6.179391220939578e-7,
        "seek": 91582,
        "start": 940.1800000000001,
        "temperature": 0,
        "text": " which probably makes sense.",
        "tokens": [
          51582,
          597,
          1391,
          1669,
          2020,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.26885846455891926,
        "compression_ratio": 1.425531914893617,
        "end": 946.5,
        "id": 359,
        "no_speech_prob": 0.0000015534969861619174,
        "seek": 94150,
        "start": 941.5,
        "temperature": 0,
        "text": " So actually, all I want to do is say label equals result.",
        "tokens": [
          50364,
          407,
          767,
          11,
          439,
          286,
          528,
          281,
          360,
          307,
          584,
          7645,
          6915,
          1874,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.26885846455891926,
        "compression_ratio": 1.425531914893617,
        "end": 950.14,
        "id": 360,
        "no_speech_prob": 0.0000015534969861619174,
        "seek": 94150,
        "start": 948.34,
        "temperature": 0,
        "text": " So that was a little bit of a digression,",
        "tokens": [
          50706,
          407,
          300,
          390,
          257,
          707,
          857,
          295,
          257,
          2528,
          2775,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.26885846455891926,
        "compression_ratio": 1.425531914893617,
        "end": 952.28,
        "id": 361,
        "no_speech_prob": 0.0000015534969861619174,
        "seek": 94150,
        "start": 950.14,
        "temperature": 0,
        "text": " I had to figure out what I did wrong there.",
        "tokens": [
          50796,
          286,
          632,
          281,
          2573,
          484,
          437,
          286,
          630,
          2085,
          456,
          13,
          50903
        ]
      },
      {
        "avg_logprob": -0.26885846455891926,
        "compression_ratio": 1.425531914893617,
        "end": 955.38,
        "id": 362,
        "no_speech_prob": 0.0000015534969861619174,
        "seek": 94150,
        "start": 952.28,
        "temperature": 0,
        "text": " Now, this should work.",
        "tokens": [
          50903,
          823,
          11,
          341,
          820,
          589,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.26885846455891926,
        "compression_ratio": 1.425531914893617,
        "end": 956.42,
        "id": 363,
        "no_speech_prob": 0.0000015534969861619174,
        "seek": 94150,
        "start": 955.38,
        "temperature": 0,
        "text": " Okay, ready?",
        "tokens": [
          51058,
          1033,
          11,
          1919,
          30,
          51110
        ]
      },
      {
        "avg_logprob": -0.26885846455891926,
        "compression_ratio": 1.425531914893617,
        "end": 958.12,
        "id": 364,
        "no_speech_prob": 0.0000015534969861619174,
        "seek": 94150,
        "start": 956.42,
        "temperature": 0,
        "text": " Let's try it with the ukulele.",
        "tokens": [
          51110,
          961,
          311,
          853,
          309,
          365,
          264,
          26769,
          2271,
          306,
          13,
          51195
        ]
      },
      {
        "avg_logprob": -0.26885846455891926,
        "compression_ratio": 1.425531914893617,
        "end": 964.38,
        "id": 365,
        "no_speech_prob": 0.0000015534969861619174,
        "seek": 94150,
        "start": 959.38,
        "temperature": 0,
        "text": " Ukulele, you're giving it a lot of examples of a ukulele.",
        "tokens": [
          51258,
          9816,
          2271,
          306,
          11,
          291,
          434,
          2902,
          309,
          257,
          688,
          295,
          5110,
          295,
          257,
          26769,
          2271,
          306,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.36532518756923393,
        "compression_ratio": 1.504,
        "end": 970.38,
        "id": 366,
        "no_speech_prob": 0.00003535614814609289,
        "seek": 96438,
        "start": 965.38,
        "temperature": 0,
        "text": " You're giving it a lot of examples of a whistle.",
        "tokens": [
          50414,
          509,
          434,
          2902,
          309,
          257,
          688,
          295,
          5110,
          295,
          257,
          23470,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.36532518756923393,
        "compression_ratio": 1.504,
        "end": 975.56,
        "id": 367,
        "no_speech_prob": 0.00003535614814609289,
        "seek": 96438,
        "start": 972.14,
        "temperature": 0,
        "text": " Now I'm going to train it, I'm going to do my training dance.",
        "tokens": [
          50752,
          823,
          286,
          478,
          516,
          281,
          3847,
          309,
          11,
          286,
          478,
          516,
          281,
          360,
          452,
          3097,
          4489,
          13,
          50923
        ]
      },
      {
        "avg_logprob": -0.36532518756923393,
        "compression_ratio": 1.504,
        "end": 979.64,
        "id": 368,
        "no_speech_prob": 0.00003535614814609289,
        "seek": 96438,
        "start": 978.14,
        "temperature": 0,
        "text": " And training is complete.",
        "tokens": [
          51052,
          400,
          3097,
          307,
          3566,
          13,
          51127
        ]
      },
      {
        "avg_logprob": -0.36532518756923393,
        "compression_ratio": 1.504,
        "end": 983.3,
        "id": 369,
        "no_speech_prob": 0.00003535614814609289,
        "seek": 96438,
        "start": 981.72,
        "temperature": 0,
        "text": " Here's a ukulele.",
        "tokens": [
          51231,
          1692,
          311,
          257,
          26769,
          2271,
          306,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.36532518756923393,
        "compression_ratio": 1.504,
        "end": 986.14,
        "id": 370,
        "no_speech_prob": 0.00003535614814609289,
        "seek": 96438,
        "start": 984.78,
        "temperature": 0,
        "text": " It is a ukulele.",
        "tokens": [
          51384,
          467,
          307,
          257,
          26769,
          2271,
          306,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.36532518756923393,
        "compression_ratio": 1.504,
        "end": 990.62,
        "id": 371,
        "no_speech_prob": 0.00003535614814609289,
        "seek": 96438,
        "start": 989.06,
        "temperature": 0,
        "text": " It is a whistle.",
        "tokens": [
          51598,
          467,
          307,
          257,
          23470,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 992.54,
        "id": 372,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 991.22,
        "temperature": 0,
        "text": " It is a ukulele.",
        "tokens": [
          50394,
          467,
          307,
          257,
          26769,
          2271,
          306,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 999.02,
        "id": 373,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 996.9,
        "temperature": 0,
        "text": " It is a whistle.",
        "tokens": [
          50678,
          467,
          307,
          257,
          23470,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 999.86,
        "id": 374,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 999.02,
        "temperature": 0,
        "text": " Yay, okay!",
        "tokens": [
          50784,
          13268,
          11,
          1392,
          0,
          50826
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1002.98,
        "id": 375,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1002.12,
        "temperature": 0,
        "text": " So this actually works.",
        "tokens": [
          50939,
          407,
          341,
          767,
          1985,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1004.82,
        "id": 376,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1002.98,
        "temperature": 0,
        "text": " Here's the thing, I want to show you",
        "tokens": [
          50982,
          1692,
          311,
          264,
          551,
          11,
          286,
          528,
          281,
          855,
          291,
          51074
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1006.42,
        "id": 377,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1004.82,
        "temperature": 0,
        "text": " something more interesting here.",
        "tokens": [
          51074,
          746,
          544,
          1880,
          510,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1008.38,
        "id": 378,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1007.54,
        "temperature": 0,
        "text": " And it's not more interesting,",
        "tokens": [
          51210,
          400,
          309,
          311,
          406,
          544,
          1880,
          11,
          51252
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1009.62,
        "id": 379,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1008.38,
        "temperature": 0,
        "text": " I'm going to show you something different.",
        "tokens": [
          51252,
          286,
          478,
          516,
          281,
          855,
          291,
          746,
          819,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1011.0600000000001,
        "id": 380,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1009.62,
        "temperature": 0,
        "text": " I'm going to change this to,",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          11,
          51386
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1013.18,
        "id": 381,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1011.0600000000001,
        "temperature": 0,
        "text": " I'm going to leave all the variable names the same,",
        "tokens": [
          51386,
          286,
          478,
          516,
          281,
          1856,
          439,
          264,
          7006,
          5288,
          264,
          912,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1015.54,
        "id": 382,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1013.18,
        "temperature": 0,
        "text": " but I'm going to change this to smile.",
        "tokens": [
          51492,
          457,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          7563,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1017.2,
        "id": 383,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1015.54,
        "temperature": 0,
        "text": " I'm going to change this to happy.",
        "tokens": [
          51610,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          2055,
          13,
          51693
        ]
      },
      {
        "avg_logprob": -0.2833326444851132,
        "compression_ratio": 2.0725388601036268,
        "end": 1020.26,
        "id": 384,
        "no_speech_prob": 0.00003535609721438959,
        "seek": 99062,
        "start": 1018.26,
        "temperature": 0,
        "text": " I'm going to change this to sad.",
        "tokens": [
          51746,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          4227,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1023.22,
        "id": 385,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1021.62,
        "temperature": 0,
        "text": " Sad, okay?",
        "tokens": [
          50414,
          12269,
          11,
          1392,
          30,
          50494
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1025.02,
        "id": 386,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1023.22,
        "temperature": 0,
        "text": " So, and I'm going to run this again.",
        "tokens": [
          50494,
          407,
          11,
          293,
          286,
          478,
          516,
          281,
          1190,
          341,
          797,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1027.38,
        "id": 387,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1026.14,
        "temperature": 0,
        "text": " And I'm going to do this.",
        "tokens": [
          50640,
          400,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1035.62,
        "id": 388,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1030.62,
        "temperature": 0,
        "text": " I'm going to get up, I'm going to get up, a knee smiling.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          483,
          493,
          11,
          286,
          478,
          516,
          281,
          483,
          493,
          11,
          257,
          9434,
          16005,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1038.06,
        "id": 389,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1035.82,
        "temperature": 0,
        "text": " Mm, mm, mm, mm, mm, mm, mm.",
        "tokens": [
          51124,
          8266,
          11,
          11169,
          11,
          11169,
          11,
          11169,
          11,
          11169,
          11,
          11169,
          11,
          11169,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1041.1,
        "id": 390,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1039.66,
        "temperature": 0,
        "text": " Then I'm going to hit train.",
        "tokens": [
          51316,
          1396,
          286,
          478,
          516,
          281,
          2045,
          3847,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1044.34,
        "id": 391,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1042.34,
        "temperature": 0,
        "text": " Let it train for a little bit.",
        "tokens": [
          51450,
          961,
          309,
          3847,
          337,
          257,
          707,
          857,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.42687217048976733,
        "compression_ratio": 1.7462686567164178,
        "end": 1045.18,
        "id": 392,
        "no_speech_prob": 0.00000839799213281367,
        "seek": 102062,
        "start": 1044.34,
        "temperature": 0,
        "text": " It's finished.",
        "tokens": [
          51550,
          467,
          311,
          4335,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1051.78,
        "id": 393,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1050.62,
        "temperature": 0,
        "text": " It's finished.",
        "tokens": [
          50364,
          467,
          311,
          4335,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1059.58,
        "id": 394,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1058.1399999999999,
        "temperature": 0,
        "text": " I mean, how long should I do that for?",
        "tokens": [
          50740,
          286,
          914,
          11,
          577,
          938,
          820,
          286,
          360,
          300,
          337,
          30,
          50812
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1060.86,
        "id": 395,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1059.58,
        "temperature": 0,
        "text": " This is pretty cool.",
        "tokens": [
          50812,
          639,
          307,
          1238,
          1627,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1062.1799999999998,
        "id": 396,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1060.86,
        "temperature": 0,
        "text": " Here's the thing, I don't,",
        "tokens": [
          50876,
          1692,
          311,
          264,
          551,
          11,
          286,
          500,
          380,
          11,
          50942
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1063.9799999999998,
        "id": 397,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1062.1799999999998,
        "temperature": 0,
        "text": " it doesn't just have to be image recognition.",
        "tokens": [
          50942,
          309,
          1177,
          380,
          445,
          362,
          281,
          312,
          3256,
          11150,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1066.26,
        "id": 398,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1063.9799999999998,
        "temperature": 0,
        "text": " I can sort of train it with different facial expressions.",
        "tokens": [
          51032,
          286,
          393,
          1333,
          295,
          3847,
          309,
          365,
          819,
          15642,
          15277,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1069.58,
        "id": 399,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1066.26,
        "temperature": 0,
        "text": " The fact that MobileNet, what MobileNet is really good at,",
        "tokens": [
          51146,
          440,
          1186,
          300,
          22625,
          31890,
          11,
          437,
          22625,
          31890,
          307,
          534,
          665,
          412,
          11,
          51312
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1071.54,
        "id": 400,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1069.58,
        "temperature": 0,
        "text": " if you recall, is taking an image",
        "tokens": [
          51312,
          498,
          291,
          9901,
          11,
          307,
          1940,
          364,
          3256,
          51410
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1074.34,
        "id": 401,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1071.54,
        "temperature": 0,
        "text": " and boiling it down to a smaller list of numbers",
        "tokens": [
          51410,
          293,
          16208,
          309,
          760,
          281,
          257,
          4356,
          1329,
          295,
          3547,
          51550
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1076.58,
        "id": 402,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1074.34,
        "temperature": 0,
        "text": " that kind of define the essence of that image.",
        "tokens": [
          51550,
          300,
          733,
          295,
          6964,
          264,
          12801,
          295,
          300,
          3256,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.25261836581759983,
        "compression_ratio": 1.6452830188679246,
        "end": 1079.02,
        "id": 403,
        "no_speech_prob": 0.00005829102883581072,
        "seek": 105062,
        "start": 1076.58,
        "temperature": 0,
        "text": " So it doesn't matter what the content is,",
        "tokens": [
          51662,
          407,
          309,
          1177,
          380,
          1871,
          437,
          264,
          2701,
          307,
          11,
          51784
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1081.22,
        "id": 404,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1079.02,
        "temperature": 0,
        "text": " it can sort of figure out the essence of me smiling,",
        "tokens": [
          50364,
          309,
          393,
          1333,
          295,
          2573,
          484,
          264,
          12801,
          295,
          385,
          16005,
          11,
          50474
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1082.54,
        "id": 405,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1081.22,
        "temperature": 0,
        "text": " the essence of me frowning.",
        "tokens": [
          50474,
          264,
          12801,
          295,
          385,
          431,
          648,
          278,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1084.8,
        "id": 406,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1082.54,
        "temperature": 0,
        "text": " You know, it is important, though, to remember,",
        "tokens": [
          50540,
          509,
          458,
          11,
          309,
          307,
          1021,
          11,
          1673,
          11,
          281,
          1604,
          11,
          50653
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1087.82,
        "id": 407,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1084.8,
        "temperature": 0,
        "text": " it's not really learning smiling or frowning.",
        "tokens": [
          50653,
          309,
          311,
          406,
          534,
          2539,
          16005,
          420,
          431,
          648,
          278,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1091.94,
        "id": 408,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1087.82,
        "temperature": 0,
        "text": " It's kind of, and if I were to turn this like this way,",
        "tokens": [
          50804,
          467,
          311,
          733,
          295,
          11,
          293,
          498,
          286,
          645,
          281,
          1261,
          341,
          411,
          341,
          636,
          11,
          51010
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1094.74,
        "id": 409,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1091.94,
        "temperature": 0,
        "text": " you can sort of see some of the room here, and I go here.",
        "tokens": [
          51010,
          291,
          393,
          1333,
          295,
          536,
          512,
          295,
          264,
          1808,
          510,
          11,
          293,
          286,
          352,
          510,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1100.94,
        "id": 410,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1099.18,
        "temperature": 0,
        "text": " It's not working so well,",
        "tokens": [
          51372,
          467,
          311,
          406,
          1364,
          370,
          731,
          11,
          51460
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1102.82,
        "id": 411,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1100.94,
        "temperature": 0,
        "text": " because it kind of learned all that.",
        "tokens": [
          51460,
          570,
          309,
          733,
          295,
          3264,
          439,
          300,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1105.58,
        "id": 412,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1102.82,
        "temperature": 0,
        "text": " It learned sort of like all that stuff with the background.",
        "tokens": [
          51554,
          467,
          3264,
          1333,
          295,
          411,
          439,
          300,
          1507,
          365,
          264,
          3678,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.22459942547243034,
        "compression_ratio": 1.8097165991902835,
        "end": 1107.82,
        "id": 413,
        "no_speech_prob": 0.0000032887462566577597,
        "seek": 107902,
        "start": 1105.58,
        "temperature": 0,
        "text": " So there's a lot of nuance to this,",
        "tokens": [
          51692,
          407,
          456,
          311,
          257,
          688,
          295,
          42625,
          281,
          341,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1109.22,
        "id": 414,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1107.82,
        "temperature": 0,
        "text": " and it's really important to remember.",
        "tokens": [
          50364,
          293,
          309,
          311,
          534,
          1021,
          281,
          1604,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1111.3799999999999,
        "id": 415,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1109.22,
        "temperature": 0,
        "text": " It's not some magic, it doesn't understand,",
        "tokens": [
          50434,
          467,
          311,
          406,
          512,
          5585,
          11,
          309,
          1177,
          380,
          1223,
          11,
          50542
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1115.1799999999998,
        "id": 416,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1111.3799999999999,
        "temperature": 0,
        "text": " the computer doesn't have some understanding of emotions.",
        "tokens": [
          50542,
          264,
          3820,
          1177,
          380,
          362,
          512,
          3701,
          295,
          8462,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1117.98,
        "id": 417,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1115.1799999999998,
        "temperature": 0,
        "text": " It's really just looking at, I've got a new image,",
        "tokens": [
          50732,
          467,
          311,
          534,
          445,
          1237,
          412,
          11,
          286,
          600,
          658,
          257,
          777,
          3256,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1121.02,
        "id": 418,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1117.98,
        "temperature": 0,
        "text": " and I'm comparing it to a bunch of images I got before.",
        "tokens": [
          50872,
          293,
          286,
          478,
          15763,
          309,
          281,
          257,
          3840,
          295,
          5267,
          286,
          658,
          949,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1122.4399999999998,
        "id": 419,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1121.02,
        "temperature": 0,
        "text": " What's it most similar like?",
        "tokens": [
          51024,
          708,
          311,
          309,
          881,
          2531,
          411,
          30,
          51095
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1123.78,
        "id": 420,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1122.4399999999998,
        "temperature": 0,
        "text": " Let's see if it sort of,",
        "tokens": [
          51095,
          961,
          311,
          536,
          498,
          309,
          1333,
          295,
          11,
          51162
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1126.1,
        "id": 421,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1123.78,
        "temperature": 0,
        "text": " now that I moved the camera around, is it working?",
        "tokens": [
          51162,
          586,
          300,
          286,
          4259,
          264,
          2799,
          926,
          11,
          307,
          309,
          1364,
          30,
          51278
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1131.82,
        "id": 422,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1130.56,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51501,
          407,
          510,
          311,
          264,
          551,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1134.12,
        "id": 423,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1131.82,
        "temperature": 0,
        "text": " You now have something, this is the thing.",
        "tokens": [
          51564,
          509,
          586,
          362,
          746,
          11,
          341,
          307,
          264,
          551,
          13,
          51679
        ]
      },
      {
        "avg_logprob": -0.20832618314828447,
        "compression_ratio": 1.6865671641791045,
        "end": 1137.54,
        "id": 424,
        "no_speech_prob": 0.00000801348596723983,
        "seek": 110782,
        "start": 1134.12,
        "temperature": 0,
        "text": " Go, go forth, add a third category.",
        "tokens": [
          51679,
          1037,
          11,
          352,
          5220,
          11,
          909,
          257,
          2636,
          7719,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1140.82,
        "id": 425,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1138.3799999999999,
        "temperature": 0,
        "text": " Make a game where I'm playing Pong.",
        "tokens": [
          50406,
          4387,
          257,
          1216,
          689,
          286,
          478,
          2433,
          430,
          556,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1143.78,
        "id": 426,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1140.82,
        "temperature": 0,
        "text": " Actually, this is a project I should reference by Alejandro.",
        "tokens": [
          50528,
          5135,
          11,
          341,
          307,
          257,
          1716,
          286,
          820,
          6408,
          538,
          44568,
          29173,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1146.1,
        "id": 427,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1143.78,
        "temperature": 0,
        "text": " Let me go to ml5js.org.",
        "tokens": [
          50676,
          961,
          385,
          352,
          281,
          23271,
          20,
          25530,
          13,
          4646,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1148.94,
        "id": 428,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1146.1,
        "temperature": 0,
        "text": " Alejandro, under experiments,",
        "tokens": [
          50792,
          44568,
          29173,
          11,
          833,
          12050,
          11,
          50934
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1152.1399999999999,
        "id": 429,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1148.94,
        "temperature": 0,
        "text": " made a project called Pong ML,",
        "tokens": [
          50934,
          1027,
          257,
          1716,
          1219,
          430,
          556,
          21601,
          11,
          51094
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1154.46,
        "id": 430,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1152.1399999999999,
        "temperature": 0,
        "text": " which basically used the same exact technique",
        "tokens": [
          51094,
          597,
          1936,
          1143,
          264,
          912,
          1900,
          6532,
          51210
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1157.46,
        "id": 431,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1154.46,
        "temperature": 0,
        "text": " to train various hand gestures,",
        "tokens": [
          51210,
          281,
          3847,
          3683,
          1011,
          28475,
          11,
          51360
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1159.5,
        "id": 432,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1157.46,
        "temperature": 0,
        "text": " and then you could play Pong with hand gestures.",
        "tokens": [
          51360,
          293,
          550,
          291,
          727,
          862,
          430,
          556,
          365,
          1011,
          28475,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1162.5,
        "id": 433,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1159.5,
        "temperature": 0,
        "text": " So there's so many possibilities of what you could do",
        "tokens": [
          51462,
          407,
          456,
          311,
          370,
          867,
          12178,
          295,
          437,
          291,
          727,
          360,
          51612
        ]
      },
      {
        "avg_logprob": -0.21933192866189138,
        "compression_ratio": 1.5770750988142292,
        "end": 1165.54,
        "id": 434,
        "no_speech_prob": 0.000030241859349189326,
        "seek": 113754,
        "start": 1162.5,
        "temperature": 0,
        "text": " just from being able to train using,",
        "tokens": [
          51612,
          445,
          490,
          885,
          1075,
          281,
          3847,
          1228,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1167.1399999999999,
        "id": 435,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1165.54,
        "temperature": 0,
        "text": " starting with a mobile model",
        "tokens": [
          50364,
          2891,
          365,
          257,
          6013,
          2316,
          50444
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1169.02,
        "id": 436,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1167.1399999999999,
        "temperature": 0,
        "text": " and applying transfer learning.",
        "tokens": [
          50444,
          293,
          9275,
          5003,
          2539,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1171.86,
        "id": 437,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1170.5,
        "temperature": 0,
        "text": " Okay, are you with me?",
        "tokens": [
          50612,
          1033,
          11,
          366,
          291,
          365,
          385,
          30,
          50680
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1172.82,
        "id": 438,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1171.86,
        "temperature": 0,
        "text": " Did this make sense?",
        "tokens": [
          50680,
          2589,
          341,
          652,
          2020,
          30,
          50728
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1174.1,
        "id": 439,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1172.82,
        "temperature": 0,
        "text": " Make something, go and try this,",
        "tokens": [
          50728,
          4387,
          746,
          11,
          352,
          293,
          853,
          341,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1175.86,
        "id": 440,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1174.1,
        "temperature": 0,
        "text": " make your own version of it.",
        "tokens": [
          50792,
          652,
          428,
          1065,
          3037,
          295,
          309,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1178.3,
        "id": 441,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1175.86,
        "temperature": 0,
        "text": " Really think about the interface.",
        "tokens": [
          50880,
          4083,
          519,
          466,
          264,
          9226,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1179.58,
        "id": 442,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1178.3,
        "temperature": 0,
        "text": " One more thing.",
        "tokens": [
          51002,
          1485,
          544,
          551,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1180.8999999999999,
        "id": 443,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1179.58,
        "temperature": 0,
        "text": " Something you're really going to want to do,",
        "tokens": [
          51066,
          6595,
          291,
          434,
          534,
          516,
          281,
          528,
          281,
          360,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1182.3799999999999,
        "id": 444,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1180.8999999999999,
        "temperature": 0,
        "text": " and you probably noticed this,",
        "tokens": [
          51132,
          293,
          291,
          1391,
          5694,
          341,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1184.42,
        "id": 445,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1182.3799999999999,
        "temperature": 0,
        "text": " every time I restarted the sketch,",
        "tokens": [
          51206,
          633,
          565,
          286,
          21022,
          292,
          264,
          12325,
          11,
          51308
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1186.8999999999999,
        "id": 446,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1184.42,
        "temperature": 0,
        "text": " I had to retrain it with images again,",
        "tokens": [
          51308,
          286,
          632,
          281,
          1533,
          7146,
          309,
          365,
          5267,
          797,
          11,
          51432
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1190.2,
        "id": 447,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1186.8999999999999,
        "temperature": 0,
        "text": " which is fun for the real-time interactive nature of this,",
        "tokens": [
          51432,
          597,
          307,
          1019,
          337,
          264,
          957,
          12,
          3766,
          15141,
          3687,
          295,
          341,
          11,
          51597
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1193.7,
        "id": 448,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1190.2,
        "temperature": 0,
        "text": " but if you're actually going to do this for a while,",
        "tokens": [
          51597,
          457,
          498,
          291,
          434,
          767,
          516,
          281,
          360,
          341,
          337,
          257,
          1339,
          11,
          51772
        ]
      },
      {
        "avg_logprob": -0.25759336110707876,
        "compression_ratio": 1.7541528239202657,
        "end": 1195.26,
        "id": 449,
        "no_speech_prob": 0.000016187554138014093,
        "seek": 116554,
        "start": 1193.7,
        "temperature": 0,
        "text": " and you're building an installation or something,",
        "tokens": [
          51772,
          293,
          291,
          434,
          2390,
          364,
          13260,
          420,
          746,
          11,
          51850
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1196.9,
        "id": 450,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1195.98,
        "temperature": 0,
        "text": " and you've trained it with a bunch of images,",
        "tokens": [
          50400,
          293,
          291,
          600,
          8895,
          309,
          365,
          257,
          3840,
          295,
          5267,
          11,
          50446
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1199.18,
        "id": 451,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1196.9,
        "temperature": 0,
        "text": " and you want to, I don't know,",
        "tokens": [
          50446,
          293,
          291,
          528,
          281,
          11,
          286,
          500,
          380,
          458,
          11,
          50560
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1200.82,
        "id": 452,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1199.18,
        "temperature": 0,
        "text": " save the model that you've done,",
        "tokens": [
          50560,
          3155,
          264,
          2316,
          300,
          291,
          600,
          1096,
          11,
          50642
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1202.3799999999999,
        "id": 453,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1200.82,
        "temperature": 0,
        "text": " save all that work,",
        "tokens": [
          50642,
          3155,
          439,
          300,
          589,
          11,
          50720
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1204.34,
        "id": 454,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1202.3799999999999,
        "temperature": 0,
        "text": " you're going to want to save and be able to reload",
        "tokens": [
          50720,
          291,
          434,
          516,
          281,
          528,
          281,
          3155,
          293,
          312,
          1075,
          281,
          25628,
          50818
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1206.78,
        "id": 455,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1204.34,
        "temperature": 0,
        "text": " the result of that transfer learning.",
        "tokens": [
          50818,
          264,
          1874,
          295,
          300,
          5003,
          2539,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1208.42,
        "id": 456,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1206.78,
        "temperature": 0,
        "text": " At present, at the time of this recording,",
        "tokens": [
          50940,
          1711,
          1974,
          11,
          412,
          264,
          565,
          295,
          341,
          6613,
          11,
          51022
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1211.46,
        "id": 457,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1208.42,
        "temperature": 0,
        "text": " there isn't a way to do that easily with the ml5 library.",
        "tokens": [
          51022,
          456,
          1943,
          380,
          257,
          636,
          281,
          360,
          300,
          3612,
          365,
          264,
          23271,
          20,
          6405,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1213.18,
        "id": 458,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1211.46,
        "temperature": 0,
        "text": " It's really technically possible.",
        "tokens": [
          51174,
          467,
          311,
          534,
          12120,
          1944,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1214.98,
        "id": 459,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1213.18,
        "temperature": 0,
        "text": " There is a GitHub issue.",
        "tokens": [
          51260,
          821,
          307,
          257,
          23331,
          2734,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1218.18,
        "id": 460,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1214.98,
        "temperature": 0,
        "text": " Currently it is ml5 library issues 174",
        "tokens": [
          51350,
          19964,
          309,
          307,
          23271,
          20,
          6405,
          2663,
          3282,
          19,
          51510
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1219.8799999999999,
        "id": 461,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1218.18,
        "temperature": 0,
        "text": " with a discussion about this feature.",
        "tokens": [
          51510,
          365,
          257,
          5017,
          466,
          341,
          4111,
          13,
          51595
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1222.62,
        "id": 462,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1219.8799999999999,
        "temperature": 0,
        "text": " Certainly once this feature exists,",
        "tokens": [
          51595,
          16628,
          1564,
          341,
          4111,
          8198,
          11,
          51732
        ]
      },
      {
        "avg_logprob": -0.21604924519856772,
        "compression_ratio": 1.721311475409836,
        "end": 1224.5,
        "id": 463,
        "no_speech_prob": 0.000020145618691458367,
        "seek": 119526,
        "start": 1222.62,
        "temperature": 0,
        "text": " I will come back and make a video",
        "tokens": [
          51732,
          286,
          486,
          808,
          646,
          293,
          652,
          257,
          960,
          51826
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1226.34,
        "id": 464,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1224.5,
        "temperature": 0,
        "text": " to show you how to do that, okay?",
        "tokens": [
          50364,
          281,
          855,
          291,
          577,
          281,
          360,
          300,
          11,
          1392,
          30,
          50456
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1228.26,
        "id": 465,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1226.34,
        "temperature": 0,
        "text": " Thanks for watching this video.",
        "tokens": [
          50456,
          2561,
          337,
          1976,
          341,
          960,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1229.1,
        "id": 466,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1228.26,
        "temperature": 0,
        "text": " Oh, I'm going to do one more,",
        "tokens": [
          50552,
          876,
          11,
          286,
          478,
          516,
          281,
          360,
          472,
          544,
          11,
          50594
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1230.18,
        "id": 467,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1229.1,
        "temperature": 0,
        "text": " I'm going to do something interesting.",
        "tokens": [
          50594,
          286,
          478,
          516,
          281,
          360,
          746,
          1880,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1232.02,
        "id": 468,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1230.18,
        "temperature": 0,
        "text": " I'm going to do, I mean, hopefully,",
        "tokens": [
          50648,
          286,
          478,
          516,
          281,
          360,
          11,
          286,
          914,
          11,
          4696,
          11,
          50740
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1233.02,
        "id": 469,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1232.02,
        "temperature": 0,
        "text": " I'm going to do one more video",
        "tokens": [
          50740,
          286,
          478,
          516,
          281,
          360,
          472,
          544,
          960,
          50790
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1235.16,
        "id": 470,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1233.02,
        "temperature": 0,
        "text": " with something very similar to what I did just here,",
        "tokens": [
          50790,
          365,
          746,
          588,
          2531,
          281,
          437,
          286,
          630,
          445,
          510,
          11,
          50897
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1237.18,
        "id": 471,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1235.16,
        "temperature": 0,
        "text": " but I'm going to do something called a regression.",
        "tokens": [
          50897,
          457,
          286,
          478,
          516,
          281,
          360,
          746,
          1219,
          257,
          24590,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1239.14,
        "id": 472,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1237.18,
        "temperature": 0,
        "text": " So I'm going to define what a regression is",
        "tokens": [
          50998,
          407,
          286,
          478,
          516,
          281,
          6964,
          437,
          257,
          24590,
          307,
          51096
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1241.26,
        "id": 473,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1239.14,
        "temperature": 0,
        "text": " and show you how I can do transfer learning",
        "tokens": [
          51096,
          293,
          855,
          291,
          577,
          286,
          393,
          360,
          5003,
          2539,
          51202
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1243.78,
        "id": 474,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1241.26,
        "temperature": 0,
        "text": " with the MobileNet model to perform a regression.",
        "tokens": [
          51202,
          365,
          264,
          22625,
          31890,
          2316,
          281,
          2042,
          257,
          24590,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1244.62,
        "id": 475,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1243.78,
        "temperature": 0,
        "text": " Why would I want to do that?",
        "tokens": [
          51328,
          1545,
          576,
          286,
          528,
          281,
          360,
          300,
          30,
          51370
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1246.26,
        "id": 476,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1244.62,
        "temperature": 0,
        "text": " I don't know, I guess we'll have to watch.",
        "tokens": [
          51370,
          286,
          500,
          380,
          458,
          11,
          286,
          2041,
          321,
          603,
          362,
          281,
          1159,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1247.1,
        "id": 477,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1246.26,
        "temperature": 0,
        "text": " Basically a slider.",
        "tokens": [
          51452,
          8537,
          257,
          26046,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1248.58,
        "id": 478,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1247.1,
        "temperature": 0,
        "text": " If I want to build a control something",
        "tokens": [
          51494,
          759,
          286,
          528,
          281,
          1322,
          257,
          1969,
          262,
          23445,
          51568
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1250.7,
        "id": 479,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1248.58,
        "temperature": 0,
        "text": " with my hand moving back and forth as a slider,",
        "tokens": [
          51568,
          365,
          452,
          1011,
          2684,
          646,
          293,
          5220,
          382,
          257,
          26046,
          11,
          51674
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1252.28,
        "id": 480,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1250.7,
        "temperature": 0,
        "text": " that's something that I can use a regression for.",
        "tokens": [
          51674,
          300,
          311,
          746,
          300,
          286,
          393,
          764,
          257,
          24590,
          337,
          13,
          51753
        ]
      },
      {
        "avg_logprob": -0.22811599359279724,
        "compression_ratio": 2.0231884057971015,
        "end": 1254.02,
        "id": 481,
        "no_speech_prob": 0.00027802688418887556,
        "seek": 122450,
        "start": 1252.28,
        "temperature": 0,
        "text": " All right, see you there.",
        "tokens": [
          51753,
          1057,
          558,
          11,
          536,
          291,
          456,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -2.2196760177612305,
        "compression_ratio": 1.6428571428571428,
        "end": 1256.3,
        "id": 482,
        "no_speech_prob": 0.5597968101501465,
        "seek": 125402,
        "start": 1254.84,
        "temperature": 1,
        "text": " BTS",
        "tokens": [
          50405,
          17951,
          50478
        ]
      },
      {
        "avg_logprob": -2.2196760177612305,
        "compression_ratio": 1.6428571428571428,
        "end": 1257.74,
        "id": 483,
        "no_speech_prob": 0.5597968101501465,
        "seek": 125402,
        "start": 1256.3,
        "temperature": 1,
        "text": " BTS",
        "tokens": [
          50478,
          17951,
          50550
        ]
      },
      {
        "avg_logprob": -2.2196760177612305,
        "compression_ratio": 1.6428571428571428,
        "end": 1259.16,
        "id": 484,
        "no_speech_prob": 0.5597968101501465,
        "seek": 125402,
        "start": 1257.74,
        "temperature": 1,
        "text": " BTS",
        "tokens": [
          50550,
          17951,
          50621
        ]
      },
      {
        "avg_logprob": -2.2196760177612305,
        "compression_ratio": 1.6428571428571428,
        "end": 1261.34,
        "id": 485,
        "no_speech_prob": 0.5597968101501465,
        "seek": 125402,
        "start": 1259.16,
        "temperature": 1,
        "text": " BTS",
        "tokens": [
          50621,
          17951,
          50730
        ]
      },
      {
        "avg_logprob": -2.2196760177612305,
        "compression_ratio": 1.6428571428571428,
        "end": 1262.58,
        "id": 486,
        "no_speech_prob": 0.5597968101501465,
        "seek": 125402,
        "start": 1261.34,
        "temperature": 1,
        "text": " BTS",
        "tokens": [
          50730,
          31144,
          50,
          50792
        ]
      },
      {
        "avg_logprob": -2.2196760177612305,
        "compression_ratio": 1.6428571428571428,
        "end": 1263.8,
        "id": 487,
        "no_speech_prob": 0.5597968101501465,
        "seek": 125402,
        "start": 1262.58,
        "temperature": 1,
        "text": " BTS",
        "tokens": [
          50792,
          17951,
          50853
        ]
      }
    ],
    "transcription": " Okay, it is time now. I am going to build a image classifier using my own images. I am going to teach this example to not say acoustic guitar or electric guitar, but to say ukulele. I'm going to teach this example not to say syringe, but to say train whistle, okay? This is what we're going to do, and the process that I'm going to use is transfer learning. I described this process in the previous video. You can go back and watch that if you want, or you can just keep following with me. I'm going to write the code for this. One thing that I want to mention is, you might be wondering, oh, why is it called a feature extractor? How does this stuff happen? So I want to first mention and thank Gene Kogan for making the image classification and regression transfer learning with MobileNet examples. You can find these native TensorFlow.js versions of what I'm doing right now here at the ML4A, Machine Learning for Artists website. It's a wonderful website with tons of resources about machine learning, and also, it's an interesting, the whole discussion here in terms of, how should the ML5 API work, or what should things be called? So if you're curious about how open source projects choose their names of things, I might reference this particular thread. But the important piece for us is to be at the ML5 website on the feature extractor documentation page. I'm going to need to make heavy use of this page to look up what the names of all the functions I need to type are in. And then, of course, I should mention, if I just go down here to under examples, classifier with feature extractor, this is basically what I'm going to build. But the point of this video is I'm going to build it up, but you could just look at this example instead if you want. But anyway, all right, so let's go back to, let's go back to the feature extractor documentation page. What I've got here is the code that I wrote from a previous video, a couple videos ago, using the MobileNet model to classify images from the webcam. Okay, so if I go to the code, the main thing that I need to change is I no longer want to make an ML5 image classifier. I want to make an ML5 feature extractor. And there, and the difference here also is I'm not going to reference the video yet. So I'm just going to make a feature extractor built on top of MobileNet, and this callback model ready means the model has been loaded, the MobileNet model was downloaded from wherever it needed to download it from, and it's there and ready to go, okay? So this should say model is ready, I'm going to get rid of this predict function. So now if we just refresh this, I mean, a lot of stuff's going to break here, but I see model is ready, and the video appears. Now there's no labels anymore because I got rid of the image classifier. I have a feature extractor now. But I want an image classifier. So what I do is I'm going to add a variable. I'm going to write a variable called classifier. So MobileNet, the variable MobileNet is now referring to the feature extractor, and the classifier equals MobileNet, the feature extractor dot classification. So I want to make a class, classification. I want to make a classification object from the feature extractor, and I need to give that, I want to say, and I want to use images from the video. And again, if I were doing this with a database of JPEGs that I'm loading or something else, I would do it in a different way, but I'm going to use the video in this example. So I'm going to say video, and then I'm going to say video ready, because I want to have a callback also to know that the video is ready. I don't really need that callback, but it's sort of useful. I'm going to write that up here, video ready, and I'm going to say a video is ready. So let's refresh this again, and we should see my image pop up. Model's ready, video's ready. Now, we are ready to train our own labels. We have the feature extractor, we have the classifier, we can give it images of a ukulele. I don't know if I wrote this on the board just now or earlier or when, but I used to have ukulele spelled wrong. It's spelled U-K-U-L-E-L-E. I don't know why, but I feel like that's very important to say right now. So how do I do that? Well, I could look up in the feature extractor page. There's a function called add image, and it's right here. So I know some of this API from having practiced this a little bit, but this is what I'm looking for, add image. What image, add image and a label. So I can say, oh, but when do I want to add an image? I want to make a button that every time I press the button, I'm saying that's a ukulele image. So let's first create a uke button. And then I'm going to say in setup, uke button equals create button ukulele. But if it's uke, it's just U-K-E. Boy, it's confusing. Now here's the thing. I am creating this example in a very basic, what I hope is beginner-friendly way. There are so many ways you can build an interface and style your page and handle events. I'm just going to use sort of simple P5 functions that place a button on the page and a simple callback function for when I press the button. So then I'm going to say uke pressed mouse pressed. And this is where, and I could put the function name here and write the function somewhere else, which I do in some videos to be kind of, but I'm just going to put an anonymous function in here. The idea of this anonymous function is when I press the button, this function should be executed. So the code I'm writing in here will happen when I press the button. And what do I want to do there? I want to say classifier add image, and I want to give it a label, ukulele. I hope that's spelled right. So now whenever I press the button, it's a ukulele. And you know, let's add a train whistle one while we're at it. Let's say a whistle button, and let's do exactly the same thing, but with a whistle button. Whistle button. Ha ha! Create button, I'm going to have the button say whistle. I cannot spell anything. Whistle button, and then add image whistle. So you can see here I have two buttons. Ukulele, adds an image, assign the label ukulele. Whistle adds an image, assign the label whistle. Now, there's not really much point to me running this code. I should just make sure I have no errors. But we can see the buttons are there now. The image comes up, but nothing's going to happen. Like I can keep pressing this ukulele button, I can keep pressing this whistle button. Nothing's happening because I'm not giving myself any feedback. So right now I just have to hope it's working. But the thing that I need to do next, right, is actually apply a training step. Now one thing that was interesting, I showed in the previous video, the teachable machine. This project that I'm basically making is exactly the same thing. Train green, train purple, train orange. My buttons are train ukulele, train whistle. But it just started to work immediately. That's because there's a slightly different algorithm at play here. The algorithm that I'm using requires, in ML5, requires an additional step, a training step. I'm going to write this here, training. So basically the process is, add a bunch of images. Say hey, this is a ukulele, this is a ukulele, this is a whistle, this is a whistle, this is a ukulele, this is a whistle, this is a ukulele. Once I've added all those images, then I explicitly, I say I'm done with all these images. I'm going to let the model retrain itself, train itself using the features that it extracted of those images, and map those features basically to these labels. And by map, I really mean there's like another machine learning model right here. It's actually like a neural network model. And so that mapping between the features and the new labels happens with another neural network here. But ML5 and TensorFlow.js is handling all of that for us. Okay, now let me come back over here and add the training step. So I certainly need one more button. Train, choo choo button. So I'm going to add that button. Create button, train button, train. I'm going to say train, train button. Oh okay, now here. Now what am I doing in here? Ah, okay. What I'm doing in here is I'm going to say classifier.train. So I'm going to say, hey, classifier train yourself. Now I could just leave it at this and kind of say like, hey, great, I'm done. But something that I should do here is I can actually put a callback inside of here. Now this is getting pretty awkward. I'm going to allow it. And you know what, actually though, I'm going to make a separate function just for, because I might want to do a bunch of things. I'm going to say, I'm going to call it like while training. So I just want to put this in a separate function so I can just for, so I can look at it on its own. What did I call it, while training? So this function while training is a function that's going to kind of run over and over again during the training process. And it's going to report back to me information about the training process. And the information it's going to report to me is something called loss, loss. Let's just actually run this. And then I'm going to explain what loss is. Let's see if I can get this to work so far. So I'm going to refresh. My model's ready, my video is ready. I have a ukulele. I can press ukulele, ukulele, ukulele. I'm going to show it a lot of ukuleles. Here's a lot of examples of ukuleles. Now I'm going to hold up my train whistle. Here's a lot of examples of train whistles. Now I'm going to hit the button train. And yes, we see this number here in the console. It's training and training and training. While training, console log this value loss. What is the loss? So loss is a really important term in machine learning, data science. Often also called cost. And by this I mean loss function or cost function. And what the loss function or cost function is calculating is the error. So what do I mean by error? So basically if I say to the machine learning model that's training, hey, here's a ukulele. This is a ukulele, but just pretend you don't know what it is for a second. What do you think it is? And if it comes back and says, I think it's a ukulele, guess what, the error is zero. If it comes back and says, I think it's a train whistle, then the error is not zero, it's something else. But something that I haven't really mentioned because we're kind of living above the fray here, we're talking in terms of labels. The machine learning model underneath the hood is just working with numbers. The labels are only a thing for us, the human being, to use at sort of the end of the process. So when it's actually calculating an error, even if it guesses it's a ukulele, it's calculating an error based on the numeric probability that it guessed. So the machine learning model might think, okay, that's 80% likely to be a ukulele. So that might be the right answer, but we know the right answer is it's 100% a ukulele. So the error is actually the difference between 100%, 80%, or 0.2. So this idea of the aggregate error of all of the training images over time, ML5 and TensorFlow Digest is calculating that for you during that training process, and we're seeing that here. There's a clock tick-tocking, because I have a clock sound effect for some unknown reason. We can see that that loss is getting very, very low. So you want the error to be low. The error started kind of high, it was like 6.92, and then it got lower and lower and lower as it was training, and one thing you'll notice is eventually it stopped. Now, it's an arbitrary decision, when do you stop training? ML5 has kind of default settings, it's going to train for a while until the loss is a certain amount or something like that, but you can see when it's finished, it gives you the loss as null, the loss as null. So I can actually say here, if loss equals null, console.log, training, oh, I'm going to say like, training complete, else, I can console.log the loss, and then guess what? When the training's complete, what do I want to do? I want to classify, so I'm going to say, classifier.classify.gotResults, and I already have the gotResults function, right? The same got, I'm getting results just like I got results from the raw MobileNet model, but now I'm getting the results from my new transfer learn trains custom trained model. So I say classifier.classify.gotResults, I get the results if there's an error, otherwise I can give the class name to the label to get drawn on the screen, and then what do I want to do again? I want to say classifier.classify. So before it was called predict, now it's called classify. I'm not sure why, maybe at some point we, check the code that goes along with this video to see if that's changed, but that's what it is right now. Okay, so I think we're actually done with this example, sort of, let's try. Okay, model is ready, video is ready, oh boy. What's the chance that this is going to work? Stop and guess, I give it like 10 to one this works. Okay, I'm going to step out of the frame, and I'm going to train it with a bunch of images of a ukulele, I'm going to move the ukulele around to give it a lot of different examples, further back. Now, and again, I should probably add something that shows me how many training examples, because I probably want to give around the same number of training examples for the whistle as with the ukulele. I'm going to train this, whistle, whistle, whistle, whistle, whistle, now I'm going to hit train. When it's done, we should start seeing labels. Training complete, hmm, I don't see any labels. No labels, it's so sad, what did I do wrong? Okay, so something's wrong, I got to figure this out, I got to debug this. All right, I really should put console.log results in, because I don't even know if this function is being called. Let's make sure.classify is the right name of the function. Classify, callback, yeah. Oh no, no, no, yeah, callback, callback, and then the callback is a function, otherwise you can blah, blah, blah. So I think this is right, everything looks right to me. Am I just not drawing the label properly? No, there, there it is, label. This is me not paying close attention. This is interesting, and this is now a question for the ml5 library itself, but the thing that comes in the gotResults function is actually just the label that it guesses. So there's not like the class name and the probability, all that stuff that came with MobileNet, it's not giving us all of that information, which probably makes sense. So actually, all I want to do is say label equals result. So that was a little bit of a digression, I had to figure out what I did wrong there. Now, this should work. Okay, ready? Let's try it with the ukulele. Ukulele, you're giving it a lot of examples of a ukulele. You're giving it a lot of examples of a whistle. Now I'm going to train it, I'm going to do my training dance. And training is complete. Here's a ukulele. It is a ukulele. It is a whistle. It is a ukulele. It is a whistle. Yay, okay! So this actually works. Here's the thing, I want to show you something more interesting here. And it's not more interesting, I'm going to show you something different. I'm going to change this to, I'm going to leave all the variable names the same, but I'm going to change this to smile. I'm going to change this to happy. I'm going to change this to sad. Sad, okay? So, and I'm going to run this again. And I'm going to do this. I'm going to get up, I'm going to get up, a knee smiling. Mm, mm, mm, mm, mm, mm, mm. Then I'm going to hit train. Let it train for a little bit. It's finished. It's finished. I mean, how long should I do that for? This is pretty cool. Here's the thing, I don't, it doesn't just have to be image recognition. I can sort of train it with different facial expressions. The fact that MobileNet, what MobileNet is really good at, if you recall, is taking an image and boiling it down to a smaller list of numbers that kind of define the essence of that image. So it doesn't matter what the content is, it can sort of figure out the essence of me smiling, the essence of me frowning. You know, it is important, though, to remember, it's not really learning smiling or frowning. It's kind of, and if I were to turn this like this way, you can sort of see some of the room here, and I go here. It's not working so well, because it kind of learned all that. It learned sort of like all that stuff with the background. So there's a lot of nuance to this, and it's really important to remember. It's not some magic, it doesn't understand, the computer doesn't have some understanding of emotions. It's really just looking at, I've got a new image, and I'm comparing it to a bunch of images I got before. What's it most similar like? Let's see if it sort of, now that I moved the camera around, is it working? So here's the thing. You now have something, this is the thing. Go, go forth, add a third category. Make a game where I'm playing Pong. Actually, this is a project I should reference by Alejandro. Let me go to ml5js.org. Alejandro, under experiments, made a project called Pong ML, which basically used the same exact technique to train various hand gestures, and then you could play Pong with hand gestures. So there's so many possibilities of what you could do just from being able to train using, starting with a mobile model and applying transfer learning. Okay, are you with me? Did this make sense? Make something, go and try this, make your own version of it. Really think about the interface. One more thing. Something you're really going to want to do, and you probably noticed this, every time I restarted the sketch, I had to retrain it with images again, which is fun for the real-time interactive nature of this, but if you're actually going to do this for a while, and you're building an installation or something, and you've trained it with a bunch of images, and you want to, I don't know, save the model that you've done, save all that work, you're going to want to save and be able to reload the result of that transfer learning. At present, at the time of this recording, there isn't a way to do that easily with the ml5 library. It's really technically possible. There is a GitHub issue. Currently it is ml5 library issues 174 with a discussion about this feature. Certainly once this feature exists, I will come back and make a video to show you how to do that, okay? Thanks for watching this video. Oh, I'm going to do one more, I'm going to do something interesting. I'm going to do, I mean, hopefully, I'm going to do one more video with something very similar to what I did just here, but I'm going to do something called a regression. So I'm going to define what a regression is and show you how I can do transfer learning with the MobileNet model to perform a regression. Why would I want to do that? I don't know, I guess we'll have to watch. Basically a slider. If I want to build a control something with my hand moving back and forth as a slider, that's something that I can use a regression for. All right, see you there. BTS BTS BTS BTS BTS BTS",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:34.295032Z",
  "started_at": "2023-09-26T21:15:18.09535Z",
  "completed_at": "2023-09-26T21:22:02.84324Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=eeO-rWYFuG0",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 404.74789
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/q4inmobbsog5jkzsrjdvogjzgu/cancel",
    "get": "https://api.replicate.com/v1/predictions/q4inmobbsog5jkzsrjdvogjzgu"
  }
}