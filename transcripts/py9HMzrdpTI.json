{
  "id": "eqbhhojbx4kqfixeump3glr3t4",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/py9HMzrdpTI.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/1043007 [00:00<?, ?frames/s]\n  0%|          | 2284/1043007 [00:25<3:11:03, 90.78frames/s]\n  1%|          | 5284/1043007 [00:25<1:09:18, 249.55frames/s]\n  1%|          | 7676/1043007 [00:29<49:01, 351.99frames/s]  \n  1%|          | 10676/1043007 [00:30<31:48, 541.03frames/s]\n  1%|▏         | 13576/1043007 [00:32<23:04, 743.65frames/s]\n  1%|▏         | 15576/1043007 [00:32<18:44, 913.89frames/s]\n  2%|▏         | 17576/1043007 [00:33<15:21, 1113.29frames/s]\n  2%|▏         | 19576/1043007 [00:34<12:55, 1319.44frames/s]\n  2%|▏         | 21576/1043007 [00:35<11:08, 1527.83frames/s]\n  2%|▏         | 23976/1043007 [00:36<10:40, 1590.19frames/s]\n  3%|▎         | 26676/1043007 [00:44<24:42, 685.74frames/s] \n  3%|▎         | 29476/1043007 [00:53<33:40, 501.61frames/s]\n  3%|▎         | 32376/1043007 [01:00<35:28, 474.87frames/s]\n  3%|▎         | 35176/1043007 [01:08<39:37, 423.82frames/s]\n  4%|▎         | 37976/1043007 [01:15<40:49, 410.31frames/s]\n  4%|▍         | 40676/1043007 [01:24<45:05, 370.47frames/s]\n  4%|▍         | 42876/1043007 [01:31<46:26, 358.87frames/s]\n  4%|▍         | 45576/1043007 [01:38<46:07, 360.47frames/s]\n  5%|▍         | 48176/1043007 [01:44<44:14, 374.71frames/s]\n  5%|▍         | 50976/1043007 [01:53<46:24, 356.24frames/s]\n  5%|▌         | 53776/1043007 [02:00<45:08, 365.21frames/s]\n  5%|▌         | 56476/1043007 [02:09<46:33, 353.10frames/s]\n  6%|▌         | 58676/1043007 [02:14<44:41, 367.05frames/s]\n  6%|▌         | 61476/1043007 [02:21<42:39, 383.43frames/s]\n  6%|▌         | 64176/1043007 [02:29<45:12, 360.84frames/s]\n  6%|▋         | 67076/1043007 [02:37<44:33, 365.08frames/s]\n  7%|▋         | 69976/1043007 [02:44<43:26, 373.29frames/s]\n  7%|▋         | 72776/1043007 [02:52<43:07, 375.01frames/s]\n  7%|▋         | 75676/1043007 [02:58<41:27, 388.82frames/s]\n  8%|▊         | 78576/1043007 [03:06<41:05, 391.16frames/s]\n  8%|▊         | 81076/1043007 [03:13<42:33, 376.68frames/s]\n  8%|▊         | 83976/1043007 [03:19<40:08, 398.22frames/s]\n  8%|▊         | 86776/1043007 [03:27<41:21, 385.39frames/s]\n  9%|▊         | 89376/1043007 [03:32<37:54, 419.32frames/s]\n  9%|▉         | 92376/1043007 [03:38<35:09, 450.71frames/s]\n  9%|▉         | 95276/1043007 [03:44<34:26, 458.72frames/s]\n  9%|▉         | 97976/1043007 [03:49<34:14, 459.98frames/s]\n 10%|▉         | 100676/1043007 [03:56<35:10, 446.41frames/s]\n 10%|▉         | 103476/1043007 [04:03<37:15, 420.27frames/s]\n 10%|█         | 106376/1043007 [04:10<37:12, 419.57frames/s]\n 10%|█         | 109076/1043007 [04:18<38:49, 400.85frames/s]\n 11%|█         | 111976/1043007 [04:26<40:30, 383.01frames/s]\n 11%|█         | 114676/1043007 [04:33<39:09, 395.10frames/s]\n 11%|█▏        | 117376/1043007 [04:41<41:21, 373.06frames/s]\n 12%|█▏        | 120276/1043007 [04:46<37:49, 406.49frames/s]\n 12%|█▏        | 123176/1043007 [04:56<42:01, 364.80frames/s]\n 12%|█▏        | 126076/1043007 [05:05<43:47, 348.92frames/s]\n 12%|█▏        | 128476/1043007 [05:12<43:25, 351.03frames/s]\n 13%|█▎        | 131276/1043007 [05:18<40:09, 378.32frames/s]\n 13%|█▎        | 134076/1043007 [05:24<36:46, 411.90frames/s]\n 13%|█▎        | 136976/1043007 [05:33<40:16, 374.91frames/s]\n 13%|█▎        | 139776/1043007 [05:41<41:08, 365.87frames/s]\n 14%|█▎        | 142576/1043007 [05:49<41:52, 358.33frames/s]\n 14%|█▍        | 144876/1043007 [05:55<40:31, 369.42frames/s]\n 14%|█▍        | 147876/1043007 [06:00<36:08, 412.79frames/s]\n 14%|█▍        | 150476/1043007 [06:06<35:43, 416.41frames/s]\n 15%|█▍        | 153076/1043007 [06:14<37:58, 390.63frames/s]\n 15%|█▍        | 155676/1043007 [06:22<40:42, 363.33frames/s]\n 15%|█▌        | 158476/1043007 [06:29<39:04, 377.26frames/s]\n 15%|█▌        | 161376/1043007 [06:36<36:54, 398.11frames/s]\n 16%|█▌        | 164276/1043007 [06:43<36:46, 398.21frames/s]\n 16%|█▌        | 166876/1043007 [06:50<37:20, 391.10frames/s]\n 16%|█▌        | 169376/1043007 [06:56<37:12, 391.40frames/s]\n 16%|█▋        | 171976/1043007 [07:02<36:12, 400.99frames/s]\n 17%|█▋        | 174576/1043007 [07:10<38:31, 375.73frames/s]\n 17%|█▋        | 177176/1043007 [07:15<34:23, 419.49frames/s]\n 17%|█▋        | 179976/1043007 [07:22<34:38, 415.25frames/s]\n 18%|█▊        | 182576/1043007 [07:30<37:53, 378.41frames/s]\n 18%|█▊        | 185176/1043007 [07:37<37:25, 382.00frames/s]\n 18%|█▊        | 187776/1043007 [07:43<36:47, 387.49frames/s]\n 18%|█▊        | 190776/1043007 [07:47<29:53, 475.13frames/s]\n 19%|█▊        | 193076/1043007 [07:52<30:24, 465.88frames/s]\n 19%|█▉        | 195876/1043007 [07:58<30:55, 456.60frames/s]\n 19%|█▉        | 198676/1043007 [08:05<32:10, 437.44frames/s]\n 19%|█▉        | 201376/1043007 [08:12<33:32, 418.13frames/s]\n 20%|█▉        | 204276/1043007 [08:24<40:36, 344.21frames/s]\n 20%|█▉        | 207176/1043007 [08:30<36:48, 378.39frames/s]\n 20%|██        | 210176/1043007 [08:33<30:07, 460.82frames/s]\n 20%|██        | 212976/1043007 [08:39<29:58, 461.58frames/s]\n 21%|██        | 215876/1043007 [08:45<29:13, 471.62frames/s]\n 21%|██        | 218876/1043007 [08:47<22:03, 622.65frames/s]\n 21%|██        | 221476/1043007 [08:50<21:05, 649.13frames/s]\n 22%|██▏       | 224476/1043007 [08:54<19:28, 700.42frames/s]\n 22%|██▏       | 227476/1043007 [09:01<24:04, 564.67frames/s]\n 22%|██▏       | 230476/1043007 [09:07<24:36, 550.36frames/s]\n 22%|██▏       | 232776/1043007 [09:10<22:45, 593.27frames/s]\n 23%|██▎       | 235776/1043007 [09:13<19:40, 683.77frames/s]\n 23%|██▎       | 238776/1043007 [09:14<14:27, 926.98frames/s]\n 23%|██▎       | 241776/1043007 [09:16<12:28, 1071.01frames/s]\n 23%|██▎       | 243476/1043007 [09:22<19:15, 691.66frames/s] \n 24%|██▎       | 245176/1043007 [09:23<18:14, 728.97frames/s]\n 24%|██▎       | 247376/1043007 [09:29<23:18, 568.91frames/s]\n 24%|██▍       | 249576/1043007 [09:36<28:47, 459.26frames/s]\n 24%|██▍       | 252076/1043007 [09:42<29:01, 454.15frames/s]\n 24%|██▍       | 254576/1043007 [09:47<27:42, 474.14frames/s]\n 25%|██▍       | 257076/1043007 [09:52<27:54, 469.42frames/s]\n 25%|██▍       | 258976/1043007 [09:56<27:56, 467.53frames/s]\n 25%|██▌       | 261376/1043007 [10:03<31:16, 416.54frames/s]\n 25%|██▌       | 263776/1043007 [10:08<29:52, 434.74frames/s]\n 26%|██▌       | 265976/1043007 [10:14<31:04, 416.80frames/s]\n 26%|██▌       | 266476/1043007 [10:16<32:25, 399.19frames/s]\n 26%|██▌       | 269476/1043007 [10:19<24:06, 534.61frames/s]\n 26%|██▌       | 272476/1043007 [10:23<20:54, 614.33frames/s]\n 26%|██▋       | 275276/1043007 [10:32<27:47, 460.50frames/s]\n 27%|██▋       | 277176/1043007 [10:36<27:55, 456.98frames/s]\n 27%|██▋       | 280176/1043007 [10:37<19:50, 640.86frames/s]\n 27%|██▋       | 282176/1043007 [10:41<20:32, 617.25frames/s]\n 27%|██▋       | 285176/1043007 [10:45<19:02, 663.49frames/s]\n 28%|██▊       | 287576/1043007 [10:48<18:04, 696.34frames/s]\n 28%|██▊       | 290176/1043007 [10:52<18:51, 665.27frames/s]\n 28%|██▊       | 292976/1043007 [11:01<25:29, 490.50frames/s]\n 28%|██▊       | 295776/1043007 [11:05<22:23, 556.00frames/s]\n 29%|██▊       | 298376/1043007 [11:09<22:05, 561.93frames/s]\n 29%|██▉       | 301376/1043007 [11:15<23:03, 536.13frames/s]\n 29%|██▉       | 304076/1043007 [11:23<26:15, 469.07frames/s]\n 29%|██▉       | 306776/1043007 [11:28<25:14, 486.18frames/s]\n 30%|██▉       | 309576/1043007 [11:32<23:13, 526.39frames/s]\n 30%|██▉       | 312376/1043007 [11:39<25:10, 483.66frames/s]\n 30%|███       | 314876/1043007 [11:46<27:35, 439.86frames/s]\n 30%|███       | 317776/1043007 [11:53<27:20, 442.04frames/s]\n 31%|███       | 320676/1043007 [12:00<28:52, 416.84frames/s]\n 31%|███       | 323176/1043007 [12:08<31:09, 384.95frames/s]\n 31%|███       | 325876/1043007 [12:14<29:54, 399.58frames/s]\n 31%|███       | 325876/1043007 [12:30<29:54, 399.58frames/s]\n 32%|███▏      | 328676/1043007 [12:44<1:00:03, 198.26frames/s]\n 32%|███▏      | 331276/1043007 [12:50<49:41, 238.68frames/s]  \n 32%|███▏      | 333576/1043007 [12:56<44:28, 265.89frames/s]\n 32%|███▏      | 336176/1043007 [13:02<38:42, 304.29frames/s]\n 33%|███▎      | 339076/1043007 [13:09<35:49, 327.47frames/s]\n 33%|███▎      | 341776/1043007 [13:18<36:36, 319.19frames/s]\n 33%|███▎      | 344676/1043007 [13:23<31:54, 364.69frames/s]\n 33%|███▎      | 347376/1043007 [13:32<32:45, 353.99frames/s]\n 34%|███▎      | 350076/1043007 [13:38<31:27, 367.11frames/s]\n 34%|███▍      | 352476/1043007 [13:43<28:37, 402.08frames/s]\n 34%|███▍      | 354876/1043007 [13:49<28:56, 396.29frames/s]\n 34%|███▍      | 357776/1043007 [13:55<27:00, 422.73frames/s]\n 35%|███▍      | 360576/1043007 [14:04<29:49, 381.44frames/s]\n 35%|███▍      | 362976/1043007 [14:10<29:40, 381.99frames/s]\n 35%|███▌      | 365376/1043007 [14:16<28:55, 390.38frames/s]\n 35%|███▌      | 368176/1043007 [14:23<28:03, 400.87frames/s]\n 36%|███▌      | 370976/1043007 [14:29<26:49, 417.57frames/s]\n 36%|███▌      | 373876/1043007 [14:37<27:58, 398.66frames/s]\n 36%|███▌      | 376776/1043007 [14:43<27:05, 409.91frames/s]\n 36%|███▋      | 379676/1043007 [14:51<27:14, 405.82frames/s]\n 37%|███▋      | 382376/1043007 [14:59<28:37, 384.62frames/s]\n 37%|███▋      | 385076/1043007 [15:06<29:18, 374.07frames/s]\n 37%|███▋      | 387976/1043007 [15:14<29:12, 373.76frames/s]\n 37%|███▋      | 390576/1043007 [15:21<29:36, 367.25frames/s]\n 38%|███▊      | 393476/1043007 [15:28<28:01, 386.23frames/s]\n 38%|███▊      | 396276/1043007 [15:35<27:31, 391.67frames/s]\n 38%|███▊      | 399076/1043007 [15:42<26:52, 399.40frames/s]\n 39%|███▊      | 401676/1043007 [15:50<29:19, 364.50frames/s]\n 39%|███▉      | 404176/1043007 [15:59<31:50, 334.43frames/s]\n 39%|███▉      | 407076/1043007 [16:08<31:14, 339.22frames/s]\n 39%|███▉      | 409776/1043007 [16:16<31:54, 330.75frames/s]\n 40%|███▉      | 412676/1043007 [16:23<29:39, 354.12frames/s]\n 40%|███▉      | 415476/1043007 [16:33<32:01, 326.56frames/s]\n 40%|████      | 418376/1043007 [16:41<30:35, 340.32frames/s]\n 40%|████      | 421176/1043007 [16:49<30:09, 343.56frames/s]\n 41%|████      | 423676/1043007 [16:57<30:39, 336.61frames/s]\n 41%|████      | 426476/1043007 [17:04<29:12, 351.86frames/s]\n 41%|████      | 428876/1043007 [17:10<27:33, 371.47frames/s]\n 41%|████▏     | 431576/1043007 [17:17<27:33, 369.84frames/s]\n 42%|████▏     | 434376/1043007 [17:23<26:05, 388.75frames/s]\n 42%|████▏     | 437276/1043007 [17:30<25:21, 398.12frames/s]\n 42%|████▏     | 439976/1043007 [17:34<22:00, 456.71frames/s]\n 42%|████▏     | 442676/1043007 [17:40<22:11, 450.93frames/s]\n 43%|████▎     | 445176/1043007 [17:47<23:15, 428.54frames/s]\n 43%|████▎     | 447476/1043007 [17:52<23:34, 420.88frames/s]\n 43%|████▎     | 450376/1043007 [18:00<24:16, 406.98frames/s]\n 43%|████▎     | 452776/1043007 [18:06<24:00, 409.72frames/s]\n 44%|████▎     | 455576/1043007 [18:13<23:42, 413.02frames/s]\n 44%|████▍     | 458276/1043007 [18:21<25:49, 377.41frames/s]\n 44%|████▍     | 460476/1043007 [18:26<24:30, 396.15frames/s]\n 44%|████▍     | 462976/1043007 [18:31<23:29, 411.54frames/s]\n 45%|████▍     | 465676/1043007 [18:40<25:11, 382.01frames/s]\n 45%|████▍     | 468376/1043007 [18:46<24:07, 397.02frames/s]\n 45%|████▌     | 470276/1043007 [18:51<24:22, 391.50frames/s]\n 45%|████▌     | 472076/1043007 [18:54<22:08, 429.67frames/s]\n 46%|████▌     | 474976/1043007 [19:00<21:32, 439.56frames/s]\n 46%|████▌     | 477476/1043007 [19:06<22:12, 424.49frames/s]\n 46%|████▌     | 480376/1043007 [19:12<20:55, 448.06frames/s]\n 46%|████▋     | 482676/1043007 [19:15<18:36, 502.01frames/s]\n 47%|████▋     | 485276/1043007 [19:21<18:44, 496.13frames/s]\n 47%|████▋     | 487876/1043007 [19:27<20:15, 456.54frames/s]\n 47%|████▋     | 490776/1043007 [19:35<21:53, 420.53frames/s]\n 47%|████▋     | 493676/1043007 [19:45<23:58, 381.76frames/s]\n 48%|████▊     | 496476/1043007 [19:53<24:35, 370.43frames/s]\n 48%|████▊     | 499076/1043007 [20:00<25:04, 361.52frames/s]\n 48%|████▊     | 501876/1043007 [20:07<24:01, 375.34frames/s]\n 48%|████▊     | 504476/1043007 [20:13<22:32, 398.13frames/s]\n 49%|████▊     | 507076/1043007 [20:19<22:16, 400.86frames/s]\n 49%|████▉     | 508976/1043007 [20:22<20:30, 433.85frames/s]\n 49%|████▉     | 511776/1043007 [20:29<21:06, 419.36frames/s]\n 49%|████▉     | 514076/1043007 [20:36<22:37, 389.70frames/s]\n 50%|████▉     | 516976/1043007 [20:45<23:22, 375.18frames/s]\n 50%|████▉     | 519876/1043007 [20:52<22:36, 385.55frames/s]\n 50%|█████     | 522576/1043007 [20:57<21:18, 407.05frames/s]\n 50%|█████     | 525276/1043007 [21:02<19:07, 450.99frames/s]\n 51%|█████     | 528076/1043007 [21:06<17:14, 497.64frames/s]\n 51%|█████     | 530676/1043007 [21:11<16:59, 502.31frames/s]\n 51%|█████     | 533376/1043007 [21:16<16:43, 507.89frames/s]\n 51%|█████▏    | 535676/1043007 [21:22<17:10, 492.32frames/s]\n 52%|█████▏    | 538576/1043007 [21:28<17:46, 473.04frames/s]\n 52%|█████▏    | 541476/1043007 [21:35<18:23, 454.53frames/s]\n 52%|█████▏    | 544176/1043007 [21:42<19:06, 435.21frames/s]\n 52%|█████▏    | 546676/1043007 [21:47<18:34, 445.52frames/s]\n 53%|█████▎    | 548976/1043007 [21:54<20:06, 409.58frames/s]\n 53%|█████▎    | 551276/1043007 [22:01<21:09, 387.41frames/s]\n 53%|█████▎    | 553376/1043007 [22:06<20:43, 393.80frames/s]\n 53%|█████▎    | 555976/1043007 [22:11<19:19, 420.13frames/s]\n 54%|█████▎    | 558776/1043007 [22:21<22:03, 365.97frames/s]\n 54%|█████▍    | 561376/1043007 [22:27<21:28, 373.72frames/s]\n 54%|█████▍    | 564276/1043007 [22:35<20:45, 384.43frames/s]\n 54%|█████▍    | 567076/1043007 [22:44<22:20, 355.13frames/s]\n 55%|█████▍    | 569676/1043007 [22:49<20:39, 381.95frames/s]\n 55%|█████▍    | 572476/1043007 [22:54<18:00, 435.38frames/s]\n 55%|█████▌    | 574976/1043007 [22:57<15:54, 490.27frames/s]\n 55%|█████▌    | 577876/1043007 [23:03<15:36, 496.88frames/s]\n 56%|█████▌    | 579876/1043007 [23:09<17:18, 445.91frames/s]\n 56%|█████▌    | 582476/1043007 [23:13<15:45, 487.03frames/s]\n 56%|█████▌    | 584976/1043007 [23:18<15:27, 493.97frames/s]\n 56%|█████▋    | 587676/1043007 [23:23<15:04, 503.61frames/s]\n 57%|█████▋    | 590376/1043007 [23:27<13:52, 543.38frames/s]\n 57%|█████▋    | 592876/1043007 [23:32<13:51, 541.05frames/s]\n 57%|█████▋    | 595476/1043007 [23:34<11:53, 627.52frames/s]\n 57%|█████▋    | 597976/1043007 [23:38<11:28, 646.02frames/s]\n 58%|█████▊    | 600776/1043007 [23:45<13:38, 540.57frames/s]\n 58%|█████▊    | 603576/1043007 [23:48<11:50, 618.84frames/s]\n 58%|█████▊    | 606376/1043007 [23:56<14:31, 501.06frames/s]\n 58%|█████▊    | 608976/1043007 [24:01<13:56, 518.96frames/s]\n 59%|█████▊    | 611076/1043007 [24:06<14:38, 491.78frames/s]\n 59%|█████▉    | 613576/1043007 [24:09<13:02, 548.65frames/s]\n 59%|█████▉    | 615576/1043007 [24:13<13:08, 542.35frames/s]\n 59%|█████▉    | 618176/1043007 [24:17<12:52, 550.01frames/s]\n 60%|█████▉    | 620876/1043007 [24:22<12:34, 559.22frames/s]\n 60%|█████▉    | 623576/1043007 [24:30<14:42, 475.08frames/s]\n 60%|██████    | 626376/1043007 [24:35<14:33, 476.81frames/s]\n 60%|██████    | 629076/1043007 [24:40<13:57, 494.09frames/s]\n 61%|██████    | 631476/1043007 [24:46<14:23, 476.46frames/s]\n 61%|██████    | 634276/1043007 [24:50<12:36, 540.29frames/s]\n 61%|██████    | 637076/1043007 [24:54<12:17, 550.62frames/s]\n 61%|██████▏   | 639776/1043007 [25:02<14:22, 467.70frames/s]\n 62%|██████▏   | 642676/1043007 [25:12<16:45, 398.04frames/s]\n 62%|██████▏   | 645176/1043007 [25:18<16:15, 407.83frames/s]\n 62%|██████▏   | 647976/1043007 [25:24<15:53, 414.12frames/s]\n 62%|██████▏   | 650676/1043007 [25:30<15:02, 434.95frames/s]\n 63%|██████▎   | 653376/1043007 [25:35<14:38, 443.42frames/s]\n 63%|██████▎   | 656176/1043007 [25:39<12:43, 506.52frames/s]\n 63%|██████▎   | 658776/1043007 [25:43<11:37, 550.98frames/s]\n 63%|██████▎   | 661476/1043007 [25:47<11:08, 570.75frames/s]\n 64%|██████▎   | 664276/1043007 [25:50<09:36, 657.08frames/s]\n 64%|██████▍   | 666776/1043007 [25:55<10:41, 586.50frames/s]\n 64%|██████▍   | 669676/1043007 [26:02<11:50, 525.16frames/s]\n 64%|██████▍   | 671976/1043007 [26:09<13:30, 457.92frames/s]\n 65%|██████▍   | 674676/1043007 [26:16<13:58, 439.29frames/s]\n 65%|██████▍   | 677476/1043007 [26:21<13:13, 460.58frames/s]\n 65%|██████▌   | 679976/1043007 [26:29<14:41, 412.06frames/s]\n 65%|██████▌   | 682676/1043007 [26:36<14:58, 400.86frames/s]\n 66%|██████▌   | 685376/1043007 [26:44<15:36, 382.01frames/s]\n 66%|██████▌   | 688076/1043007 [26:51<15:19, 386.15frames/s]\n 66%|██████▌   | 690776/1043007 [27:00<16:50, 348.64frames/s]\n 66%|██████▋   | 693576/1043007 [27:08<16:48, 346.45frames/s]\n 67%|██████▋   | 696476/1043007 [27:17<17:05, 337.78frames/s]\n 67%|██████▋   | 699276/1043007 [27:25<16:48, 340.81frames/s]\n 67%|██████▋   | 702076/1043007 [27:32<15:53, 357.72frames/s]\n 68%|██████▊   | 704776/1043007 [27:39<15:10, 371.51frames/s]\n 68%|██████▊   | 707376/1043007 [27:46<15:14, 366.95frames/s]\n 68%|██████▊   | 710076/1043007 [27:52<14:00, 396.25frames/s]\n 68%|██████▊   | 712676/1043007 [27:59<14:01, 392.44frames/s]\n 69%|██████▊   | 715076/1043007 [28:05<14:02, 389.09frames/s]\n 69%|██████▉   | 717776/1043007 [28:12<13:55, 389.05frames/s]\n 69%|██████▉   | 720676/1043007 [28:19<13:33, 396.40frames/s]\n 69%|██████▉   | 722976/1043007 [28:23<12:37, 422.30frames/s]\n 70%|██████▉   | 725576/1043007 [28:29<12:21, 428.15frames/s]\n 70%|██████▉   | 727976/1043007 [28:33<11:14, 466.89frames/s]\n 70%|███████   | 730776/1043007 [28:39<11:11, 465.25frames/s]\n 70%|███████   | 733276/1043007 [28:44<11:00, 469.06frames/s]\n 71%|███████   | 736076/1043007 [28:51<11:16, 453.58frames/s]\n 71%|███████   | 738976/1043007 [28:56<10:28, 484.06frames/s]\n 71%|███████   | 741776/1043007 [29:01<09:43, 516.40frames/s]\n 71%|███████▏  | 744676/1043007 [29:05<08:49, 563.31frames/s]\n 72%|███████▏  | 747676/1043007 [29:09<08:22, 587.85frames/s]\n 72%|███████▏  | 750576/1043007 [29:15<08:24, 580.20frames/s]\n 72%|███████▏  | 753276/1043007 [29:18<07:50, 616.27frames/s]\n 72%|███████▏  | 755776/1043007 [29:25<09:02, 529.38frames/s]\n 73%|███████▎  | 758576/1043007 [29:30<09:06, 520.59frames/s]\n 73%|███████▎  | 761376/1043007 [29:36<08:54, 526.82frames/s]\n 73%|███████▎  | 764376/1043007 [29:38<07:22, 629.85frames/s]\n 74%|███████▎  | 767076/1043007 [29:46<08:51, 519.41frames/s]\n 74%|███████▍  | 769876/1043007 [29:53<09:26, 481.99frames/s]\n 74%|███████▍  | 772876/1043007 [29:59<09:15, 486.64frames/s]\n 74%|███████▍  | 775676/1043007 [30:06<10:07, 439.85frames/s]\n 75%|███████▍  | 778676/1043007 [30:13<09:52, 446.20frames/s]\n 75%|███████▍  | 781176/1043007 [30:19<09:48, 444.99frames/s]\n 75%|███████▌  | 783876/1043007 [30:22<08:23, 514.46frames/s]\n 75%|███████▌  | 786876/1043007 [30:28<08:31, 500.34frames/s]\n 76%|███████▌  | 789876/1043007 [30:36<09:06, 463.17frames/s]\n 76%|███████▌  | 792576/1043007 [30:42<09:20, 447.11frames/s]\n 76%|███████▋  | 795576/1043007 [30:48<08:47, 468.66frames/s]\n 77%|███████▋  | 798476/1043007 [30:53<08:14, 494.52frames/s]\n 77%|███████▋  | 801276/1043007 [30:59<08:11, 492.25frames/s]\n 77%|███████▋  | 804276/1043007 [31:05<07:54, 503.14frames/s]\n 77%|███████▋  | 806976/1043007 [31:11<08:06, 485.35frames/s]\n 78%|███████▊  | 809576/1043007 [31:14<07:11, 541.34frames/s]\n 78%|███████▊  | 812476/1043007 [31:19<06:55, 554.78frames/s]\n 78%|███████▊  | 815176/1043007 [31:27<08:19, 456.07frames/s]\n 78%|███████▊  | 818176/1043007 [31:33<07:52, 475.75frames/s]\n 79%|███████▊  | 820676/1043007 [31:37<07:21, 503.91frames/s]\n 79%|███████▉  | 822976/1043007 [31:41<07:05, 516.81frames/s]\n 79%|███████▉  | 825776/1043007 [31:48<07:18, 495.65frames/s]\n 79%|███████▉  | 828776/1043007 [31:55<07:41, 464.33frames/s]\n 80%|███████▉  | 831776/1043007 [31:58<06:23, 551.32frames/s]\n 80%|████████  | 834776/1043007 [32:03<06:01, 576.34frames/s]\n 80%|████████  | 837776/1043007 [32:05<04:56, 692.11frames/s]\n 81%|████████  | 840676/1043007 [32:11<05:33, 607.54frames/s]\n 81%|████████  | 843476/1043007 [32:18<06:01, 551.21frames/s]\n 81%|████████  | 846176/1043007 [32:22<05:57, 551.30frames/s]\n 81%|████████▏ | 849176/1043007 [32:26<05:10, 623.74frames/s]\n 82%|████████▏ | 851576/1043007 [32:31<05:37, 567.66frames/s]\n 82%|████████▏ | 854076/1043007 [32:35<05:25, 580.81frames/s]\n 82%|████████▏ | 856976/1043007 [32:44<06:43, 461.51frames/s]\n 82%|████████▏ | 859476/1043007 [32:50<06:49, 448.51frames/s]\n 83%|████████▎ | 862476/1043007 [32:54<05:39, 531.69frames/s]\n 83%|████████▎ | 864976/1043007 [32:59<05:49, 509.84frames/s]\n 83%|████████▎ | 867676/1043007 [33:05<06:02, 483.10frames/s]\n 83%|████████▎ | 870476/1043007 [33:12<06:06, 471.25frames/s]\n 83%|████████▎ | 870476/1043007 [33:30<06:06, 471.25frames/s]\n 84%|████████▎ | 873476/1043007 [33:43<13:34, 208.22frames/s]\n 84%|████████▍ | 876476/1043007 [33:49<10:44, 258.46frames/s]\n 84%|████████▍ | 879476/1043007 [33:54<08:45, 311.36frames/s]\n 85%|████████▍ | 881376/1043007 [33:57<07:41, 350.43frames/s]\n 85%|████████▍ | 883976/1043007 [34:03<07:02, 376.44frames/s]\n 85%|████████▍ | 886476/1043007 [34:09<06:59, 372.84frames/s]\n 85%|████████▌ | 888576/1043007 [34:13<06:08, 418.84frames/s]\n 85%|████████▌ | 890676/1043007 [34:17<05:48, 437.51frames/s]\n 86%|████████▌ | 892976/1043007 [34:21<05:16, 474.09frames/s]\n 86%|████████▌ | 894376/1043007 [34:24<05:24, 457.33frames/s]\n 86%|████████▌ | 896676/1043007 [34:29<05:17, 460.73frames/s]\n 86%|████████▌ | 899176/1043007 [34:35<05:17, 453.62frames/s]\n 86%|████████▋ | 901976/1043007 [34:40<04:58, 471.80frames/s]\n 87%|████████▋ | 904476/1043007 [34:45<04:40, 494.64frames/s]\n 87%|████████▋ | 906976/1043007 [34:49<04:13, 537.60frames/s]\n 87%|████████▋ | 909776/1043007 [34:54<04:15, 521.49frames/s]\n 87%|████████▋ | 912576/1043007 [35:02<04:40, 465.36frames/s]\n 88%|████████▊ | 915376/1043007 [35:07<04:20, 489.16frames/s]\n 88%|████████▊ | 918176/1043007 [35:15<04:44, 439.22frames/s]\n 88%|████████▊ | 921176/1043007 [35:17<03:44, 541.61frames/s]\n 89%|████████▊ | 923876/1043007 [35:21<03:24, 582.99frames/s]\n 89%|████████▉ | 926776/1043007 [35:26<03:19, 581.40frames/s]\n 89%|████████▉ | 929476/1043007 [35:30<03:09, 598.28frames/s]\n 89%|████████▉ | 932476/1043007 [35:35<03:04, 600.34frames/s]\n 90%|████████▉ | 934876/1043007 [35:42<03:34, 504.27frames/s]\n 90%|████████▉ | 937876/1043007 [35:47<03:20, 524.83frames/s]\n 90%|█████████ | 940676/1043007 [35:55<03:36, 472.37frames/s]\n 90%|█████████ | 943576/1043007 [36:01<03:30, 471.64frames/s]\n 91%|█████████ | 946276/1043007 [36:04<03:00, 536.20frames/s]\n 91%|█████████ | 949076/1043007 [36:09<02:47, 562.44frames/s]\n 91%|█████████▏| 951876/1043007 [36:14<02:44, 553.45frames/s]\n 92%|█████████▏| 954876/1043007 [36:20<02:48, 522.33frames/s]\n 92%|█████████▏| 957576/1043007 [36:25<02:38, 538.84frames/s]\n 92%|█████████▏| 960576/1043007 [36:30<02:25, 566.63frames/s]\n 92%|█████████▏| 963176/1043007 [36:35<02:25, 548.09frames/s]\n 93%|█████████▎| 966176/1043007 [36:41<02:23, 535.25frames/s]\n 93%|█████████▎| 969176/1043007 [36:44<01:59, 615.85frames/s]\n 93%|█████████▎| 971976/1043007 [36:51<02:14, 526.97frames/s]\n 93%|█████████▎| 974876/1043007 [36:57<02:09, 526.63frames/s]\n 94%|█████████▎| 977676/1043007 [37:03<02:14, 487.46frames/s]\n 94%|█████████▍| 980376/1043007 [37:09<02:08, 489.27frames/s]\n 94%|█████████▍| 983176/1043007 [37:14<02:00, 494.69frames/s]\n 95%|█████████▍| 985776/1043007 [37:20<01:55, 494.94frames/s]\n 95%|█████████▍| 988576/1043007 [37:26<01:51, 486.13frames/s]\n 95%|█████████▌| 991276/1043007 [37:32<01:51, 462.99frames/s]\n 95%|█████████▌| 993176/1043007 [37:36<01:45, 474.31frames/s]\n 95%|█████████▌| 993176/1043007 [37:50<01:45, 474.31frames/s]\n 96%|█████████▌| 996176/1043007 [38:06<03:44, 208.58frames/s]\n 96%|█████████▌| 996176/1043007 [38:20<03:44, 208.58frames/s]\n 96%|█████████▌| 998976/1043007 [38:39<05:07, 143.39frames/s]\n 96%|█████████▌| 1001976/1043007 [38:41<03:22, 202.82frames/s]\n 96%|█████████▌| 1001976/1043007 [39:00<03:22, 202.82frames/s]\n 96%|█████████▋| 1004376/1043007 [39:00<03:41, 174.60frames/s]\n 96%|█████████▋| 1006376/1043007 [39:04<02:56, 207.64frames/s]\n 96%|█████████▋| 1006376/1043007 [39:20<02:56, 207.64frames/s]\n 97%|█████████▋| 1009376/1043007 [39:24<03:04, 182.61frames/s]\n 97%|█████████▋| 1012066/1043007 [39:36<02:41, 191.31frames/s]\n 97%|█████████▋| 1014598/1043007 [39:40<01:57, 241.90frames/s]\n 98%|█████████▊| 1017598/1043007 [39:42<01:16, 330.78frames/s]\n 98%|█████████▊| 1020286/1043007 [39:45<00:53, 422.91frames/s]\n98%|█████████▊| 1022007/1043007 [39:49<00:50, 419.91frames/s]\n98%|█████████▊| 1022007/1043007 [39:49<00:49, 427.74frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.38198834373837426,
        "compression_ratio": 1.2601626016260163,
        "end": 162.92,
        "id": 0,
        "no_speech_prob": 0.12523266673088074,
        "seek": 15000,
        "start": 150,
        "temperature": 0,
        "text": " Audio sound check now.",
        "tokens": [
          50364,
          25706,
          1626,
          1520,
          586,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.38198834373837426,
        "compression_ratio": 1.2601626016260163,
        "end": 167.84,
        "id": 1,
        "no_speech_prob": 0.12523266673088074,
        "seek": 15000,
        "start": 162.92,
        "temperature": 0,
        "text": " My audio should be better than it usually is because I have a new microphone, but I",
        "tokens": [
          51010,
          1222,
          6278,
          820,
          312,
          1101,
          813,
          309,
          2673,
          307,
          570,
          286,
          362,
          257,
          777,
          10952,
          11,
          457,
          286,
          51256
        ]
      },
      {
        "avg_logprob": -0.38198834373837426,
        "compression_ratio": 1.2601626016260163,
        "end": 172.84,
        "id": 2,
        "no_speech_prob": 0.12523266673088074,
        "seek": 15000,
        "start": 167.84,
        "temperature": 0,
        "text": " am curious to hear from you what it sounds like.",
        "tokens": [
          51256,
          669,
          6369,
          281,
          1568,
          490,
          291,
          437,
          309,
          3263,
          411,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.977071898324149,
        "compression_ratio": 0.6,
        "end": 179.84,
        "id": 3,
        "no_speech_prob": 0.8980017304420471,
        "seek": 17284,
        "start": 172.84,
        "temperature": 0,
        "text": " Let me know!",
        "tokens": [
          50364,
          961,
          385,
          458,
          0,
          50714
        ]
      },
      {
        "avg_logprob": -0.5433203957297585,
        "compression_ratio": 1.3305785123966942,
        "end": 216.08,
        "id": 4,
        "no_speech_prob": 0.027141166850924492,
        "seek": 20284,
        "start": 202.84,
        "temperature": 0,
        "text": " Second audio sound check.",
        "tokens": [
          50364,
          5736,
          6278,
          1626,
          1520,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.5433203957297585,
        "compression_ratio": 1.3305785123966942,
        "end": 222.16,
        "id": 5,
        "no_speech_prob": 0.027141166850924492,
        "seek": 20284,
        "start": 216.08,
        "temperature": 0,
        "text": " I actually had the audio of the music doubled, so now this is a better check.",
        "tokens": [
          51026,
          286,
          767,
          632,
          264,
          6278,
          295,
          264,
          1318,
          24405,
          11,
          370,
          586,
          341,
          307,
          257,
          1101,
          1520,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.5433203957297585,
        "compression_ratio": 1.3305785123966942,
        "end": 225,
        "id": 6,
        "no_speech_prob": 0.027141166850924492,
        "seek": 20284,
        "start": 222.16,
        "temperature": 0,
        "text": " Although everyone said it sounded good before.",
        "tokens": [
          51330,
          5780,
          1518,
          848,
          309,
          17714,
          665,
          949,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.5433203957297585,
        "compression_ratio": 1.3305785123966942,
        "end": 226.76,
        "id": 7,
        "no_speech_prob": 0.027141166850924492,
        "seek": 20284,
        "start": 225,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51472,
          1057,
          558,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.36381380898611887,
        "compression_ratio": 1.1066666666666667,
        "end": 233.76,
        "id": 8,
        "no_speech_prob": 0.49847444891929626,
        "seek": 22676,
        "start": 226.76,
        "temperature": 0,
        "text": " Can anyone actually tell that this mic is better than what I used to use last week?",
        "tokens": [
          50414,
          1664,
          2878,
          767,
          980,
          300,
          341,
          3123,
          307,
          1101,
          813,
          437,
          286,
          1143,
          281,
          764,
          1036,
          1243,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.48742018247905533,
        "compression_ratio": 0.9710144927536232,
        "end": 285.76,
        "id": 9,
        "no_speech_prob": 0.22488903999328613,
        "seek": 25676,
        "start": 256.76,
        "temperature": 0,
        "text": " I'll be starting in about two minutes or one minute and 40 seconds.",
        "tokens": [
          50364,
          286,
          603,
          312,
          2891,
          294,
          466,
          732,
          2077,
          420,
          472,
          3456,
          293,
          3356,
          3949,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.8142685890197754,
        "compression_ratio": 0.5555555555555556,
        "end": 305.76,
        "id": 10,
        "no_speech_prob": 0.9682415127754211,
        "seek": 28576,
        "start": 285.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.7074798175266811,
        "compression_ratio": 0.5555555555555556,
        "end": 325.76,
        "id": 11,
        "no_speech_prob": 0.9238188862800598,
        "seek": 30576,
        "start": 305.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.4913055896759033,
        "compression_ratio": 0.5555555555555556,
        "end": 345.76,
        "id": 12,
        "no_speech_prob": 0.9308478236198425,
        "seek": 32576,
        "start": 325.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.38238791057041716,
        "compression_ratio": 0.5555555555555556,
        "end": 365.76,
        "id": 13,
        "no_speech_prob": 0.9182538390159607,
        "seek": 34576,
        "start": 345.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.6412161588668823,
        "compression_ratio": 1.037037037037037,
        "end": 375.76,
        "id": 14,
        "no_speech_prob": 0.017174335196614265,
        "seek": 36576,
        "start": 365.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.6412161588668823,
        "compression_ratio": 1.037037037037037,
        "end": 385.76,
        "id": 15,
        "no_speech_prob": 0.017174335196614265,
        "seek": 36576,
        "start": 375.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50864,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.6412161588668823,
        "compression_ratio": 1.037037037037037,
        "end": 389.76,
        "id": 16,
        "no_speech_prob": 0.017174335196614265,
        "seek": 36576,
        "start": 385.76,
        "temperature": 0,
        "text": " Hello!",
        "tokens": [
          51364,
          2425,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 395.76,
        "id": 17,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 390.76,
        "temperature": 0,
        "text": " There's got to be a universal way to say good blank with all of the different times.",
        "tokens": [
          50414,
          821,
          311,
          658,
          281,
          312,
          257,
          11455,
          636,
          281,
          584,
          665,
          8247,
          365,
          439,
          295,
          264,
          819,
          1413,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 397.76,
        "id": 18,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 395.76,
        "temperature": 0,
        "text": " Good day, but it might be the middle of the night for some of you.",
        "tokens": [
          50664,
          2205,
          786,
          11,
          457,
          309,
          1062,
          312,
          264,
          2808,
          295,
          264,
          1818,
          337,
          512,
          295,
          291,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 398.76,
        "id": 19,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 397.76,
        "temperature": 0,
        "text": " Good day!",
        "tokens": [
          50764,
          2205,
          786,
          0,
          50814
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 399.76,
        "id": 20,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 398.76,
        "temperature": 0,
        "text": " I said good day!",
        "tokens": [
          50814,
          286,
          848,
          665,
          786,
          0,
          50864
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 404.76,
        "id": 21,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 399.76,
        "temperature": 0,
        "text": " Good morning, good afternoon, good evening, good middle of the night to all of you.",
        "tokens": [
          50864,
          2205,
          2446,
          11,
          665,
          6499,
          11,
          665,
          5634,
          11,
          665,
          2808,
          295,
          264,
          1818,
          281,
          439,
          295,
          291,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 410.76,
        "id": 22,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 404.76,
        "temperature": 0,
        "text": " Hi, this is Dan coming to you live from an attic in Brooklyn, New York, where it is",
        "tokens": [
          51114,
          2421,
          11,
          341,
          307,
          3394,
          1348,
          281,
          291,
          1621,
          490,
          364,
          40766,
          294,
          21872,
          11,
          1873,
          3609,
          11,
          689,
          309,
          307,
          51414
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 413.76,
        "id": 23,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 410.76,
        "temperature": 0,
        "text": " a beautiful day outside, although getting a little chilly.",
        "tokens": [
          51414,
          257,
          2238,
          786,
          2380,
          11,
          4878,
          1242,
          257,
          707,
          39815,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20298097979637883,
        "compression_ratio": 1.6826568265682658,
        "end": 416.76,
        "id": 24,
        "no_speech_prob": 0.1732073873281479,
        "seek": 38976,
        "start": 413.76,
        "temperature": 0,
        "text": " This is not the time I usually like to livestream.",
        "tokens": [
          51564,
          639,
          307,
          406,
          264,
          565,
          286,
          2673,
          411,
          281,
          29782,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 419.76,
        "id": 25,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 416.76,
        "temperature": 0,
        "text": " This is actually the time I usually like to take a nap.",
        "tokens": [
          50364,
          639,
          307,
          767,
          264,
          565,
          286,
          2673,
          411,
          281,
          747,
          257,
          9296,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 422.76,
        "id": 26,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 419.76,
        "temperature": 0,
        "text": " But, you know, I'm wearing my cozy sweater.",
        "tokens": [
          50514,
          583,
          11,
          291,
          458,
          11,
          286,
          478,
          4769,
          452,
          29414,
          26550,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 424.76,
        "id": 27,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 422.76,
        "temperature": 0,
        "text": " I'm here on the internet with all of you.",
        "tokens": [
          50664,
          286,
          478,
          510,
          322,
          264,
          4705,
          365,
          439,
          295,
          291,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 431.76,
        "id": 28,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 424.76,
        "temperature": 0,
        "text": " So far, nobody's said anything like this has stopped working, so I'm assuming I'm actually",
        "tokens": [
          50764,
          407,
          1400,
          11,
          5079,
          311,
          848,
          1340,
          411,
          341,
          575,
          5936,
          1364,
          11,
          370,
          286,
          478,
          11926,
          286,
          478,
          767,
          51114
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 432.76,
        "id": 29,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 431.76,
        "temperature": 0,
        "text": " livestreaming.",
        "tokens": [
          51114,
          29782,
          278,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 436.76,
        "id": 30,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 432.76,
        "temperature": 0,
        "text": " Now, I've been working steadily to improve the quality of my livestreams.",
        "tokens": [
          51164,
          823,
          11,
          286,
          600,
          668,
          1364,
          36129,
          281,
          3470,
          264,
          3125,
          295,
          452,
          29782,
          82,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 440.76,
        "id": 31,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 436.76,
        "temperature": 0,
        "text": " As you might remember, last week I received some new...",
        "tokens": [
          51364,
          1018,
          291,
          1062,
          1604,
          11,
          1036,
          1243,
          286,
          4613,
          512,
          777,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 441.76,
        "id": 32,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 440.76,
        "temperature": 0,
        "text": " I received.",
        "tokens": [
          51564,
          286,
          4613,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2182711963505708,
        "compression_ratio": 1.6901408450704225,
        "end": 444.76,
        "id": 33,
        "no_speech_prob": 0.32073861360549927,
        "seek": 41676,
        "start": 441.76,
        "temperature": 0,
        "text": " I did receive them because I ordered them when they came, but I installed some new lights.",
        "tokens": [
          51614,
          286,
          630,
          4774,
          552,
          570,
          286,
          8866,
          552,
          562,
          436,
          1361,
          11,
          457,
          286,
          8899,
          512,
          777,
          5811,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2140930982736441,
        "compression_ratio": 1.5458333333333334,
        "end": 450.76,
        "id": 34,
        "no_speech_prob": 0.18947453796863556,
        "seek": 44476,
        "start": 445.76,
        "temperature": 0,
        "text": " So my skin and my face and everything should be looking positively aglow for you.",
        "tokens": [
          50414,
          407,
          452,
          3178,
          293,
          452,
          1851,
          293,
          1203,
          820,
          312,
          1237,
          25795,
          623,
          14107,
          337,
          291,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2140930982736441,
        "compression_ratio": 1.5458333333333334,
        "end": 461.76,
        "id": 35,
        "no_speech_prob": 0.18947453796863556,
        "seek": 44476,
        "start": 450.76,
        "temperature": 0,
        "text": " Now, the cool, crisp, dulcet tones of my voice should be arriving into your ear... devices",
        "tokens": [
          50664,
          823,
          11,
          264,
          1627,
          11,
          22952,
          11,
          44012,
          66,
          302,
          19995,
          295,
          452,
          3177,
          820,
          312,
          22436,
          666,
          428,
          1273,
          485,
          5759,
          51214
        ]
      },
      {
        "avg_logprob": -0.2140930982736441,
        "compression_ratio": 1.5458333333333334,
        "end": 466.76,
        "id": 36,
        "no_speech_prob": 0.18947453796863556,
        "seek": 44476,
        "start": 461.76,
        "temperature": 0,
        "text": " in a new and perhaps higher quality way because, and I'm just going to hold this up for you,",
        "tokens": [
          51214,
          294,
          257,
          777,
          293,
          4317,
          2946,
          3125,
          636,
          570,
          11,
          293,
          286,
          478,
          445,
          516,
          281,
          1797,
          341,
          493,
          337,
          291,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2140930982736441,
        "compression_ratio": 1.5458333333333334,
        "end": 472.76,
        "id": 37,
        "no_speech_prob": 0.18947453796863556,
        "seek": 44476,
        "start": 466.76,
        "temperature": 0,
        "text": " I, uh, this is not a sponsored anything, although, hey, I'm available, Elgato.",
        "tokens": [
          51464,
          286,
          11,
          2232,
          11,
          341,
          307,
          406,
          257,
          16621,
          1340,
          11,
          4878,
          11,
          4177,
          11,
          286,
          478,
          2435,
          11,
          2699,
          70,
          2513,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2140930982736441,
        "compression_ratio": 1.5458333333333334,
        "end": 473.76,
        "id": 38,
        "no_speech_prob": 0.18947453796863556,
        "seek": 44476,
        "start": 472.76,
        "temperature": 0,
        "text": " Elgato, are you listening?",
        "tokens": [
          51764,
          2699,
          70,
          2513,
          11,
          366,
          291,
          4764,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 477.76,
        "id": 39,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 474.76,
        "temperature": 0,
        "text": " This is the Elgato Wave 3 mic that I ordered.",
        "tokens": [
          50414,
          639,
          307,
          264,
          2699,
          70,
          2513,
          28530,
          805,
          3123,
          300,
          286,
          8866,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 482.76,
        "id": 40,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 478.76,
        "temperature": 0,
        "text": " And somebody in the chat, Rahith, just said, oh no, it stopped working.",
        "tokens": [
          50614,
          400,
          2618,
          294,
          264,
          5081,
          11,
          17844,
          355,
          11,
          445,
          848,
          11,
          1954,
          572,
          11,
          309,
          5936,
          1364,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 486.76,
        "id": 41,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 482.76,
        "temperature": 0,
        "text": " But I'm assuming only Rahith is having an issue with the livestream right now.",
        "tokens": [
          50814,
          583,
          286,
          478,
          11926,
          787,
          17844,
          355,
          307,
          1419,
          364,
          2734,
          365,
          264,
          29782,
          558,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 487.76,
        "id": 42,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 486.76,
        "temperature": 0,
        "text": " Rahith, come back!",
        "tokens": [
          51014,
          17844,
          355,
          11,
          808,
          646,
          0,
          51064
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 488.76,
        "id": 43,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 487.76,
        "temperature": 0,
        "text": " Come back, Rahith.",
        "tokens": [
          51064,
          2492,
          646,
          11,
          17844,
          355,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 495.76,
        "id": 44,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 489.76,
        "temperature": 0,
        "text": " I want you to be experiencing the dulcet tones of my voice in my new microphone.",
        "tokens": [
          51164,
          286,
          528,
          291,
          281,
          312,
          11139,
          264,
          44012,
          66,
          302,
          19995,
          295,
          452,
          3177,
          294,
          452,
          777,
          10952,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 497.76,
        "id": 45,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 496.76,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21432065963745117,
        "compression_ratio": 1.5404411764705883,
        "end": 501.76,
        "id": 46,
        "no_speech_prob": 0.020641058683395386,
        "seek": 47376,
        "start": 497.76,
        "temperature": 0,
        "text": " I probably should get one of those things where it's like on an arm and it swivels around",
        "tokens": [
          51564,
          286,
          1391,
          820,
          483,
          472,
          295,
          729,
          721,
          689,
          309,
          311,
          411,
          322,
          364,
          3726,
          293,
          309,
          1693,
          488,
          11784,
          926,
          51764
        ]
      },
      {
        "avg_logprob": -0.18461884585293856,
        "compression_ratio": 1.6610169491525424,
        "end": 504.76,
        "id": 47,
        "no_speech_prob": 0.0038236428517848253,
        "seek": 50176,
        "start": 501.76,
        "temperature": 0,
        "text": " and it's just like propped right here, but I don't know.",
        "tokens": [
          50364,
          293,
          309,
          311,
          445,
          411,
          447,
          3320,
          558,
          510,
          11,
          457,
          286,
          500,
          380,
          458,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18461884585293856,
        "compression_ratio": 1.6610169491525424,
        "end": 507.76,
        "id": 48,
        "no_speech_prob": 0.0038236428517848253,
        "seek": 50176,
        "start": 506.76,
        "temperature": 0,
        "text": " I don't know if that's for me.",
        "tokens": [
          50614,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          337,
          385,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18461884585293856,
        "compression_ratio": 1.6610169491525424,
        "end": 512.76,
        "id": 49,
        "no_speech_prob": 0.0038236428517848253,
        "seek": 50176,
        "start": 507.76,
        "temperature": 0,
        "text": " Every week I would like to make a small upgrade, which incidentally, I have nothing left to upgrade.",
        "tokens": [
          50664,
          2048,
          1243,
          286,
          576,
          411,
          281,
          652,
          257,
          1359,
          11484,
          11,
          597,
          9348,
          379,
          11,
          286,
          362,
          1825,
          1411,
          281,
          11484,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18461884585293856,
        "compression_ratio": 1.6610169491525424,
        "end": 516.76,
        "id": 50,
        "no_speech_prob": 0.0038236428517848253,
        "seek": 50176,
        "start": 512.76,
        "temperature": 0,
        "text": " So if you've got any ideas for me, let me know what I should upgrade for next week.",
        "tokens": [
          50914,
          407,
          498,
          291,
          600,
          658,
          604,
          3487,
          337,
          385,
          11,
          718,
          385,
          458,
          437,
          286,
          820,
          11484,
          337,
          958,
          1243,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18461884585293856,
        "compression_ratio": 1.6610169491525424,
        "end": 524.76,
        "id": 51,
        "no_speech_prob": 0.0038236428517848253,
        "seek": 50176,
        "start": 520.76,
        "temperature": 0,
        "text": " Actually, there is something also new that I would like to experiment with.",
        "tokens": [
          51314,
          5135,
          11,
          456,
          307,
          746,
          611,
          777,
          300,
          286,
          576,
          411,
          281,
          5120,
          365,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18461884585293856,
        "compression_ratio": 1.6610169491525424,
        "end": 529.76,
        "id": 52,
        "no_speech_prob": 0.0038236428517848253,
        "seek": 50176,
        "start": 525.76,
        "temperature": 0,
        "text": " Let me see here if we can get this to work.",
        "tokens": [
          51564,
          961,
          385,
          536,
          510,
          498,
          321,
          393,
          483,
          341,
          281,
          589,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 533.76,
        "id": 53,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 529.76,
        "temperature": 0,
        "text": " This is a new feature that I will be using on the Coding Train.",
        "tokens": [
          50364,
          639,
          307,
          257,
          777,
          4111,
          300,
          286,
          486,
          312,
          1228,
          322,
          264,
          383,
          8616,
          28029,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 536.76,
        "id": 54,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 534.76,
        "temperature": 0,
        "text": " And I'm just going to quickly test it right now.",
        "tokens": [
          50614,
          400,
          286,
          478,
          445,
          516,
          281,
          2661,
          1500,
          309,
          558,
          586,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 539.76,
        "id": 55,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 536.76,
        "temperature": 0,
        "text": " I probably should do more to introduce myself and what I'm going to be doing today.",
        "tokens": [
          50714,
          286,
          1391,
          820,
          360,
          544,
          281,
          5366,
          2059,
          293,
          437,
          286,
          478,
          516,
          281,
          312,
          884,
          965,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 540.76,
        "id": 56,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 539.76,
        "temperature": 0,
        "text": " But bear with me.",
        "tokens": [
          50864,
          583,
          6155,
          365,
          385,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 541.76,
        "id": 57,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 540.76,
        "temperature": 0,
        "text": " I'm moving to here.",
        "tokens": [
          50914,
          286,
          478,
          2684,
          281,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 543.76,
        "id": 58,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 541.76,
        "temperature": 0,
        "text": " Oh, and I've got my glitch page open.",
        "tokens": [
          50964,
          876,
          11,
          293,
          286,
          600,
          658,
          452,
          23552,
          3028,
          1269,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 546.76,
        "id": 59,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 543.76,
        "temperature": 0,
        "text": " But actually, let me remove this.",
        "tokens": [
          51064,
          583,
          767,
          11,
          718,
          385,
          4159,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 547.76,
        "id": 60,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 546.76,
        "temperature": 0,
        "text": " No!",
        "tokens": [
          51214,
          883,
          0,
          51264
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 548.76,
        "id": 61,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 547.76,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51264,
          708,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 549.76,
        "id": 62,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 548.76,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51314,
          883,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 550.76,
        "id": 63,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 549.76,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51364,
          2438,
          0,
          51414
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 551.76,
        "id": 64,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 550.76,
        "temperature": 0,
        "text": " Wrong button.",
        "tokens": [
          51414,
          28150,
          2960,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 552.76,
        "id": 65,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 551.76,
        "temperature": 0,
        "text": " All right, I have to do this manually.",
        "tokens": [
          51464,
          1057,
          558,
          11,
          286,
          362,
          281,
          360,
          341,
          16945,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17587720747474286,
        "compression_ratio": 1.5805243445692885,
        "end": 556.76,
        "id": 66,
        "no_speech_prob": 0.0018099455628544092,
        "seek": 52976,
        "start": 554.76,
        "temperature": 0,
        "text": " Well, this is very silly what I'm doing now.",
        "tokens": [
          51614,
          1042,
          11,
          341,
          307,
          588,
          11774,
          437,
          286,
          478,
          884,
          586,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 560.76,
        "id": 67,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 557.76,
        "temperature": 0,
        "text": " I can't find my screen to remove it.",
        "tokens": [
          50414,
          286,
          393,
          380,
          915,
          452,
          2568,
          281,
          4159,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 562.76,
        "id": 68,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 560.76,
        "temperature": 0,
        "text": " Oh, it's so hard.",
        "tokens": [
          50564,
          876,
          11,
          309,
          311,
          370,
          1152,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 563.76,
        "id": 69,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 562.76,
        "temperature": 0,
        "text": " Where?",
        "tokens": [
          50664,
          2305,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 564.76,
        "id": 70,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 563.76,
        "temperature": 0,
        "text": " Oh, there it is.",
        "tokens": [
          50714,
          876,
          11,
          456,
          309,
          307,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 567.76,
        "id": 71,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 564.76,
        "temperature": 0,
        "text": " Oh, I'm in emptiness.",
        "tokens": [
          50764,
          876,
          11,
          286,
          478,
          294,
          41993,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 570.76,
        "id": 72,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 567.76,
        "temperature": 0,
        "text": " It is so sad here in the emptiness.",
        "tokens": [
          50914,
          467,
          307,
          370,
          4227,
          510,
          294,
          264,
          41993,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 572.76,
        "id": 73,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 571.76,
        "temperature": 0,
        "text": " All right, this is fine.",
        "tokens": [
          51114,
          1057,
          558,
          11,
          341,
          307,
          2489,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 573.76,
        "id": 74,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 572.76,
        "temperature": 0,
        "text": " Just put that back.",
        "tokens": [
          51164,
          1449,
          829,
          300,
          646,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 574.76,
        "id": 75,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 573.76,
        "temperature": 0,
        "text": " It doesn't matter.",
        "tokens": [
          51214,
          467,
          1177,
          380,
          1871,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 576.76,
        "id": 76,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 575.76,
        "temperature": 0,
        "text": " Spoiler alert.",
        "tokens": [
          51314,
          45011,
          5441,
          9615,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 577.76,
        "id": 77,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 576.76,
        "temperature": 0,
        "text": " I'm going to use glitch.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          764,
          23552,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1843243980407715,
        "compression_ratio": 1.471264367816092,
        "end": 578.76,
        "id": 78,
        "no_speech_prob": 0.006387695670127869,
        "seek": 55676,
        "start": 577.76,
        "temperature": 0,
        "text": " Let's see here.",
        "tokens": [
          51414,
          961,
          311,
          536,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1957798855645316,
        "compression_ratio": 1.628,
        "end": 585.76,
        "id": 79,
        "no_speech_prob": 0.2597229778766632,
        "seek": 57876,
        "start": 578.76,
        "temperature": 0,
        "text": " So, everyone who is a Coding Train member, meaning you've signed up through the subscription.",
        "tokens": [
          50364,
          407,
          11,
          1518,
          567,
          307,
          257,
          383,
          8616,
          28029,
          4006,
          11,
          3620,
          291,
          600,
          8175,
          493,
          807,
          264,
          17231,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1957798855645316,
        "compression_ratio": 1.628,
        "end": 587.76,
        "id": 80,
        "no_speech_prob": 0.2597229778766632,
        "seek": 57876,
        "start": 585.76,
        "temperature": 0,
        "text": " No, that's not the right.",
        "tokens": [
          50714,
          883,
          11,
          300,
          311,
          406,
          264,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1957798855645316,
        "compression_ratio": 1.628,
        "end": 590.76,
        "id": 81,
        "no_speech_prob": 0.2597229778766632,
        "seek": 57876,
        "start": 587.76,
        "temperature": 0,
        "text": " I'm trying to not use the word paid, but honestly, that's what it is.",
        "tokens": [
          50814,
          286,
          478,
          1382,
          281,
          406,
          764,
          264,
          1349,
          4835,
          11,
          457,
          6095,
          11,
          300,
          311,
          437,
          309,
          307,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1957798855645316,
        "compression_ratio": 1.628,
        "end": 594.76,
        "id": 82,
        "no_speech_prob": 0.2597229778766632,
        "seek": 57876,
        "start": 591.76,
        "temperature": 0,
        "text": " There's a Discord available for everyone.",
        "tokens": [
          51014,
          821,
          311,
          257,
          32623,
          2435,
          337,
          1518,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1957798855645316,
        "compression_ratio": 1.628,
        "end": 596.76,
        "id": 83,
        "no_speech_prob": 0.2597229778766632,
        "seek": 57876,
        "start": 594.76,
        "temperature": 0,
        "text": " There's a public Discord for anybody who wants to join.",
        "tokens": [
          51164,
          821,
          311,
          257,
          1908,
          32623,
          337,
          4472,
          567,
          2738,
          281,
          3917,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1957798855645316,
        "compression_ratio": 1.628,
        "end": 600.76,
        "id": 84,
        "no_speech_prob": 0.2597229778766632,
        "seek": 57876,
        "start": 598.76,
        "temperature": 0,
        "text": " I just posted a link to it in the chat.",
        "tokens": [
          51364,
          286,
          445,
          9437,
          257,
          2113,
          281,
          309,
          294,
          264,
          5081,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1957798855645316,
        "compression_ratio": 1.628,
        "end": 605.76,
        "id": 85,
        "no_speech_prob": 0.2597229778766632,
        "seek": 57876,
        "start": 600.76,
        "temperature": 0,
        "text": " But I also have, if you would like to join the Coding Train membership program.",
        "tokens": [
          51464,
          583,
          286,
          611,
          362,
          11,
          498,
          291,
          576,
          411,
          281,
          3917,
          264,
          383,
          8616,
          28029,
          16560,
          1461,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22869225765796417,
        "compression_ratio": 1.5020576131687242,
        "end": 608.76,
        "id": 86,
        "no_speech_prob": 0.10812563449144363,
        "seek": 60576,
        "start": 606.76,
        "temperature": 0,
        "text": " I feel like...",
        "tokens": [
          50414,
          286,
          841,
          411,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.22869225765796417,
        "compression_ratio": 1.5020576131687242,
        "end": 616.76,
        "id": 87,
        "no_speech_prob": 0.10812563449144363,
        "seek": 60576,
        "start": 611.76,
        "temperature": 0,
        "text": " For your membership in the Coding Train, you will receive not very much, to be perfectly honest.",
        "tokens": [
          50664,
          1171,
          428,
          16560,
          294,
          264,
          383,
          8616,
          28029,
          11,
          291,
          486,
          4774,
          406,
          588,
          709,
          11,
          281,
          312,
          6239,
          3245,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22869225765796417,
        "compression_ratio": 1.5020576131687242,
        "end": 619.76,
        "id": 88,
        "no_speech_prob": 0.10812563449144363,
        "seek": 60576,
        "start": 616.76,
        "temperature": 0,
        "text": " But it's a nice smaller community of folks.",
        "tokens": [
          50914,
          583,
          309,
          311,
          257,
          1481,
          4356,
          1768,
          295,
          4024,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22869225765796417,
        "compression_ratio": 1.5020576131687242,
        "end": 624.76,
        "id": 89,
        "no_speech_prob": 0.10812563449144363,
        "seek": 60576,
        "start": 619.76,
        "temperature": 0,
        "text": " We've got a channel in the Discord dedicated to chatting during the live stream.",
        "tokens": [
          51064,
          492,
          600,
          658,
          257,
          2269,
          294,
          264,
          32623,
          8374,
          281,
          24654,
          1830,
          264,
          1621,
          4309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22869225765796417,
        "compression_ratio": 1.5020576131687242,
        "end": 629.76,
        "id": 90,
        "no_speech_prob": 0.10812563449144363,
        "seek": 60576,
        "start": 624.76,
        "temperature": 0,
        "text": " And what I am very excited to demonstrate for you right now, and most likely it's not going to work.",
        "tokens": [
          51314,
          400,
          437,
          286,
          669,
          588,
          2919,
          281,
          11698,
          337,
          291,
          558,
          586,
          11,
          293,
          881,
          3700,
          309,
          311,
          406,
          516,
          281,
          589,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22869225765796417,
        "compression_ratio": 1.5020576131687242,
        "end": 631.76,
        "id": 91,
        "no_speech_prob": 0.10812563449144363,
        "seek": 60576,
        "start": 630.76,
        "temperature": 0,
        "text": " I was having some problems.",
        "tokens": [
          51614,
          286,
          390,
          1419,
          512,
          2740,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 632.76,
        "id": 92,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 631.76,
        "temperature": 0,
        "text": " I was having some problems.",
        "tokens": [
          50364,
          286,
          390,
          1419,
          512,
          2740,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 636.76,
        "id": 93,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 632.76,
        "temperature": 0,
        "text": " But David Snyder and Kobe, who are...",
        "tokens": [
          50414,
          583,
          4389,
          49464,
          1068,
          293,
          46296,
          11,
          567,
          366,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 639.76,
        "id": 94,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 637.76,
        "temperature": 0,
        "text": " I can upgrade the green screen area, says Bruno.",
        "tokens": [
          50664,
          286,
          393,
          11484,
          264,
          3092,
          2568,
          1859,
          11,
          1619,
          23046,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 640.76,
        "id": 95,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 639.76,
        "temperature": 0,
        "text": " Oh, wait.",
        "tokens": [
          50764,
          876,
          11,
          1699,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 641.76,
        "id": 96,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 640.76,
        "temperature": 0,
        "text": " Let's make this.",
        "tokens": [
          50814,
          961,
          311,
          652,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 642.76,
        "id": 97,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 641.76,
        "temperature": 0,
        "text": " I don't have to.",
        "tokens": [
          50864,
          286,
          500,
          380,
          362,
          281,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 644.76,
        "id": 98,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 643.76,
        "temperature": 0,
        "text": " I need this on...",
        "tokens": [
          50964,
          286,
          643,
          341,
          322,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 645.76,
        "id": 99,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 644.76,
        "temperature": 0,
        "text": " You know what I need to do?",
        "tokens": [
          51014,
          509,
          458,
          437,
          286,
          643,
          281,
          360,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 646.76,
        "id": 100,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 645.76,
        "temperature": 0,
        "text": " I need to put this on a tablet.",
        "tokens": [
          51064,
          286,
          643,
          281,
          829,
          341,
          322,
          257,
          14136,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 648.76,
        "id": 101,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 647.76,
        "temperature": 0,
        "text": " I don't know why I didn't think of this.",
        "tokens": [
          51164,
          286,
          500,
          380,
          458,
          983,
          286,
          994,
          380,
          519,
          295,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 649.76,
        "id": 102,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 648.76,
        "temperature": 0,
        "text": " I need a tablet.",
        "tokens": [
          51214,
          286,
          643,
          257,
          14136,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 652.76,
        "id": 103,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 651.76,
        "temperature": 0,
        "text": " We need a mobile version of this.",
        "tokens": [
          51364,
          492,
          643,
          257,
          6013,
          3037,
          295,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 654.76,
        "id": 104,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 653.76,
        "temperature": 0,
        "text": " Touch enabled.",
        "tokens": [
          51464,
          20029,
          15172,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 656.76,
        "id": 105,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 655.76,
        "temperature": 0,
        "text": " Click.",
        "tokens": [
          51564,
          8230,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 657.76,
        "id": 106,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 656.76,
        "temperature": 0,
        "text": " Ah, it crashed.",
        "tokens": [
          51614,
          2438,
          11,
          309,
          24190,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20196976926591662,
        "compression_ratio": 1.680672268907563,
        "end": 659.76,
        "id": 107,
        "no_speech_prob": 0.08150304853916168,
        "seek": 63176,
        "start": 658.76,
        "temperature": 0,
        "text": " So, I don't know what's going on.",
        "tokens": [
          51714,
          407,
          11,
          286,
          500,
          380,
          458,
          437,
          311,
          516,
          322,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 661.76,
        "id": 108,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 659.76,
        "temperature": 0,
        "text": " But we're attempting to debug this.",
        "tokens": [
          50364,
          583,
          321,
          434,
          22001,
          281,
          24083,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 665.76,
        "id": 109,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 662.76,
        "temperature": 0,
        "text": " I'm using a piece of software known as DisStreamChat.",
        "tokens": [
          50514,
          286,
          478,
          1228,
          257,
          2522,
          295,
          4722,
          2570,
          382,
          4208,
          4520,
          1572,
          41683,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 671.76,
        "id": 110,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 666.76,
        "temperature": 0,
        "text": " Which I suppose is Discord plus streaming and plus chatting.",
        "tokens": [
          50714,
          3013,
          286,
          7297,
          307,
          32623,
          1804,
          11791,
          293,
          1804,
          24654,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 674.76,
        "id": 111,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 672.76,
        "temperature": 0,
        "text": " But I always think it's trying to diss me.",
        "tokens": [
          51014,
          583,
          286,
          1009,
          519,
          309,
          311,
          1382,
          281,
          7802,
          385,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 678.76,
        "id": 112,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 676.76,
        "temperature": 0,
        "text": " Oh, I amused myself.",
        "tokens": [
          51214,
          876,
          11,
          286,
          669,
          4717,
          2059,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 679.76,
        "id": 113,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 678.76,
        "temperature": 0,
        "text": " Let's run it again.",
        "tokens": [
          51314,
          961,
          311,
          1190,
          309,
          797,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 681.76,
        "id": 114,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 680.76,
        "temperature": 0,
        "text": " I have a feeling it's going to...",
        "tokens": [
          51414,
          286,
          362,
          257,
          2633,
          309,
          311,
          516,
          281,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2133350548920808,
        "compression_ratio": 1.5338645418326693,
        "end": 687.76,
        "id": 115,
        "no_speech_prob": 0.0128201674669981,
        "seek": 65976,
        "start": 681.76,
        "temperature": 0,
        "text": " For some reason right now, it's got this really wonderful feature where it works the second time I click the button.",
        "tokens": [
          51464,
          1171,
          512,
          1778,
          558,
          586,
          11,
          309,
          311,
          658,
          341,
          534,
          3715,
          4111,
          689,
          309,
          1985,
          264,
          1150,
          565,
          286,
          2052,
          264,
          2960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 689.76,
        "id": 116,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 687.76,
        "temperature": 0,
        "text": " But as soon as I click Bruno, I hope this is okay with you.",
        "tokens": [
          50364,
          583,
          382,
          2321,
          382,
          286,
          2052,
          23046,
          11,
          286,
          1454,
          341,
          307,
          1392,
          365,
          291,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 691.76,
        "id": 117,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 690.76,
        "temperature": 0,
        "text": " I'm going to assume this is okay with Bruno.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          6552,
          341,
          307,
          1392,
          365,
          23046,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 696.76,
        "id": 118,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 692.76,
        "temperature": 0,
        "text": " Bruno, can you give me a big thumbs up that I'm going to bring your chat message onto the screen right here?",
        "tokens": [
          50614,
          23046,
          11,
          393,
          291,
          976,
          385,
          257,
          955,
          8838,
          493,
          300,
          286,
          478,
          516,
          281,
          1565,
          428,
          5081,
          3636,
          3911,
          264,
          2568,
          558,
          510,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 698.76,
        "id": 119,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 697.76,
        "temperature": 0,
        "text": " I will wait.",
        "tokens": [
          50864,
          286,
          486,
          1699,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 699.76,
        "id": 120,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 698.76,
        "temperature": 0,
        "text": " Because I actually...",
        "tokens": [
          50914,
          1436,
          286,
          767,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 703.76,
        "id": 121,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 699.76,
        "temperature": 0,
        "text": " So, what I should say is that anyone who now posts in...",
        "tokens": [
          50964,
          407,
          11,
          437,
          286,
          820,
          584,
          307,
          300,
          2878,
          567,
          586,
          12300,
          294,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 704.76,
        "id": 122,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 703.76,
        "temperature": 0,
        "text": " And I could use a different channel for this.",
        "tokens": [
          51164,
          400,
          286,
          727,
          764,
          257,
          819,
          2269,
          337,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 711.76,
        "id": 123,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 704.76,
        "temperature": 0,
        "text": " But in the members Discord live chat channel.",
        "tokens": [
          51214,
          583,
          294,
          264,
          2679,
          32623,
          1621,
          5081,
          2269,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21648975926586705,
        "compression_ratio": 1.6653386454183268,
        "end": 714.76,
        "id": 124,
        "no_speech_prob": 0.010012379847466946,
        "seek": 68776,
        "start": 712.76,
        "temperature": 0,
        "text": " Then your message...",
        "tokens": [
          51614,
          1396,
          428,
          3636,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.23686161556759397,
        "compression_ratio": 1.3920454545454546,
        "end": 718.76,
        "id": 125,
        "no_speech_prob": 0.0035930192098021507,
        "seek": 71476,
        "start": 714.76,
        "temperature": 0,
        "text": " I have a mechanism by which I can click a button and your message pops up on the screen here.",
        "tokens": [
          50364,
          286,
          362,
          257,
          7513,
          538,
          597,
          286,
          393,
          2052,
          257,
          2960,
          293,
          428,
          3636,
          16795,
          493,
          322,
          264,
          2568,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23686161556759397,
        "compression_ratio": 1.3920454545454546,
        "end": 721.76,
        "id": 126,
        "no_speech_prob": 0.0035930192098021507,
        "seek": 71476,
        "start": 719.76,
        "temperature": 0,
        "text": " Using the DisStreamChat software by David and Koby.",
        "tokens": [
          50614,
          11142,
          264,
          4208,
          4520,
          1572,
          41683,
          4722,
          538,
          4389,
          293,
          591,
          13944,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23686161556759397,
        "compression_ratio": 1.3920454545454546,
        "end": 722.76,
        "id": 127,
        "no_speech_prob": 0.0035930192098021507,
        "seek": 71476,
        "start": 721.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23686161556759397,
        "compression_ratio": 1.3920454545454546,
        "end": 727.76,
        "id": 128,
        "no_speech_prob": 0.0035930192098021507,
        "seek": 71476,
        "start": 725.76,
        "temperature": 0,
        "text": " I'm waiting for Bruno to say okay.",
        "tokens": [
          50914,
          286,
          478,
          3806,
          337,
          23046,
          281,
          584,
          1392,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23686161556759397,
        "compression_ratio": 1.3920454545454546,
        "end": 729.76,
        "id": 129,
        "no_speech_prob": 0.0035930192098021507,
        "seek": 71476,
        "start": 728.76,
        "temperature": 0,
        "text": " In the meantime...",
        "tokens": [
          51064,
          682,
          264,
          14991,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.23686161556759397,
        "compression_ratio": 1.3920454545454546,
        "end": 734.76,
        "id": 130,
        "no_speech_prob": 0.0035930192098021507,
        "seek": 71476,
        "start": 732.76,
        "temperature": 0,
        "text": " Bruno is typing, everybody.",
        "tokens": [
          51264,
          23046,
          307,
          18444,
          11,
          2201,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23686161556759397,
        "compression_ratio": 1.3920454545454546,
        "end": 736.76,
        "id": 131,
        "no_speech_prob": 0.0035930192098021507,
        "seek": 71476,
        "start": 735.76,
        "temperature": 0,
        "text": " Bruno is...",
        "tokens": [
          51414,
          23046,
          307,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 737.76,
        "id": 132,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 736.76,
        "temperature": 0,
        "text": " Bruno is...",
        "tokens": [
          50364,
          23046,
          307,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 744.76,
        "id": 133,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 742.76,
        "temperature": 0,
        "text": " It's okay, says Bruno.",
        "tokens": [
          50664,
          467,
          311,
          1392,
          11,
          1619,
          23046,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 747.76,
        "id": 134,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 745.76,
        "temperature": 0,
        "text": " So, now let me go back over to here.",
        "tokens": [
          50814,
          407,
          11,
          586,
          718,
          385,
          352,
          646,
          670,
          281,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 749.76,
        "id": 135,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 748.76,
        "temperature": 0,
        "text": " I really hope this works.",
        "tokens": [
          50964,
          286,
          534,
          1454,
          341,
          1985,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 753.76,
        "id": 136,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 752.76,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          51164,
          821,
          309,
          307,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 754.76,
        "id": 137,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 753.76,
        "temperature": 0,
        "text": " Look.",
        "tokens": [
          51214,
          2053,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 755.76,
        "id": 138,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 754.76,
        "temperature": 0,
        "text": " Bruno's message popped up.",
        "tokens": [
          51264,
          23046,
          311,
          3636,
          21545,
          493,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 757.76,
        "id": 139,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 756.76,
        "temperature": 0,
        "text": " Maybe I should move this.",
        "tokens": [
          51364,
          2704,
          286,
          820,
          1286,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 758.76,
        "id": 140,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 757.76,
        "temperature": 0,
        "text": " Where should this be?",
        "tokens": [
          51414,
          2305,
          820,
          341,
          312,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 760.76,
        "id": 141,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 758.76,
        "temperature": 0,
        "text": " Ideally, where should this be positioned?",
        "tokens": [
          51464,
          40817,
          11,
          689,
          820,
          341,
          312,
          24889,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 762.76,
        "id": 142,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 761.76,
        "temperature": 0,
        "text": " How come it won't move?",
        "tokens": [
          51614,
          1012,
          808,
          309,
          1582,
          380,
          1286,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.22723689832185445,
        "compression_ratio": 1.5166666666666666,
        "end": 764.76,
        "id": 143,
        "no_speech_prob": 0.007692565210163593,
        "seek": 73676,
        "start": 763.76,
        "temperature": 0,
        "text": " How come the...",
        "tokens": [
          51714,
          1012,
          808,
          264,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 765.76,
        "id": 144,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 764.76,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50364,
          2438,
          0,
          50414
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 768.76,
        "id": 145,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 765.76,
        "temperature": 0,
        "text": " What is wrong with Open Broadcast Studio?",
        "tokens": [
          50414,
          708,
          307,
          2085,
          365,
          7238,
          14074,
          3734,
          13500,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 769.76,
        "id": 146,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 768.76,
        "temperature": 0,
        "text": " I can't move it.",
        "tokens": [
          50564,
          286,
          393,
          380,
          1286,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 770.76,
        "id": 147,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 769.76,
        "temperature": 0,
        "text": " That's so weird.",
        "tokens": [
          50614,
          663,
          311,
          370,
          3657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 772.76,
        "id": 148,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 771.76,
        "temperature": 0,
        "text": " But anyway...",
        "tokens": [
          50714,
          583,
          4033,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 774.76,
        "id": 149,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 772.76,
        "temperature": 0,
        "text": " You can see Bruno's message there.",
        "tokens": [
          50764,
          509,
          393,
          536,
          23046,
          311,
          3636,
          456,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 776.76,
        "id": 150,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 774.76,
        "temperature": 0,
        "text": " And I can even show you that Bruno said...",
        "tokens": [
          50864,
          400,
          286,
          393,
          754,
          855,
          291,
          300,
          23046,
          848,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 777.76,
        "id": 151,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 776.76,
        "temperature": 0,
        "text": " I think this might crash.",
        "tokens": [
          50964,
          286,
          519,
          341,
          1062,
          8252,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 778.76,
        "id": 152,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 777.76,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51014,
          961,
          311,
          536,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 779.76,
        "id": 153,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 778.76,
        "temperature": 0,
        "text": " And it crashed.",
        "tokens": [
          51064,
          400,
          309,
          24190,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 780.76,
        "id": 154,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 779.76,
        "temperature": 0,
        "text": " Oh, well.",
        "tokens": [
          51114,
          876,
          11,
          731,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 782.76,
        "id": 155,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 780.76,
        "temperature": 0,
        "text": " So, I'm not going to use this anymore, probably.",
        "tokens": [
          51164,
          407,
          11,
          286,
          478,
          406,
          516,
          281,
          764,
          341,
          3602,
          11,
          1391,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 785.76,
        "id": 156,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 782.76,
        "temperature": 0,
        "text": " Unless we can figure it out.",
        "tokens": [
          51264,
          16581,
          321,
          393,
          2573,
          309,
          484,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 787.76,
        "id": 157,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 785.76,
        "temperature": 0,
        "text": " And I don't know how to get Bruno's message off now.",
        "tokens": [
          51414,
          400,
          286,
          500,
          380,
          458,
          577,
          281,
          483,
          23046,
          311,
          3636,
          766,
          586,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18118362996115614,
        "compression_ratio": 1.5657370517928286,
        "end": 791.76,
        "id": 158,
        "no_speech_prob": 0.0018961778841912746,
        "seek": 76476,
        "start": 788.76,
        "temperature": 0,
        "text": " But this is my idea that...",
        "tokens": [
          51564,
          583,
          341,
          307,
          452,
          1558,
          300,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 799.76,
        "id": 159,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 792.76,
        "temperature": 0,
        "text": " That I will be able to interact a bit more by answering questions and showing messages.",
        "tokens": [
          50414,
          663,
          286,
          486,
          312,
          1075,
          281,
          4648,
          257,
          857,
          544,
          538,
          13430,
          1651,
          293,
          4099,
          7897,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 802.76,
        "id": 160,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 799.76,
        "temperature": 0,
        "text": " By selecting them and curating them and monitoring them.",
        "tokens": [
          50764,
          3146,
          18182,
          552,
          293,
          1262,
          990,
          552,
          293,
          11028,
          552,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 808.76,
        "id": 161,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 802.76,
        "temperature": 0,
        "text": " To have them show up on my fancy live streaming rectangle over here.",
        "tokens": [
          50914,
          1407,
          362,
          552,
          855,
          493,
          322,
          452,
          10247,
          1621,
          11791,
          21930,
          670,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 809.76,
        "id": 162,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 808.76,
        "temperature": 0,
        "text": " Ah, now.",
        "tokens": [
          51214,
          2438,
          11,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 813.76,
        "id": 163,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 809.76,
        "temperature": 0,
        "text": " Kenan says, Daniel, I have a lot of homework.",
        "tokens": [
          51264,
          8273,
          282,
          1619,
          11,
          8033,
          11,
          286,
          362,
          257,
          688,
          295,
          14578,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 814.76,
        "id": 164,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 813.76,
        "temperature": 0,
        "text": " But I am watching you.",
        "tokens": [
          51464,
          583,
          286,
          669,
          1976,
          291,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 816.76,
        "id": 165,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 814.76,
        "temperature": 0,
        "text": " And Kenan, I have one thing to say to you.",
        "tokens": [
          51514,
          400,
          8273,
          282,
          11,
          286,
          362,
          472,
          551,
          281,
          584,
          281,
          291,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 818.76,
        "id": 166,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 816.76,
        "temperature": 0,
        "text": " And I think everybody knows what I'm going to say.",
        "tokens": [
          51614,
          400,
          286,
          519,
          2201,
          3255,
          437,
          286,
          478,
          516,
          281,
          584,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21341533660888673,
        "compression_ratio": 1.6447876447876448,
        "end": 820.76,
        "id": 167,
        "no_speech_prob": 0.005297916010022163,
        "seek": 79176,
        "start": 818.76,
        "temperature": 0,
        "text": " You can all think about it for a minute.",
        "tokens": [
          51714,
          509,
          393,
          439,
          519,
          466,
          309,
          337,
          257,
          3456,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 821.76,
        "id": 168,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 820.76,
        "temperature": 0,
        "text": " Say it to yourselves.",
        "tokens": [
          50364,
          6463,
          309,
          281,
          14791,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 822.76,
        "id": 169,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 821.76,
        "temperature": 0,
        "text": " Mm-mm.",
        "tokens": [
          50414,
          8266,
          12,
          2174,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 826.76,
        "id": 170,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 825.76,
        "temperature": 0,
        "text": " Please.",
        "tokens": [
          50614,
          2555,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 827.76,
        "id": 171,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 826.76,
        "temperature": 0,
        "text": " Go and do your homework.",
        "tokens": [
          50664,
          1037,
          293,
          360,
          428,
          14578,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 828.76,
        "id": 172,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 827.76,
        "temperature": 0,
        "text": " I mean, my goodness.",
        "tokens": [
          50714,
          286,
          914,
          11,
          452,
          8387,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 831.76,
        "id": 173,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 829.76,
        "temperature": 0,
        "text": " I understand the desire to procrastinate.",
        "tokens": [
          50814,
          286,
          1223,
          264,
          7516,
          281,
          39306,
          13923,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 841.76,
        "id": 174,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 831.76,
        "temperature": 0,
        "text": " But I cannot imagine that anything I do here today is in any way, shape, or form anywhere close to nearly as meaningful, impactful, and important as your homework.",
        "tokens": [
          50914,
          583,
          286,
          2644,
          3811,
          300,
          1340,
          286,
          360,
          510,
          965,
          307,
          294,
          604,
          636,
          11,
          3909,
          11,
          420,
          1254,
          4992,
          1998,
          281,
          6217,
          382,
          10995,
          11,
          30842,
          11,
          293,
          1021,
          382,
          428,
          14578,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 843.76,
        "id": 175,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 841.76,
        "temperature": 0,
        "text": " So, I encourage you to do your homework.",
        "tokens": [
          51414,
          407,
          11,
          286,
          5373,
          291,
          281,
          360,
          428,
          14578,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 845.76,
        "id": 176,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 843.76,
        "temperature": 0,
        "text": " You know, maybe you've budgeted your time.",
        "tokens": [
          51514,
          509,
          458,
          11,
          1310,
          291,
          600,
          4706,
          292,
          428,
          565,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 846.76,
        "id": 177,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 845.76,
        "temperature": 0,
        "text": " You know you'll have enough time.",
        "tokens": [
          51614,
          509,
          458,
          291,
          603,
          362,
          1547,
          565,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 848.76,
        "id": 178,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 846.76,
        "temperature": 0,
        "text": " Then I suppose it's okay.",
        "tokens": [
          51664,
          1396,
          286,
          7297,
          309,
          311,
          1392,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20383808631023378,
        "compression_ratio": 1.664179104477612,
        "end": 849.76,
        "id": 179,
        "no_speech_prob": 0.09935799241065979,
        "seek": 82076,
        "start": 848.76,
        "temperature": 0,
        "text": " You can stay.",
        "tokens": [
          51764,
          509,
          393,
          1754,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 854.76,
        "id": 180,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 849.76,
        "temperature": 0,
        "text": " We can be together here on the streaming with decoding and all of that.",
        "tokens": [
          50364,
          492,
          393,
          312,
          1214,
          510,
          322,
          264,
          11791,
          365,
          979,
          8616,
          293,
          439,
          295,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 856.76,
        "id": 181,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 854.76,
        "temperature": 0,
        "text": " But please, please.",
        "tokens": [
          50614,
          583,
          1767,
          11,
          1767,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 859.76,
        "id": 182,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 856.76,
        "temperature": 0,
        "text": " Your dad is saying, please do your homework.",
        "tokens": [
          50714,
          2260,
          3546,
          307,
          1566,
          11,
          1767,
          360,
          428,
          14578,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 861.76,
        "id": 183,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 859.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 864.76,
        "id": 184,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 861.76,
        "temperature": 0,
        "text": " It should be above or below your head.",
        "tokens": [
          50964,
          467,
          820,
          312,
          3673,
          420,
          2507,
          428,
          1378,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 867.76,
        "id": 185,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 864.76,
        "temperature": 0,
        "text": " I assume that's referring to the microphone.",
        "tokens": [
          51114,
          286,
          6552,
          300,
          311,
          13761,
          281,
          264,
          10952,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 869.76,
        "id": 186,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 867.76,
        "temperature": 0,
        "text": " It is below my head right now.",
        "tokens": [
          51264,
          467,
          307,
          2507,
          452,
          1378,
          558,
          586,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 871.76,
        "id": 187,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 869.76,
        "temperature": 0,
        "text": " My head is cut off.",
        "tokens": [
          51364,
          1222,
          1378,
          307,
          1723,
          766,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 873.76,
        "id": 188,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 871.76,
        "temperature": 0,
        "text": " Oh, I have to slouch.",
        "tokens": [
          51464,
          876,
          11,
          286,
          362,
          281,
          1061,
          2220,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 876.76,
        "id": 189,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 873.76,
        "temperature": 0,
        "text": " I think I need to move the camera back.",
        "tokens": [
          51564,
          286,
          519,
          286,
          643,
          281,
          1286,
          264,
          2799,
          646,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1935267448425293,
        "compression_ratio": 1.5541125541125542,
        "end": 877.76,
        "id": 190,
        "no_speech_prob": 0.00844502542167902,
        "seek": 84976,
        "start": 876.76,
        "temperature": 0,
        "text": " Hold on, everybody.",
        "tokens": [
          51714,
          6962,
          322,
          11,
          2201,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 880.76,
        "id": 191,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 878.76,
        "temperature": 0,
        "text": " I don't have a wide enough area.",
        "tokens": [
          50414,
          286,
          500,
          380,
          362,
          257,
          4874,
          1547,
          1859,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 882.76,
        "id": 192,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 880.76,
        "temperature": 0,
        "text": " So, let's see here.",
        "tokens": [
          50514,
          407,
          11,
          718,
          311,
          536,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 885.76,
        "id": 193,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 882.76,
        "temperature": 0,
        "text": " This is probably going to cause all sorts of problems.",
        "tokens": [
          50614,
          639,
          307,
          1391,
          516,
          281,
          3082,
          439,
          7527,
          295,
          2740,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 887.76,
        "id": 194,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 885.76,
        "temperature": 0,
        "text": " Moving the camera back.",
        "tokens": [
          50764,
          14242,
          264,
          2799,
          646,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 888.76,
        "id": 195,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 887.76,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50864,
          876,
          11,
          3237,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 890.76,
        "id": 196,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 888.76,
        "temperature": 0,
        "text": " Let's see what this does.",
        "tokens": [
          50914,
          961,
          311,
          536,
          437,
          341,
          775,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 896.76,
        "id": 197,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 893.76,
        "temperature": 0,
        "text": " And there we are.",
        "tokens": [
          51164,
          400,
          456,
          321,
          366,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 901.76,
        "id": 198,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 899.76,
        "temperature": 0,
        "text": " That's a little bit better.",
        "tokens": [
          51464,
          663,
          311,
          257,
          707,
          857,
          1101,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 902.76,
        "id": 199,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 901.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51564,
          1057,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 903.76,
        "id": 200,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 902.76,
        "temperature": 0,
        "text": " So, we ironed out.",
        "tokens": [
          51614,
          407,
          11,
          321,
          6497,
          292,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 904.76,
        "id": 201,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 903.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51664,
          1057,
          558,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17040814093823703,
        "compression_ratio": 1.52,
        "end": 906.76,
        "id": 202,
        "no_speech_prob": 0.013847951777279377,
        "seek": 87776,
        "start": 904.76,
        "temperature": 0,
        "text": " So, what's happening today on today's live stream?",
        "tokens": [
          51714,
          407,
          11,
          437,
          311,
          2737,
          965,
          322,
          965,
          311,
          1621,
          4309,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.17444030240050748,
        "compression_ratio": 1.5397923875432526,
        "end": 914.76,
        "id": 203,
        "no_speech_prob": 0.05032370984554291,
        "seek": 90676,
        "start": 906.76,
        "temperature": 0,
        "text": " First of all, this is hopefully, I mean, famous last words were ever spoken by me 100,000 times in basically every stream ever.",
        "tokens": [
          50364,
          2386,
          295,
          439,
          11,
          341,
          307,
          4696,
          11,
          286,
          914,
          11,
          4618,
          1036,
          2283,
          645,
          1562,
          10759,
          538,
          385,
          2319,
          11,
          1360,
          1413,
          294,
          1936,
          633,
          4309,
          1562,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17444030240050748,
        "compression_ratio": 1.5397923875432526,
        "end": 919.76,
        "id": 204,
        "no_speech_prob": 0.05032370984554291,
        "seek": 90676,
        "start": 914.76,
        "temperature": 0,
        "text": " But I hope this will be a little bit shorter than usual.",
        "tokens": [
          50764,
          583,
          286,
          1454,
          341,
          486,
          312,
          257,
          707,
          857,
          11639,
          813,
          7713,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17444030240050748,
        "compression_ratio": 1.5397923875432526,
        "end": 924.76,
        "id": 205,
        "no_speech_prob": 0.05032370984554291,
        "seek": 90676,
        "start": 919.76,
        "temperature": 0,
        "text": " I would like to be done by 5 p.m. Eastern Time, which is an hour and 15 minutes from now.",
        "tokens": [
          51014,
          286,
          576,
          411,
          281,
          312,
          1096,
          538,
          1025,
          280,
          13,
          76,
          13,
          12901,
          6161,
          11,
          597,
          307,
          364,
          1773,
          293,
          2119,
          2077,
          490,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17444030240050748,
        "compression_ratio": 1.5397923875432526,
        "end": 929.76,
        "id": 206,
        "no_speech_prob": 0.05032370984554291,
        "seek": 90676,
        "start": 924.76,
        "temperature": 0,
        "text": " Probably not going to happen, but I do have a limited amount of time.",
        "tokens": [
          51264,
          9210,
          406,
          516,
          281,
          1051,
          11,
          457,
          286,
          360,
          362,
          257,
          5567,
          2372,
          295,
          565,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17444030240050748,
        "compression_ratio": 1.5397923875432526,
        "end": 933.76,
        "id": 207,
        "no_speech_prob": 0.05032370984554291,
        "seek": 90676,
        "start": 929.76,
        "temperature": 0,
        "text": " There is some fun family activities that I am planning for this evening.",
        "tokens": [
          51514,
          821,
          307,
          512,
          1019,
          1605,
          5354,
          300,
          286,
          669,
          5038,
          337,
          341,
          5634,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17444030240050748,
        "compression_ratio": 1.5397923875432526,
        "end": 935.76,
        "id": 208,
        "no_speech_prob": 0.05032370984554291,
        "seek": 90676,
        "start": 933.76,
        "temperature": 0,
        "text": " It is getting dark outside.",
        "tokens": [
          51714,
          467,
          307,
          1242,
          2877,
          2380,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 936.76,
        "id": 209,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 935.76,
        "temperature": 0,
        "text": " Evening is coming.",
        "tokens": [
          50364,
          2754,
          278,
          307,
          1348,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 938.76,
        "id": 210,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 936.76,
        "temperature": 0,
        "text": " Winter is coming.",
        "tokens": [
          50414,
          16444,
          307,
          1348,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 940.76,
        "id": 211,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 938.76,
        "temperature": 0,
        "text": " And I do need to get to some other stuff.",
        "tokens": [
          50514,
          400,
          286,
          360,
          643,
          281,
          483,
          281,
          512,
          661,
          1507,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 943.76,
        "id": 212,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 940.76,
        "temperature": 0,
        "text": " But I would like to do a number of things today.",
        "tokens": [
          50614,
          583,
          286,
          576,
          411,
          281,
          360,
          257,
          1230,
          295,
          721,
          965,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 947.76,
        "id": 213,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 943.76,
        "temperature": 0,
        "text": " One is thank our new member, Louise.",
        "tokens": [
          50764,
          1485,
          307,
          1309,
          527,
          777,
          4006,
          11,
          35962,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 950.76,
        "id": 214,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 947.76,
        "temperature": 0,
        "text": " Not sure if Louise is still watching.",
        "tokens": [
          50964,
          1726,
          988,
          498,
          35962,
          307,
          920,
          1976,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 953.76,
        "id": 215,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 950.76,
        "temperature": 0,
        "text": " Welcome, Louise, to the coding train.",
        "tokens": [
          51114,
          4027,
          11,
          35962,
          11,
          281,
          264,
          17720,
          3847,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 954.76,
        "id": 216,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 953.76,
        "temperature": 0,
        "text": " You have joined just now.",
        "tokens": [
          51264,
          509,
          362,
          6869,
          445,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 956.76,
        "id": 217,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 954.76,
        "temperature": 0,
        "text": " You might have joined not even being in the chat.",
        "tokens": [
          51314,
          509,
          1062,
          362,
          6869,
          406,
          754,
          885,
          294,
          264,
          5081,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17786903704627086,
        "compression_ratio": 1.683127572016461,
        "end": 960.76,
        "id": 218,
        "no_speech_prob": 0.191886767745018,
        "seek": 93576,
        "start": 956.76,
        "temperature": 0,
        "text": " Because I get a message whether or not you're watching in the chat or not and when you join.",
        "tokens": [
          51414,
          1436,
          286,
          483,
          257,
          3636,
          1968,
          420,
          406,
          291,
          434,
          1976,
          294,
          264,
          5081,
          420,
          406,
          293,
          562,
          291,
          3917,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 965.76,
        "id": 219,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 960.76,
        "temperature": 0,
        "text": " And for your joining of the coding train, I will show you this train whistle.",
        "tokens": [
          50364,
          400,
          337,
          428,
          5549,
          295,
          264,
          17720,
          3847,
          11,
          286,
          486,
          855,
          291,
          341,
          3847,
          23470,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 967.76,
        "id": 220,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 965.76,
        "temperature": 0,
        "text": " And I will ring this bell.",
        "tokens": [
          50614,
          400,
          286,
          486,
          4875,
          341,
          4549,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 970.76,
        "id": 221,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 967.76,
        "temperature": 0,
        "text": " I will also go and find my book of random numbers.",
        "tokens": [
          50714,
          286,
          486,
          611,
          352,
          293,
          915,
          452,
          1446,
          295,
          4974,
          3547,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 978.76,
        "id": 222,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 970.76,
        "temperature": 0,
        "text": " Because you will have for yourself a random number.",
        "tokens": [
          50864,
          1436,
          291,
          486,
          362,
          337,
          1803,
          257,
          4974,
          1230,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 980.76,
        "id": 223,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 978.76,
        "temperature": 0,
        "text": " Oh, dear.",
        "tokens": [
          51264,
          876,
          11,
          6875,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 981.76,
        "id": 224,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 980.76,
        "temperature": 0,
        "text": " Over there? No.",
        "tokens": [
          51364,
          4886,
          456,
          30,
          883,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 982.76,
        "id": 225,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 981.76,
        "temperature": 0,
        "text": " Over here.",
        "tokens": [
          51414,
          4886,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 986.76,
        "id": 226,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 985.76,
        "temperature": 0,
        "text": " This green screen.",
        "tokens": [
          51614,
          639,
          3092,
          2568,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 987.76,
        "id": 227,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 986.76,
        "temperature": 0,
        "text": " What's behind?",
        "tokens": [
          51664,
          708,
          311,
          2261,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.19818890479303175,
        "compression_ratio": 1.5815217391304348,
        "end": 989.76,
        "id": 228,
        "no_speech_prob": 0.4377172589302063,
        "seek": 96076,
        "start": 987.76,
        "temperature": 0,
        "text": " It's a wall.",
        "tokens": [
          51714,
          467,
          311,
          257,
          2929,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 991.76,
        "id": 229,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 989.76,
        "temperature": 0,
        "text": " Well, eh.",
        "tokens": [
          50364,
          1042,
          11,
          7670,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 992.76,
        "id": 230,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 991.76,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50464,
          961,
          311,
          536,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 993.76,
        "id": 231,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 992.76,
        "temperature": 0,
        "text": " Maybe I will...",
        "tokens": [
          50514,
          2704,
          286,
          486,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 995.76,
        "id": 232,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 993.76,
        "temperature": 0,
        "text": " There's so many different ways I could fix this.",
        "tokens": [
          50564,
          821,
          311,
          370,
          867,
          819,
          2098,
          286,
          727,
          3191,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 997.76,
        "id": 233,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 995.76,
        "temperature": 0,
        "text": " But I'm going to do it this way right now.",
        "tokens": [
          50664,
          583,
          286,
          478,
          516,
          281,
          360,
          309,
          341,
          636,
          558,
          586,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1000.76,
        "id": 234,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 999.76,
        "temperature": 0,
        "text": " Let's see how that does.",
        "tokens": [
          50864,
          961,
          311,
          536,
          577,
          300,
          775,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1007.76,
        "id": 235,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1006.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1008.76,
        "id": 236,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1007.76,
        "temperature": 0,
        "text": " I'm not going to worry about it too much.",
        "tokens": [
          51264,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          309,
          886,
          709,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1009.76,
        "id": 237,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1008.76,
        "temperature": 0,
        "text": " You can see me.",
        "tokens": [
          51314,
          509,
          393,
          536,
          385,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1010.76,
        "id": 238,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1009.76,
        "temperature": 0,
        "text": " You can hear me.",
        "tokens": [
          51364,
          509,
          393,
          1568,
          385,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1012.76,
        "id": 239,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1010.76,
        "temperature": 0,
        "text": " Let's find Louise.",
        "tokens": [
          51414,
          961,
          311,
          915,
          35962,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1013.76,
        "id": 240,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1012.76,
        "temperature": 0,
        "text": " And there's a random number.",
        "tokens": [
          51514,
          400,
          456,
          311,
          257,
          4974,
          1230,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1014.76,
        "id": 241,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1013.76,
        "temperature": 0,
        "text": " And here it is.",
        "tokens": [
          51564,
          400,
          510,
          309,
          307,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21946653269105038,
        "compression_ratio": 1.5406698564593302,
        "end": 1017.76,
        "id": 242,
        "no_speech_prob": 0.008710508234798908,
        "seek": 98976,
        "start": 1016.76,
        "temperature": 0,
        "text": " Two snaps and a circle.",
        "tokens": [
          51714,
          4453,
          19206,
          293,
          257,
          6329,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2600436680753466,
        "compression_ratio": 1.4624277456647399,
        "end": 1022.76,
        "id": 243,
        "no_speech_prob": 0.011506977491080761,
        "seek": 101776,
        "start": 1017.76,
        "temperature": 0,
        "text": " And we are at 47,081.",
        "tokens": [
          50364,
          400,
          321,
          366,
          412,
          16953,
          11,
          16133,
          16,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2600436680753466,
        "compression_ratio": 1.4624277456647399,
        "end": 1029.76,
        "id": 244,
        "no_speech_prob": 0.011506977491080761,
        "seek": 101776,
        "start": 1022.76,
        "temperature": 0,
        "text": " That is from row 6,370 and column 6.",
        "tokens": [
          50614,
          663,
          307,
          490,
          5386,
          1386,
          11,
          18,
          5867,
          293,
          7738,
          1386,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2600436680753466,
        "compression_ratio": 1.4624277456647399,
        "end": 1037.76,
        "id": 245,
        "no_speech_prob": 0.011506977491080761,
        "seek": 101776,
        "start": 1029.76,
        "temperature": 0,
        "text": " So I hope somebody, the coding train secretary who's recording this, in the coding train book of numbers,",
        "tokens": [
          50964,
          407,
          286,
          1454,
          2618,
          11,
          264,
          17720,
          3847,
          15691,
          567,
          311,
          6613,
          341,
          11,
          294,
          264,
          17720,
          3847,
          1446,
          295,
          3547,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2600436680753466,
        "compression_ratio": 1.4624277456647399,
        "end": 1043.76,
        "id": 246,
        "no_speech_prob": 0.011506977491080761,
        "seek": 101776,
        "start": 1037.76,
        "temperature": 0,
        "text": " members and their random numbers, will be saved for all of history and time forevermore.",
        "tokens": [
          51364,
          2679,
          293,
          641,
          4974,
          3547,
          11,
          486,
          312,
          6624,
          337,
          439,
          295,
          2503,
          293,
          565,
          5680,
          3138,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20085883722072695,
        "compression_ratio": 1.5668449197860963,
        "end": 1051.76,
        "id": 247,
        "no_speech_prob": 0.0034833569079637527,
        "seek": 104376,
        "start": 1044.76,
        "temperature": 0,
        "text": " Now that we've gotten that out of the way, let's set the tone for today.",
        "tokens": [
          50414,
          823,
          300,
          321,
          600,
          5768,
          300,
          484,
          295,
          264,
          636,
          11,
          718,
          311,
          992,
          264,
          8027,
          337,
          965,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20085883722072695,
        "compression_ratio": 1.5668449197860963,
        "end": 1054.76,
        "id": 248,
        "no_speech_prob": 0.0034833569079637527,
        "seek": 104376,
        "start": 1051.76,
        "temperature": 0,
        "text": " And let's read from our book of random numbers.",
        "tokens": [
          50764,
          400,
          718,
          311,
          1401,
          490,
          527,
          1446,
          295,
          4974,
          3547,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20085883722072695,
        "compression_ratio": 1.5668449197860963,
        "end": 1060.76,
        "id": 249,
        "no_speech_prob": 0.0034833569079637527,
        "seek": 104376,
        "start": 1054.76,
        "temperature": 0,
        "text": " Ah, I need to figure out where I last left off.",
        "tokens": [
          50914,
          2438,
          11,
          286,
          643,
          281,
          2573,
          484,
          689,
          286,
          1036,
          1411,
          766,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20085883722072695,
        "compression_ratio": 1.5668449197860963,
        "end": 1065.76,
        "id": 250,
        "no_speech_prob": 0.0034833569079637527,
        "seek": 104376,
        "start": 1060.76,
        "temperature": 0,
        "text": " And the way that I do that is by not showing you my screen for a second",
        "tokens": [
          51214,
          400,
          264,
          636,
          300,
          286,
          360,
          300,
          307,
          538,
          406,
          4099,
          291,
          452,
          2568,
          337,
          257,
          1150,
          51464
        ]
      },
      {
        "avg_logprob": -0.20085883722072695,
        "compression_ratio": 1.5668449197860963,
        "end": 1068.76,
        "id": 251,
        "no_speech_prob": 0.0034833569079637527,
        "seek": 104376,
        "start": 1065.76,
        "temperature": 0,
        "text": " and finding my way over to the coding train discord.",
        "tokens": [
          51464,
          293,
          5006,
          452,
          636,
          670,
          281,
          264,
          17720,
          3847,
          32989,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1079.76,
        "id": 252,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1074.76,
        "temperature": 0,
        "text": " Do, do.",
        "tokens": [
          50414,
          1144,
          11,
          360,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1080.76,
        "id": 253,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1079.76,
        "temperature": 0,
        "text": " Okay, wait, wait, wait.",
        "tokens": [
          50664,
          1033,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1084.76,
        "id": 254,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1080.76,
        "temperature": 0,
        "text": " I just got, I got just swept away in the music for a moment.",
        "tokens": [
          50714,
          286,
          445,
          658,
          11,
          286,
          658,
          445,
          31791,
          1314,
          294,
          264,
          1318,
          337,
          257,
          1623,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1087.76,
        "id": 255,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1084.76,
        "temperature": 0,
        "text": " Looking for coding train.",
        "tokens": [
          50914,
          11053,
          337,
          17720,
          3847,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1090.76,
        "id": 256,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1087.76,
        "temperature": 0,
        "text": " Live links, live links.",
        "tokens": [
          51064,
          10385,
          6123,
          11,
          1621,
          6123,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1093.76,
        "id": 257,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1090.76,
        "temperature": 0,
        "text": " Command option I.",
        "tokens": [
          51214,
          17901,
          3614,
          286,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1096.76,
        "id": 258,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1095.76,
        "temperature": 0,
        "text": " Documented again.",
        "tokens": [
          51464,
          37684,
          292,
          797,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1097.76,
        "id": 259,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1096.76,
        "temperature": 0,
        "text": " I'm going to type in a name.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          2010,
          294,
          257,
          1315,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1098.76,
        "id": 260,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1097.76,
        "temperature": 0,
        "text": " Index zero.",
        "tokens": [
          51564,
          33552,
          4018,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1100.76,
        "id": 261,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1098.76,
        "temperature": 0,
        "text": " Style of visibility was hidden.",
        "tokens": [
          51614,
          27004,
          295,
          19883,
          390,
          7633,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.4435376813334803,
        "compression_ratio": 1.4619565217391304,
        "end": 1102.76,
        "id": 262,
        "no_speech_prob": 0.07919927686452866,
        "seek": 107376,
        "start": 1100.76,
        "temperature": 0,
        "text": " Option command I.",
        "tokens": [
          51714,
          29284,
          5622,
          286,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1105.76,
        "id": 263,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1102.76,
        "temperature": 0,
        "text": " And now we're back.",
        "tokens": [
          50364,
          400,
          586,
          321,
          434,
          646,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1106.76,
        "id": 264,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1105.76,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50514,
          400,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1112.76,
        "id": 265,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1108.76,
        "temperature": 0,
        "text": " The next random number where I last left off.",
        "tokens": [
          50664,
          440,
          958,
          4974,
          1230,
          689,
          286,
          1036,
          1411,
          766,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1114.76,
        "id": 266,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1112.76,
        "temperature": 0,
        "text": " Row 14.",
        "tokens": [
          50864,
          20309,
          3499,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1117.76,
        "id": 267,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1115.76,
        "temperature": 0,
        "text": " Column 2.",
        "tokens": [
          51014,
          4004,
          16449,
          568,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1120.76,
        "id": 268,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1117.76,
        "temperature": 0,
        "text": " I'm still on page 1.",
        "tokens": [
          51114,
          286,
          478,
          920,
          322,
          3028,
          502,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1123.76,
        "id": 269,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1121.76,
        "temperature": 0,
        "text": " I mean, it's kind of amazing.",
        "tokens": [
          51314,
          286,
          914,
          11,
          309,
          311,
          733,
          295,
          2243,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23431813439657523,
        "compression_ratio": 1.3829787234042554,
        "end": 1129.76,
        "id": 270,
        "no_speech_prob": 0.0021156533621251583,
        "seek": 110276,
        "start": 1123.76,
        "temperature": 0,
        "text": " Like, I wish I had thought of this 8 years ago or whenever I started, 10 years ago, whenever I started recording videos.",
        "tokens": [
          51414,
          1743,
          11,
          286,
          3172,
          286,
          632,
          1194,
          295,
          341,
          1649,
          924,
          2057,
          420,
          5699,
          286,
          1409,
          11,
          1266,
          924,
          2057,
          11,
          5699,
          286,
          1409,
          6613,
          2145,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1130.76,
        "id": 271,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1129.76,
        "temperature": 0,
        "text": " When was my first live stream?",
        "tokens": [
          50364,
          1133,
          390,
          452,
          700,
          1621,
          4309,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1131.76,
        "id": 272,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1130.76,
        "temperature": 0,
        "text": " It's there on YouTube.",
        "tokens": [
          50414,
          467,
          311,
          456,
          322,
          3088,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1133.76,
        "id": 273,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1131.76,
        "temperature": 0,
        "text": " It's from many years ago.",
        "tokens": [
          50464,
          467,
          311,
          490,
          867,
          924,
          2057,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1136.76,
        "id": 274,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1133.76,
        "temperature": 0,
        "text": " I think that was more like 2015 if I'm correct.",
        "tokens": [
          50564,
          286,
          519,
          300,
          390,
          544,
          411,
          7546,
          498,
          286,
          478,
          3006,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1141.76,
        "id": 275,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1136.76,
        "temperature": 0,
        "text": " Some of the video tutorials were recorded in like 2011, 2012.",
        "tokens": [
          50714,
          2188,
          295,
          264,
          960,
          17616,
          645,
          8287,
          294,
          411,
          10154,
          11,
          9125,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1144.76,
        "id": 276,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1141.76,
        "temperature": 0,
        "text": " But I'm on row index 14.",
        "tokens": [
          50964,
          583,
          286,
          478,
          322,
          5386,
          8186,
          3499,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1146.76,
        "id": 277,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1144.76,
        "temperature": 0,
        "text": " Column 012.",
        "tokens": [
          51114,
          4004,
          16449,
          1958,
          4762,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1149.76,
        "id": 278,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1146.76,
        "temperature": 0,
        "text": " 87,517.",
        "tokens": [
          51214,
          27990,
          11,
          20,
          7773,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1152.76,
        "id": 279,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1149.76,
        "temperature": 0,
        "text": " 64,969.",
        "tokens": [
          51364,
          12145,
          11,
          22962,
          24,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20545357152035362,
        "compression_ratio": 1.3157894736842106,
        "end": 1156.76,
        "id": 280,
        "no_speech_prob": 0.013847210444509983,
        "seek": 112976,
        "start": 1153.76,
        "temperature": 0,
        "text": " 91,826.",
        "tokens": [
          51564,
          31064,
          11,
          23,
          10880,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1160.76,
        "id": 281,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1157.76,
        "temperature": 0,
        "text": " 8,928.",
        "tokens": [
          50414,
          1649,
          11,
          24,
          11205,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1163.76,
        "id": 282,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1160.76,
        "temperature": 0,
        "text": " There's an animal in the attic with me.",
        "tokens": [
          50564,
          821,
          311,
          364,
          5496,
          294,
          264,
          40766,
          365,
          385,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1164.76,
        "id": 283,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1163.76,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50714,
          286,
          500,
          380,
          458,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1166.76,
        "id": 284,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1164.76,
        "temperature": 0,
        "text": " It's either a cat or it's a dog.",
        "tokens": [
          50764,
          467,
          311,
          2139,
          257,
          3857,
          420,
          309,
          311,
          257,
          3000,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1168.76,
        "id": 285,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1166.76,
        "temperature": 0,
        "text": " Oh, it's a cat.",
        "tokens": [
          50864,
          876,
          11,
          309,
          311,
          257,
          3857,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1170.76,
        "id": 286,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1168.76,
        "temperature": 0,
        "text": " We'll see if the cat comes over.",
        "tokens": [
          50964,
          492,
          603,
          536,
          498,
          264,
          3857,
          1487,
          670,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1172.76,
        "id": 287,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1171.76,
        "temperature": 0,
        "text": " Kitty.",
        "tokens": [
          51114,
          36393,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1175.76,
        "id": 288,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1172.76,
        "temperature": 0,
        "text": " Would you like a random number, kitty?",
        "tokens": [
          51164,
          6068,
          291,
          411,
          257,
          4974,
          1230,
          11,
          33026,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1178.76,
        "id": 289,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1177.76,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51414,
          708,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1181.76,
        "id": 290,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1179.76,
        "temperature": 0,
        "text": " There are people watching this.",
        "tokens": [
          51514,
          821,
          366,
          561,
          1976,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1182.76,
        "id": 291,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1181.76,
        "temperature": 0,
        "text": " I kind of forgot that for a second.",
        "tokens": [
          51614,
          286,
          733,
          295,
          5298,
          300,
          337,
          257,
          1150,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16253010142933239,
        "compression_ratio": 1.4439024390243902,
        "end": 1184.76,
        "id": 292,
        "no_speech_prob": 0.006487807724624872,
        "seek": 115676,
        "start": 1182.76,
        "temperature": 0,
        "text": " I don't even remember where I am.",
        "tokens": [
          51664,
          286,
          500,
          380,
          754,
          1604,
          689,
          286,
          669,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1186.76,
        "id": 293,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1184.76,
        "temperature": 0,
        "text": " Does anyone remember the last random number I read?",
        "tokens": [
          50364,
          4402,
          2878,
          1604,
          264,
          1036,
          4974,
          1230,
          286,
          1401,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1187.76,
        "id": 294,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1186.76,
        "temperature": 0,
        "text": " Shoot.",
        "tokens": [
          50464,
          19760,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1188.76,
        "id": 295,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1187.76,
        "temperature": 0,
        "text": " Go back!",
        "tokens": [
          50514,
          1037,
          646,
          0,
          50564
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1197.76,
        "id": 296,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1191.76,
        "temperature": 0,
        "text": " Well, I was starting on row 14, column 2.",
        "tokens": [
          50714,
          1042,
          11,
          286,
          390,
          2891,
          322,
          5386,
          3499,
          11,
          7738,
          568,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1199.76,
        "id": 297,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1197.76,
        "temperature": 0,
        "text": " Oh my god.",
        "tokens": [
          51014,
          876,
          452,
          3044,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1201.76,
        "id": 298,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1200.76,
        "temperature": 0,
        "text": " This is a wash.",
        "tokens": [
          51164,
          639,
          307,
          257,
          5675,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1202.76,
        "id": 299,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1201.76,
        "temperature": 0,
        "text": " We're going to go back.",
        "tokens": [
          51214,
          492,
          434,
          516,
          281,
          352,
          646,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1203.76,
        "id": 300,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1202.76,
        "temperature": 0,
        "text": " We'll do this again.",
        "tokens": [
          51264,
          492,
          603,
          360,
          341,
          797,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1204.76,
        "id": 301,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1203.76,
        "temperature": 0,
        "text": " I'm just getting warmed up.",
        "tokens": [
          51314,
          286,
          478,
          445,
          1242,
          38201,
          493,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1205.76,
        "id": 302,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1204.76,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51364,
          2798,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1206.76,
        "id": 303,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1205.76,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51414,
          2798,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1207.76,
        "id": 304,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1206.76,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51464,
          2798,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1209.76,
        "id": 305,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1207.76,
        "temperature": 0,
        "text": " Somebody will tell me what random number was the last one I read.",
        "tokens": [
          51514,
          13463,
          486,
          980,
          385,
          437,
          4974,
          1230,
          390,
          264,
          1036,
          472,
          286,
          1401,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1211.76,
        "id": 306,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1209.76,
        "temperature": 0,
        "text": " I'll find it and then I'll post it.",
        "tokens": [
          51614,
          286,
          603,
          915,
          309,
          293,
          550,
          286,
          603,
          2183,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20184141492086743,
        "compression_ratio": 1.5836909871244635,
        "end": 1213.76,
        "id": 307,
        "no_speech_prob": 0.08880312740802765,
        "seek": 118476,
        "start": 1211.76,
        "temperature": 0,
        "text": " Everything's going to be okay.",
        "tokens": [
          51714,
          5471,
          311,
          516,
          281,
          312,
          1392,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1664867401123047,
        "compression_ratio": 1.7624521072796935,
        "end": 1214.76,
        "id": 308,
        "no_speech_prob": 0.0020507220178842545,
        "seek": 121376,
        "start": 1213.76,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50364,
          2798,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1664867401123047,
        "compression_ratio": 1.7624521072796935,
        "end": 1215.76,
        "id": 309,
        "no_speech_prob": 0.0020507220178842545,
        "seek": 121376,
        "start": 1214.76,
        "temperature": 0,
        "text": " What's happening today?",
        "tokens": [
          50414,
          708,
          311,
          2737,
          965,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.1664867401123047,
        "compression_ratio": 1.7624521072796935,
        "end": 1218.76,
        "id": 310,
        "no_speech_prob": 0.0020507220178842545,
        "seek": 121376,
        "start": 1215.76,
        "temperature": 0,
        "text": " I'm going to start doing some projects.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          722,
          884,
          512,
          4455,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1664867401123047,
        "compression_ratio": 1.7624521072796935,
        "end": 1225.76,
        "id": 311,
        "no_speech_prob": 0.0020507220178842545,
        "seek": 121376,
        "start": 1218.76,
        "temperature": 0,
        "text": " And actually, I'm going to do the same thing I did last week because I want to start training a machine learning model.",
        "tokens": [
          50614,
          400,
          767,
          11,
          286,
          478,
          516,
          281,
          360,
          264,
          912,
          551,
          286,
          630,
          1036,
          1243,
          570,
          286,
          528,
          281,
          722,
          3097,
          257,
          3479,
          2539,
          2316,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1664867401123047,
        "compression_ratio": 1.7624521072796935,
        "end": 1232.76,
        "id": 312,
        "no_speech_prob": 0.0020507220178842545,
        "seek": 121376,
        "start": 1225.76,
        "temperature": 0,
        "text": " And once I get that model cooking, I'm going to be baking it in my machine learning GPU oven.",
        "tokens": [
          50964,
          400,
          1564,
          286,
          483,
          300,
          2316,
          6361,
          11,
          286,
          478,
          516,
          281,
          312,
          12102,
          309,
          294,
          452,
          3479,
          2539,
          18407,
          9090,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1664867401123047,
        "compression_ratio": 1.7624521072796935,
        "end": 1236.76,
        "id": 313,
        "no_speech_prob": 0.0020507220178842545,
        "seek": 121376,
        "start": 1232.76,
        "temperature": 0,
        "text": " I'm going to take a break and look at some community contributions.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          747,
          257,
          1821,
          293,
          574,
          412,
          512,
          1768,
          15725,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1664867401123047,
        "compression_ratio": 1.7624521072796935,
        "end": 1240.76,
        "id": 314,
        "no_speech_prob": 0.0020507220178842545,
        "seek": 121376,
        "start": 1236.76,
        "temperature": 0,
        "text": " So things that you, the viewers of The Coding Train, have made and submitted on The Coding Train website.",
        "tokens": [
          51514,
          407,
          721,
          300,
          291,
          11,
          264,
          8499,
          295,
          440,
          383,
          8616,
          28029,
          11,
          362,
          1027,
          293,
          14405,
          322,
          440,
          383,
          8616,
          28029,
          3144,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21195274988810223,
        "compression_ratio": 1.7649402390438247,
        "end": 1244.76,
        "id": 315,
        "no_speech_prob": 0.0803510770201683,
        "seek": 124076,
        "start": 1240.76,
        "temperature": 0,
        "text": " Then I will come back and work on making a glitch.",
        "tokens": [
          50364,
          1396,
          286,
          486,
          808,
          646,
          293,
          589,
          322,
          1455,
          257,
          23552,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21195274988810223,
        "compression_ratio": 1.7649402390438247,
        "end": 1246.76,
        "id": 316,
        "no_speech_prob": 0.0803510770201683,
        "seek": 124076,
        "start": 1244.76,
        "temperature": 0,
        "text": " Well, it's not a glitch application.",
        "tokens": [
          50564,
          1042,
          11,
          309,
          311,
          406,
          257,
          23552,
          3861,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21195274988810223,
        "compression_ratio": 1.7649402390438247,
        "end": 1260.76,
        "id": 317,
        "no_speech_prob": 0.0803510770201683,
        "seek": 124076,
        "start": 1246.76,
        "temperature": 0,
        "text": " It is a web application hosted on Glitch to be able to communicate with that machine learning model when it's fully baked and crispy and delightful and very healthy.",
        "tokens": [
          50664,
          467,
          307,
          257,
          3670,
          3861,
          19204,
          322,
          5209,
          1549,
          281,
          312,
          1075,
          281,
          7890,
          365,
          300,
          3479,
          2539,
          2316,
          562,
          309,
          311,
          4498,
          19453,
          293,
          17509,
          293,
          35194,
          293,
          588,
          4627,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21195274988810223,
        "compression_ratio": 1.7649402390438247,
        "end": 1262.76,
        "id": 318,
        "no_speech_prob": 0.0803510770201683,
        "seek": 124076,
        "start": 1260.76,
        "temperature": 0,
        "text": " We're going to make a nice, healthy, low-fat.",
        "tokens": [
          51364,
          492,
          434,
          516,
          281,
          652,
          257,
          1481,
          11,
          4627,
          11,
          2295,
          12,
          35293,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21195274988810223,
        "compression_ratio": 1.7649402390438247,
        "end": 1263.76,
        "id": 319,
        "no_speech_prob": 0.0803510770201683,
        "seek": 124076,
        "start": 1262.76,
        "temperature": 0,
        "text": " That's not a thing anymore.",
        "tokens": [
          51464,
          663,
          311,
          406,
          257,
          551,
          3602,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21195274988810223,
        "compression_ratio": 1.7649402390438247,
        "end": 1266.76,
        "id": 320,
        "no_speech_prob": 0.0803510770201683,
        "seek": 124076,
        "start": 1263.76,
        "temperature": 0,
        "text": " I don't know what the low that you need is.",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          437,
          264,
          2295,
          300,
          291,
          643,
          307,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21195274988810223,
        "compression_ratio": 1.7649402390438247,
        "end": 1269.76,
        "id": 321,
        "no_speech_prob": 0.0803510770201683,
        "seek": 124076,
        "start": 1266.76,
        "temperature": 0,
        "text": " It's going to be a good, a very nice, very nice machine learning model.",
        "tokens": [
          51664,
          467,
          311,
          516,
          281,
          312,
          257,
          665,
          11,
          257,
          588,
          1481,
          11,
          588,
          1481,
          3479,
          2539,
          2316,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1273.76,
        "id": 322,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1270.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1281.76,
        "id": 323,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1273.76,
        "temperature": 0,
        "text": " So let's go to my friendly, my website from my friends over at runwayml.",
        "tokens": [
          50564,
          407,
          718,
          311,
          352,
          281,
          452,
          9208,
          11,
          452,
          3144,
          490,
          452,
          1855,
          670,
          412,
          26642,
          15480,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1284.76,
        "id": 324,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1281.76,
        "temperature": 0,
        "text": " Ah, there's something new.",
        "tokens": [
          50964,
          2438,
          11,
          456,
          311,
          746,
          777,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1287.76,
        "id": 325,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1284.76,
        "temperature": 0,
        "text": " Oh, I wasn't sure if this would show up.",
        "tokens": [
          51114,
          876,
          11,
          286,
          2067,
          380,
          988,
          498,
          341,
          576,
          855,
          493,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1290.76,
        "id": 326,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1287.76,
        "temperature": 0,
        "text": " I don't think I have anything special unlocked in my account.",
        "tokens": [
          51264,
          286,
          500,
          380,
          519,
          286,
          362,
          1340,
          2121,
          30180,
          294,
          452,
          2696,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1292.76,
        "id": 327,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1290.76,
        "temperature": 0,
        "text": " I cannot be distracted.",
        "tokens": [
          51414,
          286,
          2644,
          312,
          21658,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1293.76,
        "id": 328,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1292.76,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51514,
          6962,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2887004722248424,
        "compression_ratio": 1.4365482233502538,
        "end": 1296.76,
        "id": 329,
        "no_speech_prob": 0.08755332231521606,
        "seek": 126976,
        "start": 1293.76,
        "temperature": 0,
        "text": " I'm just opening up my Slack communiques.",
        "tokens": [
          51564,
          286,
          478,
          445,
          5193,
          493,
          452,
          37211,
          1199,
          4911,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1299.76,
        "id": 330,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1296.76,
        "temperature": 0,
        "text": " I just see if I have a Slack telegram.",
        "tokens": [
          50364,
          286,
          445,
          536,
          498,
          286,
          362,
          257,
          37211,
          4304,
          1342,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1300.76,
        "id": 331,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1299.76,
        "temperature": 0,
        "text": " No Slack telegram.",
        "tokens": [
          50514,
          883,
          37211,
          4304,
          1342,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1303.76,
        "id": 332,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1300.76,
        "temperature": 0,
        "text": " I was asking if this is something that is publicly available.",
        "tokens": [
          50564,
          286,
          390,
          3365,
          498,
          341,
          307,
          746,
          300,
          307,
          14843,
          2435,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1304.76,
        "id": 333,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1303.76,
        "temperature": 0,
        "text": " It says beta.",
        "tokens": [
          50714,
          467,
          1619,
          9861,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1305.76,
        "id": 334,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1304.76,
        "temperature": 0,
        "text": " I'm sure I could show it.",
        "tokens": [
          50764,
          286,
          478,
          988,
          286,
          727,
          855,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1306.76,
        "id": 335,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1305.76,
        "temperature": 0,
        "text": " It's on there.",
        "tokens": [
          50814,
          467,
          311,
          322,
          456,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1309.76,
        "id": 336,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1306.76,
        "temperature": 0,
        "text": " It's on their social media, but I'm not going to get distracted.",
        "tokens": [
          50864,
          467,
          311,
          322,
          641,
          2093,
          3021,
          11,
          457,
          286,
          478,
          406,
          516,
          281,
          483,
          21658,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1311.76,
        "id": 337,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1309.76,
        "temperature": 0,
        "text": " We're not doing the green screen right now.",
        "tokens": [
          51014,
          492,
          434,
          406,
          884,
          264,
          3092,
          2568,
          558,
          586,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1313.76,
        "id": 338,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1311.76,
        "temperature": 0,
        "text": " I'm going to come back to that.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1316.76,
        "id": 339,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1313.76,
        "temperature": 0,
        "text": " I am going to go to here, train.",
        "tokens": [
          51214,
          286,
          669,
          516,
          281,
          352,
          281,
          510,
          11,
          3847,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1319.76,
        "id": 340,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1316.76,
        "temperature": 0,
        "text": " And I want to do something that I have not done before.",
        "tokens": [
          51364,
          400,
          286,
          528,
          281,
          360,
          746,
          300,
          286,
          362,
          406,
          1096,
          949,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1320.76,
        "id": 341,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1319.76,
        "temperature": 0,
        "text": " Zoom on into it.",
        "tokens": [
          51514,
          13453,
          322,
          666,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23399425053096318,
        "compression_ratio": 1.7346153846153847,
        "end": 1323.76,
        "id": 342,
        "no_speech_prob": 0.03963711857795715,
        "seek": 129676,
        "start": 1320.76,
        "temperature": 0,
        "text": " Is train my own custom audio.",
        "tokens": [
          51564,
          1119,
          3847,
          452,
          1065,
          2375,
          6278,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.28566131591796873,
        "compression_ratio": 1.6733668341708543,
        "end": 1327.76,
        "id": 343,
        "no_speech_prob": 0.13295385241508484,
        "seek": 132376,
        "start": 1323.76,
        "temperature": 0,
        "text": " Is train my own custom object detection model.",
        "tokens": [
          50364,
          1119,
          3847,
          452,
          1065,
          2375,
          2657,
          17784,
          2316,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.28566131591796873,
        "compression_ratio": 1.6733668341708543,
        "end": 1335.76,
        "id": 344,
        "no_speech_prob": 0.13295385241508484,
        "seek": 132376,
        "start": 1327.76,
        "temperature": 0,
        "text": " Now, you might recall on here to with the Coding Train YouTube channel,",
        "tokens": [
          50564,
          823,
          11,
          291,
          1062,
          9901,
          322,
          510,
          281,
          365,
          264,
          383,
          8616,
          28029,
          3088,
          2269,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.28566131591796873,
        "compression_ratio": 1.6733668341708543,
        "end": 1339.76,
        "id": 345,
        "no_speech_prob": 0.13295385241508484,
        "seek": 132376,
        "start": 1335.76,
        "temperature": 0,
        "text": " Coding Train Object Detection,",
        "tokens": [
          50964,
          383,
          8616,
          28029,
          24753,
          4237,
          10183,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.28566131591796873,
        "compression_ratio": 1.6733668341708543,
        "end": 1343.76,
        "id": 346,
        "no_speech_prob": 0.13295385241508484,
        "seek": 132376,
        "start": 1339.76,
        "temperature": 0,
        "text": " that there is a video on said YouTube channel called ml5js,",
        "tokens": [
          51164,
          300,
          456,
          307,
          257,
          960,
          322,
          848,
          3088,
          2269,
          1219,
          23271,
          20,
          25530,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.28566131591796873,
        "compression_ratio": 1.6733668341708543,
        "end": 1345.76,
        "id": 347,
        "no_speech_prob": 0.13295385241508484,
        "seek": 132376,
        "start": 1343.76,
        "temperature": 0,
        "text": " object detection with CocoaSD.",
        "tokens": [
          51364,
          2657,
          17784,
          365,
          29787,
          64,
          23969,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.28566131591796873,
        "compression_ratio": 1.6733668341708543,
        "end": 1352.76,
        "id": 348,
        "no_speech_prob": 0.13295385241508484,
        "seek": 132376,
        "start": 1345.76,
        "temperature": 0,
        "text": " This is a pre-trained machine learning object detection model with 80 predefined categories.",
        "tokens": [
          51464,
          639,
          307,
          257,
          659,
          12,
          17227,
          2001,
          3479,
          2539,
          2657,
          17784,
          2316,
          365,
          4688,
          659,
          37716,
          10479,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1356.76,
        "id": 349,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1352.76,
        "temperature": 0,
        "text": " So a very limited amount of objects it's looking for and can detect",
        "tokens": [
          50364,
          407,
          257,
          588,
          5567,
          2372,
          295,
          6565,
          309,
          311,
          1237,
          337,
          293,
          393,
          5531,
          50564
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1358.76,
        "id": 350,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1356.76,
        "temperature": 0,
        "text": " and give you a bounding box.",
        "tokens": [
          50564,
          293,
          976,
          291,
          257,
          5472,
          278,
          2424,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1361.76,
        "id": 351,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1358.76,
        "temperature": 0,
        "text": " So you can watch that video, go through the code, shows you the example.",
        "tokens": [
          50664,
          407,
          291,
          393,
          1159,
          300,
          960,
          11,
          352,
          807,
          264,
          3089,
          11,
          3110,
          291,
          264,
          1365,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1367.76,
        "id": 352,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1361.76,
        "temperature": 0,
        "text": " What I was not able to demonstrate in that example is how to train your own object detection model.",
        "tokens": [
          50814,
          708,
          286,
          390,
          406,
          1075,
          281,
          11698,
          294,
          300,
          1365,
          307,
          577,
          281,
          3847,
          428,
          1065,
          2657,
          17784,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1371.76,
        "id": 353,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1367.76,
        "temperature": 0,
        "text": " And basically, you know, for example, I think what I'll do, I mean, I could do,",
        "tokens": [
          51114,
          400,
          1936,
          11,
          291,
          458,
          11,
          337,
          1365,
          11,
          286,
          519,
          437,
          286,
          603,
          360,
          11,
          286,
          914,
          11,
          286,
          727,
          360,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1372.76,
        "id": 354,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1371.76,
        "temperature": 0,
        "text": " oh, let's do the Rubik's Cube.",
        "tokens": [
          51314,
          1954,
          11,
          718,
          311,
          360,
          264,
          10518,
          1035,
          311,
          33003,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1378.76,
        "id": 355,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1372.76,
        "temperature": 0,
        "text": " I was going to do the train whistle, but I sort of feel like the Rubik's Cube might be,",
        "tokens": [
          51364,
          286,
          390,
          516,
          281,
          360,
          264,
          3847,
          23470,
          11,
          457,
          286,
          1333,
          295,
          841,
          411,
          264,
          10518,
          1035,
          311,
          33003,
          1062,
          312,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1380.76,
        "id": 356,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1378.76,
        "temperature": 0,
        "text": " by the way, I was having trouble, remember I was having trouble solving it?",
        "tokens": [
          51664,
          538,
          264,
          636,
          11,
          286,
          390,
          1419,
          5253,
          11,
          1604,
          286,
          390,
          1419,
          5253,
          12606,
          309,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.20496747478749017,
        "compression_ratio": 1.7841269841269842,
        "end": 1381.76,
        "id": 357,
        "no_speech_prob": 0.04813405126333237,
        "seek": 135276,
        "start": 1380.76,
        "temperature": 0,
        "text": " Okay, here it is.",
        "tokens": [
          51764,
          1033,
          11,
          510,
          309,
          307,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1386.76,
        "id": 358,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1381.76,
        "temperature": 0,
        "text": " The Rubik's Cube might be a kind of nicer, interesting thing to detect,",
        "tokens": [
          50364,
          440,
          10518,
          1035,
          311,
          33003,
          1062,
          312,
          257,
          733,
          295,
          22842,
          11,
          1880,
          551,
          281,
          5531,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1390.76,
        "id": 359,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1386.76,
        "temperature": 0,
        "text": " especially because I can, it's got so many different colors on different sides.",
        "tokens": [
          50614,
          2318,
          570,
          286,
          393,
          11,
          309,
          311,
          658,
          370,
          867,
          819,
          4577,
          322,
          819,
          4881,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1391.76,
        "id": 360,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1390.76,
        "temperature": 0,
        "text": " I wonder if I shuffled it.",
        "tokens": [
          50814,
          286,
          2441,
          498,
          286,
          402,
          33974,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1394.76,
        "id": 361,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1391.76,
        "temperature": 0,
        "text": " This is an interesting test case of object detection.",
        "tokens": [
          50864,
          639,
          307,
          364,
          1880,
          1500,
          1389,
          295,
          2657,
          17784,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1396.76,
        "id": 362,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1394.76,
        "temperature": 0,
        "text": " So let's use the Rubik's Cube.",
        "tokens": [
          51014,
          407,
          718,
          311,
          764,
          264,
          10518,
          1035,
          311,
          33003,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1398.76,
        "id": 363,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1396.76,
        "temperature": 0,
        "text": " Although really, I do love this mug.",
        "tokens": [
          51114,
          5780,
          534,
          11,
          286,
          360,
          959,
          341,
          23610,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1402.76,
        "id": 364,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1398.76,
        "temperature": 0,
        "text": " So, and I kind of want to make an object detection model that detects my mug.",
        "tokens": [
          51214,
          407,
          11,
          293,
          286,
          733,
          295,
          528,
          281,
          652,
          364,
          2657,
          17784,
          2316,
          300,
          5531,
          82,
          452,
          23610,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1404.76,
        "id": 365,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1402.76,
        "temperature": 0,
        "text": " I mean, there's nothing special.",
        "tokens": [
          51414,
          286,
          914,
          11,
          456,
          311,
          1825,
          2121,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1409.76,
        "id": 366,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1404.76,
        "temperature": 0,
        "text": " If only this mug were made in rainbow colors, it would be everything I'd ever hoped for",
        "tokens": [
          51514,
          759,
          787,
          341,
          23610,
          645,
          1027,
          294,
          18526,
          4577,
          11,
          309,
          576,
          312,
          1203,
          286,
          1116,
          1562,
          19737,
          337,
          51764
        ]
      },
      {
        "avg_logprob": -0.17778570358067342,
        "compression_ratio": 1.7707641196013288,
        "end": 1410.76,
        "id": 367,
        "no_speech_prob": 0.014956431463360786,
        "seek": 138176,
        "start": 1409.76,
        "temperature": 0,
        "text": " and wished for in my entire life.",
        "tokens": [
          51764,
          293,
          25811,
          337,
          294,
          452,
          2302,
          993,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1415.76,
        "id": 368,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1410.76,
        "temperature": 0,
        "text": " I am a simple but a simple man who lives, I don't live in the attic,",
        "tokens": [
          50364,
          286,
          669,
          257,
          2199,
          457,
          257,
          2199,
          587,
          567,
          2909,
          11,
          286,
          500,
          380,
          1621,
          294,
          264,
          40766,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1421.76,
        "id": 369,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1415.76,
        "temperature": 0,
        "text": " but I spend a lot of time in this attic talking to a camera.",
        "tokens": [
          50614,
          457,
          286,
          3496,
          257,
          688,
          295,
          565,
          294,
          341,
          40766,
          1417,
          281,
          257,
          2799,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1422.76,
        "id": 370,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1421.76,
        "temperature": 0,
        "text": " That's what I do.",
        "tokens": [
          50914,
          663,
          311,
          437,
          286,
          360,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1424.76,
        "id": 371,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1422.76,
        "temperature": 0,
        "text": " What's happened to me?",
        "tokens": [
          50964,
          708,
          311,
          2011,
          281,
          385,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1425.76,
        "id": 372,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1424.76,
        "temperature": 0,
        "text": " But I do love this mug.",
        "tokens": [
          51064,
          583,
          286,
          360,
          959,
          341,
          23610,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1426.76,
        "id": 373,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1425.76,
        "temperature": 0,
        "text": " It brings me great joy and happiness.",
        "tokens": [
          51114,
          467,
          5607,
          385,
          869,
          6258,
          293,
          8324,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1430.76,
        "id": 374,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1426.76,
        "temperature": 0,
        "text": " You should find something in your life that you can love,",
        "tokens": [
          51164,
          509,
          820,
          915,
          746,
          294,
          428,
          993,
          300,
          291,
          393,
          959,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.18561780218984567,
        "compression_ratio": 1.625,
        "end": 1434.76,
        "id": 375,
        "no_speech_prob": 0.07055425643920898,
        "seek": 141076,
        "start": 1430.76,
        "temperature": 0,
        "text": " and that loves you back like this mug loves me.",
        "tokens": [
          51364,
          293,
          300,
          6752,
          291,
          646,
          411,
          341,
          23610,
          6752,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23913664346212868,
        "compression_ratio": 1.536697247706422,
        "end": 1448.76,
        "id": 376,
        "no_speech_prob": 0.10086407512426376,
        "seek": 143476,
        "start": 1434.76,
        "temperature": 0,
        "text": " I understand why those like, you know, late night talk showy like things,",
        "tokens": [
          50364,
          286,
          1223,
          983,
          729,
          411,
          11,
          291,
          458,
          11,
          3469,
          1818,
          751,
          855,
          88,
          411,
          721,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.23913664346212868,
        "compression_ratio": 1.536697247706422,
        "end": 1454.76,
        "id": 377,
        "no_speech_prob": 0.10086407512426376,
        "seek": 143476,
        "start": 1448.76,
        "temperature": 0,
        "text": " they use a studio audience, because it's very weird to just be on my own.",
        "tokens": [
          51064,
          436,
          764,
          257,
          6811,
          4034,
          11,
          570,
          309,
          311,
          588,
          3657,
          281,
          445,
          312,
          322,
          452,
          1065,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23913664346212868,
        "compression_ratio": 1.536697247706422,
        "end": 1457.76,
        "id": 378,
        "no_speech_prob": 0.10086407512426376,
        "seek": 143476,
        "start": 1454.76,
        "temperature": 0,
        "text": " I should make my children sit over there and just watch me the entire time.",
        "tokens": [
          51364,
          286,
          820,
          652,
          452,
          2227,
          1394,
          670,
          456,
          293,
          445,
          1159,
          385,
          264,
          2302,
          565,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23913664346212868,
        "compression_ratio": 1.536697247706422,
        "end": 1459.76,
        "id": 379,
        "no_speech_prob": 0.10086407512426376,
        "seek": 143476,
        "start": 1457.76,
        "temperature": 0,
        "text": " That would basically torture them.",
        "tokens": [
          51514,
          663,
          576,
          1936,
          20711,
          552,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23913664346212868,
        "compression_ratio": 1.536697247706422,
        "end": 1460.76,
        "id": 380,
        "no_speech_prob": 0.10086407512426376,
        "seek": 143476,
        "start": 1459.76,
        "temperature": 0,
        "text": " What was I doing?",
        "tokens": [
          51614,
          708,
          390,
          286,
          884,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.23913664346212868,
        "compression_ratio": 1.536697247706422,
        "end": 1461.76,
        "id": 381,
        "no_speech_prob": 0.10086407512426376,
        "seek": 143476,
        "start": 1460.76,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51664,
          1779,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23913664346212868,
        "compression_ratio": 1.536697247706422,
        "end": 1462.76,
        "id": 382,
        "no_speech_prob": 0.10086407512426376,
        "seek": 143476,
        "start": 1461.76,
        "temperature": 0,
        "text": " So we're going to train the object detection model.",
        "tokens": [
          51714,
          407,
          321,
          434,
          516,
          281,
          3847,
          264,
          2657,
          17784,
          2316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.24135615162013732,
        "compression_ratio": 1.4793388429752066,
        "end": 1469.76,
        "id": 383,
        "no_speech_prob": 0.17551052570343018,
        "seek": 146276,
        "start": 1462.76,
        "temperature": 0,
        "text": " We're going to have it find the Rubik's Cube.",
        "tokens": [
          50364,
          492,
          434,
          516,
          281,
          362,
          309,
          915,
          264,
          10518,
          1035,
          311,
          33003,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24135615162013732,
        "compression_ratio": 1.4793388429752066,
        "end": 1470.76,
        "id": 384,
        "no_speech_prob": 0.17551052570343018,
        "seek": 146276,
        "start": 1469.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24135615162013732,
        "compression_ratio": 1.4793388429752066,
        "end": 1474.76,
        "id": 385,
        "no_speech_prob": 0.17551052570343018,
        "seek": 146276,
        "start": 1470.76,
        "temperature": 0,
        "text": " So the sort of key differences here, you know, I should say, so ml5.js, to be clear,",
        "tokens": [
          50764,
          407,
          264,
          1333,
          295,
          2141,
          7300,
          510,
          11,
          291,
          458,
          11,
          286,
          820,
          584,
          11,
          370,
          23271,
          20,
          13,
          25530,
          11,
          281,
          312,
          1850,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.24135615162013732,
        "compression_ratio": 1.4793388429752066,
        "end": 1480.76,
        "id": 386,
        "no_speech_prob": 0.17551052570343018,
        "seek": 146276,
        "start": 1474.76,
        "temperature": 0,
        "text": " is a JavaScript library from machine learning built on top of TensorFlow.js.",
        "tokens": [
          50964,
          307,
          257,
          15778,
          6405,
          490,
          3479,
          2539,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24135615162013732,
        "compression_ratio": 1.4793388429752066,
        "end": 1486.76,
        "id": 387,
        "no_speech_prob": 0.17551052570343018,
        "seek": 146276,
        "start": 1480.76,
        "temperature": 0,
        "text": " And Runway is a web application, a company that provides a service here,",
        "tokens": [
          51264,
          400,
          8950,
          676,
          307,
          257,
          3670,
          3861,
          11,
          257,
          2237,
          300,
          6417,
          257,
          2643,
          510,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.24135615162013732,
        "compression_ratio": 1.4793388429752066,
        "end": 1490.76,
        "id": 388,
        "no_speech_prob": 0.17551052570343018,
        "seek": 146276,
        "start": 1486.76,
        "temperature": 0,
        "text": " essentially, to operate different machine learning models in the cloud.",
        "tokens": [
          51564,
          4476,
          11,
          281,
          9651,
          819,
          3479,
          2539,
          5245,
          294,
          264,
          4588,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1491.76,
        "id": 389,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1490.76,
        "temperature": 0,
        "text": " It does cost money.",
        "tokens": [
          50364,
          467,
          775,
          2063,
          1460,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1493.76,
        "id": 390,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1491.76,
        "temperature": 0,
        "text": " You can sign up for it.",
        "tokens": [
          50414,
          509,
          393,
          1465,
          493,
          337,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1496.76,
        "id": 391,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1493.76,
        "temperature": 0,
        "text": " This is not a sponsored ad for Runway.",
        "tokens": [
          50514,
          639,
          307,
          406,
          257,
          16621,
          614,
          337,
          8950,
          676,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1500.76,
        "id": 392,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1496.76,
        "temperature": 0,
        "text": " I am the founders of Runway, are former students of mine at NYU,",
        "tokens": [
          50664,
          286,
          669,
          264,
          25608,
          295,
          8950,
          676,
          11,
          366,
          5819,
          1731,
          295,
          3892,
          412,
          42682,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1501.76,
        "id": 393,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1500.76,
        "temperature": 0,
        "text": " and I'm an advisor to the company.",
        "tokens": [
          50864,
          293,
          286,
          478,
          364,
          19161,
          281,
          264,
          2237,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1503.76,
        "id": 394,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1501.76,
        "temperature": 0,
        "text": " So in that sense, it kind of is an ad.",
        "tokens": [
          50914,
          407,
          294,
          300,
          2020,
          11,
          309,
          733,
          295,
          307,
          364,
          614,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1509.76,
        "id": 395,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1503.76,
        "temperature": 0,
        "text": " But I'm really just showing it to you out of my own enthusiasm and excitement to try using it.",
        "tokens": [
          51014,
          583,
          286,
          478,
          534,
          445,
          4099,
          309,
          281,
          291,
          484,
          295,
          452,
          1065,
          23417,
          293,
          14755,
          281,
          853,
          1228,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1512.76,
        "id": 396,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1509.76,
        "temperature": 0,
        "text": " So I'm going to go here to object detection.",
        "tokens": [
          51314,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          281,
          2657,
          17784,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1517.76,
        "id": 397,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1512.76,
        "temperature": 0,
        "text": " And actually, so before I can train the model, I need to collect my data set.",
        "tokens": [
          51464,
          400,
          767,
          11,
          370,
          949,
          286,
          393,
          3847,
          264,
          2316,
          11,
          286,
          643,
          281,
          2500,
          452,
          1412,
          992,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17386611412311423,
        "compression_ratio": 1.654109589041096,
        "end": 1519.76,
        "id": 398,
        "no_speech_prob": 0.11278443038463593,
        "seek": 149076,
        "start": 1517.76,
        "temperature": 0,
        "text": " So this is the way that I'm going to do it.",
        "tokens": [
          51714,
          407,
          341,
          307,
          264,
          636,
          300,
          286,
          478,
          516,
          281,
          360,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1525.76,
        "id": 399,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1519.76,
        "temperature": 0,
        "text": " This is the way.",
        "tokens": [
          50364,
          639,
          307,
          264,
          636,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1528.76,
        "id": 400,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1525.76,
        "temperature": 0,
        "text": " I'm going to go to new movie recording.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          352,
          281,
          777,
          3169,
          6613,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1531.76,
        "id": 401,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1528.76,
        "temperature": 0,
        "text": " And so there are a lot of different ways you can collect an image data set.",
        "tokens": [
          50814,
          400,
          370,
          456,
          366,
          257,
          688,
          295,
          819,
          2098,
          291,
          393,
          2500,
          364,
          3256,
          1412,
          992,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1534.76,
        "id": 402,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1531.76,
        "temperature": 0,
        "text": " You can see, by the way, a little behind the scenes here.",
        "tokens": [
          50964,
          509,
          393,
          536,
          11,
          538,
          264,
          636,
          11,
          257,
          707,
          2261,
          264,
          8026,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1536.76,
        "id": 403,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1534.76,
        "temperature": 0,
        "text": " Oh, I did get some.",
        "tokens": [
          51114,
          876,
          11,
          286,
          630,
          483,
          512,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1538.76,
        "id": 404,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1536.76,
        "temperature": 0,
        "text": " Here's the other upgrade I'm going to make.",
        "tokens": [
          51214,
          1692,
          311,
          264,
          661,
          11484,
          286,
          478,
          516,
          281,
          652,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1540.76,
        "id": 405,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1538.76,
        "temperature": 0,
        "text": " I have these, like, LED lights.",
        "tokens": [
          51314,
          286,
          362,
          613,
          11,
          411,
          11,
          11261,
          5811,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1543.76,
        "id": 406,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1540.76,
        "temperature": 0,
        "text": " Let me turn them on.",
        "tokens": [
          51414,
          961,
          385,
          1261,
          552,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17697866821289063,
        "compression_ratio": 1.5870445344129556,
        "end": 1547.76,
        "id": 407,
        "no_speech_prob": 0.03676803782582283,
        "seek": 151976,
        "start": 1543.76,
        "temperature": 0,
        "text": " So I'm going to – by the way, but, you know, this is why I make edited videos now,",
        "tokens": [
          51564,
          407,
          286,
          478,
          516,
          281,
          220,
          5815,
          538,
          264,
          636,
          11,
          457,
          11,
          291,
          458,
          11,
          341,
          307,
          983,
          286,
          652,
          23016,
          2145,
          586,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1550.76,
        "id": 408,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1547.76,
        "temperature": 0,
        "text": " people do enjoy the fact that I just get distracted and, like, can never get anywhere.",
        "tokens": [
          50364,
          561,
          360,
          2103,
          264,
          1186,
          300,
          286,
          445,
          483,
          21658,
          293,
          11,
          411,
          11,
          393,
          1128,
          483,
          4992,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1552.76,
        "id": 409,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1550.76,
        "temperature": 0,
        "text": " That's what the live stream is.",
        "tokens": [
          50514,
          663,
          311,
          437,
          264,
          1621,
          4309,
          307,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1556.76,
        "id": 410,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1552.76,
        "temperature": 0,
        "text": " But plenty of edited videos where I'm focused or at least I'm not focused.",
        "tokens": [
          50614,
          583,
          7140,
          295,
          23016,
          2145,
          689,
          286,
          478,
          5178,
          420,
          412,
          1935,
          286,
          478,
          406,
          5178,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1557.76,
        "id": 411,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1556.76,
        "temperature": 0,
        "text": " That part got edited out.",
        "tokens": [
          50814,
          663,
          644,
          658,
          23016,
          484,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1559.76,
        "id": 412,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1557.76,
        "temperature": 0,
        "text": " Are coming soon.",
        "tokens": [
          50864,
          2014,
          1348,
          2321,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1562.76,
        "id": 413,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1559.76,
        "temperature": 0,
        "text": " So let me go here and turn on these lights.",
        "tokens": [
          50964,
          407,
          718,
          385,
          352,
          510,
          293,
          1261,
          322,
          613,
          5811,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1564.76,
        "id": 414,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1562.76,
        "temperature": 0,
        "text": " So I just turned on those lights.",
        "tokens": [
          51114,
          407,
          286,
          445,
          3574,
          322,
          729,
          5811,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1568.76,
        "id": 415,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1564.76,
        "temperature": 0,
        "text": " Those will blink, by the way, if anybody signs up for a membership.",
        "tokens": [
          51214,
          3950,
          486,
          24667,
          11,
          538,
          264,
          636,
          11,
          498,
          4472,
          7880,
          493,
          337,
          257,
          16560,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1572.76,
        "id": 416,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1568.76,
        "temperature": 0,
        "text": " But the other upgrade I'll be making hopefully by next week is –",
        "tokens": [
          51414,
          583,
          264,
          661,
          11484,
          286,
          603,
          312,
          1455,
          4696,
          538,
          958,
          1243,
          307,
          1662,
          51614
        ]
      },
      {
        "avg_logprob": -0.20071111209150674,
        "compression_ratio": 1.631578947368421,
        "end": 1575.76,
        "id": 417,
        "no_speech_prob": 0.5116059184074402,
        "seek": 154776,
        "start": 1572.76,
        "temperature": 0,
        "text": " and I don't know what that did to my key here.",
        "tokens": [
          51614,
          293,
          286,
          500,
          380,
          458,
          437,
          300,
          630,
          281,
          452,
          2141,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1914807160695394,
        "compression_ratio": 1.608695652173913,
        "end": 1578.76,
        "id": 418,
        "no_speech_prob": 0.007815780118107796,
        "seek": 157576,
        "start": 1575.76,
        "temperature": 0,
        "text": " The idea I had, I thought this would help, like, make the key better.",
        "tokens": [
          50364,
          440,
          1558,
          286,
          632,
          11,
          286,
          1194,
          341,
          576,
          854,
          11,
          411,
          11,
          652,
          264,
          2141,
          1101,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1914807160695394,
        "compression_ratio": 1.608695652173913,
        "end": 1582.76,
        "id": 419,
        "no_speech_prob": 0.007815780118107796,
        "seek": 157576,
        "start": 1578.76,
        "temperature": 0,
        "text": " But I think it might actually be causing me some issues.",
        "tokens": [
          50514,
          583,
          286,
          519,
          309,
          1062,
          767,
          312,
          9853,
          385,
          512,
          2663,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1914807160695394,
        "compression_ratio": 1.608695652173913,
        "end": 1591.76,
        "id": 420,
        "no_speech_prob": 0.007815780118107796,
        "seek": 157576,
        "start": 1582.76,
        "temperature": 0,
        "text": " I bought white gaffer's tape so I can gaff tape the various cables and things for these LEDs with white gaffer's tape",
        "tokens": [
          50714,
          286,
          4243,
          2418,
          290,
          2518,
          260,
          311,
          7314,
          370,
          286,
          393,
          290,
          2518,
          7314,
          264,
          3683,
          17555,
          293,
          721,
          337,
          613,
          33366,
          365,
          2418,
          290,
          2518,
          260,
          311,
          7314,
          51164
        ]
      },
      {
        "avg_logprob": -0.1914807160695394,
        "compression_ratio": 1.608695652173913,
        "end": 1594.76,
        "id": 421,
        "no_speech_prob": 0.007815780118107796,
        "seek": 157576,
        "start": 1591.76,
        "temperature": 0,
        "text": " so it doesn't look as ugly as that black gaffer's tape.",
        "tokens": [
          51164,
          370,
          309,
          1177,
          380,
          574,
          382,
          12246,
          382,
          300,
          2211,
          290,
          2518,
          260,
          311,
          7314,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1914807160695394,
        "compression_ratio": 1.608695652173913,
        "end": 1598.76,
        "id": 422,
        "no_speech_prob": 0.007815780118107796,
        "seek": 157576,
        "start": 1594.76,
        "temperature": 0,
        "text": " So I am now going to hit record.",
        "tokens": [
          51314,
          407,
          286,
          669,
          586,
          516,
          281,
          2045,
          2136,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18703296266753097,
        "compression_ratio": 1.412621359223301,
        "end": 1604.76,
        "id": 423,
        "no_speech_prob": 0.013222224079072475,
        "seek": 159876,
        "start": 1598.76,
        "temperature": 0,
        "text": " And I'm going to just record a video of me with this Rubik's Cube.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          445,
          2136,
          257,
          960,
          295,
          385,
          365,
          341,
          10518,
          1035,
          311,
          33003,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18703296266753097,
        "compression_ratio": 1.412621359223301,
        "end": 1607.76,
        "id": 424,
        "no_speech_prob": 0.013222224079072475,
        "seek": 159876,
        "start": 1604.76,
        "temperature": 0,
        "text": " Kind of showing it and using it.",
        "tokens": [
          50664,
          9242,
          295,
          4099,
          309,
          293,
          1228,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18703296266753097,
        "compression_ratio": 1.412621359223301,
        "end": 1612.76,
        "id": 425,
        "no_speech_prob": 0.013222224079072475,
        "seek": 159876,
        "start": 1607.76,
        "temperature": 0,
        "text": " And I really don't want this to be more than, like, actually 20.",
        "tokens": [
          50814,
          400,
          286,
          534,
          500,
          380,
          528,
          341,
          281,
          312,
          544,
          813,
          11,
          411,
          11,
          767,
          945,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18703296266753097,
        "compression_ratio": 1.412621359223301,
        "end": 1617.76,
        "id": 426,
        "no_speech_prob": 0.013222224079072475,
        "seek": 159876,
        "start": 1612.76,
        "temperature": 0,
        "text": " I guess I can sample the frame rate however I want.",
        "tokens": [
          51064,
          286,
          2041,
          286,
          393,
          6889,
          264,
          3920,
          3314,
          4461,
          286,
          528,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18703296266753097,
        "compression_ratio": 1.412621359223301,
        "end": 1620.76,
        "id": 427,
        "no_speech_prob": 0.013222224079072475,
        "seek": 159876,
        "start": 1617.76,
        "temperature": 0,
        "text": " Let's try to get some different sizes.",
        "tokens": [
          51314,
          961,
          311,
          853,
          281,
          483,
          512,
          819,
          11602,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18703296266753097,
        "compression_ratio": 1.412621359223301,
        "end": 1626.76,
        "id": 428,
        "no_speech_prob": 0.013222224079072475,
        "seek": 159876,
        "start": 1623.76,
        "temperature": 0,
        "text": " Okay. Let's just go for 30 seconds.",
        "tokens": [
          51614,
          1033,
          13,
          961,
          311,
          445,
          352,
          337,
          2217,
          3949,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19678643170525045,
        "compression_ratio": 1.5112359550561798,
        "end": 1632.76,
        "id": 429,
        "no_speech_prob": 0.00010889397526625544,
        "seek": 162876,
        "start": 1629.76,
        "temperature": 0,
        "text": " Okay. Beautiful!",
        "tokens": [
          50414,
          1033,
          13,
          14724,
          0,
          50564
        ]
      },
      {
        "avg_logprob": -0.19678643170525045,
        "compression_ratio": 1.5112359550561798,
        "end": 1634.76,
        "id": 430,
        "no_speech_prob": 0.00010889397526625544,
        "seek": 162876,
        "start": 1632.76,
        "temperature": 0,
        "text": " I'm going to hit stop.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          2045,
          1590,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19678643170525045,
        "compression_ratio": 1.5112359550561798,
        "end": 1637.76,
        "id": 431,
        "no_speech_prob": 0.00010889397526625544,
        "seek": 162876,
        "start": 1634.76,
        "temperature": 0,
        "text": " Let us save this to the desktop.",
        "tokens": [
          50664,
          961,
          505,
          3155,
          341,
          281,
          264,
          14502,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19678643170525045,
        "compression_ratio": 1.5112359550561798,
        "end": 1641.76,
        "id": 432,
        "no_speech_prob": 0.00010889397526625544,
        "seek": 162876,
        "start": 1637.76,
        "temperature": 0,
        "text": " By the way, I was doing this already with some other tests.",
        "tokens": [
          50814,
          3146,
          264,
          636,
          11,
          286,
          390,
          884,
          341,
          1217,
          365,
          512,
          661,
          6921,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19678643170525045,
        "compression_ratio": 1.5112359550561798,
        "end": 1647.76,
        "id": 433,
        "no_speech_prob": 0.00010889397526625544,
        "seek": 162876,
        "start": 1641.76,
        "temperature": 0,
        "text": " And I'm going to just make – I might as well use this directory structure.",
        "tokens": [
          51014,
          400,
          286,
          478,
          516,
          281,
          445,
          652,
          1662,
          286,
          1062,
          382,
          731,
          764,
          341,
          21120,
          3877,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19678643170525045,
        "compression_ratio": 1.5112359550561798,
        "end": 1649.76,
        "id": 434,
        "no_speech_prob": 0.00010889397526625544,
        "seek": 162876,
        "start": 1647.76,
        "temperature": 0,
        "text": " I'm going to call this Rubik's.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          818,
          341,
          10518,
          1035,
          311,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19678643170525045,
        "compression_ratio": 1.5112359550561798,
        "end": 1654.76,
        "id": 435,
        "no_speech_prob": 0.00010889397526625544,
        "seek": 162876,
        "start": 1649.76,
        "temperature": 0,
        "text": " Let's save this as Rubik's.",
        "tokens": [
          51414,
          961,
          311,
          3155,
          341,
          382,
          10518,
          1035,
          311,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19673110820628978,
        "compression_ratio": 1.5336134453781514,
        "end": 1656.76,
        "id": 436,
        "no_speech_prob": 0.0013458456378430128,
        "seek": 165476,
        "start": 1654.76,
        "temperature": 0,
        "text": " Rubik's.",
        "tokens": [
          50364,
          10518,
          1035,
          311,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19673110820628978,
        "compression_ratio": 1.5336134453781514,
        "end": 1660.76,
        "id": 437,
        "no_speech_prob": 0.0013458456378430128,
        "seek": 165476,
        "start": 1658.76,
        "temperature": 0,
        "text": " That's all well and good.",
        "tokens": [
          50564,
          663,
          311,
          439,
          731,
          293,
          665,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19673110820628978,
        "compression_ratio": 1.5336134453781514,
        "end": 1665.76,
        "id": 438,
        "no_speech_prob": 0.0013458456378430128,
        "seek": 165476,
        "start": 1660.76,
        "temperature": 0,
        "text": " I actually – I don't know what I think I want to do just to have these be less –",
        "tokens": [
          50664,
          286,
          767,
          1662,
          286,
          500,
          380,
          458,
          437,
          286,
          519,
          286,
          528,
          281,
          360,
          445,
          281,
          362,
          613,
          312,
          1570,
          1662,
          50914
        ]
      },
      {
        "avg_logprob": -0.19673110820628978,
        "compression_ratio": 1.5336134453781514,
        "end": 1668.76,
        "id": 439,
        "no_speech_prob": 0.0013458456378430128,
        "seek": 165476,
        "start": 1665.76,
        "temperature": 0,
        "text": " I don't know if it really matters.",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          498,
          309,
          534,
          7001,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19673110820628978,
        "compression_ratio": 1.5336134453781514,
        "end": 1674.76,
        "id": 440,
        "no_speech_prob": 0.0013458456378430128,
        "seek": 165476,
        "start": 1668.76,
        "temperature": 0,
        "text": " But I think that I want – let's just at least export it as 720.",
        "tokens": [
          51064,
          583,
          286,
          519,
          300,
          286,
          528,
          1662,
          718,
          311,
          445,
          412,
          1935,
          10725,
          309,
          382,
          40881,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19673110820628978,
        "compression_ratio": 1.5336134453781514,
        "end": 1677.76,
        "id": 441,
        "no_speech_prob": 0.0013458456378430128,
        "seek": 165476,
        "start": 1674.76,
        "temperature": 0,
        "text": " Because I don't need super high resolution images for this.",
        "tokens": [
          51364,
          1436,
          286,
          500,
          380,
          643,
          1687,
          1090,
          8669,
          5267,
          337,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19673110820628978,
        "compression_ratio": 1.5336134453781514,
        "end": 1680.76,
        "id": 442,
        "no_speech_prob": 0.0013458456378430128,
        "seek": 165476,
        "start": 1677.76,
        "temperature": 0,
        "text": " I'm sort of afraid to go down to 480, although it would make total sense to do that.",
        "tokens": [
          51514,
          286,
          478,
          1333,
          295,
          4638,
          281,
          352,
          760,
          281,
          1017,
          4702,
          11,
          4878,
          309,
          576,
          652,
          3217,
          2020,
          281,
          360,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2004199192441743,
        "compression_ratio": 1.7707509881422925,
        "end": 1686.76,
        "id": 443,
        "no_speech_prob": 0.06371206790208817,
        "seek": 168076,
        "start": 1681.76,
        "temperature": 0,
        "text": " I have a feeling runway, once I upload my data set, is going to be resizing all these images to much lower resolution anyway.",
        "tokens": [
          50414,
          286,
          362,
          257,
          2633,
          26642,
          11,
          1564,
          286,
          6580,
          452,
          1412,
          992,
          11,
          307,
          516,
          281,
          312,
          725,
          3319,
          439,
          613,
          5267,
          281,
          709,
          3126,
          8669,
          4033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2004199192441743,
        "compression_ratio": 1.7707509881422925,
        "end": 1688.76,
        "id": 444,
        "no_speech_prob": 0.06371206790208817,
        "seek": 168076,
        "start": 1686.76,
        "temperature": 0,
        "text": " So that's fine.",
        "tokens": [
          50664,
          407,
          300,
          311,
          2489,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2004199192441743,
        "compression_ratio": 1.7707509881422925,
        "end": 1693.76,
        "id": 445,
        "no_speech_prob": 0.06371206790208817,
        "seek": 168076,
        "start": 1688.76,
        "temperature": 0,
        "text": " What I'm attempting to do again is collect a data set that I am going to have to hand label.",
        "tokens": [
          50764,
          708,
          286,
          478,
          22001,
          281,
          360,
          797,
          307,
          2500,
          257,
          1412,
          992,
          300,
          286,
          669,
          516,
          281,
          362,
          281,
          1011,
          7645,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2004199192441743,
        "compression_ratio": 1.7707509881422925,
        "end": 1699.76,
        "id": 446,
        "no_speech_prob": 0.06371206790208817,
        "seek": 168076,
        "start": 1693.76,
        "temperature": 0,
        "text": " So this is going to be one of the most exciting and riveting things I have ever done on the coding train.",
        "tokens": [
          51014,
          407,
          341,
          307,
          516,
          281,
          312,
          472,
          295,
          264,
          881,
          4670,
          293,
          28745,
          9880,
          721,
          286,
          362,
          1562,
          1096,
          322,
          264,
          17720,
          3847,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2004199192441743,
        "compression_ratio": 1.7707509881422925,
        "end": 1704.76,
        "id": 447,
        "no_speech_prob": 0.06371206790208817,
        "seek": 168076,
        "start": 1699.76,
        "temperature": 0,
        "text": " You're going to actually sit and watch me hand label a data set for machine learning.",
        "tokens": [
          51314,
          509,
          434,
          516,
          281,
          767,
          1394,
          293,
          1159,
          385,
          1011,
          7645,
          257,
          1412,
          992,
          337,
          3479,
          2539,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2004199192441743,
        "compression_ratio": 1.7707509881422925,
        "end": 1706.76,
        "id": 448,
        "no_speech_prob": 0.06371206790208817,
        "seek": 168076,
        "start": 1704.76,
        "temperature": 0,
        "text": " It's really exciting.",
        "tokens": [
          51564,
          467,
          311,
          534,
          4670,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21631964457403755,
        "compression_ratio": 1.584,
        "end": 1712.76,
        "id": 449,
        "no_speech_prob": 0.03621688857674599,
        "seek": 170676,
        "start": 1706.76,
        "temperature": 0,
        "text": " But – and I could have certainly used – sort of scraped the internet.",
        "tokens": [
          50364,
          583,
          1662,
          293,
          286,
          727,
          362,
          3297,
          1143,
          1662,
          1333,
          295,
          13943,
          3452,
          264,
          4705,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21631964457403755,
        "compression_ratio": 1.584,
        "end": 1718.76,
        "id": 450,
        "no_speech_prob": 0.03621688857674599,
        "seek": 170676,
        "start": 1712.76,
        "temperature": 0,
        "text": " Maybe looked – did a Google image search for Rubik's Cube and gathered a data set of images that way.",
        "tokens": [
          50664,
          2704,
          2956,
          1662,
          630,
          257,
          3329,
          3256,
          3164,
          337,
          10518,
          1035,
          311,
          33003,
          293,
          13032,
          257,
          1412,
          992,
          295,
          5267,
          300,
          636,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21631964457403755,
        "compression_ratio": 1.584,
        "end": 1725.76,
        "id": 451,
        "no_speech_prob": 0.03621688857674599,
        "seek": 170676,
        "start": 1718.76,
        "temperature": 0,
        "text": " I could have taken a lot of photos with my old-timey telephone camera and uploaded those.",
        "tokens": [
          50964,
          286,
          727,
          362,
          2726,
          257,
          688,
          295,
          5787,
          365,
          452,
          1331,
          12,
          3766,
          88,
          19800,
          2799,
          293,
          17135,
          729,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21631964457403755,
        "compression_ratio": 1.584,
        "end": 1734.76,
        "id": 452,
        "no_speech_prob": 0.03621688857674599,
        "seek": 170676,
        "start": 1725.76,
        "temperature": 0,
        "text": " But I actually find quite a useful way to collect a data set is to record a video and then extract all the frames of that video.",
        "tokens": [
          51314,
          583,
          286,
          767,
          915,
          1596,
          257,
          4420,
          636,
          281,
          2500,
          257,
          1412,
          992,
          307,
          281,
          2136,
          257,
          960,
          293,
          550,
          8947,
          439,
          264,
          12083,
          295,
          300,
          960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14180208841959635,
        "compression_ratio": 1.5267175572519085,
        "end": 1741.76,
        "id": 453,
        "no_speech_prob": 0.02556285820901394,
        "seek": 173476,
        "start": 1734.76,
        "temperature": 0,
        "text": " So the way I will do that is with FFmpeg.",
        "tokens": [
          50364,
          407,
          264,
          636,
          286,
          486,
          360,
          300,
          307,
          365,
          479,
          37,
          76,
          494,
          70,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14180208841959635,
        "compression_ratio": 1.5267175572519085,
        "end": 1744.76,
        "id": 454,
        "no_speech_prob": 0.02556285820901394,
        "seek": 173476,
        "start": 1741.76,
        "temperature": 0,
        "text": " And so I'm in my console here on my computer.",
        "tokens": [
          50714,
          400,
          370,
          286,
          478,
          294,
          452,
          11076,
          510,
          322,
          452,
          3820,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14180208841959635,
        "compression_ratio": 1.5267175572519085,
        "end": 1748.76,
        "id": 455,
        "no_speech_prob": 0.02556285820901394,
        "seek": 173476,
        "start": 1744.76,
        "temperature": 0,
        "text": " I type in FFmpeg and I see all these possible commands.",
        "tokens": [
          50864,
          286,
          2010,
          294,
          479,
          37,
          76,
          494,
          70,
          293,
          286,
          536,
          439,
          613,
          1944,
          16901,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14180208841959635,
        "compression_ratio": 1.5267175572519085,
        "end": 1752.76,
        "id": 456,
        "no_speech_prob": 0.02556285820901394,
        "seek": 173476,
        "start": 1748.76,
        "temperature": 0,
        "text": " So this won't happen automatically on your computer, whether you're on Windows or Linux or Mac.",
        "tokens": [
          51064,
          407,
          341,
          1582,
          380,
          1051,
          6772,
          322,
          428,
          3820,
          11,
          1968,
          291,
          434,
          322,
          8591,
          420,
          18734,
          420,
          5707,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14180208841959635,
        "compression_ratio": 1.5267175572519085,
        "end": 1759.76,
        "id": 457,
        "no_speech_prob": 0.02556285820901394,
        "seek": 173476,
        "start": 1752.76,
        "temperature": 0,
        "text": " You will need to make sure you go and find – I guess go to FFmpeg.org.",
        "tokens": [
          51264,
          509,
          486,
          643,
          281,
          652,
          988,
          291,
          352,
          293,
          915,
          1662,
          286,
          2041,
          352,
          281,
          479,
          37,
          76,
          494,
          70,
          13,
          4646,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.14180208841959635,
        "compression_ratio": 1.5267175572519085,
        "end": 1763.76,
        "id": 458,
        "no_speech_prob": 0.02556285820901394,
        "seek": 173476,
        "start": 1759.76,
        "temperature": 0,
        "text": " It's a complete cross-platform solution to record, convert, and stream audio and video.",
        "tokens": [
          51614,
          467,
          311,
          257,
          3566,
          3278,
          12,
          39975,
          837,
          3827,
          281,
          2136,
          11,
          7620,
          11,
          293,
          4309,
          6278,
          293,
          960,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19835616446830132,
        "compression_ratio": 1.5348837209302326,
        "end": 1768.76,
        "id": 459,
        "no_speech_prob": 0.019418515264987946,
        "seek": 176376,
        "start": 1763.76,
        "temperature": 0,
        "text": " It is a really excellently, incredibly useful tool.",
        "tokens": [
          50364,
          467,
          307,
          257,
          534,
          45817,
          2276,
          11,
          6252,
          4420,
          2290,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19835616446830132,
        "compression_ratio": 1.5348837209302326,
        "end": 1770.76,
        "id": 460,
        "no_speech_prob": 0.019418515264987946,
        "seek": 176376,
        "start": 1768.76,
        "temperature": 0,
        "text": " I use it frequently.",
        "tokens": [
          50614,
          286,
          764,
          309,
          10374,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19835616446830132,
        "compression_ratio": 1.5348837209302326,
        "end": 1776.76,
        "id": 461,
        "no_speech_prob": 0.019418515264987946,
        "seek": 176376,
        "start": 1770.76,
        "temperature": 0,
        "text": " And basically you can see here the kind of foundational example of what you do with it.",
        "tokens": [
          50714,
          400,
          1936,
          291,
          393,
          536,
          510,
          264,
          733,
          295,
          32195,
          1365,
          295,
          437,
          291,
          360,
          365,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19835616446830132,
        "compression_ratio": 1.5348837209302326,
        "end": 1784.76,
        "id": 462,
        "no_speech_prob": 0.019418515264987946,
        "seek": 176376,
        "start": 1776.76,
        "temperature": 0,
        "text": " You call the command via your console, FFmpeg –i, I believe, stands for the input video, input.mp4.",
        "tokens": [
          51014,
          509,
          818,
          264,
          5622,
          5766,
          428,
          11076,
          11,
          479,
          37,
          76,
          494,
          70,
          1662,
          72,
          11,
          286,
          1697,
          11,
          7382,
          337,
          264,
          4846,
          960,
          11,
          4846,
          13,
          2455,
          19,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19835616446830132,
        "compression_ratio": 1.5348837209302326,
        "end": 1787.76,
        "id": 463,
        "no_speech_prob": 0.019418515264987946,
        "seek": 176376,
        "start": 1784.76,
        "temperature": 0,
        "text": " And then the file name of what you want to convert it to.",
        "tokens": [
          51414,
          400,
          550,
          264,
          3991,
          1315,
          295,
          437,
          291,
          528,
          281,
          7620,
          309,
          281,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19835616446830132,
        "compression_ratio": 1.5348837209302326,
        "end": 1792.76,
        "id": 464,
        "no_speech_prob": 0.019418515264987946,
        "seek": 176376,
        "start": 1787.76,
        "temperature": 0,
        "text": " So this would be how to convert very quickly this MP4 video to an AVI file.",
        "tokens": [
          51564,
          407,
          341,
          576,
          312,
          577,
          281,
          7620,
          588,
          2661,
          341,
          14146,
          19,
          960,
          281,
          364,
          316,
          25322,
          3991,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17205664255086658,
        "compression_ratio": 1.4622222222222223,
        "end": 1796.76,
        "id": 465,
        "no_speech_prob": 0.002472552238032222,
        "seek": 179276,
        "start": 1792.76,
        "temperature": 0,
        "text": " But there is so much more you can do with FFmpeg in terms of extracting audio",
        "tokens": [
          50364,
          583,
          456,
          307,
          370,
          709,
          544,
          291,
          393,
          360,
          365,
          479,
          37,
          76,
          494,
          70,
          294,
          2115,
          295,
          49844,
          6278,
          50564
        ]
      },
      {
        "avg_logprob": -0.17205664255086658,
        "compression_ratio": 1.4622222222222223,
        "end": 1800.76,
        "id": 466,
        "no_speech_prob": 0.002472552238032222,
        "seek": 179276,
        "start": 1796.76,
        "temperature": 0,
        "text": " and automating so many kinds of video processes.",
        "tokens": [
          50564,
          293,
          3553,
          990,
          370,
          867,
          3685,
          295,
          960,
          7555,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17205664255086658,
        "compression_ratio": 1.4622222222222223,
        "end": 1807.76,
        "id": 467,
        "no_speech_prob": 0.002472552238032222,
        "seek": 179276,
        "start": 1800.76,
        "temperature": 0,
        "text": " So the one that I want to do is – and if I can – well, I need to go to the desktop.",
        "tokens": [
          50764,
          407,
          264,
          472,
          300,
          286,
          528,
          281,
          360,
          307,
          1662,
          293,
          498,
          286,
          393,
          1662,
          731,
          11,
          286,
          643,
          281,
          352,
          281,
          264,
          14502,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17205664255086658,
        "compression_ratio": 1.4622222222222223,
        "end": 1809.76,
        "id": 468,
        "no_speech_prob": 0.002472552238032222,
        "seek": 179276,
        "start": 1807.76,
        "temperature": 0,
        "text": " Under images maybe.",
        "tokens": [
          51114,
          6974,
          5267,
          1310,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17205664255086658,
        "compression_ratio": 1.4622222222222223,
        "end": 1812.76,
        "id": 469,
        "no_speech_prob": 0.002472552238032222,
        "seek": 179276,
        "start": 1809.76,
        "temperature": 0,
        "text": " I think this is where that directory was.",
        "tokens": [
          51214,
          286,
          519,
          341,
          307,
          689,
          300,
          21120,
          390,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17205664255086658,
        "compression_ratio": 1.4622222222222223,
        "end": 1816.76,
        "id": 470,
        "no_speech_prob": 0.002472552238032222,
        "seek": 179276,
        "start": 1812.76,
        "temperature": 0,
        "text": " FFmpeg. What was it called again? Rubix.",
        "tokens": [
          51364,
          479,
          37,
          76,
          494,
          70,
          13,
          708,
          390,
          309,
          1219,
          797,
          30,
          10518,
          970,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17205664255086658,
        "compression_ratio": 1.4622222222222223,
        "end": 1818.76,
        "id": 471,
        "no_speech_prob": 0.002472552238032222,
        "seek": 179276,
        "start": 1816.76,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51564,
          1692,
          321,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1438963438335218,
        "compression_ratio": 1.4540816326530612,
        "end": 1822.76,
        "id": 472,
        "no_speech_prob": 0.034617021679878235,
        "seek": 181876,
        "start": 1818.76,
        "temperature": 0,
        "text": " And I'm going to say FFmpeg –i rubix720.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          584,
          479,
          37,
          76,
          494,
          70,
          1662,
          72,
          5915,
          970,
          22,
          2009,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1438963438335218,
        "compression_ratio": 1.4540816326530612,
        "end": 1826.76,
        "id": 473,
        "no_speech_prob": 0.034617021679878235,
        "seek": 181876,
        "start": 1822.76,
        "temperature": 0,
        "text": " Does anybody happen to know?",
        "tokens": [
          50564,
          4402,
          4472,
          1051,
          281,
          458,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.1438963438335218,
        "compression_ratio": 1.4540816326530612,
        "end": 1830.76,
        "id": 474,
        "no_speech_prob": 0.034617021679878235,
        "seek": 181876,
        "start": 1826.76,
        "temperature": 0,
        "text": " And I really wish I could pin Marcos' message to the screen right now.",
        "tokens": [
          50764,
          400,
          286,
          534,
          3172,
          286,
          727,
          5447,
          2039,
          6877,
          6,
          3636,
          281,
          264,
          2568,
          558,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1438963438335218,
        "compression_ratio": 1.4540816326530612,
        "end": 1836.76,
        "id": 475,
        "no_speech_prob": 0.034617021679878235,
        "seek": 181876,
        "start": 1830.76,
        "temperature": 0,
        "text": " But does anybody happen to know the command from FFmpeg to extract it to frames?",
        "tokens": [
          50964,
          583,
          775,
          4472,
          1051,
          281,
          458,
          264,
          5622,
          490,
          479,
          37,
          76,
          494,
          70,
          281,
          8947,
          309,
          281,
          12083,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1438963438335218,
        "compression_ratio": 1.4540816326530612,
        "end": 1839.76,
        "id": 476,
        "no_speech_prob": 0.034617021679878235,
        "seek": 181876,
        "start": 1836.76,
        "temperature": 0,
        "text": " I want to say it's –vf.",
        "tokens": [
          51264,
          286,
          528,
          281,
          584,
          309,
          311,
          1662,
          85,
          69,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1438963438335218,
        "compression_ratio": 1.4540816326530612,
        "end": 1843.76,
        "id": 477,
        "no_speech_prob": 0.034617021679878235,
        "seek": 181876,
        "start": 1839.76,
        "temperature": 0,
        "text": " I don't know if that's really true.",
        "tokens": [
          51414,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          534,
          2074,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23505298907940203,
        "compression_ratio": 1.5296803652968036,
        "end": 1851.76,
        "id": 478,
        "no_speech_prob": 0.004538247361779213,
        "seek": 184376,
        "start": 1843.76,
        "temperature": 0,
        "text": " I know that I need to say fps equals – let's try just for a second one frame per second.",
        "tokens": [
          50364,
          286,
          458,
          300,
          286,
          643,
          281,
          584,
          44981,
          6915,
          1662,
          718,
          311,
          853,
          445,
          337,
          257,
          1150,
          472,
          3920,
          680,
          1150,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23505298907940203,
        "compression_ratio": 1.5296803652968036,
        "end": 1855.76,
        "id": 479,
        "no_speech_prob": 0.004538247361779213,
        "seek": 184376,
        "start": 1851.76,
        "temperature": 0,
        "text": " So I just want to get one image every second from the video.",
        "tokens": [
          50764,
          407,
          286,
          445,
          528,
          281,
          483,
          472,
          3256,
          633,
          1150,
          490,
          264,
          960,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23505298907940203,
        "compression_ratio": 1.5296803652968036,
        "end": 1863.76,
        "id": 480,
        "no_speech_prob": 0.004538247361779213,
        "seek": 184376,
        "start": 1855.76,
        "temperature": 0,
        "text": " And then I think I can just say like frames – what do you do to like number them?",
        "tokens": [
          50964,
          400,
          550,
          286,
          519,
          286,
          393,
          445,
          584,
          411,
          12083,
          1662,
          437,
          360,
          291,
          360,
          281,
          411,
          1230,
          552,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.23505298907940203,
        "compression_ratio": 1.5296803652968036,
        "end": 1869.76,
        "id": 481,
        "no_speech_prob": 0.004538247361779213,
        "seek": 184376,
        "start": 1863.76,
        "temperature": 0,
        "text": " Like if there's – this would be now the file name would be – I'm going to call it like rubix…",
        "tokens": [
          51364,
          1743,
          498,
          456,
          311,
          1662,
          341,
          576,
          312,
          586,
          264,
          3991,
          1315,
          576,
          312,
          1662,
          286,
          478,
          516,
          281,
          818,
          309,
          411,
          5915,
          970,
          1260,
          51664
        ]
      },
      {
        "avg_logprob": -0.22019425376516874,
        "compression_ratio": 1.5336134453781514,
        "end": 1873.76,
        "id": 482,
        "no_speech_prob": 0.11436284333467484,
        "seek": 186976,
        "start": 1870.76,
        "temperature": 0,
        "text": " ….png if I wanted them to be pngs.",
        "tokens": [
          50414,
          5799,
          13,
          79,
          872,
          498,
          286,
          1415,
          552,
          281,
          312,
          280,
          872,
          82,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22019425376516874,
        "compression_ratio": 1.5336134453781514,
        "end": 1877.76,
        "id": 483,
        "no_speech_prob": 0.11436284333467484,
        "seek": 186976,
        "start": 1873.76,
        "temperature": 0,
        "text": " Do I want them to be pngs or jpegs? I have no idea. Let's try this.",
        "tokens": [
          50564,
          1144,
          286,
          528,
          552,
          281,
          312,
          280,
          872,
          82,
          420,
          361,
          494,
          21559,
          30,
          286,
          362,
          572,
          1558,
          13,
          961,
          311,
          853,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22019425376516874,
        "compression_ratio": 1.5336134453781514,
        "end": 1883.76,
        "id": 484,
        "no_speech_prob": 0.11436284333467484,
        "seek": 186976,
        "start": 1877.76,
        "temperature": 0,
        "text": " Okay. So ah, that one seemed right, but I got could not open file – oh, because.",
        "tokens": [
          50764,
          1033,
          13,
          407,
          3716,
          11,
          300,
          472,
          6576,
          558,
          11,
          457,
          286,
          658,
          727,
          406,
          1269,
          3991,
          1662,
          1954,
          11,
          570,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22019425376516874,
        "compression_ratio": 1.5336134453781514,
        "end": 1887.76,
        "id": 485,
        "no_speech_prob": 0.11436284333467484,
        "seek": 186976,
        "start": 1883.76,
        "temperature": 0,
        "text": " I feel like FFmpeg should make that directory for me, but I don't think it will.",
        "tokens": [
          51064,
          286,
          841,
          411,
          479,
          37,
          76,
          494,
          70,
          820,
          652,
          300,
          21120,
          337,
          385,
          11,
          457,
          286,
          500,
          380,
          519,
          309,
          486,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22019425376516874,
        "compression_ratio": 1.5336134453781514,
        "end": 1890.76,
        "id": 486,
        "no_speech_prob": 0.11436284333467484,
        "seek": 186976,
        "start": 1887.76,
        "temperature": 0,
        "text": " So I made the frames directory.",
        "tokens": [
          51264,
          407,
          286,
          1027,
          264,
          12083,
          21120,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22019425376516874,
        "compression_ratio": 1.5336134453781514,
        "end": 1892.76,
        "id": 487,
        "no_speech_prob": 0.11436284333467484,
        "seek": 186976,
        "start": 1890.76,
        "temperature": 0,
        "text": " Let's try this again.",
        "tokens": [
          51414,
          961,
          311,
          853,
          341,
          797,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22019425376516874,
        "compression_ratio": 1.5336134453781514,
        "end": 1895.76,
        "id": 488,
        "no_speech_prob": 0.11436284333467484,
        "seek": 186976,
        "start": 1892.76,
        "temperature": 0,
        "text": " That was super fast. Did it actually work?",
        "tokens": [
          51514,
          663,
          390,
          1687,
          2370,
          13,
          2589,
          309,
          767,
          589,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2290360226350672,
        "compression_ratio": 1.3333333333333333,
        "end": 1898.76,
        "id": 489,
        "no_speech_prob": 0.0026316617149859667,
        "seek": 189576,
        "start": 1895.76,
        "temperature": 0,
        "text": " If I look in frames – there we go.",
        "tokens": [
          50364,
          759,
          286,
          574,
          294,
          12083,
          1662,
          456,
          321,
          352,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2290360226350672,
        "compression_ratio": 1.3333333333333333,
        "end": 1901.76,
        "id": 490,
        "no_speech_prob": 0.0026316617149859667,
        "seek": 189576,
        "start": 1898.76,
        "temperature": 0,
        "text": " So now I have frames of the video.",
        "tokens": [
          50514,
          407,
          586,
          286,
          362,
          12083,
          295,
          264,
          960,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2290360226350672,
        "compression_ratio": 1.3333333333333333,
        "end": 1905.76,
        "id": 491,
        "no_speech_prob": 0.0026316617149859667,
        "seek": 189576,
        "start": 1901.76,
        "temperature": 0,
        "text": " And this is probably not enough.",
        "tokens": [
          50664,
          400,
          341,
          307,
          1391,
          406,
          1547,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2290360226350672,
        "compression_ratio": 1.3333333333333333,
        "end": 1908.76,
        "id": 492,
        "no_speech_prob": 0.0026316617149859667,
        "seek": 189576,
        "start": 1905.76,
        "temperature": 0,
        "text": " This is like how many total?",
        "tokens": [
          50864,
          639,
          307,
          411,
          577,
          867,
          3217,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2290360226350672,
        "compression_ratio": 1.3333333333333333,
        "end": 1914.76,
        "id": 493,
        "no_speech_prob": 0.0026316617149859667,
        "seek": 189576,
        "start": 1908.76,
        "temperature": 0,
        "text": " 35. I think I should do – let's delete all these.",
        "tokens": [
          51014,
          6976,
          13,
          286,
          519,
          286,
          820,
          360,
          1662,
          718,
          311,
          12097,
          439,
          613,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2290360226350672,
        "compression_ratio": 1.3333333333333333,
        "end": 1921.76,
        "id": 494,
        "no_speech_prob": 0.0026316617149859667,
        "seek": 189576,
        "start": 1914.76,
        "temperature": 0,
        "text": " And let's say – hmm.",
        "tokens": [
          51314,
          400,
          718,
          311,
          584,
          1662,
          16478,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1925642830984933,
        "compression_ratio": 1.6816143497757847,
        "end": 1927.76,
        "id": 495,
        "no_speech_prob": 0.007232608739286661,
        "seek": 192176,
        "start": 1922.76,
        "temperature": 0,
        "text": " I mean how many of my – I think I could do – I think I could annotate 150 images right now.",
        "tokens": [
          50414,
          286,
          914,
          577,
          867,
          295,
          452,
          1662,
          286,
          519,
          286,
          727,
          360,
          1662,
          286,
          519,
          286,
          727,
          25339,
          473,
          8451,
          5267,
          558,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1925642830984933,
        "compression_ratio": 1.6816143497757847,
        "end": 1931.76,
        "id": 496,
        "no_speech_prob": 0.007232608739286661,
        "seek": 192176,
        "start": 1927.76,
        "temperature": 0,
        "text": " I think that's reasonable. I've got – I don't have my watch on.",
        "tokens": [
          50664,
          286,
          519,
          300,
          311,
          10585,
          13,
          286,
          600,
          658,
          1662,
          286,
          500,
          380,
          362,
          452,
          1159,
          322,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1925642830984933,
        "compression_ratio": 1.6816143497757847,
        "end": 1933.76,
        "id": 497,
        "no_speech_prob": 0.007232608739286661,
        "seek": 192176,
        "start": 1931.76,
        "temperature": 0,
        "text": " I've got like another hour here at least.",
        "tokens": [
          50864,
          286,
          600,
          658,
          411,
          1071,
          1773,
          510,
          412,
          1935,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1925642830984933,
        "compression_ratio": 1.6816143497757847,
        "end": 1935.76,
        "id": 498,
        "no_speech_prob": 0.007232608739286661,
        "seek": 192176,
        "start": 1933.76,
        "temperature": 0,
        "text": " So I think I could annotate 150 images.",
        "tokens": [
          50964,
          407,
          286,
          519,
          286,
          727,
          25339,
          473,
          8451,
          5267,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1925642830984933,
        "compression_ratio": 1.6816143497757847,
        "end": 1943.76,
        "id": 499,
        "no_speech_prob": 0.007232608739286661,
        "seek": 192176,
        "start": 1935.76,
        "temperature": 0,
        "text": " We'll play some music, some royalty free music.",
        "tokens": [
          51064,
          492,
          603,
          862,
          512,
          1318,
          11,
          512,
          40929,
          1737,
          1318,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1925642830984933,
        "compression_ratio": 1.6816143497757847,
        "end": 1949.76,
        "id": 500,
        "no_speech_prob": 0.007232608739286661,
        "seek": 192176,
        "start": 1943.76,
        "temperature": 0,
        "text": " By the way, I'm in the market for commissioned musical themes for the coding train.",
        "tokens": [
          51464,
          3146,
          264,
          636,
          11,
          286,
          478,
          294,
          264,
          2142,
          337,
          32372,
          9165,
          13544,
          337,
          264,
          17720,
          3847,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2180418650309245,
        "compression_ratio": 1.5454545454545454,
        "end": 1952.76,
        "id": 501,
        "no_speech_prob": 0.2336786836385727,
        "seek": 194976,
        "start": 1949.76,
        "temperature": 0,
        "text": " I'm already in touch with some people. I have some ideas.",
        "tokens": [
          50364,
          286,
          478,
          1217,
          294,
          2557,
          365,
          512,
          561,
          13,
          286,
          362,
          512,
          3487,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2180418650309245,
        "compression_ratio": 1.5454545454545454,
        "end": 1955.76,
        "id": 502,
        "no_speech_prob": 0.2336786836385727,
        "seek": 194976,
        "start": 1952.76,
        "temperature": 0,
        "text": " It's a very slow process because I started thinking about this probably over a year ago.",
        "tokens": [
          50514,
          467,
          311,
          257,
          588,
          2964,
          1399,
          570,
          286,
          1409,
          1953,
          466,
          341,
          1391,
          670,
          257,
          1064,
          2057,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2180418650309245,
        "compression_ratio": 1.5454545454545454,
        "end": 1959.76,
        "id": 503,
        "no_speech_prob": 0.2336786836385727,
        "seek": 194976,
        "start": 1955.76,
        "temperature": 0,
        "text": " But if you are a composer and a musician, join the Discord.",
        "tokens": [
          50664,
          583,
          498,
          291,
          366,
          257,
          26003,
          293,
          257,
          19570,
          11,
          3917,
          264,
          32623,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2180418650309245,
        "compression_ratio": 1.5454545454545454,
        "end": 1963.76,
        "id": 504,
        "no_speech_prob": 0.2336786836385727,
        "seek": 194976,
        "start": 1959.76,
        "temperature": 0,
        "text": " Please reach out. You know, you want to compose and record some music.",
        "tokens": [
          50864,
          2555,
          2524,
          484,
          13,
          509,
          458,
          11,
          291,
          528,
          281,
          35925,
          293,
          2136,
          512,
          1318,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2180418650309245,
        "compression_ratio": 1.5454545454545454,
        "end": 1966.76,
        "id": 505,
        "no_speech_prob": 0.2336786836385727,
        "seek": 194976,
        "start": 1963.76,
        "temperature": 0,
        "text": " I'm looking for contributions in that area.",
        "tokens": [
          51064,
          286,
          478,
          1237,
          337,
          15725,
          294,
          300,
          1859,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2180418650309245,
        "compression_ratio": 1.5454545454545454,
        "end": 1971.76,
        "id": 506,
        "no_speech_prob": 0.2336786836385727,
        "seek": 194976,
        "start": 1966.76,
        "temperature": 0,
        "text": " Okay. By the way, if there could ever be the coding train musical, I will just –",
        "tokens": [
          51214,
          1033,
          13,
          3146,
          264,
          636,
          11,
          498,
          456,
          727,
          1562,
          312,
          264,
          17720,
          3847,
          9165,
          11,
          286,
          486,
          445,
          1662,
          51464
        ]
      },
      {
        "avg_logprob": -0.2180418650309245,
        "compression_ratio": 1.5454545454545454,
        "end": 1975.76,
        "id": 507,
        "no_speech_prob": 0.2336786836385727,
        "seek": 194976,
        "start": 1971.76,
        "temperature": 0,
        "text": " What's the expression? I suppose die and go to heaven.",
        "tokens": [
          51464,
          708,
          311,
          264,
          6114,
          30,
          286,
          7297,
          978,
          293,
          352,
          281,
          7162,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 1979.76,
        "id": 508,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1976.76,
        "temperature": 0,
        "text": " That's not really how I think it works, scientifically speaking.",
        "tokens": [
          50414,
          663,
          311,
          406,
          534,
          577,
          286,
          519,
          309,
          1985,
          11,
          39719,
          4124,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 1982.76,
        "id": 509,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1979.76,
        "temperature": 0,
        "text": " But boy, that would make me very happy.",
        "tokens": [
          50564,
          583,
          3237,
          11,
          300,
          576,
          652,
          385,
          588,
          2055,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 1986.76,
        "id": 510,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1982.76,
        "temperature": 0,
        "text": " Okay. Let's do five frames per second.",
        "tokens": [
          50714,
          1033,
          13,
          961,
          311,
          360,
          1732,
          12083,
          680,
          1150,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 1989.76,
        "id": 511,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1986.76,
        "temperature": 0,
        "text": " That was 178 frames.",
        "tokens": [
          50914,
          663,
          390,
          3282,
          23,
          12083,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 1992.76,
        "id": 512,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1989.76,
        "temperature": 0,
        "text": " I'm going to go back to runway here.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          26642,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 1994.76,
        "id": 513,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1992.76,
        "temperature": 0,
        "text": " And I'm going to click object detection.",
        "tokens": [
          51214,
          400,
          286,
          478,
          516,
          281,
          2052,
          2657,
          17784,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 1997.76,
        "id": 514,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1994.76,
        "temperature": 0,
        "text": " Let's do Rubik's Cube.",
        "tokens": [
          51314,
          961,
          311,
          360,
          10518,
          1035,
          311,
          33003,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18183420181274415,
        "compression_ratio": 1.434782608695652,
        "end": 2001.76,
        "id": 515,
        "no_speech_prob": 0.1052035316824913,
        "seek": 197576,
        "start": 1997.76,
        "temperature": 0,
        "text": " And by the way, I probably – I should have done both of these.",
        "tokens": [
          51464,
          400,
          538,
          264,
          636,
          11,
          286,
          1391,
          1662,
          286,
          820,
          362,
          1096,
          1293,
          295,
          613,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18885334332784018,
        "compression_ratio": 1.6056338028169015,
        "end": 2008.76,
        "id": 516,
        "no_speech_prob": 0.0060035292990505695,
        "seek": 200176,
        "start": 2001.76,
        "temperature": 0,
        "text": " Because I can train an object detection model with more than one object in particular – in my dataset.",
        "tokens": [
          50364,
          1436,
          286,
          393,
          3847,
          364,
          2657,
          17784,
          2316,
          365,
          544,
          813,
          472,
          2657,
          294,
          1729,
          1662,
          294,
          452,
          28872,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18885334332784018,
        "compression_ratio": 1.6056338028169015,
        "end": 2011.76,
        "id": 517,
        "no_speech_prob": 0.0060035292990505695,
        "seek": 200176,
        "start": 2008.76,
        "temperature": 0,
        "text": " So I'm doing this in the simplest way possible.",
        "tokens": [
          50714,
          407,
          286,
          478,
          884,
          341,
          294,
          264,
          22811,
          636,
          1944,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18885334332784018,
        "compression_ratio": 1.6056338028169015,
        "end": 2014.76,
        "id": 518,
        "no_speech_prob": 0.0060035292990505695,
        "seek": 200176,
        "start": 2011.76,
        "temperature": 0,
        "text": " I'm going to create this now.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          1884,
          341,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18885334332784018,
        "compression_ratio": 1.6056338028169015,
        "end": 2020.76,
        "id": 519,
        "no_speech_prob": 0.0060035292990505695,
        "seek": 200176,
        "start": 2014.76,
        "temperature": 0,
        "text": " I'm going to upload – oh, which – oh, I'm logged in.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          6580,
          1662,
          1954,
          11,
          597,
          1662,
          1954,
          11,
          286,
          478,
          27231,
          294,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18885334332784018,
        "compression_ratio": 1.6056338028169015,
        "end": 2024.76,
        "id": 520,
        "no_speech_prob": 0.0060035292990505695,
        "seek": 200176,
        "start": 2020.76,
        "temperature": 0,
        "text": " It's fine. I meant to be logged into my other runway account.",
        "tokens": [
          51314,
          467,
          311,
          2489,
          13,
          286,
          4140,
          281,
          312,
          27231,
          666,
          452,
          661,
          26642,
          2696,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18885334332784018,
        "compression_ratio": 1.6056338028169015,
        "end": 2027.76,
        "id": 521,
        "no_speech_prob": 0.0060035292990505695,
        "seek": 200176,
        "start": 2024.76,
        "temperature": 0,
        "text": " It's all so confusing. But this is fine.",
        "tokens": [
          51514,
          467,
          311,
          439,
          370,
          13181,
          13,
          583,
          341,
          307,
          2489,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24007569188657013,
        "compression_ratio": 1.1727272727272726,
        "end": 2031.76,
        "id": 522,
        "no_speech_prob": 0.015904715284705162,
        "seek": 202776,
        "start": 2028.76,
        "temperature": 0,
        "text": " I will do that later.",
        "tokens": [
          50414,
          286,
          486,
          360,
          300,
          1780,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24007569188657013,
        "compression_ratio": 1.1727272727272726,
        "end": 2039.76,
        "id": 523,
        "no_speech_prob": 0.015904715284705162,
        "seek": 202776,
        "start": 2031.76,
        "temperature": 0,
        "text": " I'm going to go to desktop, images, FFmpeg, Rubik's frames, hit upload.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          352,
          281,
          14502,
          11,
          5267,
          11,
          479,
          37,
          76,
          494,
          70,
          11,
          10518,
          1035,
          311,
          12083,
          11,
          2045,
          6580,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24007569188657013,
        "compression_ratio": 1.1727272727272726,
        "end": 2045.76,
        "id": 524,
        "no_speech_prob": 0.015904715284705162,
        "seek": 202776,
        "start": 2042.76,
        "temperature": 0,
        "text": " And we'll wait for these to upload.",
        "tokens": [
          51114,
          400,
          321,
          603,
          1699,
          337,
          613,
          281,
          6580,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23064156067677033,
        "compression_ratio": 1.4248704663212435,
        "end": 2064.76,
        "id": 525,
        "no_speech_prob": 0.005554834380745888,
        "seek": 205776,
        "start": 2058.76,
        "temperature": 0,
        "text": " Can we do that thing in the edited videos where the time speeds up? That would be nice, right?",
        "tokens": [
          50414,
          1664,
          321,
          360,
          300,
          551,
          294,
          264,
          23016,
          2145,
          689,
          264,
          565,
          16411,
          493,
          30,
          663,
          576,
          312,
          1481,
          11,
          558,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.23064156067677033,
        "compression_ratio": 1.4248704663212435,
        "end": 2070.76,
        "id": 526,
        "no_speech_prob": 0.005554834380745888,
        "seek": 205776,
        "start": 2066.76,
        "temperature": 0,
        "text": " I guess I could log out – well, no, I'm already uploading it.",
        "tokens": [
          50814,
          286,
          2041,
          286,
          727,
          3565,
          484,
          1662,
          731,
          11,
          572,
          11,
          286,
          478,
          1217,
          27301,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23064156067677033,
        "compression_ratio": 1.4248704663212435,
        "end": 2073.76,
        "id": 527,
        "no_speech_prob": 0.005554834380745888,
        "seek": 205776,
        "start": 2070.76,
        "temperature": 0,
        "text": " I keep just messing this up.",
        "tokens": [
          51014,
          286,
          1066,
          445,
          23258,
          341,
          493,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23064156067677033,
        "compression_ratio": 1.4248704663212435,
        "end": 2080.76,
        "id": 528,
        "no_speech_prob": 0.005554834380745888,
        "seek": 205776,
        "start": 2073.76,
        "temperature": 0,
        "text": " You can see, by the way, oh, how difference – how – what a difference a year makes.",
        "tokens": [
          51164,
          509,
          393,
          536,
          11,
          538,
          264,
          636,
          11,
          1954,
          11,
          577,
          2649,
          1662,
          577,
          1662,
          437,
          257,
          2649,
          257,
          1064,
          1669,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16790951176693564,
        "compression_ratio": 1.5107296137339057,
        "end": 2087.76,
        "id": 529,
        "no_speech_prob": 0.00555482367053628,
        "seek": 208076,
        "start": 2080.76,
        "temperature": 0,
        "text": " This was a dataset that I uploaded a year ago in an attempt to work with Thanksgiving turkeys.",
        "tokens": [
          50364,
          639,
          390,
          257,
          28872,
          300,
          286,
          17135,
          257,
          1064,
          2057,
          294,
          364,
          5217,
          281,
          589,
          365,
          21230,
          3243,
          18847,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16790951176693564,
        "compression_ratio": 1.5107296137339057,
        "end": 2090.76,
        "id": 530,
        "no_speech_prob": 0.00555482367053628,
        "seek": 208076,
        "start": 2087.76,
        "temperature": 0,
        "text": " Okay, frames. Here we go.",
        "tokens": [
          50714,
          1033,
          11,
          12083,
          13,
          1692,
          321,
          352,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16790951176693564,
        "compression_ratio": 1.5107296137339057,
        "end": 2092.76,
        "id": 531,
        "no_speech_prob": 0.00555482367053628,
        "seek": 208076,
        "start": 2090.76,
        "temperature": 0,
        "text": " Click next.",
        "tokens": [
          50864,
          8230,
          958,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16790951176693564,
        "compression_ratio": 1.5107296137339057,
        "end": 2096.76,
        "id": 532,
        "no_speech_prob": 0.00555482367053628,
        "seek": 208076,
        "start": 2092.76,
        "temperature": 0,
        "text": " Now, what is the next step?",
        "tokens": [
          50964,
          823,
          11,
          437,
          307,
          264,
          958,
          1823,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.16790951176693564,
        "compression_ratio": 1.5107296137339057,
        "end": 2099.76,
        "id": 533,
        "no_speech_prob": 0.00555482367053628,
        "seek": 208076,
        "start": 2096.76,
        "temperature": 0,
        "text": " I need to create an annotation group.",
        "tokens": [
          51164,
          286,
          643,
          281,
          1884,
          364,
          48654,
          1594,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16790951176693564,
        "compression_ratio": 1.5107296137339057,
        "end": 2105.76,
        "id": 534,
        "no_speech_prob": 0.00555482367053628,
        "seek": 208076,
        "start": 2099.76,
        "temperature": 0,
        "text": " So I can't say that I entirely understand what an annotation group is in terms of the runway interface.",
        "tokens": [
          51314,
          407,
          286,
          393,
          380,
          584,
          300,
          286,
          7696,
          1223,
          437,
          364,
          48654,
          1594,
          307,
          294,
          2115,
          295,
          264,
          26642,
          9226,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16790951176693564,
        "compression_ratio": 1.5107296137339057,
        "end": 2108.76,
        "id": 535,
        "no_speech_prob": 0.00555482367053628,
        "seek": 208076,
        "start": 2105.76,
        "temperature": 0,
        "text": " But I'm assuming it means a collection of labels.",
        "tokens": [
          51614,
          583,
          286,
          478,
          11926,
          309,
          1355,
          257,
          5765,
          295,
          16949,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1907748267764137,
        "compression_ratio": 1.6,
        "end": 2116.76,
        "id": 536,
        "no_speech_prob": 0.002757582813501358,
        "seek": 210876,
        "start": 2109.76,
        "temperature": 0,
        "text": " So if I were doing Rubik's cubes and train whistles, my annotation group would contain both of those labels.",
        "tokens": [
          50414,
          407,
          498,
          286,
          645,
          884,
          10518,
          1035,
          311,
          25415,
          293,
          3847,
          49282,
          11,
          452,
          48654,
          1594,
          576,
          5304,
          1293,
          295,
          729,
          16949,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1907748267764137,
        "compression_ratio": 1.6,
        "end": 2121.76,
        "id": 537,
        "no_speech_prob": 0.002757582813501358,
        "seek": 210876,
        "start": 2116.76,
        "temperature": 0,
        "text": " But I just have one. And I don't have one that I've done before, so I'll make a new one.",
        "tokens": [
          50764,
          583,
          286,
          445,
          362,
          472,
          13,
          400,
          286,
          500,
          380,
          362,
          472,
          300,
          286,
          600,
          1096,
          949,
          11,
          370,
          286,
          603,
          652,
          257,
          777,
          472,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1907748267764137,
        "compression_ratio": 1.6,
        "end": 2127.76,
        "id": 538,
        "no_speech_prob": 0.002757582813501358,
        "seek": 210876,
        "start": 2121.76,
        "temperature": 0,
        "text": " We'll call this annotation for coding train live stream Rubik's.",
        "tokens": [
          51014,
          492,
          603,
          818,
          341,
          48654,
          337,
          17720,
          3847,
          1621,
          4309,
          10518,
          1035,
          311,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1907748267764137,
        "compression_ratio": 1.6,
        "end": 2129.76,
        "id": 539,
        "no_speech_prob": 0.002757582813501358,
        "seek": 210876,
        "start": 2127.76,
        "temperature": 0,
        "text": " Give it a very long name.",
        "tokens": [
          51314,
          5303,
          309,
          257,
          588,
          938,
          1315,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1907748267764137,
        "compression_ratio": 1.6,
        "end": 2136.76,
        "id": 540,
        "no_speech_prob": 0.002757582813501358,
        "seek": 210876,
        "start": 2129.76,
        "temperature": 0,
        "text": " And then I want to – oh, and then I want to put in the label will be Rubik's.",
        "tokens": [
          51414,
          400,
          550,
          286,
          528,
          281,
          1662,
          1954,
          11,
          293,
          550,
          286,
          528,
          281,
          829,
          294,
          264,
          7645,
          486,
          312,
          10518,
          1035,
          311,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1915585679827996,
        "compression_ratio": 1.532520325203252,
        "end": 2141.76,
        "id": 541,
        "no_speech_prob": 0.002590959658846259,
        "seek": 213676,
        "start": 2137.76,
        "temperature": 0,
        "text": " That's the one label I have. I'm going to click start annotating.",
        "tokens": [
          50414,
          663,
          311,
          264,
          472,
          7645,
          286,
          362,
          13,
          286,
          478,
          516,
          281,
          2052,
          722,
          25339,
          990,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1915585679827996,
        "compression_ratio": 1.532520325203252,
        "end": 2143.76,
        "id": 542,
        "no_speech_prob": 0.002590959658846259,
        "seek": 213676,
        "start": 2141.76,
        "temperature": 0,
        "text": " And hopefully this will load.",
        "tokens": [
          50614,
          400,
          4696,
          341,
          486,
          3677,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1915585679827996,
        "compression_ratio": 1.532520325203252,
        "end": 2145.76,
        "id": 543,
        "no_speech_prob": 0.002590959658846259,
        "seek": 213676,
        "start": 2143.76,
        "temperature": 0,
        "text": " I had a problem with this the other day.",
        "tokens": [
          50714,
          286,
          632,
          257,
          1154,
          365,
          341,
          264,
          661,
          786,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1915585679827996,
        "compression_ratio": 1.532520325203252,
        "end": 2151.76,
        "id": 544,
        "no_speech_prob": 0.002590959658846259,
        "seek": 213676,
        "start": 2145.76,
        "temperature": 0,
        "text": " Somebody can report this as a bug to runway where when I first load this page, nothing comes up.",
        "tokens": [
          50814,
          13463,
          393,
          2275,
          341,
          382,
          257,
          7426,
          281,
          26642,
          689,
          562,
          286,
          700,
          3677,
          341,
          3028,
          11,
          1825,
          1487,
          493,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1915585679827996,
        "compression_ratio": 1.532520325203252,
        "end": 2156.76,
        "id": 545,
        "no_speech_prob": 0.002590959658846259,
        "seek": 213676,
        "start": 2151.76,
        "temperature": 0,
        "text": " And I think that – let's see if I just click on image two.",
        "tokens": [
          51114,
          400,
          286,
          519,
          300,
          1662,
          718,
          311,
          536,
          498,
          286,
          445,
          2052,
          322,
          3256,
          732,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1915585679827996,
        "compression_ratio": 1.532520325203252,
        "end": 2163.76,
        "id": 546,
        "no_speech_prob": 0.002590959658846259,
        "seek": 213676,
        "start": 2156.76,
        "temperature": 0,
        "text": " If I recall correctly, what I did last time to fix this was – oh, no, it worked.",
        "tokens": [
          51364,
          759,
          286,
          9901,
          8944,
          11,
          437,
          286,
          630,
          1036,
          565,
          281,
          3191,
          341,
          390,
          1662,
          1954,
          11,
          572,
          11,
          309,
          2732,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2166.76,
        "id": 547,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2163.76,
        "temperature": 0,
        "text": " So I don't know why that first one didn't show up, but there it is.",
        "tokens": [
          50364,
          407,
          286,
          500,
          380,
          458,
          983,
          300,
          700,
          472,
          994,
          380,
          855,
          493,
          11,
          457,
          456,
          309,
          307,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2167.76,
        "id": 548,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2166.76,
        "temperature": 0,
        "text": " So this is what I'm doing.",
        "tokens": [
          50514,
          407,
          341,
          307,
          437,
          286,
          478,
          884,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2173.76,
        "id": 549,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2167.76,
        "temperature": 0,
        "text": " I'm looking at these images, and I'm going to annotate where the Rubik's cube is.",
        "tokens": [
          50564,
          286,
          478,
          1237,
          412,
          613,
          5267,
          11,
          293,
          286,
          478,
          516,
          281,
          25339,
          473,
          689,
          264,
          10518,
          1035,
          311,
          13728,
          307,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2175.76,
        "id": 550,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2173.76,
        "temperature": 0,
        "text": " But there's no Rubik's cube, so I can click skip.",
        "tokens": [
          50864,
          583,
          456,
          311,
          572,
          10518,
          1035,
          311,
          13728,
          11,
          370,
          286,
          393,
          2052,
          10023,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2179.76,
        "id": 551,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2175.76,
        "temperature": 0,
        "text": " There's a skip button all the way down here that I realize you can't see.",
        "tokens": [
          50964,
          821,
          311,
          257,
          10023,
          2960,
          439,
          264,
          636,
          760,
          510,
          300,
          286,
          4325,
          291,
          393,
          380,
          536,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2182.76,
        "id": 552,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2179.76,
        "temperature": 0,
        "text": " Skip, but I can also just hit the space bar, which will be much more efficient.",
        "tokens": [
          51164,
          46405,
          11,
          457,
          286,
          393,
          611,
          445,
          2045,
          264,
          1901,
          2159,
          11,
          597,
          486,
          312,
          709,
          544,
          7148,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2184.76,
        "id": 553,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2182.76,
        "temperature": 0,
        "text": " So I'm going through the images.",
        "tokens": [
          51314,
          407,
          286,
          478,
          516,
          807,
          264,
          5267,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2185.76,
        "id": 554,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2184.76,
        "temperature": 0,
        "text": " Now here is the Rubik's cube.",
        "tokens": [
          51414,
          823,
          510,
          307,
          264,
          10518,
          1035,
          311,
          13728,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2187.76,
        "id": 555,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2185.76,
        "temperature": 0,
        "text": " So now I'm going to annotate it.",
        "tokens": [
          51464,
          407,
          586,
          286,
          478,
          516,
          281,
          25339,
          473,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2189.76,
        "id": 556,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2187.76,
        "temperature": 0,
        "text": " I'm going to draw a little square over it.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          2642,
          257,
          707,
          3732,
          670,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14183022181193033,
        "compression_ratio": 1.9266666666666667,
        "end": 2192.76,
        "id": 557,
        "no_speech_prob": 0.00044421630445867777,
        "seek": 216376,
        "start": 2189.76,
        "temperature": 0,
        "text": " And that is the Rubik's cube, and I'm going to click next.",
        "tokens": [
          51664,
          400,
          300,
          307,
          264,
          10518,
          1035,
          311,
          13728,
          11,
          293,
          286,
          478,
          516,
          281,
          2052,
          958,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17901298132809726,
        "compression_ratio": 1.5610859728506787,
        "end": 2202.76,
        "id": 558,
        "no_speech_prob": 0.001501169870607555,
        "seek": 219276,
        "start": 2193.76,
        "temperature": 0,
        "text": " So I believe there are other tools like this, but I really appreciate how kind of quiet",
        "tokens": [
          50414,
          407,
          286,
          1697,
          456,
          366,
          661,
          3873,
          411,
          341,
          11,
          457,
          286,
          534,
          4449,
          577,
          733,
          295,
          5677,
          50864
        ]
      },
      {
        "avg_logprob": -0.17901298132809726,
        "compression_ratio": 1.5610859728506787,
        "end": 2207.76,
        "id": 559,
        "no_speech_prob": 0.001501169870607555,
        "seek": 219276,
        "start": 2202.76,
        "temperature": 0,
        "text": " and meditative and relaxing this is and how easy it is to do.",
        "tokens": [
          50864,
          293,
          1205,
          14275,
          293,
          20103,
          341,
          307,
          293,
          577,
          1858,
          309,
          307,
          281,
          360,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17901298132809726,
        "compression_ratio": 1.5610859728506787,
        "end": 2210.76,
        "id": 560,
        "no_speech_prob": 0.001501169870607555,
        "seek": 219276,
        "start": 2207.76,
        "temperature": 0,
        "text": " I can move this around and resize it.",
        "tokens": [
          51114,
          286,
          393,
          1286,
          341,
          926,
          293,
          50069,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17901298132809726,
        "compression_ratio": 1.5610859728506787,
        "end": 2215.76,
        "id": 561,
        "no_speech_prob": 0.001501169870607555,
        "seek": 219276,
        "start": 2210.76,
        "temperature": 0,
        "text": " I could be really – I'm not going to be very particular about it.",
        "tokens": [
          51264,
          286,
          727,
          312,
          534,
          1662,
          286,
          478,
          406,
          516,
          281,
          312,
          588,
          1729,
          466,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17901298132809726,
        "compression_ratio": 1.5610859728506787,
        "end": 2221.76,
        "id": 562,
        "no_speech_prob": 0.001501169870607555,
        "seek": 219276,
        "start": 2215.76,
        "temperature": 0,
        "text": " This definitely appeals to my obsessive nature to try to like very precisely annotate it,",
        "tokens": [
          51514,
          639,
          2138,
          32603,
          281,
          452,
          35803,
          488,
          3687,
          281,
          853,
          281,
          411,
          588,
          13402,
          25339,
          473,
          309,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.26803469150624376,
        "compression_ratio": 1.2125984251968505,
        "end": 2233.76,
        "id": 563,
        "no_speech_prob": 0.004982008598744869,
        "seek": 222176,
        "start": 2221.76,
        "temperature": 0,
        "text": " but I want to move quickly, and I think that I want to see if we can just have some nice, relaxing music like –",
        "tokens": [
          50364,
          457,
          286,
          528,
          281,
          1286,
          2661,
          11,
          293,
          286,
          519,
          300,
          286,
          528,
          281,
          536,
          498,
          321,
          393,
          445,
          362,
          512,
          1481,
          11,
          20103,
          1318,
          411,
          1662,
          50964
        ]
      },
      {
        "avg_logprob": -0.26803469150624376,
        "compression_ratio": 1.2125984251968505,
        "end": 2237.76,
        "id": 564,
        "no_speech_prob": 0.004982008598744869,
        "seek": 222176,
        "start": 2235.76,
        "temperature": 0,
        "text": " To annotate by.",
        "tokens": [
          51064,
          1407,
          25339,
          473,
          538,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26803469150624376,
        "compression_ratio": 1.2125984251968505,
        "end": 2244.76,
        "id": 565,
        "no_speech_prob": 0.004982008598744869,
        "seek": 222176,
        "start": 2242.76,
        "temperature": 0,
        "text": " How many do I got to do?",
        "tokens": [
          51414,
          1012,
          867,
          360,
          286,
          658,
          281,
          360,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.37156165729869495,
        "compression_ratio": 1.4651162790697674,
        "end": 2254.76,
        "id": 566,
        "no_speech_prob": 0.01242772676050663,
        "seek": 225176,
        "start": 2252.76,
        "temperature": 0,
        "text": " I'm going to try to do it.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          853,
          281,
          360,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.37156165729869495,
        "compression_ratio": 1.4651162790697674,
        "end": 2262.76,
        "id": 567,
        "no_speech_prob": 0.01242772676050663,
        "seek": 225176,
        "start": 2260.76,
        "temperature": 0,
        "text": " Talk amongst yourselves, everybody.",
        "tokens": [
          50814,
          8780,
          12918,
          14791,
          11,
          2201,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.37156165729869495,
        "compression_ratio": 1.4651162790697674,
        "end": 2272.76,
        "id": 568,
        "no_speech_prob": 0.01242772676050663,
        "seek": 225176,
        "start": 2266.76,
        "temperature": 0,
        "text": " For those of you wondering, why didn't he just do this before he started live streaming?",
        "tokens": [
          51114,
          1171,
          729,
          295,
          291,
          6359,
          11,
          983,
          994,
          380,
          415,
          445,
          360,
          341,
          949,
          415,
          1409,
          1621,
          11791,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.37156165729869495,
        "compression_ratio": 1.4651162790697674,
        "end": 2274.76,
        "id": 569,
        "no_speech_prob": 0.01242772676050663,
        "seek": 225176,
        "start": 2272.76,
        "temperature": 0,
        "text": " And then he could show us, and guess what?",
        "tokens": [
          51414,
          400,
          550,
          415,
          727,
          855,
          505,
          11,
          293,
          2041,
          437,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.37156165729869495,
        "compression_ratio": 1.4651162790697674,
        "end": 2276.76,
        "id": 570,
        "no_speech_prob": 0.01242772676050663,
        "seek": 225176,
        "start": 2274.76,
        "temperature": 0,
        "text": " Look, I actually already did this.",
        "tokens": [
          51514,
          2053,
          11,
          286,
          767,
          1217,
          630,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.37156165729869495,
        "compression_ratio": 1.4651162790697674,
        "end": 2277.76,
        "id": 571,
        "no_speech_prob": 0.01242772676050663,
        "seek": 225176,
        "start": 2276.76,
        "temperature": 0,
        "text": " Here's the finished version.",
        "tokens": [
          51614,
          1692,
          311,
          264,
          4335,
          3037,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.37156165729869495,
        "compression_ratio": 1.4651162790697674,
        "end": 2279.76,
        "id": 572,
        "no_speech_prob": 0.01242772676050663,
        "seek": 225176,
        "start": 2277.76,
        "temperature": 0,
        "text": " I'm just going to show you the beginning of the process.",
        "tokens": [
          51664,
          286,
          478,
          445,
          516,
          281,
          855,
          291,
          264,
          2863,
          295,
          264,
          1399,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1891491629860618,
        "compression_ratio": 1.4889867841409692,
        "end": 2280.76,
        "id": 573,
        "no_speech_prob": 0.003429392585530877,
        "seek": 227976,
        "start": 2279.76,
        "temperature": 0,
        "text": " Nope!",
        "tokens": [
          50364,
          12172,
          0,
          50414
        ]
      },
      {
        "avg_logprob": -0.1891491629860618,
        "compression_ratio": 1.4889867841409692,
        "end": 2282.76,
        "id": 574,
        "no_speech_prob": 0.003429392585530877,
        "seek": 227976,
        "start": 2280.76,
        "temperature": 0,
        "text": " That's not how this works, people.",
        "tokens": [
          50414,
          663,
          311,
          406,
          577,
          341,
          1985,
          11,
          561,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1891491629860618,
        "compression_ratio": 1.4889867841409692,
        "end": 2289.76,
        "id": 575,
        "no_speech_prob": 0.003429392585530877,
        "seek": 227976,
        "start": 2283.76,
        "temperature": 0,
        "text": " The whole project, all the pieces, I will demonstrate to you.",
        "tokens": [
          50564,
          440,
          1379,
          1716,
          11,
          439,
          264,
          3755,
          11,
          286,
          486,
          11698,
          281,
          291,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1891491629860618,
        "compression_ratio": 1.4889867841409692,
        "end": 2292.76,
        "id": 576,
        "no_speech_prob": 0.003429392585530877,
        "seek": 227976,
        "start": 2289.76,
        "temperature": 0,
        "text": " Oh, I'm really doing a terrible job.",
        "tokens": [
          50864,
          876,
          11,
          286,
          478,
          534,
          884,
          257,
          6237,
          1691,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1891491629860618,
        "compression_ratio": 1.4889867841409692,
        "end": 2299.76,
        "id": 577,
        "no_speech_prob": 0.003429392585530877,
        "seek": 227976,
        "start": 2292.76,
        "temperature": 0,
        "text": " By the way, what would be really cool is to build a system by which we could crowdsource this.",
        "tokens": [
          51014,
          3146,
          264,
          636,
          11,
          437,
          576,
          312,
          534,
          1627,
          307,
          281,
          1322,
          257,
          1185,
          538,
          597,
          321,
          727,
          26070,
          2948,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1891491629860618,
        "compression_ratio": 1.4889867841409692,
        "end": 2305.76,
        "id": 578,
        "no_speech_prob": 0.003429392585530877,
        "seek": 227976,
        "start": 2300.76,
        "temperature": 0,
        "text": " So what if I could give – you know, Runway could think about this.",
        "tokens": [
          51414,
          407,
          437,
          498,
          286,
          727,
          976,
          1662,
          291,
          458,
          11,
          8950,
          676,
          727,
          519,
          466,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1891491629860618,
        "compression_ratio": 1.4889867841409692,
        "end": 2308.76,
        "id": 579,
        "no_speech_prob": 0.003429392585530877,
        "seek": 227976,
        "start": 2305.76,
        "temperature": 0,
        "text": " What if I could give this URL out?",
        "tokens": [
          51664,
          708,
          498,
          286,
          727,
          976,
          341,
          12905,
          484,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.18258702754974365,
        "compression_ratio": 1.123456790123457,
        "end": 2317.76,
        "id": 580,
        "no_speech_prob": 0.0016629085876047611,
        "seek": 230876,
        "start": 2308.76,
        "temperature": 0,
        "text": " And all of you who are watching this right now could participate in the annotation process.",
        "tokens": [
          50364,
          400,
          439,
          295,
          291,
          567,
          366,
          1976,
          341,
          558,
          586,
          727,
          8197,
          294,
          264,
          48654,
          1399,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2919467001250296,
        "compression_ratio": 1.33125,
        "end": 2349.76,
        "id": 581,
        "no_speech_prob": 0.10372186452150345,
        "seek": 233876,
        "start": 2338.76,
        "temperature": 0,
        "text": " What? The song's over already? What number am I on?",
        "tokens": [
          50364,
          708,
          30,
          440,
          2153,
          311,
          670,
          1217,
          30,
          708,
          1230,
          669,
          286,
          322,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.2919467001250296,
        "compression_ratio": 1.33125,
        "end": 2355.76,
        "id": 582,
        "no_speech_prob": 0.10372186452150345,
        "seek": 233876,
        "start": 2349.76,
        "temperature": 0,
        "text": " 40. Hey, I'm not – I'm like pretty far along here.",
        "tokens": [
          50914,
          3356,
          13,
          1911,
          11,
          286,
          478,
          406,
          1662,
          286,
          478,
          411,
          1238,
          1400,
          2051,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2919467001250296,
        "compression_ratio": 1.33125,
        "end": 2361.76,
        "id": 583,
        "no_speech_prob": 0.10372186452150345,
        "seek": 233876,
        "start": 2358.76,
        "temperature": 0,
        "text": " I don't know what – no, these are all the Halloween things I had.",
        "tokens": [
          51364,
          286,
          500,
          380,
          458,
          437,
          1662,
          572,
          11,
          613,
          366,
          439,
          264,
          13860,
          721,
          286,
          632,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2919467001250296,
        "compression_ratio": 1.33125,
        "end": 2364.76,
        "id": 584,
        "no_speech_prob": 0.10372186452150345,
        "seek": 233876,
        "start": 2361.76,
        "temperature": 0,
        "text": " I forgot I had all that Halloween music.",
        "tokens": [
          51514,
          286,
          5298,
          286,
          632,
          439,
          300,
          13860,
          1318,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2982699184094445,
        "compression_ratio": 1.3154362416107384,
        "end": 2371.76,
        "id": 585,
        "no_speech_prob": 0.018830731511116028,
        "seek": 236476,
        "start": 2365.76,
        "temperature": 0,
        "text": " No, this always gets me like a copyright violation, the Goldberg variations.",
        "tokens": [
          50414,
          883,
          11,
          341,
          1009,
          2170,
          385,
          411,
          257,
          17996,
          22840,
          11,
          264,
          6731,
          6873,
          17840,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2982699184094445,
        "compression_ratio": 1.3154362416107384,
        "end": 2373.76,
        "id": 586,
        "no_speech_prob": 0.018830731511116028,
        "seek": 236476,
        "start": 2371.76,
        "temperature": 0,
        "text": " Let's try this.",
        "tokens": [
          50714,
          961,
          311,
          853,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2982699184094445,
        "compression_ratio": 1.3154362416107384,
        "end": 2378.76,
        "id": 587,
        "no_speech_prob": 0.018830731511116028,
        "seek": 236476,
        "start": 2375.76,
        "temperature": 0,
        "text": " Oh yeah, this is good. Oh my god, why did I –",
        "tokens": [
          50914,
          876,
          1338,
          11,
          341,
          307,
          665,
          13,
          876,
          452,
          3044,
          11,
          983,
          630,
          286,
          1662,
          51064
        ]
      },
      {
        "avg_logprob": -0.2982699184094445,
        "compression_ratio": 1.3154362416107384,
        "end": 2383.76,
        "id": 588,
        "no_speech_prob": 0.018830731511116028,
        "seek": 236476,
        "start": 2379.76,
        "temperature": 0,
        "text": " All right, everybody, montage, annotation montage.",
        "tokens": [
          51114,
          1057,
          558,
          11,
          2201,
          11,
          40184,
          11,
          48654,
          40184,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2982699184094445,
        "compression_ratio": 1.3154362416107384,
        "end": 2391.76,
        "id": 589,
        "no_speech_prob": 0.018830731511116028,
        "seek": 236476,
        "start": 2390.76,
        "temperature": 0,
        "text": " Hey!",
        "tokens": [
          51664,
          1911,
          0,
          51714
        ]
      },
      {
        "avg_logprob": -0.21504496653145605,
        "compression_ratio": 1.5591397849462365,
        "end": 2401.76,
        "id": 590,
        "no_speech_prob": 0.042081572115421295,
        "seek": 239476,
        "start": 2395.76,
        "temperature": 0,
        "text": " Welcome, Henry Whittaker, by joining the coding train right now.",
        "tokens": [
          50414,
          4027,
          11,
          11085,
          506,
          593,
          4003,
          11,
          538,
          5549,
          264,
          17720,
          3847,
          558,
          586,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21504496653145605,
        "compression_ratio": 1.5591397849462365,
        "end": 2408.76,
        "id": 591,
        "no_speech_prob": 0.042081572115421295,
        "seek": 239476,
        "start": 2401.76,
        "temperature": 0,
        "text": " You have interrupted me from my special hand-labeling process of machine learning imagery, but I thank you.",
        "tokens": [
          50714,
          509,
          362,
          30329,
          385,
          490,
          452,
          2121,
          1011,
          12,
          44990,
          11031,
          1399,
          295,
          3479,
          2539,
          24340,
          11,
          457,
          286,
          1309,
          291,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21504496653145605,
        "compression_ratio": 1.5591397849462365,
        "end": 2412.76,
        "id": 592,
        "no_speech_prob": 0.042081572115421295,
        "seek": 239476,
        "start": 2408.76,
        "temperature": 0,
        "text": " Actually, you've saved everybody because we were just stuck.",
        "tokens": [
          51064,
          5135,
          11,
          291,
          600,
          6624,
          2201,
          570,
          321,
          645,
          445,
          5541,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21504496653145605,
        "compression_ratio": 1.5591397849462365,
        "end": 2417.76,
        "id": 593,
        "no_speech_prob": 0.042081572115421295,
        "seek": 239476,
        "start": 2412.76,
        "temperature": 0,
        "text": " There was nothing else we could possibly do, but now, having joined the coding train, Henry,",
        "tokens": [
          51264,
          821,
          390,
          1825,
          1646,
          321,
          727,
          6264,
          360,
          11,
          457,
          586,
          11,
          1419,
          6869,
          264,
          17720,
          3847,
          11,
          11085,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.21504496653145605,
        "compression_ratio": 1.5591397849462365,
        "end": 2420.76,
        "id": 594,
        "no_speech_prob": 0.042081572115421295,
        "seek": 239476,
        "start": 2417.76,
        "temperature": 0,
        "text": " I will now find for you your very own personal random number.",
        "tokens": [
          51514,
          286,
          486,
          586,
          915,
          337,
          291,
          428,
          588,
          1065,
          2973,
          4974,
          1230,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21504496653145605,
        "compression_ratio": 1.5591397849462365,
        "end": 2423.76,
        "id": 595,
        "no_speech_prob": 0.042081572115421295,
        "seek": 239476,
        "start": 2420.76,
        "temperature": 0,
        "text": " Oh, I got the timing of that way wrong. It is.",
        "tokens": [
          51664,
          876,
          11,
          286,
          658,
          264,
          10822,
          295,
          300,
          636,
          2085,
          13,
          467,
          307,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2431.76,
        "id": 596,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2424.76,
        "temperature": 0,
        "text": " On row 8,915, column 01234567.",
        "tokens": [
          50364,
          1282,
          5386,
          1649,
          11,
          24,
          5211,
          11,
          7738,
          1958,
          4762,
          18,
          8465,
          22452,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2435.76,
        "id": 597,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2432.76,
        "temperature": 0,
        "text": " 6,469.",
        "tokens": [
          50764,
          1386,
          11,
          16169,
          24,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2438.76,
        "id": 598,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2435.76,
        "temperature": 0,
        "text": " Thank you, Henry, for your support. It means a lot.",
        "tokens": [
          50914,
          1044,
          291,
          11,
          11085,
          11,
          337,
          428,
          1406,
          13,
          467,
          1355,
          257,
          688,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2443.76,
        "id": 599,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2438.76,
        "temperature": 0,
        "text": " It helps me upgrade my studio and keeps me going.",
        "tokens": [
          51064,
          467,
          3665,
          385,
          11484,
          452,
          6811,
          293,
          5965,
          385,
          516,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2446.76,
        "id": 600,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2443.76,
        "temperature": 0,
        "text": " It motivates me. It fills me. All of that stuff.",
        "tokens": [
          51314,
          467,
          42569,
          385,
          13,
          467,
          22498,
          385,
          13,
          1057,
          295,
          300,
          1507,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2448.76,
        "id": 601,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2447.76,
        "temperature": 0,
        "text": " Wrong one.",
        "tokens": [
          51514,
          28150,
          472,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2450.76,
        "id": 602,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2449.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21897922243390763,
        "compression_ratio": 1.347305389221557,
        "end": 2452.76,
        "id": 603,
        "no_speech_prob": 0.0002959475386887789,
        "seek": 242476,
        "start": 2451.76,
        "temperature": 0,
        "text": " Back to annotating.",
        "tokens": [
          51714,
          5833,
          281,
          25339,
          990,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.154074357903522,
        "compression_ratio": 1.2654867256637168,
        "end": 2459.76,
        "id": 604,
        "no_speech_prob": 0.0002131810033461079,
        "seek": 245476,
        "start": 2455.76,
        "temperature": 0,
        "text": " I think this is not annotating. Do you know what this is?",
        "tokens": [
          50414,
          286,
          519,
          341,
          307,
          406,
          25339,
          990,
          13,
          1144,
          291,
          458,
          437,
          341,
          307,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.154074357903522,
        "compression_ratio": 1.2654867256637168,
        "end": 2462.76,
        "id": 605,
        "no_speech_prob": 0.0002131810033461079,
        "seek": 245476,
        "start": 2460.76,
        "temperature": 0,
        "text": " It's dance notating.",
        "tokens": [
          50664,
          467,
          311,
          4489,
          406,
          990,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.154074357903522,
        "compression_ratio": 1.2654867256637168,
        "end": 2477.76,
        "id": 606,
        "no_speech_prob": 0.0002131810033461079,
        "seek": 245476,
        "start": 2473.76,
        "temperature": 0,
        "text": " Kind of makes it go a little bit slower, but it's much more fun.",
        "tokens": [
          51314,
          9242,
          295,
          1669,
          309,
          352,
          257,
          707,
          857,
          14009,
          11,
          457,
          309,
          311,
          709,
          544,
          1019,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20054142291729266,
        "compression_ratio": 1.3285714285714285,
        "end": 2480.76,
        "id": 607,
        "no_speech_prob": 0.014724702574312687,
        "seek": 247776,
        "start": 2477.76,
        "temperature": 0,
        "text": " I really need a standing desk here in the attic.",
        "tokens": [
          50364,
          286,
          534,
          643,
          257,
          4877,
          10026,
          510,
          294,
          264,
          40766,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20054142291729266,
        "compression_ratio": 1.3285714285714285,
        "end": 2482.76,
        "id": 608,
        "no_speech_prob": 0.014724702574312687,
        "seek": 247776,
        "start": 2480.76,
        "temperature": 0,
        "text": " That's the other upgrade I'm going to make.",
        "tokens": [
          50514,
          663,
          311,
          264,
          661,
          11484,
          286,
          478,
          516,
          281,
          652,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20054142291729266,
        "compression_ratio": 1.3285714285714285,
        "end": 2485.76,
        "id": 609,
        "no_speech_prob": 0.014724702574312687,
        "seek": 247776,
        "start": 2482.76,
        "temperature": 0,
        "text": " This sitting while live streaming does not work for me.",
        "tokens": [
          50614,
          639,
          3798,
          1339,
          1621,
          11791,
          775,
          406,
          589,
          337,
          385,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20054142291729266,
        "compression_ratio": 1.3285714285714285,
        "end": 2489.76,
        "id": 610,
        "no_speech_prob": 0.014724702574312687,
        "seek": 247776,
        "start": 2487.76,
        "temperature": 0,
        "text": " All right. Let's move faster, people.",
        "tokens": [
          50864,
          1057,
          558,
          13,
          961,
          311,
          1286,
          4663,
          11,
          561,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.6725879510243734,
        "compression_ratio": 0.5555555555555556,
        "end": 2508.76,
        "id": 611,
        "no_speech_prob": 0.9463185667991638,
        "seek": 250776,
        "start": 2507.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2991545540945871,
        "compression_ratio": 1.1123595505617978,
        "end": 2540.76,
        "id": 612,
        "no_speech_prob": 0.03208978846669197,
        "seek": 253776,
        "start": 2538.76,
        "temperature": 0,
        "text": " Oh, that was a terrible one.",
        "tokens": [
          50414,
          876,
          11,
          300,
          390,
          257,
          6237,
          472,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2991545540945871,
        "compression_ratio": 1.1123595505617978,
        "end": 2544.76,
        "id": 613,
        "no_speech_prob": 0.03208978846669197,
        "seek": 253776,
        "start": 2541.76,
        "temperature": 0,
        "text": " I really had to go back and do this again with much greater precision.",
        "tokens": [
          50564,
          286,
          534,
          632,
          281,
          352,
          646,
          293,
          360,
          341,
          797,
          365,
          709,
          5044,
          18356,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.6486457188924154,
        "compression_ratio": 1.1702127659574468,
        "end": 2582.76,
        "id": 614,
        "no_speech_prob": 0.016399135813117027,
        "seek": 256776,
        "start": 2568.76,
        "temperature": 0.2,
        "text": " Where are we now? Halfway there, people.",
        "tokens": [
          50414,
          2305,
          366,
          321,
          586,
          30,
          15917,
          676,
          456,
          11,
          561,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.6486457188924154,
        "compression_ratio": 1.1702127659574468,
        "end": 2584.76,
        "id": 615,
        "no_speech_prob": 0.016399135813117027,
        "seek": 256776,
        "start": 2582.76,
        "temperature": 0.2,
        "text": " Halfway there.",
        "tokens": [
          51114,
          15917,
          676,
          456,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.6786299618807706,
        "compression_ratio": 0.9242424242424242,
        "end": 2586.76,
        "id": 616,
        "no_speech_prob": 0.005469008814543486,
        "seek": 258476,
        "start": 2585.76,
        "temperature": 0,
        "text": " Dance notation.",
        "tokens": [
          50414,
          16114,
          24657,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.6786299618807706,
        "compression_ratio": 0.9242424242424242,
        "end": 2595.76,
        "id": 617,
        "no_speech_prob": 0.005469008814543486,
        "seek": 258476,
        "start": 2594.76,
        "temperature": 0,
        "text": " What's happening in the chat? Anything?",
        "tokens": [
          50864,
          708,
          311,
          2737,
          294,
          264,
          5081,
          30,
          11998,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.6786299618807706,
        "compression_ratio": 0.9242424242424242,
        "end": 2601.76,
        "id": 618,
        "no_speech_prob": 0.005469008814543486,
        "seek": 258476,
        "start": 2600.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3303656101226807,
        "compression_ratio": 1.5730337078651686,
        "end": 2604.76,
        "id": 619,
        "no_speech_prob": 0.10968257486820221,
        "seek": 260176,
        "start": 2602.76,
        "temperature": 0,
        "text": " What's happening in the chat? Anything?",
        "tokens": [
          50414,
          708,
          311,
          2737,
          294,
          264,
          5081,
          30,
          11998,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.3303656101226807,
        "compression_ratio": 1.5730337078651686,
        "end": 2618.76,
        "id": 620,
        "no_speech_prob": 0.10968257486820221,
        "seek": 260176,
        "start": 2612.76,
        "temperature": 0,
        "text": " Yeah. So in the chat, there's a little bit of a discussion going on that here's a bias of how...",
        "tokens": [
          50914,
          865,
          13,
          407,
          294,
          264,
          5081,
          11,
          456,
          311,
          257,
          707,
          857,
          295,
          257,
          5017,
          516,
          322,
          300,
          510,
          311,
          257,
          12577,
          295,
          577,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.3303656101226807,
        "compression_ratio": 1.5730337078651686,
        "end": 2620.76,
        "id": 621,
        "no_speech_prob": 0.10968257486820221,
        "seek": 260176,
        "start": 2618.76,
        "temperature": 0,
        "text": " Here's a human bias. Here's an example of human bias.",
        "tokens": [
          51214,
          1692,
          311,
          257,
          1952,
          12577,
          13,
          1692,
          311,
          364,
          1365,
          295,
          1952,
          12577,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3303656101226807,
        "compression_ratio": 1.5730337078651686,
        "end": 2623.76,
        "id": 622,
        "no_speech_prob": 0.10968257486820221,
        "seek": 260176,
        "start": 2620.76,
        "temperature": 0,
        "text": " See, I really need to bring these messages up on the screen so I don't have to read them.",
        "tokens": [
          51314,
          3008,
          11,
          286,
          534,
          643,
          281,
          1565,
          613,
          7897,
          493,
          322,
          264,
          2568,
          370,
          286,
          500,
          380,
          362,
          281,
          1401,
          552,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.5774966189735814,
        "compression_ratio": 1.6266666666666667,
        "end": 2624.76,
        "id": 623,
        "no_speech_prob": 0.04023509845137596,
        "seek": 262376,
        "start": 2623.76,
        "temperature": 0,
        "text": " But I'm going to read this.",
        "tokens": [
          50364,
          583,
          286,
          478,
          516,
          281,
          1401,
          341,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.5774966189735814,
        "compression_ratio": 1.6266666666666667,
        "end": 2627.76,
        "id": 624,
        "no_speech_prob": 0.04023509845137596,
        "seek": 262376,
        "start": 2624.76,
        "temperature": 0,
        "text": " Dan's fingers are present in each annotation of the cube.",
        "tokens": [
          50414,
          3394,
          311,
          7350,
          366,
          1974,
          294,
          1184,
          48654,
          295,
          264,
          13728,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.5774966189735814,
        "compression_ratio": 1.6266666666666667,
        "end": 2634.76,
        "id": 625,
        "no_speech_prob": 0.04023509845137596,
        "seek": 262376,
        "start": 2629.76,
        "temperature": 0,
        "text": " Then the resulting model might not be able to identify a cube lying on a table because it wouldn't be surrounded by fingers.",
        "tokens": [
          50664,
          1396,
          264,
          16505,
          2316,
          1062,
          406,
          312,
          1075,
          281,
          5876,
          257,
          13728,
          8493,
          322,
          257,
          3199,
          570,
          309,
          2759,
          380,
          312,
          13221,
          538,
          7350,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.5774966189735814,
        "compression_ratio": 1.6266666666666667,
        "end": 2635.76,
        "id": 626,
        "no_speech_prob": 0.04023509845137596,
        "seek": 262376,
        "start": 2634.76,
        "temperature": 0,
        "text": " Exactly.",
        "tokens": [
          50914,
          7587,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.5774966189735814,
        "compression_ratio": 1.6266666666666667,
        "end": 2642.76,
        "id": 627,
        "no_speech_prob": 0.04023509845137596,
        "seek": 262376,
        "start": 2635.76,
        "temperature": 0,
        "text": " So if I wanted to have a very sort of broadly functional annotation of a cube,",
        "tokens": [
          50964,
          407,
          498,
          286,
          1415,
          281,
          362,
          257,
          588,
          1333,
          295,
          19511,
          11745,
          48654,
          295,
          257,
          13728,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.5774966189735814,
        "compression_ratio": 1.6266666666666667,
        "end": 2645.76,
        "id": 628,
        "no_speech_prob": 0.04023509845137596,
        "seek": 262376,
        "start": 2642.76,
        "temperature": 0,
        "text": " I would have to have a cube that was a little bit more than a cube.",
        "tokens": [
          51314,
          286,
          576,
          362,
          281,
          362,
          257,
          13728,
          300,
          390,
          257,
          707,
          857,
          544,
          813,
          257,
          13728,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19267889261245727,
        "compression_ratio": 1.616504854368932,
        "end": 2658.76,
        "id": 629,
        "no_speech_prob": 0.4959416389465332,
        "seek": 264576,
        "start": 2646.76,
        "temperature": 0,
        "text": " So if I wanted to have a very sort of broadly functional model that could recognize and find a Rubik's Cube in any image,",
        "tokens": [
          50414,
          407,
          498,
          286,
          1415,
          281,
          362,
          257,
          588,
          1333,
          295,
          19511,
          11745,
          2316,
          300,
          727,
          5521,
          293,
          915,
          257,
          10518,
          1035,
          311,
          33003,
          294,
          604,
          3256,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.19267889261245727,
        "compression_ratio": 1.616504854368932,
        "end": 2664.76,
        "id": 630,
        "no_speech_prob": 0.4959416389465332,
        "seek": 264576,
        "start": 2658.76,
        "temperature": 0,
        "text": " this would be a pretty terrible data set because the Rubik's Cube is only ever present in one environment,",
        "tokens": [
          51014,
          341,
          576,
          312,
          257,
          1238,
          6237,
          1412,
          992,
          570,
          264,
          10518,
          1035,
          311,
          33003,
          307,
          787,
          1562,
          1974,
          294,
          472,
          2823,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19267889261245727,
        "compression_ratio": 1.616504854368932,
        "end": 2670.76,
        "id": 631,
        "no_speech_prob": 0.4959416389465332,
        "seek": 264576,
        "start": 2664.76,
        "temperature": 0,
        "text": " the environment with me in it, with this green screen background, with my hand holding the Rubik's Cube.",
        "tokens": [
          51314,
          264,
          2823,
          365,
          385,
          294,
          309,
          11,
          365,
          341,
          3092,
          2568,
          3678,
          11,
          365,
          452,
          1011,
          5061,
          264,
          10518,
          1035,
          311,
          33003,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15866953617817647,
        "compression_ratio": 1.4974358974358974,
        "end": 2677.76,
        "id": 632,
        "no_speech_prob": 0.0019569506403058767,
        "seek": 267076,
        "start": 2670.76,
        "temperature": 0,
        "text": " So I would want to collect a much more elaborate and varied data set.",
        "tokens": [
          50364,
          407,
          286,
          576,
          528,
          281,
          2500,
          257,
          709,
          544,
          20945,
          293,
          22877,
          1412,
          992,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15866953617817647,
        "compression_ratio": 1.4974358974358974,
        "end": 2687.76,
        "id": 633,
        "no_speech_prob": 0.0019569506403058767,
        "seek": 267076,
        "start": 2677.76,
        "temperature": 0,
        "text": " But I would say that one of the things about what I'm doing here which isn't necessarily a problem is my use case might be",
        "tokens": [
          50714,
          583,
          286,
          576,
          584,
          300,
          472,
          295,
          264,
          721,
          466,
          437,
          286,
          478,
          884,
          510,
          597,
          1943,
          380,
          4725,
          257,
          1154,
          307,
          452,
          764,
          1389,
          1062,
          312,
          51214
        ]
      },
      {
        "avg_logprob": -0.15866953617817647,
        "compression_ratio": 1.4974358974358974,
        "end": 2695.76,
        "id": 634,
        "no_speech_prob": 0.0019569506403058767,
        "seek": 267076,
        "start": 2687.76,
        "temperature": 0,
        "text": " I want to build something for myself that can find the Rubik's Cube in my hand when I'm holding it.",
        "tokens": [
          51214,
          286,
          528,
          281,
          1322,
          746,
          337,
          2059,
          300,
          393,
          915,
          264,
          10518,
          1035,
          311,
          33003,
          294,
          452,
          1011,
          562,
          286,
          478,
          5061,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22956865484064276,
        "compression_ratio": 1.6111111111111112,
        "end": 2701.76,
        "id": 635,
        "no_speech_prob": 0.02002245932817459,
        "seek": 269576,
        "start": 2696.76,
        "temperature": 0,
        "text": " And also I don't have a single example of it without the same color on one side, so that's certainly a problem.",
        "tokens": [
          50414,
          400,
          611,
          286,
          500,
          380,
          362,
          257,
          2167,
          1365,
          295,
          309,
          1553,
          264,
          912,
          2017,
          322,
          472,
          1252,
          11,
          370,
          300,
          311,
          3297,
          257,
          1154,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22956865484064276,
        "compression_ratio": 1.6111111111111112,
        "end": 2714.76,
        "id": 636,
        "no_speech_prob": 0.02002245932817459,
        "seek": 269576,
        "start": 2701.76,
        "temperature": 0,
        "text": " But I could imagine in an interactive exhibit, for example, or some type of interactive context where you can really have control over the environment",
        "tokens": [
          50664,
          583,
          286,
          727,
          3811,
          294,
          364,
          15141,
          20487,
          11,
          337,
          1365,
          11,
          420,
          512,
          2010,
          295,
          15141,
          4319,
          689,
          291,
          393,
          534,
          362,
          1969,
          670,
          264,
          2823,
          51314
        ]
      },
      {
        "avg_logprob": -0.22956865484064276,
        "compression_ratio": 1.6111111111111112,
        "end": 2720.76,
        "id": 637,
        "no_speech_prob": 0.02002245932817459,
        "seek": 269576,
        "start": 2714.76,
        "temperature": 0,
        "text": " that having that fixed environment in your data set actually has a lot of advantages.",
        "tokens": [
          51314,
          300,
          1419,
          300,
          6806,
          2823,
          294,
          428,
          1412,
          992,
          767,
          575,
          257,
          688,
          295,
          14906,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.30401637636382006,
        "compression_ratio": 1.356164383561644,
        "end": 2733.76,
        "id": 638,
        "no_speech_prob": 0.327556312084198,
        "seek": 272076,
        "start": 2720.76,
        "temperature": 0,
        "text": " This is just not good. I just got to get slightly more, I probably also don't need 150, so this is kind of maybe a little bit ridiculous what I'm doing,",
        "tokens": [
          50364,
          639,
          307,
          445,
          406,
          665,
          13,
          286,
          445,
          658,
          281,
          483,
          4748,
          544,
          11,
          286,
          1391,
          611,
          500,
          380,
          643,
          8451,
          11,
          370,
          341,
          307,
          733,
          295,
          1310,
          257,
          707,
          857,
          11083,
          437,
          286,
          478,
          884,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.30401637636382006,
        "compression_ratio": 1.356164383561644,
        "end": 2739.76,
        "id": 639,
        "no_speech_prob": 0.327556312084198,
        "seek": 272076,
        "start": 2733.76,
        "temperature": 0,
        "text": " but I can't stop now. Can't stop, won't stop.",
        "tokens": [
          51014,
          457,
          286,
          393,
          380,
          1590,
          586,
          13,
          1664,
          380,
          1590,
          11,
          1582,
          380,
          1590,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25901322894626194,
        "compression_ratio": 1.628691983122363,
        "end": 2743.76,
        "id": 640,
        "no_speech_prob": 0.1710362583398819,
        "seek": 273976,
        "start": 2739.76,
        "temperature": 0,
        "text": " Oh, what is this weird? I don't know if this is going to be a problem, but I'm just going to...",
        "tokens": [
          50364,
          876,
          11,
          437,
          307,
          341,
          3657,
          30,
          286,
          500,
          380,
          458,
          498,
          341,
          307,
          516,
          281,
          312,
          257,
          1154,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.25901322894626194,
        "compression_ratio": 1.628691983122363,
        "end": 2748.76,
        "id": 641,
        "no_speech_prob": 0.1710362583398819,
        "seek": 273976,
        "start": 2743.76,
        "temperature": 0,
        "text": " Also all the blurriness, I didn't really think of that because I was moving it around a lot.",
        "tokens": [
          50564,
          2743,
          439,
          264,
          14257,
          81,
          1324,
          11,
          286,
          994,
          380,
          534,
          519,
          295,
          300,
          570,
          286,
          390,
          2684,
          309,
          926,
          257,
          688,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.25901322894626194,
        "compression_ratio": 1.628691983122363,
        "end": 2758.76,
        "id": 642,
        "no_speech_prob": 0.1710362583398819,
        "seek": 273976,
        "start": 2748.76,
        "temperature": 0,
        "text": " And, I mean, should I mark it here? Like, should it learn to be able to see it with my hand completely covering it?",
        "tokens": [
          50814,
          400,
          11,
          286,
          914,
          11,
          820,
          286,
          1491,
          309,
          510,
          30,
          1743,
          11,
          820,
          309,
          1466,
          281,
          312,
          1075,
          281,
          536,
          309,
          365,
          452,
          1011,
          2584,
          10322,
          309,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.25901322894626194,
        "compression_ratio": 1.628691983122363,
        "end": 2763.76,
        "id": 643,
        "no_speech_prob": 0.1710362583398819,
        "seek": 273976,
        "start": 2758.76,
        "temperature": 0,
        "text": " I'm going to annotate it that way. This is going to be an interesting experiment.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          25339,
          473,
          309,
          300,
          636,
          13,
          639,
          307,
          516,
          281,
          312,
          364,
          1880,
          5120,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2621080058894745,
        "compression_ratio": 1.6096256684491979,
        "end": 2772.76,
        "id": 644,
        "no_speech_prob": 0.5193827152252197,
        "seek": 276376,
        "start": 2764.76,
        "temperature": 0,
        "text": " And my goal here in many ways is not to do this so that I have a model that's working incredibly well.",
        "tokens": [
          50414,
          400,
          452,
          3387,
          510,
          294,
          867,
          2098,
          307,
          406,
          281,
          360,
          341,
          370,
          300,
          286,
          362,
          257,
          2316,
          300,
          311,
          1364,
          6252,
          731,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2621080058894745,
        "compression_ratio": 1.6096256684491979,
        "end": 2784.76,
        "id": 645,
        "no_speech_prob": 0.5193827152252197,
        "seek": 276376,
        "start": 2772.76,
        "temperature": 0,
        "text": " I mostly want to demonstrate this process so that if any of you want to embark on it, you might have more time or more clever ways of collecting your data",
        "tokens": [
          50814,
          286,
          5240,
          528,
          281,
          11698,
          341,
          1399,
          370,
          300,
          498,
          604,
          295,
          291,
          528,
          281,
          29832,
          322,
          309,
          11,
          291,
          1062,
          362,
          544,
          565,
          420,
          544,
          13494,
          2098,
          295,
          12510,
          428,
          1412,
          51414
        ]
      },
      {
        "avg_logprob": -0.2621080058894745,
        "compression_ratio": 1.6096256684491979,
        "end": 2787.76,
        "id": 646,
        "no_speech_prob": 0.5193827152252197,
        "seek": 276376,
        "start": 2784.76,
        "temperature": 0,
        "text": " and being more precise about annotating it.",
        "tokens": [
          51414,
          293,
          885,
          544,
          13600,
          466,
          25339,
          990,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23099383185891545,
        "compression_ratio": 1.3532608695652173,
        "end": 2792.76,
        "id": 647,
        "no_speech_prob": 0.05920799449086189,
        "seek": 278776,
        "start": 2788.76,
        "temperature": 0,
        "text": " Where are we? How are we doing? 122. Boy, I feel like I've slowed down.",
        "tokens": [
          50414,
          2305,
          366,
          321,
          30,
          1012,
          366,
          321,
          884,
          30,
          2272,
          17,
          13,
          9486,
          11,
          286,
          841,
          411,
          286,
          600,
          32057,
          760,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23099383185891545,
        "compression_ratio": 1.3532608695652173,
        "end": 2798.76,
        "id": 648,
        "no_speech_prob": 0.05920799449086189,
        "seek": 278776,
        "start": 2793.76,
        "temperature": 0,
        "text": " By the way, having an actual... I'm using a trackpad for this, which is kind of sad.",
        "tokens": [
          50664,
          3146,
          264,
          636,
          11,
          1419,
          364,
          3539,
          485,
          286,
          478,
          1228,
          257,
          2837,
          13647,
          337,
          341,
          11,
          597,
          307,
          733,
          295,
          4227,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23099383185891545,
        "compression_ratio": 1.3532608695652173,
        "end": 2800.76,
        "id": 649,
        "no_speech_prob": 0.05920799449086189,
        "seek": 278776,
        "start": 2798.76,
        "temperature": 0,
        "text": " Oh, did I finish?",
        "tokens": [
          50914,
          876,
          11,
          630,
          286,
          2413,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.23099383185891545,
        "compression_ratio": 1.3532608695652173,
        "end": 2805.76,
        "id": 650,
        "no_speech_prob": 0.05920799449086189,
        "seek": 278776,
        "start": 2802.76,
        "temperature": 0,
        "text": " Wait, what's going on? No, I don't see the images anymore.",
        "tokens": [
          51114,
          3802,
          11,
          437,
          311,
          516,
          322,
          30,
          883,
          11,
          286,
          500,
          380,
          536,
          264,
          5267,
          3602,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23099383185891545,
        "compression_ratio": 1.3532608695652173,
        "end": 2809.76,
        "id": 651,
        "no_speech_prob": 0.05920799449086189,
        "seek": 278776,
        "start": 2807.76,
        "temperature": 0,
        "text": " Weird. Hold on.",
        "tokens": [
          51364,
          32033,
          13,
          6962,
          322,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.5117318289620536,
        "compression_ratio": 0.9264705882352942,
        "end": 2814.76,
        "id": 652,
        "no_speech_prob": 0.10085111856460571,
        "seek": 280976,
        "start": 2809.76,
        "temperature": 0,
        "text": " Rename, export. What do I do here? Edit annotation group. Okay.",
        "tokens": [
          50364,
          12883,
          529,
          11,
          10725,
          13,
          708,
          360,
          286,
          360,
          510,
          30,
          33241,
          48654,
          1594,
          13,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2267709493637085,
        "compression_ratio": 1.0714285714285714,
        "end": 2817.76,
        "id": 653,
        "no_speech_prob": 0.4365794062614441,
        "seek": 281476,
        "start": 2815.76,
        "temperature": 0,
        "text": " Weird. Hold on.",
        "tokens": [
          50414,
          32033,
          13,
          6962,
          322,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2267709493637085,
        "compression_ratio": 1.0714285714285714,
        "end": 2822.76,
        "id": 654,
        "no_speech_prob": 0.4365794062614441,
        "seek": 281476,
        "start": 2819.76,
        "temperature": 0,
        "text": " Let me click here. Uh-oh.",
        "tokens": [
          50614,
          961,
          385,
          2052,
          510,
          13,
          4019,
          12,
          1445,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2267709493637085,
        "compression_ratio": 1.0714285714285714,
        "end": 2825.76,
        "id": 655,
        "no_speech_prob": 0.4365794062614441,
        "seek": 281476,
        "start": 2823.76,
        "temperature": 0,
        "text": " Rename, export. What do I do here?",
        "tokens": [
          50814,
          12883,
          529,
          11,
          10725,
          13,
          708,
          360,
          286,
          360,
          510,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.2267709493637085,
        "compression_ratio": 1.0714285714285714,
        "end": 2828.76,
        "id": 656,
        "no_speech_prob": 0.4365794062614441,
        "seek": 281476,
        "start": 2826.76,
        "temperature": 0,
        "text": " Edit annotation group. Okay.",
        "tokens": [
          50964,
          33241,
          48654,
          1594,
          13,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1991143035888672,
        "compression_ratio": 1.3228346456692914,
        "end": 2849.76,
        "id": 657,
        "no_speech_prob": 0.01717415265738964,
        "seek": 284476,
        "start": 2845.76,
        "temperature": 0,
        "text": " This will be done soon.",
        "tokens": [
          50414,
          639,
          486,
          312,
          1096,
          2321,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1991143035888672,
        "compression_ratio": 1.3228346456692914,
        "end": 2853.76,
        "id": 658,
        "no_speech_prob": 0.01717415265738964,
        "seek": 284476,
        "start": 2850.76,
        "temperature": 0,
        "text": " Don't worry, it only takes about four hours to train the model.",
        "tokens": [
          50664,
          1468,
          380,
          3292,
          11,
          309,
          787,
          2516,
          466,
          1451,
          2496,
          281,
          3847,
          264,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1991143035888672,
        "compression_ratio": 1.3228346456692914,
        "end": 2860.76,
        "id": 659,
        "no_speech_prob": 0.01717415265738964,
        "seek": 284476,
        "start": 2853.76,
        "temperature": 0,
        "text": " I'm just kidding. I'm going to let it train for as long as I can manage to wait.",
        "tokens": [
          50814,
          286,
          478,
          445,
          9287,
          13,
          286,
          478,
          516,
          281,
          718,
          309,
          3847,
          337,
          382,
          938,
          382,
          286,
          393,
          3067,
          281,
          1699,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.41096172834697525,
        "compression_ratio": 0.927536231884058,
        "end": 2902.76,
        "id": 660,
        "no_speech_prob": 0.06850653886795044,
        "seek": 287476,
        "start": 2874.76,
        "temperature": 0.2,
        "text": " What's it like to be a machine learning researcher, you may ask?",
        "tokens": [
          50364,
          708,
          311,
          309,
          411,
          281,
          312,
          257,
          3479,
          2539,
          21751,
          11,
          291,
          815,
          1029,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.3630251248677572,
        "compression_ratio": 1.3928571428571428,
        "end": 2906.76,
        "id": 661,
        "no_speech_prob": 0.07052863389253616,
        "seek": 290276,
        "start": 2902.76,
        "temperature": 0,
        "text": " Let me tell you something. Boy, is it exciting.",
        "tokens": [
          50364,
          961,
          385,
          980,
          291,
          746,
          13,
          9486,
          11,
          307,
          309,
          4670,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3630251248677572,
        "compression_ratio": 1.3928571428571428,
        "end": 2911.76,
        "id": 662,
        "no_speech_prob": 0.07052863389253616,
        "seek": 290276,
        "start": 2907.76,
        "temperature": 0,
        "text": " I'm going to move this rectangle here and slide it a little bit over,",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          1286,
          341,
          21930,
          510,
          293,
          4137,
          309,
          257,
          707,
          857,
          670,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.3630251248677572,
        "compression_ratio": 1.3928571428571428,
        "end": 2915.76,
        "id": 663,
        "no_speech_prob": 0.07052863389253616,
        "seek": 290276,
        "start": 2911.76,
        "temperature": 0,
        "text": " and a little bit over here, and all the way up to 3, 4. Yeah!",
        "tokens": [
          50814,
          293,
          257,
          707,
          857,
          670,
          510,
          11,
          293,
          439,
          264,
          636,
          493,
          281,
          805,
          11,
          1017,
          13,
          865,
          0,
          51014
        ]
      },
      {
        "avg_logprob": -0.3630251248677572,
        "compression_ratio": 1.3928571428571428,
        "end": 2921.76,
        "id": 664,
        "no_speech_prob": 0.07052863389253616,
        "seek": 290276,
        "start": 2919.76,
        "temperature": 0,
        "text": " Dance notation.",
        "tokens": [
          51214,
          16114,
          24657,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.41570109587449294,
        "compression_ratio": 0.8048780487804879,
        "end": 2934.76,
        "id": 665,
        "no_speech_prob": 0.0591614693403244,
        "seek": 292176,
        "start": 2921.76,
        "temperature": 0,
        "text": " Is there one way of doing it? No.",
        "tokens": [
          50364,
          1119,
          456,
          472,
          636,
          295,
          884,
          309,
          30,
          883,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.8105012543347417,
        "compression_ratio": 1.1926605504587156,
        "end": 2954.76,
        "id": 666,
        "no_speech_prob": 0.056542493402957916,
        "seek": 295176,
        "start": 2952.76,
        "temperature": 0,
        "text": " I know I'm getting to the end now.",
        "tokens": [
          50414,
          286,
          458,
          286,
          478,
          1242,
          281,
          264,
          917,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.8105012543347417,
        "compression_ratio": 1.1926605504587156,
        "end": 2964.76,
        "id": 667,
        "no_speech_prob": 0.056542493402957916,
        "seek": 295176,
        "start": 2960.76,
        "temperature": 0,
        "text": " I love you, Rubik's Cube. You are my baby.",
        "tokens": [
          50814,
          286,
          959,
          291,
          11,
          10518,
          1035,
          311,
          33003,
          13,
          509,
          366,
          452,
          3186,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.8105012543347417,
        "compression_ratio": 1.1926605504587156,
        "end": 2968.76,
        "id": 668,
        "no_speech_prob": 0.056542493402957916,
        "seek": 295176,
        "start": 2966.76,
        "temperature": 0,
        "text": " Yeah!",
        "tokens": [
          51114,
          865,
          0,
          51214
        ]
      },
      {
        "avg_logprob": -0.8105012543347417,
        "compression_ratio": 1.1926605504587156,
        "end": 2971.76,
        "id": 669,
        "no_speech_prob": 0.056542493402957916,
        "seek": 295176,
        "start": 2969.76,
        "temperature": 0,
        "text": " I'm going to make a little bit of a mess here.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          652,
          257,
          707,
          857,
          295,
          257,
          2082,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1935444231386538,
        "compression_ratio": 1.170940170940171,
        "end": 2977.76,
        "id": 670,
        "no_speech_prob": 0.0027575246058404446,
        "seek": 297176,
        "start": 2972.76,
        "temperature": 0,
        "text": " I love you, Rubik's Cube. You are my baby.",
        "tokens": [
          50414,
          286,
          959,
          291,
          11,
          10518,
          1035,
          311,
          33003,
          13,
          509,
          366,
          452,
          3186,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1935444231386538,
        "compression_ratio": 1.170940170940171,
        "end": 2981.76,
        "id": 671,
        "no_speech_prob": 0.0027575246058404446,
        "seek": 297176,
        "start": 2979.76,
        "temperature": 0,
        "text": " Yeah!",
        "tokens": [
          50764,
          865,
          0,
          50864
        ]
      },
      {
        "avg_logprob": -0.1935444231386538,
        "compression_ratio": 1.170940170940171,
        "end": 2983.76,
        "id": 672,
        "no_speech_prob": 0.0027575246058404446,
        "seek": 297176,
        "start": 2981.76,
        "temperature": 0,
        "text": " Oh, there's more?",
        "tokens": [
          50864,
          876,
          11,
          456,
          311,
          544,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.1935444231386538,
        "compression_ratio": 1.170940170940171,
        "end": 2994.76,
        "id": 673,
        "no_speech_prob": 0.0027575246058404446,
        "seek": 297176,
        "start": 2992.76,
        "temperature": 0,
        "text": " It's got to be the end now, right?",
        "tokens": [
          51414,
          467,
          311,
          658,
          281,
          312,
          264,
          917,
          586,
          11,
          558,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1935444231386538,
        "compression_ratio": 1.170940170940171,
        "end": 2998.76,
        "id": 674,
        "no_speech_prob": 0.0027575246058404446,
        "seek": 297176,
        "start": 2995.76,
        "temperature": 0,
        "text": " What is going on? What was I doing?",
        "tokens": [
          51564,
          708,
          307,
          516,
          322,
          30,
          708,
          390,
          286,
          884,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.37699585426144483,
        "compression_ratio": 1.330188679245283,
        "end": 3016.76,
        "id": 675,
        "no_speech_prob": 0.0006771569023840129,
        "seek": 300176,
        "start": 3001.76,
        "temperature": 0,
        "text": " Okay, come on. Almost there. Almost there. Almost there, people.",
        "tokens": [
          50364,
          1033,
          11,
          808,
          322,
          13,
          12627,
          456,
          13,
          12627,
          456,
          13,
          12627,
          456,
          11,
          561,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.37699585426144483,
        "compression_ratio": 1.330188679245283,
        "end": 3025.76,
        "id": 676,
        "no_speech_prob": 0.0006771569023840129,
        "seek": 300176,
        "start": 3020.76,
        "temperature": 0,
        "text": " All right. This is probably a bad idea. Let's give it that as some training.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          639,
          307,
          1391,
          257,
          1578,
          1558,
          13,
          961,
          311,
          976,
          309,
          300,
          382,
          512,
          3097,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20961977223880957,
        "compression_ratio": 1.584070796460177,
        "end": 3037.76,
        "id": 677,
        "no_speech_prob": 0.005910926964133978,
        "seek": 302576,
        "start": 3025.76,
        "temperature": 0,
        "text": " No Rubik's Cube. No Rubik's Cube. No Rubik's Cube. No Rubik's Cube.",
        "tokens": [
          50364,
          883,
          10518,
          1035,
          311,
          33003,
          13,
          883,
          10518,
          1035,
          311,
          33003,
          13,
          883,
          10518,
          1035,
          311,
          33003,
          13,
          883,
          10518,
          1035,
          311,
          33003,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20961977223880957,
        "compression_ratio": 1.584070796460177,
        "end": 3041.76,
        "id": 678,
        "no_speech_prob": 0.005910926964133978,
        "seek": 302576,
        "start": 3037.76,
        "temperature": 0,
        "text": " We are done, people. Close.",
        "tokens": [
          50964,
          492,
          366,
          1096,
          11,
          561,
          13,
          16346,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20961977223880957,
        "compression_ratio": 1.584070796460177,
        "end": 3051.76,
        "id": 679,
        "no_speech_prob": 0.005910926964133978,
        "seek": 302576,
        "start": 3042.76,
        "temperature": 0,
        "text": " Next, I am going to select a pre-trained model as the base model for this training.",
        "tokens": [
          51214,
          3087,
          11,
          286,
          669,
          516,
          281,
          3048,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          382,
          264,
          3096,
          2316,
          337,
          341,
          3097,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3054.76,
        "id": 680,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3052.76,
        "temperature": 0,
        "text": " Right here, we can see I can choose from other models.",
        "tokens": [
          50414,
          1779,
          510,
          11,
          321,
          393,
          536,
          286,
          393,
          2826,
          490,
          661,
          5245,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3056.76,
        "id": 681,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3054.76,
        "temperature": 0,
        "text": " I'm pretty sure the last time I checked this, that actually...",
        "tokens": [
          50514,
          286,
          478,
          1238,
          988,
          264,
          1036,
          565,
          286,
          10033,
          341,
          11,
          300,
          767,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3060.76,
        "id": 682,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3056.76,
        "temperature": 0,
        "text": " Oh, no. There's also YOLO version 3 Tiny.",
        "tokens": [
          50614,
          876,
          11,
          572,
          13,
          821,
          311,
          611,
          398,
          5046,
          46,
          3037,
          805,
          39992,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3064.76,
        "id": 683,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3060.76,
        "temperature": 0,
        "text": " Interesting. I wonder... Optimized for real time.",
        "tokens": [
          50814,
          14711,
          13,
          286,
          2441,
          485,
          35013,
          1602,
          337,
          957,
          565,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3068.76,
        "id": 684,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3064.76,
        "temperature": 0,
        "text": " Oh, interesting. I'm imagining using this in real time.",
        "tokens": [
          51014,
          876,
          11,
          1880,
          13,
          286,
          478,
          27798,
          1228,
          341,
          294,
          957,
          565,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3072.76,
        "id": 685,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3069.76,
        "temperature": 0,
        "text": " Let's train it with both. I'm going to just run this twice.",
        "tokens": [
          51264,
          961,
          311,
          3847,
          309,
          365,
          1293,
          13,
          286,
          478,
          516,
          281,
          445,
          1190,
          341,
          6091,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3076.76,
        "id": 686,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3072.76,
        "temperature": 0,
        "text": " I'm going to have this run twice. I'm going to let it go 5,000 training steps.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          362,
          341,
          1190,
          6091,
          13,
          286,
          478,
          516,
          281,
          718,
          309,
          352,
          1025,
          11,
          1360,
          3097,
          4439,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21946948016131365,
        "compression_ratio": 1.7433962264150944,
        "end": 3079.76,
        "id": 687,
        "no_speech_prob": 0.010169153101742268,
        "seek": 305176,
        "start": 3076.76,
        "temperature": 0,
        "text": " I might stop it early. I'm going to click Start Training.",
        "tokens": [
          51614,
          286,
          1062,
          1590,
          309,
          2440,
          13,
          286,
          478,
          516,
          281,
          2052,
          6481,
          20620,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.30590555960671945,
        "compression_ratio": 1.2765957446808511,
        "end": 3086.76,
        "id": 688,
        "no_speech_prob": 0.0011694907443597913,
        "seek": 307976,
        "start": 3080.76,
        "temperature": 0,
        "text": " Then I think if I go back to...",
        "tokens": [
          50414,
          1396,
          286,
          519,
          498,
          286,
          352,
          646,
          281,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.30590555960671945,
        "compression_ratio": 1.2765957446808511,
        "end": 3095.76,
        "id": 689,
        "no_speech_prob": 0.0011694907443597913,
        "seek": 307976,
        "start": 3091.76,
        "temperature": 0,
        "text": " No. Train. I do object detection again.",
        "tokens": [
          50964,
          883,
          13,
          28029,
          13,
          286,
          360,
          2657,
          17784,
          797,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.30590555960671945,
        "compression_ratio": 1.2765957446808511,
        "end": 3103.76,
        "id": 690,
        "no_speech_prob": 0.0011694907443597913,
        "seek": 307976,
        "start": 3095.76,
        "temperature": 0,
        "text": " Let's do Rubik's Cube Tiny real time?",
        "tokens": [
          51164,
          961,
          311,
          360,
          10518,
          1035,
          311,
          33003,
          39992,
          957,
          565,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.30590555960671945,
        "compression_ratio": 1.2765957446808511,
        "end": 3107.76,
        "id": 691,
        "no_speech_prob": 0.0011694907443597913,
        "seek": 307976,
        "start": 3103.76,
        "temperature": 0,
        "text": " It's going to let me use a question mark in the name of my experiment.",
        "tokens": [
          51564,
          467,
          311,
          516,
          281,
          718,
          385,
          764,
          257,
          1168,
          1491,
          294,
          264,
          1315,
          295,
          452,
          5120,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2079303874525913,
        "compression_ratio": 1.4723618090452262,
        "end": 3111.76,
        "id": 692,
        "no_speech_prob": 0.001896894071251154,
        "seek": 310776,
        "start": 3107.76,
        "temperature": 0,
        "text": " Take this. I already have these annotations.",
        "tokens": [
          50364,
          3664,
          341,
          13,
          286,
          1217,
          362,
          613,
          25339,
          763,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2079303874525913,
        "compression_ratio": 1.4723618090452262,
        "end": 3116.76,
        "id": 693,
        "no_speech_prob": 0.001896894071251154,
        "seek": 310776,
        "start": 3111.76,
        "temperature": 0,
        "text": " Next, let's choose from YOLO version 3 Tiny.",
        "tokens": [
          50564,
          3087,
          11,
          718,
          311,
          2826,
          490,
          398,
          5046,
          46,
          3037,
          805,
          39992,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2079303874525913,
        "compression_ratio": 1.4723618090452262,
        "end": 3119.76,
        "id": 694,
        "no_speech_prob": 0.001896894071251154,
        "seek": 310776,
        "start": 3116.76,
        "temperature": 0,
        "text": " Now I have both of these going.",
        "tokens": [
          50814,
          823,
          286,
          362,
          1293,
          295,
          613,
          516,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2079303874525913,
        "compression_ratio": 1.4723618090452262,
        "end": 3126.76,
        "id": 695,
        "no_speech_prob": 0.001896894071251154,
        "seek": 310776,
        "start": 3119.76,
        "temperature": 0,
        "text": " We can see them here as my two training experiments that are going.",
        "tokens": [
          50964,
          492,
          393,
          536,
          552,
          510,
          382,
          452,
          732,
          3097,
          12050,
          300,
          366,
          516,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2079303874525913,
        "compression_ratio": 1.4723618090452262,
        "end": 3129.76,
        "id": 696,
        "no_speech_prob": 0.001896894071251154,
        "seek": 310776,
        "start": 3126.76,
        "temperature": 0,
        "text": " Let's open this one in one window.",
        "tokens": [
          51314,
          961,
          311,
          1269,
          341,
          472,
          294,
          472,
          4910,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2079303874525913,
        "compression_ratio": 1.4723618090452262,
        "end": 3133.76,
        "id": 697,
        "no_speech_prob": 0.001896894071251154,
        "seek": 310776,
        "start": 3129.76,
        "temperature": 0,
        "text": " It didn't open in a new window. What did I... Click the wrong thing?",
        "tokens": [
          51464,
          467,
          994,
          380,
          1269,
          294,
          257,
          777,
          4910,
          13,
          708,
          630,
          286,
          485,
          8230,
          264,
          2085,
          551,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2577628640567555,
        "compression_ratio": 1.4213483146067416,
        "end": 3139.76,
        "id": 698,
        "no_speech_prob": 0.0053017656318843365,
        "seek": 313376,
        "start": 3133.76,
        "temperature": 0,
        "text": " Rubik's Cube. I want you to open in a new... Oh, weird.",
        "tokens": [
          50364,
          10518,
          1035,
          311,
          33003,
          13,
          286,
          528,
          291,
          281,
          1269,
          294,
          257,
          777,
          485,
          876,
          11,
          3657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2577628640567555,
        "compression_ratio": 1.4213483146067416,
        "end": 3142.76,
        "id": 699,
        "no_speech_prob": 0.0053017656318843365,
        "seek": 313376,
        "start": 3139.76,
        "temperature": 0,
        "text": " It's like... That's fine.",
        "tokens": [
          50664,
          467,
          311,
          411,
          485,
          663,
          311,
          2489,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2577628640567555,
        "compression_ratio": 1.4213483146067416,
        "end": 3148.76,
        "id": 700,
        "no_speech_prob": 0.0053017656318843365,
        "seek": 313376,
        "start": 3142.76,
        "temperature": 0,
        "text": " Then let's go to Train, Rubik's Cube, Tiny.",
        "tokens": [
          50814,
          1396,
          718,
          311,
          352,
          281,
          28029,
          11,
          10518,
          1035,
          311,
          33003,
          11,
          39992,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2577628640567555,
        "compression_ratio": 1.4213483146067416,
        "end": 3150.76,
        "id": 701,
        "no_speech_prob": 0.0053017656318843365,
        "seek": 313376,
        "start": 3148.76,
        "temperature": 0,
        "text": " We've got them both going.",
        "tokens": [
          51114,
          492,
          600,
          658,
          552,
          1293,
          516,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2577628640567555,
        "compression_ratio": 1.4213483146067416,
        "end": 3154.76,
        "id": 702,
        "no_speech_prob": 0.0053017656318843365,
        "seek": 313376,
        "start": 3150.76,
        "temperature": 0,
        "text": " Now, I'm at the point... Let me just click something here.",
        "tokens": [
          51214,
          823,
          11,
          286,
          478,
          412,
          264,
          935,
          485,
          961,
          385,
          445,
          2052,
          746,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2577628640567555,
        "compression_ratio": 1.4213483146067416,
        "end": 3157.76,
        "id": 703,
        "no_speech_prob": 0.0053017656318843365,
        "seek": 313376,
        "start": 3154.76,
        "temperature": 0,
        "text": " This is really bothering me. There we go.",
        "tokens": [
          51414,
          639,
          307,
          534,
          31432,
          385,
          13,
          821,
          321,
          352,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3169.76,
        "id": 704,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3164.76,
        "temperature": 0,
        "text": " Oh, wow. Louise, it looks like you joined and you made it into the Discord.",
        "tokens": [
          50414,
          876,
          11,
          6076,
          13,
          35962,
          11,
          309,
          1542,
          411,
          291,
          6869,
          293,
          291,
          1027,
          309,
          666,
          264,
          32623,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3171.76,
        "id": 705,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3169.76,
        "temperature": 0,
        "text": " Welcome. That's so exciting.",
        "tokens": [
          50664,
          4027,
          13,
          663,
          311,
          370,
          4670,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3174.76,
        "id": 706,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3171.76,
        "temperature": 0,
        "text": " I wish I could click your messages to bring them up on the screen.",
        "tokens": [
          50764,
          286,
          3172,
          286,
          727,
          2052,
          428,
          7897,
          281,
          1565,
          552,
          493,
          322,
          264,
          2568,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3176.76,
        "id": 707,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3174.76,
        "temperature": 0,
        "text": " Look at this glow that's going on here.",
        "tokens": [
          50914,
          2053,
          412,
          341,
          17513,
          300,
          311,
          516,
          322,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3178.76,
        "id": 708,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3176.76,
        "temperature": 0,
        "text": " I think it's the LEDs there.",
        "tokens": [
          51014,
          286,
          519,
          309,
          311,
          264,
          33366,
          456,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3182.76,
        "id": 709,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3178.76,
        "temperature": 0,
        "text": " What's going to happen now? I now am letting this run.",
        "tokens": [
          51114,
          708,
          311,
          516,
          281,
          1051,
          586,
          30,
          286,
          586,
          669,
          8295,
          341,
          1190,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3185.76,
        "id": 710,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3182.76,
        "temperature": 0,
        "text": " We can see both of these are running.",
        "tokens": [
          51314,
          492,
          393,
          536,
          1293,
          295,
          613,
          366,
          2614,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17861691643210018,
        "compression_ratio": 1.5779467680608366,
        "end": 3190.76,
        "id": 711,
        "no_speech_prob": 0.010651960968971252,
        "seek": 316376,
        "start": 3185.76,
        "temperature": 0,
        "text": " Just to be clear, let me clarify a little bit about what's happening with Runway.",
        "tokens": [
          51464,
          1449,
          281,
          312,
          1850,
          11,
          718,
          385,
          17594,
          257,
          707,
          857,
          466,
          437,
          311,
          2737,
          365,
          8950,
          676,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17194723820948338,
        "compression_ratio": 1.7298578199052133,
        "end": 3195.76,
        "id": 712,
        "no_speech_prob": 0.004264529328793287,
        "seek": 319076,
        "start": 3191.76,
        "temperature": 0,
        "text": " Nothing besides my browser is actually running on this computer right here,",
        "tokens": [
          50414,
          6693,
          11868,
          452,
          11185,
          307,
          767,
          2614,
          322,
          341,
          3820,
          558,
          510,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.17194723820948338,
        "compression_ratio": 1.7298578199052133,
        "end": 3199.76,
        "id": 713,
        "no_speech_prob": 0.004264529328793287,
        "seek": 319076,
        "start": 3195.76,
        "temperature": 0,
        "text": " the one that I am operating here.",
        "tokens": [
          50614,
          264,
          472,
          300,
          286,
          669,
          7447,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17194723820948338,
        "compression_ratio": 1.7298578199052133,
        "end": 3203.76,
        "id": 714,
        "no_speech_prob": 0.004264529328793287,
        "seek": 319076,
        "start": 3199.76,
        "temperature": 0,
        "text": " What I am looking at is a web interface to a set of servers",
        "tokens": [
          50814,
          708,
          286,
          669,
          1237,
          412,
          307,
          257,
          3670,
          9226,
          281,
          257,
          992,
          295,
          15909,
          51014
        ]
      },
      {
        "avg_logprob": -0.17194723820948338,
        "compression_ratio": 1.7298578199052133,
        "end": 3206.76,
        "id": 715,
        "no_speech_prob": 0.004264529328793287,
        "seek": 319076,
        "start": 3203.76,
        "temperature": 0,
        "text": " that are presumably Runway's web servers.",
        "tokens": [
          51014,
          300,
          366,
          26742,
          8950,
          676,
          311,
          3670,
          15909,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17194723820948338,
        "compression_ratio": 1.7298578199052133,
        "end": 3209.76,
        "id": 716,
        "no_speech_prob": 0.004264529328793287,
        "seek": 319076,
        "start": 3206.76,
        "temperature": 0,
        "text": " Runway's web servers are what are hosting up and showing me the interface",
        "tokens": [
          51164,
          8950,
          676,
          311,
          3670,
          15909,
          366,
          437,
          366,
          16058,
          493,
          293,
          4099,
          385,
          264,
          9226,
          51314
        ]
      },
      {
        "avg_logprob": -0.17194723820948338,
        "compression_ratio": 1.7298578199052133,
        "end": 3211.76,
        "id": 717,
        "no_speech_prob": 0.004264529328793287,
        "seek": 319076,
        "start": 3209.76,
        "temperature": 0,
        "text": " and all the status updates.",
        "tokens": [
          51314,
          293,
          439,
          264,
          6558,
          9205,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17194723820948338,
        "compression_ratio": 1.7298578199052133,
        "end": 3217.76,
        "id": 718,
        "no_speech_prob": 0.004264529328793287,
        "seek": 319076,
        "start": 3211.76,
        "temperature": 0,
        "text": " Runway additionally has access to what I'm assuming",
        "tokens": [
          51414,
          8950,
          676,
          43181,
          575,
          2105,
          281,
          437,
          286,
          478,
          11926,
          51714
        ]
      },
      {
        "avg_logprob": -0.18887576350459345,
        "compression_ratio": 1.4545454545454546,
        "end": 3222.76,
        "id": 719,
        "no_speech_prob": 0.0010322192683815956,
        "seek": 321776,
        "start": 3217.76,
        "temperature": 0,
        "text": " is a large number of GPU optimized for machine learning cloud servers.",
        "tokens": [
          50364,
          307,
          257,
          2416,
          1230,
          295,
          18407,
          26941,
          337,
          3479,
          2539,
          4588,
          15909,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18887576350459345,
        "compression_ratio": 1.4545454545454546,
        "end": 3228.76,
        "id": 720,
        "no_speech_prob": 0.0010322192683815956,
        "seek": 321776,
        "start": 3222.76,
        "temperature": 0,
        "text": " What you're paying for when you sign up for Runway and use Runway",
        "tokens": [
          50614,
          708,
          291,
          434,
          6229,
          337,
          562,
          291,
          1465,
          493,
          337,
          8950,
          676,
          293,
          764,
          8950,
          676,
          50914
        ]
      },
      {
        "avg_logprob": -0.18887576350459345,
        "compression_ratio": 1.4545454545454546,
        "end": 3232.76,
        "id": 721,
        "no_speech_prob": 0.0010322192683815956,
        "seek": 321776,
        "start": 3228.76,
        "temperature": 0,
        "text": " is ease and efficiency really in many ways.",
        "tokens": [
          50914,
          307,
          12708,
          293,
          10493,
          534,
          294,
          867,
          2098,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18887576350459345,
        "compression_ratio": 1.4545454545454546,
        "end": 3237.76,
        "id": 722,
        "no_speech_prob": 0.0010322192683815956,
        "seek": 321776,
        "start": 3232.76,
        "temperature": 0,
        "text": " In theory, I have a Windows PC over here with a pretty good graphics card.",
        "tokens": [
          51114,
          682,
          5261,
          11,
          286,
          362,
          257,
          8591,
          6465,
          670,
          510,
          365,
          257,
          1238,
          665,
          11837,
          2920,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18887576350459345,
        "compression_ratio": 1.4545454545454546,
        "end": 3245.76,
        "id": 723,
        "no_speech_prob": 0.0010322192683815956,
        "seek": 321776,
        "start": 3237.76,
        "temperature": 0,
        "text": " Maybe I could figure out how to set it up with a training system",
        "tokens": [
          51364,
          2704,
          286,
          727,
          2573,
          484,
          577,
          281,
          992,
          309,
          493,
          365,
          257,
          3097,
          1185,
          51764
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3250.76,
        "id": 724,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3245.76,
        "temperature": 0,
        "text": " and CUDA and tiny YOLO version 4 and all the stuff that I need",
        "tokens": [
          50364,
          293,
          29777,
          7509,
          293,
          5870,
          398,
          5046,
          46,
          3037,
          1017,
          293,
          439,
          264,
          1507,
          300,
          286,
          643,
          50614
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3254.76,
        "id": 725,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3250.76,
        "temperature": 0,
        "text": " to just train my model right over here on my own computer.",
        "tokens": [
          50614,
          281,
          445,
          3847,
          452,
          2316,
          558,
          670,
          510,
          322,
          452,
          1065,
          3820,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3259.76,
        "id": 726,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3254.76,
        "temperature": 0,
        "text": " But by having Runway have access to a pre-configured",
        "tokens": [
          50814,
          583,
          538,
          1419,
          8950,
          676,
          362,
          2105,
          281,
          257,
          659,
          12,
          1671,
          20646,
          3831,
          51064
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3263.76,
        "id": 727,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3259.76,
        "temperature": 0,
        "text": " and ready-to-go cloud server with all of the dependencies",
        "tokens": [
          51064,
          293,
          1919,
          12,
          1353,
          12,
          1571,
          4588,
          7154,
          365,
          439,
          295,
          264,
          36606,
          51264
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3265.76,
        "id": 728,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3263.76,
        "temperature": 0,
        "text": " and configuration settings it needs,",
        "tokens": [
          51264,
          293,
          11694,
          6257,
          309,
          2203,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3267.76,
        "id": 729,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3265.76,
        "temperature": 0,
        "text": " I can just upload my files, annotate them,",
        "tokens": [
          51364,
          286,
          393,
          445,
          6580,
          452,
          7098,
          11,
          25339,
          473,
          552,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3269.76,
        "id": 730,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3267.76,
        "temperature": 0,
        "text": " press a button for training and it's going to run it",
        "tokens": [
          51464,
          1886,
          257,
          2960,
          337,
          3097,
          293,
          309,
          311,
          516,
          281,
          1190,
          309,
          51564
        ]
      },
      {
        "avg_logprob": -0.17672416620087206,
        "compression_ratio": 1.5485074626865671,
        "end": 3273.76,
        "id": 731,
        "no_speech_prob": 0.015905873849987984,
        "seek": 324576,
        "start": 3269.76,
        "temperature": 0,
        "text": " and then make the finished model available to me.",
        "tokens": [
          51564,
          293,
          550,
          652,
          264,
          4335,
          2316,
          2435,
          281,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3275.76,
        "id": 732,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3273.76,
        "temperature": 0,
        "text": " You could certainly do the same kind of thing also",
        "tokens": [
          50364,
          509,
          727,
          3297,
          360,
          264,
          912,
          733,
          295,
          551,
          611,
          50464
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3280.76,
        "id": 733,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3275.76,
        "temperature": 0,
        "text": " with a Google Colab notebook, an AWS instance,",
        "tokens": [
          50464,
          365,
          257,
          3329,
          4004,
          455,
          21060,
          11,
          364,
          17650,
          5197,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3284.76,
        "id": 734,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3280.76,
        "temperature": 0,
        "text": " Spell, PaperSpace.",
        "tokens": [
          50714,
          3550,
          285,
          11,
          24990,
          44306,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3286.76,
        "id": 735,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3284.76,
        "temperature": 0,
        "text": " These are other kinds of cloud-based services",
        "tokens": [
          50914,
          1981,
          366,
          661,
          3685,
          295,
          4588,
          12,
          6032,
          3328,
          51014
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3290.76,
        "id": 736,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3286.76,
        "temperature": 0,
        "text": " that have GPU-enabled machines that you can do machine learning",
        "tokens": [
          51014,
          300,
          362,
          18407,
          12,
          268,
          8909,
          8379,
          300,
          291,
          393,
          360,
          3479,
          2539,
          51214
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3292.76,
        "id": 737,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3290.76,
        "temperature": 0,
        "text": " and other things on.",
        "tokens": [
          51214,
          293,
          661,
          721,
          322,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3295.76,
        "id": 738,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3292.76,
        "temperature": 0,
        "text": " Runway is kind of my favorite tool du jour to use.",
        "tokens": [
          51314,
          8950,
          676,
          307,
          733,
          295,
          452,
          2954,
          2290,
          1581,
          2827,
          281,
          764,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18918316773693972,
        "compression_ratio": 1.547008547008547,
        "end": 3298.76,
        "id": 739,
        "no_speech_prob": 0.0013884950894862413,
        "seek": 327376,
        "start": 3295.76,
        "temperature": 0,
        "text": " And one of the things that is the most exciting about it for me",
        "tokens": [
          51464,
          400,
          472,
          295,
          264,
          721,
          300,
          307,
          264,
          881,
          4670,
          466,
          309,
          337,
          385,
          51614
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3303.76,
        "id": 740,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3298.76,
        "temperature": 0,
        "text": " is just this huge library of models that I have access to.",
        "tokens": [
          50364,
          307,
          445,
          341,
          2603,
          6405,
          295,
          5245,
          300,
          286,
          362,
          2105,
          281,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3305.76,
        "id": 741,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3303.76,
        "temperature": 0,
        "text": " And these are new actually.",
        "tokens": [
          50614,
          400,
          613,
          366,
          777,
          767,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3309.76,
        "id": 742,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3305.76,
        "temperature": 0,
        "text": " There's a YouTube channel called Artificial Images.",
        "tokens": [
          50714,
          821,
          311,
          257,
          3088,
          2269,
          1219,
          5735,
          10371,
          4331,
          1660,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3311.76,
        "id": 743,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3309.76,
        "temperature": 0,
        "text": " I don't know who runs this channel,",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          567,
          6676,
          341,
          2269,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3314.76,
        "id": 744,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3311.76,
        "temperature": 0,
        "text": " but I've been recently quite tuned into it",
        "tokens": [
          51014,
          457,
          286,
          600,
          668,
          3938,
          1596,
          10870,
          666,
          309,
          51164
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3318.76,
        "id": 745,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3314.76,
        "temperature": 0,
        "text": " and it's been using Runway for a lot of things,",
        "tokens": [
          51164,
          293,
          309,
          311,
          668,
          1228,
          8950,
          676,
          337,
          257,
          688,
          295,
          721,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3321.76,
        "id": 746,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3318.76,
        "temperature": 0,
        "text": " making a data set, a walkthrough tutorial.",
        "tokens": [
          51364,
          1455,
          257,
          1412,
          992,
          11,
          257,
          1792,
          11529,
          7073,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3322.76,
        "id": 747,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3321.76,
        "temperature": 0,
        "text": " So this is all great.",
        "tokens": [
          51514,
          407,
          341,
          307,
          439,
          869,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3324.76,
        "id": 748,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3322.76,
        "temperature": 0,
        "text": " I really got to check some of this stuff out.",
        "tokens": [
          51564,
          286,
          534,
          658,
          281,
          1520,
          512,
          295,
          341,
          1507,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16162186284219066,
        "compression_ratio": 1.5919117647058822,
        "end": 3327.76,
        "id": 749,
        "no_speech_prob": 0.20944464206695557,
        "seek": 329876,
        "start": 3324.76,
        "temperature": 0,
        "text": " And I'm kind of trying to do some of this kinds of stuff",
        "tokens": [
          51664,
          400,
          286,
          478,
          733,
          295,
          1382,
          281,
          360,
          512,
          295,
          341,
          3685,
          295,
          1507,
          51814
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3329.76,
        "id": 750,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3327.76,
        "temperature": 0,
        "text": " on my channel as well.",
        "tokens": [
          50364,
          322,
          452,
          2269,
          382,
          731,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3330.76,
        "id": 751,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3329.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50464,
          1057,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3333.76,
        "id": 752,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3330.76,
        "temperature": 0,
        "text": " So what I think I would like...",
        "tokens": [
          50514,
          407,
          437,
          286,
          519,
          286,
          576,
          411,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3336.76,
        "id": 753,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3333.76,
        "temperature": 0,
        "text": " I'm going to do a couple of things here.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          360,
          257,
          1916,
          295,
          721,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3338.76,
        "id": 754,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3336.76,
        "temperature": 0,
        "text": " I really messed up.",
        "tokens": [
          50814,
          286,
          534,
          16507,
          493,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3345.76,
        "id": 755,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3338.76,
        "temperature": 0,
        "text": " So I apologize for this because I'm totally going to ruin everything right now.",
        "tokens": [
          50914,
          407,
          286,
          12328,
          337,
          341,
          570,
          286,
          478,
          3879,
          516,
          281,
          15514,
          1203,
          558,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3348.76,
        "id": 756,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3345.76,
        "temperature": 0,
        "text": " I'm going to check back on these models in a little while.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          1520,
          646,
          322,
          613,
          5245,
          294,
          257,
          707,
          1339,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3352.76,
        "id": 757,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3348.76,
        "temperature": 0,
        "text": " I have two Runway accounts because I want to be able to have an account",
        "tokens": [
          51414,
          286,
          362,
          732,
          8950,
          676,
          9402,
          570,
          286,
          528,
          281,
          312,
          1075,
          281,
          362,
          364,
          2696,
          51614
        ]
      },
      {
        "avg_logprob": -0.20243092764795353,
        "compression_ratio": 1.6751054852320675,
        "end": 3356.76,
        "id": 758,
        "no_speech_prob": 0.003884441452100873,
        "seek": 332776,
        "start": 3352.76,
        "temperature": 0,
        "text": " with Runway where I can upload data and do things in Runway",
        "tokens": [
          51614,
          365,
          8950,
          676,
          689,
          286,
          393,
          6580,
          1412,
          293,
          360,
          721,
          294,
          8950,
          676,
          51814
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3359.76,
        "id": 759,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3356.76,
        "temperature": 0,
        "text": " with my own private data, so to speak.",
        "tokens": [
          50364,
          365,
          452,
          1065,
          4551,
          1412,
          11,
          370,
          281,
          1710,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3363.76,
        "id": 760,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3359.76,
        "temperature": 0,
        "text": " I don't really have an example of data that I want to use with Runway",
        "tokens": [
          50514,
          286,
          500,
          380,
          534,
          362,
          364,
          1365,
          295,
          1412,
          300,
          286,
          528,
          281,
          764,
          365,
          8950,
          676,
          50714
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3366.76,
        "id": 761,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3363.76,
        "temperature": 0,
        "text": " that's private right now, but I often do this with lots of things.",
        "tokens": [
          50714,
          300,
          311,
          4551,
          558,
          586,
          11,
          457,
          286,
          2049,
          360,
          341,
          365,
          3195,
          295,
          721,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3370.76,
        "id": 762,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3366.76,
        "temperature": 0,
        "text": " I have a separate account, which is the one I stray logged into on streaming,",
        "tokens": [
          50864,
          286,
          362,
          257,
          4994,
          2696,
          11,
          597,
          307,
          264,
          472,
          286,
          36219,
          27231,
          666,
          322,
          11791,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3374.76,
        "id": 763,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3370.76,
        "temperature": 0,
        "text": " so I don't by accident open my email and that sort of thing.",
        "tokens": [
          51064,
          370,
          286,
          500,
          380,
          538,
          6398,
          1269,
          452,
          3796,
          293,
          300,
          1333,
          295,
          551,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3377.76,
        "id": 764,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3374.76,
        "temperature": 0,
        "text": " But I messed up and this Shiffman Runway account is the one",
        "tokens": [
          51264,
          583,
          286,
          16507,
          493,
          293,
          341,
          1160,
          3661,
          1601,
          8950,
          676,
          2696,
          307,
          264,
          472,
          51414
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3380.76,
        "id": 765,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3377.76,
        "temperature": 0,
        "text": " that I intended to be my private account.",
        "tokens": [
          51414,
          300,
          286,
          10226,
          281,
          312,
          452,
          4551,
          2696,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21614181518554687,
        "compression_ratio": 1.7432950191570882,
        "end": 3381.76,
        "id": 766,
        "no_speech_prob": 0.011507922783493996,
        "seek": 335676,
        "start": 3380.76,
        "temperature": 0,
        "text": " But I'm already training these models.",
        "tokens": [
          51564,
          583,
          286,
          478,
          1217,
          3097,
          613,
          5245,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3386.76,
        "id": 767,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3381.76,
        "temperature": 0,
        "text": " I'm not going to, but I'm going to log out",
        "tokens": [
          50364,
          286,
          478,
          406,
          516,
          281,
          11,
          457,
          286,
          478,
          516,
          281,
          3565,
          484,
          50614
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3388.76,
        "id": 768,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3386.76,
        "temperature": 0,
        "text": " and I'll come back to check on them in a little bit.",
        "tokens": [
          50614,
          293,
          286,
          603,
          808,
          646,
          281,
          1520,
          322,
          552,
          294,
          257,
          707,
          857,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3391.76,
        "id": 769,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3388.76,
        "temperature": 0,
        "text": " I'm going to go to my CodingTrain one.",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          352,
          281,
          452,
          383,
          8616,
          51,
          7146,
          472,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3394.76,
        "id": 770,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3391.76,
        "temperature": 0,
        "text": " Ah! Ah!",
        "tokens": [
          50864,
          2438,
          0,
          2438,
          0,
          51014
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3395.76,
        "id": 771,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3394.76,
        "temperature": 0,
        "text": " I can't get this right.",
        "tokens": [
          51014,
          286,
          393,
          380,
          483,
          341,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3397.76,
        "id": 772,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3395.76,
        "temperature": 0,
        "text": " I've done this so many times.",
        "tokens": [
          51064,
          286,
          600,
          1096,
          341,
          370,
          867,
          1413,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3400.76,
        "id": 773,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3397.76,
        "temperature": 0,
        "text": " Oh, I know what's going on.",
        "tokens": [
          51164,
          876,
          11,
          286,
          458,
          437,
          311,
          516,
          322,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3405.76,
        "id": 774,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3400.76,
        "temperature": 0,
        "text": " I also have different logins to this browser and it's fine.",
        "tokens": [
          51314,
          286,
          611,
          362,
          819,
          3565,
          1292,
          281,
          341,
          11185,
          293,
          309,
          311,
          2489,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3406.76,
        "id": 775,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3405.76,
        "temperature": 0,
        "text": " It's fine. Everything's going to be fine.",
        "tokens": [
          51564,
          467,
          311,
          2489,
          13,
          5471,
          311,
          516,
          281,
          312,
          2489,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2000657570462267,
        "compression_ratio": 1.6027397260273972,
        "end": 3408.76,
        "id": 776,
        "no_speech_prob": 0.14413771033287048,
        "seek": 338176,
        "start": 3406.76,
        "temperature": 0,
        "text": " Talk amongst yourselves.",
        "tokens": [
          51614,
          8780,
          12918,
          14791,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3443.76,
        "id": 777,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3439.76,
        "temperature": 0,
        "text": " OK. So now I'm in my ChooChoo account.",
        "tokens": [
          50414,
          2264,
          13,
          407,
          586,
          286,
          478,
          294,
          452,
          761,
          1986,
          6546,
          1986,
          2696,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3448.76,
        "id": 778,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3443.76,
        "temperature": 0,
        "text": " And we can see here that I've actually been working with this already",
        "tokens": [
          50614,
          400,
          321,
          393,
          536,
          510,
          300,
          286,
          600,
          767,
          668,
          1364,
          365,
          341,
          1217,
          50864
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3450.76,
        "id": 779,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3448.76,
        "temperature": 0,
        "text": " this past week.",
        "tokens": [
          50864,
          341,
          1791,
          1243,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3453.76,
        "id": 780,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3450.76,
        "temperature": 0,
        "text": " I have some really weird models that I was training.",
        "tokens": [
          50964,
          286,
          362,
          512,
          534,
          3657,
          5245,
          300,
          286,
          390,
          3097,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3455.76,
        "id": 781,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3453.76,
        "temperature": 0,
        "text": " Let's take a look at this one.",
        "tokens": [
          51114,
          961,
          311,
          747,
          257,
          574,
          412,
          341,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3457.76,
        "id": 782,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3455.76,
        "temperature": 0,
        "text": " This is not what I meant to show you.",
        "tokens": [
          51214,
          639,
          307,
          406,
          437,
          286,
          4140,
          281,
          855,
          291,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3460.76,
        "id": 783,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3457.76,
        "temperature": 0,
        "text": " Add to workspace.",
        "tokens": [
          51314,
          5349,
          281,
          32706,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3462.76,
        "id": 784,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3460.76,
        "temperature": 0,
        "text": " What is going on here?",
        "tokens": [
          51464,
          708,
          307,
          516,
          322,
          510,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3464.76,
        "id": 785,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3462.76,
        "temperature": 0,
        "text": " Oh, wait. Why do I have workspace?",
        "tokens": [
          51564,
          876,
          11,
          1699,
          13,
          1545,
          360,
          286,
          362,
          32706,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.21066599154691085,
        "compression_ratio": 1.566820276497696,
        "end": 3466.76,
        "id": 786,
        "no_speech_prob": 0.0017821833025664091,
        "seek": 343876,
        "start": 3464.76,
        "temperature": 0,
        "text": " Model workspaces.",
        "tokens": [
          51664,
          17105,
          1985,
          79,
          2116,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3468.76,
        "id": 787,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3466.76,
        "temperature": 0,
        "text": " What is going on?",
        "tokens": [
          50364,
          708,
          307,
          516,
          322,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3471.76,
        "id": 788,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3468.76,
        "temperature": 0,
        "text": " I think Runway changed its interface.",
        "tokens": [
          50464,
          286,
          519,
          8950,
          676,
          3105,
          1080,
          9226,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3473.76,
        "id": 789,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3471.76,
        "temperature": 0,
        "text": " My model's train hosted.",
        "tokens": [
          50614,
          1222,
          2316,
          311,
          3847,
          19204,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3475.76,
        "id": 790,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3473.76,
        "temperature": 0,
        "text": " This looks different.",
        "tokens": [
          50714,
          639,
          1542,
          819,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3478.76,
        "id": 791,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3475.76,
        "temperature": 0,
        "text": " I got to create a workspace.",
        "tokens": [
          50814,
          286,
          658,
          281,
          1884,
          257,
          32706,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3479.76,
        "id": 792,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3478.76,
        "temperature": 0,
        "text": " Add to workspace. OK, fine.",
        "tokens": [
          50964,
          5349,
          281,
          32706,
          13,
          2264,
          11,
          2489,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3480.76,
        "id": 793,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3479.76,
        "temperature": 0,
        "text": " New workspace.",
        "tokens": [
          51014,
          1873,
          32706,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3485.76,
        "id": 794,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3480.76,
        "temperature": 0,
        "text": " CodingTrainDemos.",
        "tokens": [
          51064,
          383,
          8616,
          51,
          7146,
          35,
          4485,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25181562689286247,
        "compression_ratio": 1.3964497041420119,
        "end": 3492.76,
        "id": 795,
        "no_speech_prob": 0.00024156604195013642,
        "seek": 346676,
        "start": 3487.76,
        "temperature": 0,
        "text": " And let's just run this model for a second.",
        "tokens": [
          51414,
          400,
          718,
          311,
          445,
          1190,
          341,
          2316,
          337,
          257,
          1150,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.210867366571536,
        "compression_ratio": 1.5852534562211982,
        "end": 3497.76,
        "id": 796,
        "no_speech_prob": 0.004198724869638681,
        "seek": 349276,
        "start": 3492.76,
        "temperature": 0,
        "text": " So this model is a StyleGAN model that I just trained off of images of my face",
        "tokens": [
          50364,
          407,
          341,
          2316,
          307,
          257,
          27004,
          27699,
          2316,
          300,
          286,
          445,
          8895,
          766,
          295,
          5267,
          295,
          452,
          1851,
          50614
        ]
      },
      {
        "avg_logprob": -0.210867366571536,
        "compression_ratio": 1.5852534562211982,
        "end": 3501.76,
        "id": 797,
        "no_speech_prob": 0.004198724869638681,
        "seek": 349276,
        "start": 3497.76,
        "temperature": 0,
        "text": " looking at different directions, wearing different glasses and things like that.",
        "tokens": [
          50614,
          1237,
          412,
          819,
          11095,
          11,
          4769,
          819,
          10812,
          293,
          721,
          411,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.210867366571536,
        "compression_ratio": 1.5852534562211982,
        "end": 3507.76,
        "id": 798,
        "no_speech_prob": 0.004198724869638681,
        "seek": 349276,
        "start": 3501.76,
        "temperature": 0,
        "text": " So I wanted to start with a StyleGAN model.",
        "tokens": [
          50814,
          407,
          286,
          1415,
          281,
          722,
          365,
          257,
          27004,
          27699,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.210867366571536,
        "compression_ratio": 1.5852534562211982,
        "end": 3510.76,
        "id": 799,
        "no_speech_prob": 0.004198724869638681,
        "seek": 349276,
        "start": 3507.76,
        "temperature": 0,
        "text": " I probably should just go to the SkyGAN one, which is what I was actually using,",
        "tokens": [
          51114,
          286,
          1391,
          820,
          445,
          352,
          281,
          264,
          9879,
          27699,
          472,
          11,
          597,
          307,
          437,
          286,
          390,
          767,
          1228,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.210867366571536,
        "compression_ratio": 1.5852534562211982,
        "end": 3515.76,
        "id": 800,
        "no_speech_prob": 0.004198724869638681,
        "seek": 349276,
        "start": 3510.76,
        "temperature": 0,
        "text": " just to demonstrate the next phase of what I'm going to do,",
        "tokens": [
          51264,
          445,
          281,
          11698,
          264,
          958,
          5574,
          295,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.21276203791300455,
        "compression_ratio": 1.4553990610328638,
        "end": 3525.76,
        "id": 801,
        "no_speech_prob": 0.019123805686831474,
        "seek": 351576,
        "start": 3515.76,
        "temperature": 0,
        "text": " which is demonstrate how to use Runway beyond just the interface itself",
        "tokens": [
          50364,
          597,
          307,
          11698,
          577,
          281,
          764,
          8950,
          676,
          4399,
          445,
          264,
          9226,
          2564,
          50864
        ]
      },
      {
        "avg_logprob": -0.21276203791300455,
        "compression_ratio": 1.4553990610328638,
        "end": 3529.76,
        "id": 802,
        "no_speech_prob": 0.019123805686831474,
        "seek": 351576,
        "start": 3525.76,
        "temperature": 0,
        "text": " and essentially treat it as an API with your own code.",
        "tokens": [
          50864,
          293,
          4476,
          2387,
          309,
          382,
          364,
          9362,
          365,
          428,
          1065,
          3089,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21276203791300455,
        "compression_ratio": 1.4553990610328638,
        "end": 3533.76,
        "id": 803,
        "no_speech_prob": 0.019123805686831474,
        "seek": 351576,
        "start": 3529.76,
        "temperature": 0,
        "text": " And any moment now, it looks like it's about to spin up.",
        "tokens": [
          51064,
          400,
          604,
          1623,
          586,
          11,
          309,
          1542,
          411,
          309,
          311,
          466,
          281,
          6060,
          493,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21276203791300455,
        "compression_ratio": 1.4553990610328638,
        "end": 3537.76,
        "id": 804,
        "no_speech_prob": 0.019123805686831474,
        "seek": 351576,
        "start": 3533.76,
        "temperature": 0,
        "text": " It's got this model running in the cloud, my Dan faces StyleGAN model.",
        "tokens": [
          51264,
          467,
          311,
          658,
          341,
          2316,
          2614,
          294,
          264,
          4588,
          11,
          452,
          3394,
          8475,
          27004,
          27699,
          2316,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21276203791300455,
        "compression_ratio": 1.4553990610328638,
        "end": 3541.76,
        "id": 805,
        "no_speech_prob": 0.019123805686831474,
        "seek": 351576,
        "start": 3537.76,
        "temperature": 0,
        "text": " So just to be clear, this is not an actual photo of me.",
        "tokens": [
          51464,
          407,
          445,
          281,
          312,
          1850,
          11,
          341,
          307,
          406,
          364,
          3539,
          5052,
          295,
          385,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3548.76,
        "id": 806,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3542.76,
        "temperature": 0,
        "text": " This is a StyleGAN generated version.",
        "tokens": [
          50414,
          639,
          307,
          257,
          27004,
          27699,
          10833,
          3037,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3553.76,
        "id": 807,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3548.76,
        "temperature": 0,
        "text": " You can see it's got some kind of weird aspects to it.",
        "tokens": [
          50714,
          509,
          393,
          536,
          309,
          311,
          658,
          512,
          733,
          295,
          3657,
          7270,
          281,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3555.76,
        "id": 808,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3553.76,
        "temperature": 0,
        "text": " I mean, I do look kind of like that.",
        "tokens": [
          50964,
          286,
          914,
          11,
          286,
          360,
          574,
          733,
          295,
          411,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3556.76,
        "id": 809,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3555.76,
        "temperature": 0,
        "text": " I was wearing this shirt.",
        "tokens": [
          51064,
          286,
          390,
          4769,
          341,
          8336,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3560.76,
        "id": 810,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3556.76,
        "temperature": 0,
        "text": " I was standing in front of a green screen when I collected this data set.",
        "tokens": [
          51114,
          286,
          390,
          4877,
          294,
          1868,
          295,
          257,
          3092,
          2568,
          562,
          286,
          11087,
          341,
          1412,
          992,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3565.76,
        "id": 811,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3560.76,
        "temperature": 0,
        "text": " And we can actually sort of start to move around in the latent space of me.",
        "tokens": [
          51314,
          400,
          321,
          393,
          767,
          1333,
          295,
          722,
          281,
          1286,
          926,
          294,
          264,
          48994,
          1901,
          295,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3567.76,
        "id": 812,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3565.76,
        "temperature": 0,
        "text": " Oh, my God. So weird.",
        "tokens": [
          51564,
          876,
          11,
          452,
          1265,
          13,
          407,
          3657,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3568.76,
        "id": 813,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3567.76,
        "temperature": 0,
        "text": " What have I done?",
        "tokens": [
          51664,
          708,
          362,
          286,
          1096,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.1826300234407992,
        "compression_ratio": 1.5518672199170125,
        "end": 3570.76,
        "id": 814,
        "no_speech_prob": 0.013020160607993603,
        "seek": 354176,
        "start": 3568.76,
        "temperature": 0,
        "text": " What monster have I created?",
        "tokens": [
          51714,
          708,
          10090,
          362,
          286,
          2942,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3575.76,
        "id": 815,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3570.76,
        "temperature": 0,
        "text": " So creating an image synthesis model is one that you can do.",
        "tokens": [
          50364,
          407,
          4084,
          364,
          3256,
          30252,
          2316,
          307,
          472,
          300,
          291,
          393,
          360,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3578.76,
        "id": 816,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3575.76,
        "temperature": 0,
        "text": " And I need to – I really need to get my act together",
        "tokens": [
          50614,
          400,
          286,
          643,
          281,
          220,
          5815,
          286,
          534,
          643,
          281,
          483,
          452,
          605,
          1214,
          50764
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3581.76,
        "id": 817,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3578.76,
        "temperature": 0,
        "text": " and do a whole bunch of sequenced video tutorials about this process.",
        "tokens": [
          50764,
          293,
          360,
          257,
          1379,
          3840,
          295,
          5123,
          14672,
          960,
          17616,
          466,
          341,
          1399,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3583.76,
        "id": 818,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3581.76,
        "temperature": 0,
        "text": " Right now, I'm just kind of playing with it.",
        "tokens": [
          50914,
          1779,
          586,
          11,
          286,
          478,
          445,
          733,
          295,
          2433,
          365,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3585.76,
        "id": 819,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3583.76,
        "temperature": 0,
        "text": " But let's move on over to Glitch.",
        "tokens": [
          51014,
          583,
          718,
          311,
          1286,
          322,
          670,
          281,
          5209,
          1549,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3586.76,
        "id": 820,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3585.76,
        "temperature": 0,
        "text": " I'm going to hit Stop.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          2045,
          5535,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3590.76,
        "id": 821,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3586.76,
        "temperature": 0,
        "text": " So I believe the current pricing on Runway is about like $0.05 per minute",
        "tokens": [
          51164,
          407,
          286,
          1697,
          264,
          2190,
          17621,
          322,
          8950,
          676,
          307,
          466,
          411,
          1848,
          15,
          13,
          13328,
          680,
          3456,
          51364
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3593.76,
        "id": 822,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3590.76,
        "temperature": 0,
        "text": " when you're running the model in the cloud.",
        "tokens": [
          51364,
          562,
          291,
          434,
          2614,
          264,
          2316,
          294,
          264,
          4588,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16935135661691858,
        "compression_ratio": 1.5742574257425743,
        "end": 3597.76,
        "id": 823,
        "no_speech_prob": 0.002631658222526312,
        "seek": 357076,
        "start": 3593.76,
        "temperature": 0,
        "text": " So I'm going to hit Stop so that I don't use up too many of my credits.",
        "tokens": [
          51514,
          407,
          286,
          478,
          516,
          281,
          2045,
          5535,
          370,
          300,
          286,
          500,
          380,
          764,
          493,
          886,
          867,
          295,
          452,
          16816,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15923822066363166,
        "compression_ratio": 1.5076923076923077,
        "end": 3602.76,
        "id": 824,
        "no_speech_prob": 0.0005193035467527807,
        "seek": 359776,
        "start": 3597.76,
        "temperature": 0,
        "text": " And I am going to go over to this here called Runway ML Template.",
        "tokens": [
          50364,
          400,
          286,
          669,
          516,
          281,
          352,
          670,
          281,
          341,
          510,
          1219,
          8950,
          676,
          21601,
          39563,
          473,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15923822066363166,
        "compression_ratio": 1.5076923076923077,
        "end": 3604.76,
        "id": 825,
        "no_speech_prob": 0.0005193035467527807,
        "seek": 359776,
        "start": 3602.76,
        "temperature": 0,
        "text": " And I'm going to hit Edit Project.",
        "tokens": [
          50614,
          400,
          286,
          478,
          516,
          281,
          2045,
          33241,
          9849,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15923822066363166,
        "compression_ratio": 1.5076923076923077,
        "end": 3606.76,
        "id": 826,
        "no_speech_prob": 0.0005193035467527807,
        "seek": 359776,
        "start": 3604.76,
        "temperature": 0,
        "text": " I wonder if this one is actually running.",
        "tokens": [
          50714,
          286,
          2441,
          498,
          341,
          472,
          307,
          767,
          2614,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15923822066363166,
        "compression_ratio": 1.5076923076923077,
        "end": 3612.76,
        "id": 827,
        "no_speech_prob": 0.0005193035467527807,
        "seek": 359776,
        "start": 3606.76,
        "temperature": 0,
        "text": " I think I disabled the model.",
        "tokens": [
          50814,
          286,
          519,
          286,
          15191,
          264,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15923822066363166,
        "compression_ratio": 1.5076923076923077,
        "end": 3615.76,
        "id": 828,
        "no_speech_prob": 0.0005193035467527807,
        "seek": 359776,
        "start": 3612.76,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51114,
          961,
          311,
          536,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15923822066363166,
        "compression_ratio": 1.5076923076923077,
        "end": 3617.76,
        "id": 829,
        "no_speech_prob": 0.0005193035467527807,
        "seek": 359776,
        "start": 3615.76,
        "temperature": 0,
        "text": " It actually doesn't look like I disabled it",
        "tokens": [
          51264,
          467,
          767,
          1177,
          380,
          574,
          411,
          286,
          15191,
          309,
          51364
        ]
      },
      {
        "avg_logprob": -0.15923822066363166,
        "compression_ratio": 1.5076923076923077,
        "end": 3626.76,
        "id": 830,
        "no_speech_prob": 0.0005193035467527807,
        "seek": 359776,
        "start": 3617.76,
        "temperature": 0,
        "text": " because I think if I disabled the model, it would have already –",
        "tokens": [
          51364,
          570,
          286,
          519,
          498,
          286,
          15191,
          264,
          2316,
          11,
          309,
          576,
          362,
          1217,
          1662,
          51814
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3628.76,
        "id": 831,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3626.76,
        "temperature": 0,
        "text": " it would have already given me an error message.",
        "tokens": [
          50364,
          309,
          576,
          362,
          1217,
          2212,
          385,
          364,
          6713,
          3636,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3631.76,
        "id": 832,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3628.76,
        "temperature": 0,
        "text": " So one of the things you can do with Runway is once you have a model",
        "tokens": [
          50464,
          407,
          472,
          295,
          264,
          721,
          291,
          393,
          360,
          365,
          8950,
          676,
          307,
          1564,
          291,
          362,
          257,
          2316,
          50614
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3635.76,
        "id": 833,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3631.76,
        "temperature": 0,
        "text": " like this Coding Train Dan Faces one,",
        "tokens": [
          50614,
          411,
          341,
          383,
          8616,
          28029,
          3394,
          479,
          2116,
          472,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3640.76,
        "id": 834,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3635.76,
        "temperature": 0,
        "text": " I can go click over here onto Network and I can host this model.",
        "tokens": [
          50814,
          286,
          393,
          352,
          2052,
          670,
          510,
          3911,
          12640,
          293,
          286,
          393,
          3975,
          341,
          2316,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3643.76,
        "id": 835,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3640.76,
        "temperature": 0,
        "text": " So I've done this kind of stuff previously probably about a year ago",
        "tokens": [
          51064,
          407,
          286,
          600,
          1096,
          341,
          733,
          295,
          1507,
          8046,
          1391,
          466,
          257,
          1064,
          2057,
          51214
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3645.76,
        "id": 836,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3643.76,
        "temperature": 0,
        "text": " and I used the Runway desktop software.",
        "tokens": [
          51214,
          293,
          286,
          1143,
          264,
          8950,
          676,
          14502,
          4722,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3647.76,
        "id": 837,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3645.76,
        "temperature": 0,
        "text": " That is still something you can use.",
        "tokens": [
          51314,
          663,
          307,
          920,
          746,
          291,
          393,
          764,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3650.76,
        "id": 838,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3647.76,
        "temperature": 0,
        "text": " I really prefer – the mic is off.",
        "tokens": [
          51414,
          286,
          534,
          4382,
          1662,
          264,
          3123,
          307,
          766,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16691431723350336,
        "compression_ratio": 1.6119402985074627,
        "end": 3653.76,
        "id": 839,
        "no_speech_prob": 0.03210006281733513,
        "seek": 362676,
        "start": 3650.76,
        "temperature": 0,
        "text": " I don't think the mic is off.",
        "tokens": [
          51564,
          286,
          500,
          380,
          519,
          264,
          3123,
          307,
          766,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3657.76,
        "id": 840,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3653.76,
        "temperature": 0,
        "text": " I am seeing everything working just fine.",
        "tokens": [
          50364,
          286,
          669,
          2577,
          1203,
          1364,
          445,
          2489,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3662.76,
        "id": 841,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3657.76,
        "temperature": 0,
        "text": " So hopefully somebody else will tell me and confirm.",
        "tokens": [
          50564,
          407,
          4696,
          2618,
          1646,
          486,
          980,
          385,
          293,
          9064,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3665.76,
        "id": 842,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3662.76,
        "temperature": 0,
        "text": " I think if the mic was off, I'd be getting a lot more messages.",
        "tokens": [
          50814,
          286,
          519,
          498,
          264,
          3123,
          390,
          766,
          11,
          286,
          1116,
          312,
          1242,
          257,
          688,
          544,
          7897,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3668.76,
        "id": 843,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3665.76,
        "temperature": 0,
        "text": " I'm going to click Host this model.",
        "tokens": [
          50964,
          286,
          478,
          516,
          281,
          2052,
          22047,
          341,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3672.76,
        "id": 844,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3668.76,
        "temperature": 0,
        "text": " And I'm going to host this model.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          3975,
          341,
          2316,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3674.76,
        "id": 845,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3672.76,
        "temperature": 0,
        "text": " And now I have a list of all of my hosted models.",
        "tokens": [
          51314,
          400,
          586,
          286,
          362,
          257,
          1329,
          295,
          439,
          295,
          452,
          19204,
          5245,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3675.76,
        "id": 846,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3674.76,
        "temperature": 0,
        "text": " Aha!",
        "tokens": [
          51414,
          27448,
          0,
          51464
        ]
      },
      {
        "avg_logprob": -0.19489594931914428,
        "compression_ratio": 1.5617021276595744,
        "end": 3680.76,
        "id": 847,
        "no_speech_prob": 0.002981010591611266,
        "seek": 365376,
        "start": 3675.76,
        "temperature": 0,
        "text": " This is the one that I am actually using with this code, SkyGAN – a SkyGAN model.",
        "tokens": [
          51464,
          639,
          307,
          264,
          472,
          300,
          286,
          669,
          767,
          1228,
          365,
          341,
          3089,
          11,
          9879,
          27699,
          1662,
          257,
          9879,
          27699,
          2316,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20422338304065524,
        "compression_ratio": 1.4734042553191489,
        "end": 3686.76,
        "id": 848,
        "no_speech_prob": 0.010488958097994328,
        "seek": 368076,
        "start": 3680.76,
        "temperature": 0,
        "text": " And this model will, you will see in a moment – where am I going here?",
        "tokens": [
          50364,
          400,
          341,
          2316,
          486,
          11,
          291,
          486,
          536,
          294,
          257,
          1623,
          1662,
          689,
          669,
          286,
          516,
          510,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.20422338304065524,
        "compression_ratio": 1.4734042553191489,
        "end": 3691.76,
        "id": 849,
        "no_speech_prob": 0.010488958097994328,
        "seek": 368076,
        "start": 3686.76,
        "temperature": 0,
        "text": " Generate images of the sky.",
        "tokens": [
          50664,
          15409,
          473,
          5267,
          295,
          264,
          5443,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20422338304065524,
        "compression_ratio": 1.4734042553191489,
        "end": 3699.76,
        "id": 850,
        "no_speech_prob": 0.010488958097994328,
        "seek": 368076,
        "start": 3691.76,
        "temperature": 0,
        "text": " So this is a SkyGAN model that's been trained on many, many, many images of the sky.",
        "tokens": [
          50914,
          407,
          341,
          307,
          257,
          9879,
          27699,
          2316,
          300,
          311,
          668,
          8895,
          322,
          867,
          11,
          867,
          11,
          867,
          5267,
          295,
          264,
          5443,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20422338304065524,
        "compression_ratio": 1.4734042553191489,
        "end": 3701.76,
        "id": 851,
        "no_speech_prob": 0.010488958097994328,
        "seek": 368076,
        "start": 3699.76,
        "temperature": 0,
        "text": " And one of the things you'll notice – ah, there we go.",
        "tokens": [
          51314,
          400,
          472,
          295,
          264,
          721,
          291,
          603,
          3449,
          1662,
          3716,
          11,
          456,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20422338304065524,
        "compression_ratio": 1.4734042553191489,
        "end": 3702.76,
        "id": 852,
        "no_speech_prob": 0.010488958097994328,
        "seek": 368076,
        "start": 3701.76,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51414,
          2053,
          412,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20422338304065524,
        "compression_ratio": 1.4734042553191489,
        "end": 3704.76,
        "id": 853,
        "no_speech_prob": 0.010488958097994328,
        "seek": 368076,
        "start": 3702.76,
        "temperature": 0,
        "text": " Daily limit reached.",
        "tokens": [
          51464,
          19685,
          4948,
          6488,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17974555238764336,
        "compression_ratio": 1.4532710280373833,
        "end": 3712.76,
        "id": 854,
        "no_speech_prob": 0.14414209127426147,
        "seek": 370476,
        "start": 3704.76,
        "temperature": 0,
        "text": " So you can all go to this URL, runway-ml-template.glitch.me.",
        "tokens": [
          50364,
          407,
          291,
          393,
          439,
          352,
          281,
          341,
          12905,
          11,
          26642,
          12,
          15480,
          12,
          83,
          5895,
          473,
          13,
          7191,
          1549,
          13,
          1398,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17974555238764336,
        "compression_ratio": 1.4532710280373833,
        "end": 3715.76,
        "id": 855,
        "no_speech_prob": 0.14414209127426147,
        "seek": 370476,
        "start": 3712.76,
        "temperature": 0,
        "text": " And you will not be able to generate your own sky.",
        "tokens": [
          50764,
          400,
          291,
          486,
          406,
          312,
          1075,
          281,
          8460,
          428,
          1065,
          5443,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17974555238764336,
        "compression_ratio": 1.4532710280373833,
        "end": 3720.76,
        "id": 856,
        "no_speech_prob": 0.14414209127426147,
        "seek": 370476,
        "start": 3715.76,
        "temperature": 0,
        "text": " Because when you do generate a sky, it costs me – well, I actually have some free credit.",
        "tokens": [
          50914,
          1436,
          562,
          291,
          360,
          8460,
          257,
          5443,
          11,
          309,
          5497,
          385,
          1662,
          731,
          11,
          286,
          767,
          362,
          512,
          1737,
          5397,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17974555238764336,
        "compression_ratio": 1.4532710280373833,
        "end": 3723.76,
        "id": 857,
        "no_speech_prob": 0.14414209127426147,
        "seek": 370476,
        "start": 3720.76,
        "temperature": 0,
        "text": " So I'm not paying for any of this right now.",
        "tokens": [
          51164,
          407,
          286,
          478,
          406,
          6229,
          337,
          604,
          295,
          341,
          558,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17974555238764336,
        "compression_ratio": 1.4532710280373833,
        "end": 3728.76,
        "id": 858,
        "no_speech_prob": 0.14414209127426147,
        "seek": 370476,
        "start": 3723.76,
        "temperature": 0,
        "text": " But the actual cost, the runway cost, is one cent per request.",
        "tokens": [
          51314,
          583,
          264,
          3539,
          2063,
          11,
          264,
          26642,
          2063,
          11,
          307,
          472,
          1489,
          680,
          5308,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18561761719839914,
        "compression_ratio": 1.5052631578947369,
        "end": 3734.76,
        "id": 859,
        "no_speech_prob": 0.04958629980683327,
        "seek": 372876,
        "start": 3728.76,
        "temperature": 0,
        "text": " So I, in this template that I've built, I have built into it this JSON file,",
        "tokens": [
          50364,
          407,
          286,
          11,
          294,
          341,
          12379,
          300,
          286,
          600,
          3094,
          11,
          286,
          362,
          3094,
          666,
          309,
          341,
          31828,
          3991,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.18561761719839914,
        "compression_ratio": 1.5052631578947369,
        "end": 3738.76,
        "id": 860,
        "no_speech_prob": 0.04958629980683327,
        "seek": 372876,
        "start": 3734.76,
        "temperature": 0,
        "text": " which always saves the current number of requests.",
        "tokens": [
          50664,
          597,
          1009,
          19155,
          264,
          2190,
          1230,
          295,
          12475,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18561761719839914,
        "compression_ratio": 1.5052631578947369,
        "end": 3743.76,
        "id": 861,
        "no_speech_prob": 0.04958629980683327,
        "seek": 372876,
        "start": 3738.76,
        "temperature": 0,
        "text": " And I have also placed into this.env file, which I don't want to show you right now.",
        "tokens": [
          50864,
          400,
          286,
          362,
          611,
          7074,
          666,
          341,
          2411,
          268,
          85,
          3991,
          11,
          597,
          286,
          500,
          380,
          528,
          281,
          855,
          291,
          558,
          586,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18561761719839914,
        "compression_ratio": 1.5052631578947369,
        "end": 3751.76,
        "id": 862,
        "no_speech_prob": 0.04958629980683327,
        "seek": 372876,
        "start": 3743.76,
        "temperature": 0,
        "text": " Just hold on a second.",
        "tokens": [
          51114,
          1449,
          1797,
          322,
          257,
          1150,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18561761719839914,
        "compression_ratio": 1.5052631578947369,
        "end": 3757.76,
        "id": 863,
        "no_speech_prob": 0.04958629980683327,
        "seek": 372876,
        "start": 3751.76,
        "temperature": 0,
        "text": " I'm going to zoom in on it like this for a second.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          8863,
          294,
          322,
          309,
          411,
          341,
          337,
          257,
          1150,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3761.76,
        "id": 864,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3757.76,
        "temperature": 0,
        "text": " Where one of the properties of the.env file, in addition to the tokens,",
        "tokens": [
          50364,
          2305,
          472,
          295,
          264,
          7221,
          295,
          264,
          2411,
          268,
          85,
          3991,
          11,
          294,
          4500,
          281,
          264,
          22667,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3765.76,
        "id": 865,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3761.76,
        "temperature": 0,
        "text": " which I will show you in a moment so I can regenerate them, is the daily limit.",
        "tokens": [
          50564,
          597,
          286,
          486,
          855,
          291,
          294,
          257,
          1623,
          370,
          286,
          393,
          26358,
          473,
          552,
          11,
          307,
          264,
          5212,
          4948,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3768.76,
        "id": 866,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3765.76,
        "temperature": 0,
        "text": " So I'm going to change this daily limit to 100 right now.",
        "tokens": [
          50764,
          407,
          286,
          478,
          516,
          281,
          1319,
          341,
          5212,
          4948,
          281,
          2319,
          558,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3771.76,
        "id": 867,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3768.76,
        "temperature": 0,
        "text": " That should restart the Glitch web application.",
        "tokens": [
          50914,
          663,
          820,
          21022,
          264,
          5209,
          1549,
          3670,
          3861,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3776.76,
        "id": 868,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3771.76,
        "temperature": 0,
        "text": " I realize I'm jumping right into the middle of a project with lots of pieces and things leading up to it",
        "tokens": [
          51064,
          286,
          4325,
          286,
          478,
          11233,
          558,
          666,
          264,
          2808,
          295,
          257,
          1716,
          365,
          3195,
          295,
          3755,
          293,
          721,
          5775,
          493,
          281,
          309,
          51314
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3778.76,
        "id": 869,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3776.76,
        "temperature": 0,
        "text": " that you might not be familiar with.",
        "tokens": [
          51314,
          300,
          291,
          1062,
          406,
          312,
          4963,
          365,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3780.76,
        "id": 870,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3778.76,
        "temperature": 0,
        "text": " That's okay.",
        "tokens": [
          51414,
          663,
          311,
          1392,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3781.76,
        "id": 871,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3780.76,
        "temperature": 0,
        "text": " Bear with me.",
        "tokens": [
          51514,
          19836,
          365,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3782.76,
        "id": 872,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3781.76,
        "temperature": 0,
        "text": " Ask your questions.",
        "tokens": [
          51564,
          12320,
          428,
          1651,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1531032215465199,
        "compression_ratio": 1.6245733788395904,
        "end": 3785.76,
        "id": 873,
        "no_speech_prob": 0.18950164318084717,
        "seek": 375776,
        "start": 3782.76,
        "temperature": 0,
        "text": " Join the Discord to get help.",
        "tokens": [
          51614,
          19642,
          264,
          32623,
          281,
          483,
          854,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3787.76,
        "id": 874,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3785.76,
        "temperature": 0,
        "text": " And I can see that Peter is here in the chat.",
        "tokens": [
          50364,
          400,
          286,
          393,
          536,
          300,
          6508,
          307,
          510,
          294,
          264,
          5081,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3788.76,
        "id": 875,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3787.76,
        "temperature": 0,
        "text": " Hi, Peter.",
        "tokens": [
          50464,
          2421,
          11,
          6508,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3790.76,
        "id": 876,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3788.76,
        "temperature": 0,
        "text": " Nice to see you.",
        "tokens": [
          50514,
          5490,
          281,
          536,
          291,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3794.76,
        "id": 877,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3790.76,
        "temperature": 0,
        "text": " And let me come back to here.",
        "tokens": [
          50614,
          400,
          718,
          385,
          808,
          646,
          281,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3800.76,
        "id": 878,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3794.76,
        "temperature": 0,
        "text": " And now I should be able to go back to my web application.",
        "tokens": [
          50814,
          400,
          586,
          286,
          820,
          312,
          1075,
          281,
          352,
          646,
          281,
          452,
          3670,
          3861,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3803.76,
        "id": 879,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3800.76,
        "temperature": 0,
        "text": " And we can already see the count is at 18.",
        "tokens": [
          51114,
          400,
          321,
          393,
          1217,
          536,
          264,
          1207,
          307,
          412,
          2443,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3805.76,
        "id": 880,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3803.76,
        "temperature": 0,
        "text": " Let's see if I generate one.",
        "tokens": [
          51264,
          961,
          311,
          536,
          498,
          286,
          8460,
          472,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15415560544192136,
        "compression_ratio": 1.4838709677419355,
        "end": 3809.76,
        "id": 881,
        "no_speech_prob": 0.041461363434791565,
        "seek": 378576,
        "start": 3805.76,
        "temperature": 0,
        "text": " It's going to run out of its daily limit.",
        "tokens": [
          51364,
          467,
          311,
          516,
          281,
          1190,
          484,
          295,
          1080,
          5212,
          4948,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1996180451946494,
        "compression_ratio": 1.539906103286385,
        "end": 3815.76,
        "id": 882,
        "no_speech_prob": 0.3701753616333008,
        "seek": 380976,
        "start": 3809.76,
        "temperature": 0,
        "text": " We've just collectively spent a dollar on generating sky images together.",
        "tokens": [
          50364,
          492,
          600,
          445,
          24341,
          4418,
          257,
          7241,
          322,
          17746,
          5443,
          5267,
          1214,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1996180451946494,
        "compression_ratio": 1.539906103286385,
        "end": 3821.76,
        "id": 883,
        "no_speech_prob": 0.3701753616333008,
        "seek": 380976,
        "start": 3815.76,
        "temperature": 0,
        "text": " So the reason why I've built this in is for a number of different reasons.",
        "tokens": [
          50664,
          407,
          264,
          1778,
          983,
          286,
          600,
          3094,
          341,
          294,
          307,
          337,
          257,
          1230,
          295,
          819,
          4112,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1996180451946494,
        "compression_ratio": 1.539906103286385,
        "end": 3826.76,
        "id": 884,
        "no_speech_prob": 0.3701753616333008,
        "seek": 380976,
        "start": 3821.76,
        "temperature": 0,
        "text": " But one is just to have a protection layer, a sort of rate limiting.",
        "tokens": [
          50964,
          583,
          472,
          307,
          445,
          281,
          362,
          257,
          6334,
          4583,
          11,
          257,
          1333,
          295,
          3314,
          22083,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1996180451946494,
        "compression_ratio": 1.539906103286385,
        "end": 3829.76,
        "id": 885,
        "no_speech_prob": 0.3701753616333008,
        "seek": 380976,
        "start": 3826.76,
        "temperature": 0,
        "text": " It's not something that the runway interface currently has as a feature,",
        "tokens": [
          51214,
          467,
          311,
          406,
          746,
          300,
          264,
          26642,
          9226,
          4362,
          575,
          382,
          257,
          4111,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.1996180451946494,
        "compression_ratio": 1.539906103286385,
        "end": 3833.76,
        "id": 886,
        "no_speech_prob": 0.3701753616333008,
        "seek": 380976,
        "start": 3829.76,
        "temperature": 0,
        "text": " but I've built it into this template.",
        "tokens": [
          51364,
          457,
          286,
          600,
          3094,
          309,
          666,
          341,
          12379,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18482318014468788,
        "compression_ratio": 1.6174242424242424,
        "end": 3841.76,
        "id": 887,
        "no_speech_prob": 0.1159471869468689,
        "seek": 383376,
        "start": 3833.76,
        "temperature": 0,
        "text": " So what I would like to show you how to do is how to create your own web application",
        "tokens": [
          50364,
          407,
          437,
          286,
          576,
          411,
          281,
          855,
          291,
          577,
          281,
          360,
          307,
          577,
          281,
          1884,
          428,
          1065,
          3670,
          3861,
          50764
        ]
      },
      {
        "avg_logprob": -0.18482318014468788,
        "compression_ratio": 1.6174242424242424,
        "end": 3847.76,
        "id": 888,
        "no_speech_prob": 0.1159471869468689,
        "seek": 383376,
        "start": 3841.76,
        "temperature": 0,
        "text": " where your P5.js or any other JavaScript, HTML, CSS code communicates and works with runway.",
        "tokens": [
          50764,
          689,
          428,
          430,
          20,
          13,
          25530,
          420,
          604,
          661,
          15778,
          11,
          17995,
          11,
          24387,
          3089,
          3363,
          1024,
          293,
          1985,
          365,
          26642,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18482318014468788,
        "compression_ratio": 1.6174242424242424,
        "end": 3855.76,
        "id": 889,
        "no_speech_prob": 0.1159471869468689,
        "seek": 383376,
        "start": 3847.76,
        "temperature": 0,
        "text": " And ultimately, I'm going to do that with the object detection model that I'm currently cooking here in my machine learning oven.",
        "tokens": [
          51064,
          400,
          6284,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          365,
          264,
          2657,
          17784,
          2316,
          300,
          286,
          478,
          4362,
          6361,
          510,
          294,
          452,
          3479,
          2539,
          9090,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18482318014468788,
        "compression_ratio": 1.6174242424242424,
        "end": 3858.76,
        "id": 890,
        "no_speech_prob": 0.1159471869468689,
        "seek": 383376,
        "start": 3855.76,
        "temperature": 0,
        "text": " And my machine learning oven is somewhere in the cloud.",
        "tokens": [
          51464,
          400,
          452,
          3479,
          2539,
          9090,
          307,
          4079,
          294,
          264,
          4588,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18482318014468788,
        "compression_ratio": 1.6174242424242424,
        "end": 3861.76,
        "id": 891,
        "no_speech_prob": 0.1159471869468689,
        "seek": 383376,
        "start": 3858.76,
        "temperature": 0,
        "text": " I mean, it's an underground bunker, if we're being honest here.",
        "tokens": [
          51614,
          286,
          914,
          11,
          309,
          311,
          364,
          14977,
          39579,
          11,
          498,
          321,
          434,
          885,
          3245,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1833403083715546,
        "compression_ratio": 1.5505050505050506,
        "end": 3867.76,
        "id": 892,
        "no_speech_prob": 0.04272102564573288,
        "seek": 386176,
        "start": 3861.76,
        "temperature": 0,
        "text": " The server is likely not actually floating in the sky with rainbows and birds tweeting about.",
        "tokens": [
          50364,
          440,
          7154,
          307,
          3700,
          406,
          767,
          12607,
          294,
          264,
          5443,
          365,
          4830,
          21118,
          293,
          9009,
          40090,
          466,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1833403083715546,
        "compression_ratio": 1.5505050505050506,
        "end": 3871.76,
        "id": 893,
        "no_speech_prob": 0.04272102564573288,
        "seek": 386176,
        "start": 3867.76,
        "temperature": 0,
        "text": " That would be nice, though.",
        "tokens": [
          50664,
          663,
          576,
          312,
          1481,
          11,
          1673,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1833403083715546,
        "compression_ratio": 1.5505050505050506,
        "end": 3875.76,
        "id": 894,
        "no_speech_prob": 0.04272102564573288,
        "seek": 386176,
        "start": 3871.76,
        "temperature": 0,
        "text": " So what's next?",
        "tokens": [
          50864,
          407,
          437,
          311,
          958,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1833403083715546,
        "compression_ratio": 1.5505050505050506,
        "end": 3877.76,
        "id": 895,
        "no_speech_prob": 0.04272102564573288,
        "seek": 386176,
        "start": 3875.76,
        "temperature": 0,
        "text": " So let's look at this code for a second.",
        "tokens": [
          51064,
          407,
          718,
          311,
          574,
          412,
          341,
          3089,
          337,
          257,
          1150,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1833403083715546,
        "compression_ratio": 1.5505050505050506,
        "end": 3884.76,
        "id": 896,
        "no_speech_prob": 0.04272102564573288,
        "seek": 386176,
        "start": 3877.76,
        "temperature": 0,
        "text": " And by look at this code, let me go back to here.",
        "tokens": [
          51164,
          400,
          538,
          574,
          412,
          341,
          3089,
          11,
          718,
          385,
          352,
          646,
          281,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1833403083715546,
        "compression_ratio": 1.5505050505050506,
        "end": 3889.76,
        "id": 897,
        "no_speech_prob": 0.04272102564573288,
        "seek": 386176,
        "start": 3884.76,
        "temperature": 0,
        "text": " So in the runway interface, I could also, by the way, just turn off the model.",
        "tokens": [
          51514,
          407,
          294,
          264,
          26642,
          9226,
          11,
          286,
          727,
          611,
          11,
          538,
          264,
          636,
          11,
          445,
          1261,
          766,
          264,
          2316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3891.76,
        "id": 898,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3889.76,
        "temperature": 0,
        "text": " That's another way for me to make sure.",
        "tokens": [
          50364,
          663,
          311,
          1071,
          636,
          337,
          385,
          281,
          652,
          988,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3898.76,
        "id": 899,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3891.76,
        "temperature": 0,
        "text": " You can see I've had 1,399 requests on this model to date having used it.",
        "tokens": [
          50464,
          509,
          393,
          536,
          286,
          600,
          632,
          502,
          11,
          18,
          8494,
          12475,
          322,
          341,
          2316,
          281,
          4002,
          1419,
          1143,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3902.76,
        "id": 900,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3898.76,
        "temperature": 0,
        "text": " So I could click this code snippet here.",
        "tokens": [
          50814,
          407,
          286,
          727,
          2052,
          341,
          3089,
          35623,
          302,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3909.76,
        "id": 901,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3902.76,
        "temperature": 0,
        "text": " And what you would see is that there is a JavaScript library, a runway hosted models library, that allows me.",
        "tokens": [
          51014,
          400,
          437,
          291,
          576,
          536,
          307,
          300,
          456,
          307,
          257,
          15778,
          6405,
          11,
          257,
          26642,
          19204,
          5245,
          6405,
          11,
          300,
          4045,
          385,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3911.76,
        "id": 902,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3909.76,
        "temperature": 0,
        "text": " Oh, there's my token.",
        "tokens": [
          51364,
          876,
          11,
          456,
          311,
          452,
          14862,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3912.76,
        "id": 903,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3911.76,
        "temperature": 0,
        "text": " I sort of forgot.",
        "tokens": [
          51464,
          286,
          1333,
          295,
          5298,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3914.76,
        "id": 904,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3912.76,
        "temperature": 0,
        "text": " I was thinking I'm not showing you the token.",
        "tokens": [
          51514,
          286,
          390,
          1953,
          286,
          478,
          406,
          4099,
          291,
          264,
          14862,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3915.76,
        "id": 905,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3914.76,
        "temperature": 0,
        "text": " Why is my key so off?",
        "tokens": [
          51614,
          1545,
          307,
          452,
          2141,
          370,
          766,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1913736487637047,
        "compression_ratio": 1.503787878787879,
        "end": 3918.76,
        "id": 906,
        "no_speech_prob": 0.06465061753988266,
        "seek": 388976,
        "start": 3915.76,
        "temperature": 0,
        "text": " Is it really these LEDs?",
        "tokens": [
          51664,
          1119,
          309,
          534,
          613,
          33366,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3919.76,
        "id": 907,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3918.76,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50364,
          6962,
          322,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3922.76,
        "id": 908,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3919.76,
        "temperature": 0,
        "text": " I don't know why my key has been actually really good recently.",
        "tokens": [
          50414,
          286,
          500,
          380,
          458,
          983,
          452,
          2141,
          575,
          668,
          767,
          534,
          665,
          3938,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3926.76,
        "id": 909,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3922.76,
        "temperature": 0,
        "text": " Maybe because my lights are so much brighter.",
        "tokens": [
          50564,
          2704,
          570,
          452,
          5811,
          366,
          370,
          709,
          19764,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3927.76,
        "id": 910,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3926.76,
        "temperature": 0,
        "text": " I guess that made it a little bit better.",
        "tokens": [
          50764,
          286,
          2041,
          300,
          1027,
          309,
          257,
          707,
          857,
          1101,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3934.76,
        "id": 911,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3927.76,
        "temperature": 0,
        "text": " I turned those LEDs off.",
        "tokens": [
          50814,
          286,
          3574,
          729,
          33366,
          766,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3935.76,
        "id": 912,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3934.76,
        "temperature": 0,
        "text": " Max.",
        "tokens": [
          51164,
          7402,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3939.76,
        "id": 913,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3935.76,
        "temperature": 0,
        "text": " Is that the Max that I know who's in the chat?",
        "tokens": [
          51214,
          1119,
          300,
          264,
          7402,
          300,
          286,
          458,
          567,
          311,
          294,
          264,
          5081,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3940.76,
        "id": 914,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3939.76,
        "temperature": 0,
        "text": " I think it might be.",
        "tokens": [
          51414,
          286,
          519,
          309,
          1062,
          312,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3942.76,
        "id": 915,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3940.76,
        "temperature": 0,
        "text": " Hi, Max.",
        "tokens": [
          51464,
          2421,
          11,
          7402,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3943.76,
        "id": 916,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3942.76,
        "temperature": 0,
        "text": " I'm all nervous.",
        "tokens": [
          51564,
          286,
          478,
          439,
          6296,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22466625213623048,
        "compression_ratio": 1.5279187817258884,
        "end": 3947.76,
        "id": 917,
        "no_speech_prob": 0.20432624220848083,
        "seek": 391876,
        "start": 3943.76,
        "temperature": 0,
        "text": " Max is watching.",
        "tokens": [
          51614,
          7402,
          307,
          1976,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2060462024724372,
        "compression_ratio": 1.6090534979423867,
        "end": 3951.76,
        "id": 918,
        "no_speech_prob": 0.055002856999635696,
        "seek": 394776,
        "start": 3947.76,
        "temperature": 0,
        "text": " Anyway, back to what I was looking at here.",
        "tokens": [
          50364,
          5684,
          11,
          646,
          281,
          437,
          286,
          390,
          1237,
          412,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2060462024724372,
        "compression_ratio": 1.6090534979423867,
        "end": 3953.76,
        "id": 919,
        "no_speech_prob": 0.055002856999635696,
        "seek": 394776,
        "start": 3951.76,
        "temperature": 0,
        "text": " So now you have my token.",
        "tokens": [
          50564,
          407,
          586,
          291,
          362,
          452,
          14862,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2060462024724372,
        "compression_ratio": 1.6090534979423867,
        "end": 3954.76,
        "id": 920,
        "no_speech_prob": 0.055002856999635696,
        "seek": 394776,
        "start": 3953.76,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50664,
          876,
          11,
          3237,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2060462024724372,
        "compression_ratio": 1.6090534979423867,
        "end": 3958.76,
        "id": 921,
        "no_speech_prob": 0.055002856999635696,
        "seek": 394776,
        "start": 3954.76,
        "temperature": 0,
        "text": " Let's quickly disable that model.",
        "tokens": [
          50714,
          961,
          311,
          2661,
          28362,
          300,
          2316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2060462024724372,
        "compression_ratio": 1.6090534979423867,
        "end": 3959.76,
        "id": 922,
        "no_speech_prob": 0.055002856999635696,
        "seek": 394776,
        "start": 3958.76,
        "temperature": 0,
        "text": " The request didn't go up.",
        "tokens": [
          50914,
          440,
          5308,
          994,
          380,
          352,
          493,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2060462024724372,
        "compression_ratio": 1.6090534979423867,
        "end": 3964.76,
        "id": 923,
        "no_speech_prob": 0.055002856999635696,
        "seek": 394776,
        "start": 3959.76,
        "temperature": 0,
        "text": " So you could have written your own code very quickly with that token if you could have copied it down and put it into your code.",
        "tokens": [
          50964,
          407,
          291,
          727,
          362,
          3720,
          428,
          1065,
          3089,
          588,
          2661,
          365,
          300,
          14862,
          498,
          291,
          727,
          362,
          25365,
          309,
          760,
          293,
          829,
          309,
          666,
          428,
          3089,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2060462024724372,
        "compression_ratio": 1.6090534979423867,
        "end": 3976.76,
        "id": 924,
        "no_speech_prob": 0.055002856999635696,
        "seek": 394776,
        "start": 3964.76,
        "temperature": 0,
        "text": " But looking at that code snippet again, then the idea is I can create a runway hosted model object with a URL to the model.",
        "tokens": [
          51214,
          583,
          1237,
          412,
          300,
          3089,
          35623,
          302,
          797,
          11,
          550,
          264,
          1558,
          307,
          286,
          393,
          1884,
          257,
          26642,
          19204,
          2316,
          2657,
          365,
          257,
          12905,
          281,
          264,
          2316,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3982.76,
        "id": 925,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3976.76,
        "temperature": 0,
        "text": " Token is the cat.",
        "tokens": [
          50364,
          314,
          8406,
          307,
          220,
          3322,
          3857,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3986.76,
        "id": 926,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3982.76,
        "temperature": 0,
        "text": " It's the cat.",
        "tokens": [
          50664,
          467,
          311,
          264,
          3857,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3988.76,
        "id": 927,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3986.76,
        "temperature": 0,
        "text": " I really wish the cat would come and say hello.",
        "tokens": [
          50864,
          286,
          534,
          3172,
          264,
          3857,
          576,
          808,
          293,
          584,
          7751,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3990.76,
        "id": 928,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3988.76,
        "temperature": 0,
        "text": " I forget what truncation is.",
        "tokens": [
          50964,
          286,
          2870,
          437,
          504,
          409,
          46252,
          307,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3992.76,
        "id": 929,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3990.76,
        "temperature": 0,
        "text": " We can look it up in the runway interface.",
        "tokens": [
          51064,
          492,
          393,
          574,
          309,
          493,
          294,
          264,
          26642,
          9226,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3993.76,
        "id": 930,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3992.76,
        "temperature": 0,
        "text": " I can query the model.",
        "tokens": [
          51164,
          286,
          393,
          14581,
          264,
          2316,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3994.76,
        "id": 931,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3993.76,
        "temperature": 0,
        "text": " I can get an image back.",
        "tokens": [
          51214,
          286,
          393,
          483,
          364,
          3256,
          646,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 3997.76,
        "id": 932,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3994.76,
        "temperature": 0,
        "text": " This is what I'm actually doing in my code.",
        "tokens": [
          51264,
          639,
          307,
          437,
          286,
          478,
          767,
          884,
          294,
          452,
          3089,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 4000.76,
        "id": 933,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 3997.76,
        "temperature": 0,
        "text": " However, it's actually going to look a little bit different.",
        "tokens": [
          51414,
          2908,
          11,
          309,
          311,
          767,
          516,
          281,
          574,
          257,
          707,
          857,
          819,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2519070091894117,
        "compression_ratio": 1.5857740585774058,
        "end": 4003.76,
        "id": 934,
        "no_speech_prob": 0.08035509288311005,
        "seek": 397676,
        "start": 4000.76,
        "temperature": 0,
        "text": " Because if ‑‑ and I could just paste this right ‑‑ I've done this.",
        "tokens": [
          51564,
          1436,
          498,
          220,
          27392,
          27392,
          293,
          286,
          727,
          445,
          9163,
          341,
          558,
          45217,
          286,
          600,
          1096,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4006.76,
        "id": 935,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4003.76,
        "temperature": 0,
        "text": " I could paste this right into the P5 Web Editor.",
        "tokens": [
          50364,
          286,
          727,
          9163,
          341,
          558,
          666,
          264,
          430,
          20,
          9573,
          24281,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4011.76,
        "id": 936,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4006.76,
        "temperature": 0,
        "text": " Copy, paste that, put it in the P5 Web Editor, run it, have my StyleGAN example working up and running immediately.",
        "tokens": [
          50514,
          25653,
          11,
          9163,
          300,
          11,
          829,
          309,
          294,
          264,
          430,
          20,
          9573,
          24281,
          11,
          1190,
          309,
          11,
          362,
          452,
          27004,
          27699,
          1365,
          1364,
          493,
          293,
          2614,
          4258,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4012.76,
        "id": 937,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4011.76,
        "temperature": 0,
        "text": " Woohoo!",
        "tokens": [
          50764,
          10468,
          19069,
          0,
          50814
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4014.76,
        "id": 938,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4012.76,
        "temperature": 0,
        "text": " It's awesome!",
        "tokens": [
          50814,
          467,
          311,
          3476,
          0,
          50914
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4022.76,
        "id": 939,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4014.76,
        "temperature": 0,
        "text": " But what would be the problem is my model URL and my model token would be there right in the code.",
        "tokens": [
          50914,
          583,
          437,
          576,
          312,
          264,
          1154,
          307,
          452,
          2316,
          12905,
          293,
          452,
          2316,
          14862,
          576,
          312,
          456,
          558,
          294,
          264,
          3089,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4024.76,
        "id": 940,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4022.76,
        "temperature": 0,
        "text": " And anyone on that web page could grab those.",
        "tokens": [
          51314,
          400,
          2878,
          322,
          300,
          3670,
          3028,
          727,
          4444,
          729,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4026.76,
        "id": 941,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4024.76,
        "temperature": 0,
        "text": " And I want to keep those secure.",
        "tokens": [
          51414,
          400,
          286,
          528,
          281,
          1066,
          729,
          7144,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2083740723438752,
        "compression_ratio": 1.63671875,
        "end": 4030.76,
        "id": 942,
        "no_speech_prob": 0.20432515442371368,
        "seek": 400376,
        "start": 4026.76,
        "temperature": 0,
        "text": " So what I have done here with this runway ML template.",
        "tokens": [
          51514,
          407,
          437,
          286,
          362,
          1096,
          510,
          365,
          341,
          26642,
          21601,
          12379,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.26376800537109374,
        "compression_ratio": 1.6394052044609666,
        "end": 4035.76,
        "id": 943,
        "no_speech_prob": 0.44934284687042236,
        "seek": 403076,
        "start": 4030.76,
        "temperature": 0,
        "text": " And in theory, you can use it by only ever using this server.js file.",
        "tokens": [
          50364,
          400,
          294,
          5261,
          11,
          291,
          393,
          764,
          309,
          538,
          787,
          1562,
          1228,
          341,
          7154,
          13,
          25530,
          3991,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.26376800537109374,
        "compression_ratio": 1.6394052044609666,
        "end": 4036.76,
        "id": 944,
        "no_speech_prob": 0.44934284687042236,
        "seek": 403076,
        "start": 4035.76,
        "temperature": 0,
        "text": " I'm not ‑‑ no, sorry.",
        "tokens": [
          50614,
          286,
          478,
          406,
          45217,
          572,
          11,
          2597,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.26376800537109374,
        "compression_ratio": 1.6394052044609666,
        "end": 4038.76,
        "id": 945,
        "no_speech_prob": 0.44934284687042236,
        "seek": 403076,
        "start": 4036.76,
        "temperature": 0,
        "text": " You have to use the other stuff, too.",
        "tokens": [
          50664,
          509,
          362,
          281,
          764,
          264,
          661,
          1507,
          11,
          886,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.26376800537109374,
        "compression_ratio": 1.6394052044609666,
        "end": 4042.76,
        "id": 946,
        "no_speech_prob": 0.44934284687042236,
        "seek": 403076,
        "start": 4038.76,
        "temperature": 0,
        "text": " But you could work with this without having to write your own server.",
        "tokens": [
          50764,
          583,
          291,
          727,
          589,
          365,
          341,
          1553,
          1419,
          281,
          2464,
          428,
          1065,
          7154,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26376800537109374,
        "compression_ratio": 1.6394052044609666,
        "end": 4047.76,
        "id": 947,
        "no_speech_prob": 0.44934284687042236,
        "seek": 403076,
        "start": 4042.76,
        "temperature": 0,
        "text": " But I have a server, a Node server that's actually doing the runway communication.",
        "tokens": [
          50964,
          583,
          286,
          362,
          257,
          7154,
          11,
          257,
          38640,
          7154,
          300,
          311,
          767,
          884,
          264,
          26642,
          6101,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26376800537109374,
        "compression_ratio": 1.6394052044609666,
        "end": 4052.76,
        "id": 948,
        "no_speech_prob": 0.44934284687042236,
        "seek": 403076,
        "start": 4047.76,
        "temperature": 0,
        "text": " And you'll notice in the code when I create the runway model.",
        "tokens": [
          51214,
          400,
          291,
          603,
          3449,
          294,
          264,
          3089,
          562,
          286,
          1884,
          264,
          26642,
          2316,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26376800537109374,
        "compression_ratio": 1.6394052044609666,
        "end": 4059.76,
        "id": 949,
        "no_speech_prob": 0.44934284687042236,
        "seek": 403076,
        "start": 4052.76,
        "temperature": 0,
        "text": " By the way, does anybody know ‑‑ I don't know what the equivalent family friendly ‑‑",
        "tokens": [
          51464,
          3146,
          264,
          636,
          11,
          775,
          4472,
          458,
          45217,
          286,
          500,
          380,
          458,
          437,
          264,
          10344,
          1605,
          9208,
          45217,
          51814
        ]
      },
      {
        "avg_logprob": -0.24571769578116281,
        "compression_ratio": 1.5410958904109588,
        "end": 4062.76,
        "id": 950,
        "no_speech_prob": 0.1710352897644043,
        "seek": 405976,
        "start": 4059.76,
        "temperature": 0,
        "text": " I don't know what the equivalent family friendly thing of a drinking game is.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          437,
          264,
          10344,
          1605,
          9208,
          551,
          295,
          257,
          7583,
          1216,
          307,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24571769578116281,
        "compression_ratio": 1.5410958904109588,
        "end": 4067.76,
        "id": 951,
        "no_speech_prob": 0.1710352897644043,
        "seek": 405976,
        "start": 4062.76,
        "temperature": 0,
        "text": " But, yes, put a quarter in the jar every time I show my API tokens on a stream.",
        "tokens": [
          50514,
          583,
          11,
          2086,
          11,
          829,
          257,
          6555,
          294,
          264,
          15181,
          633,
          565,
          286,
          855,
          452,
          9362,
          22667,
          322,
          257,
          4309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24571769578116281,
        "compression_ratio": 1.5410958904109588,
        "end": 4073.76,
        "id": 952,
        "no_speech_prob": 0.1710352897644043,
        "seek": 405976,
        "start": 4067.76,
        "temperature": 0,
        "text": " But you can see here I'm calling on process.env runway URL, runway token.",
        "tokens": [
          50764,
          583,
          291,
          393,
          536,
          510,
          286,
          478,
          5141,
          322,
          1399,
          13,
          268,
          85,
          26642,
          12905,
          11,
          26642,
          14862,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24571769578116281,
        "compression_ratio": 1.5410958904109588,
        "end": 4077.76,
        "id": 953,
        "no_speech_prob": 0.1710352897644043,
        "seek": 405976,
        "start": 4073.76,
        "temperature": 0,
        "text": " Which means the code itself does not actually have the token in it.",
        "tokens": [
          51064,
          3013,
          1355,
          264,
          3089,
          2564,
          775,
          406,
          767,
          362,
          264,
          14862,
          294,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24571769578116281,
        "compression_ratio": 1.5410958904109588,
        "end": 4085.76,
        "id": 954,
        "no_speech_prob": 0.1710352897644043,
        "seek": 405976,
        "start": 4077.76,
        "temperature": 0,
        "text": " Instead, I'm having like a crazy deja vu because I was literally recording a video tutorial on this yesterday that will go with my Discord bot series.",
        "tokens": [
          51264,
          7156,
          11,
          286,
          478,
          1419,
          411,
          257,
          3219,
          38260,
          9732,
          570,
          286,
          390,
          3736,
          6613,
          257,
          960,
          7073,
          322,
          341,
          5186,
          300,
          486,
          352,
          365,
          452,
          32623,
          10592,
          2638,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4090.76,
        "id": 955,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4085.76,
        "temperature": 0,
        "text": " But instead, the keys are stored in that.env file.",
        "tokens": [
          50364,
          583,
          2602,
          11,
          264,
          9317,
          366,
          12187,
          294,
          300,
          2411,
          268,
          85,
          3991,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4092.76,
        "id": 956,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4090.76,
        "temperature": 0,
        "text": " You can see that little heart key thing.",
        "tokens": [
          50614,
          509,
          393,
          536,
          300,
          707,
          1917,
          2141,
          551,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4098.76,
        "id": 957,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4092.76,
        "temperature": 0,
        "text": " This is something that only I or other, you know, approved editors to this project can see.",
        "tokens": [
          50714,
          639,
          307,
          746,
          300,
          787,
          286,
          420,
          661,
          11,
          291,
          458,
          11,
          10826,
          31446,
          281,
          341,
          1716,
          393,
          536,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4103.76,
        "id": 958,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4098.76,
        "temperature": 0,
        "text": " So if you were to go remix this project, like this code is open source.",
        "tokens": [
          51014,
          407,
          498,
          291,
          645,
          281,
          352,
          47788,
          341,
          1716,
          11,
          411,
          341,
          3089,
          307,
          1269,
          4009,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4105.76,
        "id": 959,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4103.76,
        "temperature": 0,
        "text": " You can go to the URL to it.",
        "tokens": [
          51264,
          509,
          393,
          352,
          281,
          264,
          12905,
          281,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4107.76,
        "id": 960,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4105.76,
        "temperature": 0,
        "text": " I'll paste it in the Discord.",
        "tokens": [
          51364,
          286,
          603,
          9163,
          309,
          294,
          264,
          32623,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4110.76,
        "id": 961,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4107.76,
        "temperature": 0,
        "text": " I believe if I go ‑‑ you know, you guys can all confirm this to me.",
        "tokens": [
          51464,
          286,
          1697,
          498,
          286,
          352,
          45217,
          291,
          458,
          11,
          291,
          1074,
          393,
          439,
          9064,
          341,
          281,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4112.76,
        "id": 962,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4110.76,
        "temperature": 0,
        "text": " I'm going to go back to our Discord.",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          527,
          32623,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18903653071476864,
        "compression_ratio": 1.6481481481481481,
        "end": 4114.76,
        "id": 963,
        "no_speech_prob": 0.030674055218696594,
        "seek": 408576,
        "start": 4112.76,
        "temperature": 0,
        "text": " Where did Discord go?",
        "tokens": [
          51714,
          2305,
          630,
          32623,
          352,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.19188592372796473,
        "compression_ratio": 1.5376712328767124,
        "end": 4118.76,
        "id": 964,
        "no_speech_prob": 0.038465466350317,
        "seek": 411476,
        "start": 4114.76,
        "temperature": 0,
        "text": " In the live channel, links channel and just paste it here.",
        "tokens": [
          50364,
          682,
          264,
          1621,
          2269,
          11,
          6123,
          2269,
          293,
          445,
          9163,
          309,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19188592372796473,
        "compression_ratio": 1.5376712328767124,
        "end": 4121.76,
        "id": 965,
        "no_speech_prob": 0.038465466350317,
        "seek": 411476,
        "start": 4118.76,
        "temperature": 0,
        "text": " So you can grab that URL, go there, you'll see all the code.",
        "tokens": [
          50564,
          407,
          291,
          393,
          4444,
          300,
          12905,
          11,
          352,
          456,
          11,
          291,
          603,
          536,
          439,
          264,
          3089,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19188592372796473,
        "compression_ratio": 1.5376712328767124,
        "end": 4124.76,
        "id": 966,
        "no_speech_prob": 0.038465466350317,
        "seek": 411476,
        "start": 4121.76,
        "temperature": 0,
        "text": " But when you go to the.env file, it will be empty.",
        "tokens": [
          50714,
          583,
          562,
          291,
          352,
          281,
          264,
          2411,
          268,
          85,
          3991,
          11,
          309,
          486,
          312,
          6707,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19188592372796473,
        "compression_ratio": 1.5376712328767124,
        "end": 4127.76,
        "id": 967,
        "no_speech_prob": 0.038465466350317,
        "seek": 411476,
        "start": 4124.76,
        "temperature": 0,
        "text": " Because I'm not packaging that up with the example.",
        "tokens": [
          50864,
          1436,
          286,
          478,
          406,
          16836,
          300,
          493,
          365,
          264,
          1365,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19188592372796473,
        "compression_ratio": 1.5376712328767124,
        "end": 4130.76,
        "id": 968,
        "no_speech_prob": 0.038465466350317,
        "seek": 411476,
        "start": 4127.76,
        "temperature": 0,
        "text": " So that's a really convenient ‑‑ and this is not unique to Glitch.",
        "tokens": [
          51014,
          407,
          300,
          311,
          257,
          534,
          10851,
          45217,
          293,
          341,
          307,
          406,
          3845,
          281,
          5209,
          1549,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19188592372796473,
        "compression_ratio": 1.5376712328767124,
        "end": 4140.76,
        "id": 969,
        "no_speech_prob": 0.038465466350317,
        "seek": 411476,
        "start": 4130.76,
        "temperature": 0,
        "text": " This is a common sort of standard for how to save, you know, secret important information in environment variables across different web applications.",
        "tokens": [
          51164,
          639,
          307,
          257,
          2689,
          1333,
          295,
          3832,
          337,
          577,
          281,
          3155,
          11,
          291,
          458,
          11,
          4054,
          1021,
          1589,
          294,
          2823,
          9102,
          2108,
          819,
          3670,
          5821,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19188592372796473,
        "compression_ratio": 1.5376712328767124,
        "end": 4142.76,
        "id": 970,
        "no_speech_prob": 0.038465466350317,
        "seek": 411476,
        "start": 4140.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4147.76,
        "id": 971,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4142.76,
        "temperature": 0,
        "text": " So what I want to show you here is let's look at the actual P5 code.",
        "tokens": [
          50364,
          407,
          437,
          286,
          528,
          281,
          855,
          291,
          510,
          307,
          718,
          311,
          574,
          412,
          264,
          3539,
          430,
          20,
          3089,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4153.76,
        "id": 972,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4147.76,
        "temperature": 0,
        "text": " Does anybody know, by the way, how to increase the font size in the P5 in the Glitch web editor?",
        "tokens": [
          50614,
          4402,
          4472,
          458,
          11,
          538,
          264,
          636,
          11,
          577,
          281,
          3488,
          264,
          10703,
          2744,
          294,
          264,
          430,
          20,
          294,
          264,
          5209,
          1549,
          3670,
          9839,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4155.76,
        "id": 973,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4153.76,
        "temperature": 0,
        "text": " I have not been able to figure out how to do this.",
        "tokens": [
          50914,
          286,
          362,
          406,
          668,
          1075,
          281,
          2573,
          484,
          577,
          281,
          360,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4160.76,
        "id": 974,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4155.76,
        "temperature": 0,
        "text": " I know I could zoom the web page, but it grows everything, which kind of makes me a little bit crazy.",
        "tokens": [
          51014,
          286,
          458,
          286,
          727,
          8863,
          264,
          3670,
          3028,
          11,
          457,
          309,
          13156,
          1203,
          11,
          597,
          733,
          295,
          1669,
          385,
          257,
          707,
          857,
          3219,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4162.76,
        "id": 975,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4160.76,
        "temperature": 0,
        "text": " But I'll just do that for right now.",
        "tokens": [
          51264,
          583,
          286,
          603,
          445,
          360,
          300,
          337,
          558,
          586,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4164.76,
        "id": 976,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4162.76,
        "temperature": 0,
        "text": " Look at all you nice people popping up.",
        "tokens": [
          51364,
          2053,
          412,
          439,
          291,
          1481,
          561,
          18374,
          493,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4166.76,
        "id": 977,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4164.76,
        "temperature": 0,
        "text": " Anonymous, anonymous.",
        "tokens": [
          51464,
          1107,
          18092,
          11,
          24932,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4168.76,
        "id": 978,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4166.76,
        "temperature": 0,
        "text": " Who are you?",
        "tokens": [
          51564,
          2102,
          366,
          291,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2102901259465004,
        "compression_ratio": 1.547945205479452,
        "end": 4170.76,
        "id": 979,
        "no_speech_prob": 0.013019767589867115,
        "seek": 414276,
        "start": 4168.76,
        "temperature": 0,
        "text": " Who are you watching?",
        "tokens": [
          51664,
          2102,
          366,
          291,
          1976,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4172.76,
        "id": 980,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4170.76,
        "temperature": 0,
        "text": " Shrey and Sian and Shrey?",
        "tokens": [
          50364,
          1160,
          7950,
          293,
          318,
          952,
          293,
          1160,
          7950,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4174.76,
        "id": 981,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4172.76,
        "temperature": 0,
        "text": " Shrey is watching it twice.",
        "tokens": [
          50464,
          1160,
          7950,
          307,
          1976,
          309,
          6091,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4176.76,
        "id": 982,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4174.76,
        "temperature": 0,
        "text": " Are you two people?",
        "tokens": [
          50564,
          2014,
          291,
          732,
          561,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4180.76,
        "id": 983,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4176.76,
        "temperature": 0,
        "text": " But all the rest of you are just these anonymous little smiley faces.",
        "tokens": [
          50664,
          583,
          439,
          264,
          1472,
          295,
          291,
          366,
          445,
          613,
          24932,
          707,
          7563,
          88,
          8475,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4182.76,
        "id": 984,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4180.76,
        "temperature": 0,
        "text": " Hi, anonymous little smiley faces.",
        "tokens": [
          50864,
          2421,
          11,
          24932,
          707,
          7563,
          88,
          8475,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4184.76,
        "id": 985,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4182.76,
        "temperature": 0,
        "text": " I love you all.",
        "tokens": [
          50964,
          286,
          959,
          291,
          439,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4186.76,
        "id": 986,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4184.76,
        "temperature": 0,
        "text": " What time?",
        "tokens": [
          51064,
          708,
          565,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4188.76,
        "id": 987,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4186.76,
        "temperature": 0,
        "text": " I said it was going to be.5.",
        "tokens": [
          51164,
          286,
          848,
          309,
          390,
          516,
          281,
          312,
          2411,
          20,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4190.76,
        "id": 988,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4188.76,
        "temperature": 0,
        "text": " We'll see.",
        "tokens": [
          51264,
          492,
          603,
          536,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4192.76,
        "id": 989,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4190.76,
        "temperature": 0,
        "text": " So here's what I'm showing you.",
        "tokens": [
          51364,
          407,
          510,
          311,
          437,
          286,
          478,
          4099,
          291,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4194.76,
        "id": 990,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4192.76,
        "temperature": 0,
        "text": " The code is quite simple on the client side.",
        "tokens": [
          51464,
          440,
          3089,
          307,
          1596,
          2199,
          322,
          264,
          6423,
          1252,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.269136518239975,
        "compression_ratio": 1.6382113821138211,
        "end": 4196.76,
        "id": 991,
        "no_speech_prob": 0.3072613477706909,
        "seek": 417076,
        "start": 4194.76,
        "temperature": 0,
        "text": " Rather than programming this whole thing, I'm just going to talk you through it.",
        "tokens": [
          51564,
          16571,
          813,
          9410,
          341,
          1379,
          551,
          11,
          286,
          478,
          445,
          516,
          281,
          751,
          291,
          807,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4198.76,
        "id": 992,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4196.76,
        "temperature": 0,
        "text": " And then I'm going to make some new versions.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          516,
          281,
          652,
          512,
          777,
          9606,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4201.76,
        "id": 993,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4198.76,
        "temperature": 0,
        "text": " I'm going to remix it and make some new versions of it to do other things.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          47788,
          309,
          293,
          652,
          512,
          777,
          9606,
          295,
          309,
          281,
          360,
          661,
          721,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4203.76,
        "id": 994,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4201.76,
        "temperature": 0,
        "text": " So one is I'm creating a canvas.",
        "tokens": [
          50614,
          407,
          472,
          307,
          286,
          478,
          4084,
          257,
          16267,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4205.76,
        "id": 995,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4203.76,
        "temperature": 0,
        "text": " It's 640 by 480.",
        "tokens": [
          50714,
          467,
          311,
          1386,
          5254,
          538,
          1017,
          4702,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4207.76,
        "id": 996,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4205.76,
        "temperature": 0,
        "text": " I'm creating a button, that button called Generate.",
        "tokens": [
          50814,
          286,
          478,
          4084,
          257,
          2960,
          11,
          300,
          2960,
          1219,
          15409,
          473,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4209.76,
        "id": 997,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4207.76,
        "temperature": 0,
        "text": " We can see all of this here.",
        "tokens": [
          50914,
          492,
          393,
          536,
          439,
          295,
          341,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4211.76,
        "id": 998,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4209.76,
        "temperature": 0,
        "text": " Canvas, the Generate button.",
        "tokens": [
          51014,
          25725,
          11,
          264,
          15409,
          473,
          2960,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4215.76,
        "id": 999,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4211.76,
        "temperature": 0,
        "text": " This is all P5 code for manipulating a canvas and DOM elements.",
        "tokens": [
          51114,
          639,
          307,
          439,
          430,
          20,
          3089,
          337,
          40805,
          257,
          16267,
          293,
          35727,
          4959,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15506410240230703,
        "compression_ratio": 1.7276119402985075,
        "end": 4221.76,
        "id": 1000,
        "no_speech_prob": 0.21203778684139252,
        "seek": 419676,
        "start": 4215.76,
        "temperature": 0,
        "text": " It's not your sort of traditional JavaScript, but it's the way I like to work with the P5 creative coding environment.",
        "tokens": [
          51314,
          467,
          311,
          406,
          428,
          1333,
          295,
          5164,
          15778,
          11,
          457,
          309,
          311,
          264,
          636,
          286,
          411,
          281,
          589,
          365,
          264,
          430,
          20,
          5880,
          17720,
          2823,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4225.76,
        "id": 1001,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4221.76,
        "temperature": 0,
        "text": " I'm making this sort of span DOM element because I want to show the count.",
        "tokens": [
          50364,
          286,
          478,
          1455,
          341,
          1333,
          295,
          16174,
          35727,
          4478,
          570,
          286,
          528,
          281,
          855,
          264,
          1207,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4227.76,
        "id": 1002,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4225.76,
        "temperature": 0,
        "text": " That's rather unnecessary.",
        "tokens": [
          50564,
          663,
          311,
          2831,
          19350,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4229.76,
        "id": 1003,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4227.76,
        "temperature": 0,
        "text": " But we've got to tally all the votes.",
        "tokens": [
          50664,
          583,
          321,
          600,
          658,
          281,
          256,
          379,
          439,
          264,
          12068,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4234.76,
        "id": 1004,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4229.76,
        "temperature": 0,
        "text": " I mean, count all of our requests to the runway server.",
        "tokens": [
          50764,
          286,
          914,
          11,
          1207,
          439,
          295,
          527,
          12475,
          281,
          264,
          26642,
          7154,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4239.76,
        "id": 1005,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4234.76,
        "temperature": 0,
        "text": " And then when I press the mouse, this function send vector is called.",
        "tokens": [
          51014,
          400,
          550,
          562,
          286,
          1886,
          264,
          9719,
          11,
          341,
          2445,
          2845,
          8062,
          307,
          1219,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4243.76,
        "id": 1006,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4239.76,
        "temperature": 0,
        "text": " It's the callback to the mouse-pressed event on the Generate button.",
        "tokens": [
          51264,
          467,
          311,
          264,
          818,
          3207,
          281,
          264,
          9719,
          12,
          79,
          3805,
          2280,
          322,
          264,
          15409,
          473,
          2960,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4245.76,
        "id": 1007,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4243.76,
        "temperature": 0,
        "text": " So what's going on in that function?",
        "tokens": [
          51464,
          407,
          437,
          311,
          516,
          322,
          294,
          300,
          2445,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.23075225705006083,
        "compression_ratio": 1.6171003717472119,
        "end": 4250.76,
        "id": 1008,
        "no_speech_prob": 0.19928450882434845,
        "seek": 422176,
        "start": 4245.76,
        "temperature": 0,
        "text": " Well, every model in runway, and if I go back to browse models,",
        "tokens": [
          51564,
          1042,
          11,
          633,
          2316,
          294,
          26642,
          11,
          293,
          498,
          286,
          352,
          646,
          281,
          31442,
          5245,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4257.76,
        "id": 1009,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4250.76,
        "temperature": 0,
        "text": " and I search for SkyGAN, and I come up to it, and let's just add it to create it.",
        "tokens": [
          50364,
          293,
          286,
          3164,
          337,
          9879,
          27699,
          11,
          293,
          286,
          808,
          493,
          281,
          309,
          11,
          293,
          718,
          311,
          445,
          909,
          309,
          281,
          1884,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4259.76,
        "id": 1010,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4257.76,
        "temperature": 0,
        "text": " Why do I need to create a new workspace?",
        "tokens": [
          50714,
          1545,
          360,
          286,
          643,
          281,
          1884,
          257,
          777,
          32706,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4263.76,
        "id": 1011,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4259.76,
        "temperature": 0,
        "text": " Isn't there, shouldn't it like add to my existing workspace?",
        "tokens": [
          50814,
          6998,
          380,
          456,
          11,
          4659,
          380,
          309,
          411,
          909,
          281,
          452,
          6741,
          32706,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4265.76,
        "id": 1012,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4263.76,
        "temperature": 0,
        "text": " Here's my model workspace.",
        "tokens": [
          51014,
          1692,
          311,
          452,
          2316,
          32706,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4268.76,
        "id": 1013,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4265.76,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          51114,
          286,
          478,
          370,
          9019,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4270.76,
        "id": 1014,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4268.76,
        "temperature": 0,
        "text": " I'm just not going to worry about this.",
        "tokens": [
          51264,
          286,
          478,
          445,
          406,
          516,
          281,
          3292,
          466,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4272.76,
        "id": 1015,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4270.76,
        "temperature": 0,
        "text": " Something is going on.",
        "tokens": [
          51364,
          6595,
          307,
          516,
          322,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4275.76,
        "id": 1016,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4272.76,
        "temperature": 0,
        "text": " Somebody will teach me how to use runway.",
        "tokens": [
          51464,
          13463,
          486,
          2924,
          385,
          577,
          281,
          764,
          26642,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20661892807274534,
        "compression_ratio": 1.617391304347826,
        "end": 4277.76,
        "id": 1017,
        "no_speech_prob": 0.0034833557438105345,
        "seek": 425076,
        "start": 4275.76,
        "temperature": 0,
        "text": " By the way, there's a slack for runway.",
        "tokens": [
          51614,
          3146,
          264,
          636,
          11,
          456,
          311,
          257,
          29767,
          337,
          26642,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4281.76,
        "id": 1018,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4277.76,
        "temperature": 0,
        "text": " I'm almost taking notes so I can give all this feedback to them.",
        "tokens": [
          50364,
          286,
          478,
          1920,
          1940,
          5570,
          370,
          286,
          393,
          976,
          439,
          341,
          5824,
          281,
          552,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4285.76,
        "id": 1019,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4281.76,
        "temperature": 0,
        "text": " So I don't know, coding train 2, I don't know why I have more than one workspace.",
        "tokens": [
          50564,
          407,
          286,
          500,
          380,
          458,
          11,
          17720,
          3847,
          568,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          362,
          544,
          813,
          472,
          32706,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4286.76,
        "id": 1020,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4285.76,
        "temperature": 0,
        "text": " Was I in my other account?",
        "tokens": [
          50764,
          3027,
          286,
          294,
          452,
          661,
          2696,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4287.76,
        "id": 1021,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4286.76,
        "temperature": 0,
        "text": " I don't think so.",
        "tokens": [
          50814,
          286,
          500,
          380,
          519,
          370,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4289.76,
        "id": 1022,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4287.76,
        "temperature": 0,
        "text": " Where's the other workspace?",
        "tokens": [
          50864,
          2305,
          311,
          264,
          661,
          32706,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4290.76,
        "id": 1023,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4289.76,
        "temperature": 0,
        "text": " So strange.",
        "tokens": [
          50964,
          407,
          5861,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4301.76,
        "id": 1024,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4290.76,
        "temperature": 0,
        "text": " But with every single model, where does inference know, what am I looking at?",
        "tokens": [
          51014,
          583,
          365,
          633,
          2167,
          2316,
          11,
          689,
          775,
          38253,
          458,
          11,
          437,
          669,
          286,
          1237,
          412,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4303.76,
        "id": 1025,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4301.76,
        "temperature": 0,
        "text": " I think I want to look at here.",
        "tokens": [
          51564,
          286,
          519,
          286,
          528,
          281,
          574,
          412,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23702022007533483,
        "compression_ratio": 1.6680672268907564,
        "end": 4306.76,
        "id": 1026,
        "no_speech_prob": 0.14803896844387054,
        "seek": 427776,
        "start": 4303.76,
        "temperature": 0,
        "text": " I want to look at where it shows me the sort of specs,",
        "tokens": [
          51664,
          286,
          528,
          281,
          574,
          412,
          689,
          309,
          3110,
          385,
          264,
          1333,
          295,
          27911,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4309.76,
        "id": 1027,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4306.76,
        "temperature": 0,
        "text": " the model, the inputs and the outputs.",
        "tokens": [
          50364,
          264,
          2316,
          11,
          264,
          15743,
          293,
          264,
          23930,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4312.76,
        "id": 1028,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4309.76,
        "temperature": 0,
        "text": " And you're probably all saying this, and this always happens to me,",
        "tokens": [
          50514,
          400,
          291,
          434,
          1391,
          439,
          1566,
          341,
          11,
          293,
          341,
          1009,
          2314,
          281,
          385,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4314.76,
        "id": 1029,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4312.76,
        "temperature": 0,
        "text": " where you're all saying how to do this in the chat,",
        "tokens": [
          50664,
          689,
          291,
          434,
          439,
          1566,
          577,
          281,
          360,
          341,
          294,
          264,
          5081,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4316.76,
        "id": 1030,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4314.76,
        "temperature": 0,
        "text": " and I'm just completely incapable of seeing it.",
        "tokens": [
          50764,
          293,
          286,
          478,
          445,
          2584,
          44174,
          295,
          2577,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4317.76,
        "id": 1031,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4316.76,
        "temperature": 0,
        "text": " My models, no.",
        "tokens": [
          50864,
          1222,
          5245,
          11,
          572,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4319.76,
        "id": 1032,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4317.76,
        "temperature": 0,
        "text": " Model workspace, yes.",
        "tokens": [
          50914,
          17105,
          32706,
          11,
          2086,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4324.76,
        "id": 1033,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4319.76,
        "temperature": 0,
        "text": " All right, well, I know what it is, and it's telling me right here, vector.",
        "tokens": [
          51014,
          1057,
          558,
          11,
          731,
          11,
          286,
          458,
          437,
          309,
          307,
          11,
          293,
          309,
          311,
          3585,
          385,
          558,
          510,
          11,
          8062,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4329.76,
        "id": 1034,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4324.76,
        "temperature": 0,
        "text": " So the input to this particular model, our vector,",
        "tokens": [
          51264,
          407,
          264,
          4846,
          281,
          341,
          1729,
          2316,
          11,
          527,
          8062,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4331.76,
        "id": 1035,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4329.76,
        "temperature": 0,
        "text": " oh, I'm going to have to make a whole video about this.",
        "tokens": [
          51514,
          1954,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          652,
          257,
          1379,
          960,
          466,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4332.76,
        "id": 1036,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4331.76,
        "temperature": 0,
        "text": " I've talked about this before.",
        "tokens": [
          51614,
          286,
          600,
          2825,
          466,
          341,
          949,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1973412020894505,
        "compression_ratio": 1.7560137457044673,
        "end": 4334.76,
        "id": 1037,
        "no_speech_prob": 0.017176466062664986,
        "seek": 430676,
        "start": 4332.76,
        "temperature": 0,
        "text": " I don't want to get into the weeds of this right now.",
        "tokens": [
          51664,
          286,
          500,
          380,
          528,
          281,
          483,
          666,
          264,
          26370,
          295,
          341,
          558,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4337.76,
        "id": 1038,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4334.76,
        "temperature": 0,
        "text": " But in an image classification context,",
        "tokens": [
          50364,
          583,
          294,
          364,
          3256,
          21538,
          4319,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4340.76,
        "id": 1039,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4337.76,
        "temperature": 0,
        "text": " the inputs to the machine learning model would be the image.",
        "tokens": [
          50514,
          264,
          15743,
          281,
          264,
          3479,
          2539,
          2316,
          576,
          312,
          264,
          3256,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4342.76,
        "id": 1040,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4340.76,
        "temperature": 0,
        "text": " The outputs would be the labels.",
        "tokens": [
          50664,
          440,
          23930,
          576,
          312,
          264,
          16949,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4344.76,
        "id": 1041,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4342.76,
        "temperature": 0,
        "text": " Here, this is a generative model,",
        "tokens": [
          50764,
          1692,
          11,
          341,
          307,
          257,
          1337,
          1166,
          2316,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4348.76,
        "id": 1042,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4344.76,
        "temperature": 0,
        "text": " so the inputs is actually really just like a bucket of numbers, like a noise.",
        "tokens": [
          50864,
          370,
          264,
          15743,
          307,
          767,
          534,
          445,
          411,
          257,
          13058,
          295,
          3547,
          11,
          411,
          257,
          5658,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4353.76,
        "id": 1043,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4348.76,
        "temperature": 0,
        "text": " It's like a list of noise, and that list of noise is the signature,",
        "tokens": [
          51064,
          467,
          311,
          411,
          257,
          1329,
          295,
          5658,
          11,
          293,
          300,
          1329,
          295,
          5658,
          307,
          264,
          13397,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4356.76,
        "id": 1044,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4353.76,
        "temperature": 0,
        "text": " that signature input which will generate a particular image.",
        "tokens": [
          51314,
          300,
          13397,
          4846,
          597,
          486,
          8460,
          257,
          1729,
          3256,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1948705060141427,
        "compression_ratio": 1.7479674796747968,
        "end": 4363.76,
        "id": 1045,
        "no_speech_prob": 0.019419142976403236,
        "seek": 433476,
        "start": 4356.76,
        "temperature": 0,
        "text": " So that's what I'm doing in my code, wherever that was,",
        "tokens": [
          51464,
          407,
          300,
          311,
          437,
          286,
          478,
          884,
          294,
          452,
          3089,
          11,
          8660,
          300,
          390,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4370.76,
        "id": 1046,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4363.76,
        "temperature": 0,
        "text": " where I am, I know the expectation for StyleGAN is to receive 512 input values,",
        "tokens": [
          50364,
          689,
          286,
          669,
          11,
          286,
          458,
          264,
          14334,
          337,
          27004,
          27699,
          307,
          281,
          4774,
          1025,
          4762,
          4846,
          4190,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4372.76,
        "id": 1047,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4370.76,
        "temperature": 0,
        "text": " a vector of 512 numbers.",
        "tokens": [
          50714,
          257,
          8062,
          295,
          1025,
          4762,
          3547,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4374.76,
        "id": 1048,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4372.76,
        "temperature": 0,
        "text": " I think an appropriate range is between negative one and one,",
        "tokens": [
          50814,
          286,
          519,
          364,
          6854,
          3613,
          307,
          1296,
          3671,
          472,
          293,
          472,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4376.76,
        "id": 1049,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4374.76,
        "temperature": 0,
        "text": " but I'm not entirely sure.",
        "tokens": [
          50914,
          457,
          286,
          478,
          406,
          7696,
          988,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4378.76,
        "id": 1050,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4376.76,
        "temperature": 0,
        "text": " And so I make the inputs with the Z,",
        "tokens": [
          51014,
          400,
          370,
          286,
          652,
          264,
          15743,
          365,
          264,
          1176,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4383.76,
        "id": 1051,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4378.76,
        "temperature": 0,
        "text": " it's often referred to as the Z vector or the latent vector is another term for this.",
        "tokens": [
          51114,
          309,
          311,
          2049,
          10839,
          281,
          382,
          264,
          1176,
          8062,
          420,
          264,
          48994,
          8062,
          307,
          1071,
          1433,
          337,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4386.76,
        "id": 1052,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4383.76,
        "temperature": 0,
        "text": " And then I don't see the runway code anymore.",
        "tokens": [
          51364,
          400,
          550,
          286,
          500,
          380,
          536,
          264,
          26642,
          3089,
          3602,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1848722185407366,
        "compression_ratio": 1.5824175824175823,
        "end": 4391.76,
        "id": 1053,
        "no_speech_prob": 0.007577168755233288,
        "seek": 436376,
        "start": 4386.76,
        "temperature": 0,
        "text": " The reason is I'm actually going to send the vector to my own server.",
        "tokens": [
          51514,
          440,
          1778,
          307,
          286,
          478,
          767,
          516,
          281,
          2845,
          264,
          8062,
          281,
          452,
          1065,
          7154,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4394.76,
        "id": 1054,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4391.76,
        "temperature": 0,
        "text": " The server is essentially middleware, is that the right term?",
        "tokens": [
          50364,
          440,
          7154,
          307,
          4476,
          2808,
          3039,
          11,
          307,
          300,
          264,
          558,
          1433,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4398.76,
        "id": 1055,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4394.76,
        "temperature": 0,
        "text": " It is really just, its job is just to like pass the football, pass the baton.",
        "tokens": [
          50514,
          467,
          307,
          534,
          445,
          11,
          1080,
          1691,
          307,
          445,
          281,
          411,
          1320,
          264,
          7346,
          11,
          1320,
          264,
          7362,
          266,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4400.76,
        "id": 1056,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4398.76,
        "temperature": 0,
        "text": " That's a better metaphor, I think.",
        "tokens": [
          50714,
          663,
          311,
          257,
          1101,
          19157,
          11,
          286,
          519,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4401.76,
        "id": 1057,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4400.76,
        "temperature": 0,
        "text": " It's a relay race.",
        "tokens": [
          50814,
          467,
          311,
          257,
          24214,
          4569,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4403.76,
        "id": 1058,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4401.76,
        "temperature": 0,
        "text": " The runner is running up with its vector.",
        "tokens": [
          50864,
          440,
          24376,
          307,
          2614,
          493,
          365,
          1080,
          8062,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4408.76,
        "id": 1059,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4403.76,
        "temperature": 0,
        "text": " It's passing the baton to the server, who's going to run it all the way to runway.",
        "tokens": [
          50964,
          467,
          311,
          8437,
          264,
          7362,
          266,
          281,
          264,
          7154,
          11,
          567,
          311,
          516,
          281,
          1190,
          309,
          439,
          264,
          636,
          281,
          26642,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4410.76,
        "id": 1060,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4408.76,
        "temperature": 0,
        "text": " The server is really secure.",
        "tokens": [
          51214,
          440,
          7154,
          307,
          534,
          7144,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4413.76,
        "id": 1061,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4410.76,
        "temperature": 0,
        "text": " I mean, it's not that secure to be honest, but it's much more secure.",
        "tokens": [
          51314,
          286,
          914,
          11,
          309,
          311,
          406,
          300,
          7144,
          281,
          312,
          3245,
          11,
          457,
          309,
          311,
          709,
          544,
          7144,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1747866221836635,
        "compression_ratio": 1.8237547892720307,
        "end": 4416.76,
        "id": 1062,
        "no_speech_prob": 0.2974414527416229,
        "seek": 439176,
        "start": 4413.76,
        "temperature": 0,
        "text": " I mean, I'm sure there's security flaws in what I'm doing,",
        "tokens": [
          51464,
          286,
          914,
          11,
          286,
          478,
          988,
          456,
          311,
          3825,
          27108,
          294,
          437,
          286,
          478,
          884,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.20667169074050518,
        "compression_ratio": 1.6654676258992807,
        "end": 4421.76,
        "id": 1063,
        "no_speech_prob": 0.34153786301612854,
        "seek": 441676,
        "start": 4416.76,
        "temperature": 0,
        "text": " but it is secure in the sense that it's got the sort of secret keys to talk to runway.",
        "tokens": [
          50364,
          457,
          309,
          307,
          7144,
          294,
          264,
          2020,
          300,
          309,
          311,
          658,
          264,
          1333,
          295,
          4054,
          9317,
          281,
          751,
          281,
          26642,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20667169074050518,
        "compression_ratio": 1.6654676258992807,
        "end": 4424.76,
        "id": 1064,
        "no_speech_prob": 0.34153786301612854,
        "seek": 441676,
        "start": 4421.76,
        "temperature": 0,
        "text": " So you can see I'm using the JavaScript fetch function,",
        "tokens": [
          50614,
          407,
          291,
          393,
          536,
          286,
          478,
          1228,
          264,
          15778,
          23673,
          2445,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.20667169074050518,
        "compression_ratio": 1.6654676258992807,
        "end": 4429.76,
        "id": 1065,
        "no_speech_prob": 0.34153786301612854,
        "seek": 441676,
        "start": 4424.76,
        "temperature": 0,
        "text": " my endpoint on my own API that I've basically written to that node server is called runway.",
        "tokens": [
          50764,
          452,
          35795,
          322,
          452,
          1065,
          9362,
          300,
          286,
          600,
          1936,
          3720,
          281,
          300,
          9984,
          7154,
          307,
          1219,
          26642,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20667169074050518,
        "compression_ratio": 1.6654676258992807,
        "end": 4433.76,
        "id": 1066,
        "no_speech_prob": 0.34153786301612854,
        "seek": 441676,
        "start": 4429.76,
        "temperature": 0,
        "text": " So and then the server is keeping track of the count.",
        "tokens": [
          51014,
          407,
          293,
          550,
          264,
          7154,
          307,
          5145,
          2837,
          295,
          264,
          1207,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20667169074050518,
        "compression_ratio": 1.6654676258992807,
        "end": 4438.76,
        "id": 1067,
        "no_speech_prob": 0.34153786301612854,
        "seek": 441676,
        "start": 4433.76,
        "temperature": 0,
        "text": " And if it's reached its limit, it'll just log the daily limit was reached.",
        "tokens": [
          51214,
          400,
          498,
          309,
          311,
          6488,
          1080,
          4948,
          11,
          309,
          603,
          445,
          3565,
          264,
          5212,
          4948,
          390,
          6488,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20667169074050518,
        "compression_ratio": 1.6654676258992807,
        "end": 4442.76,
        "id": 1068,
        "no_speech_prob": 0.34153786301612854,
        "seek": 441676,
        "start": 4438.76,
        "temperature": 0,
        "text": " Otherwise it returns the outputs from the model.",
        "tokens": [
          51464,
          10328,
          309,
          11247,
          264,
          23930,
          490,
          264,
          2316,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20667169074050518,
        "compression_ratio": 1.6654676258992807,
        "end": 4444.76,
        "id": 1069,
        "no_speech_prob": 0.34153786301612854,
        "seek": 441676,
        "start": 4442.76,
        "temperature": 0,
        "text": " And that's an image which I can generate and draw.",
        "tokens": [
          51664,
          400,
          300,
          311,
          364,
          3256,
          597,
          286,
          393,
          8460,
          293,
          2642,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2022128164032359,
        "compression_ratio": 1.6432432432432433,
        "end": 4446.76,
        "id": 1070,
        "no_speech_prob": 0.017442086711525917,
        "seek": 444476,
        "start": 4444.76,
        "temperature": 0,
        "text": " So this is looks this is identical.",
        "tokens": [
          50364,
          407,
          341,
          307,
          1542,
          341,
          307,
          14800,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2022128164032359,
        "compression_ratio": 1.6432432432432433,
        "end": 4456.76,
        "id": 1071,
        "no_speech_prob": 0.017442086711525917,
        "seek": 444476,
        "start": 4446.76,
        "temperature": 0,
        "text": " The way I've set this template up is if you send the inputs to the node server's runway ML endpoint,",
        "tokens": [
          50464,
          440,
          636,
          286,
          600,
          992,
          341,
          12379,
          493,
          307,
          498,
          291,
          2845,
          264,
          15743,
          281,
          264,
          9984,
          7154,
          311,
          26642,
          21601,
          35795,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.2022128164032359,
        "compression_ratio": 1.6432432432432433,
        "end": 4459.76,
        "id": 1072,
        "no_speech_prob": 0.017442086711525917,
        "seek": 444476,
        "start": 4456.76,
        "temperature": 0,
        "text": " that node server, if I look all the way down here,",
        "tokens": [
          50964,
          300,
          9984,
          7154,
          11,
          498,
          286,
          574,
          439,
          264,
          636,
          760,
          510,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.2022128164032359,
        "compression_ratio": 1.6432432432432433,
        "end": 4466.76,
        "id": 1073,
        "no_speech_prob": 0.017442086711525917,
        "seek": 444476,
        "start": 4459.76,
        "temperature": 0,
        "text": " will take the body of that request as inputs and then call await model dot query.",
        "tokens": [
          51114,
          486,
          747,
          264,
          1772,
          295,
          300,
          5308,
          382,
          15743,
          293,
          550,
          818,
          19670,
          2316,
          5893,
          14581,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2022128164032359,
        "compression_ratio": 1.6432432432432433,
        "end": 4468.76,
        "id": 1074,
        "no_speech_prob": 0.017442086711525917,
        "seek": 444476,
        "start": 4466.76,
        "temperature": 0,
        "text": " So this is the actual runway call.",
        "tokens": [
          51464,
          407,
          341,
          307,
          264,
          3539,
          26642,
          818,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19588260297422055,
        "compression_ratio": 1.6436781609195403,
        "end": 4474.76,
        "id": 1075,
        "no_speech_prob": 0.46090009808540344,
        "seek": 446876,
        "start": 4468.76,
        "temperature": 0,
        "text": " And if it comes back and works, it sets a status to success and returns the outputs.",
        "tokens": [
          50364,
          400,
          498,
          309,
          1487,
          646,
          293,
          1985,
          11,
          309,
          6352,
          257,
          6558,
          281,
          2245,
          293,
          11247,
          264,
          23930,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19588260297422055,
        "compression_ratio": 1.6436781609195403,
        "end": 4477.76,
        "id": 1076,
        "no_speech_prob": 0.46090009808540344,
        "seek": 446876,
        "start": 4474.76,
        "temperature": 0,
        "text": " Otherwise, I'm just keeping track of this count, right?",
        "tokens": [
          50664,
          10328,
          11,
          286,
          478,
          445,
          5145,
          2837,
          295,
          341,
          1207,
          11,
          558,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.19588260297422055,
        "compression_ratio": 1.6436781609195403,
        "end": 4481.76,
        "id": 1077,
        "no_speech_prob": 0.46090009808540344,
        "seek": 446876,
        "start": 4477.76,
        "temperature": 0,
        "text": " This is my highly advanced rate limiting methodology.",
        "tokens": [
          50814,
          639,
          307,
          452,
          5405,
          7339,
          3314,
          22083,
          24850,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19588260297422055,
        "compression_ratio": 1.6436781609195403,
        "end": 4484.76,
        "id": 1078,
        "no_speech_prob": 0.46090009808540344,
        "seek": 446876,
        "start": 4481.76,
        "temperature": 0,
        "text": " I have a variable, which is literally a count.",
        "tokens": [
          51014,
          286,
          362,
          257,
          7006,
          11,
          597,
          307,
          3736,
          257,
          1207,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19588260297422055,
        "compression_ratio": 1.6436781609195403,
        "end": 4490.76,
        "id": 1079,
        "no_speech_prob": 0.46090009808540344,
        "seek": 446876,
        "start": 4484.76,
        "temperature": 0,
        "text": " And as it goes up, if it goes above some threshold, which is defined here in the environment variables,",
        "tokens": [
          51164,
          400,
          382,
          309,
          1709,
          493,
          11,
          498,
          309,
          1709,
          3673,
          512,
          14678,
          11,
          597,
          307,
          7642,
          510,
          294,
          264,
          2823,
          9102,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19588260297422055,
        "compression_ratio": 1.6436781609195403,
        "end": 4495.76,
        "id": 1080,
        "no_speech_prob": 0.46090009808540344,
        "seek": 446876,
        "start": 4490.76,
        "temperature": 0,
        "text": " you can see, by the way, here's the URL and the token in the environment variables.",
        "tokens": [
          51464,
          291,
          393,
          536,
          11,
          538,
          264,
          636,
          11,
          510,
          311,
          264,
          12905,
          293,
          264,
          14862,
          294,
          264,
          2823,
          9102,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22435575265150803,
        "compression_ratio": 1.5872340425531914,
        "end": 4504.76,
        "id": 1081,
        "no_speech_prob": 0.06371095776557922,
        "seek": 449576,
        "start": 4495.76,
        "temperature": 0,
        "text": " If it reaches that count, it is trying to say that it just sends back doesn't actually query the model.",
        "tokens": [
          50364,
          759,
          309,
          14235,
          300,
          1207,
          11,
          309,
          307,
          1382,
          281,
          584,
          300,
          309,
          445,
          14790,
          646,
          1177,
          380,
          767,
          14581,
          264,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22435575265150803,
        "compression_ratio": 1.5872340425531914,
        "end": 4508.76,
        "id": 1082,
        "no_speech_prob": 0.06371095776557922,
        "seek": 449576,
        "start": 4504.76,
        "temperature": 0,
        "text": " And I also made an endpoint to just like check the count.",
        "tokens": [
          50814,
          400,
          286,
          611,
          1027,
          364,
          35795,
          281,
          445,
          411,
          1520,
          264,
          1207,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22435575265150803,
        "compression_ratio": 1.5872340425531914,
        "end": 4516.76,
        "id": 1083,
        "no_speech_prob": 0.06371095776557922,
        "seek": 449576,
        "start": 4508.76,
        "temperature": 0,
        "text": " So, for example, I think that if I do slash count here, you can see that it's at 100.",
        "tokens": [
          51014,
          407,
          11,
          337,
          1365,
          11,
          286,
          519,
          300,
          498,
          286,
          360,
          17330,
          1207,
          510,
          11,
          291,
          393,
          536,
          300,
          309,
          311,
          412,
          2319,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22435575265150803,
        "compression_ratio": 1.5872340425531914,
        "end": 4521.76,
        "id": 1084,
        "no_speech_prob": 0.06371095776557922,
        "seek": 449576,
        "start": 4516.76,
        "temperature": 0,
        "text": " And if I went back to here and I went, the count is also being stored in this JSON file.",
        "tokens": [
          51414,
          400,
          498,
          286,
          1437,
          646,
          281,
          510,
          293,
          286,
          1437,
          11,
          264,
          1207,
          307,
          611,
          885,
          12187,
          294,
          341,
          31828,
          3991,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22435575265150803,
        "compression_ratio": 1.5872340425531914,
        "end": 4523.76,
        "id": 1085,
        "no_speech_prob": 0.06371095776557922,
        "seek": 449576,
        "start": 4521.76,
        "temperature": 0,
        "text": " I don't know why it says five there.",
        "tokens": [
          51664,
          286,
          500,
          380,
          458,
          983,
          309,
          1619,
          1732,
          456,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4525.76,
        "id": 1086,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4523.76,
        "temperature": 0,
        "text": " Something funny happens with me with Glitch.",
        "tokens": [
          50364,
          6595,
          4074,
          2314,
          365,
          385,
          365,
          5209,
          1549,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4526.76,
        "id": 1087,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4525.76,
        "temperature": 0,
        "text": " I don't really get it.",
        "tokens": [
          50464,
          286,
          500,
          380,
          534,
          483,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4531.76,
        "id": 1088,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4526.76,
        "temperature": 0,
        "text": " When you're writing to text files or JSON files, the browser doesn't always like refresh the latest contents.",
        "tokens": [
          50514,
          1133,
          291,
          434,
          3579,
          281,
          2487,
          7098,
          420,
          31828,
          7098,
          11,
          264,
          11185,
          1177,
          380,
          1009,
          411,
          15134,
          264,
          6792,
          15768,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4536.76,
        "id": 1089,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4531.76,
        "temperature": 0,
        "text": " But if I set that to zero and it'll like save it and then go back to here.",
        "tokens": [
          50764,
          583,
          498,
          286,
          992,
          300,
          281,
          4018,
          293,
          309,
          603,
          411,
          3155,
          309,
          293,
          550,
          352,
          646,
          281,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4538.76,
        "id": 1090,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4536.76,
        "temperature": 0,
        "text": " Oh, and my app went to sleep.",
        "tokens": [
          51014,
          876,
          11,
          293,
          452,
          724,
          1437,
          281,
          2817,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4540.76,
        "id": 1091,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4538.76,
        "temperature": 0,
        "text": " I thought I had, by the way, I have a Glitch Pro account.",
        "tokens": [
          51114,
          286,
          1194,
          286,
          632,
          11,
          538,
          264,
          636,
          11,
          286,
          362,
          257,
          5209,
          1549,
          1705,
          2696,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4542.76,
        "id": 1092,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4540.76,
        "temperature": 0,
        "text": " I thought I boosted this.",
        "tokens": [
          51214,
          286,
          1194,
          286,
          9194,
          292,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4544.76,
        "id": 1093,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4542.76,
        "temperature": 0,
        "text": " But you can see now the count is zero.",
        "tokens": [
          51314,
          583,
          291,
          393,
          536,
          586,
          264,
          1207,
          307,
          4018,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1833717097406802,
        "compression_ratio": 1.6452702702702702,
        "end": 4552.76,
        "id": 1094,
        "no_speech_prob": 0.03514409810304642,
        "seek": 452376,
        "start": 4544.76,
        "temperature": 0,
        "text": " And then this won't actually work right now because I think I disabled the model.",
        "tokens": [
          51414,
          400,
          550,
          341,
          1582,
          380,
          767,
          589,
          558,
          586,
          570,
          286,
          519,
          286,
          15191,
          264,
          2316,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20704390207926432,
        "compression_ratio": 1.44,
        "end": 4560.76,
        "id": 1095,
        "no_speech_prob": 0.030675387009978294,
        "seek": 455276,
        "start": 4552.76,
        "temperature": 0,
        "text": " But you get that's the entire story.",
        "tokens": [
          50364,
          583,
          291,
          483,
          300,
          311,
          264,
          2302,
          1657,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20704390207926432,
        "compression_ratio": 1.44,
        "end": 4562.76,
        "id": 1096,
        "no_speech_prob": 0.030675387009978294,
        "seek": 455276,
        "start": 4560.76,
        "temperature": 0,
        "text": " So, let's see.",
        "tokens": [
          50764,
          407,
          11,
          718,
          311,
          536,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20704390207926432,
        "compression_ratio": 1.44,
        "end": 4573.76,
        "id": 1097,
        "no_speech_prob": 0.030675387009978294,
        "seek": 455276,
        "start": 4562.76,
        "temperature": 0,
        "text": " And right, so protecting it by an IP address, there's a variety of other ways you could protect it also.",
        "tokens": [
          50864,
          400,
          558,
          11,
          370,
          12316,
          309,
          538,
          364,
          8671,
          2985,
          11,
          456,
          311,
          257,
          5673,
          295,
          661,
          2098,
          291,
          727,
          2371,
          309,
          611,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20704390207926432,
        "compression_ratio": 1.44,
        "end": 4574.76,
        "id": 1098,
        "no_speech_prob": 0.030675387009978294,
        "seek": 455276,
        "start": 4573.76,
        "temperature": 0,
        "text": " Let's see here.",
        "tokens": [
          51414,
          961,
          311,
          536,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20704390207926432,
        "compression_ratio": 1.44,
        "end": 4576.76,
        "id": 1099,
        "no_speech_prob": 0.030675387009978294,
        "seek": 455276,
        "start": 4574.76,
        "temperature": 0,
        "text": " What questions do you have about this?",
        "tokens": [
          51464,
          708,
          1651,
          360,
          291,
          362,
          466,
          341,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.20704390207926432,
        "compression_ratio": 1.44,
        "end": 4579.76,
        "id": 1100,
        "no_speech_prob": 0.030675387009978294,
        "seek": 455276,
        "start": 4576.76,
        "temperature": 0,
        "text": " Let's check our models that are cooking.",
        "tokens": [
          51564,
          961,
          311,
          1520,
          527,
          5245,
          300,
          366,
          6361,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4582.76,
        "id": 1101,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4579.76,
        "temperature": 0,
        "text": " I'm going to go.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          352,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4586.76,
        "id": 1102,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4582.76,
        "temperature": 0,
        "text": " This is so ridiculous what I've done here by using two runway accounts.",
        "tokens": [
          50514,
          639,
          307,
          370,
          11083,
          437,
          286,
          600,
          1096,
          510,
          538,
          1228,
          732,
          26642,
          9402,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4589.76,
        "id": 1103,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4586.76,
        "temperature": 0,
        "text": " Let's log out.",
        "tokens": [
          50714,
          961,
          311,
          3565,
          484,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4592.76,
        "id": 1104,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4589.76,
        "temperature": 0,
        "text": " And let's log into my other runway account.",
        "tokens": [
          50864,
          400,
          718,
          311,
          3565,
          666,
          452,
          661,
          26642,
          2696,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4594.76,
        "id": 1105,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4592.76,
        "temperature": 0,
        "text": " This is not a necessary thing for you to do.",
        "tokens": [
          51014,
          639,
          307,
          406,
          257,
          4818,
          551,
          337,
          291,
          281,
          360,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4596.76,
        "id": 1106,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4594.76,
        "temperature": 0,
        "text": " Go under train.",
        "tokens": [
          51114,
          1037,
          833,
          3847,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4601.76,
        "id": 1107,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4596.76,
        "temperature": 0,
        "text": " And let's check these models.",
        "tokens": [
          51214,
          400,
          718,
          311,
          1520,
          613,
          5245,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4602.76,
        "id": 1108,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4601.76,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51464,
          961,
          311,
          536,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17098605632781982,
        "compression_ratio": 1.6,
        "end": 4606.76,
        "id": 1109,
        "no_speech_prob": 0.04467976465821266,
        "seek": 457976,
        "start": 4602.76,
        "temperature": 0,
        "text": " This one is 46% done and this one is 28% done.",
        "tokens": [
          51514,
          639,
          472,
          307,
          17835,
          4,
          1096,
          293,
          341,
          472,
          307,
          7562,
          4,
          1096,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17016072175940689,
        "compression_ratio": 1.7031963470319635,
        "end": 4609.76,
        "id": 1110,
        "no_speech_prob": 0.05184445157647133,
        "seek": 460676,
        "start": 4606.76,
        "temperature": 0,
        "text": " Let's take a look at the one that's 46% done.",
        "tokens": [
          50364,
          961,
          311,
          747,
          257,
          574,
          412,
          264,
          472,
          300,
          311,
          17835,
          4,
          1096,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17016072175940689,
        "compression_ratio": 1.7031963470319635,
        "end": 4619.76,
        "id": 1111,
        "no_speech_prob": 0.05184445157647133,
        "seek": 460676,
        "start": 4609.76,
        "temperature": 0,
        "text": " So, you can see here what I love about the runway interface is it's actually showing me its progress while it's training.",
        "tokens": [
          50514,
          407,
          11,
          291,
          393,
          536,
          510,
          437,
          286,
          959,
          466,
          264,
          26642,
          9226,
          307,
          309,
          311,
          767,
          4099,
          385,
          1080,
          4205,
          1339,
          309,
          311,
          3097,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17016072175940689,
        "compression_ratio": 1.7031963470319635,
        "end": 4623.76,
        "id": 1112,
        "no_speech_prob": 0.05184445157647133,
        "seek": 460676,
        "start": 4619.76,
        "temperature": 0,
        "text": " So, it's running a bunch of training images through the model.",
        "tokens": [
          51014,
          407,
          11,
          309,
          311,
          2614,
          257,
          3840,
          295,
          3097,
          5267,
          807,
          264,
          2316,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17016072175940689,
        "compression_ratio": 1.7031963470319635,
        "end": 4625.76,
        "id": 1113,
        "no_speech_prob": 0.05184445157647133,
        "seek": 460676,
        "start": 4623.76,
        "temperature": 0,
        "text": " This is not showing me my annotations, right?",
        "tokens": [
          51214,
          639,
          307,
          406,
          4099,
          385,
          452,
          25339,
          763,
          11,
          558,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.17016072175940689,
        "compression_ratio": 1.7031963470319635,
        "end": 4631.76,
        "id": 1114,
        "no_speech_prob": 0.05184445157647133,
        "seek": 460676,
        "start": 4625.76,
        "temperature": 0,
        "text": " This is showing me its guess based on the current state of the model, based on the current step.",
        "tokens": [
          51314,
          639,
          307,
          4099,
          385,
          1080,
          2041,
          2361,
          322,
          264,
          2190,
          1785,
          295,
          264,
          2316,
          11,
          2361,
          322,
          264,
          2190,
          1823,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2336861878922842,
        "compression_ratio": 1.4873949579831933,
        "end": 4637.76,
        "id": 1115,
        "no_speech_prob": 0.02517854981124401,
        "seek": 463176,
        "start": 4631.76,
        "temperature": 0,
        "text": " And if I go back, like I look at step 1200, 600, all the way back to one foot.",
        "tokens": [
          50364,
          400,
          498,
          286,
          352,
          646,
          11,
          411,
          286,
          574,
          412,
          1823,
          29139,
          11,
          11849,
          11,
          439,
          264,
          636,
          646,
          281,
          472,
          2671,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2336861878922842,
        "compression_ratio": 1.4873949579831933,
        "end": 4638.76,
        "id": 1116,
        "no_speech_prob": 0.02517854981124401,
        "seek": 463176,
        "start": 4637.76,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50664,
          1779,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2336861878922842,
        "compression_ratio": 1.4873949579831933,
        "end": 4639.76,
        "id": 1117,
        "no_speech_prob": 0.02517854981124401,
        "seek": 463176,
        "start": 4638.76,
        "temperature": 0,
        "text": " This was early in the training process.",
        "tokens": [
          50714,
          639,
          390,
          2440,
          294,
          264,
          3097,
          1399,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2336861878922842,
        "compression_ratio": 1.4873949579831933,
        "end": 4642.76,
        "id": 1118,
        "no_speech_prob": 0.02517854981124401,
        "seek": 463176,
        "start": 4639.76,
        "temperature": 0,
        "text": " It was finding the Rubik's Cube everywhere.",
        "tokens": [
          50764,
          467,
          390,
          5006,
          264,
          10518,
          1035,
          311,
          33003,
          5315,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2336861878922842,
        "compression_ratio": 1.4873949579831933,
        "end": 4646.76,
        "id": 1119,
        "no_speech_prob": 0.02517854981124401,
        "seek": 463176,
        "start": 4642.76,
        "temperature": 0,
        "text": " And around step 750, it sort of found it in two places.",
        "tokens": [
          50914,
          400,
          926,
          1823,
          31682,
          11,
          309,
          1333,
          295,
          1352,
          309,
          294,
          732,
          3190,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2336861878922842,
        "compression_ratio": 1.4873949579831933,
        "end": 4648.76,
        "id": 1120,
        "no_speech_prob": 0.02517854981124401,
        "seek": 463176,
        "start": 4646.76,
        "temperature": 0,
        "text": " It's getting more and more accurate.",
        "tokens": [
          51114,
          467,
          311,
          1242,
          544,
          293,
          544,
          8559,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2336861878922842,
        "compression_ratio": 1.4873949579831933,
        "end": 4654.76,
        "id": 1121,
        "no_speech_prob": 0.02517854981124401,
        "seek": 463176,
        "start": 4648.76,
        "temperature": 0,
        "text": " And, you know, I might venture to say that I can stop this from training because it's done.",
        "tokens": [
          51214,
          400,
          11,
          291,
          458,
          11,
          286,
          1062,
          18474,
          281,
          584,
          300,
          286,
          393,
          1590,
          341,
          490,
          3097,
          570,
          309,
          311,
          1096,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16609224172738882,
        "compression_ratio": 1.766773162939297,
        "end": 4662.76,
        "id": 1122,
        "no_speech_prob": 0.42626655101776123,
        "seek": 465476,
        "start": 4654.76,
        "temperature": 0,
        "text": " But this is the sort of like metric, this map metric, which is mean average precision, a measure of a performance of an object detection model.",
        "tokens": [
          50364,
          583,
          341,
          307,
          264,
          1333,
          295,
          411,
          20678,
          11,
          341,
          4471,
          20678,
          11,
          597,
          307,
          914,
          4274,
          18356,
          11,
          257,
          3481,
          295,
          257,
          3389,
          295,
          364,
          2657,
          17784,
          2316,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16609224172738882,
        "compression_ratio": 1.766773162939297,
        "end": 4669.76,
        "id": 1123,
        "no_speech_prob": 0.42626655101776123,
        "seek": 465476,
        "start": 4662.76,
        "temperature": 0,
        "text": " It summarizes both the position, how many of the predicted bounding boxes correspond to the true bounding boxes, as well as its recall,",
        "tokens": [
          50764,
          467,
          14611,
          5660,
          1293,
          264,
          2535,
          11,
          577,
          867,
          295,
          264,
          19147,
          5472,
          278,
          9002,
          6805,
          281,
          264,
          2074,
          5472,
          278,
          9002,
          11,
          382,
          731,
          382,
          1080,
          9901,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.16609224172738882,
        "compression_ratio": 1.766773162939297,
        "end": 4673.76,
        "id": 1124,
        "no_speech_prob": 0.42626655101776123,
        "seek": 465476,
        "start": 4669.76,
        "temperature": 0,
        "text": " which measures how many of the true bounding boxes have been correctly predicted by the model.",
        "tokens": [
          51114,
          597,
          8000,
          577,
          867,
          295,
          264,
          2074,
          5472,
          278,
          9002,
          362,
          668,
          8944,
          19147,
          538,
          264,
          2316,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16609224172738882,
        "compression_ratio": 1.766773162939297,
        "end": 4676.76,
        "id": 1125,
        "no_speech_prob": 0.42626655101776123,
        "seek": 465476,
        "start": 4673.76,
        "temperature": 0,
        "text": " So, I would like to see this at 100%.",
        "tokens": [
          51314,
          407,
          11,
          286,
          576,
          411,
          281,
          536,
          341,
          412,
          2319,
          6856,
          51464
        ]
      },
      {
        "avg_logprob": -0.16609224172738882,
        "compression_ratio": 1.766773162939297,
        "end": 4679.76,
        "id": 1126,
        "no_speech_prob": 0.42626655101776123,
        "seek": 465476,
        "start": 4676.76,
        "temperature": 0,
        "text": " We can look through all the different example images.",
        "tokens": [
          51464,
          492,
          393,
          574,
          807,
          439,
          264,
          819,
          1365,
          5267,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16609224172738882,
        "compression_ratio": 1.766773162939297,
        "end": 4683.76,
        "id": 1127,
        "no_speech_prob": 0.42626655101776123,
        "seek": 465476,
        "start": 4679.76,
        "temperature": 0,
        "text": " This is probably good enough for me to try running it in my own application right now.",
        "tokens": [
          51614,
          639,
          307,
          1391,
          665,
          1547,
          337,
          385,
          281,
          853,
          2614,
          309,
          294,
          452,
          1065,
          3861,
          558,
          586,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15363407135009766,
        "compression_ratio": 1.588235294117647,
        "end": 4686.76,
        "id": 1128,
        "no_speech_prob": 0.09946484118700027,
        "seek": 468376,
        "start": 4683.76,
        "temperature": 0,
        "text": " But let's let it train a little bit more.",
        "tokens": [
          50364,
          583,
          718,
          311,
          718,
          309,
          3847,
          257,
          707,
          857,
          544,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15363407135009766,
        "compression_ratio": 1.588235294117647,
        "end": 4689.76,
        "id": 1129,
        "no_speech_prob": 0.09946484118700027,
        "seek": 468376,
        "start": 4686.76,
        "temperature": 0,
        "text": " And I'm pretty happy with how Tiny YOLO is working.",
        "tokens": [
          50514,
          400,
          286,
          478,
          1238,
          2055,
          365,
          577,
          39992,
          398,
          5046,
          46,
          307,
          1364,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15363407135009766,
        "compression_ratio": 1.588235294117647,
        "end": 4695.76,
        "id": 1130,
        "no_speech_prob": 0.09946484118700027,
        "seek": 468376,
        "start": 4689.76,
        "temperature": 0,
        "text": " So, since that is a faster, smaller model, it's probably the one I'll want to use.",
        "tokens": [
          50664,
          407,
          11,
          1670,
          300,
          307,
          257,
          4663,
          11,
          4356,
          2316,
          11,
          309,
          311,
          1391,
          264,
          472,
          286,
          603,
          528,
          281,
          764,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15363407135009766,
        "compression_ratio": 1.588235294117647,
        "end": 4699.76,
        "id": 1131,
        "no_speech_prob": 0.09946484118700027,
        "seek": 468376,
        "start": 4695.76,
        "temperature": 0,
        "text": " I wonder if this is something, I believe Tiny YOLO is compatible with JavaScript.",
        "tokens": [
          50964,
          286,
          2441,
          498,
          341,
          307,
          746,
          11,
          286,
          1697,
          39992,
          398,
          5046,
          46,
          307,
          18218,
          365,
          15778,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15363407135009766,
        "compression_ratio": 1.588235294117647,
        "end": 4707.76,
        "id": 1132,
        "no_speech_prob": 0.09946484118700027,
        "seek": 468376,
        "start": 4699.76,
        "temperature": 0,
        "text": " And I wonder if this is something that Runway, I mean, I realize the business model here is to use their cloud servers.",
        "tokens": [
          51164,
          400,
          286,
          2441,
          498,
          341,
          307,
          746,
          300,
          8950,
          676,
          11,
          286,
          914,
          11,
          286,
          4325,
          264,
          1606,
          2316,
          510,
          307,
          281,
          764,
          641,
          4588,
          15909,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21919297157449924,
        "compression_ratio": 1.6143497757847534,
        "end": 4713.76,
        "id": 1133,
        "no_speech_prob": 0.2658504843711853,
        "seek": 470776,
        "start": 4708.76,
        "temperature": 0,
        "text": " But I wonder if there is a possibility of doing like an export to JavaScript so I could download a sort of like local.",
        "tokens": [
          50414,
          583,
          286,
          2441,
          498,
          456,
          307,
          257,
          7959,
          295,
          884,
          411,
          364,
          10725,
          281,
          15778,
          370,
          286,
          727,
          5484,
          257,
          1333,
          295,
          411,
          2654,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21919297157449924,
        "compression_ratio": 1.6143497757847534,
        "end": 4717.76,
        "id": 1134,
        "no_speech_prob": 0.2658504843711853,
        "seek": 470776,
        "start": 4713.76,
        "temperature": 0,
        "text": " I think you can download any, it does let you download any model that you've trained.",
        "tokens": [
          50664,
          286,
          519,
          291,
          393,
          5484,
          604,
          11,
          309,
          775,
          718,
          291,
          5484,
          604,
          2316,
          300,
          291,
          600,
          8895,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21919297157449924,
        "compression_ratio": 1.6143497757847534,
        "end": 4719.76,
        "id": 1135,
        "no_speech_prob": 0.2658504843711853,
        "seek": 470776,
        "start": 4717.76,
        "temperature": 0,
        "text": " So, you can work with it locally.",
        "tokens": [
          50864,
          407,
          11,
          291,
          393,
          589,
          365,
          309,
          16143,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21919297157449924,
        "compression_ratio": 1.6143497757847534,
        "end": 4723.76,
        "id": 1136,
        "no_speech_prob": 0.2658504843711853,
        "seek": 470776,
        "start": 4719.76,
        "temperature": 0,
        "text": " But what I would like to download is a JavaScript compatible one.",
        "tokens": [
          50964,
          583,
          437,
          286,
          576,
          411,
          281,
          5484,
          307,
          257,
          15778,
          18218,
          472,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21919297157449924,
        "compression_ratio": 1.6143497757847534,
        "end": 4728.76,
        "id": 1137,
        "no_speech_prob": 0.2658504843711853,
        "seek": 470776,
        "start": 4723.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21919297157449924,
        "compression_ratio": 1.6143497757847534,
        "end": 4735.76,
        "id": 1138,
        "no_speech_prob": 0.2658504843711853,
        "seek": 470776,
        "start": 4728.76,
        "temperature": 0,
        "text": " That was confusing as hell, writes Nitrous Oxide.",
        "tokens": [
          51414,
          663,
          390,
          13181,
          382,
          4921,
          11,
          13657,
          37942,
          21189,
          16489,
          482,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4736.76,
        "id": 1139,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4735.76,
        "temperature": 0,
        "text": " Apologies.",
        "tokens": [
          50364,
          8723,
          6204,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4738.76,
        "id": 1140,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4736.76,
        "temperature": 0,
        "text": " I don't know which part was confusing.",
        "tokens": [
          50414,
          286,
          500,
          380,
          458,
          597,
          644,
          390,
          13181,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4741.76,
        "id": 1141,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4738.76,
        "temperature": 0,
        "text": " But I'm kind of just bouncing around between a lot of different things.",
        "tokens": [
          50514,
          583,
          286,
          478,
          733,
          295,
          445,
          27380,
          926,
          1296,
          257,
          688,
          295,
          819,
          721,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4744.76,
        "id": 1142,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4741.76,
        "temperature": 0,
        "text": " So, I recognize that this could be confusing.",
        "tokens": [
          50664,
          407,
          11,
          286,
          5521,
          300,
          341,
          727,
          312,
          13181,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4745.76,
        "id": 1143,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4744.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50814,
          1057,
          558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4748.76,
        "id": 1144,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4745.76,
        "temperature": 0,
        "text": " So, we've got some non-anonymous people.",
        "tokens": [
          50864,
          407,
          11,
          321,
          600,
          658,
          512,
          2107,
          12,
          282,
          18092,
          561,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4749.76,
        "id": 1145,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4748.76,
        "temperature": 0,
        "text": " Welcome.",
        "tokens": [
          51014,
          4027,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4751.76,
        "id": 1146,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4749.76,
        "temperature": 0,
        "text": " Welcome to this Glitch application.",
        "tokens": [
          51064,
          4027,
          281,
          341,
          5209,
          1549,
          3861,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4756.76,
        "id": 1147,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4751.76,
        "temperature": 0,
        "text": " So, what do I, one of the things that I've been wanting to make as an example for my course.",
        "tokens": [
          51164,
          407,
          11,
          437,
          360,
          286,
          11,
          472,
          295,
          264,
          721,
          300,
          286,
          600,
          668,
          7935,
          281,
          652,
          382,
          364,
          1365,
          337,
          452,
          1164,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4758.76,
        "id": 1148,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4756.76,
        "temperature": 0,
        "text": " And I'm going to go back.",
        "tokens": [
          51414,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17496938029612144,
        "compression_ratio": 1.5851851851851853,
        "end": 4762.76,
        "id": 1149,
        "no_speech_prob": 0.0071211750619113445,
        "seek": 473576,
        "start": 4758.76,
        "temperature": 0,
        "text": " This is very ridiculous what I'm doing here.",
        "tokens": [
          51514,
          639,
          307,
          588,
          11083,
          437,
          286,
          478,
          884,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1954007362251851,
        "compression_ratio": 1.5294117647058822,
        "end": 4766.76,
        "id": 1150,
        "no_speech_prob": 0.10230115056037903,
        "seek": 476276,
        "start": 4762.76,
        "temperature": 0,
        "text": " I'm going to, I can't believe this is what I'm doing.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          11,
          286,
          393,
          380,
          1697,
          341,
          307,
          437,
          286,
          478,
          884,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1954007362251851,
        "compression_ratio": 1.5294117647058822,
        "end": 4768.76,
        "id": 1151,
        "no_speech_prob": 0.10230115056037903,
        "seek": 476276,
        "start": 4766.76,
        "temperature": 0,
        "text": " But it's too late for me.",
        "tokens": [
          50564,
          583,
          309,
          311,
          886,
          3469,
          337,
          385,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1954007362251851,
        "compression_ratio": 1.5294117647058822,
        "end": 4770.76,
        "id": 1152,
        "no_speech_prob": 0.10230115056037903,
        "seek": 476276,
        "start": 4768.76,
        "temperature": 0,
        "text": " I'm going to log into this one.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          3565,
          666,
          341,
          472,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1954007362251851,
        "compression_ratio": 1.5294117647058822,
        "end": 4776.76,
        "id": 1153,
        "no_speech_prob": 0.10230115056037903,
        "seek": 476276,
        "start": 4770.76,
        "temperature": 0,
        "text": " And I'm going to look for models.",
        "tokens": [
          50764,
          400,
          286,
          478,
          516,
          281,
          574,
          337,
          5245,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1954007362251851,
        "compression_ratio": 1.5294117647058822,
        "end": 4784.76,
        "id": 1154,
        "no_speech_prob": 0.10230115056037903,
        "seek": 476276,
        "start": 4776.76,
        "temperature": 0,
        "text": " I want to look for a particular model called spade landscapes.",
        "tokens": [
          51064,
          286,
          528,
          281,
          574,
          337,
          257,
          1729,
          2316,
          1219,
          637,
          762,
          29822,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1684246063232422,
        "compression_ratio": 1.5235294117647058,
        "end": 4790.76,
        "id": 1155,
        "no_speech_prob": 0.12939570844173431,
        "seek": 478476,
        "start": 4784.76,
        "temperature": 0,
        "text": " So, this is an image segmentation model.",
        "tokens": [
          50364,
          407,
          11,
          341,
          307,
          364,
          3256,
          9469,
          399,
          2316,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1684246063232422,
        "compression_ratio": 1.5235294117647058,
        "end": 4798.76,
        "id": 1156,
        "no_speech_prob": 0.12939570844173431,
        "seek": 478476,
        "start": 4790.76,
        "temperature": 0,
        "text": " Which will allow me to, like it says, generate realistic images of landscapes from sketches and doodles.",
        "tokens": [
          50664,
          3013,
          486,
          2089,
          385,
          281,
          11,
          411,
          309,
          1619,
          11,
          8460,
          12465,
          5267,
          295,
          29822,
          490,
          34547,
          293,
          360,
          35192,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1684246063232422,
        "compression_ratio": 1.5235294117647058,
        "end": 4802.76,
        "id": 1157,
        "no_speech_prob": 0.12939570844173431,
        "seek": 478476,
        "start": 4798.76,
        "temperature": 0,
        "text": " Let's take a look at this one.",
        "tokens": [
          51064,
          961,
          311,
          747,
          257,
          574,
          412,
          341,
          472,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1684246063232422,
        "compression_ratio": 1.5235294117647058,
        "end": 4804.76,
        "id": 1158,
        "no_speech_prob": 0.12939570844173431,
        "seek": 478476,
        "start": 4802.76,
        "temperature": 0,
        "text": " See, it's asking me to make a new workspace again.",
        "tokens": [
          51264,
          3008,
          11,
          309,
          311,
          3365,
          385,
          281,
          652,
          257,
          777,
          32706,
          797,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1684246063232422,
        "compression_ratio": 1.5235294117647058,
        "end": 4806.76,
        "id": 1159,
        "no_speech_prob": 0.12939570844173431,
        "seek": 478476,
        "start": 4804.76,
        "temperature": 0,
        "text": " I don't get it.",
        "tokens": [
          51364,
          286,
          500,
          380,
          483,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1684246063232422,
        "compression_ratio": 1.5235294117647058,
        "end": 4809.76,
        "id": 1160,
        "no_speech_prob": 0.12939570844173431,
        "seek": 478476,
        "start": 4806.76,
        "temperature": 0,
        "text": " I don't get it.",
        "tokens": [
          51464,
          286,
          500,
          380,
          483,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4812.76,
        "id": 1161,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4809.76,
        "temperature": 0,
        "text": " Coding train 3.",
        "tokens": [
          50364,
          383,
          8616,
          3847,
          805,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4815.76,
        "id": 1162,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4812.76,
        "temperature": 0,
        "text": " Electric boogaloo.",
        "tokens": [
          50514,
          24677,
          748,
          664,
          304,
          1986,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4817.76,
        "id": 1163,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4815.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4818.76,
        "id": 1164,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4817.76,
        "temperature": 0,
        "text": " Now we're in this model.",
        "tokens": [
          50764,
          823,
          321,
          434,
          294,
          341,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4821.76,
        "id": 1165,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4818.76,
        "temperature": 0,
        "text": " I'm going to choose an input source, which will be a segmentation.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          2826,
          364,
          4846,
          4009,
          11,
          597,
          486,
          312,
          257,
          9469,
          399,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4823.76,
        "id": 1166,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4821.76,
        "temperature": 0,
        "text": " And I'm going to run this model.",
        "tokens": [
          50964,
          400,
          286,
          478,
          516,
          281,
          1190,
          341,
          2316,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4831.76,
        "id": 1167,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4823.76,
        "temperature": 0,
        "text": " So, runway, again, one of the reasons why I love using runway is I can just immediately play around and see how the model works.",
        "tokens": [
          51064,
          407,
          11,
          26642,
          11,
          797,
          11,
          472,
          295,
          264,
          4112,
          983,
          286,
          959,
          1228,
          26642,
          307,
          286,
          393,
          445,
          4258,
          862,
          926,
          293,
          536,
          577,
          264,
          2316,
          1985,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4833.76,
        "id": 1168,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4831.76,
        "temperature": 0,
        "text": " Before trying to build it into my own application.",
        "tokens": [
          51464,
          4546,
          1382,
          281,
          1322,
          309,
          666,
          452,
          1065,
          3861,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1777889314761832,
        "compression_ratio": 1.5960784313725491,
        "end": 4836.76,
        "id": 1169,
        "no_speech_prob": 0.02161475643515587,
        "seek": 480976,
        "start": 4833.76,
        "temperature": 0,
        "text": " So, let's look at how this model works while it's booting up.",
        "tokens": [
          51564,
          407,
          11,
          718,
          311,
          574,
          412,
          577,
          341,
          2316,
          1985,
          1339,
          309,
          311,
          11450,
          278,
          493,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17214884076799666,
        "compression_ratio": 1.7379679144385027,
        "end": 4839.76,
        "id": 1170,
        "no_speech_prob": 0.09807512909173965,
        "seek": 483676,
        "start": 4837.76,
        "temperature": 0,
        "text": " This is an image segmentation model.",
        "tokens": [
          50414,
          639,
          307,
          364,
          3256,
          9469,
          399,
          2316,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17214884076799666,
        "compression_ratio": 1.7379679144385027,
        "end": 4840.76,
        "id": 1171,
        "no_speech_prob": 0.09807512909173965,
        "seek": 483676,
        "start": 4839.76,
        "temperature": 0,
        "text": " What does that mean?",
        "tokens": [
          50514,
          708,
          775,
          300,
          914,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.17214884076799666,
        "compression_ratio": 1.7379679144385027,
        "end": 4845.76,
        "id": 1172,
        "no_speech_prob": 0.09807512909173965,
        "seek": 483676,
        "start": 4840.76,
        "temperature": 0,
        "text": " Usually an image segmentation model is for doing the inverse of what I'm about to do.",
        "tokens": [
          50564,
          11419,
          364,
          3256,
          9469,
          399,
          2316,
          307,
          337,
          884,
          264,
          17340,
          295,
          437,
          286,
          478,
          466,
          281,
          360,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17214884076799666,
        "compression_ratio": 1.7379679144385027,
        "end": 4852.76,
        "id": 1173,
        "no_speech_prob": 0.09807512909173965,
        "seek": 483676,
        "start": 4845.76,
        "temperature": 0,
        "text": " We can see this in, let's see, if I go to ml5 and look at body pics, for example.",
        "tokens": [
          50814,
          492,
          393,
          536,
          341,
          294,
          11,
          718,
          311,
          536,
          11,
          498,
          286,
          352,
          281,
          23271,
          20,
          293,
          574,
          412,
          1772,
          46690,
          11,
          337,
          1365,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17214884076799666,
        "compression_ratio": 1.7379679144385027,
        "end": 4856.76,
        "id": 1174,
        "no_speech_prob": 0.09807512909173965,
        "seek": 483676,
        "start": 4852.76,
        "temperature": 0,
        "text": " This is an image segmentation model.",
        "tokens": [
          51164,
          639,
          307,
          364,
          3256,
          9469,
          399,
          2316,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17214884076799666,
        "compression_ratio": 1.7379679144385027,
        "end": 4860.76,
        "id": 1175,
        "no_speech_prob": 0.09807512909173965,
        "seek": 483676,
        "start": 4856.76,
        "temperature": 0,
        "text": " Actually, let's look at unet.",
        "tokens": [
          51364,
          5135,
          11,
          718,
          311,
          574,
          412,
          517,
          302,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17214884076799666,
        "compression_ratio": 1.7379679144385027,
        "end": 4863.76,
        "id": 1176,
        "no_speech_prob": 0.09807512909173965,
        "seek": 483676,
        "start": 4860.76,
        "temperature": 0,
        "text": " I'm just curious about this one.",
        "tokens": [
          51564,
          286,
          478,
          445,
          6369,
          466,
          341,
          472,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22099294662475585,
        "compression_ratio": 1.4,
        "end": 4867.76,
        "id": 1177,
        "no_speech_prob": 0.0005357781192287803,
        "seek": 486376,
        "start": 4863.76,
        "temperature": 0,
        "text": " Let's go here really quickly and see if I can grab one of the examples.",
        "tokens": [
          50364,
          961,
          311,
          352,
          510,
          534,
          2661,
          293,
          536,
          498,
          286,
          393,
          4444,
          472,
          295,
          264,
          5110,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22099294662475585,
        "compression_ratio": 1.4,
        "end": 4869.76,
        "id": 1178,
        "no_speech_prob": 0.0005357781192287803,
        "seek": 486376,
        "start": 4867.76,
        "temperature": 0,
        "text": " I'm just curious to see if this works.",
        "tokens": [
          50564,
          286,
          478,
          445,
          6369,
          281,
          536,
          498,
          341,
          1985,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22099294662475585,
        "compression_ratio": 1.4,
        "end": 4875.76,
        "id": 1179,
        "no_speech_prob": 0.0005357781192287803,
        "seek": 486376,
        "start": 4869.76,
        "temperature": 0,
        "text": " I haven't run this one in a while.",
        "tokens": [
          50664,
          286,
          2378,
          380,
          1190,
          341,
          472,
          294,
          257,
          1339,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22099294662475585,
        "compression_ratio": 1.4,
        "end": 4878.76,
        "id": 1180,
        "no_speech_prob": 0.0005357781192287803,
        "seek": 486376,
        "start": 4875.76,
        "temperature": 0,
        "text": " Ah, open broadcast studio virtual camera.",
        "tokens": [
          50964,
          2438,
          11,
          1269,
          9975,
          6811,
          6374,
          2799,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22099294662475585,
        "compression_ratio": 1.4,
        "end": 4879.76,
        "id": 1181,
        "no_speech_prob": 0.0005357781192287803,
        "seek": 486376,
        "start": 4878.76,
        "temperature": 0,
        "text": " So frustrating here.",
        "tokens": [
          51114,
          407,
          16522,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22099294662475585,
        "compression_ratio": 1.4,
        "end": 4882.76,
        "id": 1182,
        "no_speech_prob": 0.0005357781192287803,
        "seek": 486376,
        "start": 4879.76,
        "temperature": 0,
        "text": " Let me just search body pics.",
        "tokens": [
          51164,
          961,
          385,
          445,
          3164,
          1772,
          46690,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23428563067787572,
        "compression_ratio": 1.3333333333333333,
        "end": 4894.76,
        "id": 1183,
        "no_speech_prob": 0.05419754981994629,
        "seek": 488276,
        "start": 4883.76,
        "temperature": 0,
        "text": " So, this is what image segmentation typically does.",
        "tokens": [
          50414,
          407,
          11,
          341,
          307,
          437,
          3256,
          9469,
          399,
          5850,
          775,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23428563067787572,
        "compression_ratio": 1.3333333333333333,
        "end": 4900.76,
        "id": 1184,
        "no_speech_prob": 0.05419754981994629,
        "seek": 488276,
        "start": 4894.76,
        "temperature": 0,
        "text": " It takes as the input the image and labels different pixels of the image as part of a given segment.",
        "tokens": [
          50964,
          467,
          2516,
          382,
          264,
          4846,
          264,
          3256,
          293,
          16949,
          819,
          18668,
          295,
          264,
          3256,
          382,
          644,
          295,
          257,
          2212,
          9469,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1874168940952846,
        "compression_ratio": 1.6729323308270676,
        "end": 4914.76,
        "id": 1185,
        "no_speech_prob": 0.030213715508580208,
        "seek": 490076,
        "start": 4901.76,
        "temperature": 0,
        "text": " So, in the body pics model, it's able to recognize the human form and label different parts as torso, green, maybe thigh, as purple, right thigh, left thigh, head, and sort of segment the image that way.",
        "tokens": [
          50414,
          407,
          11,
          294,
          264,
          1772,
          46690,
          2316,
          11,
          309,
          311,
          1075,
          281,
          5521,
          264,
          1952,
          1254,
          293,
          7645,
          819,
          3166,
          382,
          34917,
          11,
          3092,
          11,
          1310,
          27871,
          11,
          382,
          9656,
          11,
          558,
          27871,
          11,
          1411,
          27871,
          11,
          1378,
          11,
          293,
          1333,
          295,
          9469,
          264,
          3256,
          300,
          636,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1874168940952846,
        "compression_ratio": 1.6729323308270676,
        "end": 4921.76,
        "id": 1186,
        "no_speech_prob": 0.030213715508580208,
        "seek": 490076,
        "start": 4914.76,
        "temperature": 0,
        "text": " And you could use that for a variety of different creative applications that I'm sure are swimming around in your head right now.",
        "tokens": [
          51064,
          400,
          291,
          727,
          764,
          300,
          337,
          257,
          5673,
          295,
          819,
          5880,
          5821,
          300,
          286,
          478,
          988,
          366,
          11989,
          926,
          294,
          428,
          1378,
          558,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1874168940952846,
        "compression_ratio": 1.6729323308270676,
        "end": 4929.76,
        "id": 1187,
        "no_speech_prob": 0.030213715508580208,
        "seek": 490076,
        "start": 4921.76,
        "temperature": 0,
        "text": " What I love about the inverse of that, for example, if I come back to this particular image segmentation model,",
        "tokens": [
          51414,
          708,
          286,
          959,
          466,
          264,
          17340,
          295,
          300,
          11,
          337,
          1365,
          11,
          498,
          286,
          808,
          646,
          281,
          341,
          1729,
          3256,
          9469,
          399,
          2316,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4931.76,
        "id": 1188,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4929.76,
        "temperature": 0,
        "text": " is that it's doing the reverse.",
        "tokens": [
          50364,
          307,
          300,
          309,
          311,
          884,
          264,
          9943,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4933.76,
        "id": 1189,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4931.76,
        "temperature": 0,
        "text": " This is a generative model.",
        "tokens": [
          50464,
          639,
          307,
          257,
          1337,
          1166,
          2316,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4935.76,
        "id": 1190,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4933.76,
        "temperature": 0,
        "text": " It's generating an image.",
        "tokens": [
          50564,
          467,
          311,
          17746,
          364,
          3256,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4940.76,
        "id": 1191,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4935.76,
        "temperature": 0,
        "text": " And I am providing the segments via a color map.",
        "tokens": [
          50664,
          400,
          286,
          669,
          6530,
          264,
          19904,
          5766,
          257,
          2017,
          4471,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4941.76,
        "id": 1192,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4940.76,
        "temperature": 0,
        "text": " So, I'm going to create a scene.",
        "tokens": [
          50914,
          407,
          11,
          286,
          478,
          516,
          281,
          1884,
          257,
          4145,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4945.76,
        "id": 1193,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4941.76,
        "temperature": 0,
        "text": " Oh, this is like perfect for doing like a Bob Ross, like pseudo fake.",
        "tokens": [
          50964,
          876,
          11,
          341,
          307,
          411,
          2176,
          337,
          884,
          411,
          257,
          6085,
          16140,
          11,
          411,
          35899,
          7592,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4951.76,
        "id": 1194,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4945.76,
        "temperature": 0,
        "text": " I should really set that up and just have like a little wig and a little like thing that I could paint colors on and have it generate the landscape for me.",
        "tokens": [
          51164,
          286,
          820,
          534,
          992,
          300,
          493,
          293,
          445,
          362,
          411,
          257,
          707,
          24094,
          293,
          257,
          707,
          411,
          551,
          300,
          286,
          727,
          4225,
          4577,
          322,
          293,
          362,
          309,
          8460,
          264,
          9661,
          337,
          385,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4952.76,
        "id": 1195,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4951.76,
        "temperature": 0,
        "text": " This is great.",
        "tokens": [
          51464,
          639,
          307,
          869,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19665267523818128,
        "compression_ratio": 1.6545454545454545,
        "end": 4954.76,
        "id": 1196,
        "no_speech_prob": 0.004905337933450937,
        "seek": 492976,
        "start": 4952.76,
        "temperature": 0,
        "text": " That'll be next Halloween or April Fool's Day.",
        "tokens": [
          51514,
          663,
          603,
          312,
          958,
          13860,
          420,
          6929,
          41583,
          311,
          5226,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18083715438842773,
        "compression_ratio": 1.6073298429319371,
        "end": 4959.76,
        "id": 1197,
        "no_speech_prob": 0.10087331384420395,
        "seek": 495476,
        "start": 4954.76,
        "temperature": 0,
        "text": " But I can sort of paint over here because this is where the grass should be.",
        "tokens": [
          50364,
          583,
          286,
          393,
          1333,
          295,
          4225,
          670,
          510,
          570,
          341,
          307,
          689,
          264,
          8054,
          820,
          312,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18083715438842773,
        "compression_ratio": 1.6073298429319371,
        "end": 4964.76,
        "id": 1198,
        "no_speech_prob": 0.10087331384420395,
        "seek": 495476,
        "start": 4959.76,
        "temperature": 0,
        "text": " And you can see it's starting to generate this image below.",
        "tokens": [
          50614,
          400,
          291,
          393,
          536,
          309,
          311,
          2891,
          281,
          8460,
          341,
          3256,
          2507,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18083715438842773,
        "compression_ratio": 1.6073298429319371,
        "end": 4973.76,
        "id": 1199,
        "no_speech_prob": 0.10087331384420395,
        "seek": 495476,
        "start": 4964.76,
        "temperature": 0,
        "text": " Then I'm going to add a river that's going to flow like through here.",
        "tokens": [
          50864,
          1396,
          286,
          478,
          516,
          281,
          909,
          257,
          6810,
          300,
          311,
          516,
          281,
          3095,
          411,
          807,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18083715438842773,
        "compression_ratio": 1.6073298429319371,
        "end": 4975.76,
        "id": 1200,
        "no_speech_prob": 0.10087331384420395,
        "seek": 495476,
        "start": 4973.76,
        "temperature": 0,
        "text": " I don't know if this makes sense.",
        "tokens": [
          51314,
          286,
          500,
          380,
          458,
          498,
          341,
          1669,
          2020,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18083715438842773,
        "compression_ratio": 1.6073298429319371,
        "end": 4979.76,
        "id": 1201,
        "no_speech_prob": 0.10087331384420395,
        "seek": 495476,
        "start": 4975.76,
        "temperature": 0,
        "text": " Let's add a river.",
        "tokens": [
          51414,
          961,
          311,
          909,
          257,
          6810,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18083715438842773,
        "compression_ratio": 1.6073298429319371,
        "end": 4981.76,
        "id": 1202,
        "no_speech_prob": 0.10087331384420395,
        "seek": 495476,
        "start": 4979.76,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51614,
          286,
          500,
          380,
          458,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18083715438842773,
        "compression_ratio": 1.6073298429319371,
        "end": 4983.76,
        "id": 1203,
        "no_speech_prob": 0.10087331384420395,
        "seek": 495476,
        "start": 4981.76,
        "temperature": 0,
        "text": " That's very weird what I'm doing.",
        "tokens": [
          51714,
          663,
          311,
          588,
          3657,
          437,
          286,
          478,
          884,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19733203725611909,
        "compression_ratio": 1.2280701754385965,
        "end": 4991.76,
        "id": 1204,
        "no_speech_prob": 0.07695770263671875,
        "seek": 498376,
        "start": 4983.76,
        "temperature": 0,
        "text": " Let's draw some trees.",
        "tokens": [
          50364,
          961,
          311,
          2642,
          512,
          5852,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19733203725611909,
        "compression_ratio": 1.2280701754385965,
        "end": 5000.76,
        "id": 1205,
        "no_speech_prob": 0.07695770263671875,
        "seek": 498376,
        "start": 4991.76,
        "temperature": 0,
        "text": " Some trees here and some clouds in the sky.",
        "tokens": [
          50764,
          2188,
          5852,
          510,
          293,
          512,
          12193,
          294,
          264,
          5443,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19733203725611909,
        "compression_ratio": 1.2280701754385965,
        "end": 5002.76,
        "id": 1206,
        "no_speech_prob": 0.07695770263671875,
        "seek": 498376,
        "start": 5000.76,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51214,
          400,
          456,
          321,
          352,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19733203725611909,
        "compression_ratio": 1.2280701754385965,
        "end": 5004.76,
        "id": 1207,
        "no_speech_prob": 0.07695770263671875,
        "seek": 498376,
        "start": 5002.76,
        "temperature": 0,
        "text": " Oh, look at my beautiful landscape.",
        "tokens": [
          51314,
          876,
          11,
          574,
          412,
          452,
          2238,
          9661,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19733203725611909,
        "compression_ratio": 1.2280701754385965,
        "end": 5006.76,
        "id": 1208,
        "no_speech_prob": 0.07695770263671875,
        "seek": 498376,
        "start": 5004.76,
        "temperature": 0,
        "text": " I am such an artist.",
        "tokens": [
          51414,
          286,
          669,
          1270,
          364,
          5748,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20524274541976603,
        "compression_ratio": 1.7116279069767442,
        "end": 5014.76,
        "id": 1209,
        "no_speech_prob": 0.7339816689491272,
        "seek": 500676,
        "start": 5007.76,
        "temperature": 0,
        "text": " So, what I have done with this model is I have generated this image from this segment map.",
        "tokens": [
          50414,
          407,
          11,
          437,
          286,
          362,
          1096,
          365,
          341,
          2316,
          307,
          286,
          362,
          10833,
          341,
          3256,
          490,
          341,
          9469,
          4471,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20524274541976603,
        "compression_ratio": 1.7116279069767442,
        "end": 5017.76,
        "id": 1210,
        "no_speech_prob": 0.7339816689491272,
        "seek": 500676,
        "start": 5014.76,
        "temperature": 0,
        "text": " So, this is fun to play around with Runway.",
        "tokens": [
          50764,
          407,
          11,
          341,
          307,
          1019,
          281,
          862,
          926,
          365,
          8950,
          676,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20524274541976603,
        "compression_ratio": 1.7116279069767442,
        "end": 5019.76,
        "id": 1211,
        "no_speech_prob": 0.7339816689491272,
        "seek": 500676,
        "start": 5017.76,
        "temperature": 0,
        "text": " And if this is all I want to do, then great.",
        "tokens": [
          50914,
          400,
          498,
          341,
          307,
          439,
          286,
          528,
          281,
          360,
          11,
          550,
          869,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20524274541976603,
        "compression_ratio": 1.7116279069767442,
        "end": 5032.76,
        "id": 1212,
        "no_speech_prob": 0.7339816689491272,
        "seek": 500676,
        "start": 5019.76,
        "temperature": 0,
        "text": " But what if I wanted to create my own P5.js sketch or processing sketch or other type of software application where the segment map is the segmentation map is generated in a different way?",
        "tokens": [
          51014,
          583,
          437,
          498,
          286,
          1415,
          281,
          1884,
          452,
          1065,
          430,
          20,
          13,
          25530,
          12325,
          420,
          9007,
          12325,
          420,
          661,
          2010,
          295,
          4722,
          3861,
          689,
          264,
          9469,
          4471,
          307,
          264,
          9469,
          399,
          4471,
          307,
          10833,
          294,
          257,
          819,
          636,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.21876591444015503,
        "compression_ratio": 1.79,
        "end": 5035.76,
        "id": 1213,
        "no_speech_prob": 0.07695640623569489,
        "seek": 503276,
        "start": 5032.76,
        "temperature": 0,
        "text": " What I want to do right now is just recreate exactly this.",
        "tokens": [
          50364,
          708,
          286,
          528,
          281,
          360,
          558,
          586,
          307,
          445,
          25833,
          2293,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21876591444015503,
        "compression_ratio": 1.79,
        "end": 5045.76,
        "id": 1214,
        "no_speech_prob": 0.07695640623569489,
        "seek": 503276,
        "start": 5035.76,
        "temperature": 0,
        "text": " So, I want to go look at that glitch template and recreate exactly this interaction, but with my own code.",
        "tokens": [
          50514,
          407,
          11,
          286,
          528,
          281,
          352,
          574,
          412,
          300,
          23552,
          12379,
          293,
          25833,
          2293,
          341,
          9285,
          11,
          457,
          365,
          452,
          1065,
          3089,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21876591444015503,
        "compression_ratio": 1.79,
        "end": 5048.76,
        "id": 1215,
        "no_speech_prob": 0.07695640623569489,
        "seek": 503276,
        "start": 5045.76,
        "temperature": 0,
        "text": " So, first I'm going to hit stop.",
        "tokens": [
          51014,
          407,
          11,
          700,
          286,
          478,
          516,
          281,
          2045,
          1590,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21876591444015503,
        "compression_ratio": 1.79,
        "end": 5055.76,
        "id": 1216,
        "no_speech_prob": 0.07695640623569489,
        "seek": 503276,
        "start": 5048.76,
        "temperature": 0,
        "text": " Then I'm going to go to one thing I really want to do is click this export colors because I really need to get the colors right.",
        "tokens": [
          51164,
          1396,
          286,
          478,
          516,
          281,
          352,
          281,
          220,
          546,
          551,
          286,
          534,
          528,
          281,
          360,
          307,
          2052,
          341,
          10725,
          4577,
          570,
          286,
          534,
          643,
          281,
          483,
          264,
          4577,
          558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21876591444015503,
        "compression_ratio": 1.79,
        "end": 5058.76,
        "id": 1217,
        "no_speech_prob": 0.07695640623569489,
        "seek": 503276,
        "start": 5055.76,
        "temperature": 0,
        "text": " So, let's click export colors.",
        "tokens": [
          51514,
          407,
          11,
          718,
          311,
          2052,
          10725,
          4577,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5061.76,
        "id": 1218,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5059.76,
        "temperature": 0,
        "text": " And it came in as a CSV.",
        "tokens": [
          50414,
          400,
          309,
          1361,
          294,
          382,
          257,
          48814,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5064.76,
        "id": 1219,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5061.76,
        "temperature": 0,
        "text": " So, I'll take a look at that in a moment.",
        "tokens": [
          50514,
          407,
          11,
          286,
          603,
          747,
          257,
          574,
          412,
          300,
          294,
          257,
          1623,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5066.76,
        "id": 1220,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5064.76,
        "temperature": 0,
        "text": " Let's just put that over there.",
        "tokens": [
          50664,
          961,
          311,
          445,
          829,
          300,
          670,
          456,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5067.76,
        "id": 1221,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5066.76,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50764,
          45263,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5069.76,
        "id": 1222,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5067.76,
        "temperature": 0,
        "text": " How come you didn't show up over here?",
        "tokens": [
          50814,
          1012,
          808,
          291,
          994,
          380,
          855,
          493,
          670,
          510,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5072.76,
        "id": 1223,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5069.76,
        "temperature": 0,
        "text": " Where are you, colors?",
        "tokens": [
          50914,
          2305,
          366,
          291,
          11,
          4577,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5075.76,
        "id": 1224,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5072.76,
        "temperature": 0,
        "text": " And I'll find that later.",
        "tokens": [
          51064,
          400,
          286,
          603,
          915,
          300,
          1780,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5079.76,
        "id": 1225,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5075.76,
        "temperature": 0,
        "text": " Let's go to ‑‑ whoops.",
        "tokens": [
          51214,
          961,
          311,
          352,
          281,
          220,
          27392,
          27392,
          567,
          3370,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5084.76,
        "id": 1226,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5079.76,
        "temperature": 0,
        "text": " Let's host this model and host the model.",
        "tokens": [
          51414,
          961,
          311,
          3975,
          341,
          2316,
          293,
          3975,
          264,
          2316,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18231421654377508,
        "compression_ratio": 1.4832535885167464,
        "end": 5087.76,
        "id": 1227,
        "no_speech_prob": 0.03308501094579697,
        "seek": 505876,
        "start": 5084.76,
        "temperature": 0,
        "text": " I'm going to have to not show you my API keys.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          362,
          281,
          406,
          855,
          291,
          452,
          9362,
          9317,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5088.76,
        "id": 1228,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5087.76,
        "temperature": 0,
        "text": " Let's turn this one off.",
        "tokens": [
          50364,
          961,
          311,
          1261,
          341,
          472,
          766,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5090.76,
        "id": 1229,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5088.76,
        "temperature": 0,
        "text": " I don't need that one on.",
        "tokens": [
          50414,
          286,
          500,
          380,
          643,
          300,
          472,
          322,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5091.76,
        "id": 1230,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5090.76,
        "temperature": 0,
        "text": " I'm going to go here.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5095.76,
        "id": 1231,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5091.76,
        "temperature": 0,
        "text": " So, now I want ‑‑ how do you do this in Runway if this is my project?",
        "tokens": [
          50564,
          407,
          11,
          586,
          286,
          528,
          45217,
          577,
          360,
          291,
          360,
          341,
          294,
          8950,
          676,
          498,
          341,
          307,
          452,
          1716,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5097.76,
        "id": 1232,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5095.76,
        "temperature": 0,
        "text": " I think I can still do remix.",
        "tokens": [
          50764,
          286,
          519,
          286,
          393,
          920,
          360,
          47788,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5102.76,
        "id": 1233,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5097.76,
        "temperature": 0,
        "text": " So, I'm going to show you the process of starting with my template and remixing it.",
        "tokens": [
          50864,
          407,
          11,
          286,
          478,
          516,
          281,
          855,
          291,
          264,
          1399,
          295,
          2891,
          365,
          452,
          12379,
          293,
          47788,
          278,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5105.76,
        "id": 1234,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5102.76,
        "temperature": 0,
        "text": " So, I'm going to hit remix.",
        "tokens": [
          51114,
          407,
          11,
          286,
          478,
          516,
          281,
          2045,
          47788,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18335183950570913,
        "compression_ratio": 1.71875,
        "end": 5116.76,
        "id": 1235,
        "no_speech_prob": 0.010488883592188358,
        "seek": 508776,
        "start": 5105.76,
        "temperature": 0,
        "text": " And then this will be ‑‑ and ideally my goal here is to create like many, many, many examples in Glitch of working with different models in Runway.",
        "tokens": [
          51264,
          400,
          550,
          341,
          486,
          312,
          45217,
          293,
          22915,
          452,
          3387,
          510,
          307,
          281,
          1884,
          411,
          867,
          11,
          867,
          11,
          867,
          5110,
          294,
          5209,
          1549,
          295,
          1364,
          365,
          819,
          5245,
          294,
          8950,
          676,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5123.76,
        "id": 1236,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5117.76,
        "temperature": 0,
        "text": " So, I'm going to call this a spade co‑coding train.",
        "tokens": [
          50414,
          407,
          11,
          286,
          478,
          516,
          281,
          818,
          341,
          257,
          637,
          762,
          598,
          27392,
          66,
          8616,
          3847,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5127.76,
        "id": 1237,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5123.76,
        "temperature": 0,
        "text": " Oh, that's a co‑coding train.",
        "tokens": [
          50714,
          876,
          11,
          300,
          311,
          257,
          598,
          27392,
          66,
          8616,
          3847,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5128.76,
        "id": 1238,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5127.76,
        "temperature": 0,
        "text": " Choo, choo.",
        "tokens": [
          50914,
          761,
          1986,
          11,
          1586,
          78,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5130.76,
        "id": 1239,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5128.76,
        "temperature": 0,
        "text": " Yeah, it's got to have the choo, choo on there.",
        "tokens": [
          50964,
          865,
          11,
          309,
          311,
          658,
          281,
          362,
          264,
          1586,
          78,
          11,
          1586,
          78,
          322,
          456,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5132.76,
        "id": 1240,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5130.76,
        "temperature": 0,
        "text": " This is everything.",
        "tokens": [
          51064,
          639,
          307,
          1203,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5133.76,
        "id": 1241,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5132.76,
        "temperature": 0,
        "text": " Here we go, right?",
        "tokens": [
          51164,
          1692,
          321,
          352,
          11,
          558,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5135.76,
        "id": 1242,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5133.76,
        "temperature": 0,
        "text": " No, put a little dash there.",
        "tokens": [
          51214,
          883,
          11,
          829,
          257,
          707,
          8240,
          456,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5136.76,
        "id": 1243,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5135.76,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51314,
          821,
          321,
          352,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5140.76,
        "id": 1244,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5136.76,
        "temperature": 0,
        "text": " This is like the best name of any Glitch project ever.",
        "tokens": [
          51364,
          639,
          307,
          411,
          264,
          1151,
          1315,
          295,
          604,
          5209,
          1549,
          1716,
          1562,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23210198775581692,
        "compression_ratio": 1.5854922279792747,
        "end": 5144.76,
        "id": 1245,
        "no_speech_prob": 0.08151387423276901,
        "seek": 511676,
        "start": 5140.76,
        "temperature": 0,
        "text": " Spade co‑coding train.",
        "tokens": [
          51564,
          1738,
          762,
          598,
          27392,
          66,
          8616,
          3847,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21622681199458607,
        "compression_ratio": 1.6493506493506493,
        "end": 5149.76,
        "id": 1246,
        "no_speech_prob": 0.014502868056297302,
        "seek": 514476,
        "start": 5145.76,
        "temperature": 0,
        "text": " Now, I'm going to hit ‑‑ and look at this.",
        "tokens": [
          50414,
          823,
          11,
          286,
          478,
          516,
          281,
          2045,
          45217,
          293,
          574,
          412,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21622681199458607,
        "compression_ratio": 1.6493506493506493,
        "end": 5153.76,
        "id": 1247,
        "no_speech_prob": 0.014502868056297302,
        "seek": 514476,
        "start": 5149.76,
        "temperature": 0,
        "text": " So, I should be going to the.env files and nothing is there.",
        "tokens": [
          50614,
          407,
          11,
          286,
          820,
          312,
          516,
          281,
          264,
          2411,
          268,
          85,
          7098,
          293,
          1825,
          307,
          456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21622681199458607,
        "compression_ratio": 1.6493506493506493,
        "end": 5157.76,
        "id": 1248,
        "no_speech_prob": 0.014502868056297302,
        "seek": 514476,
        "start": 5153.76,
        "temperature": 0,
        "text": " So, just to be safe and secure, I'm going to make my daily limit five.",
        "tokens": [
          50814,
          407,
          11,
          445,
          281,
          312,
          3273,
          293,
          7144,
          11,
          286,
          478,
          516,
          281,
          652,
          452,
          5212,
          4948,
          1732,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21622681199458607,
        "compression_ratio": 1.6493506493506493,
        "end": 5167.76,
        "id": 1249,
        "no_speech_prob": 0.014502868056297302,
        "seek": 514476,
        "start": 5157.76,
        "temperature": 0,
        "text": " So, make sure that as I start putting this in there, if my token goes out into the wild of the URL, if this project goes out into the wild, I'll have some protections.",
        "tokens": [
          51014,
          407,
          11,
          652,
          988,
          300,
          382,
          286,
          722,
          3372,
          341,
          294,
          456,
          11,
          498,
          452,
          14862,
          1709,
          484,
          666,
          264,
          4868,
          295,
          264,
          12905,
          11,
          498,
          341,
          1716,
          1709,
          484,
          666,
          264,
          4868,
          11,
          286,
          603,
          362,
          512,
          29031,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21622681199458607,
        "compression_ratio": 1.6493506493506493,
        "end": 5168.76,
        "id": 1250,
        "no_speech_prob": 0.014502868056297302,
        "seek": 514476,
        "start": 5167.76,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          51514,
          467,
          311,
          2489,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21622681199458607,
        "compression_ratio": 1.6493506493506493,
        "end": 5170.76,
        "id": 1251,
        "no_speech_prob": 0.014502868056297302,
        "seek": 514476,
        "start": 5168.76,
        "temperature": 0,
        "text": " Let's just make it 100.",
        "tokens": [
          51564,
          961,
          311,
          445,
          652,
          309,
          2319,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18385227359071069,
        "compression_ratio": 1.5205479452054795,
        "end": 5176.76,
        "id": 1252,
        "no_speech_prob": 0.1824163943529129,
        "seek": 517076,
        "start": 5171.76,
        "temperature": 0,
        "text": " And then the server I'm suggesting doesn't need to change.",
        "tokens": [
          50414,
          400,
          550,
          264,
          7154,
          286,
          478,
          18094,
          1177,
          380,
          643,
          281,
          1319,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18385227359071069,
        "compression_ratio": 1.5205479452054795,
        "end": 5179.76,
        "id": 1253,
        "no_speech_prob": 0.1824163943529129,
        "seek": 517076,
        "start": 5176.76,
        "temperature": 0,
        "text": " The server is totally generic.",
        "tokens": [
          50664,
          440,
          7154,
          307,
          3879,
          19577,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18385227359071069,
        "compression_ratio": 1.5205479452054795,
        "end": 5188.76,
        "id": 1254,
        "no_speech_prob": 0.1824163943529129,
        "seek": 517076,
        "start": 5179.76,
        "temperature": 0,
        "text": " As long as I send my request to the runway ML endpoint on the server, the inputs come in, go to the model, the outputs go out.",
        "tokens": [
          50814,
          1018,
          938,
          382,
          286,
          2845,
          452,
          5308,
          281,
          264,
          26642,
          21601,
          35795,
          322,
          264,
          7154,
          11,
          264,
          15743,
          808,
          294,
          11,
          352,
          281,
          264,
          2316,
          11,
          264,
          23930,
          352,
          484,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18385227359071069,
        "compression_ratio": 1.5205479452054795,
        "end": 5192.76,
        "id": 1255,
        "no_speech_prob": 0.1824163943529129,
        "seek": 517076,
        "start": 5188.76,
        "temperature": 0,
        "text": " So, I just want to work on my P5 code.",
        "tokens": [
          51264,
          407,
          11,
          286,
          445,
          528,
          281,
          589,
          322,
          452,
          430,
          20,
          3089,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18385227359071069,
        "compression_ratio": 1.5205479452054795,
        "end": 5195.76,
        "id": 1256,
        "no_speech_prob": 0.1824163943529129,
        "seek": 517076,
        "start": 5192.76,
        "temperature": 0,
        "text": " So, here I am in Sketch.js.",
        "tokens": [
          51464,
          407,
          11,
          510,
          286,
          669,
          294,
          49245,
          13,
          25530,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18385227359071069,
        "compression_ratio": 1.5205479452054795,
        "end": 5198.76,
        "id": 1257,
        "no_speech_prob": 0.1824163943529129,
        "seek": 517076,
        "start": 5195.76,
        "temperature": 0,
        "text": " This is ‑‑ and I need to do this differently.",
        "tokens": [
          51614,
          639,
          307,
          45217,
          293,
          286,
          643,
          281,
          360,
          341,
          7614,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1999164762951079,
        "compression_ratio": 1.5052631578947369,
        "end": 5203.76,
        "id": 1258,
        "no_speech_prob": 0.02556433156132698,
        "seek": 519876,
        "start": 5198.76,
        "temperature": 0,
        "text": " So, very quickly, let's not worry about runway for a second.",
        "tokens": [
          50364,
          407,
          11,
          588,
          2661,
          11,
          718,
          311,
          406,
          3292,
          466,
          26642,
          337,
          257,
          1150,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1999164762951079,
        "compression_ratio": 1.5052631578947369,
        "end": 5214.76,
        "id": 1259,
        "no_speech_prob": 0.02556433156132698,
        "seek": 519876,
        "start": 5203.76,
        "temperature": 0,
        "text": " This image should be send ‑‑ it should be called send image because I am not sending a vector.",
        "tokens": [
          50614,
          639,
          3256,
          820,
          312,
          2845,
          45217,
          309,
          820,
          312,
          1219,
          2845,
          3256,
          570,
          286,
          669,
          406,
          7750,
          257,
          8062,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1999164762951079,
        "compression_ratio": 1.5052631578947369,
        "end": 5219.76,
        "id": 1260,
        "no_speech_prob": 0.02556433156132698,
        "seek": 519876,
        "start": 5214.76,
        "temperature": 0,
        "text": " The input to spade cocoa is an image.",
        "tokens": [
          51164,
          440,
          4846,
          281,
          637,
          762,
          30634,
          307,
          364,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1999164762951079,
        "compression_ratio": 1.5052631578947369,
        "end": 5220.76,
        "id": 1261,
        "no_speech_prob": 0.02556433156132698,
        "seek": 519876,
        "start": 5219.76,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51414,
          876,
          11,
          1338,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1999164762951079,
        "compression_ratio": 1.5052631578947369,
        "end": 5221.76,
        "id": 1262,
        "no_speech_prob": 0.02556433156132698,
        "seek": 519876,
        "start": 5220.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1999164762951079,
        "compression_ratio": 1.5052631578947369,
        "end": 5224.76,
        "id": 1263,
        "no_speech_prob": 0.02556433156132698,
        "seek": 519876,
        "start": 5221.76,
        "temperature": 0,
        "text": " So, I'm going to take ‑‑ I'm not going to worry about this just yet.",
        "tokens": [
          51514,
          407,
          11,
          286,
          478,
          516,
          281,
          747,
          45217,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          341,
          445,
          1939,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17576093259065048,
        "compression_ratio": 1.5174129353233832,
        "end": 5231.76,
        "id": 1264,
        "no_speech_prob": 0.02635432407259941,
        "seek": 522476,
        "start": 5224.76,
        "temperature": 0,
        "text": " So, let's actually comment all this out just for the time being.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          767,
          2871,
          439,
          341,
          484,
          445,
          337,
          264,
          565,
          885,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17576093259065048,
        "compression_ratio": 1.5174129353233832,
        "end": 5236.76,
        "id": 1265,
        "no_speech_prob": 0.02635432407259941,
        "seek": 522476,
        "start": 5231.76,
        "temperature": 0,
        "text": " And let's look at this in a new window.",
        "tokens": [
          50714,
          400,
          718,
          311,
          574,
          412,
          341,
          294,
          257,
          777,
          4910,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17576093259065048,
        "compression_ratio": 1.5174129353233832,
        "end": 5237.76,
        "id": 1266,
        "no_speech_prob": 0.02635432407259941,
        "seek": 522476,
        "start": 5236.76,
        "temperature": 0,
        "text": " Failed to start.",
        "tokens": [
          50964,
          479,
          24731,
          281,
          722,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17576093259065048,
        "compression_ratio": 1.5174129353233832,
        "end": 5239.76,
        "id": 1267,
        "no_speech_prob": 0.02635432407259941,
        "seek": 522476,
        "start": 5237.76,
        "temperature": 0,
        "text": " There's an error in my project.",
        "tokens": [
          51014,
          821,
          311,
          364,
          6713,
          294,
          452,
          1716,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17576093259065048,
        "compression_ratio": 1.5174129353233832,
        "end": 5240.76,
        "id": 1268,
        "no_speech_prob": 0.02635432407259941,
        "seek": 522476,
        "start": 5239.76,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51114,
          1779,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17576093259065048,
        "compression_ratio": 1.5174129353233832,
        "end": 5247.76,
        "id": 1269,
        "no_speech_prob": 0.02635432407259941,
        "seek": 522476,
        "start": 5240.76,
        "temperature": 0,
        "text": " The error in the project, which I can see here by going probably under tools, under logs, is that there is no valid token.",
        "tokens": [
          51164,
          440,
          6713,
          294,
          264,
          1716,
          11,
          597,
          286,
          393,
          536,
          510,
          538,
          516,
          1391,
          833,
          3873,
          11,
          833,
          20820,
          11,
          307,
          300,
          456,
          307,
          572,
          7363,
          14862,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17576093259065048,
        "compression_ratio": 1.5174129353233832,
        "end": 5250.76,
        "id": 1270,
        "no_speech_prob": 0.02635432407259941,
        "seek": 522476,
        "start": 5247.76,
        "temperature": 0,
        "text": " So, hold off on that.",
        "tokens": [
          51514,
          407,
          11,
          1797,
          766,
          322,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21300502533608295,
        "compression_ratio": 1.2,
        "end": 5254.76,
        "id": 1271,
        "no_speech_prob": 0.3629356324672699,
        "seek": 525076,
        "start": 5251.76,
        "temperature": 0,
        "text": " I'll put the token in in a little bit.",
        "tokens": [
          50414,
          286,
          603,
          829,
          264,
          14862,
          294,
          294,
          257,
          707,
          857,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21300502533608295,
        "compression_ratio": 1.2,
        "end": 5265.76,
        "id": 1272,
        "no_speech_prob": 0.3629356324672699,
        "seek": 525076,
        "start": 5254.76,
        "temperature": 0,
        "text": " And what I want to do here is instead, let's say background 255, function draw.",
        "tokens": [
          50564,
          400,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          2602,
          11,
          718,
          311,
          584,
          3678,
          3552,
          20,
          11,
          2445,
          2642,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21300502533608295,
        "compression_ratio": 1.2,
        "end": 5269.76,
        "id": 1273,
        "no_speech_prob": 0.3629356324672699,
        "seek": 525076,
        "start": 5265.76,
        "temperature": 0,
        "text": " I'm going to say ellipse.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          584,
          8284,
          48041,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2046900612967355,
        "compression_ratio": 1.6026200873362446,
        "end": 5271.76,
        "id": 1274,
        "no_speech_prob": 0.20179568231105804,
        "seek": 526976,
        "start": 5269.76,
        "temperature": 0,
        "text": " I'm going to make this in the simplest way.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          652,
          341,
          294,
          264,
          22811,
          636,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2046900612967355,
        "compression_ratio": 1.6026200873362446,
        "end": 5281.76,
        "id": 1275,
        "no_speech_prob": 0.20179568231105804,
        "seek": 526976,
        "start": 5271.76,
        "temperature": 0,
        "text": " If mouse is pressed ellipse, mouse X, mouse Y, 32.",
        "tokens": [
          50464,
          759,
          9719,
          307,
          17355,
          8284,
          48041,
          11,
          9719,
          1783,
          11,
          9719,
          398,
          11,
          8858,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2046900612967355,
        "compression_ratio": 1.6026200873362446,
        "end": 5291.76,
        "id": 1276,
        "no_speech_prob": 0.20179568231105804,
        "seek": 526976,
        "start": 5281.76,
        "temperature": 0,
        "text": " So, obviously, I would probably in a sort of fantasy way of doing this, I would want to create a whole drawing interface where I can select colors and change the size.",
        "tokens": [
          50964,
          407,
          11,
          2745,
          11,
          286,
          576,
          1391,
          294,
          257,
          1333,
          295,
          13861,
          636,
          295,
          884,
          341,
          11,
          286,
          576,
          528,
          281,
          1884,
          257,
          1379,
          6316,
          9226,
          689,
          286,
          393,
          3048,
          4577,
          293,
          1319,
          264,
          2744,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2046900612967355,
        "compression_ratio": 1.6026200873362446,
        "end": 5293.76,
        "id": 1277,
        "no_speech_prob": 0.20179568231105804,
        "seek": 526976,
        "start": 5291.76,
        "temperature": 0,
        "text": " I'm not going to do any of that right now.",
        "tokens": [
          51464,
          286,
          478,
          406,
          516,
          281,
          360,
          604,
          295,
          300,
          558,
          586,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2046900612967355,
        "compression_ratio": 1.6026200873362446,
        "end": 5295.76,
        "id": 1278,
        "no_speech_prob": 0.20179568231105804,
        "seek": 526976,
        "start": 5293.76,
        "temperature": 0,
        "text": " I just want to see it draw.",
        "tokens": [
          51564,
          286,
          445,
          528,
          281,
          536,
          309,
          2642,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2046900612967355,
        "compression_ratio": 1.6026200873362446,
        "end": 5297.76,
        "id": 1279,
        "no_speech_prob": 0.20179568231105804,
        "seek": 526976,
        "start": 5295.76,
        "temperature": 0,
        "text": " And let me get one of the colors.",
        "tokens": [
          51664,
          400,
          718,
          385,
          483,
          472,
          295,
          264,
          4577,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20022275050481161,
        "compression_ratio": 1.4824120603015076,
        "end": 5307.76,
        "id": 1280,
        "no_speech_prob": 0.010986720211803913,
        "seek": 529776,
        "start": 5297.76,
        "temperature": 0,
        "text": " So, if I go to the desktop, and I think this is the colors, can I open this with, I don't know what, Visual Studio Code.",
        "tokens": [
          50364,
          407,
          11,
          498,
          286,
          352,
          281,
          264,
          14502,
          11,
          293,
          286,
          519,
          341,
          307,
          264,
          4577,
          11,
          393,
          286,
          1269,
          341,
          365,
          11,
          286,
          500,
          380,
          458,
          437,
          11,
          23187,
          13500,
          15549,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20022275050481161,
        "compression_ratio": 1.4824120603015076,
        "end": 5310.76,
        "id": 1281,
        "no_speech_prob": 0.010986720211803913,
        "seek": 529776,
        "start": 5307.76,
        "temperature": 0,
        "text": " Can I actually just bring this into like assets?",
        "tokens": [
          50864,
          1664,
          286,
          767,
          445,
          1565,
          341,
          666,
          411,
          9769,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.20022275050481161,
        "compression_ratio": 1.4824120603015076,
        "end": 5312.76,
        "id": 1282,
        "no_speech_prob": 0.010986720211803913,
        "seek": 529776,
        "start": 5310.76,
        "temperature": 0,
        "text": " Whoa, no, I don't want to open numbers.",
        "tokens": [
          51014,
          7521,
          11,
          572,
          11,
          286,
          500,
          380,
          528,
          281,
          1269,
          3547,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20022275050481161,
        "compression_ratio": 1.4824120603015076,
        "end": 5314.76,
        "id": 1283,
        "no_speech_prob": 0.010986720211803913,
        "seek": 529776,
        "start": 5312.76,
        "temperature": 0,
        "text": " Are you insane?",
        "tokens": [
          51114,
          2014,
          291,
          10838,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.20022275050481161,
        "compression_ratio": 1.4824120603015076,
        "end": 5315.76,
        "id": 1284,
        "no_speech_prob": 0.010986720211803913,
        "seek": 529776,
        "start": 5314.76,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51214,
          3769,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20022275050481161,
        "compression_ratio": 1.4824120603015076,
        "end": 5316.76,
        "id": 1285,
        "no_speech_prob": 0.010986720211803913,
        "seek": 529776,
        "start": 5315.76,
        "temperature": 0,
        "text": " So, here we go.",
        "tokens": [
          51264,
          407,
          11,
          510,
          321,
          352,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20022275050481161,
        "compression_ratio": 1.4824120603015076,
        "end": 5320.76,
        "id": 1286,
        "no_speech_prob": 0.010986720211803913,
        "seek": 529776,
        "start": 5316.76,
        "temperature": 0,
        "text": " So, let's start with sky, which is this color.",
        "tokens": [
          51314,
          407,
          11,
          718,
          311,
          722,
          365,
          5443,
          11,
          597,
          307,
          341,
          2017,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21791382466465975,
        "compression_ratio": 1.618705035971223,
        "end": 5328.76,
        "id": 1287,
        "no_speech_prob": 0.4186522364616394,
        "seek": 532076,
        "start": 5321.76,
        "temperature": 0,
        "text": " And I could load, I would want to load from this file and make this much fancier, but I'm doing the quickest Hello World version of this, I can think.",
        "tokens": [
          50414,
          400,
          286,
          727,
          3677,
          11,
          286,
          576,
          528,
          281,
          3677,
          490,
          341,
          3991,
          293,
          652,
          341,
          709,
          3429,
          27674,
          11,
          457,
          286,
          478,
          884,
          264,
          49403,
          2425,
          3937,
          3037,
          295,
          341,
          11,
          286,
          393,
          519,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21791382466465975,
        "compression_ratio": 1.618705035971223,
        "end": 5333.76,
        "id": 1288,
        "no_speech_prob": 0.4186522364616394,
        "seek": 532076,
        "start": 5328.76,
        "temperature": 0,
        "text": " No stroke, fill, and just use that hex color.",
        "tokens": [
          50764,
          883,
          12403,
          11,
          2836,
          11,
          293,
          445,
          764,
          300,
          23291,
          2017,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21791382466465975,
        "compression_ratio": 1.618705035971223,
        "end": 5344.76,
        "id": 1289,
        "no_speech_prob": 0.4186522364616394,
        "seek": 532076,
        "start": 5333.76,
        "temperature": 0,
        "text": " And by the way, I think there's a way to disable these, but because of the weirdness of P5 and how it uses the global namespace for its functions, Glitch always thinks these are errors.",
        "tokens": [
          51014,
          400,
          538,
          264,
          636,
          11,
          286,
          519,
          456,
          311,
          257,
          636,
          281,
          28362,
          613,
          11,
          457,
          570,
          295,
          264,
          3657,
          1287,
          295,
          430,
          20,
          293,
          577,
          309,
          4960,
          264,
          4338,
          5288,
          17940,
          337,
          1080,
          6828,
          11,
          5209,
          1549,
          1009,
          7309,
          613,
          366,
          13603,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21791382466465975,
        "compression_ratio": 1.618705035971223,
        "end": 5347.76,
        "id": 1290,
        "no_speech_prob": 0.4186522364616394,
        "seek": 532076,
        "start": 5344.76,
        "temperature": 0,
        "text": " Who knows how to just like tell Glitch to stop.",
        "tokens": [
          51564,
          2102,
          3255,
          577,
          281,
          445,
          411,
          980,
          5209,
          1549,
          281,
          1590,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21791382466465975,
        "compression_ratio": 1.618705035971223,
        "end": 5349.76,
        "id": 1291,
        "no_speech_prob": 0.4186522364616394,
        "seek": 532076,
        "start": 5347.76,
        "temperature": 0,
        "text": " That would be good.",
        "tokens": [
          51714,
          663,
          576,
          312,
          665,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5352.76,
        "id": 1292,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5349.76,
        "temperature": 0,
        "text": " I copied the HTML code into the style.css file.",
        "tokens": [
          50364,
          286,
          25365,
          264,
          17995,
          3089,
          666,
          264,
          3758,
          13,
          66,
          3810,
          3991,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5353.76,
        "id": 1293,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5352.76,
        "temperature": 0,
        "text": " I certainly did.",
        "tokens": [
          50514,
          286,
          3297,
          630,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5355.76,
        "id": 1294,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5353.76,
        "temperature": 0,
        "text": " When did I do that?",
        "tokens": [
          50564,
          1133,
          630,
          286,
          360,
          300,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5358.76,
        "id": 1295,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5355.76,
        "temperature": 0,
        "text": " It's so weird.",
        "tokens": [
          50664,
          467,
          311,
          370,
          3657,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5362.76,
        "id": 1296,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5358.76,
        "temperature": 0,
        "text": " Is that like in all of the, in my template I did that?",
        "tokens": [
          50814,
          1119,
          300,
          411,
          294,
          439,
          295,
          264,
          11,
          294,
          452,
          12379,
          286,
          630,
          300,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5363.76,
        "id": 1297,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5362.76,
        "temperature": 0,
        "text": " Let's just take that out.",
        "tokens": [
          51014,
          961,
          311,
          445,
          747,
          300,
          484,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5365.76,
        "id": 1298,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5363.76,
        "temperature": 0,
        "text": " I don't know why, what happened there?",
        "tokens": [
          51064,
          286,
          500,
          380,
          458,
          983,
          11,
          437,
          2011,
          456,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5371.76,
        "id": 1299,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5365.76,
        "temperature": 0,
        "text": " That was very weird.",
        "tokens": [
          51164,
          663,
          390,
          588,
          3657,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5376.76,
        "id": 1300,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5371.76,
        "temperature": 0,
        "text": " So, the Glitch app is attempting to wake up, but I'm going to need those API keys.",
        "tokens": [
          51464,
          407,
          11,
          264,
          5209,
          1549,
          724,
          307,
          22001,
          281,
          6634,
          493,
          11,
          457,
          286,
          478,
          516,
          281,
          643,
          729,
          9362,
          9317,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18317184448242188,
        "compression_ratio": 1.5248868778280542,
        "end": 5378.76,
        "id": 1301,
        "no_speech_prob": 0.05749090760946274,
        "seek": 534976,
        "start": 5376.76,
        "temperature": 0,
        "text": " So, let's go.",
        "tokens": [
          51714,
          407,
          11,
          718,
          311,
          352,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1923273153472365,
        "compression_ratio": 1.784037558685446,
        "end": 5387.76,
        "id": 1302,
        "no_speech_prob": 0.013222640380263329,
        "seek": 537876,
        "start": 5378.76,
        "temperature": 0,
        "text": " So, what I'm, actually I think I'm going to go back to hosted models runway, and I'm going to grab, if I click on this, it's going to copy the API key to the clipboard.",
        "tokens": [
          50364,
          407,
          11,
          437,
          286,
          478,
          11,
          767,
          286,
          519,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          19204,
          5245,
          26642,
          11,
          293,
          286,
          478,
          516,
          281,
          4444,
          11,
          498,
          286,
          2052,
          322,
          341,
          11,
          309,
          311,
          516,
          281,
          5055,
          264,
          9362,
          2141,
          281,
          264,
          7353,
          3787,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1923273153472365,
        "compression_ratio": 1.784037558685446,
        "end": 5389.76,
        "id": 1303,
        "no_speech_prob": 0.013222640380263329,
        "seek": 537876,
        "start": 5387.76,
        "temperature": 0,
        "text": " Oops, sorry, I'm missing.",
        "tokens": [
          50814,
          21726,
          11,
          2597,
          11,
          286,
          478,
          5361,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1923273153472365,
        "compression_ratio": 1.784037558685446,
        "end": 5402.76,
        "id": 1304,
        "no_speech_prob": 0.013222640380263329,
        "seek": 537876,
        "start": 5389.76,
        "temperature": 0,
        "text": " I'm going to go back to this view, and I'm going to, right now I'm going to attempt to put the API key into the runway, into the.env file without you seeing it.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          341,
          1910,
          11,
          293,
          286,
          478,
          516,
          281,
          11,
          558,
          586,
          286,
          478,
          516,
          281,
          5217,
          281,
          829,
          264,
          9362,
          2141,
          666,
          264,
          26642,
          11,
          666,
          264,
          2411,
          268,
          85,
          3991,
          1553,
          291,
          2577,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1923273153472365,
        "compression_ratio": 1.784037558685446,
        "end": 5405.76,
        "id": 1305,
        "no_speech_prob": 0.013222640380263329,
        "seek": 537876,
        "start": 5402.76,
        "temperature": 0,
        "text": " Let's get the model URL.",
        "tokens": [
          51564,
          961,
          311,
          483,
          264,
          2316,
          12905,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17338376821473586,
        "compression_ratio": 1.4550264550264551,
        "end": 5408.76,
        "id": 1306,
        "no_speech_prob": 0.05749167501926422,
        "seek": 540576,
        "start": 5406.76,
        "temperature": 0,
        "text": " Just so I stop getting those errors.",
        "tokens": [
          50414,
          1449,
          370,
          286,
          1590,
          1242,
          729,
          13603,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17338376821473586,
        "compression_ratio": 1.4550264550264551,
        "end": 5417.76,
        "id": 1307,
        "no_speech_prob": 0.05749167501926422,
        "seek": 540576,
        "start": 5408.76,
        "temperature": 0,
        "text": " So, I've got the model URL and the token, and I'm going back to my code, and that is now done, and I can show it to you again.",
        "tokens": [
          50514,
          407,
          11,
          286,
          600,
          658,
          264,
          2316,
          12905,
          293,
          264,
          14862,
          11,
          293,
          286,
          478,
          516,
          646,
          281,
          452,
          3089,
          11,
          293,
          300,
          307,
          586,
          1096,
          11,
          293,
          286,
          393,
          855,
          309,
          281,
          291,
          797,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17338376821473586,
        "compression_ratio": 1.4550264550264551,
        "end": 5423.76,
        "id": 1308,
        "no_speech_prob": 0.05749167501926422,
        "seek": 540576,
        "start": 5417.76,
        "temperature": 0,
        "text": " All right, so I have put the API keys into the.env file.",
        "tokens": [
          50964,
          1057,
          558,
          11,
          370,
          286,
          362,
          829,
          264,
          9362,
          9317,
          666,
          264,
          2411,
          268,
          85,
          3991,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17338376821473586,
        "compression_ratio": 1.4550264550264551,
        "end": 5429.76,
        "id": 1309,
        "no_speech_prob": 0.05749167501926422,
        "seek": 540576,
        "start": 5423.76,
        "temperature": 0,
        "text": " And now I should see this.",
        "tokens": [
          51264,
          400,
          586,
          286,
          820,
          536,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17338376821473586,
        "compression_ratio": 1.4550264550264551,
        "end": 5432.76,
        "id": 1310,
        "no_speech_prob": 0.05749167501926422,
        "seek": 540576,
        "start": 5429.76,
        "temperature": 0,
        "text": " Send vector is not defined.",
        "tokens": [
          51564,
          17908,
          8062,
          307,
          406,
          7642,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1930765128997435,
        "compression_ratio": 1.7534246575342465,
        "end": 5437.76,
        "id": 1311,
        "no_speech_prob": 0.014063248410820961,
        "seek": 543276,
        "start": 5432.76,
        "temperature": 0,
        "text": " Where did I put send vector in?",
        "tokens": [
          50364,
          2305,
          630,
          286,
          829,
          2845,
          8062,
          294,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.1930765128997435,
        "compression_ratio": 1.7534246575342465,
        "end": 5440.76,
        "id": 1312,
        "no_speech_prob": 0.014063248410820961,
        "seek": 543276,
        "start": 5437.76,
        "temperature": 0,
        "text": " Send image, send, oh, whoops, right.",
        "tokens": [
          50614,
          17908,
          3256,
          11,
          2845,
          11,
          1954,
          11,
          567,
          3370,
          11,
          558,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1930765128997435,
        "compression_ratio": 1.7534246575342465,
        "end": 5444.76,
        "id": 1313,
        "no_speech_prob": 0.014063248410820961,
        "seek": 543276,
        "start": 5440.76,
        "temperature": 0,
        "text": " So, let's also comment this out.",
        "tokens": [
          50764,
          407,
          11,
          718,
          311,
          611,
          2871,
          341,
          484,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1930765128997435,
        "compression_ratio": 1.7534246575342465,
        "end": 5445.76,
        "id": 1314,
        "no_speech_prob": 0.014063248410820961,
        "seek": 543276,
        "start": 5444.76,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50964,
          3769,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1930765128997435,
        "compression_ratio": 1.7534246575342465,
        "end": 5460.76,
        "id": 1315,
        "no_speech_prob": 0.014063248410820961,
        "seek": 543276,
        "start": 5445.76,
        "temperature": 0,
        "text": " So, now I can draw just by, I can only draw one color, and I can only, I can only draw one color, and I can only draw one color, and one thickness.",
        "tokens": [
          51014,
          407,
          11,
          586,
          286,
          393,
          2642,
          445,
          538,
          11,
          286,
          393,
          787,
          2642,
          472,
          2017,
          11,
          293,
          286,
          393,
          787,
          11,
          286,
          393,
          787,
          2642,
          472,
          2017,
          11,
          293,
          286,
          393,
          787,
          2642,
          472,
          2017,
          11,
          293,
          472,
          14855,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5461.76,
        "id": 1316,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5460.76,
        "temperature": 0,
        "text": " Sorry, what was the other part?",
        "tokens": [
          50364,
          4919,
          11,
          437,
          390,
          264,
          661,
          644,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5462.76,
        "id": 1317,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5461.76,
        "temperature": 0,
        "text": " I'm getting tired.",
        "tokens": [
          50414,
          286,
          478,
          1242,
          5868,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5466.76,
        "id": 1318,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5462.76,
        "temperature": 0,
        "text": " It's 5 o'clock.",
        "tokens": [
          50464,
          467,
          311,
          1025,
          277,
          6,
          9023,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5468.76,
        "id": 1319,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5466.76,
        "temperature": 0,
        "text": " We're going to do this, then the object detection model.",
        "tokens": [
          50664,
          492,
          434,
          516,
          281,
          360,
          341,
          11,
          550,
          264,
          2657,
          17784,
          2316,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5473.76,
        "id": 1320,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5468.76,
        "temperature": 0,
        "text": " Oh, I was going to do, I've got to do some community contributions.",
        "tokens": [
          50764,
          876,
          11,
          286,
          390,
          516,
          281,
          360,
          11,
          286,
          600,
          658,
          281,
          360,
          512,
          1768,
          15725,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5475.76,
        "id": 1321,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5473.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51014,
          865,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5476.76,
        "id": 1322,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5475.76,
        "temperature": 0,
        "text": " So, okay.",
        "tokens": [
          51114,
          407,
          11,
          1392,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5479.76,
        "id": 1323,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5476.76,
        "temperature": 0,
        "text": " Next.",
        "tokens": [
          51164,
          3087,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5480.76,
        "id": 1324,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5479.76,
        "temperature": 0,
        "text": " Let me rethink this a little bit.",
        "tokens": [
          51314,
          961,
          385,
          34595,
          341,
          257,
          707,
          857,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1995403717975227,
        "compression_ratio": 1.4527363184079602,
        "end": 5486.76,
        "id": 1325,
        "no_speech_prob": 0.06953895092010498,
        "seek": 546076,
        "start": 5480.76,
        "temperature": 0,
        "text": " I'm going to make the background that color.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          652,
          264,
          3678,
          300,
          2017,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5489.76,
        "id": 1326,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5486.76,
        "temperature": 0,
        "text": " So, the background will already be sky.",
        "tokens": [
          50364,
          407,
          11,
          264,
          3678,
          486,
          1217,
          312,
          5443,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5493.76,
        "id": 1327,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5489.76,
        "temperature": 0,
        "text": " And then I think I'll just try to draw clouds.",
        "tokens": [
          50514,
          400,
          550,
          286,
          519,
          286,
          603,
          445,
          853,
          281,
          2642,
          12193,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5496.76,
        "id": 1328,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5493.76,
        "temperature": 0,
        "text": " So, if I go look at the assets, where did I upload that?",
        "tokens": [
          50714,
          407,
          11,
          498,
          286,
          352,
          574,
          412,
          264,
          9769,
          11,
          689,
          630,
          286,
          6580,
          300,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5497.76,
        "id": 1329,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5496.76,
        "temperature": 0,
        "text": " Oh, it's here.",
        "tokens": [
          50864,
          876,
          11,
          309,
          311,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5501.76,
        "id": 1330,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5497.76,
        "temperature": 0,
        "text": " Clouds, oh, clouds is just this.",
        "tokens": [
          50914,
          8061,
          82,
          11,
          1954,
          11,
          12193,
          307,
          445,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5505.76,
        "id": 1331,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5501.76,
        "temperature": 0,
        "text": " So, let's just try it with sky, and I'm drawing, although let's try sea.",
        "tokens": [
          51114,
          407,
          11,
          718,
          311,
          445,
          853,
          309,
          365,
          5443,
          11,
          293,
          286,
          478,
          6316,
          11,
          4878,
          718,
          311,
          853,
          4158,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5507.76,
        "id": 1332,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5505.76,
        "temperature": 0,
        "text": " I'm just curious here.",
        "tokens": [
          51314,
          286,
          478,
          445,
          6369,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1743383315003034,
        "compression_ratio": 1.556701030927835,
        "end": 5513.76,
        "id": 1333,
        "no_speech_prob": 0.07158719003200531,
        "seek": 548676,
        "start": 5507.76,
        "temperature": 0,
        "text": " Let's try sea.",
        "tokens": [
          51414,
          961,
          311,
          853,
          4158,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1478387858416583,
        "compression_ratio": 1.3515151515151516,
        "end": 5526.76,
        "id": 1334,
        "no_speech_prob": 0.0009697492350824177,
        "seek": 551376,
        "start": 5513.76,
        "temperature": 0,
        "text": " So, if I say fill here, and now it's going to default with, and I can draw, excuse me, the sea down here.",
        "tokens": [
          50364,
          407,
          11,
          498,
          286,
          584,
          2836,
          510,
          11,
          293,
          586,
          309,
          311,
          516,
          281,
          7576,
          365,
          11,
          293,
          286,
          393,
          2642,
          11,
          8960,
          385,
          11,
          264,
          4158,
          760,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1478387858416583,
        "compression_ratio": 1.3515151515151516,
        "end": 5529.76,
        "id": 1335,
        "no_speech_prob": 0.0009697492350824177,
        "seek": 551376,
        "start": 5526.76,
        "temperature": 0,
        "text": " Coming back.",
        "tokens": [
          51014,
          12473,
          646,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1478387858416583,
        "compression_ratio": 1.3515151515151516,
        "end": 5531.76,
        "id": 1336,
        "no_speech_prob": 0.0009697492350824177,
        "seek": 551376,
        "start": 5529.76,
        "temperature": 0,
        "text": " Let's make this a little bit bigger, just so I can do it more quickly.",
        "tokens": [
          51164,
          961,
          311,
          652,
          341,
          257,
          707,
          857,
          3801,
          11,
          445,
          370,
          286,
          393,
          360,
          309,
          544,
          2661,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1478387858416583,
        "compression_ratio": 1.3515151515151516,
        "end": 5534.76,
        "id": 1337,
        "no_speech_prob": 0.0009697492350824177,
        "seek": 551376,
        "start": 5531.76,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51264,
          3769,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1478387858416583,
        "compression_ratio": 1.3515151515151516,
        "end": 5536.76,
        "id": 1338,
        "no_speech_prob": 0.0009697492350824177,
        "seek": 551376,
        "start": 5534.76,
        "temperature": 0,
        "text": " Now, what do I need to do?",
        "tokens": [
          51414,
          823,
          11,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.16120070827250577,
        "compression_ratio": 1.675,
        "end": 5545.76,
        "id": 1339,
        "no_speech_prob": 0.46098792552948,
        "seek": 553676,
        "start": 5537.76,
        "temperature": 0,
        "text": " I need to send the, and what I want to show you is going to leak my keys again, but that's fine.",
        "tokens": [
          50414,
          286,
          643,
          281,
          2845,
          264,
          11,
          293,
          437,
          286,
          528,
          281,
          855,
          291,
          307,
          516,
          281,
          17143,
          452,
          9317,
          797,
          11,
          457,
          300,
          311,
          2489,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16120070827250577,
        "compression_ratio": 1.675,
        "end": 5547.76,
        "id": 1340,
        "no_speech_prob": 0.46098792552948,
        "seek": 553676,
        "start": 5545.76,
        "temperature": 0,
        "text": " I'll regenerate them.",
        "tokens": [
          50814,
          286,
          603,
          26358,
          473,
          552,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16120070827250577,
        "compression_ratio": 1.675,
        "end": 5549.76,
        "id": 1341,
        "no_speech_prob": 0.46098792552948,
        "seek": 553676,
        "start": 5547.76,
        "temperature": 0,
        "text": " I need to adjust this code.",
        "tokens": [
          50914,
          286,
          643,
          281,
          4369,
          341,
          3089,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16120070827250577,
        "compression_ratio": 1.675,
        "end": 5557.76,
        "id": 1342,
        "no_speech_prob": 0.46098792552948,
        "seek": 553676,
        "start": 5549.76,
        "temperature": 0,
        "text": " So, the first thing that I need to do is get the image in a format that I can use to send to runway.",
        "tokens": [
          51014,
          407,
          11,
          264,
          700,
          551,
          300,
          286,
          643,
          281,
          360,
          307,
          483,
          264,
          3256,
          294,
          257,
          7877,
          300,
          286,
          393,
          764,
          281,
          2845,
          281,
          26642,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16120070827250577,
        "compression_ratio": 1.675,
        "end": 5565.76,
        "id": 1343,
        "no_speech_prob": 0.46098792552948,
        "seek": 553676,
        "start": 5557.76,
        "temperature": 0,
        "text": " And the way that I will do that is by turning it into a base 64 encoding of that image.",
        "tokens": [
          51414,
          400,
          264,
          636,
          300,
          286,
          486,
          360,
          300,
          307,
          538,
          6246,
          309,
          666,
          257,
          3096,
          12145,
          43430,
          295,
          300,
          3256,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5567.76,
        "id": 1344,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5565.76,
        "temperature": 0,
        "text": " So, how does that work?",
        "tokens": [
          50364,
          407,
          11,
          577,
          775,
          300,
          589,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5572.76,
        "id": 1345,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5567.76,
        "temperature": 0,
        "text": " I am going to say image 64 equals canvas.",
        "tokens": [
          50464,
          286,
          669,
          516,
          281,
          584,
          3256,
          12145,
          6915,
          16267,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5578.76,
        "id": 1346,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5572.76,
        "temperature": 0,
        "text": " I need to make a variable to store the canvas.",
        "tokens": [
          50714,
          286,
          643,
          281,
          652,
          257,
          7006,
          281,
          3531,
          264,
          16267,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5580.76,
        "id": 1347,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5578.76,
        "temperature": 0,
        "text": " And what happened?",
        "tokens": [
          51014,
          400,
          437,
          2011,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5582.76,
        "id": 1348,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5580.76,
        "temperature": 0,
        "text": " All the red dots went away.",
        "tokens": [
          51114,
          1057,
          264,
          2182,
          15026,
          1437,
          1314,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5584.76,
        "id": 1349,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5582.76,
        "temperature": 0,
        "text": " I talked about it, and they disappeared.",
        "tokens": [
          51214,
          286,
          2825,
          466,
          309,
          11,
          293,
          436,
          13954,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5586.76,
        "id": 1350,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5584.76,
        "temperature": 0,
        "text": " Did somebody do something to make that happen?",
        "tokens": [
          51314,
          2589,
          2618,
          360,
          746,
          281,
          652,
          300,
          1051,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5588.76,
        "id": 1351,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5586.76,
        "temperature": 0,
        "text": " What is going on?",
        "tokens": [
          51414,
          708,
          307,
          516,
          322,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5590.76,
        "id": 1352,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5588.76,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51514,
          876,
          11,
          452,
          8387,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5592.76,
        "id": 1353,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5590.76,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          51614,
          2438,
          11,
          1392,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20690048442167394,
        "compression_ratio": 1.5095238095238095,
        "end": 5594.76,
        "id": 1354,
        "no_speech_prob": 0.007815824821591377,
        "seek": 556576,
        "start": 5592.76,
        "temperature": 0,
        "text": " So, Simon is clarifying.",
        "tokens": [
          51714,
          407,
          11,
          13193,
          307,
          6093,
          5489,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23766408108248568,
        "compression_ratio": 1.6666666666666667,
        "end": 5600.76,
        "id": 1355,
        "no_speech_prob": 0.2479659467935562,
        "seek": 559476,
        "start": 5594.76,
        "temperature": 0,
        "text": " I'm talking about image segmentation models, and I was saying what we're doing really is the inverse of it.",
        "tokens": [
          50364,
          286,
          478,
          1417,
          466,
          3256,
          9469,
          399,
          5245,
          11,
          293,
          286,
          390,
          1566,
          437,
          321,
          434,
          884,
          534,
          307,
          264,
          17340,
          295,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23766408108248568,
        "compression_ratio": 1.6666666666666667,
        "end": 5602.76,
        "id": 1356,
        "no_speech_prob": 0.2479659467935562,
        "seek": 559476,
        "start": 5600.76,
        "temperature": 0,
        "text": " And actually, there is a specific name for that.",
        "tokens": [
          50664,
          400,
          767,
          11,
          456,
          307,
          257,
          2685,
          1315,
          337,
          300,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23766408108248568,
        "compression_ratio": 1.6666666666666667,
        "end": 5604.76,
        "id": 1357,
        "no_speech_prob": 0.2479659467935562,
        "seek": 559476,
        "start": 5602.76,
        "temperature": 0,
        "text": " It's called a reverse image segmentation model.",
        "tokens": [
          50764,
          467,
          311,
          1219,
          257,
          9943,
          3256,
          9469,
          399,
          2316,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23766408108248568,
        "compression_ratio": 1.6666666666666667,
        "end": 5608.76,
        "id": 1358,
        "no_speech_prob": 0.2479659467935562,
        "seek": 559476,
        "start": 5604.76,
        "temperature": 0,
        "text": " Thank you for that clarification.",
        "tokens": [
          50864,
          1044,
          291,
          337,
          300,
          34449,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23766408108248568,
        "compression_ratio": 1.6666666666666667,
        "end": 5612.76,
        "id": 1359,
        "no_speech_prob": 0.2479659467935562,
        "seek": 559476,
        "start": 5608.76,
        "temperature": 0,
        "text": " So, image canvas.elt.",
        "tokens": [
          51064,
          407,
          11,
          3256,
          16267,
          13,
          2018,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23766408108248568,
        "compression_ratio": 1.6666666666666667,
        "end": 5614.76,
        "id": 1360,
        "no_speech_prob": 0.2479659467935562,
        "seek": 559476,
        "start": 5612.76,
        "temperature": 0,
        "text": " So, let's talk about what's going on here.",
        "tokens": [
          51264,
          407,
          11,
          718,
          311,
          751,
          466,
          437,
          311,
          516,
          322,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23766408108248568,
        "compression_ratio": 1.6666666666666667,
        "end": 5621.76,
        "id": 1361,
        "no_speech_prob": 0.2479659467935562,
        "seek": 559476,
        "start": 5614.76,
        "temperature": 0,
        "text": " Canvas is a variable that's holding on to a P5 canvas object.",
        "tokens": [
          51364,
          25725,
          307,
          257,
          7006,
          300,
          311,
          5061,
          322,
          281,
          257,
          430,
          20,
          16267,
          2657,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1816171547035118,
        "compression_ratio": 1.402116402116402,
        "end": 5628.76,
        "id": 1362,
        "no_speech_prob": 0.03161834552884102,
        "seek": 562176,
        "start": 5621.76,
        "temperature": 0,
        "text": " The P5 canvas object is a wrapper of the native JavaScript browser canvas DOM element.",
        "tokens": [
          50364,
          440,
          430,
          20,
          16267,
          2657,
          307,
          257,
          46906,
          295,
          264,
          8470,
          15778,
          11185,
          16267,
          35727,
          4478,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1816171547035118,
        "compression_ratio": 1.402116402116402,
        "end": 5632.76,
        "id": 1363,
        "no_speech_prob": 0.03161834552884102,
        "seek": 562176,
        "start": 5628.76,
        "temperature": 0,
        "text": " That happens to exist in the.elt property.",
        "tokens": [
          50714,
          663,
          2314,
          281,
          2514,
          294,
          264,
          2411,
          2018,
          4707,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1816171547035118,
        "compression_ratio": 1.402116402116402,
        "end": 5636.76,
        "id": 1364,
        "no_speech_prob": 0.03161834552884102,
        "seek": 562176,
        "start": 5632.76,
        "temperature": 0,
        "text": " And then I should be able to say to data URL.",
        "tokens": [
          50914,
          400,
          550,
          286,
          820,
          312,
          1075,
          281,
          584,
          281,
          1412,
          12905,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1816171547035118,
        "compression_ratio": 1.402116402116402,
        "end": 5639.76,
        "id": 1365,
        "no_speech_prob": 0.03161834552884102,
        "seek": 562176,
        "start": 5636.76,
        "temperature": 0,
        "text": " Is that the right name of the function?",
        "tokens": [
          51114,
          1119,
          300,
          264,
          558,
          1315,
          295,
          264,
          2445,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1816171547035118,
        "compression_ratio": 1.402116402116402,
        "end": 5641.76,
        "id": 1366,
        "no_speech_prob": 0.03161834552884102,
        "seek": 562176,
        "start": 5639.76,
        "temperature": 0,
        "text": " Let's look this up.",
        "tokens": [
          51264,
          961,
          311,
          574,
          341,
          493,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1816171547035118,
        "compression_ratio": 1.402116402116402,
        "end": 5644.76,
        "id": 1367,
        "no_speech_prob": 0.03161834552884102,
        "seek": 562176,
        "start": 5641.76,
        "temperature": 0,
        "text": " To data URL JavaScript.",
        "tokens": [
          51364,
          1407,
          1412,
          12905,
          15778,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1816171547035118,
        "compression_ratio": 1.402116402116402,
        "end": 5646.76,
        "id": 1368,
        "no_speech_prob": 0.03161834552884102,
        "seek": 562176,
        "start": 5644.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51514,
          865,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2138255221172444,
        "compression_ratio": 1.6521739130434783,
        "end": 5656.76,
        "id": 1369,
        "no_speech_prob": 0.04208635166287422,
        "seek": 564676,
        "start": 5646.76,
        "temperature": 0,
        "text": " So, the to data URL function returns a data URI containing a representative of the image in the format specified by the type parameter, defaults to PNG.",
        "tokens": [
          50364,
          407,
          11,
          264,
          281,
          1412,
          12905,
          2445,
          11247,
          257,
          1412,
          624,
          5577,
          19273,
          257,
          12424,
          295,
          264,
          3256,
          294,
          264,
          7877,
          22206,
          538,
          264,
          2010,
          13075,
          11,
          7576,
          82,
          281,
          430,
          30237,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2138255221172444,
        "compression_ratio": 1.6521739130434783,
        "end": 5663.76,
        "id": 1370,
        "no_speech_prob": 0.04208635166287422,
        "seek": 564676,
        "start": 5656.76,
        "temperature": 0,
        "text": " So, there's a lot of ways I can configure this, but this particular function is what I want to turn the image essentially into a string.",
        "tokens": [
          50864,
          407,
          11,
          456,
          311,
          257,
          688,
          295,
          2098,
          286,
          393,
          22162,
          341,
          11,
          457,
          341,
          1729,
          2445,
          307,
          437,
          286,
          528,
          281,
          1261,
          264,
          3256,
          4476,
          666,
          257,
          6798,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2138255221172444,
        "compression_ratio": 1.6521739130434783,
        "end": 5666.76,
        "id": 1371,
        "no_speech_prob": 0.04208635166287422,
        "seek": 564676,
        "start": 5663.76,
        "temperature": 0,
        "text": " Now, it seems like a crazy thing, turning the image into a string.",
        "tokens": [
          51214,
          823,
          11,
          309,
          2544,
          411,
          257,
          3219,
          551,
          11,
          6246,
          264,
          3256,
          666,
          257,
          6798,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2138255221172444,
        "compression_ratio": 1.6521739130434783,
        "end": 5669.76,
        "id": 1372,
        "no_speech_prob": 0.04208635166287422,
        "seek": 564676,
        "start": 5666.76,
        "temperature": 0,
        "text": " I think I've talked about this in some of my video tutorials.",
        "tokens": [
          51364,
          286,
          519,
          286,
          600,
          2825,
          466,
          341,
          294,
          512,
          295,
          452,
          960,
          17616,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22027753579496134,
        "compression_ratio": 1.4241071428571428,
        "end": 5678.76,
        "id": 1373,
        "no_speech_prob": 0.17552071809768677,
        "seek": 566976,
        "start": 5669.76,
        "temperature": 0,
        "text": " But this makes it very convenient to pass it over a post request, to send it to a web server.",
        "tokens": [
          50364,
          583,
          341,
          1669,
          309,
          588,
          10851,
          281,
          1320,
          309,
          670,
          257,
          2183,
          5308,
          11,
          281,
          2845,
          309,
          281,
          257,
          3670,
          7154,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22027753579496134,
        "compression_ratio": 1.4241071428571428,
        "end": 5681.76,
        "id": 1374,
        "no_speech_prob": 0.17552071809768677,
        "seek": 566976,
        "start": 5678.76,
        "temperature": 0,
        "text": " Okay. So, now where was I here?",
        "tokens": [
          50814,
          1033,
          13,
          407,
          11,
          586,
          689,
          390,
          286,
          510,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.22027753579496134,
        "compression_ratio": 1.4241071428571428,
        "end": 5683.76,
        "id": 1375,
        "no_speech_prob": 0.17552071809768677,
        "seek": 566976,
        "start": 5681.76,
        "temperature": 0,
        "text": " Did I get the name of the function right?",
        "tokens": [
          50964,
          2589,
          286,
          483,
          264,
          1315,
          295,
          264,
          2445,
          558,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.22027753579496134,
        "compression_ratio": 1.4241071428571428,
        "end": 5684.76,
        "id": 1376,
        "no_speech_prob": 0.17552071809768677,
        "seek": 566976,
        "start": 5683.76,
        "temperature": 0,
        "text": " I didn't, actually.",
        "tokens": [
          51064,
          286,
          994,
          380,
          11,
          767,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22027753579496134,
        "compression_ratio": 1.4241071428571428,
        "end": 5687.76,
        "id": 1377,
        "no_speech_prob": 0.17552071809768677,
        "seek": 566976,
        "start": 5684.76,
        "temperature": 0,
        "text": " It's to data URL with capital URL.",
        "tokens": [
          51114,
          467,
          311,
          281,
          1412,
          12905,
          365,
          4238,
          12905,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22027753579496134,
        "compression_ratio": 1.4241071428571428,
        "end": 5689.76,
        "id": 1378,
        "no_speech_prob": 0.17552071809768677,
        "seek": 566976,
        "start": 5687.76,
        "temperature": 0,
        "text": " So, that would go here.",
        "tokens": [
          51264,
          407,
          11,
          300,
          576,
          352,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22027753579496134,
        "compression_ratio": 1.4241071428571428,
        "end": 5692.76,
        "id": 1379,
        "no_speech_prob": 0.17552071809768677,
        "seek": 566976,
        "start": 5689.76,
        "temperature": 0,
        "text": " And let's just ‑‑ this is a little bit ridiculous for me to do this.",
        "tokens": [
          51364,
          400,
          718,
          311,
          445,
          220,
          27392,
          27392,
          341,
          307,
          257,
          707,
          857,
          11083,
          337,
          385,
          281,
          360,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18838472624082822,
        "compression_ratio": 1.4470588235294117,
        "end": 5699.76,
        "id": 1380,
        "no_speech_prob": 0.04672294482588768,
        "seek": 569276,
        "start": 5692.76,
        "temperature": 0,
        "text": " But let's just console log it so we can see if this works.",
        "tokens": [
          50364,
          583,
          718,
          311,
          445,
          11076,
          3565,
          309,
          370,
          321,
          393,
          536,
          498,
          341,
          1985,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18838472624082822,
        "compression_ratio": 1.4470588235294117,
        "end": 5702.76,
        "id": 1381,
        "no_speech_prob": 0.04672294482588768,
        "seek": 569276,
        "start": 5699.76,
        "temperature": 0,
        "text": " I'll paint a little bit, hit generate, and there it is.",
        "tokens": [
          50714,
          286,
          603,
          4225,
          257,
          707,
          857,
          11,
          2045,
          8460,
          11,
          293,
          456,
          309,
          307,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18838472624082822,
        "compression_ratio": 1.4470588235294117,
        "end": 5709.76,
        "id": 1382,
        "no_speech_prob": 0.04672294482588768,
        "seek": 569276,
        "start": 5702.76,
        "temperature": 0,
        "text": " This is the entire image encoded as a base 64 string of characters.",
        "tokens": [
          50864,
          639,
          307,
          264,
          2302,
          3256,
          2058,
          12340,
          382,
          257,
          3096,
          12145,
          6798,
          295,
          4342,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18838472624082822,
        "compression_ratio": 1.4470588235294117,
        "end": 5713.76,
        "id": 1383,
        "no_speech_prob": 0.04672294482588768,
        "seek": 569276,
        "start": 5709.76,
        "temperature": 0,
        "text": " So, now if I go back to here, I don't want to console log that.",
        "tokens": [
          51214,
          407,
          11,
          586,
          498,
          286,
          352,
          646,
          281,
          510,
          11,
          286,
          500,
          380,
          528,
          281,
          11076,
          3565,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19505588729660234,
        "compression_ratio": 1.521472392638037,
        "end": 5716.76,
        "id": 1384,
        "no_speech_prob": 0.12420819699764252,
        "seek": 571376,
        "start": 5714.76,
        "temperature": 0,
        "text": " I want to create my post request.",
        "tokens": [
          50414,
          286,
          528,
          281,
          1884,
          452,
          2183,
          5308,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19505588729660234,
        "compression_ratio": 1.521472392638037,
        "end": 5723.76,
        "id": 1385,
        "no_speech_prob": 0.12420819699764252,
        "seek": 571376,
        "start": 5722.76,
        "temperature": 0,
        "text": " And the inputs are.",
        "tokens": [
          50814,
          400,
          264,
          15743,
          366,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19505588729660234,
        "compression_ratio": 1.521472392638037,
        "end": 5726.76,
        "id": 1386,
        "no_speech_prob": 0.12420819699764252,
        "seek": 571376,
        "start": 5723.76,
        "temperature": 0,
        "text": " Now, this is what I need to look up in Runway.",
        "tokens": [
          50864,
          823,
          11,
          341,
          307,
          437,
          286,
          643,
          281,
          574,
          493,
          294,
          8950,
          676,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19505588729660234,
        "compression_ratio": 1.521472392638037,
        "end": 5728.76,
        "id": 1387,
        "no_speech_prob": 0.12420819699764252,
        "seek": 571376,
        "start": 5726.76,
        "temperature": 0,
        "text": " I don't recall what the inputs are.",
        "tokens": [
          51014,
          286,
          500,
          380,
          9901,
          437,
          264,
          15743,
          366,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19505588729660234,
        "compression_ratio": 1.521472392638037,
        "end": 5729.76,
        "id": 1388,
        "no_speech_prob": 0.12420819699764252,
        "seek": 571376,
        "start": 5728.76,
        "temperature": 0,
        "text": " I know it's the image.",
        "tokens": [
          51114,
          286,
          458,
          309,
          311,
          264,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19505588729660234,
        "compression_ratio": 1.521472392638037,
        "end": 5739.76,
        "id": 1389,
        "no_speech_prob": 0.12420819699764252,
        "seek": 571376,
        "start": 5729.76,
        "temperature": 0,
        "text": " It's probably something like this is probably what I send it, but I'm not entirely sure.",
        "tokens": [
          51164,
          467,
          311,
          1391,
          746,
          411,
          341,
          307,
          1391,
          437,
          286,
          2845,
          309,
          11,
          457,
          286,
          478,
          406,
          7696,
          988,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5743.76,
        "id": 1390,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5739.76,
        "temperature": 0,
        "text": " I need to look it up in Runway, but it's going to show my API token.",
        "tokens": [
          50364,
          286,
          643,
          281,
          574,
          309,
          493,
          294,
          8950,
          676,
          11,
          457,
          309,
          311,
          516,
          281,
          855,
          452,
          9362,
          14862,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5745.76,
        "id": 1391,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5743.76,
        "temperature": 0,
        "text": " So, I don't mind.",
        "tokens": [
          50564,
          407,
          11,
          286,
          500,
          380,
          1575,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5751.76,
        "id": 1392,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5745.76,
        "temperature": 0,
        "text": " I'm going to show you how to do it with showing your API token and then quickly regenerate your API token.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          855,
          291,
          577,
          281,
          360,
          309,
          365,
          4099,
          428,
          9362,
          14862,
          293,
          550,
          2661,
          26358,
          473,
          428,
          9362,
          14862,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5755.76,
        "id": 1393,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5751.76,
        "temperature": 0,
        "text": " So, first thing I'm going to do is I'm going to disable the model so it's not active.",
        "tokens": [
          50964,
          407,
          11,
          700,
          551,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          28362,
          264,
          2316,
          370,
          309,
          311,
          406,
          4967,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5758.76,
        "id": 1394,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5755.76,
        "temperature": 0,
        "text": " Then I'm going to click on view the code snippet.",
        "tokens": [
          51164,
          1396,
          286,
          478,
          516,
          281,
          2052,
          322,
          1910,
          264,
          3089,
          35623,
          302,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5760.76,
        "id": 1395,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5758.76,
        "temperature": 0,
        "text": " And that's where it's showing the API key.",
        "tokens": [
          51314,
          400,
          300,
          311,
          689,
          309,
          311,
          4099,
          264,
          9362,
          2141,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5764.76,
        "id": 1396,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5760.76,
        "temperature": 0,
        "text": " And I can see the inputs is, ah, it's called semantic map.",
        "tokens": [
          51414,
          400,
          286,
          393,
          536,
          264,
          15743,
          307,
          11,
          3716,
          11,
          309,
          311,
          1219,
          47982,
          4471,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16485306312297954,
        "compression_ratio": 1.8988326848249026,
        "end": 5767.76,
        "id": 1397,
        "no_speech_prob": 0.031143203377723694,
        "seek": 573976,
        "start": 5764.76,
        "temperature": 0,
        "text": " So, what I'm sending is something called a semantic map.",
        "tokens": [
          51614,
          407,
          11,
          437,
          286,
          478,
          7750,
          307,
          746,
          1219,
          257,
          47982,
          4471,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1814475108667747,
        "compression_ratio": 1.6538461538461537,
        "end": 5770.76,
        "id": 1398,
        "no_speech_prob": 0.05920775234699249,
        "seek": 576776,
        "start": 5767.76,
        "temperature": 0,
        "text": " And then the property, the value, that's the property name.",
        "tokens": [
          50364,
          400,
          550,
          264,
          4707,
          11,
          264,
          2158,
          11,
          300,
          311,
          264,
          4707,
          1315,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1814475108667747,
        "compression_ratio": 1.6538461538461537,
        "end": 5772.76,
        "id": 1399,
        "no_speech_prob": 0.05920775234699249,
        "seek": 576776,
        "start": 5770.76,
        "temperature": 0,
        "text": " The value is a base 64 image.",
        "tokens": [
          50514,
          440,
          2158,
          307,
          257,
          3096,
          12145,
          3256,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1814475108667747,
        "compression_ratio": 1.6538461538461537,
        "end": 5781.76,
        "id": 1400,
        "no_speech_prob": 0.05920775234699249,
        "seek": 576776,
        "start": 5772.76,
        "temperature": 0,
        "text": " So, let us, how do I do the regenerate the token edit?",
        "tokens": [
          50614,
          407,
          11,
          718,
          505,
          11,
          577,
          360,
          286,
          360,
          264,
          26358,
          473,
          264,
          14862,
          8129,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1814475108667747,
        "compression_ratio": 1.6538461538461537,
        "end": 5782.76,
        "id": 1401,
        "no_speech_prob": 0.05920775234699249,
        "seek": 576776,
        "start": 5781.76,
        "temperature": 0,
        "text": " Right down here.",
        "tokens": [
          51064,
          1779,
          760,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1814475108667747,
        "compression_ratio": 1.6538461538461537,
        "end": 5786.76,
        "id": 1402,
        "no_speech_prob": 0.05920775234699249,
        "seek": 576776,
        "start": 5782.76,
        "temperature": 0,
        "text": " So, this is me regenerating the API key, which I'm going to do.",
        "tokens": [
          51114,
          407,
          11,
          341,
          307,
          385,
          26358,
          990,
          264,
          9362,
          2141,
          11,
          597,
          286,
          478,
          516,
          281,
          360,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1814475108667747,
        "compression_ratio": 1.6538461538461537,
        "end": 5790.76,
        "id": 1403,
        "no_speech_prob": 0.05920775234699249,
        "seek": 576776,
        "start": 5786.76,
        "temperature": 0,
        "text": " And I'm not going to let you see the regenerated one.",
        "tokens": [
          51314,
          400,
          286,
          478,
          406,
          516,
          281,
          718,
          291,
          536,
          264,
          26358,
          770,
          472,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1814475108667747,
        "compression_ratio": 1.6538461538461537,
        "end": 5793.76,
        "id": 1404,
        "no_speech_prob": 0.05920775234699249,
        "seek": 576776,
        "start": 5790.76,
        "temperature": 0,
        "text": " I'm going to copy it.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          5055,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5800.76,
        "id": 1405,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5793.76,
        "temperature": 0,
        "text": " I'm going to put it into my.env file.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          829,
          309,
          666,
          452,
          2411,
          268,
          85,
          3991,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5802.76,
        "id": 1406,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5800.76,
        "temperature": 0,
        "text": " The new token is there.",
        "tokens": [
          50714,
          440,
          777,
          14862,
          307,
          456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5805.76,
        "id": 1407,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5802.76,
        "temperature": 0,
        "text": " Go back to sketch.js.",
        "tokens": [
          50814,
          1037,
          646,
          281,
          12325,
          13,
          25530,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5806.76,
        "id": 1408,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5805.76,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          50964,
          2305,
          669,
          286,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5807.76,
        "id": 1409,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5806.76,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          51014,
          2305,
          669,
          286,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5808.76,
        "id": 1410,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5807.76,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          51064,
          2305,
          669,
          286,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5810.76,
        "id": 1411,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5808.76,
        "temperature": 0,
        "text": " Let's turn, ah, I can come back to show you.",
        "tokens": [
          51114,
          961,
          311,
          1261,
          11,
          3716,
          11,
          286,
          393,
          808,
          646,
          281,
          855,
          291,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5812.76,
        "id": 1412,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5810.76,
        "temperature": 0,
        "text": " Let's turn the model back on.",
        "tokens": [
          51214,
          961,
          311,
          1261,
          264,
          2316,
          646,
          322,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5814.76,
        "id": 1413,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5812.76,
        "temperature": 0,
        "text": " Activate it.",
        "tokens": [
          51314,
          28550,
          473,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5820.76,
        "id": 1414,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5814.76,
        "temperature": 0,
        "text": " And this is supposed to be now where you remember semantic map.",
        "tokens": [
          51414,
          400,
          341,
          307,
          3442,
          281,
          312,
          586,
          689,
          291,
          1604,
          47982,
          4471,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1815171065153899,
        "compression_ratio": 1.5913978494623655,
        "end": 5822.76,
        "id": 1415,
        "no_speech_prob": 0.019718941301107407,
        "seek": 579376,
        "start": 5820.76,
        "temperature": 0,
        "text": " So, that's semantic map.",
        "tokens": [
          51714,
          407,
          11,
          300,
          311,
          47982,
          4471,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5824.76,
        "id": 1416,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5822.76,
        "temperature": 0,
        "text": " And then send to runway.",
        "tokens": [
          50364,
          400,
          550,
          2845,
          281,
          26642,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5825.76,
        "id": 1417,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5824.76,
        "temperature": 0,
        "text": " Wait for the outputs.",
        "tokens": [
          50464,
          3802,
          337,
          264,
          23930,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5829.76,
        "id": 1418,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5825.76,
        "temperature": 0,
        "text": " And I don't, let's just look at console log outputs.",
        "tokens": [
          50514,
          400,
          286,
          500,
          380,
          11,
          718,
          311,
          445,
          574,
          412,
          11076,
          3565,
          23930,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5830.76,
        "id": 1419,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5829.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5835.76,
        "id": 1420,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5830.76,
        "temperature": 0,
        "text": " So, I'm going to look at the output that comes back.",
        "tokens": [
          50764,
          407,
          11,
          286,
          478,
          516,
          281,
          574,
          412,
          264,
          5598,
          300,
          1487,
          646,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5837.76,
        "id": 1421,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5835.76,
        "temperature": 0,
        "text": " Let's refresh this page.",
        "tokens": [
          51014,
          961,
          311,
          15134,
          341,
          3028,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5838.76,
        "id": 1422,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5837.76,
        "temperature": 0,
        "text": " Generate.",
        "tokens": [
          51114,
          15409,
          473,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5839.76,
        "id": 1423,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5838.76,
        "temperature": 0,
        "text": " Sending the image.",
        "tokens": [
          51164,
          318,
          2029,
          264,
          3256,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5842.76,
        "id": 1424,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5839.76,
        "temperature": 0,
        "text": " Now, it will probably take quite some time for it to, oh, it came back.",
        "tokens": [
          51214,
          823,
          11,
          309,
          486,
          1391,
          747,
          1596,
          512,
          565,
          337,
          309,
          281,
          11,
          1954,
          11,
          309,
          1361,
          646,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5843.76,
        "id": 1425,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5842.76,
        "temperature": 0,
        "text": " Look, there we go.",
        "tokens": [
          51364,
          2053,
          11,
          456,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5845.76,
        "id": 1426,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5843.76,
        "temperature": 0,
        "text": " I have an output, which is, guess what?",
        "tokens": [
          51414,
          286,
          362,
          364,
          5598,
          11,
          597,
          307,
          11,
          2041,
          437,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5847.76,
        "id": 1427,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5845.76,
        "temperature": 0,
        "text": " A base 64 encoded image.",
        "tokens": [
          51514,
          316,
          3096,
          12145,
          2058,
          12340,
          3256,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5848.76,
        "id": 1428,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5847.76,
        "temperature": 0,
        "text": " Status success.",
        "tokens": [
          51614,
          47409,
          2245,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.204715673474298,
        "compression_ratio": 1.5868725868725868,
        "end": 5850.76,
        "id": 1429,
        "no_speech_prob": 0.15405181050300598,
        "seek": 582276,
        "start": 5848.76,
        "temperature": 0,
        "text": " And the count is going up.",
        "tokens": [
          51664,
          400,
          264,
          1207,
          307,
          516,
          493,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18072471618652344,
        "compression_ratio": 1.474025974025974,
        "end": 5852.76,
        "id": 1430,
        "no_speech_prob": 0.01615273766219616,
        "seek": 585076,
        "start": 5850.76,
        "temperature": 0,
        "text": " So, I can go back to the code.",
        "tokens": [
          50364,
          407,
          11,
          286,
          393,
          352,
          646,
          281,
          264,
          3089,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18072471618652344,
        "compression_ratio": 1.474025974025974,
        "end": 5857.76,
        "id": 1431,
        "no_speech_prob": 0.01615273766219616,
        "seek": 585076,
        "start": 5852.76,
        "temperature": 0,
        "text": " And I can now put this stuff back in.",
        "tokens": [
          50464,
          400,
          286,
          393,
          586,
          829,
          341,
          1507,
          646,
          294,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18072471618652344,
        "compression_ratio": 1.474025974025974,
        "end": 5863.76,
        "id": 1432,
        "no_speech_prob": 0.01615273766219616,
        "seek": 585076,
        "start": 5857.76,
        "temperature": 0,
        "text": " The outputs, it wasn't, whoa, what was it called?",
        "tokens": [
          50714,
          440,
          23930,
          11,
          309,
          2067,
          380,
          11,
          13310,
          11,
          437,
          390,
          309,
          1219,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18072471618652344,
        "compression_ratio": 1.474025974025974,
        "end": 5866.76,
        "id": 1433,
        "no_speech_prob": 0.01615273766219616,
        "seek": 585076,
        "start": 5863.76,
        "temperature": 0,
        "text": " It wasn't called image, was it?",
        "tokens": [
          51014,
          467,
          2067,
          380,
          1219,
          3256,
          11,
          390,
          309,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.18072471618652344,
        "compression_ratio": 1.474025974025974,
        "end": 5869.76,
        "id": 1434,
        "no_speech_prob": 0.01615273766219616,
        "seek": 585076,
        "start": 5866.76,
        "temperature": 0,
        "text": " So weird.",
        "tokens": [
          51164,
          407,
          3657,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18072471618652344,
        "compression_ratio": 1.474025974025974,
        "end": 5871.76,
        "id": 1435,
        "no_speech_prob": 0.01615273766219616,
        "seek": 585076,
        "start": 5869.76,
        "temperature": 0,
        "text": " Why do I have an error now?",
        "tokens": [
          51314,
          1545,
          360,
          286,
          362,
          364,
          6713,
          586,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.18072471618652344,
        "compression_ratio": 1.474025974025974,
        "end": 5876.76,
        "id": 1436,
        "no_speech_prob": 0.01615273766219616,
        "seek": 585076,
        "start": 5871.76,
        "temperature": 0,
        "text": " Oh, I have two things called image 64.",
        "tokens": [
          51414,
          876,
          11,
          286,
          362,
          732,
          721,
          1219,
          3256,
          12145,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24228612203446645,
        "compression_ratio": 1.2627737226277371,
        "end": 5881.76,
        "id": 1437,
        "no_speech_prob": 0.042721714824438095,
        "seek": 587676,
        "start": 5876.76,
        "temperature": 0,
        "text": " Input image 64.",
        "tokens": [
          50364,
          682,
          2582,
          3256,
          12145,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24228612203446645,
        "compression_ratio": 1.2627737226277371,
        "end": 5883.76,
        "id": 1438,
        "no_speech_prob": 0.042721714824438095,
        "seek": 587676,
        "start": 5881.76,
        "temperature": 0,
        "text": " 764.",
        "tokens": [
          50614,
          1614,
          19395,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24228612203446645,
        "compression_ratio": 1.2627737226277371,
        "end": 5887.76,
        "id": 1439,
        "no_speech_prob": 0.042721714824438095,
        "seek": 587676,
        "start": 5883.76,
        "temperature": 0,
        "text": " Let's call it that.",
        "tokens": [
          50714,
          961,
          311,
          818,
          309,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24228612203446645,
        "compression_ratio": 1.2627737226277371,
        "end": 5891.76,
        "id": 1440,
        "no_speech_prob": 0.042721714824438095,
        "seek": 587676,
        "start": 5887.76,
        "temperature": 0,
        "text": " I'll just leave this one this.",
        "tokens": [
          50914,
          286,
          603,
          445,
          1856,
          341,
          472,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24228612203446645,
        "compression_ratio": 1.2627737226277371,
        "end": 5895.76,
        "id": 1441,
        "no_speech_prob": 0.042721714824438095,
        "seek": 587676,
        "start": 5891.76,
        "temperature": 0,
        "text": " You know, I'll just rename this variable to landscape.",
        "tokens": [
          51114,
          509,
          458,
          11,
          286,
          603,
          445,
          36741,
          341,
          7006,
          281,
          9661,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24228612203446645,
        "compression_ratio": 1.2627737226277371,
        "end": 5900.76,
        "id": 1442,
        "no_speech_prob": 0.042721714824438095,
        "seek": 587676,
        "start": 5895.76,
        "temperature": 0,
        "text": " Because why not?",
        "tokens": [
          51314,
          1436,
          983,
          406,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.24228612203446645,
        "compression_ratio": 1.2627737226277371,
        "end": 5904.76,
        "id": 1443,
        "no_speech_prob": 0.042721714824438095,
        "seek": 587676,
        "start": 5900.76,
        "temperature": 0,
        "text": " And then, I forgot what it's,",
        "tokens": [
          51564,
          400,
          550,
          11,
          286,
          5298,
          437,
          309,
          311,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.32822340726852417,
        "compression_ratio": 1.2869565217391303,
        "end": 5906.76,
        "id": 1444,
        "no_speech_prob": 0.051080092787742615,
        "seek": 590476,
        "start": 5904.76,
        "temperature": 0,
        "text": " daily limit reached.",
        "tokens": [
          50364,
          5212,
          4948,
          6488,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.32822340726852417,
        "compression_ratio": 1.2869565217391303,
        "end": 5908.76,
        "id": 1445,
        "no_speech_prob": 0.051080092787742615,
        "seek": 590476,
        "start": 5906.76,
        "temperature": 0,
        "text": " Come on, people.",
        "tokens": [
          50464,
          2492,
          322,
          11,
          561,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.32822340726852417,
        "compression_ratio": 1.2869565217391303,
        "end": 5917.76,
        "id": 1446,
        "no_speech_prob": 0.051080092787742615,
        "seek": 590476,
        "start": 5908.76,
        "temperature": 0,
        "text": " Have a little pity on me here.",
        "tokens": [
          50564,
          3560,
          257,
          707,
          21103,
          322,
          385,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.32822340726852417,
        "compression_ratio": 1.2869565217391303,
        "end": 5922.76,
        "id": 1447,
        "no_speech_prob": 0.051080092787742615,
        "seek": 590476,
        "start": 5917.76,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51014,
          2438,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.32822340726852417,
        "compression_ratio": 1.2869565217391303,
        "end": 5929.76,
        "id": 1448,
        "no_speech_prob": 0.051080092787742615,
        "seek": 590476,
        "start": 5922.76,
        "temperature": 0,
        "text": " Come on, you don't, don't you want to bring generated landscape imagery out",
        "tokens": [
          51264,
          2492,
          322,
          11,
          291,
          500,
          380,
          11,
          500,
          380,
          291,
          528,
          281,
          1565,
          10833,
          9661,
          24340,
          484,
          51614
        ]
      },
      {
        "avg_logprob": -0.21404572475103684,
        "compression_ratio": 1.440217391304348,
        "end": 5935.76,
        "id": 1449,
        "no_speech_prob": 0.13116119801998138,
        "seek": 592976,
        "start": 5929.76,
        "temperature": 0,
        "text": " into the world in a way that we can all enjoy?",
        "tokens": [
          50364,
          666,
          264,
          1002,
          294,
          257,
          636,
          300,
          321,
          393,
          439,
          2103,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.21404572475103684,
        "compression_ratio": 1.440217391304348,
        "end": 5941.76,
        "id": 1450,
        "no_speech_prob": 0.13116119801998138,
        "seek": 592976,
        "start": 5935.76,
        "temperature": 0,
        "text": " I am going to, against my better judgment, go to here.",
        "tokens": [
          50664,
          286,
          669,
          516,
          281,
          11,
          1970,
          452,
          1101,
          12216,
          11,
          352,
          281,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21404572475103684,
        "compression_ratio": 1.440217391304348,
        "end": 5944.76,
        "id": 1451,
        "no_speech_prob": 0.13116119801998138,
        "seek": 592976,
        "start": 5941.76,
        "temperature": 0,
        "text": " Set this back to zero.",
        "tokens": [
          50964,
          8928,
          341,
          646,
          281,
          4018,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21404572475103684,
        "compression_ratio": 1.440217391304348,
        "end": 5950.76,
        "id": 1452,
        "no_speech_prob": 0.13116119801998138,
        "seek": 592976,
        "start": 5944.76,
        "temperature": 0,
        "text": " And try to beat everybody.",
        "tokens": [
          51114,
          400,
          853,
          281,
          4224,
          2201,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21404572475103684,
        "compression_ratio": 1.440217391304348,
        "end": 5951.76,
        "id": 1453,
        "no_speech_prob": 0.13116119801998138,
        "seek": 592976,
        "start": 5950.76,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51414,
          3769,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21404572475103684,
        "compression_ratio": 1.440217391304348,
        "end": 5958.76,
        "id": 1454,
        "no_speech_prob": 0.13116119801998138,
        "seek": 592976,
        "start": 5951.76,
        "temperature": 0,
        "text": " So, oh, it's, so this is something, this is another bit of feedback for those of you who are taking notes.",
        "tokens": [
          51464,
          407,
          11,
          1954,
          11,
          309,
          311,
          11,
          370,
          341,
          307,
          746,
          11,
          341,
          307,
          1071,
          857,
          295,
          5824,
          337,
          729,
          295,
          291,
          567,
          366,
          1940,
          5570,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23996068143296514,
        "compression_ratio": 1.4904761904761905,
        "end": 5961.76,
        "id": 1455,
        "no_speech_prob": 0.10374166816473007,
        "seek": 595876,
        "start": 5958.76,
        "temperature": 0,
        "text": " It's weird that the property is called output here.",
        "tokens": [
          50364,
          467,
          311,
          3657,
          300,
          264,
          4707,
          307,
          1219,
          5598,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23996068143296514,
        "compression_ratio": 1.4904761904761905,
        "end": 5963.76,
        "id": 1456,
        "no_speech_prob": 0.10374166816473007,
        "seek": 595876,
        "start": 5961.76,
        "temperature": 0,
        "text": " And in SkyGan, it was called image.",
        "tokens": [
          50514,
          400,
          294,
          9879,
          38,
          282,
          11,
          309,
          390,
          1219,
          3256,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23996068143296514,
        "compression_ratio": 1.4904761904761905,
        "end": 5967.76,
        "id": 1457,
        "no_speech_prob": 0.10374166816473007,
        "seek": 595876,
        "start": 5963.76,
        "temperature": 0,
        "text": " Like, I feel like that would make sense for that to be pretty consistent across runway models.",
        "tokens": [
          50614,
          1743,
          11,
          286,
          841,
          411,
          300,
          576,
          652,
          2020,
          337,
          300,
          281,
          312,
          1238,
          8398,
          2108,
          26642,
          5245,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23996068143296514,
        "compression_ratio": 1.4904761904761905,
        "end": 5970.76,
        "id": 1458,
        "no_speech_prob": 0.10374166816473007,
        "seek": 595876,
        "start": 5967.76,
        "temperature": 0,
        "text": " So I wouldn't have to keep changing it for every example.",
        "tokens": [
          50814,
          407,
          286,
          2759,
          380,
          362,
          281,
          1066,
          4473,
          309,
          337,
          633,
          1365,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23996068143296514,
        "compression_ratio": 1.4904761904761905,
        "end": 5978.76,
        "id": 1459,
        "no_speech_prob": 0.10374166816473007,
        "seek": 595876,
        "start": 5970.76,
        "temperature": 0,
        "text": " So, but here under sketch.js, I'm going to call this now outputs.output.",
        "tokens": [
          50964,
          407,
          11,
          457,
          510,
          833,
          12325,
          13,
          25530,
          11,
          286,
          478,
          516,
          281,
          818,
          341,
          586,
          23930,
          13,
          346,
          2582,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19283946615750672,
        "compression_ratio": 1.330827067669173,
        "end": 5990.76,
        "id": 1460,
        "no_speech_prob": 0.28139230608940125,
        "seek": 597876,
        "start": 5979.76,
        "temperature": 0,
        "text": " And the, this is a spade cocoa generated landscape.",
        "tokens": [
          50414,
          400,
          264,
          11,
          341,
          307,
          257,
          637,
          762,
          30634,
          10833,
          9661,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19283946615750672,
        "compression_ratio": 1.330827067669173,
        "end": 5995.76,
        "id": 1461,
        "no_speech_prob": 0.28139230608940125,
        "seek": 597876,
        "start": 5990.76,
        "temperature": 0,
        "text": " And let's try this one more time.",
        "tokens": [
          50964,
          400,
          718,
          311,
          853,
          341,
          472,
          544,
          565,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19283946615750672,
        "compression_ratio": 1.330827067669173,
        "end": 5998.76,
        "id": 1462,
        "no_speech_prob": 0.28139230608940125,
        "seek": 597876,
        "start": 5995.76,
        "temperature": 0,
        "text": " Oh, I need to refresh the page.",
        "tokens": [
          51214,
          876,
          11,
          286,
          643,
          281,
          15134,
          264,
          3028,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19283946615750672,
        "compression_ratio": 1.330827067669173,
        "end": 6000.76,
        "id": 1463,
        "no_speech_prob": 0.28139230608940125,
        "seek": 597876,
        "start": 5998.76,
        "temperature": 0,
        "text": " Oh, there we got it.",
        "tokens": [
          51364,
          876,
          11,
          456,
          321,
          658,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19283946615750672,
        "compression_ratio": 1.330827067669173,
        "end": 6001.76,
        "id": 1464,
        "no_speech_prob": 0.28139230608940125,
        "seek": 597876,
        "start": 6000.76,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51464,
          2053,
          412,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19283946615750672,
        "compression_ratio": 1.330827067669173,
        "end": 6004.76,
        "id": 1465,
        "no_speech_prob": 0.28139230608940125,
        "seek": 597876,
        "start": 6001.76,
        "temperature": 0,
        "text": " That's my generated sky.",
        "tokens": [
          51514,
          663,
          311,
          452,
          10833,
          5443,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6006.76,
        "id": 1466,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6004.76,
        "temperature": 0,
        "text": " Let's draw some ocean on it.",
        "tokens": [
          50364,
          961,
          311,
          2642,
          512,
          7810,
          322,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6012.76,
        "id": 1467,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6006.76,
        "temperature": 0,
        "text": " Try to be faster than all of you people.",
        "tokens": [
          50464,
          6526,
          281,
          312,
          4663,
          813,
          439,
          295,
          291,
          561,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6013.76,
        "id": 1468,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6012.76,
        "temperature": 0,
        "text": " And there's the ocean.",
        "tokens": [
          50764,
          400,
          456,
          311,
          264,
          7810,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6017.76,
        "id": 1469,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6013.76,
        "temperature": 0,
        "text": " Oh, this is so cool.",
        "tokens": [
          50814,
          876,
          11,
          341,
          307,
          370,
          1627,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6019.76,
        "id": 1470,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6017.76,
        "temperature": 0,
        "text": " And I'm at eight.",
        "tokens": [
          51014,
          400,
          286,
          478,
          412,
          3180,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6020.76,
        "id": 1471,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6019.76,
        "temperature": 0,
        "text": " Thank you, people.",
        "tokens": [
          51114,
          1044,
          291,
          11,
          561,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6021.76,
        "id": 1472,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6020.76,
        "temperature": 0,
        "text": " Please, please.",
        "tokens": [
          51164,
          2555,
          11,
          1767,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6022.76,
        "id": 1473,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6021.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51214,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1748568254358628,
        "compression_ratio": 1.4363636363636363,
        "end": 6029.76,
        "id": 1474,
        "no_speech_prob": 0.028435302898287773,
        "seek": 600476,
        "start": 6022.76,
        "temperature": 0,
        "text": " I guess what I'll do just to shut it off for a minute here.",
        "tokens": [
          51264,
          286,
          2041,
          437,
          286,
          603,
          360,
          445,
          281,
          5309,
          309,
          766,
          337,
          257,
          3456,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.229014892578125,
        "compression_ratio": 1.6158536585365855,
        "end": 6033.76,
        "id": 1475,
        "no_speech_prob": 0.00181019795127213,
        "seek": 602976,
        "start": 6029.76,
        "temperature": 0,
        "text": " So this is why I should run this stuff locally so only I could run it and then deploy it to glitch.",
        "tokens": [
          50364,
          407,
          341,
          307,
          983,
          286,
          820,
          1190,
          341,
          1507,
          16143,
          370,
          787,
          286,
          727,
          1190,
          309,
          293,
          550,
          7274,
          309,
          281,
          23552,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.229014892578125,
        "compression_ratio": 1.6158536585365855,
        "end": 6035.76,
        "id": 1476,
        "no_speech_prob": 0.00181019795127213,
        "seek": 602976,
        "start": 6033.76,
        "temperature": 0,
        "text": " But so I want to do something now.",
        "tokens": [
          50564,
          583,
          370,
          286,
          528,
          281,
          360,
          746,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.229014892578125,
        "compression_ratio": 1.6158536585365855,
        "end": 6038.76,
        "id": 1477,
        "no_speech_prob": 0.00181019795127213,
        "seek": 602976,
        "start": 6035.76,
        "temperature": 0,
        "text": " I want to change the code.",
        "tokens": [
          50664,
          286,
          528,
          281,
          1319,
          264,
          3089,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.229014892578125,
        "compression_ratio": 1.6158536585365855,
        "end": 6049.76,
        "id": 1478,
        "no_speech_prob": 0.00181019795127213,
        "seek": 602976,
        "start": 6038.76,
        "temperature": 0,
        "text": " I want to make a variable called output image.",
        "tokens": [
          50814,
          286,
          528,
          281,
          652,
          257,
          7006,
          1219,
          5598,
          3256,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.229014892578125,
        "compression_ratio": 1.6158536585365855,
        "end": 6056.76,
        "id": 1479,
        "no_speech_prob": 0.00181019795127213,
        "seek": 602976,
        "start": 6049.76,
        "temperature": 0,
        "text": " And that is going to be output image.create image blank.",
        "tokens": [
          51364,
          400,
          300,
          307,
          516,
          281,
          312,
          5598,
          3256,
          13,
          14066,
          473,
          3256,
          8247,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17859221907222972,
        "compression_ratio": 1.4107142857142858,
        "end": 6063.76,
        "id": 1480,
        "no_speech_prob": 0.034100018441677094,
        "seek": 605676,
        "start": 6056.76,
        "temperature": 0,
        "text": " So I want to create an image DOM element that's sitting below the canvas.",
        "tokens": [
          50364,
          407,
          286,
          528,
          281,
          1884,
          364,
          3256,
          35727,
          4478,
          300,
          311,
          3798,
          2507,
          264,
          16267,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17859221907222972,
        "compression_ratio": 1.4107142857142858,
        "end": 6074.76,
        "id": 1481,
        "no_speech_prob": 0.034100018441677094,
        "seek": 605676,
        "start": 6063.76,
        "temperature": 0,
        "text": " And then rather than make a new one here, I just want to take the existing one.",
        "tokens": [
          50714,
          400,
          550,
          2831,
          813,
          652,
          257,
          777,
          472,
          510,
          11,
          286,
          445,
          528,
          281,
          747,
          264,
          6741,
          472,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17859221907222972,
        "compression_ratio": 1.4107142857142858,
        "end": 6077.76,
        "id": 1482,
        "no_speech_prob": 0.034100018441677094,
        "seek": 605676,
        "start": 6074.76,
        "temperature": 0,
        "text": " Let me put the alt text in.",
        "tokens": [
          51264,
          961,
          385,
          829,
          264,
          4955,
          2487,
          294,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17859221907222972,
        "compression_ratio": 1.4107142857142858,
        "end": 6079.76,
        "id": 1483,
        "no_speech_prob": 0.034100018441677094,
        "seek": 605676,
        "start": 6077.76,
        "temperature": 0,
        "text": " Hopefully this works.",
        "tokens": [
          51414,
          10429,
          341,
          1985,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17859221907222972,
        "compression_ratio": 1.4107142857142858,
        "end": 6083.76,
        "id": 1484,
        "no_speech_prob": 0.034100018441677094,
        "seek": 605676,
        "start": 6079.76,
        "temperature": 0,
        "text": " I've not tried to do this before.",
        "tokens": [
          51514,
          286,
          600,
          406,
          3031,
          281,
          360,
          341,
          949,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2416931354638302,
        "compression_ratio": 1.4181818181818182,
        "end": 6088.76,
        "id": 1485,
        "no_speech_prob": 0.20688381791114807,
        "seek": 608376,
        "start": 6083.76,
        "temperature": 0,
        "text": " Let's put this in here.",
        "tokens": [
          50364,
          961,
          311,
          829,
          341,
          294,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2416931354638302,
        "compression_ratio": 1.4181818181818182,
        "end": 6098.76,
        "id": 1486,
        "no_speech_prob": 0.20688381791114807,
        "seek": 608376,
        "start": 6088.76,
        "temperature": 0,
        "text": " And I think I can say like output image.elt.source equals image 64.",
        "tokens": [
          50614,
          400,
          286,
          519,
          286,
          393,
          584,
          411,
          5598,
          3256,
          13,
          2018,
          13,
          41676,
          6915,
          3256,
          12145,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2416931354638302,
        "compression_ratio": 1.4181818181818182,
        "end": 6107.76,
        "id": 1487,
        "no_speech_prob": 0.20688381791114807,
        "seek": 608376,
        "start": 6098.76,
        "temperature": 0,
        "text": " This would be setting the source of the image to that base 64 encoding, which would make it appear in the DOM element, I think.",
        "tokens": [
          51114,
          639,
          576,
          312,
          3287,
          264,
          4009,
          295,
          264,
          3256,
          281,
          300,
          3096,
          12145,
          43430,
          11,
          597,
          576,
          652,
          309,
          4204,
          294,
          264,
          35727,
          4478,
          11,
          286,
          519,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2416931354638302,
        "compression_ratio": 1.4181818181818182,
        "end": 6108.76,
        "id": 1488,
        "no_speech_prob": 0.20688381791114807,
        "seek": 608376,
        "start": 6107.76,
        "temperature": 0,
        "text": " Is that right?",
        "tokens": [
          51564,
          1119,
          300,
          558,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.24448793074663946,
        "compression_ratio": 1.1333333333333333,
        "end": 6120.76,
        "id": 1489,
        "no_speech_prob": 0.25682079792022705,
        "seek": 610876,
        "start": 6108.76,
        "temperature": 0,
        "text": " Does anybody know?",
        "tokens": [
          50364,
          4402,
          4472,
          458,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.24448793074663946,
        "compression_ratio": 1.1333333333333333,
        "end": 6127.76,
        "id": 1490,
        "no_speech_prob": 0.25682079792022705,
        "seek": 610876,
        "start": 6120.76,
        "temperature": 0,
        "text": " Cannot read property create image of undefined.",
        "tokens": [
          50964,
          29866,
          310,
          1401,
          4707,
          1884,
          3256,
          295,
          674,
          5666,
          2001,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24448793074663946,
        "compression_ratio": 1.1333333333333333,
        "end": 6133.76,
        "id": 1491,
        "no_speech_prob": 0.25682079792022705,
        "seek": 610876,
        "start": 6127.76,
        "temperature": 0,
        "text": " Oh, equals create image.",
        "tokens": [
          51314,
          876,
          11,
          6915,
          1884,
          3256,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24448793074663946,
        "compression_ratio": 1.1333333333333333,
        "end": 6134.76,
        "id": 1492,
        "no_speech_prob": 0.25682079792022705,
        "seek": 610876,
        "start": 6133.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51614,
          1057,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23008848190307618,
        "compression_ratio": 1.304,
        "end": 6139.76,
        "id": 1493,
        "no_speech_prob": 0.34507888555526733,
        "seek": 613476,
        "start": 6135.76,
        "temperature": 0,
        "text": " I've disabled it.",
        "tokens": [
          50414,
          286,
          600,
          15191,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23008848190307618,
        "compression_ratio": 1.304,
        "end": 6145.76,
        "id": 1494,
        "no_speech_prob": 0.34507888555526733,
        "seek": 613476,
        "start": 6139.76,
        "temperature": 0,
        "text": " If you could please hold off on running this for a moment.",
        "tokens": [
          50614,
          759,
          291,
          727,
          1767,
          1797,
          766,
          322,
          2614,
          341,
          337,
          257,
          1623,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23008848190307618,
        "compression_ratio": 1.304,
        "end": 6158.76,
        "id": 1495,
        "no_speech_prob": 0.34507888555526733,
        "seek": 613476,
        "start": 6145.76,
        "temperature": 0,
        "text": " I guess I could make it a private project, but I think let's see if this works.",
        "tokens": [
          50914,
          286,
          2041,
          286,
          727,
          652,
          309,
          257,
          4551,
          1716,
          11,
          457,
          286,
          519,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23008848190307618,
        "compression_ratio": 1.304,
        "end": 6159.76,
        "id": 1496,
        "no_speech_prob": 0.34507888555526733,
        "seek": 613476,
        "start": 6158.76,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51564,
          3769,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6163.76,
        "id": 1497,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6159.76,
        "temperature": 0,
        "text": " And then if I do this, it generates a daily limit reached.",
        "tokens": [
          50364,
          400,
          550,
          498,
          286,
          360,
          341,
          11,
          309,
          23815,
          257,
          5212,
          4948,
          6488,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6167.76,
        "id": 1498,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6163.76,
        "temperature": 0,
        "text": " Come on, people!",
        "tokens": [
          50564,
          2492,
          322,
          11,
          561,
          0,
          50764
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6170.76,
        "id": 1499,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6167.76,
        "temperature": 0,
        "text": " This isn't even a sponsored live stream.",
        "tokens": [
          50764,
          639,
          1943,
          380,
          754,
          257,
          16621,
          1621,
          4309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6172.76,
        "id": 1500,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6170.76,
        "temperature": 0,
        "text": " I'm using up all my credits.",
        "tokens": [
          50914,
          286,
          478,
          1228,
          493,
          439,
          452,
          16816,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6174.76,
        "id": 1501,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6172.76,
        "temperature": 0,
        "text": " I don't even know.",
        "tokens": [
          51014,
          286,
          500,
          380,
          754,
          458,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6176.76,
        "id": 1502,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6174.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51114,
          1057,
          558,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6177.76,
        "id": 1503,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6176.76,
        "temperature": 0,
        "text": " Back over here.",
        "tokens": [
          51214,
          5833,
          670,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6180.76,
        "id": 1504,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6177.76,
        "temperature": 0,
        "text": " I'm going to be doing my object model detection.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          312,
          884,
          452,
          2657,
          2316,
          17784,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6185.76,
        "id": 1505,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6180.76,
        "temperature": 0,
        "text": " Sorry, my object detection example.",
        "tokens": [
          51414,
          4919,
          11,
          452,
          2657,
          17784,
          1365,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24530875926115076,
        "compression_ratio": 1.5678391959798994,
        "end": 6187.76,
        "id": 1506,
        "no_speech_prob": 0.6150020360946655,
        "seek": 615976,
        "start": 6185.76,
        "temperature": 0,
        "text": " I'm going to be doing that locally.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          312,
          884,
          300,
          16143,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2635852098464966,
        "compression_ratio": 1.3580246913580247,
        "end": 6202.76,
        "id": 1507,
        "no_speech_prob": 0.41108062863349915,
        "seek": 618776,
        "start": 6187.76,
        "temperature": 0,
        "text": " You won't be able to see it.",
        "tokens": [
          50364,
          509,
          1582,
          380,
          312,
          1075,
          281,
          536,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2635852098464966,
        "compression_ratio": 1.3580246913580247,
        "end": 6210.76,
        "id": 1508,
        "no_speech_prob": 0.41108062863349915,
        "seek": 618776,
        "start": 6202.76,
        "temperature": 0,
        "text": " I want to see if I can get...",
        "tokens": [
          51114,
          286,
          528,
          281,
          536,
          498,
          286,
          393,
          483,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.2635852098464966,
        "compression_ratio": 1.3580246913580247,
        "end": 6215.76,
        "id": 1509,
        "no_speech_prob": 0.41108062863349915,
        "seek": 618776,
        "start": 6210.76,
        "temperature": 0,
        "text": " I want to see if it will replace it with a new one.",
        "tokens": [
          51514,
          286,
          528,
          281,
          536,
          498,
          309,
          486,
          7406,
          309,
          365,
          257,
          777,
          472,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6216.76,
        "id": 1510,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6215.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6217.76,
        "id": 1511,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6216.76,
        "temperature": 0,
        "text": " So that works.",
        "tokens": [
          50414,
          407,
          300,
          1985,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6221.76,
        "id": 1512,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6217.76,
        "temperature": 0,
        "text": " Now if I do this and hit generate again.",
        "tokens": [
          50464,
          823,
          498,
          286,
          360,
          341,
          293,
          2045,
          8460,
          797,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6222.76,
        "id": 1513,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6221.76,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50664,
          3769,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6223.76,
        "id": 1514,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6222.76,
        "temperature": 0,
        "text": " Awesome.",
        "tokens": [
          50714,
          10391,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6224.76,
        "id": 1515,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6223.76,
        "temperature": 0,
        "text": " It's working.",
        "tokens": [
          50764,
          467,
          311,
          1364,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6226.76,
        "id": 1516,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6224.76,
        "temperature": 0,
        "text": " Shutting you down, people.",
        "tokens": [
          50814,
          13870,
          783,
          291,
          760,
          11,
          561,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6227.76,
        "id": 1517,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6226.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50914,
          1057,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6232.76,
        "id": 1518,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6227.76,
        "temperature": 0,
        "text": " So this works now that it's going to always update this one.",
        "tokens": [
          50964,
          407,
          341,
          1985,
          586,
          300,
          309,
          311,
          516,
          281,
          1009,
          5623,
          341,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6237.76,
        "id": 1519,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6232.76,
        "temperature": 0,
        "text": " Maybe I don't need 640 by 480 just to be able to see it.",
        "tokens": [
          51214,
          2704,
          286,
          500,
          380,
          643,
          1386,
          5254,
          538,
          1017,
          4702,
          445,
          281,
          312,
          1075,
          281,
          536,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6241.76,
        "id": 1520,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6237.76,
        "temperature": 0,
        "text": " What I'm going to do now is have it update as I'm drawing.",
        "tokens": [
          51464,
          708,
          286,
          478,
          516,
          281,
          360,
          586,
          307,
          362,
          309,
          5623,
          382,
          286,
          478,
          6316,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16951870918273926,
        "compression_ratio": 1.5945945945945945,
        "end": 6243.76,
        "id": 1521,
        "no_speech_prob": 0.03114253468811512,
        "seek": 621576,
        "start": 6241.76,
        "temperature": 0,
        "text": " So this is going to use a lot of requests.",
        "tokens": [
          51664,
          407,
          341,
          307,
          516,
          281,
          764,
          257,
          688,
          295,
          12475,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2360934777693315,
        "compression_ratio": 1.3966480446927374,
        "end": 6248.76,
        "id": 1522,
        "no_speech_prob": 0.31401532888412476,
        "seek": 624376,
        "start": 6243.76,
        "temperature": 0,
        "text": " This is where I would want probably more like a socket connection or something to the model.",
        "tokens": [
          50364,
          639,
          307,
          689,
          286,
          576,
          528,
          1391,
          544,
          411,
          257,
          19741,
          4984,
          420,
          746,
          281,
          264,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2360934777693315,
        "compression_ratio": 1.3966480446927374,
        "end": 6253.76,
        "id": 1523,
        "no_speech_prob": 0.31401532888412476,
        "seek": 624376,
        "start": 6248.76,
        "temperature": 0,
        "text": " But let's just sort of see what happens here.",
        "tokens": [
          50614,
          583,
          718,
          311,
          445,
          1333,
          295,
          536,
          437,
          2314,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2360934777693315,
        "compression_ratio": 1.3966480446927374,
        "end": 6256.76,
        "id": 1524,
        "no_speech_prob": 0.31401532888412476,
        "seek": 624376,
        "start": 6253.76,
        "temperature": 0,
        "text": " So if I go back to Sketch.js.",
        "tokens": [
          50864,
          407,
          498,
          286,
          352,
          646,
          281,
          49245,
          13,
          25530,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2360934777693315,
        "compression_ratio": 1.3966480446927374,
        "end": 6269.76,
        "id": 1525,
        "no_speech_prob": 0.31401532888412476,
        "seek": 624376,
        "start": 6256.76,
        "temperature": 0,
        "text": " And then essentially this send image function, I am going to call it recursively.",
        "tokens": [
          51014,
          400,
          550,
          4476,
          341,
          2845,
          3256,
          2445,
          11,
          286,
          669,
          516,
          281,
          818,
          309,
          20560,
          3413,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17202754701886858,
        "compression_ratio": 1.5217391304347827,
        "end": 6273.76,
        "id": 1526,
        "no_speech_prob": 0.22268526256084442,
        "seek": 626976,
        "start": 6269.76,
        "temperature": 0,
        "text": " I am going to call it immediately when the program starts.",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          818,
          309,
          4258,
          562,
          264,
          1461,
          3719,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17202754701886858,
        "compression_ratio": 1.5217391304347827,
        "end": 6279.76,
        "id": 1527,
        "no_speech_prob": 0.22268526256084442,
        "seek": 626976,
        "start": 6273.76,
        "temperature": 0,
        "text": " And then every time after I've updated the image, I'm going to call send image again.",
        "tokens": [
          50564,
          400,
          550,
          633,
          565,
          934,
          286,
          600,
          10588,
          264,
          3256,
          11,
          286,
          478,
          516,
          281,
          818,
          2845,
          3256,
          797,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17202754701886858,
        "compression_ratio": 1.5217391304347827,
        "end": 6282.76,
        "id": 1528,
        "no_speech_prob": 0.22268526256084442,
        "seek": 626976,
        "start": 6279.76,
        "temperature": 0,
        "text": " And let's see.",
        "tokens": [
          50864,
          400,
          718,
          311,
          536,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17202754701886858,
        "compression_ratio": 1.5217391304347827,
        "end": 6286.76,
        "id": 1529,
        "no_speech_prob": 0.22268526256084442,
        "seek": 626976,
        "start": 6282.76,
        "temperature": 0,
        "text": " Let me set the count back down to zero.",
        "tokens": [
          51014,
          961,
          385,
          992,
          264,
          1207,
          646,
          760,
          281,
          4018,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17202754701886858,
        "compression_ratio": 1.5217391304347827,
        "end": 6290.76,
        "id": 1530,
        "no_speech_prob": 0.22268526256084442,
        "seek": 626976,
        "start": 6286.76,
        "temperature": 0,
        "text": " Let me turn the model back on to activate it.",
        "tokens": [
          51214,
          961,
          385,
          1261,
          264,
          2316,
          646,
          322,
          281,
          13615,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16580599004572089,
        "compression_ratio": 1.2478632478632479,
        "end": 6305.76,
        "id": 1531,
        "no_speech_prob": 0.05834466964006424,
        "seek": 629076,
        "start": 6290.76,
        "temperature": 0,
        "text": " And now it should be updating as I draw.",
        "tokens": [
          50364,
          400,
          586,
          309,
          820,
          312,
          25113,
          382,
          286,
          2642,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16580599004572089,
        "compression_ratio": 1.2478632478632479,
        "end": 6310.76,
        "id": 1532,
        "no_speech_prob": 0.05834466964006424,
        "seek": 629076,
        "start": 6305.76,
        "temperature": 0,
        "text": " So I didn't pick like really smart colors here.",
        "tokens": [
          51114,
          407,
          286,
          994,
          380,
          1888,
          411,
          534,
          4069,
          4577,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16580599004572089,
        "compression_ratio": 1.2478632478632479,
        "end": 6315.76,
        "id": 1533,
        "no_speech_prob": 0.05834466964006424,
        "seek": 629076,
        "start": 6310.76,
        "temperature": 0,
        "text": " But you can see here as I'm drawing, it's updating below.",
        "tokens": [
          51364,
          583,
          291,
          393,
          536,
          510,
          382,
          286,
          478,
          6316,
          11,
          309,
          311,
          25113,
          2507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19579990978898673,
        "compression_ratio": 1.4014598540145986,
        "end": 6321.76,
        "id": 1534,
        "no_speech_prob": 0.07807661592960358,
        "seek": 631576,
        "start": 6315.76,
        "temperature": 0,
        "text": " And I should obviously turn this off.",
        "tokens": [
          50364,
          400,
          286,
          820,
          2745,
          1261,
          341,
          766,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19579990978898673,
        "compression_ratio": 1.4014598540145986,
        "end": 6327.76,
        "id": 1535,
        "no_speech_prob": 0.07807661592960358,
        "seek": 631576,
        "start": 6321.76,
        "temperature": 0,
        "text": " I should certainly.",
        "tokens": [
          50664,
          286,
          820,
          3297,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19579990978898673,
        "compression_ratio": 1.4014598540145986,
        "end": 6328.76,
        "id": 1536,
        "no_speech_prob": 0.07807661592960358,
        "seek": 631576,
        "start": 6327.76,
        "temperature": 0,
        "text": " What am I saying?",
        "tokens": [
          50964,
          708,
          669,
          286,
          1566,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.19579990978898673,
        "compression_ratio": 1.4014598540145986,
        "end": 6329.76,
        "id": 1537,
        "no_speech_prob": 0.07807661592960358,
        "seek": 631576,
        "start": 6328.76,
        "temperature": 0,
        "text": " I should certainly like.",
        "tokens": [
          51014,
          286,
          820,
          3297,
          411,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19579990978898673,
        "compression_ratio": 1.4014598540145986,
        "end": 6331.76,
        "id": 1538,
        "no_speech_prob": 0.07807661592960358,
        "seek": 631576,
        "start": 6329.76,
        "temperature": 0,
        "text": " So there's lots more next steps to this.",
        "tokens": [
          51064,
          407,
          456,
          311,
          3195,
          544,
          958,
          4439,
          281,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19579990978898673,
        "compression_ratio": 1.4014598540145986,
        "end": 6335.76,
        "id": 1539,
        "no_speech_prob": 0.07807661592960358,
        "seek": 631576,
        "start": 6331.76,
        "temperature": 0,
        "text": " But I just wanted to save this as a basic example.",
        "tokens": [
          51164,
          583,
          286,
          445,
          1415,
          281,
          3155,
          341,
          382,
          257,
          3875,
          1365,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1920734083796122,
        "compression_ratio": 1.532258064516129,
        "end": 6346.76,
        "id": 1540,
        "no_speech_prob": 0.35934191942214966,
        "seek": 633576,
        "start": 6335.76,
        "temperature": 0,
        "text": " And I'm realizing here also this should say Spade Cocoa P5.js example.",
        "tokens": [
          50364,
          400,
          286,
          478,
          16734,
          510,
          611,
          341,
          820,
          584,
          1738,
          762,
          29787,
          64,
          430,
          20,
          13,
          25530,
          1365,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1920734083796122,
        "compression_ratio": 1.532258064516129,
        "end": 6350.76,
        "id": 1541,
        "no_speech_prob": 0.35934191942214966,
        "seek": 633576,
        "start": 6346.76,
        "temperature": 0,
        "text": " I think actually I should publish the example with the generate button.",
        "tokens": [
          50914,
          286,
          519,
          767,
          286,
          820,
          11374,
          264,
          1365,
          365,
          264,
          8460,
          2960,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1920734083796122,
        "compression_ratio": 1.532258064516129,
        "end": 6352.76,
        "id": 1542,
        "no_speech_prob": 0.35934191942214966,
        "seek": 633576,
        "start": 6350.76,
        "temperature": 0,
        "text": " So I just want to clean.",
        "tokens": [
          51114,
          407,
          286,
          445,
          528,
          281,
          2541,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1920734083796122,
        "compression_ratio": 1.532258064516129,
        "end": 6355.76,
        "id": 1543,
        "no_speech_prob": 0.35934191942214966,
        "seek": 633576,
        "start": 6352.76,
        "temperature": 0,
        "text": " I wanted to show you how it worked to do it continuously.",
        "tokens": [
          51214,
          286,
          1415,
          281,
          855,
          291,
          577,
          309,
          2732,
          281,
          360,
          309,
          15684,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1920734083796122,
        "compression_ratio": 1.532258064516129,
        "end": 6358.76,
        "id": 1544,
        "no_speech_prob": 0.35934191942214966,
        "seek": 633576,
        "start": 6355.76,
        "temperature": 0,
        "text": " But I'm going to take that out.",
        "tokens": [
          51364,
          583,
          286,
          478,
          516,
          281,
          747,
          300,
          484,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1920734083796122,
        "compression_ratio": 1.532258064516129,
        "end": 6361.76,
        "id": 1545,
        "no_speech_prob": 0.35934191942214966,
        "seek": 633576,
        "start": 6358.76,
        "temperature": 0,
        "text": " I'm going to take this out.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          747,
          341,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18491450352455252,
        "compression_ratio": 1.3866666666666667,
        "end": 6366.76,
        "id": 1546,
        "no_speech_prob": 0.013020405545830727,
        "seek": 636176,
        "start": 6362.76,
        "temperature": 0,
        "text": " I'm going to take this out.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          747,
          341,
          484,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18491450352455252,
        "compression_ratio": 1.3866666666666667,
        "end": 6372.76,
        "id": 1547,
        "no_speech_prob": 0.013020405545830727,
        "seek": 636176,
        "start": 6366.76,
        "temperature": 0,
        "text": " And I just want to leave this.",
        "tokens": [
          50614,
          400,
          286,
          445,
          528,
          281,
          1856,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18491450352455252,
        "compression_ratio": 1.3866666666666667,
        "end": 6375.76,
        "id": 1548,
        "no_speech_prob": 0.013020405545830727,
        "seek": 636176,
        "start": 6372.76,
        "temperature": 0,
        "text": " What would happen if I made this 320 by 240?",
        "tokens": [
          50914,
          708,
          576,
          1051,
          498,
          286,
          1027,
          341,
          42429,
          538,
          26837,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18491450352455252,
        "compression_ratio": 1.3866666666666667,
        "end": 6378.76,
        "id": 1549,
        "no_speech_prob": 0.013020405545830727,
        "seek": 636176,
        "start": 6375.76,
        "temperature": 0,
        "text": " Would it still work just as well?",
        "tokens": [
          51064,
          6068,
          309,
          920,
          589,
          445,
          382,
          731,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.18491450352455252,
        "compression_ratio": 1.3866666666666667,
        "end": 6385.76,
        "id": 1550,
        "no_speech_prob": 0.013020405545830727,
        "seek": 636176,
        "start": 6378.76,
        "temperature": 0,
        "text": " So I think it would just sort of be easier to see.",
        "tokens": [
          51214,
          407,
          286,
          519,
          309,
          576,
          445,
          1333,
          295,
          312,
          3571,
          281,
          536,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18491450352455252,
        "compression_ratio": 1.3866666666666667,
        "end": 6388.76,
        "id": 1551,
        "no_speech_prob": 0.013020405545830727,
        "seek": 636176,
        "start": 6385.76,
        "temperature": 0,
        "text": " And yeah, actually.",
        "tokens": [
          51564,
          400,
          1338,
          11,
          767,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6389.76,
        "id": 1552,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6388.76,
        "temperature": 0,
        "text": " So this should.",
        "tokens": [
          50364,
          407,
          341,
          820,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6391.76,
        "id": 1553,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6389.76,
        "temperature": 0,
        "text": " It should do this first.",
        "tokens": [
          50414,
          467,
          820,
          360,
          341,
          700,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6393.76,
        "id": 1554,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6391.76,
        "temperature": 0,
        "text": " Because I do want to see that always filled up.",
        "tokens": [
          50514,
          1436,
          286,
          360,
          528,
          281,
          536,
          300,
          1009,
          6412,
          493,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6396.76,
        "id": 1555,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6393.76,
        "temperature": 0,
        "text": " Let's turn this back on.",
        "tokens": [
          50614,
          961,
          311,
          1261,
          341,
          646,
          322,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6399.76,
        "id": 1556,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6396.76,
        "temperature": 0,
        "text": " Let's go to the server.",
        "tokens": [
          50764,
          961,
          311,
          352,
          281,
          264,
          7154,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6403.76,
        "id": 1557,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6399.76,
        "temperature": 0,
        "text": " And I'm going to set the count to one, whatever it may be.",
        "tokens": [
          50914,
          400,
          286,
          478,
          516,
          281,
          992,
          264,
          1207,
          281,
          472,
          11,
          2035,
          309,
          815,
          312,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6409.76,
        "id": 1558,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6403.76,
        "temperature": 0,
        "text": " And now let's just see if this is working again.",
        "tokens": [
          51114,
          400,
          586,
          718,
          311,
          445,
          536,
          498,
          341,
          307,
          1364,
          797,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6410.76,
        "id": 1559,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6409.76,
        "temperature": 0,
        "text": " It's weird.",
        "tokens": [
          51414,
          467,
          311,
          3657,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6411.76,
        "id": 1560,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6410.76,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          51464,
          1545,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6412.76,
        "id": 1561,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6411.76,
        "temperature": 0,
        "text": " Why is that?",
        "tokens": [
          51514,
          1545,
          307,
          300,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6413.76,
        "id": 1562,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6412.76,
        "temperature": 0,
        "text": " Why won't it put the image next to it?",
        "tokens": [
          51564,
          1545,
          1582,
          380,
          309,
          829,
          264,
          3256,
          958,
          281,
          309,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.19039159072072884,
        "compression_ratio": 1.6176470588235294,
        "end": 6415.76,
        "id": 1563,
        "no_speech_prob": 0.03258926048874855,
        "seek": 638876,
        "start": 6413.76,
        "temperature": 0,
        "text": " Well, whatever.",
        "tokens": [
          51614,
          1042,
          11,
          2035,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6424.76,
        "id": 1564,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6415.76,
        "temperature": 0,
        "text": " So now if I draw here and click generate, there we go.",
        "tokens": [
          50364,
          407,
          586,
          498,
          286,
          2642,
          510,
          293,
          2052,
          8460,
          11,
          456,
          321,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6426.76,
        "id": 1565,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6424.76,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50814,
          3769,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6428.76,
        "id": 1566,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6426.76,
        "temperature": 0,
        "text": " And I can turn it off.",
        "tokens": [
          50914,
          400,
          286,
          393,
          1261,
          309,
          766,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6429.76,
        "id": 1567,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6428.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51014,
          1057,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6430.76,
        "id": 1568,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6429.76,
        "temperature": 0,
        "text": " This example is finished.",
        "tokens": [
          51064,
          639,
          1365,
          307,
          4335,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6433.76,
        "id": 1569,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6430.76,
        "temperature": 0,
        "text": " Thank you for watching.",
        "tokens": [
          51114,
          1044,
          291,
          337,
          1976,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6436.76,
        "id": 1570,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6433.76,
        "temperature": 0,
        "text": " What was the thing that I wanted to fix here?",
        "tokens": [
          51264,
          708,
          390,
          264,
          551,
          300,
          286,
          1415,
          281,
          3191,
          510,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6441.76,
        "id": 1571,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6436.76,
        "temperature": 0,
        "text": " Oh, I don't think I need the console log here right now.",
        "tokens": [
          51414,
          876,
          11,
          286,
          500,
          380,
          519,
          286,
          643,
          264,
          11076,
          3565,
          510,
          558,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6442.76,
        "id": 1572,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6441.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1734218918875362,
        "compression_ratio": 1.4640883977900552,
        "end": 6443.76,
        "id": 1573,
        "no_speech_prob": 0.21203859150409698,
        "seek": 641576,
        "start": 6442.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51714,
          1057,
          558,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6448.76,
        "id": 1574,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6443.76,
        "temperature": 0,
        "text": " So this you can use as an example to work with a runway.",
        "tokens": [
          50364,
          407,
          341,
          291,
          393,
          764,
          382,
          364,
          1365,
          281,
          589,
          365,
          257,
          26642,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6456.76,
        "id": 1575,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6448.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50614,
          1057,
          558,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6459.76,
        "id": 1576,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6456.76,
        "temperature": 0,
        "text": " Let's take a look at our.",
        "tokens": [
          51014,
          961,
          311,
          747,
          257,
          574,
          412,
          527,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6460.76,
        "id": 1577,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6459.76,
        "temperature": 0,
        "text": " I really got to do.",
        "tokens": [
          51164,
          286,
          534,
          658,
          281,
          360,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6462.76,
        "id": 1578,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6460.76,
        "temperature": 0,
        "text": " Let's do some community contributions.",
        "tokens": [
          51214,
          961,
          311,
          360,
          512,
          1768,
          15725,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6463.76,
        "id": 1579,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6462.76,
        "temperature": 0,
        "text": " It's 520.",
        "tokens": [
          51314,
          467,
          311,
          1025,
          2009,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6464.76,
        "id": 1580,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6463.76,
        "temperature": 0,
        "text": " I got to finish up here.",
        "tokens": [
          51364,
          286,
          658,
          281,
          2413,
          493,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18501918380324905,
        "compression_ratio": 1.3548387096774193,
        "end": 6470.76,
        "id": 1581,
        "no_speech_prob": 0.10230147838592529,
        "seek": 644376,
        "start": 6464.76,
        "temperature": 0,
        "text": " Going to be done soon.",
        "tokens": [
          51414,
          10963,
          281,
          312,
          1096,
          2321,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6474.76,
        "id": 1582,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6471.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6476.76,
        "id": 1583,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6474.76,
        "temperature": 0,
        "text": " Hey, everybody.",
        "tokens": [
          50564,
          1911,
          11,
          2201,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6477.76,
        "id": 1584,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6476.76,
        "temperature": 0,
        "text": " It's time.",
        "tokens": [
          50664,
          467,
          311,
          565,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6479.76,
        "id": 1585,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6477.76,
        "temperature": 0,
        "text": " It's quite late in this stream.",
        "tokens": [
          50714,
          467,
          311,
          1596,
          3469,
          294,
          341,
          4309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6481.76,
        "id": 1586,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6479.76,
        "temperature": 0,
        "text": " Usually I try to do this at the beginning.",
        "tokens": [
          50814,
          11419,
          286,
          853,
          281,
          360,
          341,
          412,
          264,
          2863,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6485.76,
        "id": 1587,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6481.76,
        "temperature": 0,
        "text": " It's a nice way to start off and say hello to the community and people watching the coding train.",
        "tokens": [
          50914,
          467,
          311,
          257,
          1481,
          636,
          281,
          722,
          766,
          293,
          584,
          7751,
          281,
          264,
          1768,
          293,
          561,
          1976,
          264,
          17720,
          3847,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6490.76,
        "id": 1588,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6485.76,
        "temperature": 0,
        "text": " But it's very important to me that every live stream I show some of the work.",
        "tokens": [
          51114,
          583,
          309,
          311,
          588,
          1021,
          281,
          385,
          300,
          633,
          1621,
          4309,
          286,
          855,
          512,
          295,
          264,
          589,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2436509038887772,
        "compression_ratio": 1.6484018264840183,
        "end": 6494.76,
        "id": 1589,
        "no_speech_prob": 0.6857278943061829,
        "seek": 647076,
        "start": 6490.76,
        "temperature": 0,
        "text": " Because you, the people of the coding train, are what power the train itself.",
        "tokens": [
          51364,
          1436,
          291,
          11,
          264,
          561,
          295,
          264,
          17720,
          3847,
          11,
          366,
          437,
          1347,
          264,
          3847,
          2564,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2407579849015421,
        "compression_ratio": 1.6323529411764706,
        "end": 6501.76,
        "id": 1590,
        "no_speech_prob": 0.30728718638420105,
        "seek": 649476,
        "start": 6495.76,
        "temperature": 0,
        "text": " You are the engine that produces the steam that drives the train.",
        "tokens": [
          50414,
          509,
          366,
          264,
          2848,
          300,
          14725,
          264,
          11952,
          300,
          11754,
          264,
          3847,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2407579849015421,
        "compression_ratio": 1.6323529411764706,
        "end": 6505.76,
        "id": 1591,
        "no_speech_prob": 0.30728718638420105,
        "seek": 649476,
        "start": 6501.76,
        "temperature": 0,
        "text": " So let's go on over to our Discord.",
        "tokens": [
          50714,
          407,
          718,
          311,
          352,
          322,
          670,
          281,
          527,
          32623,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2407579849015421,
        "compression_ratio": 1.6323529411764706,
        "end": 6509.76,
        "id": 1592,
        "no_speech_prob": 0.30728718638420105,
        "seek": 649476,
        "start": 6505.76,
        "temperature": 0,
        "text": " And I am going to type in the wheel command.",
        "tokens": [
          50914,
          400,
          286,
          669,
          516,
          281,
          2010,
          294,
          264,
          5589,
          5622,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2407579849015421,
        "compression_ratio": 1.6323529411764706,
        "end": 6512.76,
        "id": 1593,
        "no_speech_prob": 0.30728718638420105,
        "seek": 649476,
        "start": 6509.76,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51114,
          400,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2407579849015421,
        "compression_ratio": 1.6323529411764706,
        "end": 6514.76,
        "id": 1594,
        "no_speech_prob": 0.30728718638420105,
        "seek": 649476,
        "start": 6512.76,
        "temperature": 0,
        "text": " What happened?",
        "tokens": [
          51264,
          708,
          2011,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.2407579849015421,
        "compression_ratio": 1.6323529411764706,
        "end": 6517.76,
        "id": 1595,
        "no_speech_prob": 0.30728718638420105,
        "seek": 649476,
        "start": 6514.76,
        "temperature": 0,
        "text": " What happened to the wheel?",
        "tokens": [
          51364,
          708,
          2011,
          281,
          264,
          5589,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2407579849015421,
        "compression_ratio": 1.6323529411764706,
        "end": 6522.76,
        "id": 1596,
        "no_speech_prob": 0.30728718638420105,
        "seek": 649476,
        "start": 6517.76,
        "temperature": 0,
        "text": " What happened to the wheel?",
        "tokens": [
          51514,
          708,
          2011,
          281,
          264,
          5589,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6526.76,
        "id": 1597,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6522.76,
        "temperature": 0,
        "text": " The live stream chat bot is down.",
        "tokens": [
          50364,
          440,
          1621,
          4309,
          5081,
          10592,
          307,
          760,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6528.76,
        "id": 1598,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6526.76,
        "temperature": 0,
        "text": " We can find it.",
        "tokens": [
          50564,
          492,
          393,
          915,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6532.76,
        "id": 1599,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6528.76,
        "temperature": 0,
        "text": " It's right up here.",
        "tokens": [
          50664,
          467,
          311,
          558,
          493,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6536.76,
        "id": 1600,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6532.76,
        "temperature": 0,
        "text": " So here's the wheel of community contributions.",
        "tokens": [
          50864,
          407,
          510,
          311,
          264,
          5589,
          295,
          1768,
          15725,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6542.76,
        "id": 1601,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6536.76,
        "temperature": 0,
        "text": " Thank you to David and.",
        "tokens": [
          51064,
          1044,
          291,
          281,
          4389,
          293,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6544.76,
        "id": 1602,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6542.76,
        "temperature": 0,
        "text": " King over here on the.",
        "tokens": [
          51364,
          3819,
          670,
          510,
          322,
          264,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6547.76,
        "id": 1603,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6544.76,
        "temperature": 0,
        "text": " I forgot the user's name.",
        "tokens": [
          51464,
          286,
          5298,
          264,
          4195,
          311,
          1315,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6549.76,
        "id": 1604,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6547.76,
        "temperature": 0,
        "text": " Did some of these new features.",
        "tokens": [
          51614,
          2589,
          512,
          295,
          613,
          777,
          4122,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2434602975845337,
        "compression_ratio": 1.4186046511627908,
        "end": 6550.76,
        "id": 1605,
        "no_speech_prob": 0.13113975524902344,
        "seek": 652276,
        "start": 6549.76,
        "temperature": 0,
        "text": " Let's spin the wheel.",
        "tokens": [
          51714,
          961,
          311,
          6060,
          264,
          5589,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6554.76,
        "id": 1606,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6550.76,
        "temperature": 0,
        "text": " So this pulls from some of the contributions that are on the website.",
        "tokens": [
          50364,
          407,
          341,
          16982,
          490,
          512,
          295,
          264,
          15725,
          300,
          366,
          322,
          264,
          3144,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6556.76,
        "id": 1607,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6554.76,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50564,
          400,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6557.76,
        "id": 1608,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6556.76,
        "temperature": 0,
        "text": " Ultimate.",
        "tokens": [
          50664,
          26570,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6558.76,
        "id": 1609,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6557.76,
        "temperature": 0,
        "text": " Didn't we look at ultimate tic-tac-toe?",
        "tokens": [
          50714,
          11151,
          380,
          321,
          574,
          412,
          9705,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6560.76,
        "id": 1610,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6558.76,
        "temperature": 0,
        "text": " I kind of remember looking at this one already.",
        "tokens": [
          50764,
          286,
          733,
          295,
          1604,
          1237,
          412,
          341,
          472,
          1217,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6562.76,
        "id": 1611,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6560.76,
        "temperature": 0,
        "text": " Am I wrong about that?",
        "tokens": [
          50864,
          2012,
          286,
          2085,
          466,
          300,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6563.76,
        "id": 1612,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6562.76,
        "temperature": 0,
        "text": " I looked at.",
        "tokens": [
          50964,
          286,
          2956,
          412,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6564.76,
        "id": 1613,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6563.76,
        "temperature": 0,
        "text": " We looked at this one.",
        "tokens": [
          51014,
          492,
          2956,
          412,
          341,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6565.76,
        "id": 1614,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6564.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51064,
          865,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6567.76,
        "id": 1615,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6565.76,
        "temperature": 0,
        "text": " Well, did we?",
        "tokens": [
          51114,
          1042,
          11,
          630,
          321,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6568.76,
        "id": 1616,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6567.76,
        "temperature": 0,
        "text": " I really have.",
        "tokens": [
          51214,
          286,
          534,
          362,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6570.76,
        "id": 1617,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6568.76,
        "temperature": 0,
        "text": " I looked at somebody's ultimate tic-tac-toe.",
        "tokens": [
          51264,
          286,
          2956,
          412,
          2618,
          311,
          9705,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6573.76,
        "id": 1618,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6570.76,
        "temperature": 0,
        "text": " But this now looks unfamiliar to me.",
        "tokens": [
          51364,
          583,
          341,
          586,
          1542,
          29415,
          281,
          385,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6575.76,
        "id": 1619,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6573.76,
        "temperature": 0,
        "text": " Let's move this over, by the way.",
        "tokens": [
          51514,
          961,
          311,
          1286,
          341,
          670,
          11,
          538,
          264,
          636,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19476394130759042,
        "compression_ratio": 1.668,
        "end": 6577.76,
        "id": 1620,
        "no_speech_prob": 0.09533815830945969,
        "seek": 655076,
        "start": 6575.76,
        "temperature": 0,
        "text": " So I'm not in front of it so much.",
        "tokens": [
          51614,
          407,
          286,
          478,
          406,
          294,
          1868,
          295,
          309,
          370,
          709,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6581.76,
        "id": 1621,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6577.76,
        "temperature": 0,
        "text": " Also, I like to see my friendly masked son there.",
        "tokens": [
          50364,
          2743,
          11,
          286,
          411,
          281,
          536,
          452,
          9208,
          45249,
          1872,
          456,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6584.76,
        "id": 1622,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6581.76,
        "temperature": 0,
        "text": " Where were we here?",
        "tokens": [
          50564,
          2305,
          645,
          321,
          510,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6585.76,
        "id": 1623,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6584.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6587.76,
        "id": 1624,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6585.76,
        "temperature": 0,
        "text": " So take turns playing on the highlighted board.",
        "tokens": [
          50764,
          407,
          747,
          4523,
          2433,
          322,
          264,
          17173,
          3150,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6590.76,
        "id": 1625,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6587.76,
        "temperature": 0,
        "text": " However, your move determines where your opponent will place their next move.",
        "tokens": [
          50864,
          2908,
          11,
          428,
          1286,
          24799,
          689,
          428,
          10620,
          486,
          1081,
          641,
          958,
          1286,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6592.76,
        "id": 1626,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6590.76,
        "temperature": 0,
        "text": " The first player to conquer a board claims that board.",
        "tokens": [
          51014,
          440,
          700,
          4256,
          281,
          24136,
          257,
          3150,
          9441,
          300,
          3150,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6598.76,
        "id": 1627,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6592.76,
        "temperature": 0,
        "text": " Ultimate tic-tac-toe is playing mini games of tic-tac-toe inside a larger tic-tac-toe board.",
        "tokens": [
          51114,
          26570,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          307,
          2433,
          8382,
          2813,
          295,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          1854,
          257,
          4833,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          3150,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6601.76,
        "id": 1628,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6598.76,
        "temperature": 0,
        "text": " Oh, I see.",
        "tokens": [
          51414,
          876,
          11,
          286,
          536,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6604.76,
        "id": 1629,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6601.76,
        "temperature": 0,
        "text": " I don't really know what's going on here, but this is really cool.",
        "tokens": [
          51564,
          286,
          500,
          380,
          534,
          458,
          437,
          311,
          516,
          322,
          510,
          11,
          457,
          341,
          307,
          534,
          1627,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20361280098235865,
        "compression_ratio": 1.6532846715328466,
        "end": 6606.76,
        "id": 1630,
        "no_speech_prob": 0.17104406654834747,
        "seek": 657776,
        "start": 6604.76,
        "temperature": 0,
        "text": " Wait, why does it switch?",
        "tokens": [
          51714,
          3802,
          11,
          983,
          775,
          309,
          3679,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.20785601546124713,
        "compression_ratio": 1.5121951219512195,
        "end": 6608.76,
        "id": 1631,
        "no_speech_prob": 0.00010889685654547065,
        "seek": 660676,
        "start": 6606.76,
        "temperature": 0,
        "text": " So I'm playing both players.",
        "tokens": [
          50364,
          407,
          286,
          478,
          2433,
          1293,
          4150,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20785601546124713,
        "compression_ratio": 1.5121951219512195,
        "end": 6611.76,
        "id": 1632,
        "no_speech_prob": 0.00010889685654547065,
        "seek": 660676,
        "start": 6608.76,
        "temperature": 0,
        "text": " Oh, you do one board at a time.",
        "tokens": [
          50464,
          876,
          11,
          291,
          360,
          472,
          3150,
          412,
          257,
          565,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20785601546124713,
        "compression_ratio": 1.5121951219512195,
        "end": 6613.76,
        "id": 1633,
        "no_speech_prob": 0.00010889685654547065,
        "seek": 660676,
        "start": 6611.76,
        "temperature": 0,
        "text": " It just does a random one next.",
        "tokens": [
          50614,
          467,
          445,
          775,
          257,
          4974,
          472,
          958,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20785601546124713,
        "compression_ratio": 1.5121951219512195,
        "end": 6616.76,
        "id": 1634,
        "no_speech_prob": 0.00010889685654547065,
        "seek": 660676,
        "start": 6613.76,
        "temperature": 0,
        "text": " So you each get a turn in one cell.",
        "tokens": [
          50714,
          407,
          291,
          1184,
          483,
          257,
          1261,
          294,
          472,
          2815,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20785601546124713,
        "compression_ratio": 1.5121951219512195,
        "end": 6622.76,
        "id": 1635,
        "no_speech_prob": 0.00010889685654547065,
        "seek": 660676,
        "start": 6616.76,
        "temperature": 0,
        "text": " And then you get a turn in oh, it goes around randomly.",
        "tokens": [
          50864,
          400,
          550,
          291,
          483,
          257,
          1261,
          294,
          220,
          1445,
          11,
          309,
          1709,
          926,
          16979,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20785601546124713,
        "compression_ratio": 1.5121951219512195,
        "end": 6629.76,
        "id": 1636,
        "no_speech_prob": 0.00010889685654547065,
        "seek": 660676,
        "start": 6622.76,
        "temperature": 0,
        "text": " So, like, you really have an advantage if you get lucky.",
        "tokens": [
          51164,
          407,
          11,
          411,
          11,
          291,
          534,
          362,
          364,
          5002,
          498,
          291,
          483,
          6356,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20785601546124713,
        "compression_ratio": 1.5121951219512195,
        "end": 6631.76,
        "id": 1637,
        "no_speech_prob": 0.00010889685654547065,
        "seek": 660676,
        "start": 6629.76,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51514,
          1779,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6637.76,
        "id": 1638,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6631.76,
        "temperature": 0,
        "text": " Like, this is just luck now.",
        "tokens": [
          50364,
          1743,
          11,
          341,
          307,
          445,
          3668,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6640.76,
        "id": 1639,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6637.76,
        "temperature": 0,
        "text": " Who's gonna win? I'm playing against myself.",
        "tokens": [
          50664,
          2102,
          311,
          799,
          1942,
          30,
          286,
          478,
          2433,
          1970,
          2059,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6643.76,
        "id": 1640,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6640.76,
        "temperature": 0,
        "text": " I'm rooting for O, I think.",
        "tokens": [
          50814,
          286,
          478,
          41572,
          337,
          422,
          11,
          286,
          519,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6648.76,
        "id": 1641,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6643.76,
        "temperature": 0,
        "text": " O is just more friendly looking than X.",
        "tokens": [
          50964,
          422,
          307,
          445,
          544,
          9208,
          1237,
          813,
          1783,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6650.76,
        "id": 1642,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6648.76,
        "temperature": 0,
        "text": " Come on, O, you can do it.",
        "tokens": [
          51214,
          2492,
          322,
          11,
          422,
          11,
          291,
          393,
          360,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6652.76,
        "id": 1643,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6650.76,
        "temperature": 0,
        "text": " Place your bets, people, place your bets.",
        "tokens": [
          51314,
          13637,
          428,
          39922,
          11,
          561,
          11,
          1081,
          428,
          39922,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6654.76,
        "id": 1644,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6652.76,
        "temperature": 0,
        "text": " Wait.",
        "tokens": [
          51414,
          3802,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6656.76,
        "id": 1645,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6654.76,
        "temperature": 0,
        "text": " Oh, X gets to go again?",
        "tokens": [
          51514,
          876,
          11,
          1783,
          2170,
          281,
          352,
          797,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.21367758892952127,
        "compression_ratio": 1.4114583333333333,
        "end": 6659.76,
        "id": 1646,
        "no_speech_prob": 0.010327907279133797,
        "seek": 663176,
        "start": 6656.76,
        "temperature": 0,
        "text": " Shouldn't this square be done?",
        "tokens": [
          51614,
          34170,
          380,
          341,
          3732,
          312,
          1096,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6663.76,
        "id": 1647,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6659.76,
        "temperature": 0,
        "text": " O's gotta go here.",
        "tokens": [
          50364,
          422,
          311,
          3428,
          352,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6666.76,
        "id": 1648,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6663.76,
        "temperature": 0,
        "text": " O's gonna go here.",
        "tokens": [
          50564,
          422,
          311,
          799,
          352,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6669.76,
        "id": 1649,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6666.76,
        "temperature": 0,
        "text": " All right, O, looking good, O.",
        "tokens": [
          50714,
          1057,
          558,
          11,
          422,
          11,
          1237,
          665,
          11,
          422,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6671.76,
        "id": 1650,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6669.76,
        "temperature": 0,
        "text": " Uh-oh.",
        "tokens": [
          50864,
          4019,
          12,
          1445,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6674.76,
        "id": 1651,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6671.76,
        "temperature": 0,
        "text": " Yeah, this one's already done.",
        "tokens": [
          50964,
          865,
          11,
          341,
          472,
          311,
          1217,
          1096,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6675.76,
        "id": 1652,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6674.76,
        "temperature": 0,
        "text": " Where am I now?",
        "tokens": [
          51114,
          2305,
          669,
          286,
          586,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6680.76,
        "id": 1653,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6675.76,
        "temperature": 0,
        "text": " Oh, X.",
        "tokens": [
          51164,
          876,
          11,
          1783,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6683.76,
        "id": 1654,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6680.76,
        "temperature": 0,
        "text": " X is gonna block O.",
        "tokens": [
          51414,
          1783,
          307,
          799,
          3461,
          422,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17606945526905549,
        "compression_ratio": 1.3458646616541354,
        "end": 6686.76,
        "id": 1655,
        "no_speech_prob": 0.0007437022286467254,
        "seek": 665976,
        "start": 6683.76,
        "temperature": 0,
        "text": " Where are we now, here? Here?",
        "tokens": [
          51564,
          2305,
          366,
          321,
          586,
          11,
          510,
          30,
          1692,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6689.76,
        "id": 1656,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6686.76,
        "temperature": 0,
        "text": " X? I must finish this.",
        "tokens": [
          50364,
          1783,
          30,
          286,
          1633,
          2413,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6693.76,
        "id": 1657,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6689.76,
        "temperature": 0,
        "text": " Must finish.",
        "tokens": [
          50514,
          13252,
          2413,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6697.76,
        "id": 1658,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6693.76,
        "temperature": 0,
        "text": " Yeah, ha-ha.",
        "tokens": [
          50714,
          865,
          11,
          324,
          12,
          1641,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6701.76,
        "id": 1659,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6697.76,
        "temperature": 0,
        "text": " It's not random, I'm being told.",
        "tokens": [
          50914,
          467,
          311,
          406,
          4974,
          11,
          286,
          478,
          885,
          1907,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6703.76,
        "id": 1660,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6701.76,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51114,
          14711,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6705.76,
        "id": 1661,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6703.76,
        "temperature": 0,
        "text": " But O has a good spot.",
        "tokens": [
          51214,
          583,
          422,
          575,
          257,
          665,
          4008,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6707.76,
        "id": 1662,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6705.76,
        "temperature": 0,
        "text": " Where am I now, here?",
        "tokens": [
          51314,
          2305,
          669,
          286,
          586,
          11,
          510,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6709.76,
        "id": 1663,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6707.76,
        "temperature": 0,
        "text": " X is gonna go there.",
        "tokens": [
          51414,
          1783,
          307,
          799,
          352,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6711.76,
        "id": 1664,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6709.76,
        "temperature": 0,
        "text": " O.",
        "tokens": [
          51514,
          422,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21597859917617426,
        "compression_ratio": 1.3445945945945945,
        "end": 6713.76,
        "id": 1665,
        "no_speech_prob": 0.00043055679998360574,
        "seek": 668676,
        "start": 6711.76,
        "temperature": 0,
        "text": " Can I get three in a row like that?",
        "tokens": [
          51614,
          1664,
          286,
          483,
          1045,
          294,
          257,
          5386,
          411,
          300,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.18801767175847833,
        "compression_ratio": 1.135135135135135,
        "end": 6715.76,
        "id": 1666,
        "no_speech_prob": 0.1208474263548851,
        "seek": 671376,
        "start": 6713.76,
        "temperature": 0,
        "text": " Probably not, right?",
        "tokens": [
          50364,
          9210,
          406,
          11,
          558,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.18801767175847833,
        "compression_ratio": 1.135135135135135,
        "end": 6718.76,
        "id": 1667,
        "no_speech_prob": 0.1208474263548851,
        "seek": 671376,
        "start": 6715.76,
        "temperature": 0,
        "text": " O.",
        "tokens": [
          50464,
          422,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18801767175847833,
        "compression_ratio": 1.135135135135135,
        "end": 6723.76,
        "id": 1668,
        "no_speech_prob": 0.1208474263548851,
        "seek": 671376,
        "start": 6718.76,
        "temperature": 0,
        "text": " Where am I now, here? X.",
        "tokens": [
          50614,
          2305,
          669,
          286,
          586,
          11,
          510,
          30,
          1783,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18801767175847833,
        "compression_ratio": 1.135135135135135,
        "end": 6726.76,
        "id": 1669,
        "no_speech_prob": 0.1208474263548851,
        "seek": 671376,
        "start": 6723.76,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          50864,
          876,
          11,
          1338,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18801767175847833,
        "compression_ratio": 1.135135135135135,
        "end": 6734.76,
        "id": 1670,
        "no_speech_prob": 0.1208474263548851,
        "seek": 671376,
        "start": 6726.76,
        "temperature": 0,
        "text": " Come on, O, you can do it.",
        "tokens": [
          51014,
          2492,
          322,
          11,
          422,
          11,
          291,
          393,
          360,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18801767175847833,
        "compression_ratio": 1.135135135135135,
        "end": 6741.76,
        "id": 1671,
        "no_speech_prob": 0.1208474263548851,
        "seek": 671376,
        "start": 6734.76,
        "temperature": 0,
        "text": " So don't tell me the logic of which one.",
        "tokens": [
          51414,
          407,
          500,
          380,
          980,
          385,
          264,
          9952,
          295,
          597,
          472,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22069557189941405,
        "compression_ratio": 1.2053571428571428,
        "end": 6746.76,
        "id": 1672,
        "no_speech_prob": 0.04885601997375488,
        "seek": 674176,
        "start": 6741.76,
        "temperature": 0,
        "text": " Oh, a move, yeah.",
        "tokens": [
          50364,
          876,
          11,
          257,
          1286,
          11,
          1338,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22069557189941405,
        "compression_ratio": 1.2053571428571428,
        "end": 6758.76,
        "id": 1673,
        "no_speech_prob": 0.04885601997375488,
        "seek": 674176,
        "start": 6746.76,
        "temperature": 0,
        "text": " Someone tell me the logic of which one it picks, I'm curious.",
        "tokens": [
          50614,
          8734,
          980,
          385,
          264,
          9952,
          295,
          597,
          472,
          309,
          16137,
          11,
          286,
          478,
          6369,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22069557189941405,
        "compression_ratio": 1.2053571428571428,
        "end": 6760.76,
        "id": 1674,
        "no_speech_prob": 0.04885601997375488,
        "seek": 674176,
        "start": 6758.76,
        "temperature": 0,
        "text": " Where are we?",
        "tokens": [
          51214,
          2305,
          366,
          321,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.22069557189941405,
        "compression_ratio": 1.2053571428571428,
        "end": 6765.76,
        "id": 1675,
        "no_speech_prob": 0.04885601997375488,
        "seek": 674176,
        "start": 6760.76,
        "temperature": 0,
        "text": " Where are we?",
        "tokens": [
          51314,
          2305,
          366,
          321,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.22069557189941405,
        "compression_ratio": 1.2053571428571428,
        "end": 6767.76,
        "id": 1676,
        "no_speech_prob": 0.04885601997375488,
        "seek": 674176,
        "start": 6765.76,
        "temperature": 0,
        "text": " Oh, X is doing really well.",
        "tokens": [
          51564,
          876,
          11,
          1783,
          307,
          884,
          534,
          731,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1628354549407959,
        "compression_ratio": 1.3716814159292035,
        "end": 6777.76,
        "id": 1677,
        "no_speech_prob": 0.013428166508674622,
        "seek": 676776,
        "start": 6767.76,
        "temperature": 0,
        "text": " Whoever wins this down here.",
        "tokens": [
          50364,
          24743,
          10641,
          341,
          760,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1628354549407959,
        "compression_ratio": 1.3716814159292035,
        "end": 6780.76,
        "id": 1678,
        "no_speech_prob": 0.013428166508674622,
        "seek": 676776,
        "start": 6777.76,
        "temperature": 0,
        "text": " Oh, didn't O just win?",
        "tokens": [
          50864,
          876,
          11,
          994,
          380,
          422,
          445,
          1942,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1628354549407959,
        "compression_ratio": 1.3716814159292035,
        "end": 6782.76,
        "id": 1679,
        "no_speech_prob": 0.013428166508674622,
        "seek": 676776,
        "start": 6780.76,
        "temperature": 0,
        "text": " Didn't O just win?",
        "tokens": [
          51014,
          11151,
          380,
          422,
          445,
          1942,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.1628354549407959,
        "compression_ratio": 1.3716814159292035,
        "end": 6784.76,
        "id": 1680,
        "no_speech_prob": 0.013428166508674622,
        "seek": 676776,
        "start": 6782.76,
        "temperature": 0,
        "text": " Oh, no, X had already won that one.",
        "tokens": [
          51114,
          876,
          11,
          572,
          11,
          1783,
          632,
          1217,
          1582,
          300,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1628354549407959,
        "compression_ratio": 1.3716814159292035,
        "end": 6788.76,
        "id": 1681,
        "no_speech_prob": 0.013428166508674622,
        "seek": 676776,
        "start": 6784.76,
        "temperature": 0,
        "text": " I'm very confused.",
        "tokens": [
          51214,
          286,
          478,
          588,
          9019,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1628354549407959,
        "compression_ratio": 1.3716814159292035,
        "end": 6794.76,
        "id": 1682,
        "no_speech_prob": 0.013428166508674622,
        "seek": 676776,
        "start": 6788.76,
        "temperature": 0,
        "text": " Okay, wait, wait, wait, wait.",
        "tokens": [
          51414,
          1033,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22633691736169764,
        "compression_ratio": 0.9615384615384616,
        "end": 6800.76,
        "id": 1683,
        "no_speech_prob": 0.022628935053944588,
        "seek": 679476,
        "start": 6794.76,
        "temperature": 0,
        "text": " And now...",
        "tokens": [
          50364,
          400,
          586,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.22633691736169764,
        "compression_ratio": 0.9615384615384616,
        "end": 6803.76,
        "id": 1684,
        "no_speech_prob": 0.022628935053944588,
        "seek": 679476,
        "start": 6800.76,
        "temperature": 0,
        "text": " I'm lost, people.",
        "tokens": [
          50664,
          286,
          478,
          2731,
          11,
          561,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22633691736169764,
        "compression_ratio": 0.9615384615384616,
        "end": 6812.76,
        "id": 1685,
        "no_speech_prob": 0.022628935053944588,
        "seek": 679476,
        "start": 6803.76,
        "temperature": 0,
        "text": " O.",
        "tokens": [
          50814,
          422,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22633691736169764,
        "compression_ratio": 0.9615384615384616,
        "end": 6818.76,
        "id": 1686,
        "no_speech_prob": 0.022628935053944588,
        "seek": 679476,
        "start": 6812.76,
        "temperature": 0,
        "text": " Is it over?",
        "tokens": [
          51264,
          1119,
          309,
          670,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.22633691736169764,
        "compression_ratio": 0.9615384615384616,
        "end": 6819.76,
        "id": 1687,
        "no_speech_prob": 0.022628935053944588,
        "seek": 679476,
        "start": 6818.76,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          51564,
          286,
          478,
          370,
          9019,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22633691736169764,
        "compression_ratio": 0.9615384615384616,
        "end": 6822.76,
        "id": 1688,
        "no_speech_prob": 0.022628935053944588,
        "seek": 679476,
        "start": 6819.76,
        "temperature": 0,
        "text": " What happened?",
        "tokens": [
          51614,
          708,
          2011,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.21546680048892372,
        "compression_ratio": 1.3641975308641976,
        "end": 6824.76,
        "id": 1689,
        "no_speech_prob": 0.09400451928377151,
        "seek": 682276,
        "start": 6822.76,
        "temperature": 0,
        "text": " Oh, there's no...",
        "tokens": [
          50364,
          876,
          11,
          456,
          311,
          572,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.21546680048892372,
        "compression_ratio": 1.3641975308641976,
        "end": 6826.76,
        "id": 1690,
        "no_speech_prob": 0.09400451928377151,
        "seek": 682276,
        "start": 6824.76,
        "temperature": 0,
        "text": " O can go maybe wherever it wants?",
        "tokens": [
          50464,
          422,
          393,
          352,
          1310,
          8660,
          309,
          2738,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.21546680048892372,
        "compression_ratio": 1.3641975308641976,
        "end": 6827.76,
        "id": 1691,
        "no_speech_prob": 0.09400451928377151,
        "seek": 682276,
        "start": 6826.76,
        "temperature": 0,
        "text": " Yeah, okay.",
        "tokens": [
          50564,
          865,
          11,
          1392,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21546680048892372,
        "compression_ratio": 1.3641975308641976,
        "end": 6831.76,
        "id": 1692,
        "no_speech_prob": 0.09400451928377151,
        "seek": 682276,
        "start": 6827.76,
        "temperature": 0,
        "text": " Now it's over, right?",
        "tokens": [
          50614,
          823,
          309,
          311,
          670,
          11,
          558,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.21546680048892372,
        "compression_ratio": 1.3641975308641976,
        "end": 6841.76,
        "id": 1693,
        "no_speech_prob": 0.09400451928377151,
        "seek": 682276,
        "start": 6831.76,
        "temperature": 0,
        "text": " Yeah, O won!",
        "tokens": [
          50814,
          865,
          11,
          422,
          1582,
          0,
          51314
        ]
      },
      {
        "avg_logprob": -0.21546680048892372,
        "compression_ratio": 1.3641975308641976,
        "end": 6842.76,
        "id": 1694,
        "no_speech_prob": 0.09400451928377151,
        "seek": 682276,
        "start": 6841.76,
        "temperature": 0,
        "text": " Thank you, this is pretty cool.",
        "tokens": [
          51314,
          1044,
          291,
          11,
          341,
          307,
          1238,
          1627,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21546680048892372,
        "compression_ratio": 1.3641975308641976,
        "end": 6847.76,
        "id": 1695,
        "no_speech_prob": 0.09400451928377151,
        "seek": 682276,
        "start": 6842.76,
        "temperature": 0,
        "text": " I think, like, I'm like two hours into a live stream and my brain is like not functioning.",
        "tokens": [
          51364,
          286,
          519,
          11,
          411,
          11,
          286,
          478,
          411,
          732,
          2496,
          666,
          257,
          1621,
          4309,
          293,
          452,
          3567,
          307,
          411,
          406,
          18483,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22857521991340482,
        "compression_ratio": 1.5198237885462555,
        "end": 6854.76,
        "id": 1696,
        "no_speech_prob": 0.5466483235359192,
        "seek": 684776,
        "start": 6848.76,
        "temperature": 0,
        "text": " Okay, the square you select in the mini board determines which mini board the next player will play in.",
        "tokens": [
          50414,
          1033,
          11,
          264,
          3732,
          291,
          3048,
          294,
          264,
          8382,
          3150,
          24799,
          597,
          8382,
          3150,
          264,
          958,
          4256,
          486,
          862,
          294,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22857521991340482,
        "compression_ratio": 1.5198237885462555,
        "end": 6859.76,
        "id": 1697,
        "no_speech_prob": 0.5466483235359192,
        "seek": 684776,
        "start": 6854.76,
        "temperature": 0,
        "text": " Oh, can you start a new game and let the chat play?",
        "tokens": [
          50714,
          876,
          11,
          393,
          291,
          722,
          257,
          777,
          1216,
          293,
          718,
          264,
          5081,
          862,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.22857521991340482,
        "compression_ratio": 1.5198237885462555,
        "end": 6864.76,
        "id": 1698,
        "no_speech_prob": 0.5466483235359192,
        "seek": 684776,
        "start": 6859.76,
        "temperature": 0,
        "text": " It'll be havoc to read, but it'll be fun for us, says Adrian.",
        "tokens": [
          50964,
          467,
          603,
          312,
          47367,
          281,
          1401,
          11,
          457,
          309,
          603,
          312,
          1019,
          337,
          505,
          11,
          1619,
          31746,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22857521991340482,
        "compression_ratio": 1.5198237885462555,
        "end": 6866.76,
        "id": 1699,
        "no_speech_prob": 0.5466483235359192,
        "seek": 684776,
        "start": 6864.76,
        "temperature": 0,
        "text": " This is an excellent suggestion.",
        "tokens": [
          51214,
          639,
          307,
          364,
          7103,
          16541,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22857521991340482,
        "compression_ratio": 1.5198237885462555,
        "end": 6873.76,
        "id": 1700,
        "no_speech_prob": 0.5466483235359192,
        "seek": 684776,
        "start": 6866.76,
        "temperature": 0,
        "text": " However, I don't have a mechanism for doing that.",
        "tokens": [
          51314,
          2908,
          11,
          286,
          500,
          380,
          362,
          257,
          7513,
          337,
          884,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22857521991340482,
        "compression_ratio": 1.5198237885462555,
        "end": 6874.76,
        "id": 1701,
        "no_speech_prob": 0.5466483235359192,
        "seek": 684776,
        "start": 6873.76,
        "temperature": 0,
        "text": " So I think I've...",
        "tokens": [
          51664,
          407,
          286,
          519,
          286,
          600,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.22857521991340482,
        "compression_ratio": 1.5198237885462555,
        "end": 6876.76,
        "id": 1702,
        "no_speech_prob": 0.5466483235359192,
        "seek": 684776,
        "start": 6874.76,
        "temperature": 0,
        "text": " This is really wonderful.",
        "tokens": [
          51714,
          639,
          307,
          534,
          3715,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18514149459366946,
        "compression_ratio": 1.5932203389830508,
        "end": 6888.76,
        "id": 1703,
        "no_speech_prob": 0.37744081020355225,
        "seek": 687676,
        "start": 6876.76,
        "temperature": 0,
        "text": " Apologies to the creator of this for me being the brain dead person that I am, Amrit Amar, that I did not understand the logic here.",
        "tokens": [
          50364,
          8723,
          6204,
          281,
          264,
          14181,
          295,
          341,
          337,
          385,
          885,
          264,
          3567,
          3116,
          954,
          300,
          286,
          669,
          11,
          2012,
          3210,
          2012,
          289,
          11,
          300,
          286,
          630,
          406,
          1223,
          264,
          9952,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18514149459366946,
        "compression_ratio": 1.5932203389830508,
        "end": 6891.76,
        "id": 1704,
        "no_speech_prob": 0.37744081020355225,
        "seek": 687676,
        "start": 6888.76,
        "temperature": 0,
        "text": " Also, I'm playing against myself, so who knows what I would have done with that logic.",
        "tokens": [
          50964,
          2743,
          11,
          286,
          478,
          2433,
          1970,
          2059,
          11,
          370,
          567,
          3255,
          437,
          286,
          576,
          362,
          1096,
          365,
          300,
          9952,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18514149459366946,
        "compression_ratio": 1.5932203389830508,
        "end": 6899.76,
        "id": 1705,
        "no_speech_prob": 0.37744081020355225,
        "seek": 687676,
        "start": 6891.76,
        "temperature": 0,
        "text": " But now it makes sense to me that there is sort of like a meta strategy inside the regular tic-tac-toe strategy, which is really interesting to think about.",
        "tokens": [
          51114,
          583,
          586,
          309,
          1669,
          2020,
          281,
          385,
          300,
          456,
          307,
          1333,
          295,
          411,
          257,
          19616,
          5206,
          1854,
          264,
          3890,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          5206,
          11,
          597,
          307,
          534,
          1880,
          281,
          519,
          466,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22002956654765818,
        "compression_ratio": 1.743083003952569,
        "end": 6900.76,
        "id": 1706,
        "no_speech_prob": 0.18236981332302094,
        "seek": 689976,
        "start": 6899.76,
        "temperature": 0,
        "text": " I would love for it to...",
        "tokens": [
          50364,
          286,
          576,
          959,
          337,
          309,
          281,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.22002956654765818,
        "compression_ratio": 1.743083003952569,
        "end": 6910.76,
        "id": 1707,
        "no_speech_prob": 0.18236981332302094,
        "seek": 689976,
        "start": 6900.76,
        "temperature": 0,
        "text": " I think some of the color choices could be more evident and you might be able to use like a fill even also to like highlight the active square.",
        "tokens": [
          50414,
          286,
          519,
          512,
          295,
          264,
          2017,
          7994,
          727,
          312,
          544,
          16371,
          293,
          291,
          1062,
          312,
          1075,
          281,
          764,
          411,
          257,
          2836,
          754,
          611,
          281,
          411,
          5078,
          264,
          4967,
          3732,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22002956654765818,
        "compression_ratio": 1.743083003952569,
        "end": 6917.76,
        "id": 1708,
        "no_speech_prob": 0.18236981332302094,
        "seek": 689976,
        "start": 6910.76,
        "temperature": 0,
        "text": " I'm often confused, like, you know, something to like separate the individual three by three tiles might be helpful.",
        "tokens": [
          50914,
          286,
          478,
          2049,
          9019,
          11,
          411,
          11,
          291,
          458,
          11,
          746,
          281,
          411,
          4994,
          264,
          2609,
          1045,
          538,
          1045,
          21982,
          1062,
          312,
          4961,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22002956654765818,
        "compression_ratio": 1.743083003952569,
        "end": 6926.76,
        "id": 1709,
        "no_speech_prob": 0.18236981332302094,
        "seek": 689976,
        "start": 6917.76,
        "temperature": 0,
        "text": " So I think there are some visual augmentations you could make here to make the sort of like the distinctive areas and the sort of interactions more clear.",
        "tokens": [
          51264,
          407,
          286,
          519,
          456,
          366,
          512,
          5056,
          29919,
          763,
          291,
          727,
          652,
          510,
          281,
          652,
          264,
          1333,
          295,
          411,
          264,
          27766,
          3179,
          293,
          264,
          1333,
          295,
          13280,
          544,
          1850,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6930.76,
        "id": 1710,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6927.76,
        "temperature": 0,
        "text": " But this is a fantastic project.",
        "tokens": [
          50414,
          583,
          341,
          307,
          257,
          5456,
          1716,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6932.76,
        "id": 1711,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6930.76,
        "temperature": 0,
        "text": " Ding the bell.",
        "tokens": [
          50564,
          20558,
          264,
          4549,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6935.76,
        "id": 1712,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6932.76,
        "temperature": 0,
        "text": " Ring the train whistle.",
        "tokens": [
          50664,
          19844,
          264,
          3847,
          23470,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6937.76,
        "id": 1713,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6935.76,
        "temperature": 0,
        "text": " And let's move on to...",
        "tokens": [
          50814,
          400,
          718,
          311,
          1286,
          322,
          281,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6941.76,
        "id": 1714,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6940.76,
        "temperature": 0,
        "text": " Look at one more.",
        "tokens": [
          51064,
          2053,
          412,
          472,
          544,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6945.76,
        "id": 1715,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6943.76,
        "temperature": 0,
        "text": " Spin that wheel.",
        "tokens": [
          51214,
          29185,
          300,
          5589,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6952.76,
        "id": 1716,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6950.76,
        "temperature": 0,
        "text": " Wow, there's a lot of tic-tac-toe ones coming up today.",
        "tokens": [
          51564,
          3153,
          11,
          456,
          311,
          257,
          688,
          295,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          2306,
          1348,
          493,
          965,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19517545346860532,
        "compression_ratio": 1.3660130718954249,
        "end": 6954.76,
        "id": 1717,
        "no_speech_prob": 0.13843800127506256,
        "seek": 692676,
        "start": 6952.76,
        "temperature": 0,
        "text": " Resizable tic-tac-toe.",
        "tokens": [
          51664,
          5015,
          22395,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6956.76,
        "id": 1718,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6955.76,
        "temperature": 0,
        "text": " Let's look at this one.",
        "tokens": [
          50414,
          961,
          311,
          574,
          412,
          341,
          472,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6961.76,
        "id": 1719,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6958.76,
        "temperature": 0,
        "text": " Resizable tic-tac-toe PVSP.",
        "tokens": [
          50564,
          5015,
          22395,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          23035,
          27921,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6962.76,
        "id": 1720,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6961.76,
        "temperature": 0,
        "text": " Click.",
        "tokens": [
          50714,
          8230,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6964.76,
        "id": 1721,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6963.76,
        "temperature": 0,
        "text": " Oh, this one I did look at.",
        "tokens": [
          50814,
          876,
          11,
          341,
          472,
          286,
          630,
          574,
          412,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6966.76,
        "id": 1722,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6965.76,
        "temperature": 0,
        "text": " I definitely remember this one.",
        "tokens": [
          50914,
          286,
          2138,
          1604,
          341,
          472,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6968.76,
        "id": 1723,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6967.76,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51014,
          1779,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6969.76,
        "id": 1724,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6968.76,
        "temperature": 0,
        "text": " This one we've looked at before.",
        "tokens": [
          51064,
          639,
          472,
          321,
          600,
          2956,
          412,
          949,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6972.76,
        "id": 1725,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6969.76,
        "temperature": 0,
        "text": " So one of the things we need to do, one of the things I would like to do...",
        "tokens": [
          51114,
          407,
          472,
          295,
          264,
          721,
          321,
          643,
          281,
          360,
          11,
          472,
          295,
          264,
          721,
          286,
          576,
          411,
          281,
          360,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6974.76,
        "id": 1726,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6972.76,
        "temperature": 0,
        "text": " Hi, Code Guppy again.",
        "tokens": [
          51264,
          2421,
          11,
          15549,
          2694,
          7966,
          797,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6975.76,
        "id": 1727,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6974.76,
        "temperature": 0,
        "text": " Welcome.",
        "tokens": [
          51364,
          4027,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6976.76,
        "id": 1728,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6975.76,
        "temperature": 0,
        "text": " Thank you, Code Guppy.",
        "tokens": [
          51414,
          1044,
          291,
          11,
          15549,
          2694,
          7966,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19901199998526736,
        "compression_ratio": 1.5742574257425743,
        "end": 6979.76,
        "id": 1729,
        "no_speech_prob": 0.0015247705159708858,
        "seek": 695476,
        "start": 6978.76,
        "temperature": 0,
        "text": " A member of the coding train.",
        "tokens": [
          51564,
          316,
          4006,
          295,
          264,
          17720,
          3847,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 6981.76,
        "id": 1730,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6980.76,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50414,
          407,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 6984.76,
        "id": 1731,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6983.76,
        "temperature": 0,
        "text": " Thank you, Code Guppy.",
        "tokens": [
          50564,
          1044,
          291,
          11,
          15549,
          2694,
          7966,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 6985.76,
        "id": 1732,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6984.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50614,
          1057,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 6986.76,
        "id": 1733,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6985.76,
        "temperature": 0,
        "text": " Now...",
        "tokens": [
          50664,
          823,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 6990.76,
        "id": 1734,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6989.76,
        "temperature": 0,
        "text": " We looked at this.",
        "tokens": [
          50864,
          492,
          2956,
          412,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 6998.76,
        "id": 1735,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6990.76,
        "temperature": 0,
        "text": " So one of the things I really would like to do is make some improvements and advancements in this sort of community contribution sharing system.",
        "tokens": [
          50914,
          407,
          472,
          295,
          264,
          721,
          286,
          534,
          576,
          411,
          281,
          360,
          307,
          652,
          512,
          13797,
          293,
          7295,
          1117,
          294,
          341,
          1333,
          295,
          1768,
          13150,
          5414,
          1185,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 6999.76,
        "id": 1736,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6998.76,
        "temperature": 0,
        "text": " The wheel is great.",
        "tokens": [
          51314,
          440,
          5589,
          307,
          869,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 7002.76,
        "id": 1737,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 6999.76,
        "temperature": 0,
        "text": " I think there's probably some nice design upgrades we could do with it.",
        "tokens": [
          51364,
          286,
          519,
          456,
          311,
          1391,
          512,
          1481,
          1715,
          24868,
          321,
          727,
          360,
          365,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2015706759232741,
        "compression_ratio": 1.50199203187251,
        "end": 7006.76,
        "id": 1738,
        "no_speech_prob": 0.002251796191558242,
        "seek": 697976,
        "start": 7002.76,
        "temperature": 0,
        "text": " Having a sort of a database or an API that keeps track of what I've shown.",
        "tokens": [
          51514,
          10222,
          257,
          1333,
          295,
          257,
          8149,
          420,
          364,
          9362,
          300,
          5965,
          2837,
          295,
          437,
          286,
          600,
          4898,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7011.76,
        "id": 1739,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7006.76,
        "temperature": 0,
        "text": " Or kind of like tries to highlight people who haven't had their things shown.",
        "tokens": [
          50364,
          1610,
          733,
          295,
          411,
          9898,
          281,
          5078,
          561,
          567,
          2378,
          380,
          632,
          641,
          721,
          4898,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7012.76,
        "id": 1740,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7011.76,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50614,
          286,
          500,
          380,
          458,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7013.76,
        "id": 1741,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7012.76,
        "temperature": 0,
        "text": " There's a lot more that could be done with it.",
        "tokens": [
          50664,
          821,
          311,
          257,
          688,
          544,
          300,
          727,
          312,
          1096,
          365,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7014.76,
        "id": 1742,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7013.76,
        "temperature": 0,
        "text": " So apologies.",
        "tokens": [
          50714,
          407,
          34929,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7015.76,
        "id": 1743,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7014.76,
        "temperature": 0,
        "text": " Apologies for skipping that one.",
        "tokens": [
          50764,
          8723,
          6204,
          337,
          31533,
          300,
          472,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7018.76,
        "id": 1744,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7015.76,
        "temperature": 0,
        "text": " But I'm really sure that I looked at that one before in a previous.",
        "tokens": [
          50814,
          583,
          286,
          478,
          534,
          988,
          300,
          286,
          2956,
          412,
          300,
          472,
          949,
          294,
          257,
          3894,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7020.76,
        "id": 1745,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7018.76,
        "temperature": 0,
        "text": " So let's spin the wheel and look at one more.",
        "tokens": [
          50964,
          407,
          718,
          311,
          6060,
          264,
          5589,
          293,
          574,
          412,
          472,
          544,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7026.76,
        "id": 1746,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7025.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51314,
          865,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7031.76,
        "id": 1747,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7026.76,
        "temperature": 0,
        "text": " This one we also did look at because I remember that ray casting was spelled wrong.",
        "tokens": [
          51364,
          639,
          472,
          321,
          611,
          630,
          574,
          412,
          570,
          286,
          1604,
          300,
          18592,
          17301,
          390,
          34388,
          2085,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22912946798033634,
        "compression_ratio": 1.619607843137255,
        "end": 7033.76,
        "id": 1748,
        "no_speech_prob": 0.05581756681203842,
        "seek": 700676,
        "start": 7031.76,
        "temperature": 0,
        "text": " Ray casing with pygame.",
        "tokens": [
          51614,
          10883,
          45109,
          365,
          10664,
          15038,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7036.76,
        "id": 1749,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7034.76,
        "temperature": 0,
        "text": " So I'm just going to double check and confirm.",
        "tokens": [
          50414,
          407,
          286,
          478,
          445,
          516,
          281,
          3834,
          1520,
          293,
          9064,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7037.76,
        "id": 1750,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7036.76,
        "temperature": 0,
        "text": " But I have a very...",
        "tokens": [
          50514,
          583,
          286,
          362,
          257,
          588,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7038.76,
        "id": 1751,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7037.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50564,
          865,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7041.76,
        "id": 1752,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7038.76,
        "temperature": 0,
        "text": " I have a very specific memory that this one came up already.",
        "tokens": [
          50614,
          286,
          362,
          257,
          588,
          2685,
          4675,
          300,
          341,
          472,
          1361,
          493,
          1217,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7045.76,
        "id": 1753,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7041.76,
        "temperature": 0,
        "text": " Let's refresh the wheel entirely to get ten new selections.",
        "tokens": [
          50764,
          961,
          311,
          15134,
          264,
          5589,
          7696,
          281,
          483,
          2064,
          777,
          47829,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7047.76,
        "id": 1754,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7045.76,
        "temperature": 0,
        "text": " And spin that wheel.",
        "tokens": [
          50964,
          400,
          6060,
          300,
          5589,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7050.76,
        "id": 1755,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7047.76,
        "temperature": 0,
        "text": " I think we need some music to bring us better luck.",
        "tokens": [
          51064,
          286,
          519,
          321,
          643,
          512,
          1318,
          281,
          1565,
          505,
          1101,
          3668,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7056.76,
        "id": 1756,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7054.76,
        "temperature": 0,
        "text": " And guess what, everybody?",
        "tokens": [
          51414,
          400,
          2041,
          437,
          11,
          2201,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.24576768688127107,
        "compression_ratio": 1.4936170212765958,
        "end": 7060.76,
        "id": 1757,
        "no_speech_prob": 0.046715423464775085,
        "seek": 703376,
        "start": 7056.76,
        "temperature": 0,
        "text": " The coding train is brought to you today by Tic Tac Toe.",
        "tokens": [
          51514,
          440,
          17720,
          3847,
          307,
          3038,
          281,
          291,
          965,
          538,
          314,
          299,
          38848,
          1407,
          68,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7061.76,
        "id": 1758,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7060.76,
        "temperature": 0,
        "text": " It's a simple game.",
        "tokens": [
          50364,
          467,
          311,
          257,
          2199,
          1216,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7064.76,
        "id": 1759,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7061.76,
        "temperature": 0,
        "text": " Fun to play for all the family.",
        "tokens": [
          50414,
          11166,
          281,
          862,
          337,
          439,
          264,
          1605,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7067.76,
        "id": 1760,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7064.76,
        "temperature": 0,
        "text": " And yet it seems to be what everyone is.",
        "tokens": [
          50564,
          400,
          1939,
          309,
          2544,
          281,
          312,
          437,
          1518,
          307,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7068.76,
        "id": 1761,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7067.76,
        "temperature": 0,
        "text": " So let's take a look at it.",
        "tokens": [
          50714,
          407,
          718,
          311,
          747,
          257,
          574,
          412,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7071.76,
        "id": 1762,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7068.76,
        "temperature": 0,
        "text": " By Gamer5000.",
        "tokens": [
          50764,
          3146,
          460,
          13530,
          44557,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7073.76,
        "id": 1763,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7071.76,
        "temperature": 0,
        "text": " Ruggamer5000.",
        "tokens": [
          50914,
          50057,
          70,
          13530,
          44557,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7075.76,
        "id": 1764,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7073.76,
        "temperature": 0,
        "text": " I'm mispronouncing your name on purpose.",
        "tokens": [
          51014,
          286,
          478,
          3346,
          1424,
          266,
          1733,
          2175,
          428,
          1315,
          322,
          4334,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7076.76,
        "id": 1765,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7075.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7078.76,
        "id": 1766,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7076.76,
        "temperature": 0,
        "text": " We can change the size.",
        "tokens": [
          51164,
          492,
          393,
          1319,
          264,
          2744,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7079.76,
        "id": 1767,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7078.76,
        "temperature": 0,
        "text": " And we can play.",
        "tokens": [
          51264,
          400,
          321,
          393,
          862,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7080.76,
        "id": 1768,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7079.76,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51314,
          2053,
          412,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7081.76,
        "id": 1769,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7080.76,
        "temperature": 0,
        "text": " This is cool.",
        "tokens": [
          51364,
          639,
          307,
          1627,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7082.76,
        "id": 1770,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7081.76,
        "temperature": 0,
        "text": " So much Tic Tac Toe.",
        "tokens": [
          51414,
          407,
          709,
          314,
          299,
          38848,
          1407,
          68,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7084.76,
        "id": 1771,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7082.76,
        "temperature": 0,
        "text": " I love how you can do this in real time.",
        "tokens": [
          51464,
          286,
          959,
          577,
          291,
          393,
          360,
          341,
          294,
          957,
          565,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2044910217498566,
        "compression_ratio": 1.524904214559387,
        "end": 7087.76,
        "id": 1772,
        "no_speech_prob": 0.04401462897658348,
        "seek": 706076,
        "start": 7084.76,
        "temperature": 0,
        "text": " It would be interesting to think about if you were to start to play it.",
        "tokens": [
          51564,
          467,
          576,
          312,
          1880,
          281,
          519,
          466,
          498,
          291,
          645,
          281,
          722,
          281,
          862,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7091.76,
        "id": 1773,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7087.76,
        "temperature": 0,
        "text": " And you resize it and it kept what you had played so far.",
        "tokens": [
          50364,
          400,
          291,
          50069,
          309,
          293,
          309,
          4305,
          437,
          291,
          632,
          3737,
          370,
          1400,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7093.76,
        "id": 1774,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7091.76,
        "temperature": 0,
        "text": " Like you're sort of zooming out.",
        "tokens": [
          50564,
          1743,
          291,
          434,
          1333,
          295,
          48226,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7096.76,
        "id": 1775,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7093.76,
        "temperature": 0,
        "text": " Let's see if there's any interesting thing that happens when you win.",
        "tokens": [
          50664,
          961,
          311,
          536,
          498,
          456,
          311,
          604,
          1880,
          551,
          300,
          2314,
          562,
          291,
          1942,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7101.76,
        "id": 1776,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7099.76,
        "temperature": 0,
        "text": " Ooh, animating the line drawing.",
        "tokens": [
          50964,
          7951,
          11,
          2383,
          990,
          264,
          1622,
          6316,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7102.76,
        "id": 1777,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7101.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51064,
          865,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7106.76,
        "id": 1778,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7102.76,
        "temperature": 0,
        "text": " Welcome to the Tic Tac Toe coding channel.",
        "tokens": [
          51114,
          4027,
          281,
          264,
          314,
          299,
          38848,
          1407,
          68,
          17720,
          2269,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7110.76,
        "id": 1779,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7106.76,
        "temperature": 0,
        "text": " YouTube channel where every week we talk about the game Tic Tac Toe.",
        "tokens": [
          51314,
          3088,
          2269,
          689,
          633,
          1243,
          321,
          751,
          466,
          264,
          1216,
          314,
          299,
          38848,
          1407,
          68,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7111.76,
        "id": 1780,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7110.76,
        "temperature": 0,
        "text": " How do you play it?",
        "tokens": [
          51514,
          1012,
          360,
          291,
          862,
          309,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7112.76,
        "id": 1781,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7111.76,
        "temperature": 0,
        "text": " What does it mean?",
        "tokens": [
          51564,
          708,
          775,
          309,
          914,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7113.76,
        "id": 1782,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7112.76,
        "temperature": 0,
        "text": " Where did it come from?",
        "tokens": [
          51614,
          2305,
          630,
          309,
          808,
          490,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1970596468545557,
        "compression_ratio": 1.6072874493927125,
        "end": 7115.76,
        "id": 1783,
        "no_speech_prob": 0.01048809289932251,
        "seek": 708776,
        "start": 7113.76,
        "temperature": 0,
        "text": " Who loves Tic Tac Toe?",
        "tokens": [
          51664,
          2102,
          6752,
          314,
          299,
          38848,
          1407,
          68,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7116.76,
        "id": 1784,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7115.76,
        "temperature": 0,
        "text": " Where did it come from?",
        "tokens": [
          50364,
          2305,
          630,
          309,
          808,
          490,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7118.76,
        "id": 1785,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7116.76,
        "temperature": 0,
        "text": " Who loves Tic Tac Toe more than me?",
        "tokens": [
          50414,
          2102,
          6752,
          314,
          299,
          38848,
          1407,
          68,
          544,
          813,
          385,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7120.76,
        "id": 1786,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7118.76,
        "temperature": 0,
        "text": " Nobody!",
        "tokens": [
          50514,
          9297,
          0,
          50614
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7124.76,
        "id": 1787,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7123.76,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50764,
          1079,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7125.76,
        "id": 1788,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7124.76,
        "temperature": 0,
        "text": " Alright, one more.",
        "tokens": [
          50814,
          2798,
          11,
          472,
          544,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7126.76,
        "id": 1789,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7125.76,
        "temperature": 0,
        "text": " One more.",
        "tokens": [
          50864,
          1485,
          544,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7127.76,
        "id": 1790,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7126.76,
        "temperature": 0,
        "text": " One more.",
        "tokens": [
          50914,
          1485,
          544,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7129.76,
        "id": 1791,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7128.76,
        "temperature": 0,
        "text": " That was a little weird.",
        "tokens": [
          51014,
          663,
          390,
          257,
          707,
          3657,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7130.76,
        "id": 1792,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7129.76,
        "temperature": 0,
        "text": " That like yes that I did.",
        "tokens": [
          51064,
          663,
          411,
          2086,
          300,
          286,
          630,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7132.76,
        "id": 1793,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7130.76,
        "temperature": 0,
        "text": " That made me uncomfortable.",
        "tokens": [
          51114,
          663,
          1027,
          385,
          10532,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7134.76,
        "id": 1794,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7132.76,
        "temperature": 0,
        "text": " I hope you're doing alright.",
        "tokens": [
          51214,
          286,
          1454,
          291,
          434,
          884,
          5845,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7137.76,
        "id": 1795,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7135.76,
        "temperature": 0,
        "text": " Oh, it's the editable game of life.",
        "tokens": [
          51364,
          876,
          11,
          309,
          311,
          264,
          8129,
          712,
          1216,
          295,
          993,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7138.76,
        "id": 1796,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7137.76,
        "temperature": 0,
        "text": " Remember?",
        "tokens": [
          51464,
          5459,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7140.76,
        "id": 1797,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7138.76,
        "temperature": 0,
        "text": " The editable game of life.",
        "tokens": [
          51514,
          440,
          8129,
          712,
          1216,
          295,
          993,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7141.76,
        "id": 1798,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7140.76,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51614,
          2798,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7142.76,
        "id": 1799,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7141.76,
        "temperature": 0,
        "text": " We looked at that last week.",
        "tokens": [
          51664,
          492,
          2956,
          412,
          300,
          1036,
          1243,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7143.76,
        "id": 1800,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7142.76,
        "temperature": 0,
        "text": " We've got 10 print.",
        "tokens": [
          51714,
          492,
          600,
          658,
          1266,
          4482,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17055870504940257,
        "compression_ratio": 1.6244541484716157,
        "end": 7144.76,
        "id": 1801,
        "no_speech_prob": 0.11918286979198456,
        "seek": 711576,
        "start": 7143.76,
        "temperature": 0,
        "text": " I'm excited for this.",
        "tokens": [
          51764,
          286,
          478,
          2919,
          337,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20487541009571927,
        "compression_ratio": 1.6814814814814816,
        "end": 7148.76,
        "id": 1802,
        "no_speech_prob": 0.020020555704832077,
        "seek": 714476,
        "start": 7144.76,
        "temperature": 0,
        "text": " 10 print is one of my favorite coding challenges that people contribute to.",
        "tokens": [
          50364,
          1266,
          4482,
          307,
          472,
          295,
          452,
          2954,
          17720,
          4759,
          300,
          561,
          10586,
          281,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20487541009571927,
        "compression_ratio": 1.6814814814814816,
        "end": 7152.76,
        "id": 1803,
        "no_speech_prob": 0.020020555704832077,
        "seek": 714476,
        "start": 7149.76,
        "temperature": 0,
        "text": " Just to look at it briefly, it's this coding challenge.",
        "tokens": [
          50614,
          1449,
          281,
          574,
          412,
          309,
          10515,
          11,
          309,
          311,
          341,
          17720,
          3430,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20487541009571927,
        "compression_ratio": 1.6814814814814816,
        "end": 7155.76,
        "id": 1804,
        "no_speech_prob": 0.020020555704832077,
        "seek": 714476,
        "start": 7152.76,
        "temperature": 0,
        "text": " It's actually, I don't know if any of you broke the record,",
        "tokens": [
          50764,
          467,
          311,
          767,
          11,
          286,
          500,
          380,
          458,
          498,
          604,
          295,
          291,
          6902,
          264,
          2136,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20487541009571927,
        "compression_ratio": 1.6814814814814816,
        "end": 7157.76,
        "id": 1805,
        "no_speech_prob": 0.020020555704832077,
        "seek": 714476,
        "start": 7155.76,
        "temperature": 0,
        "text": " but this is one that has so many contributions.",
        "tokens": [
          50914,
          457,
          341,
          307,
          472,
          300,
          575,
          370,
          867,
          15725,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20487541009571927,
        "compression_ratio": 1.6814814814814816,
        "end": 7164.76,
        "id": 1806,
        "no_speech_prob": 0.020020555704832077,
        "seek": 714476,
        "start": 7157.76,
        "temperature": 0,
        "text": " It's a really, really simple system of drawing one of two possible lines in a grid.",
        "tokens": [
          51014,
          467,
          311,
          257,
          534,
          11,
          534,
          2199,
          1185,
          295,
          6316,
          472,
          295,
          732,
          1944,
          3876,
          294,
          257,
          10748,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20487541009571927,
        "compression_ratio": 1.6814814814814816,
        "end": 7168.76,
        "id": 1807,
        "no_speech_prob": 0.020020555704832077,
        "seek": 714476,
        "start": 7164.76,
        "temperature": 0,
        "text": " It's famously from this one line Commodore 64 program.",
        "tokens": [
          51364,
          467,
          311,
          34360,
          490,
          341,
          472,
          1622,
          3046,
          34239,
          12145,
          1461,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20487541009571927,
        "compression_ratio": 1.6814814814814816,
        "end": 7172.76,
        "id": 1808,
        "no_speech_prob": 0.020020555704832077,
        "seek": 714476,
        "start": 7168.76,
        "temperature": 0,
        "text": " If you're not familiar, I think if I just go to 10print.org with this book,",
        "tokens": [
          51564,
          759,
          291,
          434,
          406,
          4963,
          11,
          286,
          519,
          498,
          286,
          445,
          352,
          281,
          1266,
          14030,
          13,
          4646,
          365,
          341,
          1446,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7174.76,
        "id": 1809,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7172.76,
        "temperature": 0,
        "text": " by this collection of wonderful authors,",
        "tokens": [
          50364,
          538,
          341,
          5765,
          295,
          3715,
          16552,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7177.76,
        "id": 1810,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7174.76,
        "temperature": 0,
        "text": " all about the sort of like history of,",
        "tokens": [
          50464,
          439,
          466,
          264,
          1333,
          295,
          411,
          2503,
          295,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7180.76,
        "id": 1811,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7177.76,
        "temperature": 0,
        "text": " it's really in a way it's like looking at the history of creative computing",
        "tokens": [
          50614,
          309,
          311,
          534,
          294,
          257,
          636,
          309,
          311,
          411,
          1237,
          412,
          264,
          2503,
          295,
          5880,
          15866,
          50764
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7182.76,
        "id": 1812,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7180.76,
        "temperature": 0,
        "text": " through the lens of this one line of code.",
        "tokens": [
          50764,
          807,
          264,
          6765,
          295,
          341,
          472,
          1622,
          295,
          3089,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7184.76,
        "id": 1813,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7182.76,
        "temperature": 0,
        "text": " Highly recommend this wonderful book.",
        "tokens": [
          50864,
          5229,
          356,
          2748,
          341,
          3715,
          1446,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7191.76,
        "id": 1814,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7185.76,
        "temperature": 0,
        "text": " Let's take a look at this particular version of it by Nearby.",
        "tokens": [
          51014,
          961,
          311,
          747,
          257,
          574,
          412,
          341,
          1729,
          3037,
          295,
          309,
          538,
          22200,
          2322,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7197.76,
        "id": 1815,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7196.76,
        "temperature": 0,
        "text": " Oh, this is cool.",
        "tokens": [
          51564,
          876,
          11,
          341,
          307,
          1627,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7198.76,
        "id": 1816,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7197.76,
        "temperature": 0,
        "text": " This is interesting.",
        "tokens": [
          51614,
          639,
          307,
          1880,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24570020039876303,
        "compression_ratio": 1.6294642857142858,
        "end": 7200.76,
        "id": 1817,
        "no_speech_prob": 0.008061599917709827,
        "seek": 717276,
        "start": 7198.76,
        "temperature": 0,
        "text": " So at first I thought, huh,",
        "tokens": [
          51664,
          407,
          412,
          700,
          286,
          1194,
          11,
          7020,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.17103124402233005,
        "compression_ratio": 1.55859375,
        "end": 7208.76,
        "id": 1818,
        "no_speech_prob": 0.000047576282668160275,
        "seek": 720076,
        "start": 7200.76,
        "temperature": 0,
        "text": " this looks to me like it is essentially identical to the original 10 print challenge.",
        "tokens": [
          50364,
          341,
          1542,
          281,
          385,
          411,
          309,
          307,
          4476,
          14800,
          281,
          264,
          3380,
          1266,
          4482,
          3430,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17103124402233005,
        "compression_ratio": 1.55859375,
        "end": 7211.76,
        "id": 1819,
        "no_speech_prob": 0.000047576282668160275,
        "seek": 720076,
        "start": 7208.76,
        "temperature": 0,
        "text": " And I was about to say, that's wonderful.",
        "tokens": [
          50764,
          400,
          286,
          390,
          466,
          281,
          584,
          11,
          300,
          311,
          3715,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17103124402233005,
        "compression_ratio": 1.55859375,
        "end": 7216.76,
        "id": 1820,
        "no_speech_prob": 0.000047576282668160275,
        "seek": 720076,
        "start": 7211.76,
        "temperature": 0,
        "text": " There's no reason why anybody shouldn't feel free to submit their own version",
        "tokens": [
          50914,
          821,
          311,
          572,
          1778,
          983,
          4472,
          4659,
          380,
          841,
          1737,
          281,
          10315,
          641,
          1065,
          3037,
          51164
        ]
      },
      {
        "avg_logprob": -0.17103124402233005,
        "compression_ratio": 1.55859375,
        "end": 7219.76,
        "id": 1821,
        "no_speech_prob": 0.000047576282668160275,
        "seek": 720076,
        "start": 7216.76,
        "temperature": 0,
        "text": " of basically the exact same thing and getting it working.",
        "tokens": [
          51164,
          295,
          1936,
          264,
          1900,
          912,
          551,
          293,
          1242,
          309,
          1364,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17103124402233005,
        "compression_ratio": 1.55859375,
        "end": 7221.76,
        "id": 1822,
        "no_speech_prob": 0.000047576282668160275,
        "seek": 720076,
        "start": 7219.76,
        "temperature": 0,
        "text": " However, there's something quite different here.",
        "tokens": [
          51314,
          2908,
          11,
          456,
          311,
          746,
          1596,
          819,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17103124402233005,
        "compression_ratio": 1.55859375,
        "end": 7227.76,
        "id": 1823,
        "no_speech_prob": 0.000047576282668160275,
        "seek": 720076,
        "start": 7221.76,
        "temperature": 0,
        "text": " And I now have a very clear picture in my head of what I am assuming is going on here.",
        "tokens": [
          51414,
          400,
          286,
          586,
          362,
          257,
          588,
          1850,
          3036,
          294,
          452,
          1378,
          295,
          437,
          286,
          669,
          11926,
          307,
          516,
          322,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7231.76,
        "id": 1824,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7227.76,
        "temperature": 0,
        "text": " But I'm curious to see if the chat,",
        "tokens": [
          50364,
          583,
          286,
          478,
          6369,
          281,
          536,
          498,
          264,
          5081,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7234.76,
        "id": 1825,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7231.76,
        "temperature": 0,
        "text": " I know you're about 30 seconds behind me here,",
        "tokens": [
          50564,
          286,
          458,
          291,
          434,
          466,
          2217,
          3949,
          2261,
          385,
          510,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7236.76,
        "id": 1826,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7234.76,
        "temperature": 0,
        "text": " so I'll have to sort of vamp for a second.",
        "tokens": [
          50714,
          370,
          286,
          603,
          362,
          281,
          1333,
          295,
          20017,
          337,
          257,
          1150,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7240.76,
        "id": 1827,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7236.76,
        "temperature": 0,
        "text": " But if anyone in the chat wants to try to make a guess as to what is going on here,",
        "tokens": [
          50814,
          583,
          498,
          2878,
          294,
          264,
          5081,
          2738,
          281,
          853,
          281,
          652,
          257,
          2041,
          382,
          281,
          437,
          307,
          516,
          322,
          510,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7245.76,
        "id": 1828,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7240.76,
        "temperature": 0,
        "text": " how is this different from the example?",
        "tokens": [
          51014,
          577,
          307,
          341,
          819,
          490,
          264,
          1365,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7247.76,
        "id": 1829,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7245.76,
        "temperature": 0,
        "text": " If I just go back to it again,",
        "tokens": [
          51264,
          759,
          286,
          445,
          352,
          646,
          281,
          309,
          797,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7250.76,
        "id": 1830,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7247.76,
        "temperature": 0,
        "text": " if I just look at my particular example,",
        "tokens": [
          51364,
          498,
          286,
          445,
          574,
          412,
          452,
          1729,
          1365,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.18664474840517398,
        "compression_ratio": 1.5913043478260869,
        "end": 7253.76,
        "id": 1831,
        "no_speech_prob": 0.011686811223626137,
        "seek": 722776,
        "start": 7250.76,
        "temperature": 0,
        "text": " which is this, from the actual video itself,",
        "tokens": [
          51514,
          597,
          307,
          341,
          11,
          490,
          264,
          3539,
          960,
          2564,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.2387902203728171,
        "compression_ratio": 1.5736040609137056,
        "end": 7257.76,
        "id": 1832,
        "no_speech_prob": 0.08151529729366302,
        "seek": 725376,
        "start": 7253.76,
        "temperature": 0,
        "text": " looks very similar, but there is a different quality to it.",
        "tokens": [
          50364,
          1542,
          588,
          2531,
          11,
          457,
          456,
          307,
          257,
          819,
          3125,
          281,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2387902203728171,
        "compression_ratio": 1.5736040609137056,
        "end": 7264.76,
        "id": 1833,
        "no_speech_prob": 0.08151529729366302,
        "seek": 725376,
        "start": 7257.76,
        "temperature": 0,
        "text": " Let's refresh this just to see it again.",
        "tokens": [
          50564,
          961,
          311,
          15134,
          341,
          445,
          281,
          536,
          309,
          797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2387902203728171,
        "compression_ratio": 1.5736040609137056,
        "end": 7269.76,
        "id": 1834,
        "no_speech_prob": 0.08151529729366302,
        "seek": 725376,
        "start": 7264.76,
        "temperature": 0,
        "text": " So Zork Master says, I feel like that's using some sort of noise.",
        "tokens": [
          50914,
          407,
          1176,
          1284,
          6140,
          1619,
          11,
          286,
          841,
          411,
          300,
          311,
          1228,
          512,
          1333,
          295,
          5658,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2387902203728171,
        "compression_ratio": 1.5736040609137056,
        "end": 7273.76,
        "id": 1835,
        "no_speech_prob": 0.08151529729366302,
        "seek": 725376,
        "start": 7269.76,
        "temperature": 0,
        "text": " That's my thought exactly too.",
        "tokens": [
          51164,
          663,
          311,
          452,
          1194,
          2293,
          886,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2387902203728171,
        "compression_ratio": 1.5736040609137056,
        "end": 7279.76,
        "id": 1836,
        "no_speech_prob": 0.08151529729366302,
        "seek": 725376,
        "start": 7273.76,
        "temperature": 0,
        "text": " So I'm assuming that what this is doing is it's mapping the probability.",
        "tokens": [
          51364,
          407,
          286,
          478,
          11926,
          300,
          437,
          341,
          307,
          884,
          307,
          309,
          311,
          18350,
          264,
          8482,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2387902203728171,
        "compression_ratio": 1.5736040609137056,
        "end": 7280.76,
        "id": 1837,
        "no_speech_prob": 0.08151529729366302,
        "seek": 725376,
        "start": 7279.76,
        "temperature": 0,
        "text": " Well, not just mapping the probability.",
        "tokens": [
          51664,
          1042,
          11,
          406,
          445,
          18350,
          264,
          8482,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22237122412955407,
        "compression_ratio": 1.6,
        "end": 7284.76,
        "id": 1838,
        "no_speech_prob": 0.10374082624912262,
        "seek": 728076,
        "start": 7280.76,
        "temperature": 0,
        "text": " It's picking the left line or right line,",
        "tokens": [
          50364,
          467,
          311,
          8867,
          264,
          1411,
          1622,
          420,
          558,
          1622,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.22237122412955407,
        "compression_ratio": 1.6,
        "end": 7286.76,
        "id": 1839,
        "no_speech_prob": 0.10374082624912262,
        "seek": 728076,
        "start": 7284.76,
        "temperature": 0,
        "text": " whichever direction the line is going,",
        "tokens": [
          50564,
          24123,
          3513,
          264,
          1622,
          307,
          516,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.22237122412955407,
        "compression_ratio": 1.6,
        "end": 7293.76,
        "id": 1840,
        "no_speech_prob": 0.10374082624912262,
        "seek": 728076,
        "start": 7286.76,
        "temperature": 0,
        "text": " based off of most likely some Perlin noise-like algorithm rather than pure randomness.",
        "tokens": [
          50664,
          2361,
          766,
          295,
          881,
          3700,
          512,
          3026,
          5045,
          5658,
          12,
          4092,
          9284,
          2831,
          813,
          6075,
          4974,
          1287,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22237122412955407,
        "compression_ratio": 1.6,
        "end": 7296.76,
        "id": 1841,
        "no_speech_prob": 0.10374082624912262,
        "seek": 728076,
        "start": 7293.76,
        "temperature": 0,
        "text": " So in pure randomness, and one thing we can do that's nice,",
        "tokens": [
          51014,
          407,
          294,
          6075,
          4974,
          1287,
          11,
          293,
          472,
          551,
          321,
          393,
          360,
          300,
          311,
          1481,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.22237122412955407,
        "compression_ratio": 1.6,
        "end": 7300.76,
        "id": 1842,
        "no_speech_prob": 0.10374082624912262,
        "seek": 728076,
        "start": 7296.76,
        "temperature": 0,
        "text": " if I go to full here, we can see,",
        "tokens": [
          51164,
          498,
          286,
          352,
          281,
          1577,
          510,
          11,
          321,
          393,
          536,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.22237122412955407,
        "compression_ratio": 1.6,
        "end": 7303.76,
        "id": 1843,
        "no_speech_prob": 0.10374082624912262,
        "seek": 728076,
        "start": 7300.76,
        "temperature": 0,
        "text": " I can quickly click over to look at the code.",
        "tokens": [
          51364,
          286,
          393,
          2661,
          2052,
          670,
          281,
          574,
          412,
          264,
          3089,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22237122412955407,
        "compression_ratio": 1.6,
        "end": 7306.76,
        "id": 1844,
        "no_speech_prob": 0.10374082624912262,
        "seek": 728076,
        "start": 7303.76,
        "temperature": 0,
        "text": " And you can see noise, X off, Y off.",
        "tokens": [
          51514,
          400,
          291,
          393,
          536,
          5658,
          11,
          1783,
          766,
          11,
          398,
          766,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19183718639871347,
        "compression_ratio": 1.5291479820627802,
        "end": 7313.76,
        "id": 1845,
        "no_speech_prob": 0.06953827291727066,
        "seek": 730676,
        "start": 7306.76,
        "temperature": 0,
        "text": " So very quickly, you can see how it's checking to see if the value is less than 50 or greater than 50.",
        "tokens": [
          50364,
          407,
          588,
          2661,
          11,
          291,
          393,
          536,
          577,
          309,
          311,
          8568,
          281,
          536,
          498,
          264,
          2158,
          307,
          1570,
          813,
          2625,
          420,
          5044,
          813,
          2625,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19183718639871347,
        "compression_ratio": 1.5291479820627802,
        "end": 7316.76,
        "id": 1846,
        "no_speech_prob": 0.06953827291727066,
        "seek": 730676,
        "start": 7313.76,
        "temperature": 0,
        "text": " So just to demonstrate this more clearly,",
        "tokens": [
          50714,
          407,
          445,
          281,
          11698,
          341,
          544,
          4448,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.19183718639871347,
        "compression_ratio": 1.5291479820627802,
        "end": 7321.76,
        "id": 1847,
        "no_speech_prob": 0.06953827291727066,
        "seek": 730676,
        "start": 7316.76,
        "temperature": 0,
        "text": " if I were to replace that with a random number between 0 and 100, that's what we'll get.",
        "tokens": [
          50864,
          498,
          286,
          645,
          281,
          7406,
          300,
          365,
          257,
          4974,
          1230,
          1296,
          1958,
          293,
          2319,
          11,
          300,
          311,
          437,
          321,
          603,
          483,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19183718639871347,
        "compression_ratio": 1.5291479820627802,
        "end": 7324.76,
        "id": 1848,
        "no_speech_prob": 0.06953827291727066,
        "seek": 730676,
        "start": 7321.76,
        "temperature": 0,
        "text": " Oh, but also the line has a different,",
        "tokens": [
          51114,
          876,
          11,
          457,
          611,
          264,
          1622,
          575,
          257,
          819,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.19183718639871347,
        "compression_ratio": 1.5291479820627802,
        "end": 7330.76,
        "id": 1849,
        "no_speech_prob": 0.06953827291727066,
        "seek": 730676,
        "start": 7324.76,
        "temperature": 0,
        "text": " it looks to me like it's always brighter when pointing to the right.",
        "tokens": [
          51264,
          309,
          1542,
          281,
          385,
          411,
          309,
          311,
          1009,
          19764,
          562,
          12166,
          281,
          264,
          558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22692424811205816,
        "compression_ratio": 1.610878661087866,
        "end": 7337.76,
        "id": 1850,
        "no_speech_prob": 0.051842980086803436,
        "seek": 733076,
        "start": 7330.76,
        "temperature": 0,
        "text": " Is it tying its stroke also to the noise value or the random value in this case?",
        "tokens": [
          50364,
          1119,
          309,
          32405,
          1080,
          12403,
          611,
          281,
          264,
          5658,
          2158,
          420,
          264,
          4974,
          2158,
          294,
          341,
          1389,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.22692424811205816,
        "compression_ratio": 1.610878661087866,
        "end": 7338.76,
        "id": 1851,
        "no_speech_prob": 0.051842980086803436,
        "seek": 733076,
        "start": 7337.76,
        "temperature": 0,
        "text": " That's really interesting. I didn't think of that.",
        "tokens": [
          50714,
          663,
          311,
          534,
          1880,
          13,
          286,
          994,
          380,
          519,
          295,
          300,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22692424811205816,
        "compression_ratio": 1.610878661087866,
        "end": 7341.76,
        "id": 1852,
        "no_speech_prob": 0.051842980086803436,
        "seek": 733076,
        "start": 7338.76,
        "temperature": 0,
        "text": " So those are the, looks like the two changes.",
        "tokens": [
          50764,
          407,
          729,
          366,
          264,
          11,
          1542,
          411,
          264,
          732,
          2962,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22692424811205816,
        "compression_ratio": 1.610878661087866,
        "end": 7345.76,
        "id": 1853,
        "no_speech_prob": 0.051842980086803436,
        "seek": 733076,
        "start": 7341.76,
        "temperature": 0,
        "text": " If I take that out, we can see here, this is the original 10 print code.",
        "tokens": [
          50914,
          759,
          286,
          747,
          300,
          484,
          11,
          321,
          393,
          536,
          510,
          11,
          341,
          307,
          264,
          3380,
          1266,
          4482,
          3089,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22692424811205816,
        "compression_ratio": 1.610878661087866,
        "end": 7354.76,
        "id": 1854,
        "no_speech_prob": 0.051842980086803436,
        "seek": 733076,
        "start": 7345.76,
        "temperature": 0,
        "text": " But by changing it to using a noise algorithm over a two-dimensional space,",
        "tokens": [
          51114,
          583,
          538,
          4473,
          309,
          281,
          1228,
          257,
          5658,
          9284,
          670,
          257,
          732,
          12,
          18759,
          1901,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.22692424811205816,
        "compression_ratio": 1.610878661087866,
        "end": 7357.76,
        "id": 1855,
        "no_speech_prob": 0.051842980086803436,
        "seek": 733076,
        "start": 7354.76,
        "temperature": 0,
        "text": " and then additionally, and I already like got rid of that,",
        "tokens": [
          51564,
          293,
          550,
          43181,
          11,
          293,
          286,
          1217,
          411,
          658,
          3973,
          295,
          300,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.23994521741513852,
        "compression_ratio": 1.7136929460580912,
        "end": 7361.76,
        "id": 1856,
        "no_speech_prob": 0.00118788774125278,
        "seek": 735776,
        "start": 7357.76,
        "temperature": 0,
        "text": " but additionally changing the weight of the stroke weight of the line,",
        "tokens": [
          50364,
          457,
          43181,
          4473,
          264,
          3364,
          295,
          264,
          12403,
          3364,
          295,
          264,
          1622,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.23994521741513852,
        "compression_ratio": 1.7136929460580912,
        "end": 7364.76,
        "id": 1857,
        "no_speech_prob": 0.00118788774125278,
        "seek": 735776,
        "start": 7361.76,
        "temperature": 0,
        "text": " or actually it's not the stroke weight, it's the brightness of the line.",
        "tokens": [
          50564,
          420,
          767,
          309,
          311,
          406,
          264,
          12403,
          3364,
          11,
          309,
          311,
          264,
          21367,
          295,
          264,
          1622,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23994521741513852,
        "compression_ratio": 1.7136929460580912,
        "end": 7368.76,
        "id": 1858,
        "no_speech_prob": 0.00118788774125278,
        "seek": 735776,
        "start": 7364.76,
        "temperature": 0,
        "text": " Those are really clever adjustments to make.",
        "tokens": [
          50714,
          3950,
          366,
          534,
          13494,
          18624,
          281,
          652,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23994521741513852,
        "compression_ratio": 1.7136929460580912,
        "end": 7375.76,
        "id": 1859,
        "no_speech_prob": 0.00118788774125278,
        "seek": 735776,
        "start": 7368.76,
        "temperature": 0,
        "text": " There's so many rich and deep possible kinds of things you can do with this one algorithm.",
        "tokens": [
          50914,
          821,
          311,
          370,
          867,
          4593,
          293,
          2452,
          1944,
          3685,
          295,
          721,
          291,
          393,
          360,
          365,
          341,
          472,
          9284,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23994521741513852,
        "compression_ratio": 1.7136929460580912,
        "end": 7378.76,
        "id": 1860,
        "no_speech_prob": 0.00118788774125278,
        "seek": 735776,
        "start": 7375.76,
        "temperature": 0,
        "text": " That's just, I love it so much.",
        "tokens": [
          51264,
          663,
          311,
          445,
          11,
          286,
          959,
          309,
          370,
          709,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23994521741513852,
        "compression_ratio": 1.7136929460580912,
        "end": 7384.76,
        "id": 1861,
        "no_speech_prob": 0.00118788774125278,
        "seek": 735776,
        "start": 7378.76,
        "temperature": 0,
        "text": " Okay. Unoriginal pun has woken up in Australia. Is that right?",
        "tokens": [
          51414,
          1033,
          13,
          1156,
          29042,
          4468,
          575,
          261,
          8406,
          493,
          294,
          7060,
          13,
          1119,
          300,
          558,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.23994521741513852,
        "compression_ratio": 1.7136929460580912,
        "end": 7386.76,
        "id": 1862,
        "no_speech_prob": 0.00118788774125278,
        "seek": 735776,
        "start": 7384.76,
        "temperature": 0,
        "text": " Where are you located, Unoriginal pun?",
        "tokens": [
          51714,
          2305,
          366,
          291,
          6870,
          11,
          1156,
          29042,
          4468,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.1732273570826796,
        "compression_ratio": 1.4154929577464788,
        "end": 7389.76,
        "id": 1863,
        "no_speech_prob": 0.19188661873340607,
        "seek": 738676,
        "start": 7386.76,
        "temperature": 0,
        "text": " Welcome to the live stream.",
        "tokens": [
          50364,
          4027,
          281,
          264,
          1621,
          4309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1732273570826796,
        "compression_ratio": 1.4154929577464788,
        "end": 7395.76,
        "id": 1864,
        "no_speech_prob": 0.19188661873340607,
        "seek": 738676,
        "start": 7389.76,
        "temperature": 0,
        "text": " I am going to have some water here and I'm removing myself.",
        "tokens": [
          50514,
          286,
          669,
          516,
          281,
          362,
          512,
          1281,
          510,
          293,
          286,
          478,
          12720,
          2059,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1732273570826796,
        "compression_ratio": 1.4154929577464788,
        "end": 7400.76,
        "id": 1865,
        "no_speech_prob": 0.19188661873340607,
        "seek": 738676,
        "start": 7395.76,
        "temperature": 0,
        "text": " We are finishing up here, but I'm going to do one more thing before we go.",
        "tokens": [
          50814,
          492,
          366,
          12693,
          493,
          510,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          472,
          544,
          551,
          949,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1732273570826796,
        "compression_ratio": 1.4154929577464788,
        "end": 7409.76,
        "id": 1866,
        "no_speech_prob": 0.19188661873340607,
        "seek": 738676,
        "start": 7400.76,
        "temperature": 0,
        "text": " So let us go back to the Rubik's Cube.",
        "tokens": [
          51064,
          407,
          718,
          505,
          352,
          646,
          281,
          264,
          10518,
          1035,
          311,
          33003,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1887893563225156,
        "compression_ratio": 1.5026737967914439,
        "end": 7417.76,
        "id": 1867,
        "no_speech_prob": 0.2508821189403534,
        "seek": 740976,
        "start": 7409.76,
        "temperature": 0,
        "text": " I need to sign out of runway here and go back to this account because I'm a lunatic.",
        "tokens": [
          50364,
          286,
          643,
          281,
          1465,
          484,
          295,
          26642,
          510,
          293,
          352,
          646,
          281,
          341,
          2696,
          570,
          286,
          478,
          257,
          19039,
          2399,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1887893563225156,
        "compression_ratio": 1.5026737967914439,
        "end": 7422.76,
        "id": 1868,
        "no_speech_prob": 0.2508821189403534,
        "seek": 740976,
        "start": 7417.76,
        "temperature": 0,
        "text": " The tiny one completed.",
        "tokens": [
          50764,
          440,
          5870,
          472,
          7365,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1887893563225156,
        "compression_ratio": 1.5026737967914439,
        "end": 7424.76,
        "id": 1869,
        "no_speech_prob": 0.2508821189403534,
        "seek": 740976,
        "start": 7422.76,
        "temperature": 0,
        "text": " You can see, oh, the other one is at 97%.",
        "tokens": [
          51014,
          509,
          393,
          536,
          11,
          1954,
          11,
          264,
          661,
          472,
          307,
          412,
          23399,
          6856,
          51114
        ]
      },
      {
        "avg_logprob": -0.1887893563225156,
        "compression_ratio": 1.5026737967914439,
        "end": 7428.76,
        "id": 1870,
        "no_speech_prob": 0.2508821189403534,
        "seek": 740976,
        "start": 7424.76,
        "temperature": 0,
        "text": " So we could compare and contrast these, but let's look at this one.",
        "tokens": [
          51114,
          407,
          321,
          727,
          6794,
          293,
          8712,
          613,
          11,
          457,
          718,
          311,
          574,
          412,
          341,
          472,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1887893563225156,
        "compression_ratio": 1.5026737967914439,
        "end": 7432.76,
        "id": 1871,
        "no_speech_prob": 0.2508821189403534,
        "seek": 740976,
        "start": 7428.76,
        "temperature": 0,
        "text": " So this one trained, completed.",
        "tokens": [
          51314,
          407,
          341,
          472,
          8895,
          11,
          7365,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1887893563225156,
        "compression_ratio": 1.5026737967914439,
        "end": 7435.76,
        "id": 1872,
        "no_speech_prob": 0.2508821189403534,
        "seek": 740976,
        "start": 7432.76,
        "temperature": 0,
        "text": " Let's add it to the workspace.",
        "tokens": [
          51514,
          961,
          311,
          909,
          309,
          281,
          264,
          32706,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18514886498451233,
        "compression_ratio": 1.4863013698630136,
        "end": 7439.76,
        "id": 1873,
        "no_speech_prob": 0.3073040843009949,
        "seek": 743576,
        "start": 7435.76,
        "temperature": 0,
        "text": " We're going to call this coding train demo.",
        "tokens": [
          50364,
          492,
          434,
          516,
          281,
          818,
          341,
          17720,
          3847,
          10723,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18514886498451233,
        "compression_ratio": 1.4863013698630136,
        "end": 7443.76,
        "id": 1874,
        "no_speech_prob": 0.3073040843009949,
        "seek": 743576,
        "start": 7439.76,
        "temperature": 0,
        "text": " I'm going to give myself a lot more space here.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          976,
          2059,
          257,
          688,
          544,
          1901,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18514886498451233,
        "compression_ratio": 1.4863013698630136,
        "end": 7450.76,
        "id": 1875,
        "no_speech_prob": 0.3073040843009949,
        "seek": 743576,
        "start": 7443.76,
        "temperature": 0,
        "text": " I'm going to just test it out here in the browser with camera.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          445,
          1500,
          309,
          484,
          510,
          294,
          264,
          11185,
          365,
          2799,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18514886498451233,
        "compression_ratio": 1.4863013698630136,
        "end": 7455.76,
        "id": 1876,
        "no_speech_prob": 0.3073040843009949,
        "seek": 743576,
        "start": 7450.76,
        "temperature": 0,
        "text": " Then I can select the actual webcam here.",
        "tokens": [
          51114,
          1396,
          286,
          393,
          3048,
          264,
          3539,
          39490,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18514886498451233,
        "compression_ratio": 1.4863013698630136,
        "end": 7459.76,
        "id": 1877,
        "no_speech_prob": 0.3073040843009949,
        "seek": 743576,
        "start": 7455.76,
        "temperature": 0,
        "text": " Let's run the model.",
        "tokens": [
          51364,
          961,
          311,
          1190,
          264,
          2316,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22920761108398438,
        "compression_ratio": 1.5436893203883495,
        "end": 7466.76,
        "id": 1878,
        "no_speech_prob": 0.25375184416770935,
        "seek": 745976,
        "start": 7459.76,
        "temperature": 0,
        "text": " And wait for it to pop up here and see how well this goes.",
        "tokens": [
          50364,
          400,
          1699,
          337,
          309,
          281,
          1665,
          493,
          510,
          293,
          536,
          577,
          731,
          341,
          1709,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22920761108398438,
        "compression_ratio": 1.5436893203883495,
        "end": 7470.76,
        "id": 1879,
        "no_speech_prob": 0.25375184416770935,
        "seek": 745976,
        "start": 7466.76,
        "temperature": 0,
        "text": " This is exciting.",
        "tokens": [
          50714,
          639,
          307,
          4670,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22920761108398438,
        "compression_ratio": 1.5436893203883495,
        "end": 7475.76,
        "id": 1880,
        "no_speech_prob": 0.25375184416770935,
        "seek": 745976,
        "start": 7470.76,
        "temperature": 0,
        "text": " Okinawa, Japan. Oh, Unoriginal pun! I have got to get in touch with you.",
        "tokens": [
          50914,
          3477,
          1426,
          4151,
          11,
          3367,
          13,
          876,
          11,
          1156,
          29042,
          4468,
          0,
          286,
          362,
          658,
          281,
          483,
          294,
          2557,
          365,
          291,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22920761108398438,
        "compression_ratio": 1.5436893203883495,
        "end": 7479.76,
        "id": 1881,
        "no_speech_prob": 0.25375184416770935,
        "seek": 745976,
        "start": 7475.76,
        "temperature": 0,
        "text": " I knew there was some reason why Okinawa, Japan was in my head.",
        "tokens": [
          51164,
          286,
          2586,
          456,
          390,
          512,
          1778,
          983,
          3477,
          1426,
          4151,
          11,
          3367,
          390,
          294,
          452,
          1378,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22920761108398438,
        "compression_ratio": 1.5436893203883495,
        "end": 7482.76,
        "id": 1882,
        "no_speech_prob": 0.25375184416770935,
        "seek": 745976,
        "start": 7479.76,
        "temperature": 0,
        "text": " Okay, we'll be in touch on Discord.",
        "tokens": [
          51364,
          1033,
          11,
          321,
          603,
          312,
          294,
          2557,
          322,
          32623,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22920761108398438,
        "compression_ratio": 1.5436893203883495,
        "end": 7485.76,
        "id": 1883,
        "no_speech_prob": 0.25375184416770935,
        "seek": 745976,
        "start": 7482.76,
        "temperature": 0,
        "text": " I've got to speak to you about Okinawa, Japan.",
        "tokens": [
          51514,
          286,
          600,
          658,
          281,
          1710,
          281,
          291,
          466,
          3477,
          1426,
          4151,
          11,
          3367,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22920761108398438,
        "compression_ratio": 1.5436893203883495,
        "end": 7487.76,
        "id": 1884,
        "no_speech_prob": 0.25375184416770935,
        "seek": 745976,
        "start": 7485.76,
        "temperature": 0,
        "text": " All right, let's see.",
        "tokens": [
          51664,
          1057,
          558,
          11,
          718,
          311,
          536,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17114043492142872,
        "compression_ratio": 1.5336538461538463,
        "end": 7490.76,
        "id": 1885,
        "no_speech_prob": 0.008711222559213638,
        "seek": 748776,
        "start": 7487.76,
        "temperature": 0,
        "text": " So this is what I was told.",
        "tokens": [
          50364,
          407,
          341,
          307,
          437,
          286,
          390,
          1907,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17114043492142872,
        "compression_ratio": 1.5336538461538463,
        "end": 7492.76,
        "id": 1886,
        "no_speech_prob": 0.008711222559213638,
        "seek": 748776,
        "start": 7490.76,
        "temperature": 0,
        "text": " This was happening to me the other day.",
        "tokens": [
          50514,
          639,
          390,
          2737,
          281,
          385,
          264,
          661,
          786,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17114043492142872,
        "compression_ratio": 1.5336538461538463,
        "end": 7495.76,
        "id": 1887,
        "no_speech_prob": 0.008711222559213638,
        "seek": 748776,
        "start": 7492.76,
        "temperature": 0,
        "text": " This, I'm told, is a bug in the runway interface.",
        "tokens": [
          50614,
          639,
          11,
          286,
          478,
          1907,
          11,
          307,
          257,
          7426,
          294,
          264,
          26642,
          9226,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17114043492142872,
        "compression_ratio": 1.5336538461538463,
        "end": 7499.76,
        "id": 1888,
        "no_speech_prob": 0.008711222559213638,
        "seek": 748776,
        "start": 7495.76,
        "temperature": 0,
        "text": " The fact that it is flickering back and forth to the edge.",
        "tokens": [
          50764,
          440,
          1186,
          300,
          309,
          307,
          22774,
          1794,
          646,
          293,
          5220,
          281,
          264,
          4691,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17114043492142872,
        "compression_ratio": 1.5336538461538463,
        "end": 7503.76,
        "id": 1889,
        "no_speech_prob": 0.008711222559213638,
        "seek": 748776,
        "start": 7499.76,
        "temperature": 0,
        "text": " So this means I've really got to do it on my own.",
        "tokens": [
          50964,
          407,
          341,
          1355,
          286,
          600,
          534,
          658,
          281,
          360,
          309,
          322,
          452,
          1065,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17114043492142872,
        "compression_ratio": 1.5336538461538463,
        "end": 7512.76,
        "id": 1890,
        "no_speech_prob": 0.008711222559213638,
        "seek": 748776,
        "start": 7503.76,
        "temperature": 0,
        "text": " Unfortunately, I cannot abide by people going to the URL of the Glitch project in real time.",
        "tokens": [
          51164,
          8590,
          11,
          286,
          2644,
          39663,
          538,
          561,
          516,
          281,
          264,
          12905,
          295,
          264,
          5209,
          1549,
          1716,
          294,
          957,
          565,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7517.76,
        "id": 1891,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7512.76,
        "temperature": 0,
        "text": " I suppose I could go to full screen in Glitch or like this.",
        "tokens": [
          50364,
          286,
          7297,
          286,
          727,
          352,
          281,
          1577,
          2568,
          294,
          5209,
          1549,
          420,
          411,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7520.76,
        "id": 1892,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7517.76,
        "temperature": 0,
        "text": " And then you can't see the...",
        "tokens": [
          50614,
          400,
          550,
          291,
          393,
          380,
          536,
          264,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7522.76,
        "id": 1893,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7520.76,
        "temperature": 0,
        "text": " Let's do it this way.",
        "tokens": [
          50764,
          961,
          311,
          360,
          309,
          341,
          636,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7525.76,
        "id": 1894,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7522.76,
        "temperature": 0,
        "text": " This is kind of cruel of me.",
        "tokens": [
          50864,
          639,
          307,
          733,
          295,
          16022,
          295,
          385,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7529.76,
        "id": 1895,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7525.76,
        "temperature": 0,
        "text": " Or I could just develop. I'm going to develop this locally.",
        "tokens": [
          51014,
          1610,
          286,
          727,
          445,
          1499,
          13,
          286,
          478,
          516,
          281,
          1499,
          341,
          16143,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7532.76,
        "id": 1896,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7529.76,
        "temperature": 0,
        "text": " I can clone a Glitch project, right?",
        "tokens": [
          51214,
          286,
          393,
          26506,
          257,
          5209,
          1549,
          1716,
          11,
          558,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7535.76,
        "id": 1897,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7532.76,
        "temperature": 0,
        "text": " So if I go back to...",
        "tokens": [
          51364,
          407,
          498,
          286,
          352,
          646,
          281,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7537.76,
        "id": 1898,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7535.76,
        "temperature": 0,
        "text": " This will be good for us to know how to do.",
        "tokens": [
          51514,
          639,
          486,
          312,
          665,
          337,
          505,
          281,
          458,
          577,
          281,
          360,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23038127205588602,
        "compression_ratio": 1.511111111111111,
        "end": 7540.76,
        "id": 1899,
        "no_speech_prob": 0.01640256494283676,
        "seek": 751276,
        "start": 7537.76,
        "temperature": 0,
        "text": " I have to sneeze so badly right now.",
        "tokens": [
          51614,
          286,
          362,
          281,
          50076,
          370,
          13425,
          558,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19823204202854888,
        "compression_ratio": 1.5510204081632653,
        "end": 7542.76,
        "id": 1900,
        "no_speech_prob": 0.05574345588684082,
        "seek": 754076,
        "start": 7540.76,
        "temperature": 0,
        "text": " I'm going to mute the mic.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          24523,
          264,
          3123,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19823204202854888,
        "compression_ratio": 1.5510204081632653,
        "end": 7553.76,
        "id": 1901,
        "no_speech_prob": 0.05574345588684082,
        "seek": 754076,
        "start": 7549.76,
        "temperature": 0,
        "text": " That was the most amazing sneeze of my whole life.",
        "tokens": [
          50814,
          663,
          390,
          264,
          881,
          2243,
          50076,
          295,
          452,
          1379,
          993,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19823204202854888,
        "compression_ratio": 1.5510204081632653,
        "end": 7556.76,
        "id": 1902,
        "no_speech_prob": 0.05574345588684082,
        "seek": 754076,
        "start": 7553.76,
        "temperature": 0,
        "text": " Do I have a box of Kleenex up here somewhere in the attic?",
        "tokens": [
          51014,
          1144,
          286,
          362,
          257,
          2424,
          295,
          17053,
          1450,
          87,
          493,
          510,
          4079,
          294,
          264,
          40766,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.19823204202854888,
        "compression_ratio": 1.5510204081632653,
        "end": 7561.76,
        "id": 1903,
        "no_speech_prob": 0.05574345588684082,
        "seek": 754076,
        "start": 7558.76,
        "temperature": 0,
        "text": " If I can reach the ceiling, a nice tin ceiling here in the attic.",
        "tokens": [
          51264,
          759,
          286,
          393,
          2524,
          264,
          13655,
          11,
          257,
          1481,
          15935,
          13655,
          510,
          294,
          264,
          40766,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19823204202854888,
        "compression_ratio": 1.5510204081632653,
        "end": 7565.76,
        "id": 1904,
        "no_speech_prob": 0.05574345588684082,
        "seek": 754076,
        "start": 7561.76,
        "temperature": 0,
        "text": " I don't have a box of Kleenex. I think I'll be all right for just a few minutes.",
        "tokens": [
          51414,
          286,
          500,
          380,
          362,
          257,
          2424,
          295,
          17053,
          1450,
          87,
          13,
          286,
          519,
          286,
          603,
          312,
          439,
          558,
          337,
          445,
          257,
          1326,
          2077,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19823204202854888,
        "compression_ratio": 1.5510204081632653,
        "end": 7569.76,
        "id": 1905,
        "no_speech_prob": 0.05574345588684082,
        "seek": 754076,
        "start": 7567.76,
        "temperature": 0,
        "text": " Whoa, what happened?",
        "tokens": [
          51714,
          7521,
          11,
          437,
          2011,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.26914319125088776,
        "compression_ratio": 1.3854166666666667,
        "end": 7572.76,
        "id": 1906,
        "no_speech_prob": 0.007460486143827438,
        "seek": 756976,
        "start": 7569.76,
        "temperature": 0,
        "text": " My camera is doing some crazy color adjusting here.",
        "tokens": [
          50364,
          1222,
          2799,
          307,
          884,
          512,
          3219,
          2017,
          23559,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.26914319125088776,
        "compression_ratio": 1.3854166666666667,
        "end": 7575.76,
        "id": 1907,
        "no_speech_prob": 0.007460486143827438,
        "seek": 756976,
        "start": 7572.76,
        "temperature": 0,
        "text": " Let's go back to the runway template.",
        "tokens": [
          50514,
          961,
          311,
          352,
          646,
          281,
          264,
          26642,
          12379,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.26914319125088776,
        "compression_ratio": 1.3854166666666667,
        "end": 7578.76,
        "id": 1908,
        "no_speech_prob": 0.007460486143827438,
        "seek": 756976,
        "start": 7575.76,
        "temperature": 0,
        "text": " Now there is a way...",
        "tokens": [
          50664,
          823,
          456,
          307,
          257,
          636,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.26914319125088776,
        "compression_ratio": 1.3854166666666667,
        "end": 7585.76,
        "id": 1909,
        "no_speech_prob": 0.007460486143827438,
        "seek": 756976,
        "start": 7578.76,
        "temperature": 0,
        "text": " If I go to edit project, how do I get the GitHub URL of a project?",
        "tokens": [
          50814,
          759,
          286,
          352,
          281,
          8129,
          1716,
          11,
          577,
          360,
          286,
          483,
          264,
          23331,
          12905,
          295,
          257,
          1716,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.26914319125088776,
        "compression_ratio": 1.3854166666666667,
        "end": 7590.76,
        "id": 1910,
        "no_speech_prob": 0.007460486143827438,
        "seek": 756976,
        "start": 7587.76,
        "temperature": 0,
        "text": " Somebody will know this and tell me in the chat.",
        "tokens": [
          51264,
          13463,
          486,
          458,
          341,
          293,
          980,
          385,
          294,
          264,
          5081,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.26914319125088776,
        "compression_ratio": 1.3854166666666667,
        "end": 7597.76,
        "id": 1911,
        "no_speech_prob": 0.007460486143827438,
        "seek": 756976,
        "start": 7593.76,
        "temperature": 0,
        "text": " Tools, custom domains, import, export.",
        "tokens": [
          51564,
          30302,
          11,
          2375,
          25514,
          11,
          974,
          11,
          10725,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.25392935309611575,
        "compression_ratio": 1.4081632653061225,
        "end": 7599.76,
        "id": 1912,
        "no_speech_prob": 0.0005884002894163132,
        "seek": 759776,
        "start": 7597.76,
        "temperature": 0,
        "text": " Here he is. Get URL.",
        "tokens": [
          50364,
          1692,
          415,
          307,
          13,
          3240,
          12905,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.25392935309611575,
        "compression_ratio": 1.4081632653061225,
        "end": 7604.76,
        "id": 1913,
        "no_speech_prob": 0.0005884002894163132,
        "seek": 759776,
        "start": 7599.76,
        "temperature": 0,
        "text": " That's where it is, by the way, under tools.",
        "tokens": [
          50464,
          663,
          311,
          689,
          309,
          307,
          11,
          538,
          264,
          636,
          11,
          833,
          3873,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25392935309611575,
        "compression_ratio": 1.4081632653061225,
        "end": 7613.76,
        "id": 1914,
        "no_speech_prob": 0.0005884002894163132,
        "seek": 759776,
        "start": 7608.76,
        "temperature": 0,
        "text": " Sorry, under tools, import, export, get URL.",
        "tokens": [
          50914,
          4919,
          11,
          833,
          3873,
          11,
          974,
          11,
          10725,
          11,
          483,
          12905,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25392935309611575,
        "compression_ratio": 1.4081632653061225,
        "end": 7615.76,
        "id": 1915,
        "no_speech_prob": 0.0005884002894163132,
        "seek": 759776,
        "start": 7613.76,
        "temperature": 0,
        "text": " Let's go back to terminal here.",
        "tokens": [
          51164,
          961,
          311,
          352,
          646,
          281,
          14709,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25392935309611575,
        "compression_ratio": 1.4081632653061225,
        "end": 7623.76,
        "id": 1916,
        "no_speech_prob": 0.0005884002894163132,
        "seek": 759776,
        "start": 7621.76,
        "temperature": 0,
        "text": " Let's see if we can clone it.",
        "tokens": [
          51564,
          961,
          311,
          536,
          498,
          321,
          393,
          26506,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25392935309611575,
        "compression_ratio": 1.4081632653061225,
        "end": 7626.76,
        "id": 1917,
        "no_speech_prob": 0.0005884002894163132,
        "seek": 759776,
        "start": 7623.76,
        "temperature": 0,
        "text": " I'm going to develop this locally.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          1499,
          341,
          16143,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21555111020110373,
        "compression_ratio": 1.5076923076923077,
        "end": 7629.76,
        "id": 1918,
        "no_speech_prob": 0.0003199952479917556,
        "seek": 762676,
        "start": 7626.76,
        "temperature": 0,
        "text": " Just because I want to keep the key...",
        "tokens": [
          50364,
          1449,
          570,
          286,
          528,
          281,
          1066,
          264,
          2141,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.21555111020110373,
        "compression_ratio": 1.5076923076923077,
        "end": 7638.76,
        "id": 1919,
        "no_speech_prob": 0.0003199952479917556,
        "seek": 762676,
        "start": 7629.76,
        "temperature": 0,
        "text": " I can keep the key secure, but I don't want to use up a zillion requests to the runway library.",
        "tokens": [
          50514,
          286,
          393,
          1066,
          264,
          2141,
          7144,
          11,
          457,
          286,
          500,
          380,
          528,
          281,
          764,
          493,
          257,
          710,
          11836,
          12475,
          281,
          264,
          26642,
          6405,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21555111020110373,
        "compression_ratio": 1.5076923076923077,
        "end": 7641.76,
        "id": 1920,
        "no_speech_prob": 0.0003199952479917556,
        "seek": 762676,
        "start": 7638.76,
        "temperature": 0,
        "text": " I just want to be able to operate it just myself.",
        "tokens": [
          50964,
          286,
          445,
          528,
          281,
          312,
          1075,
          281,
          9651,
          309,
          445,
          2059,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21555111020110373,
        "compression_ratio": 1.5076923076923077,
        "end": 7643.76,
        "id": 1921,
        "no_speech_prob": 0.0003199952479917556,
        "seek": 762676,
        "start": 7641.76,
        "temperature": 0,
        "text": " I think you'll all understand why.",
        "tokens": [
          51114,
          286,
          519,
          291,
          603,
          439,
          1223,
          983,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21555111020110373,
        "compression_ratio": 1.5076923076923077,
        "end": 7649.76,
        "id": 1922,
        "no_speech_prob": 0.0003199952479917556,
        "seek": 762676,
        "start": 7646.76,
        "temperature": 0,
        "text": " What's it called now? Runway ML template. Perfect.",
        "tokens": [
          51364,
          708,
          311,
          309,
          1219,
          586,
          30,
          8950,
          676,
          21601,
          12379,
          13,
          10246,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21555111020110373,
        "compression_ratio": 1.5076923076923077,
        "end": 7652.76,
        "id": 1923,
        "no_speech_prob": 0.0003199952479917556,
        "seek": 762676,
        "start": 7650.76,
        "temperature": 0,
        "text": " Let's open up the code.",
        "tokens": [
          51564,
          961,
          311,
          1269,
          493,
          264,
          3089,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16201683969208688,
        "compression_ratio": 1.5647668393782384,
        "end": 7661.76,
        "id": 1924,
        "no_speech_prob": 0.000129314445075579,
        "seek": 765676,
        "start": 7657.76,
        "temperature": 0,
        "text": " Here it is. I need to make a.env file.",
        "tokens": [
          50414,
          1692,
          309,
          307,
          13,
          286,
          643,
          281,
          652,
          257,
          2411,
          268,
          85,
          3991,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16201683969208688,
        "compression_ratio": 1.5647668393782384,
        "end": 7666.76,
        "id": 1925,
        "no_speech_prob": 0.000129314445075579,
        "seek": 765676,
        "start": 7663.76,
        "temperature": 0,
        "text": " If I look in here, the things that I need are...",
        "tokens": [
          50714,
          759,
          286,
          574,
          294,
          510,
          11,
          264,
          721,
          300,
          286,
          643,
          366,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.16201683969208688,
        "compression_ratio": 1.5647668393782384,
        "end": 7669.76,
        "id": 1926,
        "no_speech_prob": 0.000129314445075579,
        "seek": 765676,
        "start": 7666.76,
        "temperature": 0,
        "text": " I can not worry about the daily limit right now.",
        "tokens": [
          50864,
          286,
          393,
          406,
          3292,
          466,
          264,
          5212,
          4948,
          558,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16201683969208688,
        "compression_ratio": 1.5647668393782384,
        "end": 7674.76,
        "id": 1927,
        "no_speech_prob": 0.000129314445075579,
        "seek": 765676,
        "start": 7669.76,
        "temperature": 0,
        "text": " I'll just make it a thousand so that I have something in there.",
        "tokens": [
          51014,
          286,
          603,
          445,
          652,
          309,
          257,
          4714,
          370,
          300,
          286,
          362,
          746,
          294,
          456,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16201683969208688,
        "compression_ratio": 1.5647668393782384,
        "end": 7677.76,
        "id": 1928,
        "no_speech_prob": 0.000129314445075579,
        "seek": 765676,
        "start": 7674.76,
        "temperature": 0,
        "text": " I need to get a...",
        "tokens": [
          51264,
          286,
          643,
          281,
          483,
          257,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.16201683969208688,
        "compression_ratio": 1.5647668393782384,
        "end": 7683.76,
        "id": 1929,
        "no_speech_prob": 0.000129314445075579,
        "seek": 765676,
        "start": 7680.76,
        "temperature": 0,
        "text": " Where do I create the model? How come I don't see this?",
        "tokens": [
          51564,
          2305,
          360,
          286,
          1884,
          264,
          2316,
          30,
          1012,
          808,
          286,
          500,
          380,
          536,
          341,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.16201683969208688,
        "compression_ratio": 1.5647668393782384,
        "end": 7685.76,
        "id": 1930,
        "no_speech_prob": 0.000129314445075579,
        "seek": 765676,
        "start": 7683.76,
        "temperature": 0,
        "text": " I'm so blind. There it is.",
        "tokens": [
          51714,
          286,
          478,
          370,
          6865,
          13,
          821,
          309,
          307,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21380537033081054,
        "compression_ratio": 1.275,
        "end": 7687.76,
        "id": 1931,
        "no_speech_prob": 0.0001273096859222278,
        "seek": 768576,
        "start": 7685.76,
        "temperature": 0,
        "text": " Runway URL.",
        "tokens": [
          50364,
          8950,
          676,
          12905,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21380537033081054,
        "compression_ratio": 1.275,
        "end": 7695.76,
        "id": 1932,
        "no_speech_prob": 0.0001273096859222278,
        "seek": 768576,
        "start": 7689.76,
        "temperature": 0,
        "text": " Runway URL equals and runway token.",
        "tokens": [
          50564,
          8950,
          676,
          12905,
          6915,
          293,
          26642,
          14862,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21380537033081054,
        "compression_ratio": 1.275,
        "end": 7707.76,
        "id": 1933,
        "no_speech_prob": 0.0001273096859222278,
        "seek": 768576,
        "start": 7700.76,
        "temperature": 0,
        "text": " Let's go to runway and close all this stuff.",
        "tokens": [
          51114,
          961,
          311,
          352,
          281,
          26642,
          293,
          1998,
          439,
          341,
          1507,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21380537033081054,
        "compression_ratio": 1.275,
        "end": 7709.76,
        "id": 1934,
        "no_speech_prob": 0.0001273096859222278,
        "seek": 768576,
        "start": 7707.76,
        "temperature": 0,
        "text": " Oh, stop.",
        "tokens": [
          51464,
          876,
          11,
          1590,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21380537033081054,
        "compression_ratio": 1.275,
        "end": 7712.76,
        "id": 1935,
        "no_speech_prob": 0.0001273096859222278,
        "seek": 768576,
        "start": 7710.76,
        "temperature": 0,
        "text": " I was using up some credits there just running it.",
        "tokens": [
          51614,
          286,
          390,
          1228,
          493,
          512,
          16816,
          456,
          445,
          2614,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2528773964225472,
        "compression_ratio": 1.45625,
        "end": 7715.76,
        "id": 1936,
        "no_speech_prob": 0.003945348784327507,
        "seek": 771276,
        "start": 7712.76,
        "temperature": 0,
        "text": " Let's do network. Let's host this model.",
        "tokens": [
          50364,
          961,
          311,
          360,
          3209,
          13,
          961,
          311,
          3975,
          341,
          2316,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2528773964225472,
        "compression_ratio": 1.45625,
        "end": 7718.76,
        "id": 1937,
        "no_speech_prob": 0.003945348784327507,
        "seek": 771276,
        "start": 7716.76,
        "temperature": 0,
        "text": " Host model.",
        "tokens": [
          50564,
          22047,
          2316,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2528773964225472,
        "compression_ratio": 1.45625,
        "end": 7723.76,
        "id": 1938,
        "no_speech_prob": 0.003945348784327507,
        "seek": 771276,
        "start": 7720.76,
        "temperature": 0,
        "text": " I'm going to get the API key.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          483,
          264,
          9362,
          2141,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2528773964225472,
        "compression_ratio": 1.45625,
        "end": 7725.76,
        "id": 1939,
        "no_speech_prob": 0.003945348784327507,
        "seek": 771276,
        "start": 7723.76,
        "temperature": 0,
        "text": " Actually, let me...",
        "tokens": [
          50914,
          5135,
          11,
          718,
          385,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.2528773964225472,
        "compression_ratio": 1.45625,
        "end": 7730.76,
        "id": 1940,
        "no_speech_prob": 0.003945348784327507,
        "seek": 771276,
        "start": 7728.76,
        "temperature": 0,
        "text": " Where do I have...",
        "tokens": [
          51164,
          2305,
          360,
          286,
          362,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.2528773964225472,
        "compression_ratio": 1.45625,
        "end": 7733.76,
        "id": 1941,
        "no_speech_prob": 0.003945348784327507,
        "seek": 771276,
        "start": 7730.76,
        "temperature": 0,
        "text": " I wanted to just sort of test it with SkyGAN.",
        "tokens": [
          51264,
          286,
          1415,
          281,
          445,
          1333,
          295,
          1500,
          309,
          365,
          9879,
          27699,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2528773964225472,
        "compression_ratio": 1.45625,
        "end": 7737.76,
        "id": 1942,
        "no_speech_prob": 0.003945348784327507,
        "seek": 771276,
        "start": 7733.76,
        "temperature": 0,
        "text": " Let me just test this with SkyGAN just to make sure it's working.",
        "tokens": [
          51414,
          961,
          385,
          445,
          1500,
          341,
          365,
          9879,
          27699,
          445,
          281,
          652,
          988,
          309,
          311,
          1364,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2061362622389153,
        "compression_ratio": 1.4785714285714286,
        "end": 7745.76,
        "id": 1943,
        "no_speech_prob": 0.0000498595618410036,
        "seek": 773776,
        "start": 7738.76,
        "temperature": 0,
        "text": " Where do I go? Model, workspace, back to models, SkyGAN,",
        "tokens": [
          50414,
          2305,
          360,
          286,
          352,
          30,
          17105,
          11,
          32706,
          11,
          646,
          281,
          5245,
          11,
          9879,
          27699,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.2061362622389153,
        "compression_ratio": 1.4785714285714286,
        "end": 7752.76,
        "id": 1944,
        "no_speech_prob": 0.0000498595618410036,
        "seek": 773776,
        "start": 7745.76,
        "temperature": 0,
        "text": " SkyGAN, network, host this model, host this model.",
        "tokens": [
          50764,
          9879,
          27699,
          11,
          3209,
          11,
          3975,
          341,
          2316,
          11,
          3975,
          341,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2061362622389153,
        "compression_ratio": 1.4785714285714286,
        "end": 7759.76,
        "id": 1945,
        "no_speech_prob": 0.0000498595618410036,
        "seek": 773776,
        "start": 7753.76,
        "temperature": 0,
        "text": " I am going to grab the model URL, put it in the URL.",
        "tokens": [
          51164,
          286,
          669,
          516,
          281,
          4444,
          264,
          2316,
          12905,
          11,
          829,
          309,
          294,
          264,
          12905,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2061362622389153,
        "compression_ratio": 1.4785714285714286,
        "end": 7765.76,
        "id": 1946,
        "no_speech_prob": 0.0000498595618410036,
        "seek": 773776,
        "start": 7759.76,
        "temperature": 0,
        "text": " Then I'm going to grab the token, the API key.",
        "tokens": [
          51464,
          1396,
          286,
          478,
          516,
          281,
          4444,
          264,
          14862,
          11,
          264,
          9362,
          2141,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2073288374049689,
        "compression_ratio": 1.47979797979798,
        "end": 7767.76,
        "id": 1947,
        "no_speech_prob": 0.0005614764522761106,
        "seek": 776576,
        "start": 7765.76,
        "temperature": 0,
        "text": " I don't know why I call it runway token.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          983,
          286,
          818,
          309,
          26642,
          14862,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2073288374049689,
        "compression_ratio": 1.47979797979798,
        "end": 7769.76,
        "id": 1948,
        "no_speech_prob": 0.0005614764522761106,
        "seek": 776576,
        "start": 7767.76,
        "temperature": 0,
        "text": " I guess that makes sense. It's an API key.",
        "tokens": [
          50464,
          286,
          2041,
          300,
          1669,
          2020,
          13,
          467,
          311,
          364,
          9362,
          2141,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2073288374049689,
        "compression_ratio": 1.47979797979798,
        "end": 7776.76,
        "id": 1949,
        "no_speech_prob": 0.0005614764522761106,
        "seek": 776576,
        "start": 7769.76,
        "temperature": 0,
        "text": " I'm going to remove my screen, paste it in, hit save, hit close, and come back.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          4159,
          452,
          2568,
          11,
          9163,
          309,
          294,
          11,
          2045,
          3155,
          11,
          2045,
          1998,
          11,
          293,
          808,
          646,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2073288374049689,
        "compression_ratio": 1.47979797979798,
        "end": 7781.76,
        "id": 1950,
        "no_speech_prob": 0.0005614764522761106,
        "seek": 776576,
        "start": 7776.76,
        "temperature": 0,
        "text": " So I believe now if I were to run this...",
        "tokens": [
          50914,
          407,
          286,
          1697,
          586,
          498,
          286,
          645,
          281,
          1190,
          341,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2073288374049689,
        "compression_ratio": 1.47979797979798,
        "end": 7789.76,
        "id": 1951,
        "no_speech_prob": 0.0005614764522761106,
        "seek": 776576,
        "start": 7784.76,
        "temperature": 0,
        "text": " Oh, I guess I need to do npm install to install the node modules.",
        "tokens": [
          51314,
          876,
          11,
          286,
          2041,
          286,
          643,
          281,
          360,
          297,
          14395,
          3625,
          281,
          3625,
          264,
          9984,
          16679,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2073288374049689,
        "compression_ratio": 1.47979797979798,
        "end": 7793.76,
        "id": 1952,
        "no_speech_prob": 0.0005614764522761106,
        "seek": 776576,
        "start": 7791.76,
        "temperature": 0,
        "text": " Run the server. Nope.",
        "tokens": [
          51664,
          8950,
          264,
          7154,
          13,
          12172,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20197566350301108,
        "compression_ratio": 1.4054054054054055,
        "end": 7797.76,
        "id": 1953,
        "no_speech_prob": 0.0005033330526202917,
        "seek": 779376,
        "start": 7794.76,
        "temperature": 0,
        "text": " Writing out count, not a number.",
        "tokens": [
          50414,
          32774,
          484,
          1207,
          11,
          406,
          257,
          1230,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20197566350301108,
        "compression_ratio": 1.4054054054054055,
        "end": 7801.76,
        "id": 1954,
        "no_speech_prob": 0.0005033330526202917,
        "seek": 779376,
        "start": 7799.76,
        "temperature": 0,
        "text": " What's going on here?",
        "tokens": [
          50664,
          708,
          311,
          516,
          322,
          510,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.20197566350301108,
        "compression_ratio": 1.4054054054054055,
        "end": 7813.76,
        "id": 1955,
        "no_speech_prob": 0.0005033330526202917,
        "seek": 779376,
        "start": 7810.76,
        "temperature": 0,
        "text": " Count 100, writing out count, not a number.",
        "tokens": [
          51214,
          5247,
          2319,
          11,
          3579,
          484,
          1207,
          11,
          406,
          257,
          1230,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20197566350301108,
        "compression_ratio": 1.4054054054054055,
        "end": 7818.76,
        "id": 1956,
        "no_speech_prob": 0.0005033330526202917,
        "seek": 779376,
        "start": 7814.76,
        "temperature": 0,
        "text": " Check day. Oh, I forgot about this whole check day thing.",
        "tokens": [
          51414,
          6881,
          786,
          13,
          876,
          11,
          286,
          5298,
          466,
          341,
          1379,
          1520,
          786,
          551,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20519086111963322,
        "compression_ratio": 1.75,
        "end": 7826.76,
        "id": 1957,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 782376,
        "start": 7823.76,
        "temperature": 0,
        "text": " This is weird. I don't really care about this right now.",
        "tokens": [
          50364,
          639,
          307,
          3657,
          13,
          286,
          500,
          380,
          534,
          1127,
          466,
          341,
          558,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20519086111963322,
        "compression_ratio": 1.75,
        "end": 7829.76,
        "id": 1958,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 782376,
        "start": 7826.76,
        "temperature": 0,
        "text": " So I'm just going to comment this out. I don't know why that's not working.",
        "tokens": [
          50514,
          407,
          286,
          478,
          445,
          516,
          281,
          2871,
          341,
          484,
          13,
          286,
          500,
          380,
          458,
          983,
          300,
          311,
          406,
          1364,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20519086111963322,
        "compression_ratio": 1.75,
        "end": 7832.76,
        "id": 1959,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 782376,
        "start": 7829.76,
        "temperature": 0,
        "text": " I have a thing that I wrote that it resets the count every day.",
        "tokens": [
          50664,
          286,
          362,
          257,
          551,
          300,
          286,
          4114,
          300,
          309,
          725,
          1385,
          264,
          1207,
          633,
          786,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20519086111963322,
        "compression_ratio": 1.75,
        "end": 7835.76,
        "id": 1960,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 782376,
        "start": 7832.76,
        "temperature": 0,
        "text": " So my rate limiting is like 100 requests per day.",
        "tokens": [
          50814,
          407,
          452,
          3314,
          22083,
          307,
          411,
          2319,
          12475,
          680,
          786,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20519086111963322,
        "compression_ratio": 1.75,
        "end": 7841.76,
        "id": 1961,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 782376,
        "start": 7835.76,
        "temperature": 0,
        "text": " But I'm just going to comment this out because I don't really need to worry about the rate limiting right now.",
        "tokens": [
          50964,
          583,
          286,
          478,
          445,
          516,
          281,
          2871,
          341,
          484,
          570,
          286,
          500,
          380,
          534,
          643,
          281,
          3292,
          466,
          264,
          3314,
          22083,
          558,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20519086111963322,
        "compression_ratio": 1.75,
        "end": 7850.76,
        "id": 1962,
        "no_speech_prob": 0.00003219227437512018,
        "seek": 782376,
        "start": 7847.76,
        "temperature": 0,
        "text": " URL provide is not... Your hosted model must be in the format.",
        "tokens": [
          51564,
          12905,
          2893,
          307,
          406,
          485,
          2260,
          19204,
          2316,
          1633,
          312,
          294,
          264,
          7877,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7858.76,
        "id": 1963,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7851.76,
        "temperature": 0,
        "text": " I think I did something wrong with getting the hosted model.",
        "tokens": [
          50414,
          286,
          519,
          286,
          630,
          746,
          2085,
          365,
          1242,
          264,
          19204,
          2316,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7860.76,
        "id": 1964,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7858.76,
        "temperature": 0,
        "text": " So hold on, people.",
        "tokens": [
          50764,
          407,
          1797,
          322,
          11,
          561,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7864.76,
        "id": 1965,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7861.76,
        "temperature": 0,
        "text": " Going back to here, looking at my.env file.",
        "tokens": [
          50914,
          10963,
          646,
          281,
          510,
          11,
          1237,
          412,
          452,
          2411,
          268,
          85,
          3991,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7866.76,
        "id": 1966,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7864.76,
        "temperature": 0,
        "text": " Oh, I know what the problem is.",
        "tokens": [
          51064,
          876,
          11,
          286,
          458,
          437,
          264,
          1154,
          307,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7868.76,
        "id": 1967,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7866.76,
        "temperature": 0,
        "text": " I know what the problem is.",
        "tokens": [
          51164,
          286,
          458,
          437,
          264,
          1154,
          307,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7871.76,
        "id": 1968,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7868.76,
        "temperature": 0,
        "text": " Nobody has actually... Did I actually figure it out before the chat did?",
        "tokens": [
          51264,
          9297,
          575,
          767,
          485,
          2589,
          286,
          767,
          2573,
          309,
          484,
          949,
          264,
          5081,
          630,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7873.76,
        "id": 1969,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7871.76,
        "temperature": 0,
        "text": " Oh, how exciting.",
        "tokens": [
          51414,
          876,
          11,
          577,
          4670,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7877.76,
        "id": 1970,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7873.76,
        "temperature": 0,
        "text": " So let me close the.env file.",
        "tokens": [
          51514,
          407,
          718,
          385,
          1998,
          264,
          2411,
          268,
          85,
          3991,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17659594711748142,
        "compression_ratio": 1.6482412060301508,
        "end": 7878.76,
        "id": 1971,
        "no_speech_prob": 0.0020189713686704636,
        "seek": 785076,
        "start": 7877.76,
        "temperature": 0,
        "text": " So here's the problem.",
        "tokens": [
          51714,
          407,
          510,
          311,
          264,
          1154,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1776120112492488,
        "compression_ratio": 1.5789473684210527,
        "end": 7886.76,
        "id": 1972,
        "no_speech_prob": 0.016914241015911102,
        "seek": 787876,
        "start": 7878.76,
        "temperature": 0,
        "text": " The problem is loading the information from the.env file works out of the box on Glitch.",
        "tokens": [
          50364,
          440,
          1154,
          307,
          15114,
          264,
          1589,
          490,
          264,
          2411,
          268,
          85,
          3991,
          1985,
          484,
          295,
          264,
          2424,
          322,
          5209,
          1549,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1776120112492488,
        "compression_ratio": 1.5789473684210527,
        "end": 7888.76,
        "id": 1973,
        "no_speech_prob": 0.016914241015911102,
        "seek": 787876,
        "start": 7886.76,
        "temperature": 0,
        "text": " Glitch is set up to know about it automatically.",
        "tokens": [
          50764,
          5209,
          1549,
          307,
          992,
          493,
          281,
          458,
          466,
          309,
          6772,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1776120112492488,
        "compression_ratio": 1.5789473684210527,
        "end": 7892.76,
        "id": 1974,
        "no_speech_prob": 0.016914241015911102,
        "seek": 787876,
        "start": 7888.76,
        "temperature": 0,
        "text": " But I need to use the.env package.",
        "tokens": [
          50864,
          583,
          286,
          643,
          281,
          764,
          264,
          2411,
          268,
          85,
          7372,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1776120112492488,
        "compression_ratio": 1.5789473684210527,
        "end": 7900.76,
        "id": 1975,
        "no_speech_prob": 0.016914241015911102,
        "seek": 787876,
        "start": 7894.76,
        "temperature": 0,
        "text": " The.env file will only be loaded if I require the npm package.env and call the config function.",
        "tokens": [
          51164,
          440,
          2411,
          268,
          85,
          3991,
          486,
          787,
          312,
          13210,
          498,
          286,
          3651,
          264,
          297,
          14395,
          7372,
          2411,
          268,
          85,
          293,
          818,
          264,
          6662,
          2445,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1776120112492488,
        "compression_ratio": 1.5789473684210527,
        "end": 7905.76,
        "id": 1976,
        "no_speech_prob": 0.016914241015911102,
        "seek": 787876,
        "start": 7900.76,
        "temperature": 0,
        "text": " So I should say node npm i.env.",
        "tokens": [
          51464,
          407,
          286,
          820,
          584,
          9984,
          297,
          14395,
          741,
          13,
          268,
          85,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7909.76,
        "id": 1977,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7908.76,
        "temperature": 0,
        "text": " So I have that now.",
        "tokens": [
          50364,
          407,
          286,
          362,
          300,
          586,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7911.76,
        "id": 1978,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7909.76,
        "temperature": 0,
        "text": " And now I should be able to say...",
        "tokens": [
          50414,
          400,
          586,
          286,
          820,
          312,
          1075,
          281,
          584,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7913.76,
        "id": 1979,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7911.76,
        "temperature": 0,
        "text": " Node server.",
        "tokens": [
          50514,
          38640,
          7154,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7915.76,
        "id": 1980,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7913.76,
        "temperature": 0,
        "text": " What's this shrink wrap thing?",
        "tokens": [
          50614,
          708,
          311,
          341,
          23060,
          7019,
          551,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7916.76,
        "id": 1981,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7915.76,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          50714,
          1033,
          11,
          869,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7919.76,
        "id": 1982,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7916.76,
        "temperature": 0,
        "text": " So the app is going.",
        "tokens": [
          50764,
          407,
          264,
          724,
          307,
          516,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7921.76,
        "id": 1983,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7919.76,
        "temperature": 0,
        "text": " And it's listening on port.",
        "tokens": [
          50914,
          400,
          309,
          311,
          4764,
          322,
          2436,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7924.76,
        "id": 1984,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7922.76,
        "temperature": 0,
        "text": " I guess I...",
        "tokens": [
          51064,
          286,
          2041,
          286,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7926.76,
        "id": 1985,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7924.76,
        "temperature": 0,
        "text": " Why did it pick that port?",
        "tokens": [
          51164,
          1545,
          630,
          309,
          1888,
          300,
          2436,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7930.76,
        "id": 1986,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7926.76,
        "temperature": 0,
        "text": " I guess there's some weird things I have to change when I'm doing this locally.",
        "tokens": [
          51264,
          286,
          2041,
          456,
          311,
          512,
          3657,
          721,
          286,
          362,
          281,
          1319,
          562,
          286,
          478,
          884,
          341,
          16143,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7932.76,
        "id": 1987,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7930.76,
        "temperature": 0,
        "text": " Process.env port.",
        "tokens": [
          51464,
          31093,
          13,
          268,
          85,
          2436,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19831009872821198,
        "compression_ratio": 1.5565610859728507,
        "end": 7936.76,
        "id": 1988,
        "no_speech_prob": 0.003483165754005313,
        "seek": 790876,
        "start": 7932.76,
        "temperature": 0,
        "text": " Oh, well, I want to put this in the.env file.",
        "tokens": [
          51564,
          876,
          11,
          731,
          11,
          286,
          528,
          281,
          829,
          341,
          294,
          264,
          2411,
          268,
          85,
          3991,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7938.76,
        "id": 1989,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7937.76,
        "temperature": 0,
        "text": " But I have to...",
        "tokens": [
          50414,
          583,
          286,
          362,
          281,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7942.76,
        "id": 1990,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7938.76,
        "temperature": 0,
        "text": " Every time I look at the.env file, it's like danger, danger, Will Robinson.",
        "tokens": [
          50464,
          2048,
          565,
          286,
          574,
          412,
          264,
          2411,
          268,
          85,
          3991,
          11,
          309,
          311,
          411,
          4330,
          11,
          4330,
          11,
          3099,
          25105,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7945.76,
        "id": 1991,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7944.76,
        "temperature": 0,
        "text": " Port.",
        "tokens": [
          50764,
          6733,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7947.76,
        "id": 1992,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7945.76,
        "temperature": 0,
        "text": " I'll just do 3,000.",
        "tokens": [
          50814,
          286,
          603,
          445,
          360,
          805,
          11,
          1360,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7950.76,
        "id": 1993,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7948.76,
        "temperature": 0,
        "text": " Close that.",
        "tokens": [
          50964,
          16346,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7952.76,
        "id": 1994,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7951.76,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51114,
          400,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7958.76,
        "id": 1995,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7954.76,
        "temperature": 0,
        "text": " Okay, so I should be able to go to localhost 3000.",
        "tokens": [
          51264,
          1033,
          11,
          370,
          286,
          820,
          312,
          1075,
          281,
          352,
          281,
          2654,
          6037,
          20984,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7961.76,
        "id": 1996,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7959.76,
        "temperature": 0,
        "text": " And click generate.",
        "tokens": [
          51514,
          400,
          2052,
          8460,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7963.76,
        "id": 1997,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7961.76,
        "temperature": 0,
        "text": " Oh, it's doing it already.",
        "tokens": [
          51614,
          876,
          11,
          309,
          311,
          884,
          309,
          1217,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18653711017809416,
        "compression_ratio": 1.3556701030927836,
        "end": 7965.76,
        "id": 1998,
        "no_speech_prob": 0.0005033263005316257,
        "seek": 793676,
        "start": 7963.76,
        "temperature": 0,
        "text": " Let's make sure this works.",
        "tokens": [
          51714,
          961,
          311,
          652,
          988,
          341,
          1985,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7969.76,
        "id": 1999,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7967.76,
        "temperature": 0,
        "text": " Great, I got my SkyGAN.",
        "tokens": [
          50414,
          3769,
          11,
          286,
          658,
          452,
          9879,
          27699,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7971.76,
        "id": 2000,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7970.76,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          50564,
          400,
          574,
          412,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7973.76,
        "id": 2001,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7971.76,
        "temperature": 0,
        "text": " The count is just going up by one each time.",
        "tokens": [
          50614,
          440,
          1207,
          307,
          445,
          516,
          493,
          538,
          472,
          1184,
          565,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7977.76,
        "id": 2002,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7973.76,
        "temperature": 0,
        "text": " Because nobody else can run this but me!",
        "tokens": [
          50714,
          1436,
          5079,
          1646,
          393,
          1190,
          341,
          457,
          385,
          0,
          50914
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7979.76,
        "id": 2003,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7977.76,
        "temperature": 0,
        "text": " Ha ha!",
        "tokens": [
          50914,
          4064,
          324,
          0,
          51014
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7984.76,
        "id": 2004,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7979.76,
        "temperature": 0,
        "text": " So let's now change this over to using the object detection model.",
        "tokens": [
          51014,
          407,
          718,
          311,
          586,
          1319,
          341,
          670,
          281,
          1228,
          264,
          2657,
          17784,
          2316,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7985.76,
        "id": 2005,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7984.76,
        "temperature": 0,
        "text": " Woo!",
        "tokens": [
          51264,
          10468,
          0,
          51314
        ]
      },
      {
        "avg_logprob": -0.2746025876301091,
        "compression_ratio": 1.335164835164835,
        "end": 7991.76,
        "id": 2006,
        "no_speech_prob": 0.00007368544902419671,
        "seek": 796676,
        "start": 7988.76,
        "temperature": 0,
        "text": " So I am going to go to my p5 sketch.",
        "tokens": [
          51464,
          407,
          286,
          669,
          516,
          281,
          352,
          281,
          452,
          280,
          20,
          12325,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3130585564507378,
        "compression_ratio": 1.2210526315789474,
        "end": 7996.76,
        "id": 2007,
        "no_speech_prob": 0.0016228918684646487,
        "seek": 799176,
        "start": 7992.76,
        "temperature": 0,
        "text": " I am going to say let video.",
        "tokens": [
          50414,
          286,
          669,
          516,
          281,
          584,
          718,
          960,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3130585564507378,
        "compression_ratio": 1.2210526315789474,
        "end": 8002.76,
        "id": 2008,
        "no_speech_prob": 0.0016228918684646487,
        "seek": 799176,
        "start": 7998.76,
        "temperature": 0,
        "text": " Video equals create capture video.",
        "tokens": [
          50714,
          9777,
          6915,
          1884,
          7983,
          960,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3130585564507378,
        "compression_ratio": 1.2210526315789474,
        "end": 8004.76,
        "id": 2009,
        "no_speech_prob": 0.0016228918684646487,
        "seek": 799176,
        "start": 8003.76,
        "temperature": 0,
        "text": " Then...",
        "tokens": [
          50964,
          1396,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.3130585564507378,
        "compression_ratio": 1.2210526315789474,
        "end": 8010.76,
        "id": 2010,
        "no_speech_prob": 0.0016228918684646487,
        "seek": 799176,
        "start": 8008.76,
        "temperature": 0,
        "text": " Video.hide.",
        "tokens": [
          51214,
          9777,
          13,
          71,
          482,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3130585564507378,
        "compression_ratio": 1.2210526315789474,
        "end": 8013.76,
        "id": 2011,
        "no_speech_prob": 0.0016228918684646487,
        "seek": 799176,
        "start": 8011.76,
        "temperature": 0,
        "text": " Function draw.",
        "tokens": [
          51364,
          11166,
          882,
          2642,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3130585564507378,
        "compression_ratio": 1.2210526315789474,
        "end": 8018.76,
        "id": 2012,
        "no_speech_prob": 0.0016228918684646487,
        "seek": 799176,
        "start": 8014.76,
        "temperature": 0,
        "text": " Image video 0, 0.",
        "tokens": [
          51514,
          29903,
          960,
          1958,
          11,
          1958,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8019.76,
        "id": 2013,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8018.76,
        "temperature": 0,
        "text": " 0, 0.",
        "tokens": [
          50364,
          1958,
          11,
          1958,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8022.76,
        "id": 2014,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8019.76,
        "temperature": 0,
        "text": " And width height.",
        "tokens": [
          50414,
          400,
          11402,
          6681,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8028.76,
        "id": 2015,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8025.76,
        "temperature": 0,
        "text": " So let's not worry about send vector.",
        "tokens": [
          50714,
          407,
          718,
          311,
          406,
          3292,
          466,
          2845,
          8062,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8030.76,
        "id": 2016,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8028.76,
        "temperature": 0,
        "text": " Or calling that right now.",
        "tokens": [
          50864,
          1610,
          5141,
          300,
          558,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8032.76,
        "id": 2017,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8030.76,
        "temperature": 0,
        "text": " Or the...",
        "tokens": [
          50964,
          1610,
          264,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8035.76,
        "id": 2018,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8032.76,
        "temperature": 0,
        "text": " I am going to keep the generate button in there right now.",
        "tokens": [
          51064,
          286,
          669,
          516,
          281,
          1066,
          264,
          8460,
          2960,
          294,
          456,
          558,
          586,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8038.76,
        "id": 2019,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8037.76,
        "temperature": 0,
        "text": " Allow.",
        "tokens": [
          51314,
          32225,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8040.76,
        "id": 2020,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8038.76,
        "temperature": 0,
        "text": " And of course we have the OBS virtual camera.",
        "tokens": [
          51364,
          400,
          295,
          1164,
          321,
          362,
          264,
          422,
          8176,
          6374,
          2799,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8042.76,
        "id": 2021,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8040.76,
        "temperature": 0,
        "text": " I will switch this.",
        "tokens": [
          51464,
          286,
          486,
          3679,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8044.76,
        "id": 2022,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8042.76,
        "temperature": 0,
        "text": " I can just do it like this.",
        "tokens": [
          51564,
          286,
          393,
          445,
          360,
          309,
          411,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24242905896119396,
        "compression_ratio": 1.515,
        "end": 8047.76,
        "id": 2023,
        "no_speech_prob": 0.02479449100792408,
        "seek": 801876,
        "start": 8044.76,
        "temperature": 0,
        "text": " Why do I have to do this always and forever?",
        "tokens": [
          51664,
          1545,
          360,
          286,
          362,
          281,
          360,
          341,
          1009,
          293,
          5680,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8050.76,
        "id": 2024,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8048.76,
        "temperature": 0,
        "text": " Okay, I have got my video showing up there.",
        "tokens": [
          50364,
          1033,
          11,
          286,
          362,
          658,
          452,
          960,
          4099,
          493,
          456,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8051.76,
        "id": 2025,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8050.76,
        "temperature": 0,
        "text": " Next up.",
        "tokens": [
          50464,
          3087,
          493,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8053.76,
        "id": 2026,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8051.76,
        "temperature": 0,
        "text": " This is all the same that I already did.",
        "tokens": [
          50514,
          639,
          307,
          439,
          264,
          912,
          300,
          286,
          1217,
          630,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8054.76,
        "id": 2027,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8053.76,
        "temperature": 0,
        "text": " I should go grab...",
        "tokens": [
          50614,
          286,
          820,
          352,
          4444,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8056.76,
        "id": 2028,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8054.76,
        "temperature": 0,
        "text": " Actually, I am going to do that.",
        "tokens": [
          50664,
          5135,
          11,
          286,
          669,
          516,
          281,
          360,
          300,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8059.76,
        "id": 2029,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8056.76,
        "temperature": 0,
        "text": " Let's go back to the glitch project.",
        "tokens": [
          50764,
          961,
          311,
          352,
          646,
          281,
          264,
          23552,
          1716,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8062.76,
        "id": 2030,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8060.76,
        "temperature": 0,
        "text": " That I was working on.",
        "tokens": [
          50964,
          663,
          286,
          390,
          1364,
          322,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8064.76,
        "id": 2031,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8062.76,
        "temperature": 0,
        "text": " Spade cocoa.",
        "tokens": [
          51064,
          1738,
          762,
          30634,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8065.76,
        "id": 2032,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8064.76,
        "temperature": 0,
        "text": " Choo choo coding...",
        "tokens": [
          51164,
          761,
          1986,
          1586,
          78,
          17720,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8067.76,
        "id": 2033,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8065.76,
        "temperature": 0,
        "text": " Spade cocoa.",
        "tokens": [
          51214,
          1738,
          762,
          30634,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8068.76,
        "id": 2034,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8067.76,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51314,
          20558,
          0,
          51364
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8069.76,
        "id": 2035,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8068.76,
        "temperature": 0,
        "text": " Train choo choo!",
        "tokens": [
          51364,
          28029,
          1586,
          78,
          1586,
          78,
          0,
          51414
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8073.76,
        "id": 2036,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8071.76,
        "temperature": 0,
        "text": " Let's grab this.",
        "tokens": [
          51514,
          961,
          311,
          4444,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23974456787109374,
        "compression_ratio": 1.5294117647058822,
        "end": 8077.76,
        "id": 2037,
        "no_speech_prob": 0.00010720809950726107,
        "seek": 804876,
        "start": 8073.76,
        "temperature": 0,
        "text": " This is a much better function for me to use.",
        "tokens": [
          51614,
          639,
          307,
          257,
          709,
          1101,
          2445,
          337,
          385,
          281,
          764,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8082.76,
        "id": 2038,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8079.76,
        "temperature": 0,
        "text": " As my basis.",
        "tokens": [
          50414,
          1018,
          452,
          5143,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8087.76,
        "id": 2039,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8084.76,
        "temperature": 0,
        "text": " Now, I don't know.",
        "tokens": [
          50664,
          823,
          11,
          286,
          500,
          380,
          458,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8089.76,
        "id": 2040,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8087.76,
        "temperature": 0,
        "text": " I don't believe it is called semantic map.",
        "tokens": [
          50814,
          286,
          500,
          380,
          1697,
          309,
          307,
          1219,
          47982,
          4471,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8091.76,
        "id": 2041,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8089.76,
        "temperature": 0,
        "text": " My guess is it is called image.",
        "tokens": [
          50914,
          1222,
          2041,
          307,
          309,
          307,
          1219,
          3256,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8095.76,
        "id": 2042,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8091.76,
        "temperature": 0,
        "text": " And what is coming back is not an image.",
        "tokens": [
          51014,
          400,
          437,
          307,
          1348,
          646,
          307,
          406,
          364,
          3256,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8097.76,
        "id": 2043,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8095.76,
        "temperature": 0,
        "text": " So I can get rid of that.",
        "tokens": [
          51214,
          407,
          286,
          393,
          483,
          3973,
          295,
          300,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8099.76,
        "id": 2044,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8097.76,
        "temperature": 0,
        "text": " Let's take a look at what comes back.",
        "tokens": [
          51314,
          961,
          311,
          747,
          257,
          574,
          412,
          437,
          1487,
          646,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8103.76,
        "id": 2045,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8099.76,
        "temperature": 0,
        "text": " So I am just guessing that this is what I am supposed to send to runway.",
        "tokens": [
          51414,
          407,
          286,
          669,
          445,
          17939,
          300,
          341,
          307,
          437,
          286,
          669,
          3442,
          281,
          2845,
          281,
          26642,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18240496317545574,
        "compression_ratio": 1.5776699029126213,
        "end": 8105.76,
        "id": 2046,
        "no_speech_prob": 0.0000888801077962853,
        "seek": 807876,
        "start": 8103.76,
        "temperature": 0,
        "text": " The other thing I need to do, of course.",
        "tokens": [
          51614,
          440,
          661,
          551,
          286,
          643,
          281,
          360,
          11,
          295,
          1164,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8108.76,
        "id": 2047,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8106.76,
        "temperature": 0,
        "text": " Is go to my hosted models.",
        "tokens": [
          50414,
          1119,
          352,
          281,
          452,
          19204,
          5245,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8115.76,
        "id": 2048,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8108.76,
        "temperature": 0,
        "text": " And check and get the Rubik's Cube URL.",
        "tokens": [
          50514,
          400,
          1520,
          293,
          483,
          264,
          10518,
          1035,
          311,
          33003,
          12905,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8118.76,
        "id": 2049,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8115.76,
        "temperature": 0,
        "text": " Now, I have got to go back to my.env file again.",
        "tokens": [
          50864,
          823,
          11,
          286,
          362,
          658,
          281,
          352,
          646,
          281,
          452,
          2411,
          268,
          85,
          3991,
          797,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8119.76,
        "id": 2050,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8118.76,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51014,
          4919,
          11,
          2201,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8122.76,
        "id": 2051,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8119.76,
        "temperature": 0,
        "text": " I am going to the.env file.",
        "tokens": [
          51064,
          286,
          669,
          516,
          281,
          264,
          2411,
          268,
          85,
          3991,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8126.76,
        "id": 2052,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8125.76,
        "temperature": 0,
        "text": ".env file.",
        "tokens": [
          51364,
          2411,
          268,
          85,
          3991,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8128.76,
        "id": 2053,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8126.76,
        "temperature": 0,
        "text": " Now, I am going back to runway.",
        "tokens": [
          51414,
          823,
          11,
          286,
          669,
          516,
          646,
          281,
          26642,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8130.76,
        "id": 2054,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8128.76,
        "temperature": 0,
        "text": " I am getting the API key.",
        "tokens": [
          51514,
          286,
          669,
          1242,
          264,
          9362,
          2141,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24474708632667466,
        "compression_ratio": 1.6265060240963856,
        "end": 8134.76,
        "id": 2055,
        "no_speech_prob": 0.01282054465264082,
        "seek": 810576,
        "start": 8130.76,
        "temperature": 0,
        "text": " I am putting the API key in my.env file.",
        "tokens": [
          51614,
          286,
          669,
          3372,
          264,
          9362,
          2141,
          294,
          452,
          2411,
          268,
          85,
          3991,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8137.76,
        "id": 2056,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8135.76,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          50364,
          821,
          309,
          307,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8141.76,
        "id": 2057,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8137.76,
        "temperature": 0,
        "text": " And now, I am going back to sketch.js.",
        "tokens": [
          50464,
          400,
          586,
          11,
          286,
          669,
          516,
          646,
          281,
          12325,
          13,
          25530,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8143.76,
        "id": 2058,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8141.76,
        "temperature": 0,
        "text": " Closing the.env file.",
        "tokens": [
          50664,
          2033,
          6110,
          264,
          2411,
          268,
          85,
          3991,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8146.76,
        "id": 2059,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8143.76,
        "temperature": 0,
        "text": " Excellent.",
        "tokens": [
          50764,
          16723,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8155.76,
        "id": 2060,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8146.76,
        "temperature": 0,
        "text": " And I think I should be able to say let's do, let's create button like detect.",
        "tokens": [
          50914,
          400,
          286,
          519,
          286,
          820,
          312,
          1075,
          281,
          584,
          718,
          311,
          360,
          11,
          718,
          311,
          1884,
          2960,
          411,
          5531,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8159.76,
        "id": 2061,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8157.76,
        "temperature": 0,
        "text": " Let's call this object detect.",
        "tokens": [
          51464,
          961,
          311,
          818,
          341,
          2657,
          5531,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8162.76,
        "id": 2062,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8159.76,
        "temperature": 0,
        "text": " And then call this object detect.",
        "tokens": [
          51564,
          400,
          550,
          818,
          341,
          2657,
          5531,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21280795203314887,
        "compression_ratio": 1.5310734463276836,
        "end": 8164.76,
        "id": 2063,
        "no_speech_prob": 0.00003219220889150165,
        "seek": 813576,
        "start": 8162.76,
        "temperature": 0,
        "text": " So I am not 100% sure this is all correct.",
        "tokens": [
          51714,
          407,
          286,
          669,
          406,
          2319,
          4,
          988,
          341,
          307,
          439,
          3006,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8172.76,
        "id": 2064,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8164.76,
        "temperature": 0,
        "text": " But in theory, when I press the button, it will send the image of the video to runway.",
        "tokens": [
          50364,
          583,
          294,
          5261,
          11,
          562,
          286,
          1886,
          264,
          2960,
          11,
          309,
          486,
          2845,
          264,
          3256,
          295,
          264,
          960,
          281,
          26642,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8174.76,
        "id": 2065,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8172.76,
        "temperature": 0,
        "text": " The Node server will manage that.",
        "tokens": [
          50764,
          440,
          38640,
          7154,
          486,
          3067,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8179.76,
        "id": 2066,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8174.76,
        "temperature": 0,
        "text": " And give me back the outputs which presumably would have the label of the thing it found.",
        "tokens": [
          50864,
          400,
          976,
          385,
          646,
          264,
          23930,
          597,
          26742,
          576,
          362,
          264,
          7645,
          295,
          264,
          551,
          309,
          1352,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8181.76,
        "id": 2067,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8179.76,
        "temperature": 0,
        "text": " The XY width height.",
        "tokens": [
          51114,
          440,
          48826,
          11402,
          6681,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8183.76,
        "id": 2068,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8181.76,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51214,
          961,
          311,
          536,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8185.76,
        "id": 2069,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8183.76,
        "temperature": 0,
        "text": " So I need to go to here.",
        "tokens": [
          51314,
          407,
          286,
          643,
          281,
          352,
          281,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8187.76,
        "id": 2070,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8185.76,
        "temperature": 0,
        "text": " Hit refresh.",
        "tokens": [
          51414,
          9217,
          15134,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22375335693359374,
        "compression_ratio": 1.4705882352941178,
        "end": 8192.76,
        "id": 2071,
        "no_speech_prob": 0.0010987247806042433,
        "seek": 816476,
        "start": 8190.76,
        "temperature": 0,
        "text": " Let's hold this up.",
        "tokens": [
          51664,
          961,
          311,
          1797,
          341,
          493,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8197.76,
        "id": 2072,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8193.76,
        "temperature": 0,
        "text": " Cannot read property to your data URL of undefined.",
        "tokens": [
          50414,
          29866,
          310,
          1401,
          4707,
          281,
          428,
          1412,
          12905,
          295,
          674,
          5666,
          2001,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8200.76,
        "id": 2073,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8197.76,
        "temperature": 0,
        "text": " I didn't check what I was doing here.",
        "tokens": [
          50614,
          286,
          994,
          380,
          1520,
          437,
          286,
          390,
          884,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8201.76,
        "id": 2074,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8200.76,
        "temperature": 0,
        "text": " What am I reading?",
        "tokens": [
          50764,
          708,
          669,
          286,
          3760,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8202.76,
        "id": 2075,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8201.76,
        "temperature": 0,
        "text": " Canvas.",
        "tokens": [
          50814,
          25725,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8205.76,
        "id": 2076,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8202.76,
        "temperature": 0,
        "text": " So actually, this should be the video.",
        "tokens": [
          50864,
          407,
          767,
          11,
          341,
          820,
          312,
          264,
          960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8211.76,
        "id": 2077,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8205.76,
        "temperature": 0,
        "text": " I want to take the video and turn that into data URL and send it.",
        "tokens": [
          51014,
          286,
          528,
          281,
          747,
          264,
          960,
          293,
          1261,
          300,
          666,
          1412,
          12905,
          293,
          2845,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8214.76,
        "id": 2078,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8211.76,
        "temperature": 0,
        "text": " So this is a case where I don't want to send the canvas.",
        "tokens": [
          51314,
          407,
          341,
          307,
          257,
          1389,
          689,
          286,
          500,
          380,
          528,
          281,
          2845,
          264,
          16267,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1989695490623007,
        "compression_ratio": 1.5560975609756098,
        "end": 8217.76,
        "id": 2079,
        "no_speech_prob": 0.003075237851589918,
        "seek": 819276,
        "start": 8214.76,
        "temperature": 0,
        "text": " So hopefully, that's all I needed to do.",
        "tokens": [
          51464,
          407,
          4696,
          11,
          300,
          311,
          439,
          286,
          2978,
          281,
          360,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8223.76,
        "id": 2080,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8222.76,
        "temperature": 0,
        "text": " There's an error.",
        "tokens": [
          50364,
          821,
          311,
          364,
          6713,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8224.76,
        "id": 2081,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8223.76,
        "temperature": 0,
        "text": " To data URL could not be function.",
        "tokens": [
          50414,
          1407,
          1412,
          12905,
          727,
          406,
          312,
          2445,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8226.76,
        "id": 2082,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8224.76,
        "temperature": 0,
        "text": " You know what it is.",
        "tokens": [
          50464,
          509,
          458,
          437,
          309,
          307,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8228.76,
        "id": 2083,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8226.76,
        "temperature": 0,
        "text": " Video canvas.",
        "tokens": [
          50564,
          9777,
          16267,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8231.76,
        "id": 2084,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8228.76,
        "temperature": 0,
        "text": " And I probably have to say video load pixels.",
        "tokens": [
          50664,
          400,
          286,
          1391,
          362,
          281,
          584,
          960,
          3677,
          18668,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8236.76,
        "id": 2085,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8231.76,
        "temperature": 0,
        "text": " I think in order to turn it into a data URL, I need to not look at the DOM element.",
        "tokens": [
          50814,
          286,
          519,
          294,
          1668,
          281,
          1261,
          309,
          666,
          257,
          1412,
          12905,
          11,
          286,
          643,
          281,
          406,
          574,
          412,
          264,
          35727,
          4478,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8241.76,
        "id": 2086,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8236.76,
        "temperature": 0,
        "text": " But the canvas associated with the DOM element that has the pixel data loaded on it.",
        "tokens": [
          51064,
          583,
          264,
          16267,
          6615,
          365,
          264,
          35727,
          4478,
          300,
          575,
          264,
          19261,
          1412,
          13210,
          322,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8242.76,
        "id": 2087,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8241.76,
        "temperature": 0,
        "text": " I think.",
        "tokens": [
          51314,
          286,
          519,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8244.76,
        "id": 2088,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8242.76,
        "temperature": 0,
        "text": " We'll find out.",
        "tokens": [
          51364,
          492,
          603,
          915,
          484,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8247.76,
        "id": 2089,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8244.76,
        "temperature": 0,
        "text": " I'll try it without load pixels in a second.",
        "tokens": [
          51464,
          286,
          603,
          853,
          309,
          1553,
          3677,
          18668,
          294,
          257,
          1150,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8248.76,
        "id": 2090,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8247.76,
        "temperature": 0,
        "text": " Detect.",
        "tokens": [
          51614,
          4237,
          557,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2133112820712003,
        "compression_ratio": 1.6150627615062763,
        "end": 8249.76,
        "id": 2091,
        "no_speech_prob": 0.02716843970119953,
        "seek": 822276,
        "start": 8248.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2459214596038169,
        "compression_ratio": 1.2035398230088497,
        "end": 8251.76,
        "id": 2092,
        "no_speech_prob": 0.0023231576196849346,
        "seek": 824976,
        "start": 8250.76,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50414,
          3153,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2459214596038169,
        "compression_ratio": 1.2035398230088497,
        "end": 8253.76,
        "id": 2093,
        "no_speech_prob": 0.0023231576196849346,
        "seek": 824976,
        "start": 8251.76,
        "temperature": 0,
        "text": " It froze everything up.",
        "tokens": [
          50464,
          467,
          46077,
          1203,
          493,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2459214596038169,
        "compression_ratio": 1.2035398230088497,
        "end": 8254.76,
        "id": 2094,
        "no_speech_prob": 0.0023231576196849346,
        "seek": 824976,
        "start": 8253.76,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          50564,
          663,
          311,
          3657,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2459214596038169,
        "compression_ratio": 1.2035398230088497,
        "end": 8259.76,
        "id": 2095,
        "no_speech_prob": 0.0023231576196849346,
        "seek": 824976,
        "start": 8256.76,
        "temperature": 0,
        "text": " And it shouldn't say like console log.",
        "tokens": [
          50714,
          400,
          309,
          4659,
          380,
          584,
          411,
          11076,
          3565,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2459214596038169,
        "compression_ratio": 1.2035398230088497,
        "end": 8264.76,
        "id": 2096,
        "no_speech_prob": 0.0023231576196849346,
        "seek": 824976,
        "start": 8260.76,
        "temperature": 0,
        "text": " I'm not saying console log sending image.",
        "tokens": [
          50914,
          286,
          478,
          406,
          1566,
          11076,
          3565,
          7750,
          3256,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2459214596038169,
        "compression_ratio": 1.2035398230088497,
        "end": 8275.76,
        "id": 2097,
        "no_speech_prob": 0.0023231576196849346,
        "seek": 824976,
        "start": 8274.76,
        "temperature": 0,
        "text": " Let's check.",
        "tokens": [
          51614,
          961,
          311,
          1520,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23391238621303012,
        "compression_ratio": 1.5031055900621118,
        "end": 8283.76,
        "id": 2098,
        "no_speech_prob": 0.0004583114350680262,
        "seek": 827576,
        "start": 8275.76,
        "temperature": 0,
        "text": " One of the things that you should always check when you're doing this is, is the model awake or asleep?",
        "tokens": [
          50364,
          1485,
          295,
          264,
          721,
          300,
          291,
          820,
          1009,
          1520,
          562,
          291,
          434,
          884,
          341,
          307,
          11,
          307,
          264,
          2316,
          15994,
          420,
          11039,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.23391238621303012,
        "compression_ratio": 1.5031055900621118,
        "end": 8287.76,
        "id": 2099,
        "no_speech_prob": 0.0004583114350680262,
        "seek": 827576,
        "start": 8283.76,
        "temperature": 0,
        "text": " This is weird that the model is not waking.",
        "tokens": [
          50764,
          639,
          307,
          3657,
          300,
          264,
          2316,
          307,
          406,
          20447,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23391238621303012,
        "compression_ratio": 1.5031055900621118,
        "end": 8290.76,
        "id": 2100,
        "no_speech_prob": 0.0004583114350680262,
        "seek": 827576,
        "start": 8287.76,
        "temperature": 0,
        "text": " It should be turning yellow here.",
        "tokens": [
          50964,
          467,
          820,
          312,
          6246,
          5566,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23391238621303012,
        "compression_ratio": 1.5031055900621118,
        "end": 8295.76,
        "id": 2101,
        "no_speech_prob": 0.0004583114350680262,
        "seek": 827576,
        "start": 8294.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23391238621303012,
        "compression_ratio": 1.5031055900621118,
        "end": 8296.76,
        "id": 2102,
        "no_speech_prob": 0.0004583114350680262,
        "seek": 827576,
        "start": 8295.76,
        "temperature": 0,
        "text": " Let's.",
        "tokens": [
          51364,
          961,
          311,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23391238621303012,
        "compression_ratio": 1.5031055900621118,
        "end": 8304.76,
        "id": 2103,
        "no_speech_prob": 0.0004583114350680262,
        "seek": 827576,
        "start": 8300.76,
        "temperature": 0,
        "text": " Let me double check what it's looking for.",
        "tokens": [
          51614,
          961,
          385,
          3834,
          1520,
          437,
          309,
          311,
          1237,
          337,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8308.76,
        "id": 2104,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8305.76,
        "temperature": 0,
        "text": " So I'm going to switch back to just showing me.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          3679,
          646,
          281,
          445,
          4099,
          385,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8312.76,
        "id": 2105,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8308.76,
        "temperature": 0,
        "text": " Because when I look at the runway example code, it has the API key in it.",
        "tokens": [
          50564,
          1436,
          562,
          286,
          574,
          412,
          264,
          26642,
          1365,
          3089,
          11,
          309,
          575,
          264,
          9362,
          2141,
          294,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8314.76,
        "id": 2106,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8312.76,
        "temperature": 0,
        "text": " Image threshold.",
        "tokens": [
          50764,
          29903,
          14678,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8315.76,
        "id": 2107,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8314.76,
        "temperature": 0,
        "text": " I also need a threshold.",
        "tokens": [
          50864,
          286,
          611,
          643,
          257,
          14678,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8317.76,
        "id": 2108,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8315.76,
        "temperature": 0,
        "text": " So I'm just going to show this to you.",
        "tokens": [
          50914,
          407,
          286,
          478,
          445,
          516,
          281,
          855,
          341,
          281,
          291,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8319.76,
        "id": 2109,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8317.76,
        "temperature": 0,
        "text": " Without the API key visible.",
        "tokens": [
          51014,
          9129,
          264,
          9362,
          2141,
          8974,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8324.76,
        "id": 2110,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8319.76,
        "temperature": 0,
        "text": " So in runway, the inputs are the image, the base 64 image, as well as a threshold.",
        "tokens": [
          51114,
          407,
          294,
          26642,
          11,
          264,
          15743,
          366,
          264,
          3256,
          11,
          264,
          3096,
          12145,
          3256,
          11,
          382,
          731,
          382,
          257,
          14678,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8327.76,
        "id": 2111,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8324.76,
        "temperature": 0,
        "text": " I would assume it's using a default threshold.",
        "tokens": [
          51364,
          286,
          576,
          6552,
          309,
          311,
          1228,
          257,
          7576,
          14678,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20168012087462378,
        "compression_ratio": 1.712,
        "end": 8331.76,
        "id": 2112,
        "no_speech_prob": 0.004070041701197624,
        "seek": 830476,
        "start": 8327.76,
        "temperature": 0,
        "text": " And then I should get back bounding boxes, categories, and scores.",
        "tokens": [
          51514,
          400,
          550,
          286,
          820,
          483,
          646,
          5472,
          278,
          9002,
          11,
          10479,
          11,
          293,
          13444,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8335.76,
        "id": 2113,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8331.76,
        "temperature": 0,
        "text": " So let me make sure everything is right here.",
        "tokens": [
          50364,
          407,
          718,
          385,
          652,
          988,
          1203,
          307,
          558,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8339.76,
        "id": 2114,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8335.76,
        "temperature": 0,
        "text": " Let me make sure the URL and the token is correct.",
        "tokens": [
          50564,
          961,
          385,
          652,
          988,
          264,
          12905,
          293,
          264,
          14862,
          307,
          3006,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8343.76,
        "id": 2115,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8341.76,
        "temperature": 0,
        "text": " In the dot ENV file.",
        "tokens": [
          50864,
          682,
          264,
          5893,
          15244,
          53,
          3991,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8347.76,
        "id": 2116,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8345.76,
        "temperature": 0,
        "text": " Yeah, it looks absolutely looks right.",
        "tokens": [
          51064,
          865,
          11,
          309,
          1542,
          3122,
          1542,
          558,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8350.76,
        "id": 2117,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8349.76,
        "temperature": 0,
        "text": " Server.",
        "tokens": [
          51264,
          25684,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8351.76,
        "id": 2118,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8350.76,
        "temperature": 0,
        "text": " Let's console logs.",
        "tokens": [
          51314,
          961,
          311,
          11076,
          20820,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8353.76,
        "id": 2119,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8351.76,
        "temperature": 0,
        "text": " Is there any error in the server?",
        "tokens": [
          51364,
          1119,
          456,
          604,
          6713,
          294,
          264,
          7154,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8354.76,
        "id": 2120,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8353.76,
        "temperature": 0,
        "text": " I didn't actually check.",
        "tokens": [
          51464,
          286,
          994,
          380,
          767,
          1520,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8356.76,
        "id": 2121,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8354.76,
        "temperature": 0,
        "text": " Oh, the requests are going through.",
        "tokens": [
          51514,
          876,
          11,
          264,
          12475,
          366,
          516,
          807,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8358.76,
        "id": 2122,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8356.76,
        "temperature": 0,
        "text": " I know I need to show you my screen.",
        "tokens": [
          51614,
          286,
          458,
          286,
          643,
          281,
          855,
          291,
          452,
          2568,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20410758373784085,
        "compression_ratio": 1.4908256880733946,
        "end": 8359.76,
        "id": 2123,
        "no_speech_prob": 0.0018102037720382214,
        "seek": 833176,
        "start": 8358.76,
        "temperature": 0,
        "text": " But why?",
        "tokens": [
          51714,
          583,
          983,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2516404580378878,
        "compression_ratio": 1.4074074074074074,
        "end": 8369.76,
        "id": 2124,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 836176,
        "start": 8362.76,
        "temperature": 0,
        "text": " I'm kind of confused because this should show it as waking up.",
        "tokens": [
          50414,
          286,
          478,
          733,
          295,
          9019,
          570,
          341,
          820,
          855,
          309,
          382,
          20447,
          493,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2516404580378878,
        "compression_ratio": 1.4074074074074074,
        "end": 8373.76,
        "id": 2125,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 836176,
        "start": 8371.76,
        "temperature": 0,
        "text": " Oh, SkyGan is waking up.",
        "tokens": [
          50864,
          876,
          11,
          9879,
          38,
          282,
          307,
          20447,
          493,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2516404580378878,
        "compression_ratio": 1.4074074074074074,
        "end": 8375.76,
        "id": 2126,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 836176,
        "start": 8373.76,
        "temperature": 0,
        "text": " Because somebody is running that glitch application.",
        "tokens": [
          50964,
          1436,
          2618,
          307,
          2614,
          300,
          23552,
          3861,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2516404580378878,
        "compression_ratio": 1.4074074074074074,
        "end": 8378.76,
        "id": 2127,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 836176,
        "start": 8377.76,
        "temperature": 0,
        "text": " I should turn this one off.",
        "tokens": [
          51164,
          286,
          820,
          1261,
          341,
          472,
          766,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2516404580378878,
        "compression_ratio": 1.4074074074074074,
        "end": 8382.76,
        "id": 2128,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 836176,
        "start": 8380.76,
        "temperature": 0,
        "text": " That's not the one that I'm using right now.",
        "tokens": [
          51314,
          663,
          311,
          406,
          264,
          472,
          300,
          286,
          478,
          1228,
          558,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2516404580378878,
        "compression_ratio": 1.4074074074074074,
        "end": 8386.76,
        "id": 2129,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 836176,
        "start": 8383.76,
        "temperature": 0,
        "text": " Let's go here.",
        "tokens": [
          51464,
          961,
          311,
          352,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19421209607805526,
        "compression_ratio": 1.291044776119403,
        "end": 8396.76,
        "id": 2130,
        "no_speech_prob": 0.0010649582836776972,
        "seek": 838676,
        "start": 8387.76,
        "temperature": 0,
        "text": " And maybe I just need to also add threshold 0.5.",
        "tokens": [
          50414,
          400,
          1310,
          286,
          445,
          643,
          281,
          611,
          909,
          14678,
          1958,
          13,
          20,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19421209607805526,
        "compression_ratio": 1.291044776119403,
        "end": 8398.76,
        "id": 2131,
        "no_speech_prob": 0.0010649582836776972,
        "seek": 838676,
        "start": 8397.76,
        "temperature": 0,
        "text": " Let's try that.",
        "tokens": [
          50914,
          961,
          311,
          853,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19421209607805526,
        "compression_ratio": 1.291044776119403,
        "end": 8399.76,
        "id": 2132,
        "no_speech_prob": 0.0010649582836776972,
        "seek": 838676,
        "start": 8398.76,
        "temperature": 0,
        "text": " Threshold 0.5.",
        "tokens": [
          50964,
          334,
          14214,
          1958,
          13,
          20,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19421209607805526,
        "compression_ratio": 1.291044776119403,
        "end": 8404.76,
        "id": 2133,
        "no_speech_prob": 0.0010649582836776972,
        "seek": 838676,
        "start": 8400.76,
        "temperature": 0,
        "text": " And let's make sure that base 64 image is actually working properly.",
        "tokens": [
          51064,
          400,
          718,
          311,
          652,
          988,
          300,
          3096,
          12145,
          3256,
          307,
          767,
          1364,
          6108,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19421209607805526,
        "compression_ratio": 1.291044776119403,
        "end": 8409.76,
        "id": 2134,
        "no_speech_prob": 0.0010649582836776972,
        "seek": 838676,
        "start": 8408.76,
        "temperature": 0,
        "text": " It just got stuck there.",
        "tokens": [
          51464,
          467,
          445,
          658,
          5541,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8410.76,
        "id": 2135,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8409.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8414.76,
        "id": 2136,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8413.76,
        "temperature": 0,
        "text": " Froze.",
        "tokens": [
          50564,
          479,
          340,
          1381,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8416.76,
        "id": 2137,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8414.76,
        "temperature": 0,
        "text": " So that's definitely a base 64 image.",
        "tokens": [
          50614,
          407,
          300,
          311,
          2138,
          257,
          3096,
          12145,
          3256,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8418.76,
        "id": 2138,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8417.76,
        "temperature": 0,
        "text": " Where did it get stuck though?",
        "tokens": [
          50764,
          2305,
          630,
          309,
          483,
          5541,
          1673,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8422.76,
        "id": 2139,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8421.76,
        "temperature": 0,
        "text": " I don't see.",
        "tokens": [
          50964,
          286,
          500,
          380,
          536,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8424.76,
        "id": 2140,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8422.76,
        "temperature": 0,
        "text": " Oh, console logs sending images.",
        "tokens": [
          51014,
          876,
          11,
          11076,
          20820,
          7750,
          5267,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8431.76,
        "id": 2141,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8430.76,
        "temperature": 0,
        "text": " Oh, I got an error here.",
        "tokens": [
          51414,
          876,
          11,
          286,
          658,
          364,
          6713,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8434.76,
        "id": 2142,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8433.76,
        "temperature": 0,
        "text": " The model expires.",
        "tokens": [
          51564,
          440,
          2316,
          1278,
          3145,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8435.76,
        "id": 2143,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8434.76,
        "temperature": 0,
        "text": " I don't know what's going on.",
        "tokens": [
          51614,
          286,
          500,
          380,
          458,
          437,
          311,
          516,
          322,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.5557311411654011,
        "compression_ratio": 1.4378698224852071,
        "end": 8437.76,
        "id": 2144,
        "no_speech_prob": 0.0003250337322242558,
        "seek": 840976,
        "start": 8435.76,
        "temperature": 0,
        "text": " I'm going to go back to the console logs.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          11076,
          20820,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8440.76,
        "id": 2145,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8438.76,
        "temperature": 0,
        "text": " The model experienced an error while processing your input.",
        "tokens": [
          50414,
          440,
          2316,
          6751,
          364,
          6713,
          1339,
          9007,
          428,
          4846,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8446.76,
        "id": 2146,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8443.76,
        "temperature": 0,
        "text": " Double check that you are sending properly formed input parameters.",
        "tokens": [
          50664,
          16633,
          1520,
          300,
          291,
          366,
          7750,
          6108,
          8693,
          4846,
          9834,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8448.76,
        "id": 2147,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8446.76,
        "temperature": 0,
        "text": " Hosted model dot info method.",
        "tokens": [
          50814,
          22047,
          292,
          2316,
          5893,
          13614,
          3170,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8450.76,
        "id": 2148,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8449.76,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          50964,
          407,
          718,
          311,
          360,
          300,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8456.76,
        "id": 2149,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8454.76,
        "temperature": 0,
        "text": " Boy, this is supposed to be the end.",
        "tokens": [
          51214,
          9486,
          11,
          341,
          307,
          3442,
          281,
          312,
          264,
          917,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8458.76,
        "id": 2150,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8456.76,
        "temperature": 0,
        "text": " I'm like, it's almost six o'clock.",
        "tokens": [
          51314,
          286,
          478,
          411,
          11,
          309,
          311,
          1920,
          2309,
          277,
          6,
          9023,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8459.76,
        "id": 2151,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8458.76,
        "temperature": 0,
        "text": " I'm going an hour later than I said.",
        "tokens": [
          51414,
          286,
          478,
          516,
          364,
          1773,
          1780,
          813,
          286,
          848,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8461.76,
        "id": 2152,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8459.76,
        "temperature": 0,
        "text": " But I really want to get this to work.",
        "tokens": [
          51464,
          583,
          286,
          534,
          528,
          281,
          483,
          341,
          281,
          589,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8463.76,
        "id": 2153,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8461.76,
        "temperature": 0,
        "text": " Oh, let's turn this off.",
        "tokens": [
          51564,
          876,
          11,
          718,
          311,
          1261,
          341,
          766,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1957750667225231,
        "compression_ratio": 1.5349794238683128,
        "end": 8466.76,
        "id": 2154,
        "no_speech_prob": 0.0002453685156069696,
        "seek": 843776,
        "start": 8464.76,
        "temperature": 0,
        "text": " Take close these things.",
        "tokens": [
          51714,
          3664,
          1998,
          613,
          721,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.28047061496310766,
        "compression_ratio": 1.2432432432432432,
        "end": 8468.76,
        "id": 2155,
        "no_speech_prob": 0.000437331065768376,
        "seek": 846776,
        "start": 8467.76,
        "temperature": 0,
        "text": " Close these things.",
        "tokens": [
          50364,
          16346,
          613,
          721,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.28047061496310766,
        "compression_ratio": 1.2432432432432432,
        "end": 8475.76,
        "id": 2156,
        "no_speech_prob": 0.000437331065768376,
        "seek": 846776,
        "start": 8472.76,
        "temperature": 0,
        "text": " So let's look again.",
        "tokens": [
          50614,
          407,
          718,
          311,
          574,
          797,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28047061496310766,
        "compression_ratio": 1.2432432432432432,
        "end": 8482.76,
        "id": 2157,
        "no_speech_prob": 0.000437331065768376,
        "seek": 846776,
        "start": 8481.76,
        "temperature": 0,
        "text": " Look again at the code snippet.",
        "tokens": [
          51064,
          2053,
          797,
          412,
          264,
          3089,
          35623,
          302,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.28047061496310766,
        "compression_ratio": 1.2432432432432432,
        "end": 8492.76,
        "id": 2158,
        "no_speech_prob": 0.000437331065768376,
        "seek": 846776,
        "start": 8489.76,
        "temperature": 0,
        "text": " Threshold number from point zero one to point to one.",
        "tokens": [
          51464,
          334,
          14214,
          1230,
          490,
          935,
          4018,
          472,
          281,
          935,
          281,
          472,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.28047061496310766,
        "compression_ratio": 1.2432432432432432,
        "end": 8495.76,
        "id": 2159,
        "no_speech_prob": 0.000437331065768376,
        "seek": 846776,
        "start": 8494.76,
        "temperature": 0,
        "text": " It's weird.",
        "tokens": [
          51714,
          467,
          311,
          3657,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20391706739153181,
        "compression_ratio": 1.4509803921568627,
        "end": 8499.76,
        "id": 2160,
        "no_speech_prob": 0.00027372033218853176,
        "seek": 849776,
        "start": 8498.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20391706739153181,
        "compression_ratio": 1.4509803921568627,
        "end": 8502.76,
        "id": 2161,
        "no_speech_prob": 0.00027372033218853176,
        "seek": 849776,
        "start": 8500.76,
        "temperature": 0,
        "text": " So I'm just going to do something here in the server.",
        "tokens": [
          50514,
          407,
          286,
          478,
          445,
          516,
          281,
          360,
          746,
          510,
          294,
          264,
          7154,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20391706739153181,
        "compression_ratio": 1.4509803921568627,
        "end": 8512.76,
        "id": 2162,
        "no_speech_prob": 0.00027372033218853176,
        "seek": 849776,
        "start": 8508.76,
        "temperature": 0,
        "text": " And when I run the server, I'm going to call model dot info.",
        "tokens": [
          50914,
          400,
          562,
          286,
          1190,
          264,
          7154,
          11,
          286,
          478,
          516,
          281,
          818,
          2316,
          5893,
          13614,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20391706739153181,
        "compression_ratio": 1.4509803921568627,
        "end": 8515.76,
        "id": 2163,
        "no_speech_prob": 0.00027372033218853176,
        "seek": 849776,
        "start": 8513.76,
        "temperature": 0,
        "text": " Just to make sure that that's working properly.",
        "tokens": [
          51164,
          1449,
          281,
          652,
          988,
          300,
          300,
          311,
          1364,
          6108,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20391706739153181,
        "compression_ratio": 1.4509803921568627,
        "end": 8516.76,
        "id": 2164,
        "no_speech_prob": 0.00027372033218853176,
        "seek": 849776,
        "start": 8515.76,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          51264,
          407,
          718,
          311,
          360,
          300,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20391706739153181,
        "compression_ratio": 1.4509803921568627,
        "end": 8524.76,
        "id": 2165,
        "no_speech_prob": 0.00027372033218853176,
        "seek": 849776,
        "start": 8521.76,
        "temperature": 0,
        "text": " Something weird is going on.",
        "tokens": [
          51564,
          6595,
          3657,
          307,
          516,
          322,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20391706739153181,
        "compression_ratio": 1.4509803921568627,
        "end": 8526.76,
        "id": 2166,
        "no_speech_prob": 0.00027372033218853176,
        "seek": 849776,
        "start": 8525.76,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51764,
          1779,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.3731269836425781,
        "compression_ratio": 1.0333333333333334,
        "end": 8528.76,
        "id": 2167,
        "no_speech_prob": 0.0028442624025046825,
        "seek": 852776,
        "start": 8527.76,
        "temperature": 0,
        "text": " That.",
        "tokens": [
          50364,
          663,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.3731269836425781,
        "compression_ratio": 1.0333333333333334,
        "end": 8531.76,
        "id": 2168,
        "no_speech_prob": 0.0028442624025046825,
        "seek": 852776,
        "start": 8529.76,
        "temperature": 0,
        "text": " Your app is just in port 3000.",
        "tokens": [
          50464,
          2260,
          724,
          307,
          445,
          294,
          2436,
          20984,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3731269836425781,
        "compression_ratio": 1.0333333333333334,
        "end": 8533.76,
        "id": 2169,
        "no_speech_prob": 0.0028442624025046825,
        "seek": 852776,
        "start": 8531.76,
        "temperature": 0,
        "text": " Count 100.",
        "tokens": [
          50564,
          5247,
          2319,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.3731269836425781,
        "compression_ratio": 1.0333333333333334,
        "end": 8536.76,
        "id": 2170,
        "no_speech_prob": 0.0028442624025046825,
        "seek": 852776,
        "start": 8533.76,
        "temperature": 0,
        "text": " Why is this not communicating with the model?",
        "tokens": [
          50664,
          1545,
          307,
          341,
          406,
          17559,
          365,
          264,
          2316,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8561.76,
        "id": 2171,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8558.76,
        "temperature": 0,
        "text": " Add some additional console logs here.",
        "tokens": [
          50414,
          5349,
          512,
          4497,
          11076,
          20820,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8564.76,
        "id": 2172,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8563.76,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50664,
          821,
          321,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8567.76,
        "id": 2173,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8566.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8569.76,
        "id": 2174,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8568.76,
        "temperature": 0,
        "text": " Default.",
        "tokens": [
          50914,
          9548,
          5107,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8570.76,
        "id": 2175,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8569.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8574.76,
        "id": 2176,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8570.76,
        "temperature": 0,
        "text": " This is the inputs are channels three default name, image type image.",
        "tokens": [
          51014,
          639,
          307,
          264,
          15743,
          366,
          9235,
          1045,
          7576,
          1315,
          11,
          3256,
          2010,
          3256,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8576.76,
        "id": 2177,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8574.76,
        "temperature": 0,
        "text": " Default point five.",
        "tokens": [
          51214,
          9548,
          5107,
          935,
          1732,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8579.76,
        "id": 2178,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8577.76,
        "temperature": 0,
        "text": " Minimum constant score.",
        "tokens": [
          51364,
          2829,
          332,
          449,
          5754,
          6175,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8581.76,
        "id": 2179,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8579.76,
        "temperature": 0,
        "text": " Max one threshold name threshold.",
        "tokens": [
          51464,
          7402,
          472,
          14678,
          1315,
          14678,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8582.76,
        "id": 2180,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8581.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8584.76,
        "id": 2181,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8582.76,
        "temperature": 0,
        "text": " So image base 64 image.",
        "tokens": [
          51614,
          407,
          3256,
          3096,
          12145,
          3256,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.265116702069293,
        "compression_ratio": 1.5212765957446808,
        "end": 8586.76,
        "id": 2182,
        "no_speech_prob": 0.09946205466985703,
        "seek": 855776,
        "start": 8584.76,
        "temperature": 0,
        "text": " And then I should get objects back.",
        "tokens": [
          51714,
          400,
          550,
          286,
          820,
          483,
          6565,
          646,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8587.76,
        "id": 2183,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8586.76,
        "temperature": 0,
        "text": " So maybe the model.",
        "tokens": [
          50364,
          407,
          1310,
          264,
          2316,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8590.76,
        "id": 2184,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8588.76,
        "temperature": 0,
        "text": " Oh, it's awake now.",
        "tokens": [
          50464,
          876,
          11,
          309,
          311,
          15994,
          586,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8591.76,
        "id": 2185,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8590.76,
        "temperature": 0,
        "text": " I don't know something.",
        "tokens": [
          50564,
          286,
          500,
          380,
          458,
          746,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8593.76,
        "id": 2186,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8591.76,
        "temperature": 0,
        "text": " I guess maybe something was going weird with it.",
        "tokens": [
          50614,
          286,
          2041,
          1310,
          746,
          390,
          516,
          3657,
          365,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8597.76,
        "id": 2187,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8595.76,
        "temperature": 0,
        "text": " Let's refresh this page.",
        "tokens": [
          50814,
          961,
          311,
          15134,
          341,
          3028,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8602.76,
        "id": 2188,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8601.76,
        "temperature": 0,
        "text": " Oh, there we go.",
        "tokens": [
          51114,
          876,
          11,
          456,
          321,
          352,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8606.76,
        "id": 2189,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8604.76,
        "temperature": 0,
        "text": " The bounding boxes came back.",
        "tokens": [
          51264,
          440,
          5472,
          278,
          9002,
          1361,
          646,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8610.76,
        "id": 2190,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8606.76,
        "temperature": 0,
        "text": " Rubik's scores, status, success, bounding boxes.",
        "tokens": [
          51364,
          10518,
          1035,
          311,
          13444,
          11,
          6558,
          11,
          2245,
          11,
          5472,
          278,
          9002,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8613.76,
        "id": 2191,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8611.76,
        "temperature": 0,
        "text": " Looks like these are normalized values.",
        "tokens": [
          51614,
          10027,
          411,
          613,
          366,
          48704,
          4190,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2297853244248257,
        "compression_ratio": 1.458762886597938,
        "end": 8614.76,
        "id": 2192,
        "no_speech_prob": 0.00026947801234200597,
        "seek": 858676,
        "start": 8613.76,
        "temperature": 0,
        "text": " Now, why?",
        "tokens": [
          51714,
          823,
          11,
          983,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.20708691583920832,
        "compression_ratio": 1.4338235294117647,
        "end": 8617.76,
        "id": 2193,
        "no_speech_prob": 0.0035934720654040575,
        "seek": 861476,
        "start": 8615.76,
        "temperature": 0,
        "text": " Why, why, why, why, why did this stop?",
        "tokens": [
          50414,
          1545,
          11,
          983,
          11,
          983,
          11,
          983,
          11,
          983,
          630,
          341,
          1590,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.20708691583920832,
        "compression_ratio": 1.4338235294117647,
        "end": 8628.76,
        "id": 2194,
        "no_speech_prob": 0.0035934720654040575,
        "seek": 861476,
        "start": 8625.76,
        "temperature": 0,
        "text": " Why did that stop on the client?",
        "tokens": [
          50914,
          1545,
          630,
          300,
          1590,
          322,
          264,
          6423,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.20708691583920832,
        "compression_ratio": 1.4338235294117647,
        "end": 8631.76,
        "id": 2195,
        "no_speech_prob": 0.0035934720654040575,
        "seek": 861476,
        "start": 8630.76,
        "temperature": 0,
        "text": " Function draw.",
        "tokens": [
          51164,
          11166,
          882,
          2642,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20708691583920832,
        "compression_ratio": 1.4338235294117647,
        "end": 8636.76,
        "id": 2196,
        "no_speech_prob": 0.0035934720654040575,
        "seek": 861476,
        "start": 8635.76,
        "temperature": 0,
        "text": " Oh, hold on.",
        "tokens": [
          51414,
          876,
          11,
          1797,
          322,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20708691583920832,
        "compression_ratio": 1.4338235294117647,
        "end": 8638.76,
        "id": 2197,
        "no_speech_prob": 0.0035934720654040575,
        "seek": 861476,
        "start": 8636.76,
        "temperature": 0,
        "text": " I had something I have to do on my phone.",
        "tokens": [
          51464,
          286,
          632,
          746,
          286,
          362,
          281,
          360,
          322,
          452,
          2593,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20708691583920832,
        "compression_ratio": 1.4338235294117647,
        "end": 8639.76,
        "id": 2198,
        "no_speech_prob": 0.0035934720654040575,
        "seek": 861476,
        "start": 8638.76,
        "temperature": 0,
        "text": " The alarm went off.",
        "tokens": [
          51564,
          440,
          14183,
          1437,
          766,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20708691583920832,
        "compression_ratio": 1.4338235294117647,
        "end": 8641.76,
        "id": 2199,
        "no_speech_prob": 0.0035934720654040575,
        "seek": 861476,
        "start": 8639.76,
        "temperature": 0,
        "text": " I have to do this at six o'clock.",
        "tokens": [
          51614,
          286,
          362,
          281,
          360,
          341,
          412,
          2309,
          277,
          6,
          9023,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21583301049691658,
        "compression_ratio": 1.1875,
        "end": 8645.76,
        "id": 2200,
        "no_speech_prob": 0.0009697439381852746,
        "seek": 864176,
        "start": 8641.76,
        "temperature": 0,
        "text": " So at five 59, I need to stop for a second.",
        "tokens": [
          50364,
          407,
          412,
          1732,
          24624,
          11,
          286,
          643,
          281,
          1590,
          337,
          257,
          1150,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21583301049691658,
        "compression_ratio": 1.1875,
        "end": 8647.76,
        "id": 2201,
        "no_speech_prob": 0.0009697439381852746,
        "seek": 864176,
        "start": 8646.76,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50614,
          1545,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.21583301049691658,
        "compression_ratio": 1.1875,
        "end": 8650.76,
        "id": 2202,
        "no_speech_prob": 0.0009697439381852746,
        "seek": 864176,
        "start": 8649.76,
        "temperature": 0,
        "text": " That's so weird.",
        "tokens": [
          50764,
          663,
          311,
          370,
          3657,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21583301049691658,
        "compression_ratio": 1.1875,
        "end": 8652.76,
        "id": 2203,
        "no_speech_prob": 0.0009697439381852746,
        "seek": 864176,
        "start": 8651.76,
        "temperature": 0,
        "text": " What happened here?",
        "tokens": [
          50864,
          708,
          2011,
          510,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.21583301049691658,
        "compression_ratio": 1.1875,
        "end": 8655.76,
        "id": 2204,
        "no_speech_prob": 0.0009697439381852746,
        "seek": 864176,
        "start": 8653.76,
        "temperature": 0,
        "text": " That caused it to stop.",
        "tokens": [
          50964,
          663,
          7008,
          309,
          281,
          1590,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21583301049691658,
        "compression_ratio": 1.1875,
        "end": 8656.76,
        "id": 2205,
        "no_speech_prob": 0.0009697439381852746,
        "seek": 864176,
        "start": 8655.76,
        "temperature": 0,
        "text": " Let's let's.",
        "tokens": [
          51064,
          961,
          311,
          718,
          311,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21583301049691658,
        "compression_ratio": 1.1875,
        "end": 8662.76,
        "id": 2206,
        "no_speech_prob": 0.0009697439381852746,
        "seek": 864176,
        "start": 8661.76,
        "temperature": 0,
        "text": " It's just.",
        "tokens": [
          51364,
          467,
          311,
          445,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8673.76,
        "id": 2207,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8671.76,
        "temperature": 0,
        "text": " OK, now I'm going to detect call detect.",
        "tokens": [
          50364,
          2264,
          11,
          586,
          286,
          478,
          516,
          281,
          5531,
          818,
          5531,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8676.76,
        "id": 2208,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8675.76,
        "temperature": 0,
        "text": " That's still going.",
        "tokens": [
          50564,
          663,
          311,
          920,
          516,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8678.76,
        "id": 2209,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8677.76,
        "temperature": 0,
        "text": " Why did the canvas stop?",
        "tokens": [
          50664,
          1545,
          630,
          264,
          16267,
          1590,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8683.76,
        "id": 2210,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8682.76,
        "temperature": 0,
        "text": " Why did draw?",
        "tokens": [
          50914,
          1545,
          630,
          2642,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8687.76,
        "id": 2211,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8684.76,
        "temperature": 0,
        "text": " I mean, I recognize that this is like an this is an asynchronous function.",
        "tokens": [
          51014,
          286,
          914,
          11,
          286,
          5521,
          300,
          341,
          307,
          411,
          364,
          341,
          307,
          364,
          49174,
          2445,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8693.76,
        "id": 2212,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8690.76,
        "temperature": 0,
        "text": " Did like the load pixels active loading the pixels.",
        "tokens": [
          51314,
          2589,
          411,
          264,
          3677,
          18668,
          4967,
          15114,
          264,
          18668,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8694.76,
        "id": 2213,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8693.76,
        "temperature": 0,
        "text": " Let's let's comment this out.",
        "tokens": [
          51464,
          961,
          311,
          718,
          311,
          2871,
          341,
          484,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22440381796963244,
        "compression_ratio": 1.4918032786885247,
        "end": 8695.76,
        "id": 2214,
        "no_speech_prob": 0.00001012999018712435,
        "seek": 867176,
        "start": 8694.76,
        "temperature": 0,
        "text": " See if it works.",
        "tokens": [
          51514,
          3008,
          498,
          309,
          1985,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3031707579089749,
        "compression_ratio": 1.297709923664122,
        "end": 8696.76,
        "id": 2215,
        "no_speech_prob": 0.0001911025174194947,
        "seek": 869576,
        "start": 8695.76,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50364,
          2438,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.3031707579089749,
        "compression_ratio": 1.297709923664122,
        "end": 8700.76,
        "id": 2216,
        "no_speech_prob": 0.0001911025174194947,
        "seek": 869576,
        "start": 8697.76,
        "temperature": 0,
        "text": " So load pixels messes it up, but it can't get the.",
        "tokens": [
          50464,
          407,
          3677,
          18668,
          2082,
          279,
          309,
          493,
          11,
          457,
          309,
          393,
          380,
          483,
          264,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3031707579089749,
        "compression_ratio": 1.297709923664122,
        "end": 8709.76,
        "id": 2217,
        "no_speech_prob": 0.0001911025174194947,
        "seek": 869576,
        "start": 8704.76,
        "temperature": 0,
        "text": " Can I call like update pixels and that'll like get it going again?",
        "tokens": [
          50814,
          1664,
          286,
          818,
          411,
          5623,
          18668,
          293,
          300,
          603,
          411,
          483,
          309,
          516,
          797,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.3031707579089749,
        "compression_ratio": 1.297709923664122,
        "end": 8716.76,
        "id": 2218,
        "no_speech_prob": 0.0001911025174194947,
        "seek": 869576,
        "start": 8715.76,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51364,
          883,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3031707579089749,
        "compression_ratio": 1.297709923664122,
        "end": 8719.76,
        "id": 2219,
        "no_speech_prob": 0.0001911025174194947,
        "seek": 869576,
        "start": 8717.76,
        "temperature": 0,
        "text": " That's like a P5 bug.",
        "tokens": [
          51464,
          663,
          311,
          411,
          257,
          430,
          20,
          7426,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3031707579089749,
        "compression_ratio": 1.297709923664122,
        "end": 8720.76,
        "id": 2220,
        "no_speech_prob": 0.0001911025174194947,
        "seek": 869576,
        "start": 8719.76,
        "temperature": 0,
        "text": " It shouldn't be there.",
        "tokens": [
          51564,
          467,
          4659,
          380,
          312,
          456,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8721.76,
        "id": 2221,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8720.76,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50364,
          883,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8723.76,
        "id": 2222,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8722.76,
        "temperature": 0,
        "text": " That's like a P5 bug.",
        "tokens": [
          50464,
          663,
          311,
          411,
          257,
          430,
          20,
          7426,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8725.76,
        "id": 2223,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8724.76,
        "temperature": 0,
        "text": " It shouldn't be doing that.",
        "tokens": [
          50564,
          467,
          4659,
          380,
          312,
          884,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8726.76,
        "id": 2224,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8725.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50614,
          1057,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8727.76,
        "id": 2225,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8726.76,
        "temperature": 0,
        "text": " I'm not going to.",
        "tokens": [
          50664,
          286,
          478,
          406,
          516,
          281,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8729.76,
        "id": 2226,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8727.76,
        "temperature": 0,
        "text": " This is a P5 bug that's unrelated to what I'm trying to do.",
        "tokens": [
          50714,
          639,
          307,
          257,
          430,
          20,
          7426,
          300,
          311,
          38967,
          281,
          437,
          286,
          478,
          1382,
          281,
          360,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8734.76,
        "id": 2227,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8729.76,
        "temperature": 0,
        "text": " So I'm going to just not worry about that for because I I got to stop.",
        "tokens": [
          50814,
          407,
          286,
          478,
          516,
          281,
          445,
          406,
          3292,
          466,
          300,
          337,
          570,
          286,
          286,
          658,
          281,
          1590,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8735.76,
        "id": 2228,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8734.76,
        "temperature": 0,
        "text": " I got to stop live streaming.",
        "tokens": [
          51064,
          286,
          658,
          281,
          1590,
          1621,
          11791,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8738.76,
        "id": 2229,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8735.76,
        "temperature": 0,
        "text": " Somebody will help me figure this out.",
        "tokens": [
          51114,
          13463,
          486,
          854,
          385,
          2573,
          341,
          484,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8741.76,
        "id": 2230,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8738.76,
        "temperature": 0,
        "text": " I have two minutes till I need to do something very important on my phone.",
        "tokens": [
          51264,
          286,
          362,
          732,
          2077,
          4288,
          286,
          643,
          281,
          360,
          746,
          588,
          1021,
          322,
          452,
          2593,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8743.76,
        "id": 2231,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8742.76,
        "temperature": 0,
        "text": " But.",
        "tokens": [
          51464,
          583,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2190470188222033,
        "compression_ratio": 1.6446886446886446,
        "end": 8749.76,
        "id": 2232,
        "no_speech_prob": 0.005468938034027815,
        "seek": 872076,
        "start": 8745.76,
        "temperature": 0,
        "text": " I have an activity that I do with my kids and you have to book it 48 hours in advance.",
        "tokens": [
          51614,
          286,
          362,
          364,
          5191,
          300,
          286,
          360,
          365,
          452,
          2301,
          293,
          291,
          362,
          281,
          1446,
          309,
          11174,
          2496,
          294,
          7295,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.26238860207042475,
        "compression_ratio": 1.4972067039106145,
        "end": 8756.76,
        "id": 2233,
        "no_speech_prob": 0.00008349562267540023,
        "seek": 874976,
        "start": 8749.76,
        "temperature": 0,
        "text": " Or you know due to like COVID restrictions and if I don't do it right at 6 it's for like Monday at 6.",
        "tokens": [
          50364,
          1610,
          291,
          458,
          3462,
          281,
          411,
          4566,
          14191,
          293,
          498,
          286,
          500,
          380,
          360,
          309,
          558,
          412,
          1386,
          309,
          311,
          337,
          411,
          8138,
          412,
          1386,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.26238860207042475,
        "compression_ratio": 1.4972067039106145,
        "end": 8759.76,
        "id": 2234,
        "no_speech_prob": 0.00008349562267540023,
        "seek": 874976,
        "start": 8756.76,
        "temperature": 0,
        "text": " It doesn't like you have to join the wait list.",
        "tokens": [
          50714,
          467,
          1177,
          380,
          411,
          291,
          362,
          281,
          3917,
          264,
          1699,
          1329,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.26238860207042475,
        "compression_ratio": 1.4972067039106145,
        "end": 8761.76,
        "id": 2235,
        "no_speech_prob": 0.00008349562267540023,
        "seek": 874976,
        "start": 8759.76,
        "temperature": 0,
        "text": " So watching the clock here.",
        "tokens": [
          50864,
          407,
          1976,
          264,
          7830,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26238860207042475,
        "compression_ratio": 1.4972067039106145,
        "end": 8764.76,
        "id": 2236,
        "no_speech_prob": 0.00008349562267540023,
        "seek": 874976,
        "start": 8762.76,
        "temperature": 0,
        "text": " So let's just draw.",
        "tokens": [
          51014,
          407,
          718,
          311,
          445,
          2642,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.26238860207042475,
        "compression_ratio": 1.4972067039106145,
        "end": 8766.76,
        "id": 2237,
        "no_speech_prob": 0.00008349562267540023,
        "seek": 874976,
        "start": 8765.76,
        "temperature": 0,
        "text": " Let's do it this way.",
        "tokens": [
          51164,
          961,
          311,
          360,
          309,
          341,
          636,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26238860207042475,
        "compression_ratio": 1.4972067039106145,
        "end": 8772.76,
        "id": 2238,
        "no_speech_prob": 0.00008349562267540023,
        "seek": 874976,
        "start": 8771.76,
        "temperature": 0,
        "text": " Let's I could copy it.",
        "tokens": [
          51464,
          961,
          311,
          286,
          727,
          5055,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.26238860207042475,
        "compression_ratio": 1.4972067039106145,
        "end": 8774.76,
        "id": 2239,
        "no_speech_prob": 0.00008349562267540023,
        "seek": 874976,
        "start": 8772.76,
        "temperature": 0,
        "text": " You know what I could do.",
        "tokens": [
          51514,
          509,
          458,
          437,
          286,
          727,
          360,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.279954482098015,
        "compression_ratio": 1.2118644067796611,
        "end": 8779.76,
        "id": 2240,
        "no_speech_prob": 0.00007967251440277323,
        "seek": 877476,
        "start": 8775.76,
        "temperature": 0,
        "text": " This is making me annoyed that I want to fix this is no it's like it feels like a P5 bug.",
        "tokens": [
          50414,
          639,
          307,
          1455,
          385,
          25921,
          300,
          286,
          528,
          281,
          3191,
          341,
          307,
          572,
          309,
          311,
          411,
          309,
          3417,
          411,
          257,
          430,
          20,
          7426,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.279954482098015,
        "compression_ratio": 1.2118644067796611,
        "end": 8782.76,
        "id": 2241,
        "no_speech_prob": 0.00007967251440277323,
        "seek": 877476,
        "start": 8780.76,
        "temperature": 0,
        "text": " Let video copy.",
        "tokens": [
          50664,
          961,
          960,
          5055,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.279954482098015,
        "compression_ratio": 1.2118644067796611,
        "end": 8785.76,
        "id": 2242,
        "no_speech_prob": 0.00007967251440277323,
        "seek": 877476,
        "start": 8783.76,
        "temperature": 0,
        "text": " Oh I can just do this.",
        "tokens": [
          50814,
          876,
          286,
          393,
          445,
          360,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.279954482098015,
        "compression_ratio": 1.2118644067796611,
        "end": 8791.76,
        "id": 2243,
        "no_speech_prob": 0.00007967251440277323,
        "seek": 877476,
        "start": 8790.76,
        "temperature": 0,
        "text": " Can I do this?",
        "tokens": [
          51164,
          1664,
          286,
          360,
          341,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8810.76,
        "id": 2244,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8805.76,
        "temperature": 0,
        "text": " It does the same thing because get is going to load the pixels of the video in order to copy it.",
        "tokens": [
          50414,
          467,
          775,
          264,
          912,
          551,
          570,
          483,
          307,
          516,
          281,
          3677,
          264,
          18668,
          295,
          264,
          960,
          294,
          1668,
          281,
          5055,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8811.76,
        "id": 2245,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8810.76,
        "temperature": 0,
        "text": " Okay never mind.",
        "tokens": [
          50664,
          1033,
          1128,
          1575,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8813.76,
        "id": 2246,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8812.76,
        "temperature": 0,
        "text": " I won't worry about this.",
        "tokens": [
          50764,
          286,
          1582,
          380,
          3292,
          466,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8816.76,
        "id": 2247,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8814.76,
        "temperature": 0,
        "text": " Let's look at what comes out.",
        "tokens": [
          50864,
          961,
          311,
          574,
          412,
          437,
          1487,
          484,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8818.76,
        "id": 2248,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8817.76,
        "temperature": 0,
        "text": " Bounding boxes.",
        "tokens": [
          51014,
          363,
          24625,
          9002,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8819.76,
        "id": 2249,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8818.76,
        "temperature": 0,
        "text": " Okay nothing.",
        "tokens": [
          51064,
          1033,
          1825,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8820.76,
        "id": 2250,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8819.76,
        "temperature": 0,
        "text": " So.",
        "tokens": [
          51114,
          407,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8825.76,
        "id": 2251,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8824.76,
        "temperature": 0,
        "text": " So let's.",
        "tokens": [
          51364,
          407,
          718,
          311,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21680662631988526,
        "compression_ratio": 1.4465408805031446,
        "end": 8829.76,
        "id": 2252,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 880476,
        "start": 8828.76,
        "temperature": 0,
        "text": " I think if I do.",
        "tokens": [
          51564,
          286,
          519,
          498,
          286,
          360,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8832.76,
        "id": 2253,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8829.76,
        "temperature": 0,
        "text": " Make a variable called detections is an empty array.",
        "tokens": [
          50364,
          4387,
          257,
          7006,
          1219,
          5531,
          626,
          307,
          364,
          6707,
          10225,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8836.76,
        "id": 2254,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8834.76,
        "temperature": 0,
        "text": " And then if I say.",
        "tokens": [
          50614,
          400,
          550,
          498,
          286,
          584,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8842.76,
        "id": 2255,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8838.76,
        "temperature": 0,
        "text": " Detections equals output stop bounding boxes.",
        "tokens": [
          50814,
          4237,
          557,
          626,
          6915,
          5598,
          1590,
          5472,
          278,
          9002,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8844.76,
        "id": 2256,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8843.76,
        "temperature": 0,
        "text": " Is that what it was called?",
        "tokens": [
          51064,
          1119,
          300,
          437,
          309,
          390,
          1219,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8846.76,
        "id": 2257,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8845.76,
        "temperature": 0,
        "text": " Let's actually whoops.",
        "tokens": [
          51164,
          961,
          311,
          767,
          567,
          3370,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8851.76,
        "id": 2258,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8846.76,
        "temperature": 0,
        "text": " Let's get 558 when says 559 I'm going to stop for a second.",
        "tokens": [
          51214,
          961,
          311,
          483,
          12330,
          23,
          562,
          1619,
          12330,
          24,
          286,
          478,
          516,
          281,
          1590,
          337,
          257,
          1150,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8854.76,
        "id": 2259,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8853.76,
        "temperature": 0,
        "text": " You know I'm a stop now.",
        "tokens": [
          51564,
          509,
          458,
          286,
          478,
          257,
          1590,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.33926215379134467,
        "compression_ratio": 1.4512820512820512,
        "end": 8856.76,
        "id": 2260,
        "no_speech_prob": 0.0003569702967070043,
        "seek": 882976,
        "start": 8854.76,
        "temperature": 0,
        "text": " You guys got to bear with me.",
        "tokens": [
          51614,
          509,
          1074,
          658,
          281,
          6155,
          365,
          385,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8857.76,
        "id": 2261,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8856.76,
        "temperature": 0,
        "text": " You know I'm a stop now.",
        "tokens": [
          50364,
          509,
          458,
          286,
          478,
          257,
          1590,
          586,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8863.76,
        "id": 2262,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8857.76,
        "temperature": 0,
        "text": " You guys got to bear with me while I refresh a page on my phone over and over again.",
        "tokens": [
          50414,
          509,
          1074,
          658,
          281,
          6155,
          365,
          385,
          1339,
          286,
          15134,
          257,
          3028,
          322,
          452,
          2593,
          670,
          293,
          670,
          797,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8866.76,
        "id": 2263,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8865.76,
        "temperature": 0,
        "text": " I'm going to finish this off.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          2413,
          341,
          766,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8871.76,
        "id": 2264,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8869.76,
        "temperature": 0,
        "text": " This is such a weird thing I'm doing.",
        "tokens": [
          51014,
          639,
          307,
          1270,
          257,
          3657,
          551,
          286,
          478,
          884,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8873.76,
        "id": 2265,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8871.76,
        "temperature": 0,
        "text": " Sunday Monday.",
        "tokens": [
          51114,
          7776,
          8138,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8875.76,
        "id": 2266,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8874.76,
        "temperature": 0,
        "text": " 6pm.",
        "tokens": [
          51264,
          1386,
          14395,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8880.76,
        "id": 2267,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8875.76,
        "temperature": 0,
        "text": " You all will think of me at 6pm on Monday if I get this too early to join.",
        "tokens": [
          51314,
          509,
          439,
          486,
          519,
          295,
          385,
          412,
          1386,
          14395,
          322,
          8138,
          498,
          286,
          483,
          341,
          886,
          2440,
          281,
          3917,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22438918665835733,
        "compression_ratio": 1.564516129032258,
        "end": 8884.76,
        "id": 2268,
        "no_speech_prob": 0.015188407152891159,
        "seek": 885676,
        "start": 8883.76,
        "temperature": 0,
        "text": " Too early to join.",
        "tokens": [
          51714,
          11395,
          2440,
          281,
          3917,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8886.76,
        "id": 2269,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8884.76,
        "temperature": 1,
        "text": " Too early to join too early to join.",
        "tokens": [
          50364,
          11395,
          2440,
          281,
          3917,
          886,
          2440,
          220,
          1353,
          361,
          14312,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8890.76,
        "id": 2270,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8889.76,
        "temperature": 1,
        "text": " Really to join.",
        "tokens": [
          50614,
          8467,
          356,
          220,
          1353,
          3917,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8892.76,
        "id": 2271,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8891.76,
        "temperature": 1,
        "text": " Really to join.",
        "tokens": [
          50714,
          4083,
          220,
          1353,
          3917,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8894.76,
        "id": 2272,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8893.76,
        "temperature": 1,
        "text": " Really to join.",
        "tokens": [
          50814,
          4083,
          220,
          1353,
          361,
          14312,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8898.76,
        "id": 2273,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8896.76,
        "temperature": 1,
        "text": " Really too early",
        "tokens": [
          50964,
          497,
          68,
          379,
          886,
          2440,
          51064
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8900.76,
        "id": 2274,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8899.76,
        "temperature": 1,
        "text": " Really to join.",
        "tokens": [
          51114,
          4083,
          281,
          3917,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8902.76,
        "id": 2275,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8901.76,
        "temperature": 1,
        "text": " A join.",
        "tokens": [
          51214,
          316,
          361,
          14312,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8905.76,
        "id": 2276,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8904.76,
        "temperature": 1,
        "text": " Really really.",
        "tokens": [
          51364,
          4083,
          957,
          356,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8906.76,
        "id": 2277,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8905.76,
        "temperature": 1,
        "text": " Really doing.",
        "tokens": [
          51414,
          4083,
          884,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8910.76,
        "id": 2278,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8909.76,
        "temperature": 1,
        "text": " His joy.",
        "tokens": [
          51614,
          2812,
          6258,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -1.3765001541528947,
        "compression_ratio": 2.4714285714285715,
        "end": 8912.76,
        "id": 2279,
        "no_speech_prob": 0.14998631179332733,
        "seek": 888476,
        "start": 8911.76,
        "temperature": 1,
        "text": " Let's go.",
        "tokens": [
          51714,
          961,
          311,
          352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8916.76,
        "id": 2280,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8915.76,
        "temperature": 0,
        "text": " Change the six o'clock already.",
        "tokens": [
          50414,
          15060,
          264,
          2309,
          277,
          6,
          9023,
          1217,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8918.76,
        "id": 2281,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8917.76,
        "temperature": 0,
        "text": " Really enjoy.",
        "tokens": [
          50514,
          4083,
          2103,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8922.76,
        "id": 2282,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8921.76,
        "temperature": 0,
        "text": " Really enjoying.",
        "tokens": [
          50714,
          4083,
          9929,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8925.76,
        "id": 2283,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8924.76,
        "temperature": 0,
        "text": " Just refreshing this over and over again.",
        "tokens": [
          50864,
          1449,
          19772,
          341,
          670,
          293,
          670,
          797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8927.76,
        "id": 2284,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8926.76,
        "temperature": 0,
        "text": " Too early to join.",
        "tokens": [
          50964,
          11395,
          2440,
          281,
          3917,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8932.76,
        "id": 2285,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8931.76,
        "temperature": 0,
        "text": " Really enjoying.",
        "tokens": [
          51214,
          4083,
          9929,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8935.76,
        "id": 2286,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8933.76,
        "temperature": 0,
        "text": " Join join join join.",
        "tokens": [
          51314,
          19642,
          3917,
          3917,
          3917,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8937.76,
        "id": 2287,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8936.76,
        "temperature": 0,
        "text": " Yes, I got it.",
        "tokens": [
          51464,
          1079,
          11,
          286,
          658,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8940.76,
        "id": 2288,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8939.76,
        "temperature": 0,
        "text": " Monday at six o'clock. All right. Excellent.",
        "tokens": [
          51614,
          8138,
          412,
          2309,
          277,
          6,
          9023,
          13,
          1057,
          558,
          13,
          16723,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3336814880371094,
        "compression_ratio": 1.54375,
        "end": 8943.76,
        "id": 2289,
        "no_speech_prob": 0.0024313642643392086,
        "seek": 891476,
        "start": 8941.76,
        "temperature": 0,
        "text": " So the bounding boxes are",
        "tokens": [
          51714,
          407,
          264,
          5472,
          278,
          9002,
          366,
          51814
        ]
      },
      {
        "avg_logprob": -0.2875750190333316,
        "compression_ratio": 1.5053191489361701,
        "end": 8950.76,
        "id": 2290,
        "no_speech_prob": 0.0028892860282212496,
        "seek": 894476,
        "start": 8945.76,
        "temperature": 0,
        "text": " An array with four values in it. And I assume this is normalized to the width and the height.",
        "tokens": [
          50414,
          1107,
          10225,
          365,
          1451,
          4190,
          294,
          309,
          13,
          400,
          286,
          6552,
          341,
          307,
          48704,
          281,
          264,
          11402,
          293,
          264,
          6681,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2875750190333316,
        "compression_ratio": 1.5053191489361701,
        "end": 8954.76,
        "id": 2291,
        "no_speech_prob": 0.0028892860282212496,
        "seek": 894476,
        "start": 8951.76,
        "temperature": 0,
        "text": " So I could say here.",
        "tokens": [
          50714,
          407,
          286,
          727,
          584,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2875750190333316,
        "compression_ratio": 1.5053191489361701,
        "end": 8958.76,
        "id": 2292,
        "no_speech_prob": 0.0028892860282212496,
        "seek": 894476,
        "start": 8955.76,
        "temperature": 0,
        "text": " Now in draw for let I",
        "tokens": [
          50914,
          823,
          294,
          2642,
          337,
          718,
          286,
          51064
        ]
      },
      {
        "avg_logprob": -0.2875750190333316,
        "compression_ratio": 1.5053191489361701,
        "end": 8964.76,
        "id": 2293,
        "no_speech_prob": 0.0028892860282212496,
        "seek": 894476,
        "start": 8959.76,
        "temperature": 0,
        "text": " Equals zero eyes less than what did I call this detections sections dot length.",
        "tokens": [
          51114,
          15624,
          1124,
          4018,
          2575,
          1570,
          813,
          437,
          630,
          286,
          818,
          341,
          5531,
          626,
          10863,
          5893,
          4641,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2875750190333316,
        "compression_ratio": 1.5053191489361701,
        "end": 8973.76,
        "id": 2294,
        "no_speech_prob": 0.0028892860282212496,
        "seek": 894476,
        "start": 8966.76,
        "temperature": 0,
        "text": " Let cube equals detections index I and then I want to say X equals",
        "tokens": [
          51464,
          961,
          13728,
          6915,
          5531,
          626,
          8186,
          286,
          293,
          550,
          286,
          528,
          281,
          584,
          1783,
          6915,
          51814
        ]
      },
      {
        "avg_logprob": -0.2792947075583718,
        "compression_ratio": 1.6507936507936507,
        "end": 8976.76,
        "id": 2295,
        "no_speech_prob": 0.0001420219341525808,
        "seek": 897476,
        "start": 8974.76,
        "temperature": 0,
        "text": " Cube dot zero times with",
        "tokens": [
          50364,
          33003,
          5893,
          4018,
          1413,
          365,
          50464
        ]
      },
      {
        "avg_logprob": -0.2792947075583718,
        "compression_ratio": 1.6507936507936507,
        "end": 8984.76,
        "id": 2296,
        "no_speech_prob": 0.0001420219341525808,
        "seek": 897476,
        "start": 8980.76,
        "temperature": 0,
        "text": " Y equals cube one dot width dot height times height.",
        "tokens": [
          50664,
          398,
          6915,
          13728,
          472,
          5893,
          11402,
          5893,
          6681,
          1413,
          6681,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2792947075583718,
        "compression_ratio": 1.6507936507936507,
        "end": 8993.76,
        "id": 2297,
        "no_speech_prob": 0.0001420219341525808,
        "seek": 897476,
        "start": 8985.76,
        "temperature": 0,
        "text": " What do we think? Do we think these are the width and height of the box or do we think this is the bottom right corner of the box?",
        "tokens": [
          50914,
          708,
          360,
          321,
          519,
          30,
          1144,
          321,
          519,
          613,
          366,
          264,
          11402,
          293,
          6681,
          295,
          264,
          2424,
          420,
          360,
          321,
          519,
          341,
          307,
          264,
          2767,
          558,
          4538,
          295,
          264,
          2424,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.28180569615857354,
        "compression_ratio": 1.646153846153846,
        "end": 8999.76,
        "id": 2298,
        "no_speech_prob": 0.010986614041030407,
        "seek": 899376,
        "start": 8994.76,
        "temperature": 0,
        "text": " Does it explain that to me anywhere? I mean looking at those numbers. What would you guess? I don't think they're the width and the height.",
        "tokens": [
          50414,
          4402,
          309,
          2903,
          300,
          281,
          385,
          4992,
          30,
          286,
          914,
          1237,
          412,
          729,
          3547,
          13,
          708,
          576,
          291,
          2041,
          30,
          286,
          500,
          380,
          519,
          436,
          434,
          264,
          11402,
          293,
          264,
          6681,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.28180569615857354,
        "compression_ratio": 1.646153846153846,
        "end": 9006.76,
        "id": 2299,
        "no_speech_prob": 0.010986614041030407,
        "seek": 899376,
        "start": 9000.76,
        "temperature": 0,
        "text": " That would be huge must be the bottom right and bottom the corner. So I think I would then say",
        "tokens": [
          50714,
          663,
          576,
          312,
          2603,
          1633,
          312,
          264,
          2767,
          558,
          293,
          2767,
          264,
          4538,
          13,
          407,
          286,
          519,
          286,
          576,
          550,
          584,
          51014
        ]
      },
      {
        "avg_logprob": -0.28180569615857354,
        "compression_ratio": 1.646153846153846,
        "end": 9009.76,
        "id": 2300,
        "no_speech_prob": 0.010986614041030407,
        "seek": 899376,
        "start": 9007.76,
        "temperature": 0,
        "text": " X X one Y one.",
        "tokens": [
          51064,
          1783,
          1783,
          472,
          398,
          472,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.28180569615857354,
        "compression_ratio": 1.646153846153846,
        "end": 9019.76,
        "id": 2301,
        "no_speech_prob": 0.010986614041030407,
        "seek": 899376,
        "start": 9013.76,
        "temperature": 0,
        "text": " X two Y two two and three and then I could think I could say rect mode.",
        "tokens": [
          51364,
          1783,
          732,
          398,
          732,
          732,
          293,
          1045,
          293,
          550,
          286,
          727,
          519,
          286,
          727,
          584,
          11048,
          4391,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2679939693874783,
        "compression_ratio": 1.495,
        "end": 9030.76,
        "id": 2302,
        "no_speech_prob": 0.00018235381867270917,
        "seek": 901976,
        "start": 9019.76,
        "temperature": 0,
        "text": " Corners. I think that's what it is in P5. If instead of specifying the XY width and height. I want to specify the corners and then I would draw a rectangle X one Y one X two Y two stroke.",
        "tokens": [
          50364,
          383,
          1865,
          433,
          13,
          286,
          519,
          300,
          311,
          437,
          309,
          307,
          294,
          430,
          20,
          13,
          759,
          2602,
          295,
          1608,
          5489,
          264,
          48826,
          11402,
          293,
          6681,
          13,
          286,
          528,
          281,
          16500,
          264,
          12413,
          293,
          550,
          286,
          576,
          2642,
          257,
          21930,
          1783,
          472,
          398,
          472,
          1783,
          732,
          398,
          732,
          12403,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2679939693874783,
        "compression_ratio": 1.495,
        "end": 9037.76,
        "id": 2303,
        "no_speech_prob": 0.00018235381867270917,
        "seek": 901976,
        "start": 9032.76,
        "temperature": 0,
        "text": " 255 no fill stroke weight. Let's make it pretty thick eight.",
        "tokens": [
          51014,
          3552,
          20,
          572,
          2836,
          12403,
          3364,
          13,
          961,
          311,
          652,
          309,
          1238,
          5060,
          3180,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2679939693874783,
        "compression_ratio": 1.495,
        "end": 9040.76,
        "id": 2304,
        "no_speech_prob": 0.00018235381867270917,
        "seek": 901976,
        "start": 9038.76,
        "temperature": 0,
        "text": " All right, let's try this now.",
        "tokens": [
          51314,
          1057,
          558,
          11,
          718,
          311,
          853,
          341,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2679939693874783,
        "compression_ratio": 1.495,
        "end": 9044.76,
        "id": 2305,
        "no_speech_prob": 0.00018235381867270917,
        "seek": 901976,
        "start": 9043.76,
        "temperature": 0,
        "text": " So no Rubik's Cube.",
        "tokens": [
          51564,
          407,
          572,
          10518,
          1035,
          311,
          33003,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.294149112701416,
        "compression_ratio": 1.2621359223300972,
        "end": 9047.76,
        "id": 2306,
        "no_speech_prob": 0.00008220180461648852,
        "seek": 904476,
        "start": 9044.76,
        "temperature": 0,
        "text": " The model must have gone to sleep during all that time.",
        "tokens": [
          50364,
          440,
          2316,
          1633,
          362,
          2780,
          281,
          2817,
          1830,
          439,
          300,
          565,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.294149112701416,
        "compression_ratio": 1.2621359223300972,
        "end": 9058.76,
        "id": 2307,
        "no_speech_prob": 0.00008220180461648852,
        "seek": 904476,
        "start": 9056.76,
        "temperature": 0,
        "text": " This model has trouble waking up it seems.",
        "tokens": [
          50964,
          639,
          2316,
          575,
          5253,
          20447,
          493,
          309,
          2544,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.294149112701416,
        "compression_ratio": 1.2621359223300972,
        "end": 9062.76,
        "id": 2308,
        "no_speech_prob": 0.00008220180461648852,
        "seek": 904476,
        "start": 9061.76,
        "temperature": 0,
        "text": " So that's green.",
        "tokens": [
          51214,
          407,
          300,
          311,
          3092,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.294149112701416,
        "compression_ratio": 1.2621359223300972,
        "end": 9065.76,
        "id": 2309,
        "no_speech_prob": 0.00008220180461648852,
        "seek": 904476,
        "start": 9064.76,
        "temperature": 0,
        "text": " I'm impatient.",
        "tokens": [
          51364,
          286,
          478,
          36895,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2881377647662985,
        "compression_ratio": 1.3157894736842106,
        "end": 9069.76,
        "id": 2310,
        "no_speech_prob": 0.002844894304871559,
        "seek": 906576,
        "start": 9066.76,
        "temperature": 0,
        "text": " Oh, I'm so close to being done with this live stream.",
        "tokens": [
          50414,
          876,
          11,
          286,
          478,
          370,
          1998,
          281,
          885,
          1096,
          365,
          341,
          1621,
          4309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2881377647662985,
        "compression_ratio": 1.3157894736842106,
        "end": 9078.76,
        "id": 2311,
        "no_speech_prob": 0.002844894304871559,
        "seek": 906576,
        "start": 9073.76,
        "temperature": 0,
        "text": " Wow, why did it break? So this is also a weird bug which I would",
        "tokens": [
          50764,
          3153,
          11,
          983,
          630,
          309,
          1821,
          30,
          407,
          341,
          307,
          611,
          257,
          3657,
          7426,
          597,
          286,
          576,
          51014
        ]
      },
      {
        "avg_logprob": -0.2881377647662985,
        "compression_ratio": 1.3157894736842106,
        "end": 9086.76,
        "id": 2312,
        "no_speech_prob": 0.002844894304871559,
        "seek": 906576,
        "start": 9080.76,
        "temperature": 0,
        "text": " sort of assume is maybe a runway issue. Where did I have that querying the model?",
        "tokens": [
          51114,
          1333,
          295,
          6552,
          307,
          1310,
          257,
          26642,
          2734,
          13,
          2305,
          630,
          286,
          362,
          300,
          7083,
          1840,
          264,
          2316,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.7615194649531923,
        "compression_ratio": 1.4915254237288136,
        "end": 9089.76,
        "id": 2313,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 908676,
        "start": 9087.76,
        "temperature": 0,
        "text": " All right, let's restart the server.",
        "tokens": [
          50414,
          1057,
          558,
          11,
          718,
          311,
          21022,
          264,
          7154,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.7615194649531923,
        "compression_ratio": 1.4915254237288136,
        "end": 9100.76,
        "id": 2314,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 908676,
        "start": 9096.76,
        "temperature": 0,
        "text": " So the model is not returning. Oh, there we go. The info yet.",
        "tokens": [
          50864,
          407,
          264,
          2316,
          307,
          406,
          12678,
          13,
          876,
          11,
          456,
          321,
          352,
          13,
          440,
          13614,
          1939,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.7615194649531923,
        "compression_ratio": 1.4915254237288136,
        "end": 9105.76,
        "id": 2315,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 908676,
        "start": 9103.76,
        "temperature": 0,
        "text": " So I'm going to go back to the server.",
        "tokens": [
          51214,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          7154,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.7615194649531923,
        "compression_ratio": 1.4915254237288136,
        "end": 9109.76,
        "id": 2316,
        "no_speech_prob": 0.0006361885461956263,
        "seek": 908676,
        "start": 9107.76,
        "temperature": 0,
        "text": " And I'm going to go back to the model.",
        "tokens": [
          51414,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          2316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1880448857943217,
        "compression_ratio": 1.2232142857142858,
        "end": 9113.76,
        "id": 2317,
        "no_speech_prob": 0.0004955332260578871,
        "seek": 910976,
        "start": 9110.76,
        "temperature": 0,
        "text": " So the model is not returning. Oh, there we go. The info yet.",
        "tokens": [
          50414,
          407,
          264,
          2316,
          307,
          406,
          12678,
          13,
          876,
          11,
          456,
          321,
          352,
          13,
          440,
          13614,
          1939,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1880448857943217,
        "compression_ratio": 1.2232142857142858,
        "end": 9119.76,
        "id": 2318,
        "no_speech_prob": 0.0004955332260578871,
        "seek": 910976,
        "start": 9117.76,
        "temperature": 0,
        "text": " I suppose I could try.",
        "tokens": [
          50764,
          286,
          7297,
          286,
          727,
          853,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1880448857943217,
        "compression_ratio": 1.2232142857142858,
        "end": 9123.76,
        "id": 2319,
        "no_speech_prob": 0.0004955332260578871,
        "seek": 910976,
        "start": 9120.76,
        "temperature": 0,
        "text": " Oh, it's yellow. That's a good sign. It's waking up.",
        "tokens": [
          50914,
          876,
          11,
          309,
          311,
          5566,
          13,
          663,
          311,
          257,
          665,
          1465,
          13,
          467,
          311,
          20447,
          493,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.35433180067274306,
        "compression_ratio": 1.6217391304347826,
        "end": 9133.76,
        "id": 2320,
        "no_speech_prob": 0.011868248693645,
        "seek": 912376,
        "start": 9124.76,
        "temperature": 0,
        "text": " If anybody has watched this entire stream and has been taking notes on all the different runway related things that have come up, that would be so amazing to compile.",
        "tokens": [
          50414,
          759,
          4472,
          575,
          6337,
          341,
          2302,
          4309,
          293,
          575,
          668,
          1940,
          5570,
          322,
          439,
          264,
          819,
          26642,
          4077,
          721,
          300,
          362,
          808,
          493,
          11,
          300,
          576,
          312,
          370,
          2243,
          281,
          31413,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.35433180067274306,
        "compression_ratio": 1.6217391304347826,
        "end": 9142.76,
        "id": 2321,
        "no_speech_prob": 0.011868248693645,
        "seek": 912376,
        "start": 9134.76,
        "temperature": 0,
        "text": " I would be forever grateful, even with the time codes of when they are, because I want to get in touch with the runway folks after this.",
        "tokens": [
          50914,
          286,
          576,
          312,
          5680,
          7941,
          11,
          754,
          365,
          264,
          565,
          14211,
          295,
          562,
          436,
          366,
          11,
          570,
          286,
          528,
          281,
          483,
          294,
          2557,
          365,
          264,
          26642,
          4024,
          934,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.35433180067274306,
        "compression_ratio": 1.6217391304347826,
        "end": 9146.76,
        "id": 2322,
        "no_speech_prob": 0.011868248693645,
        "seek": 912376,
        "start": 9143.76,
        "temperature": 0,
        "text": " Is the audio peaking, by the way? I'm seeing a lot of voice comments.",
        "tokens": [
          51364,
          1119,
          264,
          6278,
          520,
          2456,
          11,
          538,
          264,
          636,
          30,
          286,
          478,
          2577,
          257,
          688,
          295,
          3177,
          800,
          791,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.5195293426513672,
        "compression_ratio": 1.6896551724137931,
        "end": 9153.76,
        "id": 2323,
        "no_speech_prob": 0.08268413692712784,
        "seek": 914676,
        "start": 9147.76,
        "temperature": 0,
        "text": " I'm seeing a lot of red in the monitor I'm using. Still yellow. Oh, no, it's awake, I think.",
        "tokens": [
          50414,
          286,
          478,
          2577,
          257,
          688,
          295,
          2182,
          294,
          264,
          6002,
          286,
          478,
          1228,
          13,
          8291,
          5566,
          13,
          876,
          11,
          572,
          11,
          309,
          311,
          15994,
          11,
          286,
          519,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.5195293426513672,
        "compression_ratio": 1.6896551724137931,
        "end": 9159.76,
        "id": 2324,
        "no_speech_prob": 0.08268413692712784,
        "seek": 914676,
        "start": 9157.76,
        "temperature": 0,
        "text": " Okay, no bounding box.",
        "tokens": [
          50914,
          1033,
          11,
          572,
          5472,
          278,
          2424,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.5195293426513672,
        "compression_ratio": 1.6896551724137931,
        "end": 9162.76,
        "id": 2325,
        "no_speech_prob": 0.08268413692712784,
        "seek": 914676,
        "start": 9160.76,
        "temperature": 0,
        "text": " There we go!",
        "tokens": [
          51064,
          821,
          321,
          352,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.5195293426513672,
        "compression_ratio": 1.6896551724137931,
        "end": 9165.76,
        "id": 2326,
        "no_speech_prob": 0.08268413692712784,
        "seek": 914676,
        "start": 9163.76,
        "temperature": 0,
        "text": " So I'm going to go back to the server.",
        "tokens": [
          51214,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          7154,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.5195293426513672,
        "compression_ratio": 1.6896551724137931,
        "end": 9168.76,
        "id": 2327,
        "no_speech_prob": 0.08268413692712784,
        "seek": 914676,
        "start": 9166.76,
        "temperature": 0,
        "text": " And I'm going to go back to the model.",
        "tokens": [
          51364,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          2316,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.5195293426513672,
        "compression_ratio": 1.6896551724137931,
        "end": 9171.76,
        "id": 2328,
        "no_speech_prob": 0.08268413692712784,
        "seek": 914676,
        "start": 9169.76,
        "temperature": 0,
        "text": " And I'm going to go back to the model.",
        "tokens": [
          51514,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          2316,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23431267676415382,
        "compression_ratio": 1.4022988505747127,
        "end": 9173.76,
        "id": 2329,
        "no_speech_prob": 0.003172655124217272,
        "seek": 917176,
        "start": 9171.76,
        "temperature": 0,
        "text": " Okay, no bounding box.",
        "tokens": [
          50364,
          1033,
          11,
          572,
          5472,
          278,
          2424,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23431267676415382,
        "compression_ratio": 1.4022988505747127,
        "end": 9176.76,
        "id": 2330,
        "no_speech_prob": 0.003172655124217272,
        "seek": 917176,
        "start": 9174.76,
        "temperature": 0,
        "text": " There we go!",
        "tokens": [
          50514,
          821,
          321,
          352,
          0,
          50614
        ]
      },
      {
        "avg_logprob": -0.23431267676415382,
        "compression_ratio": 1.4022988505747127,
        "end": 9181.76,
        "id": 2331,
        "no_speech_prob": 0.003172655124217272,
        "seek": 917176,
        "start": 9178.76,
        "temperature": 0,
        "text": " Amazing! Oh, this is so cool.",
        "tokens": [
          50714,
          14165,
          0,
          876,
          11,
          341,
          307,
          370,
          1627,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23431267676415382,
        "compression_ratio": 1.4022988505747127,
        "end": 9190.76,
        "id": 2332,
        "no_speech_prob": 0.003172655124217272,
        "seek": 917176,
        "start": 9184.76,
        "temperature": 0,
        "text": " A custom trained object detection model working, like, essentially perfectly.",
        "tokens": [
          51014,
          316,
          2375,
          8895,
          2657,
          17784,
          2316,
          1364,
          11,
          411,
          11,
          4476,
          6239,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23431267676415382,
        "compression_ratio": 1.4022988505747127,
        "end": 9193.76,
        "id": 2333,
        "no_speech_prob": 0.003172655124217272,
        "seek": 917176,
        "start": 9191.76,
        "temperature": 0,
        "text": " I mean, look how good this is.",
        "tokens": [
          51364,
          286,
          914,
          11,
          574,
          577,
          665,
          341,
          307,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23431267676415382,
        "compression_ratio": 1.4022988505747127,
        "end": 9196.76,
        "id": 2334,
        "no_speech_prob": 0.003172655124217272,
        "seek": 917176,
        "start": 9194.76,
        "temperature": 0,
        "text": " This is crazy.",
        "tokens": [
          51514,
          639,
          307,
          3219,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23431267676415382,
        "compression_ratio": 1.4022988505747127,
        "end": 9199.76,
        "id": 2335,
        "no_speech_prob": 0.003172655124217272,
        "seek": 917176,
        "start": 9197.76,
        "temperature": 0,
        "text": " The thing is, I wanted to get it to work in real time.",
        "tokens": [
          51664,
          440,
          551,
          307,
          11,
          286,
          1415,
          281,
          483,
          309,
          281,
          589,
          294,
          957,
          565,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22748344127948467,
        "compression_ratio": 1.4069767441860466,
        "end": 9212.76,
        "id": 2336,
        "no_speech_prob": 0.001244823564775288,
        "seek": 919976,
        "start": 9200.76,
        "temperature": 0,
        "text": " And I don't understand why the video is frozen whenever I call load pixels.",
        "tokens": [
          50414,
          400,
          286,
          500,
          380,
          1223,
          983,
          264,
          960,
          307,
          12496,
          5699,
          286,
          818,
          3677,
          18668,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22748344127948467,
        "compression_ratio": 1.4069767441860466,
        "end": 9215.76,
        "id": 2337,
        "no_speech_prob": 0.001244823564775288,
        "seek": 919976,
        "start": 9213.76,
        "temperature": 0,
        "text": " Such a strange thing.",
        "tokens": [
          51064,
          9653,
          257,
          5861,
          551,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22748344127948467,
        "compression_ratio": 1.4069767441860466,
        "end": 9218.76,
        "id": 2338,
        "no_speech_prob": 0.001244823564775288,
        "seek": 919976,
        "start": 9216.76,
        "temperature": 0,
        "text": " So I guess I'm going to have to work that out later.",
        "tokens": [
          51214,
          407,
          286,
          2041,
          286,
          478,
          516,
          281,
          362,
          281,
          589,
          300,
          484,
          1780,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22748344127948467,
        "compression_ratio": 1.4069767441860466,
        "end": 9221.76,
        "id": 2339,
        "no_speech_prob": 0.001244823564775288,
        "seek": 919976,
        "start": 9219.76,
        "temperature": 0,
        "text": " I'm going to publish this to Glitch right now.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          11374,
          341,
          281,
          5209,
          1549,
          558,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22748344127948467,
        "compression_ratio": 1.4069767441860466,
        "end": 9224.76,
        "id": 2340,
        "no_speech_prob": 0.001244823564775288,
        "seek": 919976,
        "start": 9222.76,
        "temperature": 0,
        "text": " Obviously without the environment variables.",
        "tokens": [
          51514,
          7580,
          1553,
          264,
          2823,
          9102,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.25444718126980764,
        "compression_ratio": 1.3716216216216217,
        "end": 9226.76,
        "id": 2341,
        "no_speech_prob": 0.053400542587041855,
        "seek": 922476,
        "start": 9224.76,
        "temperature": 0,
        "text": " If anybody wants to...",
        "tokens": [
          50364,
          759,
          4472,
          2738,
          281,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.25444718126980764,
        "compression_ratio": 1.3716216216216217,
        "end": 9231.76,
        "id": 2342,
        "no_speech_prob": 0.053400542587041855,
        "seek": 922476,
        "start": 9227.76,
        "temperature": 0,
        "text": " You could work on debugging this for me without the runway call.",
        "tokens": [
          50514,
          509,
          727,
          589,
          322,
          45592,
          341,
          337,
          385,
          1553,
          264,
          26642,
          818,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25444718126980764,
        "compression_ratio": 1.3716216216216217,
        "end": 9245.76,
        "id": 2343,
        "no_speech_prob": 0.053400542587041855,
        "seek": 922476,
        "start": 9232.76,
        "temperature": 0,
        "text": " For example, this should still work just fine if I don't actually query runway.",
        "tokens": [
          50764,
          1171,
          1365,
          11,
          341,
          820,
          920,
          589,
          445,
          2489,
          498,
          286,
          500,
          380,
          767,
          14581,
          26642,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.25444718126980764,
        "compression_ratio": 1.3716216216216217,
        "end": 9249.76,
        "id": 2344,
        "no_speech_prob": 0.053400542587041855,
        "seek": 922476,
        "start": 9246.76,
        "temperature": 0,
        "text": " Just the act of loading the pixels.",
        "tokens": [
          51464,
          1449,
          264,
          605,
          295,
          15114,
          264,
          18668,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9253.76,
        "id": 2345,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9250.76,
        "temperature": 0,
        "text": " If you want to debug this for me with P5.",
        "tokens": [
          50414,
          759,
          291,
          528,
          281,
          24083,
          341,
          337,
          385,
          365,
          430,
          20,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9257.76,
        "id": 2346,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9254.76,
        "temperature": 0,
        "text": " If I take out all of this.",
        "tokens": [
          50614,
          759,
          286,
          747,
          484,
          439,
          295,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9261.76,
        "id": 2347,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9258.76,
        "temperature": 0,
        "text": " Just comment all of this out right now.",
        "tokens": [
          50814,
          1449,
          2871,
          439,
          295,
          341,
          484,
          558,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9264.76,
        "id": 2348,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9262.76,
        "temperature": 0,
        "text": " Let's be sure about this.",
        "tokens": [
          51014,
          961,
          311,
          312,
          988,
          466,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9267.76,
        "id": 2349,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9265.76,
        "temperature": 0,
        "text": " Refresh it.",
        "tokens": [
          51164,
          16957,
          3644,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9269.76,
        "id": 2350,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9268.76,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51314,
          1779,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9275.76,
        "id": 2351,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9269.76,
        "temperature": 0,
        "text": " Just the act of calling load pixels freezes the canvas element of the video.",
        "tokens": [
          51364,
          1449,
          264,
          605,
          295,
          5141,
          3677,
          18668,
          1737,
          12214,
          264,
          16267,
          4478,
          295,
          264,
          960,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21132214864095053,
        "compression_ratio": 1.4857142857142858,
        "end": 9277.76,
        "id": 2352,
        "no_speech_prob": 0.013428060337901115,
        "seek": 924976,
        "start": 9276.76,
        "temperature": 0,
        "text": " It's not supposed to do that.",
        "tokens": [
          51714,
          467,
          311,
          406,
          3442,
          281,
          360,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9279.76,
        "id": 2353,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9277.76,
        "temperature": 0,
        "text": " I don't recall that it used to do that.",
        "tokens": [
          50364,
          286,
          500,
          380,
          9901,
          300,
          309,
          1143,
          281,
          360,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9284.76,
        "id": 2354,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9280.76,
        "temperature": 0,
        "text": " I wonder if that's a new bug.",
        "tokens": [
          50514,
          286,
          2441,
          498,
          300,
          311,
          257,
          777,
          7426,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9286.76,
        "id": 2355,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9285.76,
        "temperature": 0,
        "text": " I'm using the latest P5.",
        "tokens": [
          50764,
          286,
          478,
          1228,
          264,
          6792,
          430,
          20,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9288.76,
        "id": 2356,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9287.76,
        "temperature": 0,
        "text": " Again, I've got to stop.",
        "tokens": [
          50864,
          3764,
          11,
          286,
          600,
          658,
          281,
          1590,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9290.76,
        "id": 2357,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9289.76,
        "temperature": 0,
        "text": " I've got to turn this off.",
        "tokens": [
          50964,
          286,
          600,
          658,
          281,
          1261,
          341,
          766,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9293.76,
        "id": 2358,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9291.76,
        "temperature": 0,
        "text": " But that's one of the first things I would do is go back and try earlier versions.",
        "tokens": [
          51064,
          583,
          300,
          311,
          472,
          295,
          264,
          700,
          721,
          286,
          576,
          360,
          307,
          352,
          646,
          293,
          853,
          3071,
          9606,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9296.76,
        "id": 2359,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9294.76,
        "temperature": 0,
        "text": " This feels like a bug in P5.",
        "tokens": [
          51214,
          639,
          3417,
          411,
          257,
          7426,
          294,
          430,
          20,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9300.76,
        "id": 2360,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9297.76,
        "temperature": 0,
        "text": " Let's just wrap all this up by...",
        "tokens": [
          51364,
          961,
          311,
          445,
          7019,
          439,
          341,
          493,
          538,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.18123266046697442,
        "compression_ratio": 1.5528846153846154,
        "end": 9305.76,
        "id": 2361,
        "no_speech_prob": 0.00208291201852262,
        "seek": 927776,
        "start": 9303.76,
        "temperature": 0,
        "text": " I'm going to put this back in.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          829,
          341,
          646,
          294,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21271046956380207,
        "compression_ratio": 1.3464566929133859,
        "end": 9310.76,
        "id": 2362,
        "no_speech_prob": 0.0004173107154201716,
        "seek": 930576,
        "start": 9306.76,
        "temperature": 0,
        "text": " I am going to add a...",
        "tokens": [
          50414,
          286,
          669,
          516,
          281,
          909,
          257,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.21271046956380207,
        "compression_ratio": 1.3464566929133859,
        "end": 9314.76,
        "id": 2363,
        "no_speech_prob": 0.0004173107154201716,
        "seek": 930576,
        "start": 9313.76,
        "temperature": 0,
        "text": " How do I do this?",
        "tokens": [
          50764,
          1012,
          360,
          286,
          360,
          341,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.21271046956380207,
        "compression_ratio": 1.3464566929133859,
        "end": 9317.76,
        "id": 2364,
        "no_speech_prob": 0.0004173107154201716,
        "seek": 930576,
        "start": 9315.76,
        "temperature": 0,
        "text": " I'm going to add a.env file.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          909,
          257,
          2411,
          268,
          85,
          3991,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21271046956380207,
        "compression_ratio": 1.3464566929133859,
        "end": 9320.76,
        "id": 2365,
        "no_speech_prob": 0.0004173107154201716,
        "seek": 930576,
        "start": 9318.76,
        "temperature": 0,
        "text": " No, not in public.",
        "tokens": [
          51014,
          883,
          11,
          406,
          294,
          1908,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21271046956380207,
        "compression_ratio": 1.3464566929133859,
        "end": 9326.76,
        "id": 2366,
        "no_speech_prob": 0.0004173107154201716,
        "seek": 930576,
        "start": 9324.76,
        "temperature": 0,
        "text": " Not a.env file. Sorry.",
        "tokens": [
          51314,
          1726,
          257,
          2411,
          268,
          85,
          3991,
          13,
          4919,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21271046956380207,
        "compression_ratio": 1.3464566929133859,
        "end": 9331.76,
        "id": 2367,
        "no_speech_prob": 0.0004173107154201716,
        "seek": 930576,
        "start": 9328.76,
        "temperature": 0,
        "text": " Come on. Make a new file down here. Thank you.",
        "tokens": [
          51514,
          2492,
          322,
          13,
          4387,
          257,
          777,
          3991,
          760,
          510,
          13,
          1044,
          291,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21271046956380207,
        "compression_ratio": 1.3464566929133859,
        "end": 9333.76,
        "id": 2368,
        "no_speech_prob": 0.0004173107154201716,
        "seek": 930576,
        "start": 9332.76,
        "temperature": 0,
        "text": " A.gitignore.",
        "tokens": [
          51714,
          316,
          2411,
          70,
          270,
          788,
          418,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9334.76,
        "id": 2369,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9333.76,
        "temperature": 0,
        "text": " That's what I want to do.",
        "tokens": [
          50364,
          663,
          311,
          437,
          286,
          528,
          281,
          360,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9339.76,
        "id": 2370,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9335.76,
        "temperature": 0,
        "text": " And in.gitignore, I'm going to ignore.env node modules.",
        "tokens": [
          50464,
          400,
          294,
          2411,
          70,
          270,
          788,
          418,
          11,
          286,
          478,
          516,
          281,
          11200,
          2411,
          268,
          85,
          9984,
          16679,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9347.76,
        "id": 2371,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9345.76,
        "temperature": 0,
        "text": " I don't really need this, but that's fine.",
        "tokens": [
          50964,
          286,
          500,
          380,
          534,
          643,
          341,
          11,
          457,
          300,
          311,
          2489,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9349.76,
        "id": 2372,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9348.76,
        "temperature": 0,
        "text": " Count is fine.",
        "tokens": [
          51114,
          5247,
          307,
          2489,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9351.76,
        "id": 2373,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9350.76,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51214,
          663,
          311,
          2489,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9352.76,
        "id": 2374,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9351.76,
        "temperature": 0,
        "text": " Read me, fine.",
        "tokens": [
          51264,
          17604,
          385,
          11,
          2489,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9353.76,
        "id": 2375,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9352.76,
        "temperature": 0,
        "text": " Server, fine.",
        "tokens": [
          51314,
          25684,
          11,
          2489,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9354.76,
        "id": 2376,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9353.76,
        "temperature": 0,
        "text": " I don't know what this is.",
        "tokens": [
          51364,
          286,
          500,
          380,
          458,
          437,
          341,
          307,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9357.76,
        "id": 2377,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9355.76,
        "temperature": 0,
        "text": " I don't know what this shrink wrap YAML thing is.",
        "tokens": [
          51464,
          286,
          500,
          380,
          458,
          437,
          341,
          23060,
          7019,
          398,
          2865,
          43,
          551,
          307,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18408558732372218,
        "compression_ratio": 1.683673469387755,
        "end": 9361.76,
        "id": 2378,
        "no_speech_prob": 0.0017274223500862718,
        "seek": 933376,
        "start": 9357.76,
        "temperature": 0,
        "text": " Let me just take that out because I don't need that for what I'm doing.",
        "tokens": [
          51564,
          961,
          385,
          445,
          747,
          300,
          484,
          570,
          286,
          500,
          380,
          643,
          300,
          337,
          437,
          286,
          478,
          884,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20914997552570544,
        "compression_ratio": 1.092783505154639,
        "end": 9363.76,
        "id": 2379,
        "no_speech_prob": 0.00011412185267545283,
        "seek": 936176,
        "start": 9361.76,
        "temperature": 0,
        "text": " That seems like a glitch thing.",
        "tokens": [
          50364,
          663,
          2544,
          411,
          257,
          23552,
          551,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20914997552570544,
        "compression_ratio": 1.092783505154639,
        "end": 9365.76,
        "id": 2380,
        "no_speech_prob": 0.00011412185267545283,
        "seek": 936176,
        "start": 9364.76,
        "temperature": 0,
        "text": " I can also take this out.",
        "tokens": [
          50514,
          286,
          393,
          611,
          747,
          341,
          484,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20914997552570544,
        "compression_ratio": 1.092783505154639,
        "end": 9370.76,
        "id": 2381,
        "no_speech_prob": 0.00011412185267545283,
        "seek": 936176,
        "start": 9369.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20914997552570544,
        "compression_ratio": 1.092783505154639,
        "end": 9372.76,
        "id": 2382,
        "no_speech_prob": 0.00011412185267545283,
        "seek": 936176,
        "start": 9370.76,
        "temperature": 0,
        "text": " So now...",
        "tokens": [
          50814,
          407,
          586,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.20914997552570544,
        "compression_ratio": 1.092783505154639,
        "end": 9381.76,
        "id": 2383,
        "no_speech_prob": 0.00011412185267545283,
        "seek": 936176,
        "start": 9378.76,
        "temperature": 0,
        "text": " Let's make a branch called main.",
        "tokens": [
          51214,
          961,
          311,
          652,
          257,
          9819,
          1219,
          2135,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2662237790914682,
        "compression_ratio": 1.224,
        "end": 9393.76,
        "id": 2384,
        "no_speech_prob": 0.009707674384117126,
        "seek": 939176,
        "start": 9391.76,
        "temperature": 0,
        "text": " Let's call this...",
        "tokens": [
          50364,
          961,
          311,
          818,
          341,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2662237790914682,
        "compression_ratio": 1.224,
        "end": 9401.76,
        "id": 2385,
        "no_speech_prob": 0.009707674384117126,
        "seek": 939176,
        "start": 9400.76,
        "temperature": 0,
        "text": " Sorry, what am I doing?",
        "tokens": [
          50814,
          4919,
          11,
          437,
          669,
          286,
          884,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2662237790914682,
        "compression_ratio": 1.224,
        "end": 9404.76,
        "id": 2386,
        "no_speech_prob": 0.009707674384117126,
        "seek": 939176,
        "start": 9401.76,
        "temperature": 0,
        "text": " This is updating to work with object detection.",
        "tokens": [
          50864,
          639,
          307,
          25113,
          281,
          589,
          365,
          2657,
          17784,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2662237790914682,
        "compression_ratio": 1.224,
        "end": 9410.76,
        "id": 2387,
        "no_speech_prob": 0.009707674384117126,
        "seek": 939176,
        "start": 9406.76,
        "temperature": 0,
        "text": " Then I'm going to go to github.com coding train.",
        "tokens": [
          51114,
          1396,
          286,
          478,
          516,
          281,
          352,
          281,
          290,
          355,
          836,
          13,
          1112,
          17720,
          3847,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2662237790914682,
        "compression_ratio": 1.224,
        "end": 9418.76,
        "id": 2388,
        "no_speech_prob": 0.009707674384117126,
        "seek": 939176,
        "start": 9417.76,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          51664,
          708,
          307,
          341,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.2292843670912192,
        "compression_ratio": 1.5174825174825175,
        "end": 9419.76,
        "id": 2389,
        "no_speech_prob": 0.002115646842867136,
        "seek": 941876,
        "start": 9418.76,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          50364,
          708,
          307,
          341,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.2292843670912192,
        "compression_ratio": 1.5174825174825175,
        "end": 9423.76,
        "id": 2390,
        "no_speech_prob": 0.002115646842867136,
        "seek": 941876,
        "start": 9419.76,
        "temperature": 0,
        "text": " Runway ML object detection.",
        "tokens": [
          50414,
          8950,
          676,
          21601,
          2657,
          17784,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2292843670912192,
        "compression_ratio": 1.5174825174825175,
        "end": 9437.76,
        "id": 2391,
        "no_speech_prob": 0.002115646842867136,
        "seek": 941876,
        "start": 9425.76,
        "temperature": 0,
        "text": " Object detection model with runway ml node.js and p5.js.",
        "tokens": [
          50714,
          24753,
          17784,
          2316,
          365,
          26642,
          23271,
          9984,
          13,
          25530,
          293,
          280,
          20,
          13,
          25530,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2292843670912192,
        "compression_ratio": 1.5174825174825175,
        "end": 9443.76,
        "id": 2392,
        "no_speech_prob": 0.002115646842867136,
        "seek": 941876,
        "start": 9441.76,
        "temperature": 0,
        "text": " No, I don't want to create a repository.",
        "tokens": [
          51514,
          883,
          11,
          286,
          500,
          380,
          528,
          281,
          1884,
          257,
          1085,
          329,
          270,
          827,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2292843670912192,
        "compression_ratio": 1.5174825174825175,
        "end": 9445.76,
        "id": 2393,
        "no_speech_prob": 0.002115646842867136,
        "seek": 941876,
        "start": 9443.76,
        "temperature": 0,
        "text": " Yeah, I do want to create a repository,",
        "tokens": [
          51614,
          865,
          11,
          286,
          360,
          528,
          281,
          1884,
          257,
          25841,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.2292843670912192,
        "compression_ratio": 1.5174825174825175,
        "end": 9447.76,
        "id": 2394,
        "no_speech_prob": 0.002115646842867136,
        "seek": 941876,
        "start": 9445.76,
        "temperature": 0,
        "text": " but I'm using an existing repository.",
        "tokens": [
          51714,
          457,
          286,
          478,
          1228,
          364,
          6741,
          25841,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9448.76,
        "id": 2395,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9447.76,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50364,
          821,
          321,
          352,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9450.76,
        "id": 2396,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9449.76,
        "temperature": 0,
        "text": " Then...",
        "tokens": [
          50464,
          1396,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9454.76,
        "id": 2397,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9453.76,
        "temperature": 0,
        "text": " Okay, so...",
        "tokens": [
          50664,
          1033,
          11,
          370,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9458.76,
        "id": 2398,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9457.76,
        "temperature": 0,
        "text": " This is what I want to do.",
        "tokens": [
          50864,
          639,
          307,
          437,
          286,
          528,
          281,
          360,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9460.76,
        "id": 2399,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9459.76,
        "temperature": 0,
        "text": " Add this.",
        "tokens": [
          50964,
          5349,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9461.76,
        "id": 2400,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9460.76,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51014,
          45263,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9464.76,
        "id": 2401,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9461.76,
        "temperature": 0,
        "text": " Origin, get remote-v.",
        "tokens": [
          51064,
          45313,
          11,
          483,
          8607,
          12,
          85,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9470.76,
        "id": 2402,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9465.76,
        "temperature": 0,
        "text": " Oh, because get remote remove origin.",
        "tokens": [
          51264,
          876,
          11,
          570,
          483,
          8607,
          4159,
          4957,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2510380268096924,
        "compression_ratio": 1.2654867256637168,
        "end": 9474.76,
        "id": 2403,
        "no_speech_prob": 0.007815337739884853,
        "seek": 944776,
        "start": 9473.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2469589645798142,
        "compression_ratio": 1.3058823529411765,
        "end": 9477.76,
        "id": 2404,
        "no_speech_prob": 0.0016482553910464048,
        "seek": 947476,
        "start": 9475.76,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          50414,
          876,
          11,
          1338,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2469589645798142,
        "compression_ratio": 1.3058823529411765,
        "end": 9482.76,
        "id": 2405,
        "no_speech_prob": 0.0016482553910464048,
        "seek": 947476,
        "start": 9477.76,
        "temperature": 0,
        "text": " Okay, and then get push origin main, I guess.",
        "tokens": [
          50514,
          1033,
          11,
          293,
          550,
          483,
          2944,
          4957,
          2135,
          11,
          286,
          2041,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2469589645798142,
        "compression_ratio": 1.3058823529411765,
        "end": 9490.76,
        "id": 2406,
        "no_speech_prob": 0.0016482553910464048,
        "seek": 947476,
        "start": 9487.76,
        "temperature": 0,
        "text": " So now all the code for it is here.",
        "tokens": [
          51014,
          407,
          586,
          439,
          264,
          3089,
          337,
          309,
          307,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2469589645798142,
        "compression_ratio": 1.3058823529411765,
        "end": 9495.76,
        "id": 2407,
        "no_speech_prob": 0.0016482553910464048,
        "seek": 947476,
        "start": 9492.76,
        "temperature": 0,
        "text": " And I can put that in Discord if anybody wants to look at it.",
        "tokens": [
          51264,
          400,
          286,
          393,
          829,
          300,
          294,
          32623,
          498,
          4472,
          2738,
          281,
          574,
          412,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2469589645798142,
        "compression_ratio": 1.3058823529411765,
        "end": 9499.76,
        "id": 2408,
        "no_speech_prob": 0.0016482553910464048,
        "seek": 947476,
        "start": 9497.76,
        "temperature": 0,
        "text": " Let's see, did the distream bot come back?",
        "tokens": [
          51514,
          961,
          311,
          536,
          11,
          630,
          264,
          1483,
          1572,
          10592,
          808,
          646,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2469589645798142,
        "compression_ratio": 1.3058823529411765,
        "end": 9500.76,
        "id": 2409,
        "no_speech_prob": 0.0016482553910464048,
        "seek": 947476,
        "start": 9499.76,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51614,
          883,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2469589645798142,
        "compression_ratio": 1.3058823529411765,
        "end": 9503.76,
        "id": 2410,
        "no_speech_prob": 0.0016482553910464048,
        "seek": 947476,
        "start": 9501.76,
        "temperature": 0,
        "text": " Run object detection.",
        "tokens": [
          51714,
          8950,
          2657,
          17784,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9505.76,
        "id": 2411,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9504.76,
        "temperature": 0,
        "text": " Okay, there we go.",
        "tokens": [
          50364,
          1033,
          11,
          456,
          321,
          352,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9506.76,
        "id": 2412,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9505.76,
        "temperature": 0,
        "text": " So this is the...",
        "tokens": [
          50414,
          407,
          341,
          307,
          264,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9509.76,
        "id": 2413,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9506.76,
        "temperature": 0,
        "text": " If you're in the Discord under live, under links,",
        "tokens": [
          50464,
          759,
          291,
          434,
          294,
          264,
          32623,
          833,
          1621,
          11,
          833,
          6123,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9511.76,
        "id": 2414,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9509.76,
        "temperature": 0,
        "text": " that's the GitHub repo.",
        "tokens": [
          50614,
          300,
          311,
          264,
          23331,
          49040,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9513.76,
        "id": 2415,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9511.76,
        "temperature": 0,
        "text": " And why not just put this on glitch now?",
        "tokens": [
          50714,
          400,
          983,
          406,
          445,
          829,
          341,
          322,
          23552,
          586,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9515.76,
        "id": 2416,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9514.76,
        "temperature": 0,
        "text": " It should be able to do.",
        "tokens": [
          50864,
          467,
          820,
          312,
          1075,
          281,
          360,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9522.76,
        "id": 2417,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9519.76,
        "temperature": 0,
        "text": " So the runway ML template, that was the first one.",
        "tokens": [
          51114,
          407,
          264,
          26642,
          21601,
          12379,
          11,
          300,
          390,
          264,
          700,
          472,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9526.76,
        "id": 2418,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9523.76,
        "temperature": 0,
        "text": " The spade coco ding train choo-choo runway ML template",
        "tokens": [
          51314,
          440,
          637,
          762,
          21611,
          21211,
          3847,
          1586,
          78,
          12,
          339,
          1986,
          26642,
          21601,
          12379,
          51464
        ]
      },
      {
        "avg_logprob": -0.22372529058173152,
        "compression_ratio": 1.5392156862745099,
        "end": 9528.76,
        "id": 2419,
        "no_speech_prob": 0.00043054448906332254,
        "seek": 950476,
        "start": 9526.76,
        "temperature": 0,
        "text": " is the next one for spade coco.",
        "tokens": [
          51464,
          307,
          264,
          958,
          472,
          337,
          637,
          762,
          21611,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1875461196899414,
        "compression_ratio": 1.460122699386503,
        "end": 9533.76,
        "id": 2420,
        "no_speech_prob": 0.026353145018219948,
        "seek": 952876,
        "start": 9529.76,
        "temperature": 0,
        "text": " And now new project import from GitHub.",
        "tokens": [
          50414,
          400,
          586,
          777,
          1716,
          974,
          490,
          23331,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1875461196899414,
        "compression_ratio": 1.460122699386503,
        "end": 9535.76,
        "id": 2421,
        "no_speech_prob": 0.026353145018219948,
        "seek": 952876,
        "start": 9534.76,
        "temperature": 0,
        "text": " I think this will work.",
        "tokens": [
          50664,
          286,
          519,
          341,
          486,
          589,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1875461196899414,
        "compression_ratio": 1.460122699386503,
        "end": 9542.76,
        "id": 2422,
        "no_speech_prob": 0.026353145018219948,
        "seek": 952876,
        "start": 9538.76,
        "temperature": 0,
        "text": " And just paste this in, import from GitHub there here.",
        "tokens": [
          50864,
          400,
          445,
          9163,
          341,
          294,
          11,
          974,
          490,
          23331,
          456,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1875461196899414,
        "compression_ratio": 1.460122699386503,
        "end": 9545.76,
        "id": 2423,
        "no_speech_prob": 0.026353145018219948,
        "seek": 952876,
        "start": 9544.76,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51164,
          961,
          311,
          536,
          437,
          2314,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1875461196899414,
        "compression_ratio": 1.460122699386503,
        "end": 9549.76,
        "id": 2424,
        "no_speech_prob": 0.026353145018219948,
        "seek": 952876,
        "start": 9548.76,
        "temperature": 0,
        "text": " Well, I'll let it load.",
        "tokens": [
          51364,
          1042,
          11,
          286,
          603,
          718,
          309,
          3677,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1875461196899414,
        "compression_ratio": 1.460122699386503,
        "end": 9550.76,
        "id": 2425,
        "no_speech_prob": 0.026353145018219948,
        "seek": 952876,
        "start": 9549.76,
        "temperature": 0,
        "text": " Let's give it a minute here.",
        "tokens": [
          51414,
          961,
          311,
          976,
          309,
          257,
          3456,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1875461196899414,
        "compression_ratio": 1.460122699386503,
        "end": 9555.76,
        "id": 2426,
        "no_speech_prob": 0.026353145018219948,
        "seek": 952876,
        "start": 9553.76,
        "temperature": 0,
        "text": " So this is the end, by the way, everybody.",
        "tokens": [
          51614,
          407,
          341,
          307,
          264,
          917,
          11,
          538,
          264,
          636,
          11,
          2201,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9563.76,
        "id": 2427,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9559.76,
        "temperature": 0,
        "text": " I'll be back, hopefully next Saturday.",
        "tokens": [
          50414,
          286,
          603,
          312,
          646,
          11,
          4696,
          958,
          8803,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9566.76,
        "id": 2428,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9563.76,
        "temperature": 0,
        "text": " We'll be taking at least one Saturday off in...",
        "tokens": [
          50614,
          492,
          603,
          312,
          1940,
          412,
          1935,
          472,
          8803,
          766,
          294,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9568.76,
        "id": 2429,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9567.76,
        "temperature": 0,
        "text": " Let me pause this for a second.",
        "tokens": [
          50814,
          961,
          385,
          10465,
          341,
          337,
          257,
          1150,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9570.76,
        "id": 2430,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9568.76,
        "temperature": 0,
        "text": " We'll be taking at least one Saturday off in November.",
        "tokens": [
          50864,
          492,
          603,
          312,
          1940,
          412,
          1935,
          472,
          8803,
          766,
          294,
          7674,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9574.76,
        "id": 2431,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9570.76,
        "temperature": 0,
        "text": " I scheduled to take the Saturday of Thanksgiving weekend off.",
        "tokens": [
          50964,
          286,
          15678,
          281,
          747,
          264,
          8803,
          295,
          21230,
          6711,
          766,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9577.76,
        "id": 2432,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9575.76,
        "temperature": 0,
        "text": " I am not going anywhere for Thanksgiving.",
        "tokens": [
          51214,
          286,
          669,
          406,
          516,
          4992,
          337,
          21230,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9580.76,
        "id": 2433,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9577.76,
        "temperature": 0,
        "text": " I am not having anyone come over for Thanksgiving.",
        "tokens": [
          51314,
          286,
          669,
          406,
          1419,
          2878,
          808,
          670,
          337,
          21230,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9584.76,
        "id": 2434,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9581.76,
        "temperature": 0,
        "text": " I don't think it's really safe or advisable to do so.",
        "tokens": [
          51514,
          286,
          500,
          380,
          519,
          309,
          311,
          534,
          3273,
          420,
          10280,
          712,
          281,
          360,
          370,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15482447065156082,
        "compression_ratio": 1.8553191489361702,
        "end": 9586.76,
        "id": 2435,
        "no_speech_prob": 0.0061925663612782955,
        "seek": 955876,
        "start": 9584.76,
        "temperature": 0,
        "text": " Everyone's got to make their own decision, of course.",
        "tokens": [
          51664,
          5198,
          311,
          658,
          281,
          652,
          641,
          1065,
          3537,
          11,
          295,
          1164,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9590.76,
        "id": 2436,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9587.76,
        "temperature": 0,
        "text": " Following your local guidelines and laws.",
        "tokens": [
          50414,
          19192,
          428,
          2654,
          12470,
          293,
          6064,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9594.76,
        "id": 2437,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9591.76,
        "temperature": 0,
        "text": " But so it's conceivable that I might live stream that weekend.",
        "tokens": [
          50614,
          583,
          370,
          309,
          311,
          10413,
          34376,
          300,
          286,
          1062,
          1621,
          4309,
          300,
          6711,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9595.76,
        "id": 2438,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9594.76,
        "temperature": 0,
        "text": " But we'll see.",
        "tokens": [
          50764,
          583,
          321,
          603,
          536,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9597.76,
        "id": 2439,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9596.76,
        "temperature": 0,
        "text": " A lot is going on.",
        "tokens": [
          50864,
          316,
          688,
          307,
          516,
          322,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9599.76,
        "id": 2440,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9597.76,
        "temperature": 0,
        "text": " This is a very busy time of year with the NYU semester,",
        "tokens": [
          50914,
          639,
          307,
          257,
          588,
          5856,
          565,
          295,
          1064,
          365,
          264,
          42682,
          11894,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9601.76,
        "id": 2441,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9599.76,
        "temperature": 0,
        "text": " which is wrapping up soon, which is a good thing for me",
        "tokens": [
          51014,
          597,
          307,
          21993,
          493,
          2321,
          11,
          597,
          307,
          257,
          665,
          551,
          337,
          385,
          51114
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9603.76,
        "id": 2442,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9601.76,
        "temperature": 0,
        "text": " in terms of more time to stream.",
        "tokens": [
          51114,
          294,
          2115,
          295,
          544,
          565,
          281,
          4309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9606.76,
        "id": 2443,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9603.76,
        "temperature": 0,
        "text": " But let's just see here.",
        "tokens": [
          51214,
          583,
          718,
          311,
          445,
          536,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9610.76,
        "id": 2444,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9607.76,
        "temperature": 0,
        "text": " I believe if I look at this, there shouldn't be anything in there.",
        "tokens": [
          51414,
          286,
          1697,
          498,
          286,
          574,
          412,
          341,
          11,
          456,
          4659,
          380,
          312,
          1340,
          294,
          456,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9611.76,
        "id": 2445,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9610.76,
        "temperature": 0,
        "text": " Yeah, right.",
        "tokens": [
          51564,
          865,
          11,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19902960709699496,
        "compression_ratio": 1.5766423357664234,
        "end": 9615.76,
        "id": 2446,
        "no_speech_prob": 0.0010986784473061562,
        "seek": 958676,
        "start": 9612.76,
        "temperature": 0,
        "text": " So this you can now also find this project,",
        "tokens": [
          51664,
          407,
          341,
          291,
          393,
          586,
          611,
          915,
          341,
          1716,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.23051442521991153,
        "compression_ratio": 1.477124183006536,
        "end": 9622.76,
        "id": 2447,
        "no_speech_prob": 0.0008969258633442223,
        "seek": 961576,
        "start": 9615.76,
        "temperature": 0,
        "text": " although I want to rename it to runway ML object detection.",
        "tokens": [
          50364,
          4878,
          286,
          528,
          281,
          36741,
          309,
          281,
          26642,
          21601,
          2657,
          17784,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23051442521991153,
        "compression_ratio": 1.477124183006536,
        "end": 9627.76,
        "id": 2448,
        "no_speech_prob": 0.0008969258633442223,
        "seek": 961576,
        "start": 9625.76,
        "temperature": 0,
        "text": " So now I should be able to...",
        "tokens": [
          50864,
          407,
          586,
          286,
          820,
          312,
          1075,
          281,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.23051442521991153,
        "compression_ratio": 1.477124183006536,
        "end": 9636.76,
        "id": 2449,
        "no_speech_prob": 0.0008969258633442223,
        "seek": 961576,
        "start": 9631.76,
        "temperature": 0,
        "text": " You should be able to see this project as well here.",
        "tokens": [
          51164,
          509,
          820,
          312,
          1075,
          281,
          536,
          341,
          1716,
          382,
          731,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23051442521991153,
        "compression_ratio": 1.477124183006536,
        "end": 9638.76,
        "id": 2450,
        "no_speech_prob": 0.0008969258633442223,
        "seek": 961576,
        "start": 9637.76,
        "temperature": 0,
        "text": " It's on the read me. Sorry about that.",
        "tokens": [
          51464,
          467,
          311,
          322,
          264,
          1401,
          385,
          13,
          4919,
          466,
          300,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23051442521991153,
        "compression_ratio": 1.477124183006536,
        "end": 9642.76,
        "id": 2451,
        "no_speech_prob": 0.0008969258633442223,
        "seek": 961576,
        "start": 9638.76,
        "temperature": 0,
        "text": " So I'm going to disable the model right now.",
        "tokens": [
          51514,
          407,
          286,
          478,
          516,
          281,
          28362,
          264,
          2316,
          558,
          586,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9646.76,
        "id": 2452,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9643.76,
        "temperature": 0,
        "text": " And the API keys aren't in this anyway.",
        "tokens": [
          50414,
          400,
          264,
          9362,
          9317,
          3212,
          380,
          294,
          341,
          4033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9647.76,
        "id": 2453,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9646.76,
        "temperature": 0,
        "text": " But so that wraps that up.",
        "tokens": [
          50564,
          583,
          370,
          300,
          25831,
          300,
          493,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9651.76,
        "id": 2454,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9647.76,
        "temperature": 0,
        "text": " So what is coming next on the coding train?",
        "tokens": [
          50614,
          407,
          437,
          307,
          1348,
          958,
          322,
          264,
          17720,
          3847,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9657.76,
        "id": 2455,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9651.76,
        "temperature": 0,
        "text": " Yesterday on Friday, I recorded four...",
        "tokens": [
          50814,
          19765,
          322,
          6984,
          11,
          286,
          8287,
          1451,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9660.76,
        "id": 2456,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9659.76,
        "temperature": 0,
        "text": " There are five.",
        "tokens": [
          51214,
          821,
          366,
          1732,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9661.76,
        "id": 2457,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9660.76,
        "temperature": 0,
        "text": " I have five in the can now.",
        "tokens": [
          51264,
          286,
          362,
          1732,
          294,
          264,
          393,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9664.76,
        "id": 2458,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9661.76,
        "temperature": 0,
        "text": " Five video tutorials to come out.",
        "tokens": [
          51314,
          9436,
          960,
          17616,
          281,
          808,
          484,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9669.76,
        "id": 2459,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9665.76,
        "temperature": 0,
        "text": " The first one is using ML5 convolutional neural network.",
        "tokens": [
          51514,
          440,
          700,
          472,
          307,
          1228,
          21601,
          20,
          45216,
          304,
          18161,
          3209,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23596446433763826,
        "compression_ratio": 1.4532019704433496,
        "end": 9670.76,
        "id": 2460,
        "no_speech_prob": 0.002590916818007827,
        "seek": 964276,
        "start": 9669.76,
        "temperature": 0,
        "text": " Part one.",
        "tokens": [
          51714,
          4100,
          472,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9673.76,
        "id": 2461,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9670.76,
        "temperature": 0,
        "text": " The second is using ML5 convolutional neural network.",
        "tokens": [
          50364,
          440,
          1150,
          307,
          1228,
          21601,
          20,
          45216,
          304,
          18161,
          3209,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9674.76,
        "id": 2462,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9673.76,
        "temperature": 0,
        "text": " Part two.",
        "tokens": [
          50514,
          4100,
          732,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9679.76,
        "id": 2463,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9674.76,
        "temperature": 0,
        "text": " The third is using the ML5 pre-trained convolutional neural network model,",
        "tokens": [
          50564,
          440,
          2636,
          307,
          1228,
          264,
          21601,
          20,
          659,
          12,
          17227,
          2001,
          45216,
          304,
          18161,
          3209,
          2316,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9680.76,
        "id": 2464,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9679.76,
        "temperature": 0,
        "text": " DoodleNet.",
        "tokens": [
          50814,
          1144,
          30013,
          31890,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9686.76,
        "id": 2465,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9681.76,
        "temperature": 0,
        "text": " The fourth is posting GIFs from your Discord bot.",
        "tokens": [
          50914,
          440,
          6409,
          307,
          15978,
          460,
          12775,
          82,
          490,
          428,
          32623,
          10592,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9688.76,
        "id": 2466,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9686.76,
        "temperature": 0,
        "text": " And the fifth is...",
        "tokens": [
          51164,
          400,
          264,
          9266,
          307,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9690.76,
        "id": 2467,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9689.76,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          51314,
          876,
          11,
          572,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9695.76,
        "id": 2468,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9690.76,
        "temperature": 0,
        "text": " The fourth is using a.env file to hide your API keys with a Discord bot,",
        "tokens": [
          51364,
          440,
          6409,
          307,
          1228,
          257,
          2411,
          268,
          85,
          3991,
          281,
          6479,
          428,
          9362,
          9317,
          365,
          257,
          32623,
          10592,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.20173653689297763,
        "compression_ratio": 1.6488888888888888,
        "end": 9698.76,
        "id": 2469,
        "no_speech_prob": 0.05261421203613281,
        "seek": 967076,
        "start": 9695.76,
        "temperature": 0,
        "text": " which if you watch today's stream, you're familiar with that somewhat.",
        "tokens": [
          51614,
          597,
          498,
          291,
          1159,
          965,
          311,
          4309,
          11,
          291,
          434,
          4963,
          365,
          300,
          8344,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9700.76,
        "id": 2470,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9698.76,
        "temperature": 0,
        "text": " And the fifth is posting GIFs.",
        "tokens": [
          50364,
          400,
          264,
          9266,
          307,
          15978,
          460,
          12775,
          82,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9703.76,
        "id": 2471,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9700.76,
        "temperature": 0,
        "text": " So hopefully those will come out soon.",
        "tokens": [
          50464,
          407,
          4696,
          729,
          486,
          808,
          484,
          2321,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9705.76,
        "id": 2472,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9704.76,
        "temperature": 0,
        "text": " If you...",
        "tokens": [
          50664,
          759,
          291,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9708.76,
        "id": 2473,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9705.76,
        "temperature": 0,
        "text": " I've been doing recording sessions on Fridays.",
        "tokens": [
          50714,
          286,
          600,
          668,
          884,
          6613,
          11081,
          322,
          46306,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9711.76,
        "id": 2474,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9708.76,
        "temperature": 0,
        "text": " It's a little bonus if you want to join as a member.",
        "tokens": [
          50864,
          467,
          311,
          257,
          707,
          10882,
          498,
          291,
          528,
          281,
          3917,
          382,
          257,
          4006,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9715.76,
        "id": 2475,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9711.76,
        "temperature": 0,
        "text": " You can sort of tune in to those recording sessions.",
        "tokens": [
          51014,
          509,
          393,
          1333,
          295,
          10864,
          294,
          281,
          729,
          6613,
          11081,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9716.76,
        "id": 2476,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9715.76,
        "temperature": 0,
        "text": " If you're not a member, don't worry.",
        "tokens": [
          51214,
          759,
          291,
          434,
          406,
          257,
          4006,
          11,
          500,
          380,
          3292,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9718.76,
        "id": 2477,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9716.76,
        "temperature": 0,
        "text": " You're really not missing anything.",
        "tokens": [
          51264,
          509,
          434,
          534,
          406,
          5361,
          1340,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9722.76,
        "id": 2478,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9718.76,
        "temperature": 0,
        "text": " Because ultimately, all the content from those recording sessions get released eventually.",
        "tokens": [
          51364,
          1436,
          6284,
          11,
          439,
          264,
          2701,
          490,
          729,
          6613,
          11081,
          483,
          4736,
          4728,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9724.76,
        "id": 2479,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9722.76,
        "temperature": 0,
        "text": " But if you want a little early access or to interact in that way,",
        "tokens": [
          51564,
          583,
          498,
          291,
          528,
          257,
          707,
          2440,
          2105,
          420,
          281,
          4648,
          294,
          300,
          636,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.18900477091471354,
        "compression_ratio": 1.7755102040816326,
        "end": 9727.76,
        "id": 2480,
        "no_speech_prob": 0.03258207067847252,
        "seek": 969876,
        "start": 9724.76,
        "temperature": 0,
        "text": " you're welcome to join the coding train membership program.",
        "tokens": [
          51664,
          291,
          434,
          2928,
          281,
          3917,
          264,
          17720,
          3847,
          16560,
          1461,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2028502828067111,
        "compression_ratio": 1.6213991769547325,
        "end": 9732.76,
        "id": 2481,
        "no_speech_prob": 0.0014549549669027328,
        "seek": 972876,
        "start": 9729.76,
        "temperature": 0,
        "text": " Hopefully at least one of them will come out next week.",
        "tokens": [
          50414,
          10429,
          412,
          1935,
          472,
          295,
          552,
          486,
          808,
          484,
          958,
          1243,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2028502828067111,
        "compression_ratio": 1.6213991769547325,
        "end": 9735.76,
        "id": 2482,
        "no_speech_prob": 0.0014549549669027328,
        "seek": 972876,
        "start": 9732.76,
        "temperature": 0,
        "text": " My process has really slowed down for better or worse.",
        "tokens": [
          50564,
          1222,
          1399,
          575,
          534,
          32057,
          760,
          337,
          1101,
          420,
          5324,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2028502828067111,
        "compression_ratio": 1.6213991769547325,
        "end": 9740.76,
        "id": 2483,
        "no_speech_prob": 0.0014549549669027328,
        "seek": 972876,
        "start": 9736.76,
        "temperature": 0,
        "text": " But I'm working with doing some video editing and getting the descriptions",
        "tokens": [
          50764,
          583,
          286,
          478,
          1364,
          365,
          884,
          512,
          960,
          10000,
          293,
          1242,
          264,
          24406,
          50964
        ]
      },
      {
        "avg_logprob": -0.2028502828067111,
        "compression_ratio": 1.6213991769547325,
        "end": 9744.76,
        "id": 2484,
        "no_speech_prob": 0.0014549549669027328,
        "seek": 972876,
        "start": 9740.76,
        "temperature": 0,
        "text": " and the captions and all that stuff done before they are released.",
        "tokens": [
          50964,
          293,
          264,
          44832,
          293,
          439,
          300,
          1507,
          1096,
          949,
          436,
          366,
          4736,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2028502828067111,
        "compression_ratio": 1.6213991769547325,
        "end": 9750.76,
        "id": 2485,
        "no_speech_prob": 0.0014549549669027328,
        "seek": 972876,
        "start": 9744.76,
        "temperature": 0,
        "text": " I'm looking in the chat to see if there's any questions or otherwise things coming out.",
        "tokens": [
          51164,
          286,
          478,
          1237,
          294,
          264,
          5081,
          281,
          536,
          498,
          456,
          311,
          604,
          1651,
          420,
          5911,
          721,
          1348,
          484,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2028502828067111,
        "compression_ratio": 1.6213991769547325,
        "end": 9752.76,
        "id": 2486,
        "no_speech_prob": 0.0014549549669027328,
        "seek": 972876,
        "start": 9750.76,
        "temperature": 0,
        "text": " Question mark wheel.",
        "tokens": [
          51464,
          14464,
          1491,
          5589,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2028502828067111,
        "compression_ratio": 1.6213991769547325,
        "end": 9755.76,
        "id": 2487,
        "no_speech_prob": 0.0014549549669027328,
        "seek": 972876,
        "start": 9752.76,
        "temperature": 0,
        "text": " Ah, I'm told the prefix changed.",
        "tokens": [
          51564,
          2438,
          11,
          286,
          478,
          1907,
          264,
          46969,
          3105,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9757.76,
        "id": 2488,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9756.76,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50414,
          821,
          321,
          352,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9758.76,
        "id": 2489,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9757.76,
        "temperature": 0,
        "text": " Question mark wheel.",
        "tokens": [
          50464,
          14464,
          1491,
          5589,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9762.76,
        "id": 2490,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9758.76,
        "temperature": 0,
        "text": " The prefix in train bot 2.0 distream bot had changed.",
        "tokens": [
          50514,
          440,
          46969,
          294,
          3847,
          10592,
          568,
          13,
          15,
          1483,
          1572,
          10592,
          632,
          3105,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9763.76,
        "id": 2491,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9762.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9768.76,
        "id": 2492,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9765.76,
        "temperature": 0,
        "text": " So anyway, I hope you enjoyed today's live stream.",
        "tokens": [
          50864,
          407,
          4033,
          11,
          286,
          1454,
          291,
          4626,
          965,
          311,
          1621,
          4309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9773.76,
        "id": 2493,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9768.76,
        "temperature": 0,
        "text": " I feel like last week was such a disaster.",
        "tokens": [
          51014,
          286,
          841,
          411,
          1036,
          1243,
          390,
          1270,
          257,
          11293,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9776.76,
        "id": 2494,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9774.76,
        "temperature": 0,
        "text": " Unmitigated disaster, I suppose.",
        "tokens": [
          51314,
          1156,
          3508,
          328,
          770,
          11293,
          11,
          286,
          7297,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9777.76,
        "id": 2495,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9776.76,
        "temperature": 0,
        "text": " Put everyone...",
        "tokens": [
          51414,
          4935,
          1518,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9779.76,
        "id": 2496,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9777.76,
        "temperature": 0,
        "text": " Hey, Patricia Parker!",
        "tokens": [
          51464,
          1911,
          11,
          34307,
          20155,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9782.76,
        "id": 2497,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9780.76,
        "temperature": 0,
        "text": " Hold the presses!",
        "tokens": [
          51614,
          6962,
          264,
          40892,
          0,
          51714
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9783.76,
        "id": 2498,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9782.76,
        "temperature": 0,
        "text": " Stop!",
        "tokens": [
          51714,
          5535,
          0,
          51764
        ]
      },
      {
        "avg_logprob": -0.24297338724136353,
        "compression_ratio": 1.396135265700483,
        "end": 9784.76,
        "id": 2499,
        "no_speech_prob": 0.010985856875777245,
        "seek": 975576,
        "start": 9783.76,
        "temperature": 0,
        "text": " Pause!",
        "tokens": [
          51764,
          31973,
          0,
          51814
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9788.76,
        "id": 2500,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9785.76,
        "temperature": 0,
        "text": " Let's everybody take a moment to welcome...",
        "tokens": [
          50364,
          961,
          311,
          2201,
          747,
          257,
          1623,
          281,
          2928,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9790.76,
        "id": 2501,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9789.76,
        "temperature": 0,
        "text": " Patricia Parker!",
        "tokens": [
          50564,
          34307,
          20155,
          0,
          50614
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9793.76,
        "id": 2502,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9790.76,
        "temperature": 0,
        "text": " Welcome for boarding the coding train.",
        "tokens": [
          50614,
          4027,
          337,
          30528,
          264,
          17720,
          3847,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9797.76,
        "id": 2503,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9794.76,
        "temperature": 0,
        "text": " We'll ring the bell for you and blow the train whistle.",
        "tokens": [
          50814,
          492,
          603,
          4875,
          264,
          4549,
          337,
          291,
          293,
          6327,
          264,
          3847,
          23470,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9800.76,
        "id": 2504,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9798.76,
        "temperature": 0,
        "text": " Your membership is greatly appreciated.",
        "tokens": [
          51014,
          2260,
          16560,
          307,
          14147,
          17169,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9801.76,
        "id": 2505,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9800.76,
        "temperature": 0,
        "text": " It is really just...",
        "tokens": [
          51114,
          467,
          307,
          534,
          445,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9803.76,
        "id": 2506,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9801.76,
        "temperature": 0,
        "text": " I'm honored and thrilled and thankful.",
        "tokens": [
          51164,
          286,
          478,
          14556,
          293,
          18744,
          293,
          13611,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9807.76,
        "id": 2507,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9804.76,
        "temperature": 0,
        "text": " And for each member of the coding train.",
        "tokens": [
          51314,
          400,
          337,
          1184,
          4006,
          295,
          264,
          17720,
          3847,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9809.76,
        "id": 2508,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9808.76,
        "temperature": 0,
        "text": " At some point you will get some stickers in the mail.",
        "tokens": [
          51514,
          1711,
          512,
          935,
          291,
          486,
          483,
          512,
          21019,
          294,
          264,
          10071,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9810.76,
        "id": 2509,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9809.76,
        "temperature": 0,
        "text": " I'm getting myself...",
        "tokens": [
          51564,
          286,
          478,
          1242,
          2059,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.21899212531323703,
        "compression_ratio": 1.6416666666666666,
        "end": 9811.76,
        "id": 2510,
        "no_speech_prob": 0.0036494212690740824,
        "seek": 978576,
        "start": 9810.76,
        "temperature": 0,
        "text": " It's actually been...",
        "tokens": [
          51614,
          467,
          311,
          767,
          668,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9816.76,
        "id": 2511,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9812.76,
        "temperature": 0,
        "text": " Actually, the sticker mailing process is really working quite well.",
        "tokens": [
          50414,
          5135,
          11,
          264,
          20400,
          41612,
          1399,
          307,
          534,
          1364,
          1596,
          731,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9818.76,
        "id": 2512,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9816.76,
        "temperature": 0,
        "text": " Much better than it ever has before.",
        "tokens": [
          50614,
          12313,
          1101,
          813,
          309,
          1562,
          575,
          949,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9820.76,
        "id": 2513,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9818.76,
        "temperature": 0,
        "text": " So stay tuned for more about that.",
        "tokens": [
          50714,
          407,
          1754,
          10870,
          337,
          544,
          466,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9821.76,
        "id": 2514,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9820.76,
        "temperature": 0,
        "text": " That's happening soon.",
        "tokens": [
          50814,
          663,
          311,
          2737,
          2321,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9824.76,
        "id": 2515,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9822.76,
        "temperature": 0,
        "text": " A lot of you got them recently.",
        "tokens": [
          50914,
          316,
          688,
          295,
          291,
          658,
          552,
          3938,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9826.76,
        "id": 2516,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9824.76,
        "temperature": 0,
        "text": " But all of you who have joined in the last few weeks,",
        "tokens": [
          51014,
          583,
          439,
          295,
          291,
          567,
          362,
          6869,
          294,
          264,
          1036,
          1326,
          3259,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9828.76,
        "id": 2517,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9826.76,
        "temperature": 0,
        "text": " you should be getting them soon.",
        "tokens": [
          51114,
          291,
          820,
          312,
          1242,
          552,
          2321,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9830.76,
        "id": 2518,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9828.76,
        "temperature": 0,
        "text": " I know poor David has been waiting like two years.",
        "tokens": [
          51214,
          286,
          458,
          4716,
          4389,
          575,
          668,
          3806,
          411,
          732,
          924,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9832.76,
        "id": 2519,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9830.76,
        "temperature": 0,
        "text": " And there was like some...",
        "tokens": [
          51314,
          400,
          456,
          390,
          411,
          512,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9833.76,
        "id": 2520,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9832.76,
        "temperature": 0,
        "text": " A lot of mix-ups that happened.",
        "tokens": [
          51414,
          316,
          688,
          295,
          2890,
          12,
          7528,
          300,
          2011,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9834.76,
        "id": 2521,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9833.76,
        "temperature": 0,
        "text": " So my apologies to David.",
        "tokens": [
          51464,
          407,
          452,
          34929,
          281,
          4389,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.243960205078125,
        "compression_ratio": 1.599290780141844,
        "end": 9837.76,
        "id": 2522,
        "no_speech_prob": 0.009703333489596844,
        "seek": 981176,
        "start": 9834.76,
        "temperature": 0,
        "text": " But Patricia, your random number.",
        "tokens": [
          51514,
          583,
          34307,
          11,
          428,
          4974,
          1230,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25114273658165565,
        "compression_ratio": 1.2,
        "end": 9843.76,
        "id": 2523,
        "no_speech_prob": 0.03730522841215134,
        "seek": 984176,
        "start": 9842.76,
        "temperature": 0,
        "text": " Is...",
        "tokens": [
          50414,
          1119,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.25114273658165565,
        "compression_ratio": 1.2,
        "end": 9846.76,
        "id": 2524,
        "no_speech_prob": 0.03730522841215134,
        "seek": 984176,
        "start": 9843.76,
        "temperature": 0,
        "text": " And again, we really need a system for keeping track of all these.",
        "tokens": [
          50464,
          400,
          797,
          11,
          321,
          534,
          643,
          257,
          1185,
          337,
          5145,
          2837,
          295,
          439,
          613,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25114273658165565,
        "compression_ratio": 1.2,
        "end": 9853.76,
        "id": 2525,
        "no_speech_prob": 0.03730522841215134,
        "seek": 984176,
        "start": 9849.76,
        "temperature": 0,
        "text": " On page 187, row 9308, column...",
        "tokens": [
          50764,
          1282,
          3028,
          2443,
          22,
          11,
          5386,
          1722,
          3446,
          23,
          11,
          7738,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.25114273658165565,
        "compression_ratio": 1.2,
        "end": 9858.76,
        "id": 2526,
        "no_speech_prob": 0.03730522841215134,
        "seek": 984176,
        "start": 9855.76,
        "temperature": 0,
        "text": " 4, 73803.",
        "tokens": [
          51064,
          1017,
          11,
          28387,
          4702,
          18,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25114273658165565,
        "compression_ratio": 1.2,
        "end": 9861.76,
        "id": 2527,
        "no_speech_prob": 0.03730522841215134,
        "seek": 984176,
        "start": 9858.76,
        "temperature": 0,
        "text": " Thank you, Patricia.",
        "tokens": [
          51214,
          1044,
          291,
          11,
          34307,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.25114273658165565,
        "compression_ratio": 1.2,
        "end": 9864.76,
        "id": 2528,
        "no_speech_prob": 0.03730522841215134,
        "seek": 984176,
        "start": 9863.76,
        "temperature": 0,
        "text": " Reset my song.",
        "tokens": [
          51464,
          5015,
          302,
          452,
          2153,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25114273658165565,
        "compression_ratio": 1.2,
        "end": 9868.76,
        "id": 2529,
        "no_speech_prob": 0.03730522841215134,
        "seek": 984176,
        "start": 9866.76,
        "temperature": 0,
        "text": " Greetings Lars from Denmark.",
        "tokens": [
          51614,
          20032,
          41563,
          490,
          28065,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9874.76,
        "id": 2530,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9871.76,
        "temperature": 0,
        "text": " I was thinking what I would do actually with the...",
        "tokens": [
          50364,
          286,
          390,
          1953,
          437,
          286,
          576,
          360,
          767,
          365,
          264,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9877.76,
        "id": 2531,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9875.76,
        "temperature": 0,
        "text": " Tutorial about how to post a GIF to your Discord bot.",
        "tokens": [
          50564,
          18392,
          5181,
          466,
          577,
          281,
          2183,
          257,
          460,
          12775,
          281,
          428,
          32623,
          10592,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9879.76,
        "id": 2532,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9877.76,
        "temperature": 0,
        "text": " That I would release two versions of it.",
        "tokens": [
          50664,
          663,
          286,
          576,
          4374,
          732,
          9606,
          295,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9881.76,
        "id": 2533,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9879.76,
        "temperature": 0,
        "text": " One with me saying GIF.",
        "tokens": [
          50764,
          1485,
          365,
          385,
          1566,
          460,
          12775,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9883.76,
        "id": 2534,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9881.76,
        "temperature": 0,
        "text": " And one with me saying JIF.",
        "tokens": [
          50864,
          400,
          472,
          365,
          385,
          1566,
          508,
          12775,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9885.76,
        "id": 2535,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9883.76,
        "temperature": 0,
        "text": " It would be exactly the same tutorial.",
        "tokens": [
          50964,
          467,
          576,
          312,
          2293,
          264,
          912,
          7073,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9886.76,
        "id": 2536,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9885.76,
        "temperature": 0,
        "text": " But I'd have two...",
        "tokens": [
          51064,
          583,
          286,
          1116,
          362,
          732,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9888.76,
        "id": 2537,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9886.76,
        "temperature": 0,
        "text": " Actually, I think I really will do this.",
        "tokens": [
          51114,
          5135,
          11,
          286,
          519,
          286,
          534,
          486,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9890.76,
        "id": 2538,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9888.76,
        "temperature": 0,
        "text": " So I'm just gonna have to dub it over.",
        "tokens": [
          51214,
          407,
          286,
          478,
          445,
          799,
          362,
          281,
          18540,
          309,
          670,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9892.76,
        "id": 2539,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9890.76,
        "temperature": 0,
        "text": " Or use machine learning or something.",
        "tokens": [
          51314,
          1610,
          764,
          3479,
          2539,
          420,
          746,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9893.76,
        "id": 2540,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9892.76,
        "temperature": 0,
        "text": " I think I should dub it over actually.",
        "tokens": [
          51414,
          286,
          519,
          286,
          820,
          18540,
          309,
          670,
          767,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9894.76,
        "id": 2541,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9893.76,
        "temperature": 0,
        "text": " But just...",
        "tokens": [
          51464,
          583,
          445,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9897.76,
        "id": 2542,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9894.76,
        "temperature": 0,
        "text": " And then this is where you post your GIF.",
        "tokens": [
          51514,
          400,
          550,
          341,
          307,
          689,
          291,
          2183,
          428,
          460,
          12775,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23685425789125503,
        "compression_ratio": 1.8613138686131387,
        "end": 9899.76,
        "id": 2543,
        "no_speech_prob": 0.8185104131698608,
        "seek": 987176,
        "start": 9897.76,
        "temperature": 0,
        "text": " And then this is where you post your JIF.",
        "tokens": [
          51664,
          400,
          550,
          341,
          307,
          689,
          291,
          2183,
          428,
          508,
          12775,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9902.76,
        "id": 2544,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9900.76,
        "temperature": 0,
        "text": " So I think that'll be pretty awesome.",
        "tokens": [
          50414,
          407,
          286,
          519,
          300,
          603,
          312,
          1238,
          3476,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9905.76,
        "id": 2545,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9904.76,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50614,
          2798,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9908.76,
        "id": 2546,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9905.76,
        "temperature": 0,
        "text": " Bruno's asking me if I regenerated all the keys leaked early.",
        "tokens": [
          50664,
          23046,
          311,
          3365,
          385,
          498,
          286,
          26358,
          770,
          439,
          264,
          9317,
          31779,
          2440,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9909.76,
        "id": 2547,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9908.76,
        "temperature": 0,
        "text": " I think I did.",
        "tokens": [
          50814,
          286,
          519,
          286,
          630,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9913.76,
        "id": 2548,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9909.76,
        "temperature": 0,
        "text": " But I think I either regenerated or then I disabled the models.",
        "tokens": [
          50864,
          583,
          286,
          519,
          286,
          2139,
          26358,
          770,
          420,
          550,
          286,
          15191,
          264,
          5245,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9917.76,
        "id": 2549,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9914.76,
        "temperature": 0,
        "text": " I'm letting this run for another two minutes.",
        "tokens": [
          51114,
          286,
          478,
          8295,
          341,
          1190,
          337,
          1071,
          732,
          2077,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9920.76,
        "id": 2550,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9917.76,
        "temperature": 0,
        "text": " I'll answer any questions that I see in the chat.",
        "tokens": [
          51264,
          286,
          603,
          1867,
          604,
          1651,
          300,
          286,
          536,
          294,
          264,
          5081,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9924.76,
        "id": 2551,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9921.76,
        "temperature": 0,
        "text": " By the way, what's funny to me about the membership thing...",
        "tokens": [
          51464,
          3146,
          264,
          636,
          11,
          437,
          311,
          4074,
          281,
          385,
          466,
          264,
          16560,
          551,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.19189575390938002,
        "compression_ratio": 1.6450381679389312,
        "end": 9928.76,
        "id": 2552,
        "no_speech_prob": 0.036758903414011,
        "seek": 989976,
        "start": 9924.76,
        "temperature": 0,
        "text": " Is literally that message will come in if somebody just happened to join at this time.",
        "tokens": [
          51614,
          1119,
          3736,
          300,
          3636,
          486,
          808,
          294,
          498,
          2618,
          445,
          2011,
          281,
          3917,
          412,
          341,
          565,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9929.76,
        "id": 2553,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9928.76,
        "temperature": 0,
        "text": " And I'm not actually tuning in.",
        "tokens": [
          50364,
          400,
          286,
          478,
          406,
          767,
          15164,
          294,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9931.76,
        "id": 2554,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9929.76,
        "temperature": 0,
        "text": " I know I said this already in the livestream.",
        "tokens": [
          50414,
          286,
          458,
          286,
          848,
          341,
          1217,
          294,
          264,
          29782,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9933.76,
        "id": 2555,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9931.76,
        "temperature": 0,
        "text": " So Patricia, I don't know if you're actually there.",
        "tokens": [
          50514,
          407,
          34307,
          11,
          286,
          500,
          380,
          458,
          498,
          291,
          434,
          767,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9934.76,
        "id": 2556,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9933.76,
        "temperature": 0,
        "text": " But please make sure you...",
        "tokens": [
          50614,
          583,
          1767,
          652,
          988,
          291,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9939.76,
        "id": 2557,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9934.76,
        "temperature": 0,
        "text": " If you are there, Patricia, make sure you sign up and get information about the Discord.",
        "tokens": [
          50664,
          759,
          291,
          366,
          456,
          11,
          34307,
          11,
          652,
          988,
          291,
          1465,
          493,
          293,
          483,
          1589,
          466,
          264,
          32623,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9940.76,
        "id": 2558,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9939.76,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50914,
          1079,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9942.76,
        "id": 2559,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9940.76,
        "temperature": 0,
        "text": " The way it's pronounced is definitely GIF.",
        "tokens": [
          50964,
          440,
          636,
          309,
          311,
          23155,
          307,
          2138,
          460,
          12775,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9944.76,
        "id": 2560,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9942.76,
        "temperature": 0,
        "text": " That's how it's pronounced.",
        "tokens": [
          51064,
          663,
          311,
          577,
          309,
          311,
          23155,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9947.76,
        "id": 2561,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9946.76,
        "temperature": 0,
        "text": " Am I from Denmark?",
        "tokens": [
          51264,
          2012,
          286,
          490,
          28065,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9948.76,
        "id": 2562,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9947.76,
        "temperature": 0,
        "text": " I am not from Denmark.",
        "tokens": [
          51314,
          286,
          669,
          406,
          490,
          28065,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9950.76,
        "id": 2563,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9948.76,
        "temperature": 0,
        "text": " Have I ever been to Denmark?",
        "tokens": [
          51364,
          3560,
          286,
          1562,
          668,
          281,
          28065,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9952.76,
        "id": 2564,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9950.76,
        "temperature": 0,
        "text": " Nobody asked that question, but I'm asking it.",
        "tokens": [
          51464,
          9297,
          2351,
          300,
          1168,
          11,
          457,
          286,
          478,
          3365,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9955.76,
        "id": 2565,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9954.76,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51664,
          883,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1997292658665797,
        "compression_ratio": 1.6989247311827957,
        "end": 9956.76,
        "id": 2566,
        "no_speech_prob": 0.12078874558210373,
        "seek": 992876,
        "start": 9955.76,
        "temperature": 0,
        "text": " I have never been to Denmark.",
        "tokens": [
          51714,
          286,
          362,
          1128,
          668,
          281,
          28065,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9958.76,
        "id": 2567,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9956.76,
        "temperature": 0,
        "text": " I've got to get to Denmark.",
        "tokens": [
          50364,
          286,
          600,
          658,
          281,
          483,
          281,
          28065,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9960.76,
        "id": 2568,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9958.76,
        "temperature": 0,
        "text": " An unoriginal pun.",
        "tokens": [
          50464,
          1107,
          517,
          29042,
          4468,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9961.76,
        "id": 2569,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9960.76,
        "temperature": 0,
        "text": " If you're still watching.",
        "tokens": [
          50564,
          759,
          291,
          434,
          920,
          1976,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9963.76,
        "id": 2570,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9961.76,
        "temperature": 0,
        "text": " I've got to talk to you about Okinawa, Japan.",
        "tokens": [
          50614,
          286,
          600,
          658,
          281,
          751,
          281,
          291,
          466,
          3477,
          1426,
          4151,
          11,
          3367,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9969.76,
        "id": 2571,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9965.76,
        "temperature": 0,
        "text": " I'm in the market for a place to live for a little while.",
        "tokens": [
          50814,
          286,
          478,
          294,
          264,
          2142,
          337,
          257,
          1081,
          281,
          1621,
          337,
          257,
          707,
          1339,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9973.76,
        "id": 2572,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9971.76,
        "temperature": 0,
        "text": " And I have fantasies of going to various places.",
        "tokens": [
          51114,
          400,
          286,
          362,
          31255,
          530,
          295,
          516,
          281,
          3683,
          3190,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9976.76,
        "id": 2573,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9973.76,
        "temperature": 0,
        "text": " And Okinawa, Japan is kind of on my list.",
        "tokens": [
          51214,
          400,
          3477,
          1426,
          4151,
          11,
          3367,
          307,
          733,
          295,
          322,
          452,
          1329,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9977.76,
        "id": 2574,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9976.76,
        "temperature": 0,
        "text": " If...",
        "tokens": [
          51364,
          759,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9978.76,
        "id": 2575,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9977.76,
        "temperature": 0,
        "text": " Patricia is here.",
        "tokens": [
          51414,
          34307,
          307,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9979.76,
        "id": 2576,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9978.76,
        "temperature": 0,
        "text": " Hi, Patricia.",
        "tokens": [
          51464,
          2421,
          11,
          34307,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1961864243205796,
        "compression_ratio": 1.6222222222222222,
        "end": 9983.76,
        "id": 2577,
        "no_speech_prob": 0.013806132599711418,
        "seek": 995676,
        "start": 9979.76,
        "temperature": 0,
        "text": " If you live somewhere beautiful and amazing in the world...",
        "tokens": [
          51514,
          759,
          291,
          1621,
          4079,
          2238,
          293,
          2243,
          294,
          264,
          1002,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 9990.76,
        "id": 2578,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 9984.76,
        "temperature": 0,
        "text": " I have what I'm hoping is a six-month period where I could, with my family, go on a little adventure.",
        "tokens": [
          50414,
          286,
          362,
          437,
          286,
          478,
          7159,
          307,
          257,
          2309,
          12,
          23534,
          2896,
          689,
          286,
          727,
          11,
          365,
          452,
          1605,
          11,
          352,
          322,
          257,
          707,
          9868,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 9992.76,
        "id": 2579,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 9990.76,
        "temperature": 0,
        "text": " You know, assuming this is far off in the future.",
        "tokens": [
          50714,
          509,
          458,
          11,
          11926,
          341,
          307,
          1400,
          766,
          294,
          264,
          2027,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 9999.76,
        "id": 2580,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 9992.76,
        "temperature": 0,
        "text": " I'm kind of assuming that the world will hopefully be mostly recovered from the pandemic currently.",
        "tokens": [
          50814,
          286,
          478,
          733,
          295,
          11926,
          300,
          264,
          1002,
          486,
          4696,
          312,
          5240,
          19542,
          490,
          264,
          5388,
          4362,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 10002.76,
        "id": 2581,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 9999.76,
        "temperature": 0,
        "text": " That's a huge assumption, obviously.",
        "tokens": [
          51164,
          663,
          311,
          257,
          2603,
          15302,
          11,
          2745,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 10005.76,
        "id": 2582,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 10002.76,
        "temperature": 0,
        "text": " But I'm starting to plan for that possibility.",
        "tokens": [
          51314,
          583,
          286,
          478,
          2891,
          281,
          1393,
          337,
          300,
          7959,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 10007.76,
        "id": 2583,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 10005.76,
        "temperature": 0,
        "text": " Just to look forward to something.",
        "tokens": [
          51464,
          1449,
          281,
          574,
          2128,
          281,
          746,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 10009.76,
        "id": 2584,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 10007.76,
        "temperature": 0,
        "text": " I hope that you have something to look forward to.",
        "tokens": [
          51564,
          286,
          1454,
          300,
          291,
          362,
          746,
          281,
          574,
          2128,
          281,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1988094036395733,
        "compression_ratio": 1.6593406593406594,
        "end": 10011.76,
        "id": 2585,
        "no_speech_prob": 0.2170487493276596,
        "seek": 998376,
        "start": 10009.76,
        "temperature": 0,
        "text": " Boy, this is really depressing.",
        "tokens": [
          51664,
          9486,
          11,
          341,
          307,
          534,
          36355,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10013.76,
        "id": 2586,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10011.76,
        "temperature": 0,
        "text": " There's 20 seconds left.",
        "tokens": [
          50364,
          821,
          311,
          945,
          3949,
          1411,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10017.76,
        "id": 2587,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10016.76,
        "temperature": 0,
        "text": " Don't go to Denmark.",
        "tokens": [
          50614,
          1468,
          380,
          352,
          281,
          28065,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10018.76,
        "id": 2588,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10017.76,
        "temperature": 0,
        "text": " Norway. I have been to Norway.",
        "tokens": [
          50664,
          24354,
          13,
          286,
          362,
          668,
          281,
          24354,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10021.76,
        "id": 2589,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10018.76,
        "temperature": 0,
        "text": " Okay. Can I tell you about one of my favorite places in the world?",
        "tokens": [
          50714,
          1033,
          13,
          1664,
          286,
          980,
          291,
          466,
          472,
          295,
          452,
          2954,
          3190,
          294,
          264,
          1002,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10026.76,
        "id": 2590,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10023.76,
        "temperature": 0,
        "text": " I have some of my favorite memories in life from this place.",
        "tokens": [
          50964,
          286,
          362,
          512,
          295,
          452,
          2954,
          8495,
          294,
          993,
          490,
          341,
          1081,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10028.76,
        "id": 2591,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10026.76,
        "temperature": 0,
        "text": " And I'm going to tell you all about it right now.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          980,
          291,
          439,
          466,
          309,
          558,
          586,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10032.76,
        "id": 2592,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10028.76,
        "temperature": 0,
        "text": " It is the island of Runda in Norway.",
        "tokens": [
          51214,
          467,
          307,
          264,
          6077,
          295,
          497,
          11946,
          294,
          24354,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10035.76,
        "id": 2593,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10033.76,
        "temperature": 0,
        "text": " This is where it is. Right here.",
        "tokens": [
          51464,
          639,
          307,
          689,
          309,
          307,
          13,
          1779,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17424275459499533,
        "compression_ratio": 1.5855855855855856,
        "end": 10037.76,
        "id": 2594,
        "no_speech_prob": 0.04135763645172119,
        "seek": 1001176,
        "start": 10035.76,
        "temperature": 0,
        "text": " I can zoom all the way out.",
        "tokens": [
          51564,
          286,
          393,
          8863,
          439,
          264,
          636,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10040.76,
        "id": 2595,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10037.76,
        "temperature": 0,
        "text": " I spent three or four days there with my family.",
        "tokens": [
          50364,
          286,
          4418,
          1045,
          420,
          1451,
          1708,
          456,
          365,
          452,
          1605,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10043.76,
        "id": 2596,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10040.76,
        "temperature": 0,
        "text": " I believe it means Bird Island.",
        "tokens": [
          50514,
          286,
          1697,
          309,
          1355,
          15931,
          7637,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10045.76,
        "id": 2597,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10043.76,
        "temperature": 0,
        "text": " And we went on hikes.",
        "tokens": [
          50664,
          400,
          321,
          1437,
          322,
          276,
          8916,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10048.76,
        "id": 2598,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10045.76,
        "temperature": 0,
        "text": " We hiked all the way out to this lighthouse here.",
        "tokens": [
          50764,
          492,
          276,
          44070,
          439,
          264,
          636,
          484,
          281,
          341,
          47481,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10053.76,
        "id": 2599,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10048.76,
        "temperature": 0,
        "text": " And by the way, there's no way to get to that lighthouse other than hiking.",
        "tokens": [
          50914,
          400,
          538,
          264,
          636,
          11,
          456,
          311,
          572,
          636,
          281,
          483,
          281,
          300,
          47481,
          661,
          813,
          23784,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10055.76,
        "id": 2600,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10053.76,
        "temperature": 0,
        "text": " And it was like an hours and hours hike.",
        "tokens": [
          51164,
          400,
          309,
          390,
          411,
          364,
          2496,
          293,
          2496,
          23282,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10059.76,
        "id": 2601,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10055.76,
        "temperature": 0,
        "text": " I had a three-year-old and a six-year-old at the time.",
        "tokens": [
          51264,
          286,
          632,
          257,
          1045,
          12,
          5294,
          12,
          2641,
          293,
          257,
          2309,
          12,
          5294,
          12,
          2641,
          412,
          264,
          565,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10061.76,
        "id": 2602,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10059.76,
        "temperature": 0,
        "text": " It was a really amazing adventure.",
        "tokens": [
          51464,
          467,
          390,
          257,
          534,
          2243,
          9868,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18115176260471344,
        "compression_ratio": 1.7601626016260163,
        "end": 10065.76,
        "id": 2603,
        "no_speech_prob": 0.09668121486902237,
        "seek": 1003776,
        "start": 10061.76,
        "temperature": 0,
        "text": " And I actually asked, when I got there, the proprietor of the lighthouse.",
        "tokens": [
          51564,
          400,
          286,
          767,
          2351,
          11,
          562,
          286,
          658,
          456,
          11,
          264,
          27881,
          284,
          295,
          264,
          47481,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10068.76,
        "id": 2604,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10065.76,
        "temperature": 0,
        "text": " Which you can stay overnight there for free if you hike out there.",
        "tokens": [
          50364,
          3013,
          291,
          393,
          1754,
          13935,
          456,
          337,
          1737,
          498,
          291,
          23282,
          484,
          456,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10072.76,
        "id": 2605,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10068.76,
        "temperature": 0,
        "text": " I asked the proprietor if there was maybe a boat that could take us back.",
        "tokens": [
          50514,
          286,
          2351,
          264,
          27881,
          284,
          498,
          456,
          390,
          1310,
          257,
          6582,
          300,
          727,
          747,
          505,
          646,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10076.76,
        "id": 2606,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10072.76,
        "temperature": 0,
        "text": " And they laughed at me in a friendly way.",
        "tokens": [
          50714,
          400,
          436,
          20881,
          412,
          385,
          294,
          257,
          9208,
          636,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10077.76,
        "id": 2607,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10076.76,
        "temperature": 0,
        "text": " It's kind of funny.",
        "tokens": [
          50914,
          467,
          311,
          733,
          295,
          4074,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10078.76,
        "id": 2608,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10077.76,
        "temperature": 0,
        "text": " We hiked back.",
        "tokens": [
          50964,
          492,
          276,
          44070,
          646,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10079.76,
        "id": 2609,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10078.76,
        "temperature": 0,
        "text": " I had such an amazing time.",
        "tokens": [
          51014,
          286,
          632,
          1270,
          364,
          2243,
          565,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10081.76,
        "id": 2610,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10079.76,
        "temperature": 0,
        "text": " We went there to see puffins.",
        "tokens": [
          51064,
          492,
          1437,
          456,
          281,
          536,
          19613,
          1292,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10083.76,
        "id": 2611,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10081.76,
        "temperature": 0,
        "text": " We were at the wrong time of year.",
        "tokens": [
          51164,
          492,
          645,
          412,
          264,
          2085,
          565,
          295,
          1064,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10084.76,
        "id": 2612,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10083.76,
        "temperature": 0,
        "text": " There were no puffins.",
        "tokens": [
          51264,
          821,
          645,
          572,
          19613,
          1292,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10086.76,
        "id": 2613,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10084.76,
        "temperature": 0,
        "text": " But I really just had – I would love to go back there.",
        "tokens": [
          51314,
          583,
          286,
          534,
          445,
          632,
          220,
          5815,
          286,
          576,
          959,
          281,
          352,
          646,
          456,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19160049767802945,
        "compression_ratio": 1.7158273381294964,
        "end": 10092.76,
        "id": 2614,
        "no_speech_prob": 0.008187511935830116,
        "seek": 1006576,
        "start": 10086.76,
        "temperature": 0,
        "text": " That was really just an amazing time on this little spot in the world that we visited.",
        "tokens": [
          51414,
          663,
          390,
          534,
          445,
          364,
          2243,
          565,
          322,
          341,
          707,
          4008,
          294,
          264,
          1002,
          300,
          321,
          11220,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10094.76,
        "id": 2615,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10093.76,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10096.76,
        "id": 2616,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10094.76,
        "temperature": 0,
        "text": " 16 seconds left.",
        "tokens": [
          50464,
          3165,
          3949,
          1411,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10099.76,
        "id": 2617,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10098.76,
        "temperature": 0,
        "text": " All right, everyone.",
        "tokens": [
          50664,
          1057,
          558,
          11,
          1518,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10103.76,
        "id": 2618,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10099.76,
        "temperature": 0,
        "text": " I will see you hopefully next – stay tuned.",
        "tokens": [
          50714,
          286,
          486,
          536,
          291,
          4696,
          958,
          1662,
          1754,
          10870,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10104.76,
        "id": 2619,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10103.76,
        "temperature": 0,
        "text": " Probably next Saturday.",
        "tokens": [
          50914,
          9210,
          958,
          8803,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10108.76,
        "id": 2620,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10104.76,
        "temperature": 0,
        "text": " But some Saturday in the future here on the Coding Brain.",
        "tokens": [
          50964,
          583,
          512,
          8803,
          294,
          264,
          2027,
          510,
          322,
          264,
          383,
          8616,
          29783,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10109.76,
        "id": 2621,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10108.76,
        "temperature": 0,
        "text": " Hopefully in the morning again on my time.",
        "tokens": [
          51164,
          10429,
          294,
          264,
          2446,
          797,
          322,
          452,
          565,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10110.76,
        "id": 2622,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10109.76,
        "temperature": 0,
        "text": " But we'll see.",
        "tokens": [
          51214,
          583,
          321,
          603,
          536,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23009787379084407,
        "compression_ratio": 1.3928571428571428,
        "end": 10111.76,
        "id": 2623,
        "no_speech_prob": 0.034096766263246536,
        "seek": 1009276,
        "start": 10110.76,
        "temperature": 0,
        "text": " Bye.",
        "tokens": [
          51264,
          4621,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.6112904071807861,
        "compression_ratio": 0.9565217391304348,
        "end": 10113.76,
        "id": 2624,
        "no_speech_prob": 0.7419118881225586,
        "seek": 1011176,
        "start": 10111.76,
        "temperature": 0.6000000000000001,
        "text": " As always, I always forget to Vistac.",
        "tokens": [
          50364,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          281,
          691,
          468,
          326,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.6112904071807861,
        "compression_ratio": 0.9565217391304348,
        "end": 10116.76,
        "id": 2625,
        "no_speech_prob": 0.7419118881225586,
        "seek": 1011176,
        "start": 10115.76,
        "temperature": 0.6000000000000001,
        "text": " Uh-oh.",
        "tokens": [
          50564,
          4019,
          12,
          1445,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10173.76,
        "id": 2626,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10172.76,
        "temperature": 0,
        "text": " I'm gonna do the Vistac.",
        "tokens": [
          50414,
          286,
          478,
          799,
          360,
          264,
          691,
          468,
          326,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10175.76,
        "id": 2627,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10173.76,
        "temperature": 0,
        "text": " Vistac! Vistac! Vistac!",
        "tokens": [
          50464,
          691,
          468,
          326,
          0,
          691,
          468,
          326,
          0,
          691,
          468,
          326,
          0,
          50564
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10177.76,
        "id": 2628,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10175.76,
        "temperature": 0,
        "text": " The Vistac song, never forget the Vistac.",
        "tokens": [
          50564,
          440,
          691,
          468,
          326,
          2153,
          11,
          1128,
          2870,
          264,
          691,
          468,
          326,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10180.76,
        "id": 2629,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10178.76,
        "temperature": 0,
        "text": " Somebody compose that song for me.",
        "tokens": [
          50714,
          13463,
          35925,
          300,
          2153,
          337,
          385,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10195.76,
        "id": 2630,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10193.76,
        "temperature": 0,
        "text": " I'm gonna say once again.",
        "tokens": [
          51464,
          286,
          478,
          799,
          584,
          1564,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10196.76,
        "id": 2631,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10195.76,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51564,
          1692,
          321,
          352,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10197.76,
        "id": 2632,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10196.76,
        "temperature": 0,
        "text": " Sing it with me.",
        "tokens": [
          51614,
          7474,
          309,
          365,
          385,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.30406851768493653,
        "compression_ratio": 1.5390625,
        "end": 10199.76,
        "id": 2633,
        "no_speech_prob": 0.31161031126976013,
        "seek": 1017176,
        "start": 10197.76,
        "temperature": 0,
        "text": " It's the fourth.",
        "tokens": [
          51664,
          467,
          311,
          264,
          6409,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3077732631138393,
        "compression_ratio": 1.3736263736263736,
        "end": 10202.76,
        "id": 2634,
        "no_speech_prob": 0.2712017893791199,
        "seek": 1019976,
        "start": 10199.76,
        "temperature": 0,
        "text": " To Cartesian coordinate songs.",
        "tokens": [
          50364,
          1407,
          22478,
          42434,
          15670,
          5781,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3077732631138393,
        "compression_ratio": 1.3736263736263736,
        "end": 10210.76,
        "id": 2635,
        "no_speech_prob": 0.2712017893791199,
        "seek": 1019976,
        "start": 10206.76,
        "temperature": 0,
        "text": " It's the fourth to Cartesian coordinate songs.",
        "tokens": [
          50714,
          467,
          311,
          264,
          6409,
          281,
          22478,
          42434,
          15670,
          5781,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3077732631138393,
        "compression_ratio": 1.3736263736263736,
        "end": 10227.76,
        "id": 2636,
        "no_speech_prob": 0.2712017893791199,
        "seek": 1019976,
        "start": 10224.76,
        "temperature": 0,
        "text": " Autotune and the internet will fix that for me.",
        "tokens": [
          51614,
          6049,
          310,
          2613,
          293,
          264,
          4705,
          486,
          3191,
          300,
          337,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.9641514608304794,
        "compression_ratio": 2.3870967741935485,
        "end": 10231.76,
        "id": 2637,
        "no_speech_prob": 0.10576209425926208,
        "seek": 1022976,
        "start": 10229.76,
        "temperature": 1,
        "text": " Everyone is welcome, right?",
        "tokens": [
          50364,
          5198,
          307,
          2928,
          11,
          558,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.9641514608304794,
        "compression_ratio": 2.3870967741935485,
        "end": 10235.76,
        "id": 2638,
        "no_speech_prob": 0.10576209425926208,
        "seek": 1022976,
        "start": 10233.76,
        "temperature": 1,
        "text": " It's the fourth.",
        "tokens": [
          50564,
          467,
          311,
          220,
          3322,
          6409,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.9641514608304794,
        "compression_ratio": 2.3870967741935485,
        "end": 10236.76,
        "id": 2639,
        "no_speech_prob": 0.10576209425926208,
        "seek": 1022976,
        "start": 10235.76,
        "temperature": 1,
        "text": " To Cartesian...",
        "tokens": [
          50664,
          1407,
          22478,
          42434,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.9641514608304794,
        "compression_ratio": 2.3870967741935485,
        "end": 10239.76,
        "id": 2640,
        "no_speech_prob": 0.10576209425926208,
        "seek": 1022976,
        "start": 10236.76,
        "temperature": 1,
        "text": "... coordinate songs.",
        "tokens": [
          50714,
          1097,
          15670,
          5781,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.9641514608304794,
        "compression_ratio": 2.3870967741935485,
        "end": 10246.76,
        "id": 2641,
        "no_speech_prob": 0.10576209425926208,
        "seek": 1022976,
        "start": 10242.76,
        "temperature": 1,
        "text": " It's the fourth to Cartesian coordinate songs.",
        "tokens": [
          51014,
          467,
          311,
          264,
          6409,
          281,
          2741,
          7269,
          952,
          15670,
          5781,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.9641514608304794,
        "compression_ratio": 2.3870967741935485,
        "end": 10250.76,
        "id": 2642,
        "no_speech_prob": 0.10576209425926208,
        "seek": 1022976,
        "start": 10247.76,
        "temperature": 1,
        "text": " It's the fourth to Cartesian coordinate songs.",
        "tokens": [
          51264,
          467,
          311,
          264,
          6409,
          220,
          1353,
          2741,
          7269,
          952,
          15670,
          5781,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.9641514608304794,
        "compression_ratio": 2.3870967741935485,
        "end": 10253.76,
        "id": 2643,
        "no_speech_prob": 0.10576209425926208,
        "seek": 1022976,
        "start": 10250.76,
        "temperature": 1,
        "text": " It's the fourth to Cartesian coordinate songs.",
        "tokens": [
          51414,
          467,
          311,
          264,
          32012,
          81,
          392,
          281,
          22478,
          42434,
          15670,
          370,
          872,
          82,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10256.76,
        "id": 2644,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10253.76,
        "temperature": 0,
        "text": " It's the fourth to Cartesian coordinate songs.",
        "tokens": [
          50364,
          467,
          311,
          264,
          6409,
          281,
          22478,
          42434,
          15670,
          5781,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10260.76,
        "id": 2645,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10258.76,
        "temperature": 0,
        "text": " Unicorns and rainbows and cupcakes.",
        "tokens": [
          50614,
          1156,
          23115,
          82,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10262.76,
        "id": 2646,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10260.76,
        "temperature": 0,
        "text": " What else is there?",
        "tokens": [
          50714,
          708,
          1646,
          307,
          456,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10265.76,
        "id": 2647,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10263.76,
        "temperature": 0,
        "text": " Yes, kittens. Thank you very much.",
        "tokens": [
          50864,
          1079,
          11,
          47363,
          13,
          1044,
          291,
          588,
          709,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10267.76,
        "id": 2648,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10265.76,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50964,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10269.76,
        "id": 2649,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10267.76,
        "temperature": 0,
        "text": " Notice that. Look what I get.",
        "tokens": [
          51064,
          13428,
          300,
          13,
          2053,
          437,
          286,
          483,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10271.76,
        "id": 2650,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10269.76,
        "temperature": 0,
        "text": " I'm really losing my mind.",
        "tokens": [
          51164,
          286,
          478,
          534,
          7027,
          452,
          1575,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2286357644163532,
        "compression_ratio": 1.4335260115606936,
        "end": 10273.76,
        "id": 2651,
        "no_speech_prob": 0.32015690207481384,
        "seek": 1025376,
        "start": 10272.76,
        "temperature": 0,
        "text": " Okay, let's do it.",
        "tokens": [
          51314,
          1033,
          11,
          718,
          311,
          360,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.7938421794346401,
        "compression_ratio": 2,
        "end": 10283.76,
        "id": 2652,
        "no_speech_prob": 0.9477493166923523,
        "seek": 1027376,
        "start": 10273.76,
        "temperature": 0.6000000000000001,
        "text": " Kittens, kittens, kittens, kittens, kittens...",
        "tokens": [
          50364,
          591,
          39449,
          11,
          47363,
          11,
          47363,
          11,
          47363,
          11,
          47363,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.7676118703988882,
        "compression_ratio": 1.317829457364341,
        "end": 10314.24,
        "id": 2653,
        "no_speech_prob": 0.11737722158432007,
        "seek": 1030376,
        "start": 10303.76,
        "temperature": 0.8,
        "text": " This is usually the part of the livestream as I'm packing up that I, I like to do a little",
        "tokens": [
          50364,
          639,
          307,
          32247,
          379,
          264,
          644,
          295,
          264,
          29782,
          382,
          286,
          478,
          20815,
          493,
          300,
          286,
          11,
          286,
          411,
          281,
          360,
          257,
          707,
          50888
        ]
      },
      {
        "avg_logprob": -0.7676118703988882,
        "compression_ratio": 1.317829457364341,
        "end": 10318.32,
        "id": 2654,
        "no_speech_prob": 0.11737722158432007,
        "seek": 1030376,
        "start": 10314.24,
        "temperature": 0.8,
        "text": " behind the scenes here.",
        "tokens": [
          50888,
          2261,
          264,
          8026,
          510,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.7676118703988882,
        "compression_ratio": 1.317829457364341,
        "end": 10324.22,
        "id": 2655,
        "no_speech_prob": 0.11737722158432007,
        "seek": 1030376,
        "start": 10318.32,
        "temperature": 0.8,
        "text": " Take down the green screen.",
        "tokens": [
          51092,
          3664,
          360,
          895,
          264,
          3092,
          2568,
          13,
          51387
        ]
      },
      {
        "avg_logprob": -0.7676118703988882,
        "compression_ratio": 1.317829457364341,
        "end": 10330.66,
        "id": 2656,
        "no_speech_prob": 0.11737722158432007,
        "seek": 1030376,
        "start": 10324.22,
        "temperature": 0.8,
        "text": " We can turn off the lights.",
        "tokens": [
          51387,
          492,
          393,
          1261,
          766,
          264,
          5811,
          13,
          51709
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10332.34,
        "id": 2657,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10331.34,
        "temperature": 0,
        "text": " I gotta listen.",
        "tokens": [
          50398,
          286,
          3428,
          2140,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10334.539999999999,
        "id": 2658,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10332.34,
        "temperature": 0,
        "text": " I'm very curious to listen back to how this microphone is.",
        "tokens": [
          50448,
          286,
          478,
          588,
          6369,
          281,
          2140,
          646,
          281,
          577,
          341,
          10952,
          307,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10338.46,
        "id": 2659,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10334.539999999999,
        "temperature": 0,
        "text": " If I even have it like set up correctly.",
        "tokens": [
          50558,
          759,
          286,
          754,
          362,
          309,
          411,
          992,
          493,
          8944,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10345.98,
        "id": 2660,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10338.46,
        "temperature": 0,
        "text": " Come on control center.",
        "tokens": [
          50754,
          2492,
          322,
          1969,
          3056,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10346.98,
        "id": 2661,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10345.98,
        "temperature": 0,
        "text": " Turn off the light.",
        "tokens": [
          51130,
          7956,
          766,
          264,
          1442,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10347.98,
        "id": 2662,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10346.98,
        "temperature": 0,
        "text": " Oh darkness.",
        "tokens": [
          51180,
          876,
          11262,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10348.98,
        "id": 2663,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10347.98,
        "temperature": 0,
        "text": " Oh it's so dark.",
        "tokens": [
          51230,
          876,
          309,
          311,
          370,
          2877,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.4645177439639443,
        "compression_ratio": 1.4390243902439024,
        "end": 10355.98,
        "id": 2664,
        "no_speech_prob": 0.0036498645786195993,
        "seek": 1033066,
        "start": 10348.98,
        "temperature": 0,
        "text": " I didn't realize I had all the lights off now.",
        "tokens": [
          51280,
          286,
          994,
          380,
          4325,
          286,
          632,
          439,
          264,
          5811,
          766,
          586,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.48259648409756745,
        "compression_ratio": 1.3587786259541985,
        "end": 10360.18,
        "id": 2665,
        "no_speech_prob": 0.0003981988993473351,
        "seek": 1035598,
        "start": 10356.3,
        "temperature": 0,
        "text": " Should at least turn on the regular lights.",
        "tokens": [
          50380,
          6454,
          412,
          1935,
          1261,
          322,
          264,
          3890,
          5811,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.48259648409756745,
        "compression_ratio": 1.3587786259541985,
        "end": 10363.74,
        "id": 2666,
        "no_speech_prob": 0.0003981988993473351,
        "seek": 1035598,
        "start": 10360.18,
        "temperature": 0,
        "text": " Which now I'm realizing that's why the key was weird.",
        "tokens": [
          50574,
          3013,
          586,
          286,
          478,
          16734,
          300,
          311,
          983,
          264,
          2141,
          390,
          3657,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.48259648409756745,
        "compression_ratio": 1.3587786259541985,
        "end": 10369.58,
        "id": 2667,
        "no_speech_prob": 0.0003981988993473351,
        "seek": 1035598,
        "start": 10363.74,
        "temperature": 0,
        "text": " I have these other just regular lamps that usually brighten up the green screen.",
        "tokens": [
          50752,
          286,
          362,
          613,
          661,
          445,
          3890,
          34887,
          300,
          2673,
          49007,
          493,
          264,
          3092,
          2568,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.6465330600738526,
        "compression_ratio": 1.2702702702702702,
        "end": 10400.619999999999,
        "id": 2668,
        "no_speech_prob": 0.14218588173389435,
        "seek": 1038598,
        "start": 10385.98,
        "temperature": 0,
        "text": " Thanks everybody for watching.",
        "tokens": [
          50364,
          2561,
          2201,
          337,
          1976,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.6465330600738526,
        "compression_ratio": 1.2702702702702702,
        "end": 10403.3,
        "id": 2669,
        "no_speech_prob": 0.14218588173389435,
        "seek": 1038598,
        "start": 10400.619999999999,
        "temperature": 0,
        "text": " I think I have successfully put everything away.",
        "tokens": [
          51096,
          286,
          519,
          286,
          362,
          10727,
          829,
          1203,
          1314,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.6465330600738526,
        "compression_ratio": 1.2702702702702702,
        "end": 10406.859999999999,
        "id": 2670,
        "no_speech_prob": 0.14218588173389435,
        "seek": 1038598,
        "start": 10403.3,
        "temperature": 0,
        "text": " This is the big grand finale of the song.",
        "tokens": [
          51230,
          639,
          307,
          264,
          955,
          2697,
          23510,
          295,
          264,
          2153,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.6465330600738526,
        "compression_ratio": 1.2702702702702702,
        "end": 10412.859999999999,
        "id": 2671,
        "no_speech_prob": 0.14218588173389435,
        "seek": 1038598,
        "start": 10406.859999999999,
        "temperature": 0,
        "text": " Wish I had the cat.",
        "tokens": [
          51408,
          27697,
          286,
          632,
          264,
          3857,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -1.836029325212751,
        "compression_ratio": 0.6363636363636364,
        "end": 10417.380000000001,
        "id": 2672,
        "no_speech_prob": 0.35892632603645325,
        "seek": 1041286,
        "start": 10412.86,
        "temperature": 1,
        "text": " All right bye.",
        "tokens": [
          50382,
          1057,
          558,
          6543,
          13,
          50590
        ]
      }
    ],
    "transcription": " Audio sound check now. My audio should be better than it usually is because I have a new microphone, but I am curious to hear from you what it sounds like. Let me know! Second audio sound check. I actually had the audio of the music doubled, so now this is a better check. Although everyone said it sounded good before. All right. Can anyone actually tell that this mic is better than what I used to use last week? I'll be starting in about two minutes or one minute and 40 seconds. All right. All right. All right. All right. All right. All right. Hello! There's got to be a universal way to say good blank with all of the different times. Good day, but it might be the middle of the night for some of you. Good day! I said good day! Good morning, good afternoon, good evening, good middle of the night to all of you. Hi, this is Dan coming to you live from an attic in Brooklyn, New York, where it is a beautiful day outside, although getting a little chilly. This is not the time I usually like to livestream. This is actually the time I usually like to take a nap. But, you know, I'm wearing my cozy sweater. I'm here on the internet with all of you. So far, nobody's said anything like this has stopped working, so I'm assuming I'm actually livestreaming. Now, I've been working steadily to improve the quality of my livestreams. As you might remember, last week I received some new... I received. I did receive them because I ordered them when they came, but I installed some new lights. So my skin and my face and everything should be looking positively aglow for you. Now, the cool, crisp, dulcet tones of my voice should be arriving into your ear... devices in a new and perhaps higher quality way because, and I'm just going to hold this up for you, I, uh, this is not a sponsored anything, although, hey, I'm available, Elgato. Elgato, are you listening? This is the Elgato Wave 3 mic that I ordered. And somebody in the chat, Rahith, just said, oh no, it stopped working. But I'm assuming only Rahith is having an issue with the livestream right now. Rahith, come back! Come back, Rahith. I want you to be experiencing the dulcet tones of my voice in my new microphone. I don't know. I probably should get one of those things where it's like on an arm and it swivels around and it's just like propped right here, but I don't know. I don't know if that's for me. Every week I would like to make a small upgrade, which incidentally, I have nothing left to upgrade. So if you've got any ideas for me, let me know what I should upgrade for next week. Actually, there is something also new that I would like to experiment with. Let me see here if we can get this to work. This is a new feature that I will be using on the Coding Train. And I'm just going to quickly test it right now. I probably should do more to introduce myself and what I'm going to be doing today. But bear with me. I'm moving to here. Oh, and I've got my glitch page open. But actually, let me remove this. No! What? No. Ah! Wrong button. All right, I have to do this manually. Well, this is very silly what I'm doing now. I can't find my screen to remove it. Oh, it's so hard. Where? Oh, there it is. Oh, I'm in emptiness. It is so sad here in the emptiness. All right, this is fine. Just put that back. It doesn't matter. Spoiler alert. I'm going to use glitch. Let's see here. So, everyone who is a Coding Train member, meaning you've signed up through the subscription. No, that's not the right. I'm trying to not use the word paid, but honestly, that's what it is. There's a Discord available for everyone. There's a public Discord for anybody who wants to join. I just posted a link to it in the chat. But I also have, if you would like to join the Coding Train membership program. I feel like... For your membership in the Coding Train, you will receive not very much, to be perfectly honest. But it's a nice smaller community of folks. We've got a channel in the Discord dedicated to chatting during the live stream. And what I am very excited to demonstrate for you right now, and most likely it's not going to work. I was having some problems. I was having some problems. But David Snyder and Kobe, who are... I can upgrade the green screen area, says Bruno. Oh, wait. Let's make this. I don't have to. I need this on... You know what I need to do? I need to put this on a tablet. I don't know why I didn't think of this. I need a tablet. We need a mobile version of this. Touch enabled. Click. Ah, it crashed. So, I don't know what's going on. But we're attempting to debug this. I'm using a piece of software known as DisStreamChat. Which I suppose is Discord plus streaming and plus chatting. But I always think it's trying to diss me. Oh, I amused myself. Let's run it again. I have a feeling it's going to... For some reason right now, it's got this really wonderful feature where it works the second time I click the button. But as soon as I click Bruno, I hope this is okay with you. I'm going to assume this is okay with Bruno. Bruno, can you give me a big thumbs up that I'm going to bring your chat message onto the screen right here? I will wait. Because I actually... So, what I should say is that anyone who now posts in... And I could use a different channel for this. But in the members Discord live chat channel. Then your message... I have a mechanism by which I can click a button and your message pops up on the screen here. Using the DisStreamChat software by David and Koby. Okay. I'm waiting for Bruno to say okay. In the meantime... Bruno is typing, everybody. Bruno is... Bruno is... It's okay, says Bruno. So, now let me go back over to here. I really hope this works. There it is. Look. Bruno's message popped up. Maybe I should move this. Where should this be? Ideally, where should this be positioned? How come it won't move? How come the... Ah! What is wrong with Open Broadcast Studio? I can't move it. That's so weird. But anyway... You can see Bruno's message there. And I can even show you that Bruno said... I think this might crash. Let's see. And it crashed. Oh, well. So, I'm not going to use this anymore, probably. Unless we can figure it out. And I don't know how to get Bruno's message off now. But this is my idea that... That I will be able to interact a bit more by answering questions and showing messages. By selecting them and curating them and monitoring them. To have them show up on my fancy live streaming rectangle over here. Ah, now. Kenan says, Daniel, I have a lot of homework. But I am watching you. And Kenan, I have one thing to say to you. And I think everybody knows what I'm going to say. You can all think about it for a minute. Say it to yourselves. Mm-mm. Please. Go and do your homework. I mean, my goodness. I understand the desire to procrastinate. But I cannot imagine that anything I do here today is in any way, shape, or form anywhere close to nearly as meaningful, impactful, and important as your homework. So, I encourage you to do your homework. You know, maybe you've budgeted your time. You know you'll have enough time. Then I suppose it's okay. You can stay. We can be together here on the streaming with decoding and all of that. But please, please. Your dad is saying, please do your homework. Okay. It should be above or below your head. I assume that's referring to the microphone. It is below my head right now. My head is cut off. Oh, I have to slouch. I think I need to move the camera back. Hold on, everybody. I don't have a wide enough area. So, let's see here. This is probably going to cause all sorts of problems. Moving the camera back. Oh, boy. Let's see what this does. And there we are. That's a little bit better. All right. So, we ironed out. All right. So, what's happening today on today's live stream? First of all, this is hopefully, I mean, famous last words were ever spoken by me 100,000 times in basically every stream ever. But I hope this will be a little bit shorter than usual. I would like to be done by 5 p.m. Eastern Time, which is an hour and 15 minutes from now. Probably not going to happen, but I do have a limited amount of time. There is some fun family activities that I am planning for this evening. It is getting dark outside. Evening is coming. Winter is coming. And I do need to get to some other stuff. But I would like to do a number of things today. One is thank our new member, Louise. Not sure if Louise is still watching. Welcome, Louise, to the coding train. You have joined just now. You might have joined not even being in the chat. Because I get a message whether or not you're watching in the chat or not and when you join. And for your joining of the coding train, I will show you this train whistle. And I will ring this bell. I will also go and find my book of random numbers. Because you will have for yourself a random number. Oh, dear. Over there? No. Over here. This green screen. What's behind? It's a wall. Well, eh. Let's see. Maybe I will... There's so many different ways I could fix this. But I'm going to do it this way right now. Let's see how that does. Okay. I'm not going to worry about it too much. You can see me. You can hear me. Let's find Louise. And there's a random number. And here it is. Two snaps and a circle. And we are at 47,081. That is from row 6,370 and column 6. So I hope somebody, the coding train secretary who's recording this, in the coding train book of numbers, members and their random numbers, will be saved for all of history and time forevermore. Now that we've gotten that out of the way, let's set the tone for today. And let's read from our book of random numbers. Ah, I need to figure out where I last left off. And the way that I do that is by not showing you my screen for a second and finding my way over to the coding train discord. Do, do. Okay, wait, wait, wait. I just got, I got just swept away in the music for a moment. Looking for coding train. Live links, live links. Command option I. Documented again. I'm going to type in a name. Index zero. Style of visibility was hidden. Option command I. And now we're back. And. The next random number where I last left off. Row 14. Column 2. I'm still on page 1. I mean, it's kind of amazing. Like, I wish I had thought of this 8 years ago or whenever I started, 10 years ago, whenever I started recording videos. When was my first live stream? It's there on YouTube. It's from many years ago. I think that was more like 2015 if I'm correct. Some of the video tutorials were recorded in like 2011, 2012. But I'm on row index 14. Column 012. 87,517. 64,969. 91,826. 8,928. There's an animal in the attic with me. I don't know. It's either a cat or it's a dog. Oh, it's a cat. We'll see if the cat comes over. Kitty. Would you like a random number, kitty? What? There are people watching this. I kind of forgot that for a second. I don't even remember where I am. Does anyone remember the last random number I read? Shoot. Go back! Well, I was starting on row 14, column 2. Oh my god. This is a wash. We're going to go back. We'll do this again. I'm just getting warmed up. Alright. Alright. Alright. Somebody will tell me what random number was the last one I read. I'll find it and then I'll post it. Everything's going to be okay. Alright. What's happening today? I'm going to start doing some projects. And actually, I'm going to do the same thing I did last week because I want to start training a machine learning model. And once I get that model cooking, I'm going to be baking it in my machine learning GPU oven. I'm going to take a break and look at some community contributions. So things that you, the viewers of The Coding Train, have made and submitted on The Coding Train website. Then I will come back and work on making a glitch. Well, it's not a glitch application. It is a web application hosted on Glitch to be able to communicate with that machine learning model when it's fully baked and crispy and delightful and very healthy. We're going to make a nice, healthy, low-fat. That's not a thing anymore. I don't know what the low that you need is. It's going to be a good, a very nice, very nice machine learning model. Okay. So let's go to my friendly, my website from my friends over at runwayml. Ah, there's something new. Oh, I wasn't sure if this would show up. I don't think I have anything special unlocked in my account. I cannot be distracted. Hold on. I'm just opening up my Slack communiques. I just see if I have a Slack telegram. No Slack telegram. I was asking if this is something that is publicly available. It says beta. I'm sure I could show it. It's on there. It's on their social media, but I'm not going to get distracted. We're not doing the green screen right now. I'm going to come back to that. I am going to go to here, train. And I want to do something that I have not done before. Zoom on into it. Is train my own custom audio. Is train my own custom object detection model. Now, you might recall on here to with the Coding Train YouTube channel, Coding Train Object Detection, that there is a video on said YouTube channel called ml5js, object detection with CocoaSD. This is a pre-trained machine learning object detection model with 80 predefined categories. So a very limited amount of objects it's looking for and can detect and give you a bounding box. So you can watch that video, go through the code, shows you the example. What I was not able to demonstrate in that example is how to train your own object detection model. And basically, you know, for example, I think what I'll do, I mean, I could do, oh, let's do the Rubik's Cube. I was going to do the train whistle, but I sort of feel like the Rubik's Cube might be, by the way, I was having trouble, remember I was having trouble solving it? Okay, here it is. The Rubik's Cube might be a kind of nicer, interesting thing to detect, especially because I can, it's got so many different colors on different sides. I wonder if I shuffled it. This is an interesting test case of object detection. So let's use the Rubik's Cube. Although really, I do love this mug. So, and I kind of want to make an object detection model that detects my mug. I mean, there's nothing special. If only this mug were made in rainbow colors, it would be everything I'd ever hoped for and wished for in my entire life. I am a simple but a simple man who lives, I don't live in the attic, but I spend a lot of time in this attic talking to a camera. That's what I do. What's happened to me? But I do love this mug. It brings me great joy and happiness. You should find something in your life that you can love, and that loves you back like this mug loves me. I understand why those like, you know, late night talk showy like things, they use a studio audience, because it's very weird to just be on my own. I should make my children sit over there and just watch me the entire time. That would basically torture them. What was I doing? Right. So we're going to train the object detection model. We're going to have it find the Rubik's Cube. Okay. So the sort of key differences here, you know, I should say, so ml5.js, to be clear, is a JavaScript library from machine learning built on top of TensorFlow.js. And Runway is a web application, a company that provides a service here, essentially, to operate different machine learning models in the cloud. It does cost money. You can sign up for it. This is not a sponsored ad for Runway. I am the founders of Runway, are former students of mine at NYU, and I'm an advisor to the company. So in that sense, it kind of is an ad. But I'm really just showing it to you out of my own enthusiasm and excitement to try using it. So I'm going to go here to object detection. And actually, so before I can train the model, I need to collect my data set. So this is the way that I'm going to do it. This is the way. I'm going to go to new movie recording. And so there are a lot of different ways you can collect an image data set. You can see, by the way, a little behind the scenes here. Oh, I did get some. Here's the other upgrade I'm going to make. I have these, like, LED lights. Let me turn them on. So I'm going to – by the way, but, you know, this is why I make edited videos now, people do enjoy the fact that I just get distracted and, like, can never get anywhere. That's what the live stream is. But plenty of edited videos where I'm focused or at least I'm not focused. That part got edited out. Are coming soon. So let me go here and turn on these lights. So I just turned on those lights. Those will blink, by the way, if anybody signs up for a membership. But the other upgrade I'll be making hopefully by next week is – and I don't know what that did to my key here. The idea I had, I thought this would help, like, make the key better. But I think it might actually be causing me some issues. I bought white gaffer's tape so I can gaff tape the various cables and things for these LEDs with white gaffer's tape so it doesn't look as ugly as that black gaffer's tape. So I am now going to hit record. And I'm going to just record a video of me with this Rubik's Cube. Kind of showing it and using it. And I really don't want this to be more than, like, actually 20. I guess I can sample the frame rate however I want. Let's try to get some different sizes. Okay. Let's just go for 30 seconds. Okay. Beautiful! I'm going to hit stop. Let us save this to the desktop. By the way, I was doing this already with some other tests. And I'm going to just make – I might as well use this directory structure. I'm going to call this Rubik's. Let's save this as Rubik's. Rubik's. That's all well and good. I actually – I don't know what I think I want to do just to have these be less – I don't know if it really matters. But I think that I want – let's just at least export it as 720. Because I don't need super high resolution images for this. I'm sort of afraid to go down to 480, although it would make total sense to do that. I have a feeling runway, once I upload my data set, is going to be resizing all these images to much lower resolution anyway. So that's fine. What I'm attempting to do again is collect a data set that I am going to have to hand label. So this is going to be one of the most exciting and riveting things I have ever done on the coding train. You're going to actually sit and watch me hand label a data set for machine learning. It's really exciting. But – and I could have certainly used – sort of scraped the internet. Maybe looked – did a Google image search for Rubik's Cube and gathered a data set of images that way. I could have taken a lot of photos with my old-timey telephone camera and uploaded those. But I actually find quite a useful way to collect a data set is to record a video and then extract all the frames of that video. So the way I will do that is with FFmpeg. And so I'm in my console here on my computer. I type in FFmpeg and I see all these possible commands. So this won't happen automatically on your computer, whether you're on Windows or Linux or Mac. You will need to make sure you go and find – I guess go to FFmpeg.org. It's a complete cross-platform solution to record, convert, and stream audio and video. It is a really excellently, incredibly useful tool. I use it frequently. And basically you can see here the kind of foundational example of what you do with it. You call the command via your console, FFmpeg –i, I believe, stands for the input video, input.mp4. And then the file name of what you want to convert it to. So this would be how to convert very quickly this MP4 video to an AVI file. But there is so much more you can do with FFmpeg in terms of extracting audio and automating so many kinds of video processes. So the one that I want to do is – and if I can – well, I need to go to the desktop. Under images maybe. I think this is where that directory was. FFmpeg. What was it called again? Rubix. Here we go. And I'm going to say FFmpeg –i rubix720. Does anybody happen to know? And I really wish I could pin Marcos' message to the screen right now. But does anybody happen to know the command from FFmpeg to extract it to frames? I want to say it's –vf. I don't know if that's really true. I know that I need to say fps equals – let's try just for a second one frame per second. So I just want to get one image every second from the video. And then I think I can just say like frames – what do you do to like number them? Like if there's – this would be now the file name would be – I'm going to call it like rubix… ….png if I wanted them to be pngs. Do I want them to be pngs or jpegs? I have no idea. Let's try this. Okay. So ah, that one seemed right, but I got could not open file – oh, because. I feel like FFmpeg should make that directory for me, but I don't think it will. So I made the frames directory. Let's try this again. That was super fast. Did it actually work? If I look in frames – there we go. So now I have frames of the video. And this is probably not enough. This is like how many total? 35. I think I should do – let's delete all these. And let's say – hmm. I mean how many of my – I think I could do – I think I could annotate 150 images right now. I think that's reasonable. I've got – I don't have my watch on. I've got like another hour here at least. So I think I could annotate 150 images. We'll play some music, some royalty free music. By the way, I'm in the market for commissioned musical themes for the coding train. I'm already in touch with some people. I have some ideas. It's a very slow process because I started thinking about this probably over a year ago. But if you are a composer and a musician, join the Discord. Please reach out. You know, you want to compose and record some music. I'm looking for contributions in that area. Okay. By the way, if there could ever be the coding train musical, I will just – What's the expression? I suppose die and go to heaven. That's not really how I think it works, scientifically speaking. But boy, that would make me very happy. Okay. Let's do five frames per second. That was 178 frames. I'm going to go back to runway here. And I'm going to click object detection. Let's do Rubik's Cube. And by the way, I probably – I should have done both of these. Because I can train an object detection model with more than one object in particular – in my dataset. So I'm doing this in the simplest way possible. I'm going to create this now. I'm going to upload – oh, which – oh, I'm logged in. It's fine. I meant to be logged into my other runway account. It's all so confusing. But this is fine. I will do that later. I'm going to go to desktop, images, FFmpeg, Rubik's frames, hit upload. And we'll wait for these to upload. Can we do that thing in the edited videos where the time speeds up? That would be nice, right? I guess I could log out – well, no, I'm already uploading it. I keep just messing this up. You can see, by the way, oh, how difference – how – what a difference a year makes. This was a dataset that I uploaded a year ago in an attempt to work with Thanksgiving turkeys. Okay, frames. Here we go. Click next. Now, what is the next step? I need to create an annotation group. So I can't say that I entirely understand what an annotation group is in terms of the runway interface. But I'm assuming it means a collection of labels. So if I were doing Rubik's cubes and train whistles, my annotation group would contain both of those labels. But I just have one. And I don't have one that I've done before, so I'll make a new one. We'll call this annotation for coding train live stream Rubik's. Give it a very long name. And then I want to – oh, and then I want to put in the label will be Rubik's. That's the one label I have. I'm going to click start annotating. And hopefully this will load. I had a problem with this the other day. Somebody can report this as a bug to runway where when I first load this page, nothing comes up. And I think that – let's see if I just click on image two. If I recall correctly, what I did last time to fix this was – oh, no, it worked. So I don't know why that first one didn't show up, but there it is. So this is what I'm doing. I'm looking at these images, and I'm going to annotate where the Rubik's cube is. But there's no Rubik's cube, so I can click skip. There's a skip button all the way down here that I realize you can't see. Skip, but I can also just hit the space bar, which will be much more efficient. So I'm going through the images. Now here is the Rubik's cube. So now I'm going to annotate it. I'm going to draw a little square over it. And that is the Rubik's cube, and I'm going to click next. So I believe there are other tools like this, but I really appreciate how kind of quiet and meditative and relaxing this is and how easy it is to do. I can move this around and resize it. I could be really – I'm not going to be very particular about it. This definitely appeals to my obsessive nature to try to like very precisely annotate it, but I want to move quickly, and I think that I want to see if we can just have some nice, relaxing music like – To annotate by. How many do I got to do? I'm going to try to do it. Talk amongst yourselves, everybody. For those of you wondering, why didn't he just do this before he started live streaming? And then he could show us, and guess what? Look, I actually already did this. Here's the finished version. I'm just going to show you the beginning of the process. Nope! That's not how this works, people. The whole project, all the pieces, I will demonstrate to you. Oh, I'm really doing a terrible job. By the way, what would be really cool is to build a system by which we could crowdsource this. So what if I could give – you know, Runway could think about this. What if I could give this URL out? And all of you who are watching this right now could participate in the annotation process. What? The song's over already? What number am I on? 40. Hey, I'm not – I'm like pretty far along here. I don't know what – no, these are all the Halloween things I had. I forgot I had all that Halloween music. No, this always gets me like a copyright violation, the Goldberg variations. Let's try this. Oh yeah, this is good. Oh my god, why did I – All right, everybody, montage, annotation montage. Hey! Welcome, Henry Whittaker, by joining the coding train right now. You have interrupted me from my special hand-labeling process of machine learning imagery, but I thank you. Actually, you've saved everybody because we were just stuck. There was nothing else we could possibly do, but now, having joined the coding train, Henry, I will now find for you your very own personal random number. Oh, I got the timing of that way wrong. It is. On row 8,915, column 01234567. 6,469. Thank you, Henry, for your support. It means a lot. It helps me upgrade my studio and keeps me going. It motivates me. It fills me. All of that stuff. Wrong one. Okay. Back to annotating. I think this is not annotating. Do you know what this is? It's dance notating. Kind of makes it go a little bit slower, but it's much more fun. I really need a standing desk here in the attic. That's the other upgrade I'm going to make. This sitting while live streaming does not work for me. All right. Let's move faster, people. All right. Oh, that was a terrible one. I really had to go back and do this again with much greater precision. Where are we now? Halfway there, people. Halfway there. Dance notation. What's happening in the chat? Anything? Okay. What's happening in the chat? Anything? Yeah. So in the chat, there's a little bit of a discussion going on that here's a bias of how... Here's a human bias. Here's an example of human bias. See, I really need to bring these messages up on the screen so I don't have to read them. But I'm going to read this. Dan's fingers are present in each annotation of the cube. Then the resulting model might not be able to identify a cube lying on a table because it wouldn't be surrounded by fingers. Exactly. So if I wanted to have a very sort of broadly functional annotation of a cube, I would have to have a cube that was a little bit more than a cube. So if I wanted to have a very sort of broadly functional model that could recognize and find a Rubik's Cube in any image, this would be a pretty terrible data set because the Rubik's Cube is only ever present in one environment, the environment with me in it, with this green screen background, with my hand holding the Rubik's Cube. So I would want to collect a much more elaborate and varied data set. But I would say that one of the things about what I'm doing here which isn't necessarily a problem is my use case might be I want to build something for myself that can find the Rubik's Cube in my hand when I'm holding it. And also I don't have a single example of it without the same color on one side, so that's certainly a problem. But I could imagine in an interactive exhibit, for example, or some type of interactive context where you can really have control over the environment that having that fixed environment in your data set actually has a lot of advantages. This is just not good. I just got to get slightly more, I probably also don't need 150, so this is kind of maybe a little bit ridiculous what I'm doing, but I can't stop now. Can't stop, won't stop. Oh, what is this weird? I don't know if this is going to be a problem, but I'm just going to... Also all the blurriness, I didn't really think of that because I was moving it around a lot. And, I mean, should I mark it here? Like, should it learn to be able to see it with my hand completely covering it? I'm going to annotate it that way. This is going to be an interesting experiment. And my goal here in many ways is not to do this so that I have a model that's working incredibly well. I mostly want to demonstrate this process so that if any of you want to embark on it, you might have more time or more clever ways of collecting your data and being more precise about annotating it. Where are we? How are we doing? 122. Boy, I feel like I've slowed down. By the way, having an actual... I'm using a trackpad for this, which is kind of sad. Oh, did I finish? Wait, what's going on? No, I don't see the images anymore. Weird. Hold on. Rename, export. What do I do here? Edit annotation group. Okay. Weird. Hold on. Let me click here. Uh-oh. Rename, export. What do I do here? Edit annotation group. Okay. This will be done soon. Don't worry, it only takes about four hours to train the model. I'm just kidding. I'm going to let it train for as long as I can manage to wait. What's it like to be a machine learning researcher, you may ask? Let me tell you something. Boy, is it exciting. I'm going to move this rectangle here and slide it a little bit over, and a little bit over here, and all the way up to 3, 4. Yeah! Dance notation. Is there one way of doing it? No. I know I'm getting to the end now. I love you, Rubik's Cube. You are my baby. Yeah! I'm going to make a little bit of a mess here. I love you, Rubik's Cube. You are my baby. Yeah! Oh, there's more? It's got to be the end now, right? What is going on? What was I doing? Okay, come on. Almost there. Almost there. Almost there, people. All right. This is probably a bad idea. Let's give it that as some training. No Rubik's Cube. No Rubik's Cube. No Rubik's Cube. No Rubik's Cube. We are done, people. Close. Next, I am going to select a pre-trained model as the base model for this training. Right here, we can see I can choose from other models. I'm pretty sure the last time I checked this, that actually... Oh, no. There's also YOLO version 3 Tiny. Interesting. I wonder... Optimized for real time. Oh, interesting. I'm imagining using this in real time. Let's train it with both. I'm going to just run this twice. I'm going to have this run twice. I'm going to let it go 5,000 training steps. I might stop it early. I'm going to click Start Training. Then I think if I go back to... No. Train. I do object detection again. Let's do Rubik's Cube Tiny real time? It's going to let me use a question mark in the name of my experiment. Take this. I already have these annotations. Next, let's choose from YOLO version 3 Tiny. Now I have both of these going. We can see them here as my two training experiments that are going. Let's open this one in one window. It didn't open in a new window. What did I... Click the wrong thing? Rubik's Cube. I want you to open in a new... Oh, weird. It's like... That's fine. Then let's go to Train, Rubik's Cube, Tiny. We've got them both going. Now, I'm at the point... Let me just click something here. This is really bothering me. There we go. Oh, wow. Louise, it looks like you joined and you made it into the Discord. Welcome. That's so exciting. I wish I could click your messages to bring them up on the screen. Look at this glow that's going on here. I think it's the LEDs there. What's going to happen now? I now am letting this run. We can see both of these are running. Just to be clear, let me clarify a little bit about what's happening with Runway. Nothing besides my browser is actually running on this computer right here, the one that I am operating here. What I am looking at is a web interface to a set of servers that are presumably Runway's web servers. Runway's web servers are what are hosting up and showing me the interface and all the status updates. Runway additionally has access to what I'm assuming is a large number of GPU optimized for machine learning cloud servers. What you're paying for when you sign up for Runway and use Runway is ease and efficiency really in many ways. In theory, I have a Windows PC over here with a pretty good graphics card. Maybe I could figure out how to set it up with a training system and CUDA and tiny YOLO version 4 and all the stuff that I need to just train my model right over here on my own computer. But by having Runway have access to a pre-configured and ready-to-go cloud server with all of the dependencies and configuration settings it needs, I can just upload my files, annotate them, press a button for training and it's going to run it and then make the finished model available to me. You could certainly do the same kind of thing also with a Google Colab notebook, an AWS instance, Spell, PaperSpace. These are other kinds of cloud-based services that have GPU-enabled machines that you can do machine learning and other things on. Runway is kind of my favorite tool du jour to use. And one of the things that is the most exciting about it for me is just this huge library of models that I have access to. And these are new actually. There's a YouTube channel called Artificial Images. I don't know who runs this channel, but I've been recently quite tuned into it and it's been using Runway for a lot of things, making a data set, a walkthrough tutorial. So this is all great. I really got to check some of this stuff out. And I'm kind of trying to do some of this kinds of stuff on my channel as well. All right. So what I think I would like... I'm going to do a couple of things here. I really messed up. So I apologize for this because I'm totally going to ruin everything right now. I'm going to check back on these models in a little while. I have two Runway accounts because I want to be able to have an account with Runway where I can upload data and do things in Runway with my own private data, so to speak. I don't really have an example of data that I want to use with Runway that's private right now, but I often do this with lots of things. I have a separate account, which is the one I stray logged into on streaming, so I don't by accident open my email and that sort of thing. But I messed up and this Shiffman Runway account is the one that I intended to be my private account. But I'm already training these models. I'm not going to, but I'm going to log out and I'll come back to check on them in a little bit. I'm going to go to my CodingTrain one. Ah! Ah! I can't get this right. I've done this so many times. Oh, I know what's going on. I also have different logins to this browser and it's fine. It's fine. Everything's going to be fine. Talk amongst yourselves. OK. So now I'm in my ChooChoo account. And we can see here that I've actually been working with this already this past week. I have some really weird models that I was training. Let's take a look at this one. This is not what I meant to show you. Add to workspace. What is going on here? Oh, wait. Why do I have workspace? Model workspaces. What is going on? I think Runway changed its interface. My model's train hosted. This looks different. I got to create a workspace. Add to workspace. OK, fine. New workspace. CodingTrainDemos. And let's just run this model for a second. So this model is a StyleGAN model that I just trained off of images of my face looking at different directions, wearing different glasses and things like that. So I wanted to start with a StyleGAN model. I probably should just go to the SkyGAN one, which is what I was actually using, just to demonstrate the next phase of what I'm going to do, which is demonstrate how to use Runway beyond just the interface itself and essentially treat it as an API with your own code. And any moment now, it looks like it's about to spin up. It's got this model running in the cloud, my Dan faces StyleGAN model. So just to be clear, this is not an actual photo of me. This is a StyleGAN generated version. You can see it's got some kind of weird aspects to it. I mean, I do look kind of like that. I was wearing this shirt. I was standing in front of a green screen when I collected this data set. And we can actually sort of start to move around in the latent space of me. Oh, my God. So weird. What have I done? What monster have I created? So creating an image synthesis model is one that you can do. And I need to – I really need to get my act together and do a whole bunch of sequenced video tutorials about this process. Right now, I'm just kind of playing with it. But let's move on over to Glitch. I'm going to hit Stop. So I believe the current pricing on Runway is about like $0.05 per minute when you're running the model in the cloud. So I'm going to hit Stop so that I don't use up too many of my credits. And I am going to go over to this here called Runway ML Template. And I'm going to hit Edit Project. I wonder if this one is actually running. I think I disabled the model. Let's see. It actually doesn't look like I disabled it because I think if I disabled the model, it would have already – it would have already given me an error message. So one of the things you can do with Runway is once you have a model like this Coding Train Dan Faces one, I can go click over here onto Network and I can host this model. So I've done this kind of stuff previously probably about a year ago and I used the Runway desktop software. That is still something you can use. I really prefer – the mic is off. I don't think the mic is off. I am seeing everything working just fine. So hopefully somebody else will tell me and confirm. I think if the mic was off, I'd be getting a lot more messages. I'm going to click Host this model. And I'm going to host this model. And now I have a list of all of my hosted models. Aha! This is the one that I am actually using with this code, SkyGAN – a SkyGAN model. And this model will, you will see in a moment – where am I going here? Generate images of the sky. So this is a SkyGAN model that's been trained on many, many, many images of the sky. And one of the things you'll notice – ah, there we go. Look at this. Daily limit reached. So you can all go to this URL, runway-ml-template.glitch.me. And you will not be able to generate your own sky. Because when you do generate a sky, it costs me – well, I actually have some free credit. So I'm not paying for any of this right now. But the actual cost, the runway cost, is one cent per request. So I, in this template that I've built, I have built into it this JSON file, which always saves the current number of requests. And I have also placed into this.env file, which I don't want to show you right now. Just hold on a second. I'm going to zoom in on it like this for a second. Where one of the properties of the.env file, in addition to the tokens, which I will show you in a moment so I can regenerate them, is the daily limit. So I'm going to change this daily limit to 100 right now. That should restart the Glitch web application. I realize I'm jumping right into the middle of a project with lots of pieces and things leading up to it that you might not be familiar with. That's okay. Bear with me. Ask your questions. Join the Discord to get help. And I can see that Peter is here in the chat. Hi, Peter. Nice to see you. And let me come back to here. And now I should be able to go back to my web application. And we can already see the count is at 18. Let's see if I generate one. It's going to run out of its daily limit. We've just collectively spent a dollar on generating sky images together. So the reason why I've built this in is for a number of different reasons. But one is just to have a protection layer, a sort of rate limiting. It's not something that the runway interface currently has as a feature, but I've built it into this template. So what I would like to show you how to do is how to create your own web application where your P5.js or any other JavaScript, HTML, CSS code communicates and works with runway. And ultimately, I'm going to do that with the object detection model that I'm currently cooking here in my machine learning oven. And my machine learning oven is somewhere in the cloud. I mean, it's an underground bunker, if we're being honest here. The server is likely not actually floating in the sky with rainbows and birds tweeting about. That would be nice, though. So what's next? So let's look at this code for a second. And by look at this code, let me go back to here. So in the runway interface, I could also, by the way, just turn off the model. That's another way for me to make sure. You can see I've had 1,399 requests on this model to date having used it. So I could click this code snippet here. And what you would see is that there is a JavaScript library, a runway hosted models library, that allows me. Oh, there's my token. I sort of forgot. I was thinking I'm not showing you the token. Why is my key so off? Is it really these LEDs? Hold on. I don't know why my key has been actually really good recently. Maybe because my lights are so much brighter. I guess that made it a little bit better. I turned those LEDs off. Max. Is that the Max that I know who's in the chat? I think it might be. Hi, Max. I'm all nervous. Max is watching. Anyway, back to what I was looking at here. So now you have my token. Oh, boy. Let's quickly disable that model. The request didn't go up. So you could have written your own code very quickly with that token if you could have copied it down and put it into your code. But looking at that code snippet again, then the idea is I can create a runway hosted model object with a URL to the model. Token is the cat. It's the cat. I really wish the cat would come and say hello. I forget what truncation is. We can look it up in the runway interface. I can query the model. I can get an image back. This is what I'm actually doing in my code. However, it's actually going to look a little bit different. Because if ‑‑ and I could just paste this right ‑‑ I've done this. I could paste this right into the P5 Web Editor. Copy, paste that, put it in the P5 Web Editor, run it, have my StyleGAN example working up and running immediately. Woohoo! It's awesome! But what would be the problem is my model URL and my model token would be there right in the code. And anyone on that web page could grab those. And I want to keep those secure. So what I have done here with this runway ML template. And in theory, you can use it by only ever using this server.js file. I'm not ‑‑ no, sorry. You have to use the other stuff, too. But you could work with this without having to write your own server. But I have a server, a Node server that's actually doing the runway communication. And you'll notice in the code when I create the runway model. By the way, does anybody know ‑‑ I don't know what the equivalent family friendly ‑‑ I don't know what the equivalent family friendly thing of a drinking game is. But, yes, put a quarter in the jar every time I show my API tokens on a stream. But you can see here I'm calling on process.env runway URL, runway token. Which means the code itself does not actually have the token in it. Instead, I'm having like a crazy deja vu because I was literally recording a video tutorial on this yesterday that will go with my Discord bot series. But instead, the keys are stored in that.env file. You can see that little heart key thing. This is something that only I or other, you know, approved editors to this project can see. So if you were to go remix this project, like this code is open source. You can go to the URL to it. I'll paste it in the Discord. I believe if I go ‑‑ you know, you guys can all confirm this to me. I'm going to go back to our Discord. Where did Discord go? In the live channel, links channel and just paste it here. So you can grab that URL, go there, you'll see all the code. But when you go to the.env file, it will be empty. Because I'm not packaging that up with the example. So that's a really convenient ‑‑ and this is not unique to Glitch. This is a common sort of standard for how to save, you know, secret important information in environment variables across different web applications. Okay. So what I want to show you here is let's look at the actual P5 code. Does anybody know, by the way, how to increase the font size in the P5 in the Glitch web editor? I have not been able to figure out how to do this. I know I could zoom the web page, but it grows everything, which kind of makes me a little bit crazy. But I'll just do that for right now. Look at all you nice people popping up. Anonymous, anonymous. Who are you? Who are you watching? Shrey and Sian and Shrey? Shrey is watching it twice. Are you two people? But all the rest of you are just these anonymous little smiley faces. Hi, anonymous little smiley faces. I love you all. What time? I said it was going to be.5. We'll see. So here's what I'm showing you. The code is quite simple on the client side. Rather than programming this whole thing, I'm just going to talk you through it. And then I'm going to make some new versions. I'm going to remix it and make some new versions of it to do other things. So one is I'm creating a canvas. It's 640 by 480. I'm creating a button, that button called Generate. We can see all of this here. Canvas, the Generate button. This is all P5 code for manipulating a canvas and DOM elements. It's not your sort of traditional JavaScript, but it's the way I like to work with the P5 creative coding environment. I'm making this sort of span DOM element because I want to show the count. That's rather unnecessary. But we've got to tally all the votes. I mean, count all of our requests to the runway server. And then when I press the mouse, this function send vector is called. It's the callback to the mouse-pressed event on the Generate button. So what's going on in that function? Well, every model in runway, and if I go back to browse models, and I search for SkyGAN, and I come up to it, and let's just add it to create it. Why do I need to create a new workspace? Isn't there, shouldn't it like add to my existing workspace? Here's my model workspace. I'm so confused. I'm just not going to worry about this. Something is going on. Somebody will teach me how to use runway. By the way, there's a slack for runway. I'm almost taking notes so I can give all this feedback to them. So I don't know, coding train 2, I don't know why I have more than one workspace. Was I in my other account? I don't think so. Where's the other workspace? So strange. But with every single model, where does inference know, what am I looking at? I think I want to look at here. I want to look at where it shows me the sort of specs, the model, the inputs and the outputs. And you're probably all saying this, and this always happens to me, where you're all saying how to do this in the chat, and I'm just completely incapable of seeing it. My models, no. Model workspace, yes. All right, well, I know what it is, and it's telling me right here, vector. So the input to this particular model, our vector, oh, I'm going to have to make a whole video about this. I've talked about this before. I don't want to get into the weeds of this right now. But in an image classification context, the inputs to the machine learning model would be the image. The outputs would be the labels. Here, this is a generative model, so the inputs is actually really just like a bucket of numbers, like a noise. It's like a list of noise, and that list of noise is the signature, that signature input which will generate a particular image. So that's what I'm doing in my code, wherever that was, where I am, I know the expectation for StyleGAN is to receive 512 input values, a vector of 512 numbers. I think an appropriate range is between negative one and one, but I'm not entirely sure. And so I make the inputs with the Z, it's often referred to as the Z vector or the latent vector is another term for this. And then I don't see the runway code anymore. The reason is I'm actually going to send the vector to my own server. The server is essentially middleware, is that the right term? It is really just, its job is just to like pass the football, pass the baton. That's a better metaphor, I think. It's a relay race. The runner is running up with its vector. It's passing the baton to the server, who's going to run it all the way to runway. The server is really secure. I mean, it's not that secure to be honest, but it's much more secure. I mean, I'm sure there's security flaws in what I'm doing, but it is secure in the sense that it's got the sort of secret keys to talk to runway. So you can see I'm using the JavaScript fetch function, my endpoint on my own API that I've basically written to that node server is called runway. So and then the server is keeping track of the count. And if it's reached its limit, it'll just log the daily limit was reached. Otherwise it returns the outputs from the model. And that's an image which I can generate and draw. So this is looks this is identical. The way I've set this template up is if you send the inputs to the node server's runway ML endpoint, that node server, if I look all the way down here, will take the body of that request as inputs and then call await model dot query. So this is the actual runway call. And if it comes back and works, it sets a status to success and returns the outputs. Otherwise, I'm just keeping track of this count, right? This is my highly advanced rate limiting methodology. I have a variable, which is literally a count. And as it goes up, if it goes above some threshold, which is defined here in the environment variables, you can see, by the way, here's the URL and the token in the environment variables. If it reaches that count, it is trying to say that it just sends back doesn't actually query the model. And I also made an endpoint to just like check the count. So, for example, I think that if I do slash count here, you can see that it's at 100. And if I went back to here and I went, the count is also being stored in this JSON file. I don't know why it says five there. Something funny happens with me with Glitch. I don't really get it. When you're writing to text files or JSON files, the browser doesn't always like refresh the latest contents. But if I set that to zero and it'll like save it and then go back to here. Oh, and my app went to sleep. I thought I had, by the way, I have a Glitch Pro account. I thought I boosted this. But you can see now the count is zero. And then this won't actually work right now because I think I disabled the model. But you get that's the entire story. So, let's see. And right, so protecting it by an IP address, there's a variety of other ways you could protect it also. Let's see here. What questions do you have about this? Let's check our models that are cooking. I'm going to go. This is so ridiculous what I've done here by using two runway accounts. Let's log out. And let's log into my other runway account. This is not a necessary thing for you to do. Go under train. And let's check these models. Let's see. This one is 46% done and this one is 28% done. Let's take a look at the one that's 46% done. So, you can see here what I love about the runway interface is it's actually showing me its progress while it's training. So, it's running a bunch of training images through the model. This is not showing me my annotations, right? This is showing me its guess based on the current state of the model, based on the current step. And if I go back, like I look at step 1200, 600, all the way back to one foot. Right. This was early in the training process. It was finding the Rubik's Cube everywhere. And around step 750, it sort of found it in two places. It's getting more and more accurate. And, you know, I might venture to say that I can stop this from training because it's done. But this is the sort of like metric, this map metric, which is mean average precision, a measure of a performance of an object detection model. It summarizes both the position, how many of the predicted bounding boxes correspond to the true bounding boxes, as well as its recall, which measures how many of the true bounding boxes have been correctly predicted by the model. So, I would like to see this at 100%. We can look through all the different example images. This is probably good enough for me to try running it in my own application right now. But let's let it train a little bit more. And I'm pretty happy with how Tiny YOLO is working. So, since that is a faster, smaller model, it's probably the one I'll want to use. I wonder if this is something, I believe Tiny YOLO is compatible with JavaScript. And I wonder if this is something that Runway, I mean, I realize the business model here is to use their cloud servers. But I wonder if there is a possibility of doing like an export to JavaScript so I could download a sort of like local. I think you can download any, it does let you download any model that you've trained. So, you can work with it locally. But what I would like to download is a JavaScript compatible one. Okay. That was confusing as hell, writes Nitrous Oxide. Apologies. I don't know which part was confusing. But I'm kind of just bouncing around between a lot of different things. So, I recognize that this could be confusing. All right. So, we've got some non-anonymous people. Welcome. Welcome to this Glitch application. So, what do I, one of the things that I've been wanting to make as an example for my course. And I'm going to go back. This is very ridiculous what I'm doing here. I'm going to, I can't believe this is what I'm doing. But it's too late for me. I'm going to log into this one. And I'm going to look for models. I want to look for a particular model called spade landscapes. So, this is an image segmentation model. Which will allow me to, like it says, generate realistic images of landscapes from sketches and doodles. Let's take a look at this one. See, it's asking me to make a new workspace again. I don't get it. I don't get it. Coding train 3. Electric boogaloo. Okay. Now we're in this model. I'm going to choose an input source, which will be a segmentation. And I'm going to run this model. So, runway, again, one of the reasons why I love using runway is I can just immediately play around and see how the model works. Before trying to build it into my own application. So, let's look at how this model works while it's booting up. This is an image segmentation model. What does that mean? Usually an image segmentation model is for doing the inverse of what I'm about to do. We can see this in, let's see, if I go to ml5 and look at body pics, for example. This is an image segmentation model. Actually, let's look at unet. I'm just curious about this one. Let's go here really quickly and see if I can grab one of the examples. I'm just curious to see if this works. I haven't run this one in a while. Ah, open broadcast studio virtual camera. So frustrating here. Let me just search body pics. So, this is what image segmentation typically does. It takes as the input the image and labels different pixels of the image as part of a given segment. So, in the body pics model, it's able to recognize the human form and label different parts as torso, green, maybe thigh, as purple, right thigh, left thigh, head, and sort of segment the image that way. And you could use that for a variety of different creative applications that I'm sure are swimming around in your head right now. What I love about the inverse of that, for example, if I come back to this particular image segmentation model, is that it's doing the reverse. This is a generative model. It's generating an image. And I am providing the segments via a color map. So, I'm going to create a scene. Oh, this is like perfect for doing like a Bob Ross, like pseudo fake. I should really set that up and just have like a little wig and a little like thing that I could paint colors on and have it generate the landscape for me. This is great. That'll be next Halloween or April Fool's Day. But I can sort of paint over here because this is where the grass should be. And you can see it's starting to generate this image below. Then I'm going to add a river that's going to flow like through here. I don't know if this makes sense. Let's add a river. I don't know. That's very weird what I'm doing. Let's draw some trees. Some trees here and some clouds in the sky. And there we go. Oh, look at my beautiful landscape. I am such an artist. So, what I have done with this model is I have generated this image from this segment map. So, this is fun to play around with Runway. And if this is all I want to do, then great. But what if I wanted to create my own P5.js sketch or processing sketch or other type of software application where the segment map is the segmentation map is generated in a different way? What I want to do right now is just recreate exactly this. So, I want to go look at that glitch template and recreate exactly this interaction, but with my own code. So, first I'm going to hit stop. Then I'm going to go to one thing I really want to do is click this export colors because I really need to get the colors right. So, let's click export colors. And it came in as a CSV. So, I'll take a look at that in a moment. Let's just put that over there. Whoops. How come you didn't show up over here? Where are you, colors? And I'll find that later. Let's go to ‑‑ whoops. Let's host this model and host the model. I'm going to have to not show you my API keys. Let's turn this one off. I don't need that one on. I'm going to go here. So, now I want ‑‑ how do you do this in Runway if this is my project? I think I can still do remix. So, I'm going to show you the process of starting with my template and remixing it. So, I'm going to hit remix. And then this will be ‑‑ and ideally my goal here is to create like many, many, many examples in Glitch of working with different models in Runway. So, I'm going to call this a spade co‑coding train. Oh, that's a co‑coding train. Choo, choo. Yeah, it's got to have the choo, choo on there. This is everything. Here we go, right? No, put a little dash there. There we go. This is like the best name of any Glitch project ever. Spade co‑coding train. Now, I'm going to hit ‑‑ and look at this. So, I should be going to the.env files and nothing is there. So, just to be safe and secure, I'm going to make my daily limit five. So, make sure that as I start putting this in there, if my token goes out into the wild of the URL, if this project goes out into the wild, I'll have some protections. It's fine. Let's just make it 100. And then the server I'm suggesting doesn't need to change. The server is totally generic. As long as I send my request to the runway ML endpoint on the server, the inputs come in, go to the model, the outputs go out. So, I just want to work on my P5 code. So, here I am in Sketch.js. This is ‑‑ and I need to do this differently. So, very quickly, let's not worry about runway for a second. This image should be send ‑‑ it should be called send image because I am not sending a vector. The input to spade cocoa is an image. Oh, yeah. Okay. So, I'm going to take ‑‑ I'm not going to worry about this just yet. So, let's actually comment all this out just for the time being. And let's look at this in a new window. Failed to start. There's an error in my project. Right. The error in the project, which I can see here by going probably under tools, under logs, is that there is no valid token. So, hold off on that. I'll put the token in in a little bit. And what I want to do here is instead, let's say background 255, function draw. I'm going to say ellipse. I'm going to make this in the simplest way. If mouse is pressed ellipse, mouse X, mouse Y, 32. So, obviously, I would probably in a sort of fantasy way of doing this, I would want to create a whole drawing interface where I can select colors and change the size. I'm not going to do any of that right now. I just want to see it draw. And let me get one of the colors. So, if I go to the desktop, and I think this is the colors, can I open this with, I don't know what, Visual Studio Code. Can I actually just bring this into like assets? Whoa, no, I don't want to open numbers. Are you insane? Great. So, here we go. So, let's start with sky, which is this color. And I could load, I would want to load from this file and make this much fancier, but I'm doing the quickest Hello World version of this, I can think. No stroke, fill, and just use that hex color. And by the way, I think there's a way to disable these, but because of the weirdness of P5 and how it uses the global namespace for its functions, Glitch always thinks these are errors. Who knows how to just like tell Glitch to stop. That would be good. I copied the HTML code into the style.css file. I certainly did. When did I do that? It's so weird. Is that like in all of the, in my template I did that? Let's just take that out. I don't know why, what happened there? That was very weird. So, the Glitch app is attempting to wake up, but I'm going to need those API keys. So, let's go. So, what I'm, actually I think I'm going to go back to hosted models runway, and I'm going to grab, if I click on this, it's going to copy the API key to the clipboard. Oops, sorry, I'm missing. I'm going to go back to this view, and I'm going to, right now I'm going to attempt to put the API key into the runway, into the.env file without you seeing it. Let's get the model URL. Just so I stop getting those errors. So, I've got the model URL and the token, and I'm going back to my code, and that is now done, and I can show it to you again. All right, so I have put the API keys into the.env file. And now I should see this. Send vector is not defined. Where did I put send vector in? Send image, send, oh, whoops, right. So, let's also comment this out. Great. So, now I can draw just by, I can only draw one color, and I can only, I can only draw one color, and I can only draw one color, and one thickness. Sorry, what was the other part? I'm getting tired. It's 5 o'clock. We're going to do this, then the object detection model. Oh, I was going to do, I've got to do some community contributions. Yeah. So, okay. Next. Let me rethink this a little bit. I'm going to make the background that color. So, the background will already be sky. And then I think I'll just try to draw clouds. So, if I go look at the assets, where did I upload that? Oh, it's here. Clouds, oh, clouds is just this. So, let's just try it with sky, and I'm drawing, although let's try sea. I'm just curious here. Let's try sea. So, if I say fill here, and now it's going to default with, and I can draw, excuse me, the sea down here. Coming back. Let's make this a little bit bigger, just so I can do it more quickly. Great. Now, what do I need to do? I need to send the, and what I want to show you is going to leak my keys again, but that's fine. I'll regenerate them. I need to adjust this code. So, the first thing that I need to do is get the image in a format that I can use to send to runway. And the way that I will do that is by turning it into a base 64 encoding of that image. So, how does that work? I am going to say image 64 equals canvas. I need to make a variable to store the canvas. And what happened? All the red dots went away. I talked about it, and they disappeared. Did somebody do something to make that happen? What is going on? Oh, my goodness. Ah, okay. So, Simon is clarifying. I'm talking about image segmentation models, and I was saying what we're doing really is the inverse of it. And actually, there is a specific name for that. It's called a reverse image segmentation model. Thank you for that clarification. So, image canvas.elt. So, let's talk about what's going on here. Canvas is a variable that's holding on to a P5 canvas object. The P5 canvas object is a wrapper of the native JavaScript browser canvas DOM element. That happens to exist in the.elt property. And then I should be able to say to data URL. Is that the right name of the function? Let's look this up. To data URL JavaScript. Yeah. So, the to data URL function returns a data URI containing a representative of the image in the format specified by the type parameter, defaults to PNG. So, there's a lot of ways I can configure this, but this particular function is what I want to turn the image essentially into a string. Now, it seems like a crazy thing, turning the image into a string. I think I've talked about this in some of my video tutorials. But this makes it very convenient to pass it over a post request, to send it to a web server. Okay. So, now where was I here? Did I get the name of the function right? I didn't, actually. It's to data URL with capital URL. So, that would go here. And let's just ‑‑ this is a little bit ridiculous for me to do this. But let's just console log it so we can see if this works. I'll paint a little bit, hit generate, and there it is. This is the entire image encoded as a base 64 string of characters. So, now if I go back to here, I don't want to console log that. I want to create my post request. And the inputs are. Now, this is what I need to look up in Runway. I don't recall what the inputs are. I know it's the image. It's probably something like this is probably what I send it, but I'm not entirely sure. I need to look it up in Runway, but it's going to show my API token. So, I don't mind. I'm going to show you how to do it with showing your API token and then quickly regenerate your API token. So, first thing I'm going to do is I'm going to disable the model so it's not active. Then I'm going to click on view the code snippet. And that's where it's showing the API key. And I can see the inputs is, ah, it's called semantic map. So, what I'm sending is something called a semantic map. And then the property, the value, that's the property name. The value is a base 64 image. So, let us, how do I do the regenerate the token edit? Right down here. So, this is me regenerating the API key, which I'm going to do. And I'm not going to let you see the regenerated one. I'm going to copy it. I'm going to put it into my.env file. The new token is there. Go back to sketch.js. Where am I? Where am I? Where am I? Let's turn, ah, I can come back to show you. Let's turn the model back on. Activate it. And this is supposed to be now where you remember semantic map. So, that's semantic map. And then send to runway. Wait for the outputs. And I don't, let's just look at console log outputs. Okay. So, I'm going to look at the output that comes back. Let's refresh this page. Generate. Sending the image. Now, it will probably take quite some time for it to, oh, it came back. Look, there we go. I have an output, which is, guess what? A base 64 encoded image. Status success. And the count is going up. So, I can go back to the code. And I can now put this stuff back in. The outputs, it wasn't, whoa, what was it called? It wasn't called image, was it? So weird. Why do I have an error now? Oh, I have two things called image 64. Input image 64. 764. Let's call it that. I'll just leave this one this. You know, I'll just rename this variable to landscape. Because why not? And then, I forgot what it's, daily limit reached. Come on, people. Have a little pity on me here. Ah. Come on, you don't, don't you want to bring generated landscape imagery out into the world in a way that we can all enjoy? I am going to, against my better judgment, go to here. Set this back to zero. And try to beat everybody. Great. So, oh, it's, so this is something, this is another bit of feedback for those of you who are taking notes. It's weird that the property is called output here. And in SkyGan, it was called image. Like, I feel like that would make sense for that to be pretty consistent across runway models. So I wouldn't have to keep changing it for every example. So, but here under sketch.js, I'm going to call this now outputs.output. And the, this is a spade cocoa generated landscape. And let's try this one more time. Oh, I need to refresh the page. Oh, there we got it. Look at this. That's my generated sky. Let's draw some ocean on it. Try to be faster than all of you people. And there's the ocean. Oh, this is so cool. And I'm at eight. Thank you, people. Please, please. All right. I guess what I'll do just to shut it off for a minute here. So this is why I should run this stuff locally so only I could run it and then deploy it to glitch. But so I want to do something now. I want to change the code. I want to make a variable called output image. And that is going to be output image.create image blank. So I want to create an image DOM element that's sitting below the canvas. And then rather than make a new one here, I just want to take the existing one. Let me put the alt text in. Hopefully this works. I've not tried to do this before. Let's put this in here. And I think I can say like output image.elt.source equals image 64. This would be setting the source of the image to that base 64 encoding, which would make it appear in the DOM element, I think. Is that right? Does anybody know? Cannot read property create image of undefined. Oh, equals create image. All right. I've disabled it. If you could please hold off on running this for a moment. I guess I could make it a private project, but I think let's see if this works. Great. And then if I do this, it generates a daily limit reached. Come on, people! This isn't even a sponsored live stream. I'm using up all my credits. I don't even know. All right. Back over here. I'm going to be doing my object model detection. Sorry, my object detection example. I'm going to be doing that locally. You won't be able to see it. I want to see if I can get... I want to see if it will replace it with a new one. All right. So that works. Now if I do this and hit generate again. Great. Awesome. It's working. Shutting you down, people. All right. So this works now that it's going to always update this one. Maybe I don't need 640 by 480 just to be able to see it. What I'm going to do now is have it update as I'm drawing. So this is going to use a lot of requests. This is where I would want probably more like a socket connection or something to the model. But let's just sort of see what happens here. So if I go back to Sketch.js. And then essentially this send image function, I am going to call it recursively. I am going to call it immediately when the program starts. And then every time after I've updated the image, I'm going to call send image again. And let's see. Let me set the count back down to zero. Let me turn the model back on to activate it. And now it should be updating as I draw. So I didn't pick like really smart colors here. But you can see here as I'm drawing, it's updating below. And I should obviously turn this off. I should certainly. What am I saying? I should certainly like. So there's lots more next steps to this. But I just wanted to save this as a basic example. And I'm realizing here also this should say Spade Cocoa P5.js example. I think actually I should publish the example with the generate button. So I just want to clean. I wanted to show you how it worked to do it continuously. But I'm going to take that out. I'm going to take this out. I'm going to take this out. And I just want to leave this. What would happen if I made this 320 by 240? Would it still work just as well? So I think it would just sort of be easier to see. And yeah, actually. So this should. It should do this first. Because I do want to see that always filled up. Let's turn this back on. Let's go to the server. And I'm going to set the count to one, whatever it may be. And now let's just see if this is working again. It's weird. Why? Why is that? Why won't it put the image next to it? Well, whatever. So now if I draw here and click generate, there we go. Great. And I can turn it off. All right. This example is finished. Thank you for watching. What was the thing that I wanted to fix here? Oh, I don't think I need the console log here right now. Okay. All right. So this you can use as an example to work with a runway. All right. Let's take a look at our. I really got to do. Let's do some community contributions. It's 520. I got to finish up here. Going to be done soon. Okay. Hey, everybody. It's time. It's quite late in this stream. Usually I try to do this at the beginning. It's a nice way to start off and say hello to the community and people watching the coding train. But it's very important to me that every live stream I show some of the work. Because you, the people of the coding train, are what power the train itself. You are the engine that produces the steam that drives the train. So let's go on over to our Discord. And I am going to type in the wheel command. And. What happened? What happened to the wheel? What happened to the wheel? The live stream chat bot is down. We can find it. It's right up here. So here's the wheel of community contributions. Thank you to David and. King over here on the. I forgot the user's name. Did some of these new features. Let's spin the wheel. So this pulls from some of the contributions that are on the website. And. Ultimate. Didn't we look at ultimate tic-tac-toe? I kind of remember looking at this one already. Am I wrong about that? I looked at. We looked at this one. Yeah. Well, did we? I really have. I looked at somebody's ultimate tic-tac-toe. But this now looks unfamiliar to me. Let's move this over, by the way. So I'm not in front of it so much. Also, I like to see my friendly masked son there. Where were we here? Okay. So take turns playing on the highlighted board. However, your move determines where your opponent will place their next move. The first player to conquer a board claims that board. Ultimate tic-tac-toe is playing mini games of tic-tac-toe inside a larger tic-tac-toe board. Oh, I see. I don't really know what's going on here, but this is really cool. Wait, why does it switch? So I'm playing both players. Oh, you do one board at a time. It just does a random one next. So you each get a turn in one cell. And then you get a turn in oh, it goes around randomly. So, like, you really have an advantage if you get lucky. Right? Like, this is just luck now. Who's gonna win? I'm playing against myself. I'm rooting for O, I think. O is just more friendly looking than X. Come on, O, you can do it. Place your bets, people, place your bets. Wait. Oh, X gets to go again? Shouldn't this square be done? O's gotta go here. O's gonna go here. All right, O, looking good, O. Uh-oh. Yeah, this one's already done. Where am I now? Oh, X. X is gonna block O. Where are we now, here? Here? X? I must finish this. Must finish. Yeah, ha-ha. It's not random, I'm being told. Interesting. But O has a good spot. Where am I now, here? X is gonna go there. O. Can I get three in a row like that? Probably not, right? O. Where am I now, here? X. Oh, yeah. Come on, O, you can do it. So don't tell me the logic of which one. Oh, a move, yeah. Someone tell me the logic of which one it picks, I'm curious. Where are we? Where are we? Oh, X is doing really well. Whoever wins this down here. Oh, didn't O just win? Didn't O just win? Oh, no, X had already won that one. I'm very confused. Okay, wait, wait, wait, wait. And now... I'm lost, people. O. Is it over? I'm so confused. What happened? Oh, there's no... O can go maybe wherever it wants? Yeah, okay. Now it's over, right? Yeah, O won! Thank you, this is pretty cool. I think, like, I'm like two hours into a live stream and my brain is like not functioning. Okay, the square you select in the mini board determines which mini board the next player will play in. Oh, can you start a new game and let the chat play? It'll be havoc to read, but it'll be fun for us, says Adrian. This is an excellent suggestion. However, I don't have a mechanism for doing that. So I think I've... This is really wonderful. Apologies to the creator of this for me being the brain dead person that I am, Amrit Amar, that I did not understand the logic here. Also, I'm playing against myself, so who knows what I would have done with that logic. But now it makes sense to me that there is sort of like a meta strategy inside the regular tic-tac-toe strategy, which is really interesting to think about. I would love for it to... I think some of the color choices could be more evident and you might be able to use like a fill even also to like highlight the active square. I'm often confused, like, you know, something to like separate the individual three by three tiles might be helpful. So I think there are some visual augmentations you could make here to make the sort of like the distinctive areas and the sort of interactions more clear. But this is a fantastic project. Ding the bell. Ring the train whistle. And let's move on to... Look at one more. Spin that wheel. Wow, there's a lot of tic-tac-toe ones coming up today. Resizable tic-tac-toe. Let's look at this one. Resizable tic-tac-toe PVSP. Click. Oh, this one I did look at. I definitely remember this one. Right? This one we've looked at before. So one of the things we need to do, one of the things I would like to do... Hi, Code Guppy again. Welcome. Thank you, Code Guppy. A member of the coding train. So... Thank you, Code Guppy. All right. Now... We looked at this. So one of the things I really would like to do is make some improvements and advancements in this sort of community contribution sharing system. The wheel is great. I think there's probably some nice design upgrades we could do with it. Having a sort of a database or an API that keeps track of what I've shown. Or kind of like tries to highlight people who haven't had their things shown. I don't know. There's a lot more that could be done with it. So apologies. Apologies for skipping that one. But I'm really sure that I looked at that one before in a previous. So let's spin the wheel and look at one more. Yeah. This one we also did look at because I remember that ray casting was spelled wrong. Ray casing with pygame. So I'm just going to double check and confirm. But I have a very... Yeah. I have a very specific memory that this one came up already. Let's refresh the wheel entirely to get ten new selections. And spin that wheel. I think we need some music to bring us better luck. And guess what, everybody? The coding train is brought to you today by Tic Tac Toe. It's a simple game. Fun to play for all the family. And yet it seems to be what everyone is. So let's take a look at it. By Gamer5000. Ruggamer5000. I'm mispronouncing your name on purpose. Okay. We can change the size. And we can play. Look at this. This is cool. So much Tic Tac Toe. I love how you can do this in real time. It would be interesting to think about if you were to start to play it. And you resize it and it kept what you had played so far. Like you're sort of zooming out. Let's see if there's any interesting thing that happens when you win. Ooh, animating the line drawing. Yeah. Welcome to the Tic Tac Toe coding channel. YouTube channel where every week we talk about the game Tic Tac Toe. How do you play it? What does it mean? Where did it come from? Who loves Tic Tac Toe? Where did it come from? Who loves Tic Tac Toe more than me? Nobody! Yes. Alright, one more. One more. One more. That was a little weird. That like yes that I did. That made me uncomfortable. I hope you're doing alright. Oh, it's the editable game of life. Remember? The editable game of life. Alright. We looked at that last week. We've got 10 print. I'm excited for this. 10 print is one of my favorite coding challenges that people contribute to. Just to look at it briefly, it's this coding challenge. It's actually, I don't know if any of you broke the record, but this is one that has so many contributions. It's a really, really simple system of drawing one of two possible lines in a grid. It's famously from this one line Commodore 64 program. If you're not familiar, I think if I just go to 10print.org with this book, by this collection of wonderful authors, all about the sort of like history of, it's really in a way it's like looking at the history of creative computing through the lens of this one line of code. Highly recommend this wonderful book. Let's take a look at this particular version of it by Nearby. Oh, this is cool. This is interesting. So at first I thought, huh, this looks to me like it is essentially identical to the original 10 print challenge. And I was about to say, that's wonderful. There's no reason why anybody shouldn't feel free to submit their own version of basically the exact same thing and getting it working. However, there's something quite different here. And I now have a very clear picture in my head of what I am assuming is going on here. But I'm curious to see if the chat, I know you're about 30 seconds behind me here, so I'll have to sort of vamp for a second. But if anyone in the chat wants to try to make a guess as to what is going on here, how is this different from the example? If I just go back to it again, if I just look at my particular example, which is this, from the actual video itself, looks very similar, but there is a different quality to it. Let's refresh this just to see it again. So Zork Master says, I feel like that's using some sort of noise. That's my thought exactly too. So I'm assuming that what this is doing is it's mapping the probability. Well, not just mapping the probability. It's picking the left line or right line, whichever direction the line is going, based off of most likely some Perlin noise-like algorithm rather than pure randomness. So in pure randomness, and one thing we can do that's nice, if I go to full here, we can see, I can quickly click over to look at the code. And you can see noise, X off, Y off. So very quickly, you can see how it's checking to see if the value is less than 50 or greater than 50. So just to demonstrate this more clearly, if I were to replace that with a random number between 0 and 100, that's what we'll get. Oh, but also the line has a different, it looks to me like it's always brighter when pointing to the right. Is it tying its stroke also to the noise value or the random value in this case? That's really interesting. I didn't think of that. So those are the, looks like the two changes. If I take that out, we can see here, this is the original 10 print code. But by changing it to using a noise algorithm over a two-dimensional space, and then additionally, and I already like got rid of that, but additionally changing the weight of the stroke weight of the line, or actually it's not the stroke weight, it's the brightness of the line. Those are really clever adjustments to make. There's so many rich and deep possible kinds of things you can do with this one algorithm. That's just, I love it so much. Okay. Unoriginal pun has woken up in Australia. Is that right? Where are you located, Unoriginal pun? Welcome to the live stream. I am going to have some water here and I'm removing myself. We are finishing up here, but I'm going to do one more thing before we go. So let us go back to the Rubik's Cube. I need to sign out of runway here and go back to this account because I'm a lunatic. The tiny one completed. You can see, oh, the other one is at 97%. So we could compare and contrast these, but let's look at this one. So this one trained, completed. Let's add it to the workspace. We're going to call this coding train demo. I'm going to give myself a lot more space here. I'm going to just test it out here in the browser with camera. Then I can select the actual webcam here. Let's run the model. And wait for it to pop up here and see how well this goes. This is exciting. Okinawa, Japan. Oh, Unoriginal pun! I have got to get in touch with you. I knew there was some reason why Okinawa, Japan was in my head. Okay, we'll be in touch on Discord. I've got to speak to you about Okinawa, Japan. All right, let's see. So this is what I was told. This was happening to me the other day. This, I'm told, is a bug in the runway interface. The fact that it is flickering back and forth to the edge. So this means I've really got to do it on my own. Unfortunately, I cannot abide by people going to the URL of the Glitch project in real time. I suppose I could go to full screen in Glitch or like this. And then you can't see the... Let's do it this way. This is kind of cruel of me. Or I could just develop. I'm going to develop this locally. I can clone a Glitch project, right? So if I go back to... This will be good for us to know how to do. I have to sneeze so badly right now. I'm going to mute the mic. That was the most amazing sneeze of my whole life. Do I have a box of Kleenex up here somewhere in the attic? If I can reach the ceiling, a nice tin ceiling here in the attic. I don't have a box of Kleenex. I think I'll be all right for just a few minutes. Whoa, what happened? My camera is doing some crazy color adjusting here. Let's go back to the runway template. Now there is a way... If I go to edit project, how do I get the GitHub URL of a project? Somebody will know this and tell me in the chat. Tools, custom domains, import, export. Here he is. Get URL. That's where it is, by the way, under tools. Sorry, under tools, import, export, get URL. Let's go back to terminal here. Let's see if we can clone it. I'm going to develop this locally. Just because I want to keep the key... I can keep the key secure, but I don't want to use up a zillion requests to the runway library. I just want to be able to operate it just myself. I think you'll all understand why. What's it called now? Runway ML template. Perfect. Let's open up the code. Here it is. I need to make a.env file. If I look in here, the things that I need are... I can not worry about the daily limit right now. I'll just make it a thousand so that I have something in there. I need to get a... Where do I create the model? How come I don't see this? I'm so blind. There it is. Runway URL. Runway URL equals and runway token. Let's go to runway and close all this stuff. Oh, stop. I was using up some credits there just running it. Let's do network. Let's host this model. Host model. I'm going to get the API key. Actually, let me... Where do I have... I wanted to just sort of test it with SkyGAN. Let me just test this with SkyGAN just to make sure it's working. Where do I go? Model, workspace, back to models, SkyGAN, SkyGAN, network, host this model, host this model. I am going to grab the model URL, put it in the URL. Then I'm going to grab the token, the API key. I don't know why I call it runway token. I guess that makes sense. It's an API key. I'm going to remove my screen, paste it in, hit save, hit close, and come back. So I believe now if I were to run this... Oh, I guess I need to do npm install to install the node modules. Run the server. Nope. Writing out count, not a number. What's going on here? Count 100, writing out count, not a number. Check day. Oh, I forgot about this whole check day thing. This is weird. I don't really care about this right now. So I'm just going to comment this out. I don't know why that's not working. I have a thing that I wrote that it resets the count every day. So my rate limiting is like 100 requests per day. But I'm just going to comment this out because I don't really need to worry about the rate limiting right now. URL provide is not... Your hosted model must be in the format. I think I did something wrong with getting the hosted model. So hold on, people. Going back to here, looking at my.env file. Oh, I know what the problem is. I know what the problem is. Nobody has actually... Did I actually figure it out before the chat did? Oh, how exciting. So let me close the.env file. So here's the problem. The problem is loading the information from the.env file works out of the box on Glitch. Glitch is set up to know about it automatically. But I need to use the.env package. The.env file will only be loaded if I require the npm package.env and call the config function. So I should say node npm i.env. So I have that now. And now I should be able to say... Node server. What's this shrink wrap thing? Okay, great. So the app is going. And it's listening on port. I guess I... Why did it pick that port? I guess there's some weird things I have to change when I'm doing this locally. Process.env port. Oh, well, I want to put this in the.env file. But I have to... Every time I look at the.env file, it's like danger, danger, Will Robinson. Port. I'll just do 3,000. Close that. And... Okay, so I should be able to go to localhost 3000. And click generate. Oh, it's doing it already. Let's make sure this works. Great, I got my SkyGAN. And look at this. The count is just going up by one each time. Because nobody else can run this but me! Ha ha! So let's now change this over to using the object detection model. Woo! So I am going to go to my p5 sketch. I am going to say let video. Video equals create capture video. Then... Video.hide. Function draw. Image video 0, 0. 0, 0. And width height. So let's not worry about send vector. Or calling that right now. Or the... I am going to keep the generate button in there right now. Allow. And of course we have the OBS virtual camera. I will switch this. I can just do it like this. Why do I have to do this always and forever? Okay, I have got my video showing up there. Next up. This is all the same that I already did. I should go grab... Actually, I am going to do that. Let's go back to the glitch project. That I was working on. Spade cocoa. Choo choo coding... Spade cocoa. Ding! Train choo choo! Let's grab this. This is a much better function for me to use. As my basis. Now, I don't know. I don't believe it is called semantic map. My guess is it is called image. And what is coming back is not an image. So I can get rid of that. Let's take a look at what comes back. So I am just guessing that this is what I am supposed to send to runway. The other thing I need to do, of course. Is go to my hosted models. And check and get the Rubik's Cube URL. Now, I have got to go back to my.env file again. Sorry, everybody. I am going to the.env file..env file. Now, I am going back to runway. I am getting the API key. I am putting the API key in my.env file. There it is. And now, I am going back to sketch.js. Closing the.env file. Excellent. And I think I should be able to say let's do, let's create button like detect. Let's call this object detect. And then call this object detect. So I am not 100% sure this is all correct. But in theory, when I press the button, it will send the image of the video to runway. The Node server will manage that. And give me back the outputs which presumably would have the label of the thing it found. The XY width height. Let's see. So I need to go to here. Hit refresh. Let's hold this up. Cannot read property to your data URL of undefined. I didn't check what I was doing here. What am I reading? Canvas. So actually, this should be the video. I want to take the video and turn that into data URL and send it. So this is a case where I don't want to send the canvas. So hopefully, that's all I needed to do. There's an error. To data URL could not be function. You know what it is. Video canvas. And I probably have to say video load pixels. I think in order to turn it into a data URL, I need to not look at the DOM element. But the canvas associated with the DOM element that has the pixel data loaded on it. I think. We'll find out. I'll try it without load pixels in a second. Detect. Okay. Wow. It froze everything up. That's weird. And it shouldn't say like console log. I'm not saying console log sending image. Let's check. One of the things that you should always check when you're doing this is, is the model awake or asleep? This is weird that the model is not waking. It should be turning yellow here. All right. Let's. Let me double check what it's looking for. So I'm going to switch back to just showing me. Because when I look at the runway example code, it has the API key in it. Image threshold. I also need a threshold. So I'm just going to show this to you. Without the API key visible. So in runway, the inputs are the image, the base 64 image, as well as a threshold. I would assume it's using a default threshold. And then I should get back bounding boxes, categories, and scores. So let me make sure everything is right here. Let me make sure the URL and the token is correct. In the dot ENV file. Yeah, it looks absolutely looks right. Server. Let's console logs. Is there any error in the server? I didn't actually check. Oh, the requests are going through. I know I need to show you my screen. But why? I'm kind of confused because this should show it as waking up. Oh, SkyGan is waking up. Because somebody is running that glitch application. I should turn this one off. That's not the one that I'm using right now. Let's go here. And maybe I just need to also add threshold 0.5. Let's try that. Threshold 0.5. And let's make sure that base 64 image is actually working properly. It just got stuck there. Okay. Froze. So that's definitely a base 64 image. Where did it get stuck though? I don't see. Oh, console logs sending images. Oh, I got an error here. The model expires. I don't know what's going on. I'm going to go back to the console logs. The model experienced an error while processing your input. Double check that you are sending properly formed input parameters. Hosted model dot info method. So let's do that. Boy, this is supposed to be the end. I'm like, it's almost six o'clock. I'm going an hour later than I said. But I really want to get this to work. Oh, let's turn this off. Take close these things. Close these things. So let's look again. Look again at the code snippet. Threshold number from point zero one to point to one. It's weird. Okay. So I'm just going to do something here in the server. And when I run the server, I'm going to call model dot info. Just to make sure that that's working properly. So let's do that. Something weird is going on. Right? That. Your app is just in port 3000. Count 100. Why is this not communicating with the model? Add some additional console logs here. There we go. Okay. Default. Okay. This is the inputs are channels three default name, image type image. Default point five. Minimum constant score. Max one threshold name threshold. Okay. So image base 64 image. And then I should get objects back. So maybe the model. Oh, it's awake now. I don't know something. I guess maybe something was going weird with it. Let's refresh this page. Oh, there we go. The bounding boxes came back. Rubik's scores, status, success, bounding boxes. Looks like these are normalized values. Now, why? Why, why, why, why, why did this stop? Why did that stop on the client? Function draw. Oh, hold on. I had something I have to do on my phone. The alarm went off. I have to do this at six o'clock. So at five 59, I need to stop for a second. Why? That's so weird. What happened here? That caused it to stop. Let's let's. It's just. OK, now I'm going to detect call detect. That's still going. Why did the canvas stop? Why did draw? I mean, I recognize that this is like an this is an asynchronous function. Did like the load pixels active loading the pixels. Let's let's comment this out. See if it works. Ah. So load pixels messes it up, but it can't get the. Can I call like update pixels and that'll like get it going again? No. That's like a P5 bug. It shouldn't be there. No. That's like a P5 bug. It shouldn't be doing that. All right. I'm not going to. This is a P5 bug that's unrelated to what I'm trying to do. So I'm going to just not worry about that for because I I got to stop. I got to stop live streaming. Somebody will help me figure this out. I have two minutes till I need to do something very important on my phone. But. I have an activity that I do with my kids and you have to book it 48 hours in advance. Or you know due to like COVID restrictions and if I don't do it right at 6 it's for like Monday at 6. It doesn't like you have to join the wait list. So watching the clock here. So let's just draw. Let's do it this way. Let's I could copy it. You know what I could do. This is making me annoyed that I want to fix this is no it's like it feels like a P5 bug. Let video copy. Oh I can just do this. Can I do this? It does the same thing because get is going to load the pixels of the video in order to copy it. Okay never mind. I won't worry about this. Let's look at what comes out. Bounding boxes. Okay nothing. So. So let's. I think if I do. Make a variable called detections is an empty array. And then if I say. Detections equals output stop bounding boxes. Is that what it was called? Let's actually whoops. Let's get 558 when says 559 I'm going to stop for a second. You know I'm a stop now. You guys got to bear with me. You know I'm a stop now. You guys got to bear with me while I refresh a page on my phone over and over again. I'm going to finish this off. This is such a weird thing I'm doing. Sunday Monday. 6pm. You all will think of me at 6pm on Monday if I get this too early to join. Too early to join. Too early to join too early to join. Really to join. Really to join. Really to join. Really too early Really to join. A join. Really really. Really doing. His joy. Let's go. Change the six o'clock already. Really enjoy. Really enjoying. Just refreshing this over and over again. Too early to join. Really enjoying. Join join join join. Yes, I got it. Monday at six o'clock. All right. Excellent. So the bounding boxes are An array with four values in it. And I assume this is normalized to the width and the height. So I could say here. Now in draw for let I Equals zero eyes less than what did I call this detections sections dot length. Let cube equals detections index I and then I want to say X equals Cube dot zero times with Y equals cube one dot width dot height times height. What do we think? Do we think these are the width and height of the box or do we think this is the bottom right corner of the box? Does it explain that to me anywhere? I mean looking at those numbers. What would you guess? I don't think they're the width and the height. That would be huge must be the bottom right and bottom the corner. So I think I would then say X X one Y one. X two Y two two and three and then I could think I could say rect mode. Corners. I think that's what it is in P5. If instead of specifying the XY width and height. I want to specify the corners and then I would draw a rectangle X one Y one X two Y two stroke. 255 no fill stroke weight. Let's make it pretty thick eight. All right, let's try this now. So no Rubik's Cube. The model must have gone to sleep during all that time. This model has trouble waking up it seems. So that's green. I'm impatient. Oh, I'm so close to being done with this live stream. Wow, why did it break? So this is also a weird bug which I would sort of assume is maybe a runway issue. Where did I have that querying the model? All right, let's restart the server. So the model is not returning. Oh, there we go. The info yet. So I'm going to go back to the server. And I'm going to go back to the model. So the model is not returning. Oh, there we go. The info yet. I suppose I could try. Oh, it's yellow. That's a good sign. It's waking up. If anybody has watched this entire stream and has been taking notes on all the different runway related things that have come up, that would be so amazing to compile. I would be forever grateful, even with the time codes of when they are, because I want to get in touch with the runway folks after this. Is the audio peaking, by the way? I'm seeing a lot of voice comments. I'm seeing a lot of red in the monitor I'm using. Still yellow. Oh, no, it's awake, I think. Okay, no bounding box. There we go! So I'm going to go back to the server. And I'm going to go back to the model. And I'm going to go back to the model. Okay, no bounding box. There we go! Amazing! Oh, this is so cool. A custom trained object detection model working, like, essentially perfectly. I mean, look how good this is. This is crazy. The thing is, I wanted to get it to work in real time. And I don't understand why the video is frozen whenever I call load pixels. Such a strange thing. So I guess I'm going to have to work that out later. I'm going to publish this to Glitch right now. Obviously without the environment variables. If anybody wants to... You could work on debugging this for me without the runway call. For example, this should still work just fine if I don't actually query runway. Just the act of loading the pixels. If you want to debug this for me with P5. If I take out all of this. Just comment all of this out right now. Let's be sure about this. Refresh it. Right? Just the act of calling load pixels freezes the canvas element of the video. It's not supposed to do that. I don't recall that it used to do that. I wonder if that's a new bug. I'm using the latest P5. Again, I've got to stop. I've got to turn this off. But that's one of the first things I would do is go back and try earlier versions. This feels like a bug in P5. Let's just wrap all this up by... I'm going to put this back in. I am going to add a... How do I do this? I'm going to add a.env file. No, not in public. Not a.env file. Sorry. Come on. Make a new file down here. Thank you. A.gitignore. That's what I want to do. And in.gitignore, I'm going to ignore.env node modules. I don't really need this, but that's fine. Count is fine. That's fine. Read me, fine. Server, fine. I don't know what this is. I don't know what this shrink wrap YAML thing is. Let me just take that out because I don't need that for what I'm doing. That seems like a glitch thing. I can also take this out. Okay. So now... Let's make a branch called main. Let's call this... Sorry, what am I doing? This is updating to work with object detection. Then I'm going to go to github.com coding train. What is this? What is this? Runway ML object detection. Object detection model with runway ml node.js and p5.js. No, I don't want to create a repository. Yeah, I do want to create a repository, but I'm using an existing repository. There we go. Then... Okay, so... This is what I want to do. Add this. Whoops. Origin, get remote-v. Oh, because get remote remove origin. Okay. Oh, yeah. Okay, and then get push origin main, I guess. So now all the code for it is here. And I can put that in Discord if anybody wants to look at it. Let's see, did the distream bot come back? No. Run object detection. Okay, there we go. So this is the... If you're in the Discord under live, under links, that's the GitHub repo. And why not just put this on glitch now? It should be able to do. So the runway ML template, that was the first one. The spade coco ding train choo-choo runway ML template is the next one for spade coco. And now new project import from GitHub. I think this will work. And just paste this in, import from GitHub there here. Let's see what happens. Well, I'll let it load. Let's give it a minute here. So this is the end, by the way, everybody. I'll be back, hopefully next Saturday. We'll be taking at least one Saturday off in... Let me pause this for a second. We'll be taking at least one Saturday off in November. I scheduled to take the Saturday of Thanksgiving weekend off. I am not going anywhere for Thanksgiving. I am not having anyone come over for Thanksgiving. I don't think it's really safe or advisable to do so. Everyone's got to make their own decision, of course. Following your local guidelines and laws. But so it's conceivable that I might live stream that weekend. But we'll see. A lot is going on. This is a very busy time of year with the NYU semester, which is wrapping up soon, which is a good thing for me in terms of more time to stream. But let's just see here. I believe if I look at this, there shouldn't be anything in there. Yeah, right. So this you can now also find this project, although I want to rename it to runway ML object detection. So now I should be able to... You should be able to see this project as well here. It's on the read me. Sorry about that. So I'm going to disable the model right now. And the API keys aren't in this anyway. But so that wraps that up. So what is coming next on the coding train? Yesterday on Friday, I recorded four... There are five. I have five in the can now. Five video tutorials to come out. The first one is using ML5 convolutional neural network. Part one. The second is using ML5 convolutional neural network. Part two. The third is using the ML5 pre-trained convolutional neural network model, DoodleNet. The fourth is posting GIFs from your Discord bot. And the fifth is... Oh, no. The fourth is using a.env file to hide your API keys with a Discord bot, which if you watch today's stream, you're familiar with that somewhat. And the fifth is posting GIFs. So hopefully those will come out soon. If you... I've been doing recording sessions on Fridays. It's a little bonus if you want to join as a member. You can sort of tune in to those recording sessions. If you're not a member, don't worry. You're really not missing anything. Because ultimately, all the content from those recording sessions get released eventually. But if you want a little early access or to interact in that way, you're welcome to join the coding train membership program. Hopefully at least one of them will come out next week. My process has really slowed down for better or worse. But I'm working with doing some video editing and getting the descriptions and the captions and all that stuff done before they are released. I'm looking in the chat to see if there's any questions or otherwise things coming out. Question mark wheel. Ah, I'm told the prefix changed. There we go. Question mark wheel. The prefix in train bot 2.0 distream bot had changed. Okay. So anyway, I hope you enjoyed today's live stream. I feel like last week was such a disaster. Unmitigated disaster, I suppose. Put everyone... Hey, Patricia Parker! Hold the presses! Stop! Pause! Let's everybody take a moment to welcome... Patricia Parker! Welcome for boarding the coding train. We'll ring the bell for you and blow the train whistle. Your membership is greatly appreciated. It is really just... I'm honored and thrilled and thankful. And for each member of the coding train. At some point you will get some stickers in the mail. I'm getting myself... It's actually been... Actually, the sticker mailing process is really working quite well. Much better than it ever has before. So stay tuned for more about that. That's happening soon. A lot of you got them recently. But all of you who have joined in the last few weeks, you should be getting them soon. I know poor David has been waiting like two years. And there was like some... A lot of mix-ups that happened. So my apologies to David. But Patricia, your random number. Is... And again, we really need a system for keeping track of all these. On page 187, row 9308, column... 4, 73803. Thank you, Patricia. Reset my song. Greetings Lars from Denmark. I was thinking what I would do actually with the... Tutorial about how to post a GIF to your Discord bot. That I would release two versions of it. One with me saying GIF. And one with me saying JIF. It would be exactly the same tutorial. But I'd have two... Actually, I think I really will do this. So I'm just gonna have to dub it over. Or use machine learning or something. I think I should dub it over actually. But just... And then this is where you post your GIF. And then this is where you post your JIF. So I think that'll be pretty awesome. Alright. Bruno's asking me if I regenerated all the keys leaked early. I think I did. But I think I either regenerated or then I disabled the models. I'm letting this run for another two minutes. I'll answer any questions that I see in the chat. By the way, what's funny to me about the membership thing... Is literally that message will come in if somebody just happened to join at this time. And I'm not actually tuning in. I know I said this already in the livestream. So Patricia, I don't know if you're actually there. But please make sure you... If you are there, Patricia, make sure you sign up and get information about the Discord. Yes. The way it's pronounced is definitely GIF. That's how it's pronounced. Am I from Denmark? I am not from Denmark. Have I ever been to Denmark? Nobody asked that question, but I'm asking it. No. I have never been to Denmark. I've got to get to Denmark. An unoriginal pun. If you're still watching. I've got to talk to you about Okinawa, Japan. I'm in the market for a place to live for a little while. And I have fantasies of going to various places. And Okinawa, Japan is kind of on my list. If... Patricia is here. Hi, Patricia. If you live somewhere beautiful and amazing in the world... I have what I'm hoping is a six-month period where I could, with my family, go on a little adventure. You know, assuming this is far off in the future. I'm kind of assuming that the world will hopefully be mostly recovered from the pandemic currently. That's a huge assumption, obviously. But I'm starting to plan for that possibility. Just to look forward to something. I hope that you have something to look forward to. Boy, this is really depressing. There's 20 seconds left. Don't go to Denmark. Norway. I have been to Norway. Okay. Can I tell you about one of my favorite places in the world? I have some of my favorite memories in life from this place. And I'm going to tell you all about it right now. It is the island of Runda in Norway. This is where it is. Right here. I can zoom all the way out. I spent three or four days there with my family. I believe it means Bird Island. And we went on hikes. We hiked all the way out to this lighthouse here. And by the way, there's no way to get to that lighthouse other than hiking. And it was like an hours and hours hike. I had a three-year-old and a six-year-old at the time. It was a really amazing adventure. And I actually asked, when I got there, the proprietor of the lighthouse. Which you can stay overnight there for free if you hike out there. I asked the proprietor if there was maybe a boat that could take us back. And they laughed at me in a friendly way. It's kind of funny. We hiked back. I had such an amazing time. We went there to see puffins. We were at the wrong time of year. There were no puffins. But I really just had – I would love to go back there. That was really just an amazing time on this little spot in the world that we visited. Okay. 16 seconds left. All right, everyone. I will see you hopefully next – stay tuned. Probably next Saturday. But some Saturday in the future here on the Coding Brain. Hopefully in the morning again on my time. But we'll see. Bye. As always, I always forget to Vistac. Uh-oh. I'm gonna do the Vistac. Vistac! Vistac! Vistac! The Vistac song, never forget the Vistac. Somebody compose that song for me. I'm gonna say once again. Here we go. Sing it with me. It's the fourth. To Cartesian coordinate songs. It's the fourth to Cartesian coordinate songs. Autotune and the internet will fix that for me. Everyone is welcome, right? It's the fourth. To Cartesian...... coordinate songs. It's the fourth to Cartesian coordinate songs. It's the fourth to Cartesian coordinate songs. It's the fourth to Cartesian coordinate songs. It's the fourth to Cartesian coordinate songs. Unicorns and rainbows and cupcakes. What else is there? Yes, kittens. Thank you very much. Kittens and rainbows and cupcakes. Notice that. Look what I get. I'm really losing my mind. Okay, let's do it. Kittens, kittens, kittens, kittens, kittens... This is usually the part of the livestream as I'm packing up that I, I like to do a little behind the scenes here. Take down the green screen. We can turn off the lights. I gotta listen. I'm very curious to listen back to how this microphone is. If I even have it like set up correctly. Come on control center. Turn off the light. Oh darkness. Oh it's so dark. I didn't realize I had all the lights off now. Should at least turn on the regular lights. Which now I'm realizing that's why the key was weird. I have these other just regular lamps that usually brighten up the green screen. Thanks everybody for watching. I think I have successfully put everything away. This is the big grand finale of the song. Wish I had the cat. All right bye.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:41.638387Z",
  "started_at": "2023-09-26T21:16:14.478708Z",
  "completed_at": "2023-09-26T21:56:48.040529Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=py9HMzrdpTI",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 2433.561821
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/eqbhhojbx4kqfixeump3glr3t4/cancel",
    "get": "https://api.replicate.com/v1/predictions/eqbhhojbx4kqfixeump3glr3t4"
  }
}