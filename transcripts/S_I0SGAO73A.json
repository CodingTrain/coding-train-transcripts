{
  "id": "mbxxn4jbczpdsksrahz53wo6ru",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/S_I0SGAO73A.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/130066 [00:00<?, ?frames/s]\n  2%|▏         | 2912/130066 [00:06<05:05, 416.78frames/s]\n  4%|▍         | 5760/130066 [00:17<06:22, 325.11frames/s]\n  6%|▋         | 8240/130066 [00:22<05:19, 381.40frames/s]\n  8%|▊         | 10908/130066 [00:26<04:25, 449.53frames/s]\n 10%|█         | 13256/130066 [00:29<03:45, 517.25frames/s]\n 12%|█▏        | 16192/130066 [00:34<03:30, 541.57frames/s]\n 15%|█▍        | 19164/130066 [00:38<03:06, 596.03frames/s]\n 17%|█▋        | 22148/130066 [00:44<03:16, 547.87frames/s]\n 19%|█▉        | 24512/130066 [00:48<03:04, 571.74frames/s]\n 21%|██        | 26940/130066 [00:51<02:43, 629.44frames/s]\n 22%|██▏       | 28976/130066 [00:54<02:41, 625.49frames/s]\n 25%|██▍       | 31964/130066 [00:58<02:29, 655.04frames/s]\n 27%|██▋       | 34904/130066 [01:03<02:23, 660.96frames/s]\n 29%|██▉       | 37684/130066 [01:07<02:18, 666.25frames/s]\n 31%|███▏      | 40680/130066 [01:13<02:25, 616.08frames/s]\n 34%|███▎      | 43588/130066 [01:18<02:27, 587.59frames/s]\n 36%|███▌      | 46384/130066 [01:22<02:17, 608.92frames/s]\n 37%|███▋      | 48604/130066 [01:24<02:01, 671.86frames/s]\n 39%|███▉      | 51276/130066 [01:29<01:58, 663.86frames/s]\n 42%|████▏     | 54016/130066 [01:32<01:46, 714.12frames/s]\n 43%|████▎     | 56460/130066 [01:36<01:51, 662.45frames/s]\n 46%|████▌     | 59452/130066 [01:43<02:01, 580.04frames/s]\n 48%|████▊     | 62180/130066 [01:47<01:56, 582.73frames/s]\n 50%|█████     | 65180/130066 [01:53<01:53, 570.33frames/s]\n 52%|█████▏    | 67780/130066 [01:58<01:52, 554.97frames/s]\n 54%|█████▍    | 70444/130066 [02:03<01:50, 538.42frames/s]\n 56%|█████▋    | 73364/130066 [02:07<01:36, 586.39frames/s]\n 58%|█████▊    | 76072/130066 [02:12<01:32, 581.23frames/s]\n 60%|██████    | 78072/130066 [02:16<01:36, 541.42frames/s]\n 62%|██████▏   | 80672/130066 [02:20<01:26, 571.62frames/s]\n 64%|██████▍   | 83212/130066 [02:25<01:22, 567.69frames/s]\n 66%|██████▌   | 86152/130066 [02:28<01:06, 663.75frames/s]\n 68%|██████▊   | 88712/130066 [02:33<01:08, 599.49frames/s]\n 70%|███████   | 91132/130066 [02:39<01:11, 542.21frames/s]\n 72%|███████▏  | 94072/130066 [02:44<01:06, 542.88frames/s]\n 75%|███████▍  | 97032/130066 [02:51<01:05, 503.08frames/s]\n 76%|███████▋  | 99312/130066 [02:54<00:56, 544.30frames/s]\n 78%|███████▊  | 101912/130066 [02:58<00:47, 587.29frames/s]\n 80%|████████  | 104692/130066 [03:03<00:44, 567.40frames/s]\n 83%|████████▎ | 107412/130066 [03:07<00:38, 591.85frames/s]\n 85%|████████▍ | 110332/130066 [03:11<00:32, 613.20frames/s]\n 87%|████████▋ | 112932/130066 [03:15<00:27, 633.92frames/s]\n 89%|████████▊ | 115132/130066 [03:19<00:23, 628.44frames/s]\n 91%|█████████ | 117942/130066 [03:24<00:19, 615.80frames/s]\n 93%|█████████▎| 120602/130066 [03:29<00:16, 570.97frames/s]\n 95%|█████████▍| 123252/130066 [03:34<00:12, 548.18frames/s]\n 97%|█████████▋| 126100/130066 [03:42<00:08, 462.21frames/s]\n 99%|█████████▉| 129056/130066 [03:52<00:02, 402.48frames/s]\n100%|██████████| 130066/130066 [03:54<00:00, 412.04frames/s]\n100%|██████████| 130066/130066 [03:54<00:00, 554.81frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 4.6000000000000005,
        "id": 0,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " All right, we are here in the third Spell video.",
        "tokens": [
          50364,
          1057,
          558,
          11,
          321,
          366,
          510,
          294,
          264,
          2636,
          3550,
          285,
          960,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 7.08,
        "id": 1,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 4.6000000000000005,
        "temperature": 0,
        "text": " Thank you to Spell for sponsoring.",
        "tokens": [
          50594,
          1044,
          291,
          281,
          3550,
          285,
          337,
          30311,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 9.68,
        "id": 2,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 7.08,
        "temperature": 0,
        "text": " Sign up at spell.run slash coding train.",
        "tokens": [
          50718,
          13515,
          493,
          412,
          9827,
          13,
          12997,
          17330,
          17720,
          3847,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 13.48,
        "id": 3,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 9.68,
        "temperature": 0,
        "text": " OK, so if you watched the first video where I explained",
        "tokens": [
          50848,
          2264,
          11,
          370,
          498,
          291,
          6337,
          264,
          700,
          960,
          689,
          286,
          8825,
          51038
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 16.5,
        "id": 4,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 13.48,
        "temperature": 0,
        "text": " how to set up Spell, then you watch the second video which",
        "tokens": [
          51038,
          577,
          281,
          992,
          493,
          3550,
          285,
          11,
          550,
          291,
          1159,
          264,
          1150,
          960,
          597,
          51189
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 19.400000000000002,
        "id": 5,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 16.5,
        "temperature": 0,
        "text": " you trained your own style transfer model using",
        "tokens": [
          51189,
          291,
          8895,
          428,
          1065,
          3758,
          5003,
          2316,
          1228,
          51334
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 24.04,
        "id": 6,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 19.400000000000002,
        "temperature": 0,
        "text": " TensorFlow and Python, running it in the cloud on spell.run.",
        "tokens": [
          51334,
          37624,
          293,
          15329,
          11,
          2614,
          309,
          294,
          264,
          4588,
          322,
          9827,
          13,
          12997,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 26.12,
        "id": 7,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 24.04,
        "temperature": 0,
        "text": " Now you're ready for that last step,",
        "tokens": [
          51566,
          823,
          291,
          434,
          1919,
          337,
          300,
          1036,
          1823,
          11,
          51670
        ]
      },
      {
        "avg_logprob": -0.27355610091110755,
        "compression_ratio": 1.6589147286821706,
        "end": 29.12,
        "id": 8,
        "no_speech_prob": 0.02160552330315113,
        "seek": 0,
        "start": 26.12,
        "temperature": 0,
        "text": " downloading your trained model from Spell,",
        "tokens": [
          51670,
          32529,
          428,
          8895,
          2316,
          490,
          3550,
          285,
          11,
          51820
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 33.160000000000004,
        "id": 9,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 29.12,
        "temperature": 0,
        "text": " bringing it into the browser using the ml5.js open source",
        "tokens": [
          50364,
          5062,
          309,
          666,
          264,
          11185,
          1228,
          264,
          23271,
          20,
          13,
          25530,
          1269,
          4009,
          50566
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 35.96,
        "id": 10,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 33.160000000000004,
        "temperature": 0,
        "text": " library, p5.js open source library.",
        "tokens": [
          50566,
          6405,
          11,
          280,
          20,
          13,
          25530,
          1269,
          4009,
          6405,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 38.120000000000005,
        "id": 11,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 35.96,
        "temperature": 0,
        "text": " ml5, by the way, is built on top of TensorFlow.js.",
        "tokens": [
          50706,
          23271,
          20,
          11,
          538,
          264,
          636,
          11,
          307,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 39.660000000000004,
        "id": 12,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 38.120000000000005,
        "temperature": 0,
        "text": " Got to mention all these libraries.",
        "tokens": [
          50814,
          5803,
          281,
          2152,
          439,
          613,
          15148,
          13,
          50891
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 41.260000000000005,
        "id": 13,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 39.660000000000004,
        "temperature": 0,
        "text": " All these libraries come together,",
        "tokens": [
          50891,
          1057,
          613,
          15148,
          808,
          1214,
          11,
          50971
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 44.08,
        "id": 14,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 41.260000000000005,
        "temperature": 0,
        "text": " and you can then take real time images from your webcam",
        "tokens": [
          50971,
          293,
          291,
          393,
          550,
          747,
          957,
          565,
          5267,
          490,
          428,
          39490,
          51112
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 46.2,
        "id": 15,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 44.08,
        "temperature": 0,
        "text": " and style it with your style transfer model.",
        "tokens": [
          51112,
          293,
          3758,
          309,
          365,
          428,
          3758,
          5003,
          2316,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 47.46,
        "id": 16,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 46.2,
        "temperature": 0,
        "text": " So follow this tutorial.",
        "tokens": [
          51218,
          407,
          1524,
          341,
          7073,
          13,
          51281
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 50.08,
        "id": 17,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 47.46,
        "temperature": 0,
        "text": " If you get this working, please, please, please share it",
        "tokens": [
          51281,
          759,
          291,
          483,
          341,
          1364,
          11,
          1767,
          11,
          1767,
          11,
          1767,
          2073,
          309,
          51412
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 52.68,
        "id": 18,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 50.08,
        "temperature": 0,
        "text": " with me, hashtag this.style on Twitter,",
        "tokens": [
          51412,
          365,
          385,
          11,
          20379,
          341,
          13,
          15014,
          322,
          5794,
          11,
          51542
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 54.44,
        "id": 19,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 52.68,
        "temperature": 0,
        "text": " share it in the comments here, or anywhere",
        "tokens": [
          51542,
          2073,
          309,
          294,
          264,
          3053,
          510,
          11,
          420,
          4992,
          51630
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 55.480000000000004,
        "id": 20,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 54.44,
        "temperature": 0,
        "text": " you can find to share it.",
        "tokens": [
          51630,
          291,
          393,
          915,
          281,
          2073,
          309,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.2485353274223132,
        "compression_ratio": 1.8377483443708609,
        "end": 57.6,
        "id": 21,
        "no_speech_prob": 0.0004108285065740347,
        "seek": 2912,
        "start": 55.480000000000004,
        "temperature": 0,
        "text": " I would love to know and see what you all make.",
        "tokens": [
          51682,
          286,
          576,
          959,
          281,
          458,
          293,
          536,
          437,
          291,
          439,
          652,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.28259242905510795,
        "compression_ratio": 1.4915254237288136,
        "end": 61.28,
        "id": 22,
        "no_speech_prob": 0.00012533234257716686,
        "seek": 5760,
        "start": 57.6,
        "temperature": 0,
        "text": " OK, enjoy this video from Yining again.",
        "tokens": [
          50364,
          2264,
          11,
          2103,
          341,
          960,
          490,
          398,
          1760,
          797,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.28259242905510795,
        "compression_ratio": 1.4915254237288136,
        "end": 64.72,
        "id": 23,
        "no_speech_prob": 0.00012533234257716686,
        "seek": 5760,
        "start": 61.28,
        "temperature": 0,
        "text": " So far, we set up the environment.",
        "tokens": [
          50548,
          407,
          1400,
          11,
          321,
          992,
          493,
          264,
          2823,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.28259242905510795,
        "compression_ratio": 1.4915254237288136,
        "end": 66.64,
        "id": 24,
        "no_speech_prob": 0.00012533234257716686,
        "seek": 5760,
        "start": 64.72,
        "temperature": 0,
        "text": " We downloaded the data set.",
        "tokens": [
          50720,
          492,
          21748,
          264,
          1412,
          992,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.28259242905510795,
        "compression_ratio": 1.4915254237288136,
        "end": 72.6,
        "id": 25,
        "no_speech_prob": 0.00012533234257716686,
        "seek": 5760,
        "start": 66.64,
        "temperature": 0,
        "text": " We trained the model with the style Python script.",
        "tokens": [
          50816,
          492,
          8895,
          264,
          2316,
          365,
          264,
          3758,
          15329,
          5755,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.28259242905510795,
        "compression_ratio": 1.4915254237288136,
        "end": 78,
        "id": 26,
        "no_speech_prob": 0.00012533234257716686,
        "seek": 5760,
        "start": 72.6,
        "temperature": 0,
        "text": " We copied our trained model back to our local computer.",
        "tokens": [
          51114,
          492,
          25365,
          527,
          8895,
          2316,
          646,
          281,
          527,
          2654,
          3820,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.28259242905510795,
        "compression_ratio": 1.4915254237288136,
        "end": 82.4,
        "id": 27,
        "no_speech_prob": 0.00012533234257716686,
        "seek": 5760,
        "start": 78,
        "temperature": 0,
        "text": " And then last step is to convert the model to a format",
        "tokens": [
          51384,
          400,
          550,
          1036,
          1823,
          307,
          281,
          7620,
          264,
          2316,
          281,
          257,
          7877,
          51604
        ]
      },
      {
        "avg_logprob": -0.2658376097679138,
        "compression_ratio": 1.2949640287769784,
        "end": 87.92,
        "id": 28,
        "no_speech_prob": 0.0016229202738031745,
        "seek": 8240,
        "start": 82.44000000000001,
        "temperature": 0,
        "text": " that we can use in TensorFlow.js and ml5.js.",
        "tokens": [
          50366,
          300,
          321,
          393,
          764,
          294,
          37624,
          13,
          25530,
          293,
          23271,
          20,
          13,
          25530,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.2658376097679138,
        "compression_ratio": 1.2949640287769784,
        "end": 90.08000000000001,
        "id": 29,
        "no_speech_prob": 0.0016229202738031745,
        "seek": 8240,
        "start": 87.92,
        "temperature": 0,
        "text": " OK, let's do this.",
        "tokens": [
          50640,
          2264,
          11,
          718,
          311,
          360,
          341,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.2658376097679138,
        "compression_ratio": 1.2949640287769784,
        "end": 94.76,
        "id": 30,
        "no_speech_prob": 0.0016229202738031745,
        "seek": 8240,
        "start": 90.08000000000001,
        "temperature": 0,
        "text": " Oh, by the way, this is the trained model",
        "tokens": [
          50748,
          876,
          11,
          538,
          264,
          636,
          11,
          341,
          307,
          264,
          8895,
          2316,
          50982
        ]
      },
      {
        "avg_logprob": -0.2658376097679138,
        "compression_ratio": 1.2949640287769784,
        "end": 97.44000000000001,
        "id": 31,
        "no_speech_prob": 0.0016229202738031745,
        "seek": 8240,
        "start": 94.76,
        "temperature": 0,
        "text": " that we got on the desktop.",
        "tokens": [
          50982,
          300,
          321,
          658,
          322,
          264,
          14502,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2658376097679138,
        "compression_ratio": 1.2949640287769784,
        "end": 109.08000000000001,
        "id": 32,
        "no_speech_prob": 0.0016229202738031745,
        "seek": 8240,
        "start": 100.44,
        "temperature": 0,
        "text": " OK, so if I go back to my old directory, which",
        "tokens": [
          51266,
          2264,
          11,
          370,
          498,
          286,
          352,
          646,
          281,
          452,
          1331,
          21120,
          11,
          597,
          51698
        ]
      },
      {
        "avg_logprob": -0.35942210321841034,
        "compression_ratio": 1.2956521739130435,
        "end": 123.64,
        "id": 33,
        "no_speech_prob": 0.00023050548043102026,
        "seek": 10908,
        "start": 109.16,
        "temperature": 0,
        "text": " is live stream here, we're going to use the scripts that",
        "tokens": [
          50368,
          307,
          1621,
          4309,
          510,
          11,
          321,
          434,
          516,
          281,
          764,
          264,
          23294,
          300,
          51092
        ]
      },
      {
        "avg_logprob": -0.35942210321841034,
        "compression_ratio": 1.2956521739130435,
        "end": 128.24,
        "id": 34,
        "no_speech_prob": 0.00023050548043102026,
        "seek": 10908,
        "start": 123.64,
        "temperature": 0,
        "text": " is from file style transfer deeplearn.js.",
        "tokens": [
          51092,
          307,
          490,
          3991,
          3758,
          5003,
          2452,
          306,
          1083,
          13,
          25530,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.35942210321841034,
        "compression_ratio": 1.2956521739130435,
        "end": 132.56,
        "id": 35,
        "no_speech_prob": 0.00023050548043102026,
        "seek": 10908,
        "start": 128.24,
        "temperature": 0,
        "text": " Deeplearn.js is the formal name for TensorFlow.js.",
        "tokens": [
          51322,
          14895,
          306,
          1083,
          13,
          25530,
          307,
          264,
          9860,
          1315,
          337,
          37624,
          13,
          25530,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.3441168641390866,
        "compression_ratio": 1.4,
        "end": 142.44,
        "id": 36,
        "no_speech_prob": 0.00009027726628119126,
        "seek": 13256,
        "start": 132.56,
        "temperature": 0,
        "text": " This repo is built by Richiro Nakano.",
        "tokens": [
          50364,
          639,
          49040,
          307,
          3094,
          538,
          497,
          480,
          5182,
          25779,
          3730,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.3441168641390866,
        "compression_ratio": 1.4,
        "end": 145.36,
        "id": 37,
        "no_speech_prob": 0.00009027726628119126,
        "seek": 13256,
        "start": 142.44,
        "temperature": 0,
        "text": " His work is amazing.",
        "tokens": [
          50858,
          2812,
          589,
          307,
          2243,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.3441168641390866,
        "compression_ratio": 1.4,
        "end": 151.4,
        "id": 38,
        "no_speech_prob": 0.00009027726628119126,
        "seek": 13256,
        "start": 145.36,
        "temperature": 0,
        "text": " He recently contributed a new model called sketch RN to ml5.js",
        "tokens": [
          51004,
          634,
          3938,
          18434,
          257,
          777,
          2316,
          1219,
          12325,
          45702,
          281,
          23271,
          20,
          13,
          25530,
          51306
        ]
      },
      {
        "avg_logprob": -0.3441168641390866,
        "compression_ratio": 1.4,
        "end": 152.24,
        "id": 39,
        "no_speech_prob": 0.00009027726628119126,
        "seek": 13256,
        "start": 151.4,
        "temperature": 0,
        "text": " too.",
        "tokens": [
          51306,
          886,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.3441168641390866,
        "compression_ratio": 1.4,
        "end": 155.56,
        "id": 40,
        "no_speech_prob": 0.00009027726628119126,
        "seek": 13256,
        "start": 152.24,
        "temperature": 0,
        "text": " You guys should definitely check out his work.",
        "tokens": [
          51348,
          509,
          1074,
          820,
          2138,
          1520,
          484,
          702,
          589,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3441168641390866,
        "compression_ratio": 1.4,
        "end": 157.72,
        "id": 41,
        "no_speech_prob": 0.00009027726628119126,
        "seek": 13256,
        "start": 155.56,
        "temperature": 0,
        "text": " But we're going to use his script",
        "tokens": [
          51514,
          583,
          321,
          434,
          516,
          281,
          764,
          702,
          5755,
          51622
        ]
      },
      {
        "avg_logprob": -0.3441168641390866,
        "compression_ratio": 1.4,
        "end": 161.92000000000002,
        "id": 42,
        "no_speech_prob": 0.00009027726628119126,
        "seek": 13256,
        "start": 157.72,
        "temperature": 0,
        "text": " to convert the TensorFlow model into a model",
        "tokens": [
          51622,
          281,
          7620,
          264,
          37624,
          2316,
          666,
          257,
          2316,
          51832
        ]
      },
      {
        "avg_logprob": -0.33957058588663735,
        "compression_ratio": 1.5158730158730158,
        "end": 163.23999999999998,
        "id": 43,
        "no_speech_prob": 0.000012805383448721841,
        "seek": 16192,
        "start": 161.92,
        "temperature": 0,
        "text": " that we can use in ml5.js.",
        "tokens": [
          50364,
          300,
          321,
          393,
          764,
          294,
          23271,
          20,
          13,
          25530,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.33957058588663735,
        "compression_ratio": 1.5158730158730158,
        "end": 175.67999999999998,
        "id": 44,
        "no_speech_prob": 0.000012805383448721841,
        "seek": 16192,
        "start": 166.04,
        "temperature": 0,
        "text": " So the way that we're going to do it is to clone his GitHub",
        "tokens": [
          50570,
          407,
          264,
          636,
          300,
          321,
          434,
          516,
          281,
          360,
          309,
          307,
          281,
          26506,
          702,
          23331,
          51052
        ]
      },
      {
        "avg_logprob": -0.33957058588663735,
        "compression_ratio": 1.5158730158730158,
        "end": 176.16,
        "id": 45,
        "no_speech_prob": 0.000012805383448721841,
        "seek": 16192,
        "start": 175.67999999999998,
        "temperature": 0,
        "text": " repo.",
        "tokens": [
          51052,
          49040,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.33957058588663735,
        "compression_ratio": 1.5158730158730158,
        "end": 183.95999999999998,
        "id": 46,
        "no_speech_prob": 0.000012805383448721841,
        "seek": 16192,
        "start": 180.35999999999999,
        "temperature": 0,
        "text": " And then we're going inside to this GitHub repo.",
        "tokens": [
          51286,
          400,
          550,
          321,
          434,
          516,
          1854,
          281,
          341,
          23331,
          49040,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.33957058588663735,
        "compression_ratio": 1.5158730158730158,
        "end": 191.64,
        "id": 47,
        "no_speech_prob": 0.000012805383448721841,
        "seek": 16192,
        "start": 186.67999999999998,
        "temperature": 0,
        "text": " And we're going to put all those checkpoint files",
        "tokens": [
          51602,
          400,
          321,
          434,
          516,
          281,
          829,
          439,
          729,
          42269,
          7098,
          51850
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 197.32,
        "id": 48,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 191.67999999999998,
        "temperature": 0,
        "text": " that we got into one of the folders",
        "tokens": [
          50366,
          300,
          321,
          658,
          666,
          472,
          295,
          264,
          31082,
          50648
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 201.44,
        "id": 49,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 197.32,
        "temperature": 0,
        "text": " inside of this GitHub repo, which is.",
        "tokens": [
          50648,
          1854,
          295,
          341,
          23331,
          49040,
          11,
          597,
          307,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 205.92,
        "id": 50,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 201.44,
        "temperature": 0,
        "text": " So I'm just going to go to file style transfer deeplearn.js.",
        "tokens": [
          50854,
          407,
          286,
          478,
          445,
          516,
          281,
          352,
          281,
          3991,
          3758,
          5003,
          2452,
          306,
          1083,
          13,
          25530,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 209.56,
        "id": 51,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 205.92,
        "temperature": 0,
        "text": " Now just copy this folder to the root directory",
        "tokens": [
          51078,
          823,
          445,
          5055,
          341,
          10820,
          281,
          264,
          5593,
          21120,
          51260
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 212.2,
        "id": 52,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 209.56,
        "temperature": 0,
        "text": " of this GitHub repo.",
        "tokens": [
          51260,
          295,
          341,
          23331,
          49040,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 213.44,
        "id": 53,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 212.2,
        "temperature": 0,
        "text": " And I just did.",
        "tokens": [
          51392,
          400,
          286,
          445,
          630,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 214.72,
        "id": 54,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 213.44,
        "temperature": 0,
        "text": " It's here.",
        "tokens": [
          51454,
          467,
          311,
          510,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 218.79999999999998,
        "id": 55,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 214.72,
        "temperature": 0,
        "text": " And then we're going to run two Python scripts.",
        "tokens": [
          51518,
          400,
          550,
          321,
          434,
          516,
          281,
          1190,
          732,
          15329,
          23294,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.23938601778954574,
        "compression_ratio": 1.5735294117647058,
        "end": 221.48,
        "id": 56,
        "no_speech_prob": 0.000028409580409061164,
        "seek": 19164,
        "start": 218.79999999999998,
        "temperature": 0,
        "text": " The first thing is to dump the checkpoints",
        "tokens": [
          51722,
          440,
          700,
          551,
          307,
          281,
          11430,
          264,
          1520,
          20552,
          51856
        ]
      },
      {
        "avg_logprob": -0.3269628223619963,
        "compression_ratio": 1.4429530201342282,
        "end": 224.51999999999998,
        "id": 57,
        "no_speech_prob": 0.0000394416565541178,
        "seek": 22148,
        "start": 221.67999999999998,
        "temperature": 0,
        "text": " just to convert the format.",
        "tokens": [
          50374,
          445,
          281,
          7620,
          264,
          7877,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.3269628223619963,
        "compression_ratio": 1.4429530201342282,
        "end": 232.44,
        "id": 58,
        "no_speech_prob": 0.0000394416565541178,
        "seek": 22148,
        "start": 224.51999999999998,
        "temperature": 0,
        "text": " So what we're going to do is copy paste this command.",
        "tokens": [
          50516,
          407,
          437,
          321,
          434,
          516,
          281,
          360,
          307,
          5055,
          9163,
          341,
          5622,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.3269628223619963,
        "compression_ratio": 1.4429530201342282,
        "end": 236.48,
        "id": 59,
        "no_speech_prob": 0.0000394416565541178,
        "seek": 22148,
        "start": 232.44,
        "temperature": 0,
        "text": " Let's edit this in the code editor first.",
        "tokens": [
          50912,
          961,
          311,
          8129,
          341,
          294,
          264,
          3089,
          9839,
          700,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3269628223619963,
        "compression_ratio": 1.4429530201342282,
        "end": 239.83999999999997,
        "id": 60,
        "no_speech_prob": 0.0000394416565541178,
        "seek": 22148,
        "start": 236.48,
        "temperature": 0,
        "text": " Python script and run this script.",
        "tokens": [
          51114,
          15329,
          5755,
          293,
          1190,
          341,
          5755,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.3269628223619963,
        "compression_ratio": 1.4429530201342282,
        "end": 245.12,
        "id": 61,
        "no_speech_prob": 0.0000394416565541178,
        "seek": 22148,
        "start": 239.83999999999997,
        "temperature": 0,
        "text": " And then the output directory is source slash checkpoint",
        "tokens": [
          51282,
          400,
          550,
          264,
          5598,
          21120,
          307,
          4009,
          17330,
          42269,
          51546
        ]
      },
      {
        "avg_logprob": -0.30787330627441406,
        "compression_ratio": 1.346774193548387,
        "end": 251.96,
        "id": 62,
        "no_speech_prob": 0.006388218142092228,
        "seek": 24512,
        "start": 246,
        "temperature": 0,
        "text": " our folder name, which will be spell model.",
        "tokens": [
          50408,
          527,
          10820,
          1315,
          11,
          597,
          486,
          312,
          9827,
          2316,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.30787330627441406,
        "compression_ratio": 1.346774193548387,
        "end": 256.16,
        "id": 63,
        "no_speech_prob": 0.006388218142092228,
        "seek": 24512,
        "start": 251.96,
        "temperature": 0,
        "text": " And then the checkpoint file is in the root directory",
        "tokens": [
          50706,
          400,
          550,
          264,
          42269,
          3991,
          307,
          294,
          264,
          5593,
          21120,
          50916
        ]
      },
      {
        "avg_logprob": -0.30787330627441406,
        "compression_ratio": 1.346774193548387,
        "end": 257.76,
        "id": 64,
        "no_speech_prob": 0.006388218142092228,
        "seek": 24512,
        "start": 256.16,
        "temperature": 0,
        "text": " of the GitHub repo.",
        "tokens": [
          50916,
          295,
          264,
          23331,
          49040,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.30787330627441406,
        "compression_ratio": 1.346774193548387,
        "end": 269.4,
        "id": 65,
        "no_speech_prob": 0.006388218142092228,
        "seek": 24512,
        "start": 261.08,
        "temperature": 0,
        "text": " So it's dot slash spell model slash fns dot ckpt.",
        "tokens": [
          51162,
          407,
          309,
          311,
          5893,
          17330,
          9827,
          2316,
          17330,
          283,
          3695,
          5893,
          269,
          74,
          662,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.23264757792154947,
        "compression_ratio": 1.4573643410852712,
        "end": 275.44,
        "id": 66,
        "no_speech_prob": 0.000015689496649429202,
        "seek": 26940,
        "start": 269.44,
        "temperature": 0,
        "text": " This is the path to our model, which we saw before",
        "tokens": [
          50366,
          639,
          307,
          264,
          3100,
          281,
          527,
          2316,
          11,
          597,
          321,
          1866,
          949,
          50666
        ]
      },
      {
        "avg_logprob": -0.23264757792154947,
        "compression_ratio": 1.4573643410852712,
        "end": 279.32,
        "id": 67,
        "no_speech_prob": 0.000015689496649429202,
        "seek": 26940,
        "start": 275.44,
        "temperature": 0,
        "text": " in this checkpoint file.",
        "tokens": [
          50666,
          294,
          341,
          42269,
          3991,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.23264757792154947,
        "compression_ratio": 1.4573643410852712,
        "end": 283.12,
        "id": 68,
        "no_speech_prob": 0.000015689496649429202,
        "seek": 26940,
        "start": 279.32,
        "temperature": 0,
        "text": " This is the path to our checkpoint.",
        "tokens": [
          50860,
          639,
          307,
          264,
          3100,
          281,
          527,
          42269,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.23264757792154947,
        "compression_ratio": 1.4573643410852712,
        "end": 287.03999999999996,
        "id": 69,
        "no_speech_prob": 0.000015689496649429202,
        "seek": 26940,
        "start": 283.12,
        "temperature": 0,
        "text": " That's why we have this name here.",
        "tokens": [
          51050,
          663,
          311,
          983,
          321,
          362,
          341,
          1315,
          510,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.23264757792154947,
        "compression_ratio": 1.4573643410852712,
        "end": 289.76,
        "id": 70,
        "no_speech_prob": 0.000015689496649429202,
        "seek": 26940,
        "start": 287.03999999999996,
        "temperature": 0,
        "text": " So now I'm just going to run this script.",
        "tokens": [
          51246,
          407,
          586,
          286,
          478,
          445,
          516,
          281,
          1190,
          341,
          5755,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.6961422820589436,
        "compression_ratio": 1.6666666666666667,
        "end": 292.59999999999997,
        "id": 71,
        "no_speech_prob": 0.00006605201633647084,
        "seek": 28976,
        "start": 290.59999999999997,
        "temperature": 0,
        "text": " And then you can see it's done.",
        "tokens": [
          50406,
          400,
          550,
          291,
          393,
          536,
          309,
          311,
          1096,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.6961422820589436,
        "compression_ratio": 1.6666666666666667,
        "end": 297.76,
        "id": 72,
        "no_speech_prob": 0.00006605201633647084,
        "seek": 28976,
        "start": 292.59999999999997,
        "temperature": 0,
        "text": " So it actually created one checkpoint file",
        "tokens": [
          50506,
          407,
          309,
          767,
          2942,
          472,
          42269,
          3991,
          50764
        ]
      },
      {
        "avg_logprob": -0.6961422820589436,
        "compression_ratio": 1.6666666666666667,
        "end": 301.32,
        "id": 73,
        "no_speech_prob": 0.00006605201633647084,
        "seek": 28976,
        "start": 297.76,
        "temperature": 0,
        "text": " and 49 other files.",
        "tokens": [
          50764,
          293,
          16513,
          661,
          7098,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.6961422820589436,
        "compression_ratio": 1.6666666666666667,
        "end": 307.8,
        "id": 74,
        "no_speech_prob": 0.00006605201633647084,
        "seek": 28976,
        "start": 301.32,
        "temperature": 0,
        "text": " And we can go there to see what is the output.",
        "tokens": [
          50942,
          400,
          321,
          393,
          352,
          456,
          281,
          536,
          437,
          307,
          264,
          5598,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.6961422820589436,
        "compression_ratio": 1.6666666666666667,
        "end": 313.84,
        "id": 75,
        "no_speech_prob": 0.00006605201633647084,
        "seek": 28976,
        "start": 307.8,
        "temperature": 0,
        "text": " The output lives in source checkpoint.",
        "tokens": [
          51266,
          440,
          5598,
          2909,
          294,
          4009,
          42269,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.6961422820589436,
        "compression_ratio": 1.6666666666666667,
        "end": 319.64,
        "id": 76,
        "no_speech_prob": 0.00006605201633647084,
        "seek": 28976,
        "start": 313.84,
        "temperature": 0,
        "text": " And we can see that the output is in the source checkpoint.",
        "tokens": [
          51568,
          400,
          321,
          393,
          536,
          300,
          264,
          5598,
          307,
          294,
          264,
          4009,
          42269,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.3008413875804228,
        "compression_ratio": 1.455128205128205,
        "end": 323.76,
        "id": 77,
        "no_speech_prob": 0.00004331883246777579,
        "seek": 31964,
        "start": 320.32,
        "temperature": 0,
        "text": " And this is our model.",
        "tokens": [
          50398,
          400,
          341,
          307,
          527,
          2316,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.3008413875804228,
        "compression_ratio": 1.455128205128205,
        "end": 329.44,
        "id": 78,
        "no_speech_prob": 0.00004331883246777579,
        "seek": 31964,
        "start": 323.76,
        "temperature": 0,
        "text": " And you can see that we got the manifest JSON.",
        "tokens": [
          50570,
          400,
          291,
          393,
          536,
          300,
          321,
          658,
          264,
          10067,
          31828,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.3008413875804228,
        "compression_ratio": 1.455128205128205,
        "end": 332.36,
        "id": 79,
        "no_speech_prob": 0.00004331883246777579,
        "seek": 31964,
        "start": 329.44,
        "temperature": 0,
        "text": " This tells us the structure of the graph.",
        "tokens": [
          50854,
          639,
          5112,
          505,
          264,
          3877,
          295,
          264,
          4295,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.3008413875804228,
        "compression_ratio": 1.455128205128205,
        "end": 342.96,
        "id": 80,
        "no_speech_prob": 0.00004331883246777579,
        "seek": 31964,
        "start": 335.59999999999997,
        "temperature": 0,
        "text": " And also 49 files that tells us all those variables",
        "tokens": [
          51162,
          400,
          611,
          16513,
          7098,
          300,
          5112,
          505,
          439,
          729,
          9102,
          51530
        ]
      },
      {
        "avg_logprob": -0.3008413875804228,
        "compression_ratio": 1.455128205128205,
        "end": 344.91999999999996,
        "id": 81,
        "no_speech_prob": 0.00004331883246777579,
        "seek": 31964,
        "start": 342.96,
        "temperature": 0,
        "text": " in each layer.",
        "tokens": [
          51530,
          294,
          1184,
          4583,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.3008413875804228,
        "compression_ratio": 1.455128205128205,
        "end": 349.03999999999996,
        "id": 82,
        "no_speech_prob": 0.00004331883246777579,
        "seek": 31964,
        "start": 344.91999999999996,
        "temperature": 0,
        "text": " And this is the format that we can use in ml5.js",
        "tokens": [
          51628,
          400,
          341,
          307,
          264,
          7877,
          300,
          321,
          393,
          764,
          294,
          23271,
          20,
          13,
          25530,
          51834
        ]
      },
      {
        "avg_logprob": -0.29734873367568193,
        "compression_ratio": 1.4296296296296296,
        "end": 352,
        "id": 83,
        "no_speech_prob": 0.00009461236913921311,
        "seek": 34904,
        "start": 349.04,
        "temperature": 0,
        "text": " and TensorFlow.js.",
        "tokens": [
          50364,
          293,
          37624,
          13,
          25530,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.29734873367568193,
        "compression_ratio": 1.4296296296296296,
        "end": 361.52000000000004,
        "id": 84,
        "no_speech_prob": 0.00009461236913921311,
        "seek": 34904,
        "start": 352,
        "temperature": 0,
        "text": " So now I'm just going to copy this model back to my desktop.",
        "tokens": [
          50512,
          407,
          586,
          286,
          478,
          445,
          516,
          281,
          5055,
          341,
          2316,
          646,
          281,
          452,
          14502,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.29734873367568193,
        "compression_ratio": 1.4296296296296296,
        "end": 365.88,
        "id": 85,
        "no_speech_prob": 0.00009461236913921311,
        "seek": 34904,
        "start": 361.52000000000004,
        "temperature": 0,
        "text": " Going to rename it and drag it to my desktop.",
        "tokens": [
          50988,
          10963,
          281,
          36741,
          309,
          293,
          5286,
          309,
          281,
          452,
          14502,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.29734873367568193,
        "compression_ratio": 1.4296296296296296,
        "end": 373.40000000000003,
        "id": 86,
        "no_speech_prob": 0.00009461236913921311,
        "seek": 34904,
        "start": 365.88,
        "temperature": 0,
        "text": " So so far, we got two models.",
        "tokens": [
          51206,
          407,
          370,
          1400,
          11,
          321,
          658,
          732,
          5245,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.29734873367568193,
        "compression_ratio": 1.4296296296296296,
        "end": 376.84000000000003,
        "id": 87,
        "no_speech_prob": 0.00009461236913921311,
        "seek": 34904,
        "start": 373.40000000000003,
        "temperature": 0,
        "text": " We have a TensorFlow saved model that",
        "tokens": [
          51582,
          492,
          362,
          257,
          37624,
          6624,
          2316,
          300,
          51754
        ]
      },
      {
        "avg_logprob": -0.1759450823761696,
        "compression_ratio": 1.6071428571428572,
        "end": 379.67999999999995,
        "id": 88,
        "no_speech_prob": 0.00036258413456380367,
        "seek": 37684,
        "start": 376.84,
        "temperature": 0,
        "text": " can work in TensorFlow, of course.",
        "tokens": [
          50364,
          393,
          589,
          294,
          37624,
          11,
          295,
          1164,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.1759450823761696,
        "compression_ratio": 1.6071428571428572,
        "end": 381.59999999999997,
        "id": 89,
        "no_speech_prob": 0.00036258413456380367,
        "seek": 37684,
        "start": 379.67999999999995,
        "temperature": 0,
        "text": " And then we also got another model",
        "tokens": [
          50506,
          400,
          550,
          321,
          611,
          658,
          1071,
          2316,
          50602
        ]
      },
      {
        "avg_logprob": -0.1759450823761696,
        "compression_ratio": 1.6071428571428572,
        "end": 385.59999999999997,
        "id": 90,
        "no_speech_prob": 0.00036258413456380367,
        "seek": 37684,
        "start": 381.59999999999997,
        "temperature": 0,
        "text": " that can work in ml5.js and TensorFlow.js.",
        "tokens": [
          50602,
          300,
          393,
          589,
          294,
          23271,
          20,
          13,
          25530,
          293,
          37624,
          13,
          25530,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.1759450823761696,
        "compression_ratio": 1.6071428571428572,
        "end": 387.32,
        "id": 91,
        "no_speech_prob": 0.00036258413456380367,
        "seek": 37684,
        "start": 385.59999999999997,
        "temperature": 0,
        "text": " So this is what we got today.",
        "tokens": [
          50802,
          407,
          341,
          307,
          437,
          321,
          658,
          965,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.1759450823761696,
        "compression_ratio": 1.6071428571428572,
        "end": 395.96,
        "id": 92,
        "no_speech_prob": 0.00036258413456380367,
        "seek": 37684,
        "start": 390.47999999999996,
        "temperature": 0,
        "text": " And the next step is to run this model in ml5.js.",
        "tokens": [
          51046,
          400,
          264,
          958,
          1823,
          307,
          281,
          1190,
          341,
          2316,
          294,
          23271,
          20,
          13,
          25530,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.1759450823761696,
        "compression_ratio": 1.6071428571428572,
        "end": 400.96,
        "id": 93,
        "no_speech_prob": 0.00036258413456380367,
        "seek": 37684,
        "start": 395.96,
        "temperature": 0,
        "text": " Here are two demos on ml5's website.",
        "tokens": [
          51320,
          1692,
          366,
          732,
          33788,
          322,
          23271,
          20,
          311,
          3144,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.1759450823761696,
        "compression_ratio": 1.6071428571428572,
        "end": 406.79999999999995,
        "id": 94,
        "no_speech_prob": 0.00036258413456380367,
        "seek": 37684,
        "start": 400.96,
        "temperature": 0,
        "text": " And we also have this demo here that you",
        "tokens": [
          51570,
          400,
          321,
          611,
          362,
          341,
          10723,
          510,
          300,
          291,
          51862
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 409.96000000000004,
        "id": 95,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 407.76,
        "temperature": 0,
        "text": " can select different styles.",
        "tokens": [
          50412,
          393,
          3048,
          819,
          13273,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 413.56,
        "id": 96,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 409.96000000000004,
        "temperature": 0,
        "text": " You can upload the image.",
        "tokens": [
          50522,
          509,
          393,
          6580,
          264,
          3256,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 415.96000000000004,
        "id": 97,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 413.56,
        "temperature": 0,
        "text": " You can change your style here.",
        "tokens": [
          50702,
          509,
          393,
          1319,
          428,
          3758,
          510,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 418.2,
        "id": 98,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 415.96000000000004,
        "temperature": 0,
        "text": " And you can upload the image.",
        "tokens": [
          50822,
          400,
          291,
          393,
          6580,
          264,
          3256,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 425.92,
        "id": 99,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 418.2,
        "temperature": 0,
        "text": " I'm going to upload a photo, a photo of a cat.",
        "tokens": [
          50934,
          286,
          478,
          516,
          281,
          6580,
          257,
          5052,
          11,
          257,
          5052,
          295,
          257,
          3857,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 428.88,
        "id": 100,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 425.92,
        "temperature": 0,
        "text": " And then click this Transfer My Image.",
        "tokens": [
          51320,
          400,
          550,
          2052,
          341,
          35025,
          1222,
          29903,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 432.04,
        "id": 101,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 428.88,
        "temperature": 0,
        "text": " This is the transferred cat.",
        "tokens": [
          51468,
          639,
          307,
          264,
          15809,
          3857,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.26957046694871856,
        "compression_ratio": 1.7177914110429449,
        "end": 435.88,
        "id": 102,
        "no_speech_prob": 0.000034807922929758206,
        "seek": 40680,
        "start": 432.04,
        "temperature": 0,
        "text": " You can also play it with different styles, too.",
        "tokens": [
          51626,
          509,
          393,
          611,
          862,
          309,
          365,
          819,
          13273,
          11,
          886,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.2992437081258805,
        "compression_ratio": 1.481203007518797,
        "end": 437.04,
        "id": 103,
        "no_speech_prob": 0.000015206575881165918,
        "seek": 43588,
        "start": 435.92,
        "temperature": 0,
        "text": " Oh, I do like this one.",
        "tokens": [
          50366,
          876,
          11,
          286,
          360,
          411,
          341,
          472,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.2992437081258805,
        "compression_ratio": 1.481203007518797,
        "end": 442.71999999999997,
        "id": 104,
        "no_speech_prob": 0.000015206575881165918,
        "seek": 43588,
        "start": 440.04,
        "temperature": 0,
        "text": " And also, you can use webcam.",
        "tokens": [
          50572,
          400,
          611,
          11,
          291,
          393,
          764,
          39490,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.2992437081258805,
        "compression_ratio": 1.481203007518797,
        "end": 449.24,
        "id": 105,
        "no_speech_prob": 0.000015206575881165918,
        "seek": 43588,
        "start": 445.71999999999997,
        "temperature": 0,
        "text": " And then click this button.",
        "tokens": [
          50856,
          400,
          550,
          2052,
          341,
          2960,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2992437081258805,
        "compression_ratio": 1.481203007518797,
        "end": 458.4,
        "id": 106,
        "no_speech_prob": 0.000015206575881165918,
        "seek": 43588,
        "start": 449.24,
        "temperature": 0,
        "text": " And you can see the transferred version of the images",
        "tokens": [
          51032,
          400,
          291,
          393,
          536,
          264,
          15809,
          3037,
          295,
          264,
          5267,
          51490
        ]
      },
      {
        "avg_logprob": -0.2992437081258805,
        "compression_ratio": 1.481203007518797,
        "end": 460.4,
        "id": 107,
        "no_speech_prob": 0.000015206575881165918,
        "seek": 43588,
        "start": 458.4,
        "temperature": 0,
        "text": " from the webcam.",
        "tokens": [
          51490,
          490,
          264,
          39490,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.2992437081258805,
        "compression_ratio": 1.481203007518797,
        "end": 463.84,
        "id": 108,
        "no_speech_prob": 0.000015206575881165918,
        "seek": 43588,
        "start": 460.4,
        "temperature": 0,
        "text": " So you can go there and check this demo out.",
        "tokens": [
          51590,
          407,
          291,
          393,
          352,
          456,
          293,
          1520,
          341,
          10723,
          484,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.3162662506103516,
        "compression_ratio": 1.035294117647059,
        "end": 476.47999999999996,
        "id": 109,
        "no_speech_prob": 0.000015206738680717535,
        "seek": 46384,
        "start": 463.84,
        "temperature": 0,
        "text": " But next, we're just going to run this model in our ml5 demo.",
        "tokens": [
          50364,
          583,
          958,
          11,
          321,
          434,
          445,
          516,
          281,
          1190,
          341,
          2316,
          294,
          527,
          23271,
          20,
          10723,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.3162662506103516,
        "compression_ratio": 1.035294117647059,
        "end": 486.03999999999996,
        "id": 110,
        "no_speech_prob": 0.000015206738680717535,
        "seek": 46384,
        "start": 479.32,
        "temperature": 0,
        "text": " So we can do this quickly.",
        "tokens": [
          51138,
          407,
          321,
          393,
          360,
          341,
          2661,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.6141076405843099,
        "compression_ratio": 1.5179856115107915,
        "end": 490.36,
        "id": 111,
        "no_speech_prob": 0.00015597885067109019,
        "seek": 48604,
        "start": 487.04,
        "temperature": 0,
        "text": " Here, we're just going to clone this GitHub repo.",
        "tokens": [
          50414,
          1692,
          11,
          321,
          434,
          445,
          516,
          281,
          26506,
          341,
          23331,
          49040,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.6141076405843099,
        "compression_ratio": 1.5179856115107915,
        "end": 500.16,
        "id": 112,
        "no_speech_prob": 0.00015597885067109019,
        "seek": 48604,
        "start": 494.36,
        "temperature": 0,
        "text": " And then go inside to that folder, styleTransfer underscore",
        "tokens": [
          50780,
          400,
          550,
          352,
          1854,
          281,
          300,
          10820,
          11,
          3758,
          33339,
          612,
          37556,
          51070
        ]
      },
      {
        "avg_logprob": -0.6141076405843099,
        "compression_ratio": 1.5179856115107915,
        "end": 502.12,
        "id": 113,
        "no_speech_prob": 0.00015597885067109019,
        "seek": 48604,
        "start": 500.16,
        "temperature": 0,
        "text": " spell.",
        "tokens": [
          51070,
          9827,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.6141076405843099,
        "compression_ratio": 1.5179856115107915,
        "end": 507.12,
        "id": 114,
        "no_speech_prob": 0.00015597885067109019,
        "seek": 48604,
        "start": 502.12,
        "temperature": 0,
        "text": " And we're going to open this folder in your code editor.",
        "tokens": [
          51168,
          400,
          321,
          434,
          516,
          281,
          1269,
          341,
          10820,
          294,
          428,
          3089,
          9839,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.6141076405843099,
        "compression_ratio": 1.5179856115107915,
        "end": 512.76,
        "id": 115,
        "no_speech_prob": 0.00015597885067109019,
        "seek": 48604,
        "start": 507.12,
        "temperature": 0,
        "text": " And in its models folder, we're going",
        "tokens": [
          51418,
          400,
          294,
          1080,
          5245,
          10820,
          11,
          321,
          434,
          516,
          51700
        ]
      },
      {
        "avg_logprob": -0.32275792385669466,
        "compression_ratio": 1.3620689655172413,
        "end": 525.24,
        "id": 116,
        "no_speech_prob": 0.0003920382878277451,
        "seek": 51276,
        "start": 512.76,
        "temperature": 0,
        "text": " to add our new models inside of this folder.",
        "tokens": [
          50364,
          281,
          909,
          527,
          777,
          5245,
          1854,
          295,
          341,
          10820,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.32275792385669466,
        "compression_ratio": 1.3620689655172413,
        "end": 533.28,
        "id": 117,
        "no_speech_prob": 0.0003920382878277451,
        "seek": 51276,
        "start": 525.24,
        "temperature": 0,
        "text": " So what I'm going to do is to find that GitHub repo.",
        "tokens": [
          50988,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          281,
          915,
          300,
          23331,
          49040,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.32275792385669466,
        "compression_ratio": 1.3620689655172413,
        "end": 540.16,
        "id": 118,
        "no_speech_prob": 0.0003920382878277451,
        "seek": 51276,
        "start": 533.28,
        "temperature": 0,
        "text": " And inside of models, I'm going to copy paste this model in.",
        "tokens": [
          51390,
          400,
          1854,
          295,
          5245,
          11,
          286,
          478,
          516,
          281,
          5055,
          9163,
          341,
          2316,
          294,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.26400017738342285,
        "compression_ratio": 1.3642384105960266,
        "end": 547.3199999999999,
        "id": 119,
        "no_speech_prob": 0.000013419818969850894,
        "seek": 54016,
        "start": 540.16,
        "temperature": 0,
        "text": " I'm just going to rename it to Lotus, because the name of the art",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          36741,
          309,
          281,
          44769,
          11,
          570,
          264,
          1315,
          295,
          264,
          1523,
          50722
        ]
      },
      {
        "avg_logprob": -0.26400017738342285,
        "compression_ratio": 1.3642384105960266,
        "end": 548.04,
        "id": 120,
        "no_speech_prob": 0.000013419818969850894,
        "seek": 54016,
        "start": 547.3199999999999,
        "temperature": 0,
        "text": " is called Lotus.",
        "tokens": [
          50722,
          307,
          1219,
          44769,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.26400017738342285,
        "compression_ratio": 1.3642384105960266,
        "end": 555.28,
        "id": 121,
        "no_speech_prob": 0.000013419818969850894,
        "seek": 54016,
        "start": 552.1999999999999,
        "temperature": 0,
        "text": " So now we go back to our code editor.",
        "tokens": [
          50966,
          407,
          586,
          321,
          352,
          646,
          281,
          527,
          3089,
          9839,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.26400017738342285,
        "compression_ratio": 1.3642384105960266,
        "end": 557.9599999999999,
        "id": 122,
        "no_speech_prob": 0.000013419818969850894,
        "seek": 54016,
        "start": 555.28,
        "temperature": 0,
        "text": " We have a new model here.",
        "tokens": [
          51120,
          492,
          362,
          257,
          777,
          2316,
          510,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.26400017738342285,
        "compression_ratio": 1.3642384105960266,
        "end": 564.6,
        "id": 123,
        "no_speech_prob": 0.000013419818969850894,
        "seek": 54016,
        "start": 557.9599999999999,
        "temperature": 0,
        "text": " And we can take a look at what is inside of the index HTML.",
        "tokens": [
          51254,
          400,
          321,
          393,
          747,
          257,
          574,
          412,
          437,
          307,
          1854,
          295,
          264,
          8186,
          17995,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 572.2,
        "id": 124,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 564.6,
        "temperature": 0,
        "text": " So to build this demo, we need p5.js, mainly",
        "tokens": [
          50364,
          407,
          281,
          1322,
          341,
          10723,
          11,
          321,
          643,
          280,
          20,
          13,
          25530,
          11,
          8704,
          50744
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 575.12,
        "id": 125,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 572.2,
        "temperature": 0,
        "text": " to get the video from the webcam.",
        "tokens": [
          50744,
          281,
          483,
          264,
          960,
          490,
          264,
          39490,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 579.76,
        "id": 126,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 575.12,
        "temperature": 0,
        "text": " And also, we need p5 DOM library to make it easier",
        "tokens": [
          50890,
          400,
          611,
          11,
          321,
          643,
          280,
          20,
          35727,
          6405,
          281,
          652,
          309,
          3571,
          51122
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 582.5600000000001,
        "id": 127,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 579.76,
        "temperature": 0,
        "text": " to create DOM elements for us.",
        "tokens": [
          51122,
          281,
          1884,
          35727,
          4959,
          337,
          505,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 587.52,
        "id": 128,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 582.5600000000001,
        "temperature": 0,
        "text": " And then in the end, we need the ml5 library.",
        "tokens": [
          51262,
          400,
          550,
          294,
          264,
          917,
          11,
          321,
          643,
          264,
          23271,
          20,
          6405,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 589.48,
        "id": 129,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 587.52,
        "temperature": 0,
        "text": " And we have some styles here.",
        "tokens": [
          51510,
          400,
          321,
          362,
          512,
          13273,
          510,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 591.72,
        "id": 130,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 589.48,
        "temperature": 0,
        "text": " We can ignore them for now.",
        "tokens": [
          51608,
          492,
          393,
          11200,
          552,
          337,
          586,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.23265136640096448,
        "compression_ratio": 1.556701030927835,
        "end": 594.52,
        "id": 131,
        "no_speech_prob": 0.00037995344609953463,
        "seek": 56460,
        "start": 591.72,
        "temperature": 0,
        "text": " And we're also running the Sketch.js.",
        "tokens": [
          51720,
          400,
          321,
          434,
          611,
          2614,
          264,
          49245,
          13,
          25530,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.2547902922699417,
        "compression_ratio": 1.5244755244755244,
        "end": 596.1999999999999,
        "id": 132,
        "no_speech_prob": 0.00007031011045910418,
        "seek": 59452,
        "start": 594.52,
        "temperature": 0,
        "text": " Script here.",
        "tokens": [
          50364,
          15675,
          510,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.2547902922699417,
        "compression_ratio": 1.5244755244755244,
        "end": 600.56,
        "id": 133,
        "no_speech_prob": 0.00007031011045910418,
        "seek": 59452,
        "start": 596.1999999999999,
        "temperature": 0,
        "text": " And in the body, we have header tag.",
        "tokens": [
          50448,
          400,
          294,
          264,
          1772,
          11,
          321,
          362,
          23117,
          6162,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2547902922699417,
        "compression_ratio": 1.5244755244755244,
        "end": 604.1999999999999,
        "id": 134,
        "no_speech_prob": 0.00007031011045910418,
        "seek": 59452,
        "start": 600.56,
        "temperature": 0,
        "text": " We have p tag.",
        "tokens": [
          50666,
          492,
          362,
          280,
          6162,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2547902922699417,
        "compression_ratio": 1.5244755244755244,
        "end": 612.28,
        "id": 135,
        "no_speech_prob": 0.00007031011045910418,
        "seek": 59452,
        "start": 604.1999999999999,
        "temperature": 0,
        "text": " And we are linking the source of the image, the art style image.",
        "tokens": [
          50848,
          400,
          321,
          366,
          25775,
          264,
          4009,
          295,
          264,
          3256,
          11,
          264,
          1523,
          3758,
          3256,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.2547902922699417,
        "compression_ratio": 1.5244755244755244,
        "end": 617.16,
        "id": 136,
        "no_speech_prob": 0.00007031011045910418,
        "seek": 59452,
        "start": 612.28,
        "temperature": 0,
        "text": " And also, we are showing the art image.",
        "tokens": [
          51252,
          400,
          611,
          11,
          321,
          366,
          4099,
          264,
          1523,
          3256,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2547902922699417,
        "compression_ratio": 1.5244755244755244,
        "end": 621.8,
        "id": 137,
        "no_speech_prob": 0.00007031011045910418,
        "seek": 59452,
        "start": 617.16,
        "temperature": 0,
        "text": " But I'm going to change this to the Lotus image.",
        "tokens": [
          51496,
          583,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          264,
          44769,
          3256,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.3026916640145438,
        "compression_ratio": 1.5549132947976878,
        "end": 623.3599999999999,
        "id": 138,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 62180,
        "start": 621.8,
        "temperature": 0,
        "text": " This is a pre-trained model.",
        "tokens": [
          50364,
          639,
          307,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.3026916640145438,
        "compression_ratio": 1.5549132947976878,
        "end": 631.28,
        "id": 139,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 62180,
        "start": 626.56,
        "temperature": 0,
        "text": " I'm going to add this image into this image folder.",
        "tokens": [
          50602,
          286,
          478,
          516,
          281,
          909,
          341,
          3256,
          666,
          341,
          3256,
          10820,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.3026916640145438,
        "compression_ratio": 1.5549132947976878,
        "end": 639.16,
        "id": 140,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 62180,
        "start": 634.9599999999999,
        "temperature": 0,
        "text": " So here, we can say images slash Lotus.",
        "tokens": [
          51022,
          407,
          510,
          11,
          321,
          393,
          584,
          5267,
          17330,
          44769,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.3026916640145438,
        "compression_ratio": 1.5549132947976878,
        "end": 640.68,
        "id": 141,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 62180,
        "start": 639.16,
        "temperature": 0,
        "text": " So we are going to show that image.",
        "tokens": [
          51232,
          407,
          321,
          366,
          516,
          281,
          855,
          300,
          3256,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.3026916640145438,
        "compression_ratio": 1.5549132947976878,
        "end": 643.76,
        "id": 142,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 62180,
        "start": 640.68,
        "temperature": 0,
        "text": " And in the end, we have a div container",
        "tokens": [
          51308,
          400,
          294,
          264,
          917,
          11,
          321,
          362,
          257,
          3414,
          10129,
          51462
        ]
      },
      {
        "avg_logprob": -0.3026916640145438,
        "compression_ratio": 1.5549132947976878,
        "end": 646.88,
        "id": 143,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 62180,
        "start": 643.76,
        "temperature": 0,
        "text": " to contain our canvas.",
        "tokens": [
          51462,
          281,
          5304,
          527,
          16267,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.3026916640145438,
        "compression_ratio": 1.5549132947976878,
        "end": 651.04,
        "id": 144,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 62180,
        "start": 646.88,
        "temperature": 0,
        "text": " And now we can go to, let's save this index HTML.",
        "tokens": [
          51618,
          400,
          586,
          321,
          393,
          352,
          281,
          11,
          718,
          311,
          3155,
          341,
          8186,
          17995,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.23264580803948479,
        "compression_ratio": 1.5030674846625767,
        "end": 655.24,
        "id": 145,
        "no_speech_prob": 0.000020145236703683622,
        "seek": 65180,
        "start": 652.3199999999999,
        "temperature": 0,
        "text": " And then we can go to Sketch.js.",
        "tokens": [
          50390,
          400,
          550,
          321,
          393,
          352,
          281,
          49245,
          13,
          25530,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.23264580803948479,
        "compression_ratio": 1.5030674846625767,
        "end": 657.68,
        "id": 146,
        "no_speech_prob": 0.000020145236703683622,
        "seek": 65180,
        "start": 655.24,
        "temperature": 0,
        "text": " I'm just going to delete all the code here",
        "tokens": [
          50536,
          286,
          478,
          445,
          516,
          281,
          12097,
          439,
          264,
          3089,
          510,
          50658
        ]
      },
      {
        "avg_logprob": -0.23264580803948479,
        "compression_ratio": 1.5030674846625767,
        "end": 661.4799999999999,
        "id": 147,
        "no_speech_prob": 0.000020145236703683622,
        "seek": 65180,
        "start": 657.68,
        "temperature": 0,
        "text": " so we can do it ourselves one more time together.",
        "tokens": [
          50658,
          370,
          321,
          393,
          360,
          309,
          4175,
          472,
          544,
          565,
          1214,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.23264580803948479,
        "compression_ratio": 1.5030674846625767,
        "end": 668.64,
        "id": 148,
        "no_speech_prob": 0.000020145236703683622,
        "seek": 65180,
        "start": 664.56,
        "temperature": 0,
        "text": " So to build this demo, we need three things.",
        "tokens": [
          51002,
          407,
          281,
          1322,
          341,
          10723,
          11,
          321,
          643,
          1045,
          721,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.23264580803948479,
        "compression_ratio": 1.5030674846625767,
        "end": 675.7199999999999,
        "id": 149,
        "no_speech_prob": 0.000020145236703683622,
        "seek": 65180,
        "start": 668.64,
        "temperature": 0,
        "text": " We need a video that can get the images from our webcam.",
        "tokens": [
          51206,
          492,
          643,
          257,
          960,
          300,
          393,
          483,
          264,
          5267,
          490,
          527,
          39490,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.23264580803948479,
        "compression_ratio": 1.5030674846625767,
        "end": 677.8,
        "id": 150,
        "no_speech_prob": 0.000020145236703683622,
        "seek": 65180,
        "start": 675.7199999999999,
        "temperature": 0,
        "text": " So we have video.",
        "tokens": [
          51560,
          407,
          321,
          362,
          960,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25494558811187745,
        "compression_ratio": 1.5454545454545454,
        "end": 683.28,
        "id": 151,
        "no_speech_prob": 0.000012411382158461493,
        "seek": 67780,
        "start": 677.8,
        "temperature": 0,
        "text": " We also need the style transfer from ML5 library",
        "tokens": [
          50364,
          492,
          611,
          643,
          264,
          3758,
          5003,
          490,
          21601,
          20,
          6405,
          50638
        ]
      },
      {
        "avg_logprob": -0.25494558811187745,
        "compression_ratio": 1.5454545454545454,
        "end": 686.0799999999999,
        "id": 152,
        "no_speech_prob": 0.000012411382158461493,
        "seek": 67780,
        "start": 683.28,
        "temperature": 0,
        "text": " to allow us to transfer images.",
        "tokens": [
          50638,
          281,
          2089,
          505,
          281,
          5003,
          5267,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.25494558811187745,
        "compression_ratio": 1.5454545454545454,
        "end": 690.88,
        "id": 153,
        "no_speech_prob": 0.000012411382158461493,
        "seek": 67780,
        "start": 686.0799999999999,
        "temperature": 0,
        "text": " So I'm going to have another variable called style.",
        "tokens": [
          50778,
          407,
          286,
          478,
          516,
          281,
          362,
          1071,
          7006,
          1219,
          3758,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.25494558811187745,
        "compression_ratio": 1.5454545454545454,
        "end": 692.68,
        "id": 154,
        "no_speech_prob": 0.000012411382158461493,
        "seek": 67780,
        "start": 690.88,
        "temperature": 0,
        "text": " And in the end, we need a variable",
        "tokens": [
          51018,
          400,
          294,
          264,
          917,
          11,
          321,
          643,
          257,
          7006,
          51108
        ]
      },
      {
        "avg_logprob": -0.25494558811187745,
        "compression_ratio": 1.5454545454545454,
        "end": 694.9599999999999,
        "id": 155,
        "no_speech_prob": 0.000012411382158461493,
        "seek": 67780,
        "start": 692.68,
        "temperature": 0,
        "text": " to hold our output image.",
        "tokens": [
          51108,
          281,
          1797,
          527,
          5598,
          3256,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.25494558811187745,
        "compression_ratio": 1.5454545454545454,
        "end": 702.4399999999999,
        "id": 156,
        "no_speech_prob": 0.000012411382158461493,
        "seek": 67780,
        "start": 694.9599999999999,
        "temperature": 0,
        "text": " So we're going to do let result IMG.",
        "tokens": [
          51222,
          407,
          321,
          434,
          516,
          281,
          360,
          718,
          1874,
          21463,
          38,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.25494558811187745,
        "compression_ratio": 1.5454545454545454,
        "end": 704.4399999999999,
        "id": 157,
        "no_speech_prob": 0.000012411382158461493,
        "seek": 67780,
        "start": 702.4399999999999,
        "temperature": 0,
        "text": " So this is the three things that we need.",
        "tokens": [
          51596,
          407,
          341,
          307,
          264,
          1045,
          721,
          300,
          321,
          643,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.2779193088926118,
        "compression_ratio": 1.3525179856115108,
        "end": 711,
        "id": 158,
        "no_speech_prob": 0.000016187499568331987,
        "seek": 70444,
        "start": 705,
        "temperature": 0,
        "text": " And in p5, there is a setup function.",
        "tokens": [
          50392,
          400,
          294,
          280,
          20,
          11,
          456,
          307,
          257,
          8657,
          2445,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2779193088926118,
        "compression_ratio": 1.3525179856115108,
        "end": 714.12,
        "id": 159,
        "no_speech_prob": 0.000016187499568331987,
        "seek": 70444,
        "start": 711,
        "temperature": 0,
        "text": " That will be called once at the beginning.",
        "tokens": [
          50692,
          663,
          486,
          312,
          1219,
          1564,
          412,
          264,
          2863,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2779193088926118,
        "compression_ratio": 1.3525179856115108,
        "end": 718.6400000000001,
        "id": 160,
        "no_speech_prob": 0.000016187499568331987,
        "seek": 70444,
        "start": 714.12,
        "temperature": 0,
        "text": " So in this setup function, we're going to use p5.js",
        "tokens": [
          50848,
          407,
          294,
          341,
          8657,
          2445,
          11,
          321,
          434,
          516,
          281,
          764,
          280,
          20,
          13,
          25530,
          51074
        ]
      },
      {
        "avg_logprob": -0.2779193088926118,
        "compression_ratio": 1.3525179856115108,
        "end": 733.6400000000001,
        "id": 161,
        "no_speech_prob": 0.000016187499568331987,
        "seek": 70444,
        "start": 718.6400000000001,
        "temperature": 0,
        "text": " to create a canvas that is 320 wide and 250 its height.",
        "tokens": [
          51074,
          281,
          1884,
          257,
          16267,
          300,
          307,
          42429,
          4874,
          293,
          11650,
          1080,
          6681,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.28002214431762695,
        "compression_ratio": 1.536144578313253,
        "end": 737.84,
        "id": 162,
        "no_speech_prob": 0.000012218585652590264,
        "seek": 73364,
        "start": 733.68,
        "temperature": 0,
        "text": " And then we're going to use this p5 DOM library",
        "tokens": [
          50366,
          400,
          550,
          321,
          434,
          516,
          281,
          764,
          341,
          280,
          20,
          35727,
          6405,
          50574
        ]
      },
      {
        "avg_logprob": -0.28002214431762695,
        "compression_ratio": 1.536144578313253,
        "end": 743.1999999999999,
        "id": 163,
        "no_speech_prob": 0.000012218585652590264,
        "seek": 73364,
        "start": 737.84,
        "temperature": 0,
        "text": " to put this canvas element inside of a div element",
        "tokens": [
          50574,
          281,
          829,
          341,
          16267,
          4478,
          1854,
          295,
          257,
          3414,
          4478,
          50842
        ]
      },
      {
        "avg_logprob": -0.28002214431762695,
        "compression_ratio": 1.536144578313253,
        "end": 749.16,
        "id": 164,
        "no_speech_prob": 0.000012218585652590264,
        "seek": 73364,
        "start": 743.1999999999999,
        "temperature": 0,
        "text": " whose ID is canvas container.",
        "tokens": [
          50842,
          6104,
          7348,
          307,
          16267,
          10129,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.28002214431762695,
        "compression_ratio": 1.536144578313253,
        "end": 752.12,
        "id": 165,
        "no_speech_prob": 0.000012218585652590264,
        "seek": 73364,
        "start": 749.16,
        "temperature": 0,
        "text": " OK, so we create a canvas.",
        "tokens": [
          51140,
          2264,
          11,
          370,
          321,
          1884,
          257,
          16267,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.28002214431762695,
        "compression_ratio": 1.536144578313253,
        "end": 753,
        "id": 166,
        "no_speech_prob": 0.000012218585652590264,
        "seek": 73364,
        "start": 752.12,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          51288,
          663,
          311,
          309,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.28002214431762695,
        "compression_ratio": 1.536144578313253,
        "end": 756.16,
        "id": 167,
        "no_speech_prob": 0.000012218585652590264,
        "seek": 73364,
        "start": 753,
        "temperature": 0,
        "text": " And then we're going to create the video.",
        "tokens": [
          51332,
          400,
          550,
          321,
          434,
          516,
          281,
          1884,
          264,
          960,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.28002214431762695,
        "compression_ratio": 1.536144578313253,
        "end": 760.72,
        "id": 168,
        "no_speech_prob": 0.000012218585652590264,
        "seek": 73364,
        "start": 756.16,
        "temperature": 0,
        "text": " So p5 has this function called create capture.",
        "tokens": [
          51490,
          407,
          280,
          20,
          575,
          341,
          2445,
          1219,
          1884,
          7983,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.43106852351008235,
        "compression_ratio": 1.6209150326797386,
        "end": 765.2,
        "id": 169,
        "no_speech_prob": 0.00002178248905693181,
        "seek": 76072,
        "start": 761.36,
        "temperature": 0,
        "text": " And if we pass the uppercase video in,",
        "tokens": [
          50396,
          400,
          498,
          321,
          1320,
          264,
          11775,
          2869,
          651,
          960,
          294,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.43106852351008235,
        "compression_ratio": 1.6209150326797386,
        "end": 768.1600000000001,
        "id": 170,
        "no_speech_prob": 0.00002178248905693181,
        "seek": 76072,
        "start": 765.2,
        "temperature": 0,
        "text": " it will try to get the video from your webcam.",
        "tokens": [
          50588,
          309,
          486,
          853,
          281,
          483,
          264,
          960,
          490,
          428,
          39490,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.43106852351008235,
        "compression_ratio": 1.6209150326797386,
        "end": 770.64,
        "id": 171,
        "no_speech_prob": 0.00002178248905693181,
        "seek": 76072,
        "start": 768.1600000000001,
        "temperature": 0,
        "text": " And we're also going to say video.height,",
        "tokens": [
          50736,
          400,
          321,
          434,
          611,
          516,
          281,
          584,
          960,
          13,
          675,
          397,
          11,
          50860
        ]
      },
      {
        "avg_logprob": -0.43106852351008235,
        "compression_ratio": 1.6209150326797386,
        "end": 773.0400000000001,
        "id": 172,
        "no_speech_prob": 0.00002178248905693181,
        "seek": 76072,
        "start": 770.64,
        "temperature": 0,
        "text": " because we don't really need the original video.",
        "tokens": [
          50860,
          570,
          321,
          500,
          380,
          534,
          643,
          264,
          3380,
          960,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.43106852351008235,
        "compression_ratio": 1.6209150326797386,
        "end": 776.28,
        "id": 173,
        "no_speech_prob": 0.00002178248905693181,
        "seek": 76072,
        "start": 773.0400000000001,
        "temperature": 0,
        "text": " We need the transferred video.",
        "tokens": [
          50980,
          492,
          643,
          264,
          15809,
          960,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.43106852351008235,
        "compression_ratio": 1.6209150326797386,
        "end": 780.72,
        "id": 174,
        "no_speech_prob": 0.00002178248905693181,
        "seek": 76072,
        "start": 776.28,
        "temperature": 0,
        "text": " So we're also going to say video height.",
        "tokens": [
          51142,
          407,
          321,
          434,
          611,
          516,
          281,
          584,
          960,
          6681,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.7249639238630022,
        "compression_ratio": 1.5033557046979866,
        "end": 786.72,
        "id": 175,
        "no_speech_prob": 0.0005792768788523972,
        "seek": 78072,
        "start": 781.32,
        "temperature": 0,
        "text": " And we're also going to create the result image.",
        "tokens": [
          50394,
          400,
          321,
          434,
          611,
          516,
          281,
          1884,
          264,
          1874,
          3256,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.7249639238630022,
        "compression_ratio": 1.5033557046979866,
        "end": 790.72,
        "id": 176,
        "no_speech_prob": 0.0005792768788523972,
        "seek": 78072,
        "start": 786.72,
        "temperature": 0,
        "text": " p5 DOM library has this.",
        "tokens": [
          50664,
          280,
          20,
          35727,
          6405,
          575,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.7249639238630022,
        "compression_ratio": 1.5033557046979866,
        "end": 794.72,
        "id": 177,
        "no_speech_prob": 0.0005792768788523972,
        "seek": 78072,
        "start": 790.72,
        "temperature": 0,
        "text": " I just want to make it a little bit better.",
        "tokens": [
          50864,
          286,
          445,
          528,
          281,
          652,
          309,
          257,
          707,
          857,
          1101,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.7249639238630022,
        "compression_ratio": 1.5033557046979866,
        "end": 801.72,
        "id": 178,
        "no_speech_prob": 0.0005792768788523972,
        "seek": 78072,
        "start": 797.72,
        "temperature": 0,
        "text": " We're going to create this result image.",
        "tokens": [
          51214,
          492,
          434,
          516,
          281,
          1884,
          341,
          1874,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.7249639238630022,
        "compression_ratio": 1.5033557046979866,
        "end": 804.72,
        "id": 179,
        "no_speech_prob": 0.0005792768788523972,
        "seek": 78072,
        "start": 801.72,
        "temperature": 0,
        "text": " You could start with this.",
        "tokens": [
          51414,
          509,
          727,
          722,
          365,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.7249639238630022,
        "compression_ratio": 1.5033557046979866,
        "end": 806.72,
        "id": 180,
        "no_speech_prob": 0.0005792768788523972,
        "seek": 78072,
        "start": 804.72,
        "temperature": 0,
        "text": " And then we're going to say, OK, we're",
        "tokens": [
          51564,
          400,
          550,
          321,
          434,
          516,
          281,
          584,
          11,
          2264,
          11,
          321,
          434,
          51664
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 809.72,
        "id": 181,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 806.72,
        "temperature": 0,
        "text": " going to create this result image.",
        "tokens": [
          50364,
          516,
          281,
          1884,
          341,
          1874,
          3256,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 813.72,
        "id": 182,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 809.72,
        "temperature": 0,
        "text": " It goes to create IMG.",
        "tokens": [
          50514,
          467,
          1709,
          281,
          1884,
          21463,
          38,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 816.72,
        "id": 183,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 813.72,
        "temperature": 0,
        "text": " Pass the empty string there.",
        "tokens": [
          50714,
          10319,
          264,
          6707,
          6798,
          456,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 821.32,
        "id": 184,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 816.72,
        "temperature": 0,
        "text": " And we're also going to hide this image.",
        "tokens": [
          50864,
          400,
          321,
          434,
          611,
          516,
          281,
          6479,
          341,
          3256,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 823.72,
        "id": 185,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 821.32,
        "temperature": 0,
        "text": " We're going to draw the image on the canvas,",
        "tokens": [
          51094,
          492,
          434,
          516,
          281,
          2642,
          264,
          3256,
          322,
          264,
          16267,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 826.32,
        "id": 186,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 823.72,
        "temperature": 0,
        "text": " so we don't really need this image.",
        "tokens": [
          51214,
          370,
          321,
          500,
          380,
          534,
          643,
          341,
          3256,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 830.52,
        "id": 187,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 826.32,
        "temperature": 0,
        "text": " And in the end, we're going to use ml5 to get the style",
        "tokens": [
          51344,
          400,
          294,
          264,
          917,
          11,
          321,
          434,
          516,
          281,
          764,
          23271,
          20,
          281,
          483,
          264,
          3758,
          51554
        ]
      },
      {
        "avg_logprob": -0.27941965253165596,
        "compression_ratio": 1.6214689265536724,
        "end": 832.12,
        "id": 188,
        "no_speech_prob": 0.0008969134651124477,
        "seek": 80672,
        "start": 830.52,
        "temperature": 0,
        "text": " transfer model, right?",
        "tokens": [
          51554,
          5003,
          2316,
          11,
          558,
          30,
          51634
        ]
      },
      {
        "avg_logprob": -0.3298959732055664,
        "compression_ratio": 1.3306451612903225,
        "end": 836.12,
        "id": 189,
        "no_speech_prob": 0.0003740733955055475,
        "seek": 83212,
        "start": 832.12,
        "temperature": 0,
        "text": " So style equals to ml5.styleTransfer.",
        "tokens": [
          50364,
          407,
          3758,
          6915,
          281,
          23271,
          20,
          13,
          15014,
          33339,
          612,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3298959732055664,
        "compression_ratio": 1.3306451612903225,
        "end": 845.52,
        "id": 190,
        "no_speech_prob": 0.0003740733955055475,
        "seek": 83212,
        "start": 842.12,
        "temperature": 0,
        "text": " And we are going to pass in the path to the model.",
        "tokens": [
          50864,
          400,
          321,
          366,
          516,
          281,
          1320,
          294,
          264,
          3100,
          281,
          264,
          2316,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.3298959732055664,
        "compression_ratio": 1.3306451612903225,
        "end": 852.52,
        "id": 191,
        "no_speech_prob": 0.0003740733955055475,
        "seek": 83212,
        "start": 845.52,
        "temperature": 0,
        "text": " So it's models slash Lotus.",
        "tokens": [
          51034,
          407,
          309,
          311,
          5245,
          17330,
          44769,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.3298959732055664,
        "compression_ratio": 1.3306451612903225,
        "end": 857.32,
        "id": 192,
        "no_speech_prob": 0.0003740733955055475,
        "seek": 83212,
        "start": 856.32,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51574,
          2264,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.3298959732055664,
        "compression_ratio": 1.3306451612903225,
        "end": 861.52,
        "id": 193,
        "no_speech_prob": 0.0003740733955055475,
        "seek": 83212,
        "start": 857.32,
        "temperature": 0,
        "text": " And then we can also tell the style transfer",
        "tokens": [
          51624,
          400,
          550,
          321,
          393,
          611,
          980,
          264,
          3758,
          5003,
          51834
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 864.72,
        "id": 194,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 861.52,
        "temperature": 0,
        "text": " to look for inputs from our video.",
        "tokens": [
          50364,
          281,
          574,
          337,
          15743,
          490,
          527,
          960,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 866.52,
        "id": 195,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 864.72,
        "temperature": 0,
        "text": " So we're passing the video.",
        "tokens": [
          50524,
          407,
          321,
          434,
          8437,
          264,
          960,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 869.92,
        "id": 196,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 866.52,
        "temperature": 0,
        "text": " And also, we have a callback function saying,",
        "tokens": [
          50614,
          400,
          611,
          11,
          321,
          362,
          257,
          818,
          3207,
          2445,
          1566,
          11,
          50784
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 873.72,
        "id": 197,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 869.92,
        "temperature": 0,
        "text": " oh, if you finish loading this model, let me know.",
        "tokens": [
          50784,
          1954,
          11,
          498,
          291,
          2413,
          15114,
          341,
          2316,
          11,
          718,
          385,
          458,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 878.12,
        "id": 198,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 873.72,
        "temperature": 0,
        "text": " So this is a callback function called modelLoaded.",
        "tokens": [
          50974,
          407,
          341,
          307,
          257,
          818,
          3207,
          2445,
          1219,
          2316,
          31645,
          12777,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 880.92,
        "id": 199,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 878.12,
        "temperature": 0,
        "text": " We're going to define this function now.",
        "tokens": [
          51194,
          492,
          434,
          516,
          281,
          6964,
          341,
          2445,
          586,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 882.72,
        "id": 200,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 880.92,
        "temperature": 0,
        "text": " This is a callback function.",
        "tokens": [
          51334,
          639,
          307,
          257,
          818,
          3207,
          2445,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.18268219629923502,
        "compression_ratio": 1.8670520231213872,
        "end": 887.12,
        "id": 201,
        "no_speech_prob": 0.00012148077803431079,
        "seek": 86152,
        "start": 882.72,
        "temperature": 0,
        "text": " So we're going to do function modelLoaded.",
        "tokens": [
          51424,
          407,
          321,
          434,
          516,
          281,
          360,
          2445,
          2316,
          31645,
          12777,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.206840713818868,
        "compression_ratio": 1.4969325153374233,
        "end": 892.92,
        "id": 202,
        "no_speech_prob": 0.00004683872248278931,
        "seek": 88712,
        "start": 888.12,
        "temperature": 0,
        "text": " Once the model is loaded, we can just",
        "tokens": [
          50414,
          3443,
          264,
          2316,
          307,
          13210,
          11,
          321,
          393,
          445,
          50654
        ]
      },
      {
        "avg_logprob": -0.206840713818868,
        "compression_ratio": 1.4969325153374233,
        "end": 895.52,
        "id": 203,
        "no_speech_prob": 0.00004683872248278931,
        "seek": 88712,
        "start": 892.92,
        "temperature": 0,
        "text": " ask the style transfer to transfer something.",
        "tokens": [
          50654,
          1029,
          264,
          3758,
          5003,
          281,
          5003,
          746,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.206840713818868,
        "compression_ratio": 1.4969325153374233,
        "end": 899.92,
        "id": 204,
        "no_speech_prob": 0.00004683872248278931,
        "seek": 88712,
        "start": 895.52,
        "temperature": 0,
        "text": " But at first, I want to change the text on this p tag",
        "tokens": [
          50784,
          583,
          412,
          700,
          11,
          286,
          528,
          281,
          1319,
          264,
          2487,
          322,
          341,
          280,
          6162,
          51004
        ]
      },
      {
        "avg_logprob": -0.206840713818868,
        "compression_ratio": 1.4969325153374233,
        "end": 902.92,
        "id": 205,
        "no_speech_prob": 0.00004683872248278931,
        "seek": 88712,
        "start": 899.92,
        "temperature": 0,
        "text": " into modelLoaded, just to let people know",
        "tokens": [
          51004,
          666,
          2316,
          31645,
          12777,
          11,
          445,
          281,
          718,
          561,
          458,
          51154
        ]
      },
      {
        "avg_logprob": -0.206840713818868,
        "compression_ratio": 1.4969325153374233,
        "end": 905.32,
        "id": 206,
        "no_speech_prob": 0.00004683872248278931,
        "seek": 88712,
        "start": 902.92,
        "temperature": 0,
        "text": " that the model is good to go.",
        "tokens": [
          51154,
          300,
          264,
          2316,
          307,
          665,
          281,
          352,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.206840713818868,
        "compression_ratio": 1.4969325153374233,
        "end": 911.32,
        "id": 207,
        "no_speech_prob": 0.00004683872248278931,
        "seek": 88712,
        "start": 905.32,
        "temperature": 0,
        "text": " So I'm going to select an element.",
        "tokens": [
          51274,
          407,
          286,
          478,
          516,
          281,
          3048,
          364,
          4478,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.21716072134775657,
        "compression_ratio": 1.3905325443786982,
        "end": 919.5200000000001,
        "id": 208,
        "no_speech_prob": 0.000015689391148043796,
        "seek": 91132,
        "start": 911.5200000000001,
        "temperature": 0,
        "text": " And this is a function from p5 DOM library",
        "tokens": [
          50374,
          400,
          341,
          307,
          257,
          2445,
          490,
          280,
          20,
          35727,
          6405,
          50774
        ]
      },
      {
        "avg_logprob": -0.21716072134775657,
        "compression_ratio": 1.3905325443786982,
        "end": 924.72,
        "id": 209,
        "no_speech_prob": 0.000015689391148043796,
        "seek": 91132,
        "start": 919.5200000000001,
        "temperature": 0,
        "text": " to select an HTML element from the DOM.",
        "tokens": [
          50774,
          281,
          3048,
          364,
          17995,
          4478,
          490,
          264,
          35727,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.21716072134775657,
        "compression_ratio": 1.3905325443786982,
        "end": 927.5200000000001,
        "id": 210,
        "no_speech_prob": 0.000015689391148043796,
        "seek": 91132,
        "start": 924.72,
        "temperature": 0,
        "text": " The ID is status.",
        "tokens": [
          51034,
          440,
          7348,
          307,
          6558,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.21716072134775657,
        "compression_ratio": 1.3905325443786982,
        "end": 934.72,
        "id": 211,
        "no_speech_prob": 0.000015689391148043796,
        "seek": 91132,
        "start": 927.5200000000001,
        "temperature": 0,
        "text": " And I want to change its HTML to modelLoaded.",
        "tokens": [
          51174,
          400,
          286,
          528,
          281,
          1319,
          1080,
          17995,
          281,
          2316,
          31645,
          12777,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.21716072134775657,
        "compression_ratio": 1.3905325443786982,
        "end": 935.9200000000001,
        "id": 212,
        "no_speech_prob": 0.000015689391148043796,
        "seek": 91132,
        "start": 934.72,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51534,
          2264,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.21716072134775657,
        "compression_ratio": 1.3905325443786982,
        "end": 937.5200000000001,
        "id": 213,
        "no_speech_prob": 0.000015689391148043796,
        "seek": 91132,
        "start": 935.9200000000001,
        "temperature": 0,
        "text": " And then once the model is loaded,",
        "tokens": [
          51594,
          400,
          550,
          1564,
          264,
          2316,
          307,
          13210,
          11,
          51674
        ]
      },
      {
        "avg_logprob": -0.21716072134775657,
        "compression_ratio": 1.3905325443786982,
        "end": 940.72,
        "id": 214,
        "no_speech_prob": 0.000015689391148043796,
        "seek": 91132,
        "start": 937.5200000000001,
        "temperature": 0,
        "text": " I'm going to ask the style to transfer something.",
        "tokens": [
          51674,
          286,
          478,
          516,
          281,
          1029,
          264,
          3758,
          281,
          5003,
          746,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 944.12,
        "id": 215,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 940.72,
        "temperature": 0,
        "text": " So I'm going to say style.transfer.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          584,
          3758,
          13,
          24999,
          612,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 950.32,
        "id": 216,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 944.12,
        "temperature": 0,
        "text": " And I'm going to pass in another function called result.",
        "tokens": [
          50534,
          400,
          286,
          478,
          516,
          281,
          1320,
          294,
          1071,
          2445,
          1219,
          1874,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 952.12,
        "id": 217,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 950.32,
        "temperature": 0,
        "text": " So this is a callback function.",
        "tokens": [
          50844,
          407,
          341,
          307,
          257,
          818,
          3207,
          2445,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 955.12,
        "id": 218,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 952.12,
        "temperature": 0,
        "text": " Once the model got anything back,",
        "tokens": [
          50934,
          3443,
          264,
          2316,
          658,
          1340,
          646,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 956.72,
        "id": 219,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 955.12,
        "temperature": 0,
        "text": " this function will be called.",
        "tokens": [
          51084,
          341,
          2445,
          486,
          312,
          1219,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 959.9200000000001,
        "id": 220,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 956.72,
        "temperature": 0,
        "text": " So let's make up this function.",
        "tokens": [
          51164,
          407,
          718,
          311,
          652,
          493,
          341,
          2445,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 961.52,
        "id": 221,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 959.9200000000001,
        "temperature": 0,
        "text": " Function got result.",
        "tokens": [
          51324,
          11166,
          882,
          658,
          1874,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 963.52,
        "id": 222,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 961.52,
        "temperature": 0,
        "text": " It will get two things.",
        "tokens": [
          51404,
          467,
          486,
          483,
          732,
          721,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 967.52,
        "id": 223,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 963.52,
        "temperature": 0,
        "text": " One is if there's any error during this process,",
        "tokens": [
          51504,
          1485,
          307,
          498,
          456,
          311,
          604,
          6713,
          1830,
          341,
          1399,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.159958227625433,
        "compression_ratio": 1.722488038277512,
        "end": 970.32,
        "id": 224,
        "no_speech_prob": 0.000018342430848861113,
        "seek": 94072,
        "start": 967.52,
        "temperature": 0,
        "text": " it will put the error in this error variable.",
        "tokens": [
          51704,
          309,
          486,
          829,
          264,
          6713,
          294,
          341,
          6713,
          7006,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.23902316012624966,
        "compression_ratio": 1.6639344262295082,
        "end": 973.9200000000001,
        "id": 225,
        "no_speech_prob": 0.00006108767411205918,
        "seek": 97032,
        "start": 970.32,
        "temperature": 0,
        "text": " And another thing is the output, which is an image.",
        "tokens": [
          50364,
          400,
          1071,
          551,
          307,
          264,
          5598,
          11,
          597,
          307,
          364,
          3256,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.23902316012624966,
        "compression_ratio": 1.6639344262295082,
        "end": 982.5200000000001,
        "id": 226,
        "no_speech_prob": 0.00006108767411205918,
        "seek": 97032,
        "start": 973.9200000000001,
        "temperature": 0,
        "text": " So once we got the result, we are going to give the result",
        "tokens": [
          50544,
          407,
          1564,
          321,
          658,
          264,
          1874,
          11,
          321,
          366,
          516,
          281,
          976,
          264,
          1874,
          50974
        ]
      },
      {
        "avg_logprob": -0.23902316012624966,
        "compression_ratio": 1.6639344262295082,
        "end": 989.72,
        "id": 227,
        "no_speech_prob": 0.00006108767411205918,
        "seek": 97032,
        "start": 982.5200000000001,
        "temperature": 0,
        "text": " image an attribute to hold this image.source.",
        "tokens": [
          50974,
          3256,
          364,
          19667,
          281,
          1797,
          341,
          3256,
          13,
          41676,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.23902316012624966,
        "compression_ratio": 1.6639344262295082,
        "end": 993.12,
        "id": 228,
        "no_speech_prob": 0.00006108767411205918,
        "seek": 97032,
        "start": 989.72,
        "temperature": 0,
        "text": " So we are going to say result image.attribute.",
        "tokens": [
          51334,
          407,
          321,
          366,
          516,
          281,
          584,
          1874,
          3256,
          13,
          1591,
          2024,
          1169,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.35751095624037194,
        "compression_ratio": 1.6285714285714286,
        "end": 997.92,
        "id": 229,
        "no_speech_prob": 0.00016346012125723064,
        "seek": 99312,
        "start": 994.12,
        "temperature": 0,
        "text": " We copy the source of this image,",
        "tokens": [
          50414,
          492,
          5055,
          264,
          4009,
          295,
          341,
          3256,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.35751095624037194,
        "compression_ratio": 1.6285714285714286,
        "end": 1002.72,
        "id": 230,
        "no_speech_prob": 0.00016346012125723064,
        "seek": 99312,
        "start": 997.92,
        "temperature": 0,
        "text": " the source, to our result image.",
        "tokens": [
          50604,
          264,
          4009,
          11,
          281,
          527,
          1874,
          3256,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.35751095624037194,
        "compression_ratio": 1.6285714285714286,
        "end": 1004.92,
        "id": 231,
        "no_speech_prob": 0.00016346012125723064,
        "seek": 99312,
        "start": 1002.72,
        "temperature": 0,
        "text": " And after we got the result, we want",
        "tokens": [
          50844,
          400,
          934,
          321,
          658,
          264,
          1874,
          11,
          321,
          528,
          50954
        ]
      },
      {
        "avg_logprob": -0.35751095624037194,
        "compression_ratio": 1.6285714285714286,
        "end": 1011.72,
        "id": 232,
        "no_speech_prob": 0.00016346012125723064,
        "seek": 99312,
        "start": 1004.92,
        "temperature": 0,
        "text": " to call this style.transfer again over and over again",
        "tokens": [
          50954,
          281,
          818,
          341,
          3758,
          13,
          24999,
          612,
          797,
          670,
          293,
          670,
          797,
          51294
        ]
      },
      {
        "avg_logprob": -0.35751095624037194,
        "compression_ratio": 1.6285714285714286,
        "end": 1014.92,
        "id": 233,
        "no_speech_prob": 0.00016346012125723064,
        "seek": 99312,
        "start": 1011.72,
        "temperature": 0,
        "text": " to see more result.",
        "tokens": [
          51294,
          281,
          536,
          544,
          1874,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.35751095624037194,
        "compression_ratio": 1.6285714285714286,
        "end": 1019.12,
        "id": 234,
        "no_speech_prob": 0.00016346012125723064,
        "seek": 99312,
        "start": 1014.92,
        "temperature": 0,
        "text": " So we are going to do style.transfer.result again.",
        "tokens": [
          51454,
          407,
          321,
          366,
          516,
          281,
          360,
          3758,
          13,
          24999,
          612,
          13,
          495,
          723,
          797,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1023.72,
        "id": 235,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1019.12,
        "temperature": 0,
        "text": " We are going to do style.transfer.result again.",
        "tokens": [
          50364,
          492,
          366,
          516,
          281,
          360,
          3758,
          13,
          24999,
          612,
          13,
          495,
          723,
          797,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1027.32,
        "id": 236,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1023.72,
        "temperature": 0,
        "text": " And one thing is missing because we did update",
        "tokens": [
          50594,
          400,
          472,
          551,
          307,
          5361,
          570,
          321,
          630,
          5623,
          50774
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1029.12,
        "id": 237,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1027.32,
        "temperature": 0,
        "text": " the source for result image.",
        "tokens": [
          50774,
          264,
          4009,
          337,
          1874,
          3256,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1031.52,
        "id": 238,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1029.12,
        "temperature": 0,
        "text": " But this result image is hidden.",
        "tokens": [
          50864,
          583,
          341,
          1874,
          3256,
          307,
          7633,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1034.52,
        "id": 239,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1031.52,
        "temperature": 0,
        "text": " So we cannot see it.",
        "tokens": [
          50984,
          407,
          321,
          2644,
          536,
          309,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1038.92,
        "id": 240,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1034.52,
        "temperature": 0,
        "text": " But p5 has a function called draw.",
        "tokens": [
          51134,
          583,
          280,
          20,
          575,
          257,
          2445,
          1219,
          2642,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1042.12,
        "id": 241,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1038.92,
        "temperature": 0,
        "text": " It will run over and over again.",
        "tokens": [
          51354,
          467,
          486,
          1190,
          670,
          293,
          670,
          797,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20800016214559366,
        "compression_ratio": 1.6594594594594594,
        "end": 1046.92,
        "id": 242,
        "no_speech_prob": 0.00017130473861470819,
        "seek": 101912,
        "start": 1042.12,
        "temperature": 0,
        "text": " In the draw function, we are going to draw this result image.",
        "tokens": [
          51514,
          682,
          264,
          2642,
          2445,
          11,
          321,
          366,
          516,
          281,
          2642,
          341,
          1874,
          3256,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.23072811814605212,
        "compression_ratio": 1.1908396946564885,
        "end": 1050.72,
        "id": 243,
        "no_speech_prob": 0.00011959742550970986,
        "seek": 104692,
        "start": 1047.1200000000001,
        "temperature": 0,
        "text": " So I'm just going to say image.",
        "tokens": [
          50374,
          407,
          286,
          478,
          445,
          516,
          281,
          584,
          3256,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.23072811814605212,
        "compression_ratio": 1.1908396946564885,
        "end": 1052.72,
        "id": 244,
        "no_speech_prob": 0.00011959742550970986,
        "seek": 104692,
        "start": 1050.72,
        "temperature": 0,
        "text": " It's lowercase i.",
        "tokens": [
          50554,
          467,
          311,
          3126,
          9765,
          741,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.23072811814605212,
        "compression_ratio": 1.1908396946564885,
        "end": 1060.72,
        "id": 245,
        "no_speech_prob": 0.00011959742550970986,
        "seek": 104692,
        "start": 1052.72,
        "temperature": 0,
        "text": " Image result img from origin 0, 0.",
        "tokens": [
          50654,
          29903,
          1874,
          566,
          70,
          490,
          4957,
          1958,
          11,
          1958,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.23072811814605212,
        "compression_ratio": 1.1908396946564885,
        "end": 1066.1200000000001,
        "id": 246,
        "no_speech_prob": 0.00011959742550970986,
        "seek": 104692,
        "start": 1060.72,
        "temperature": 0,
        "text": " And the size is 320 to 240.",
        "tokens": [
          51054,
          400,
          264,
          2744,
          307,
          42429,
          281,
          26837,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.23072811814605212,
        "compression_ratio": 1.1908396946564885,
        "end": 1066.92,
        "id": 247,
        "no_speech_prob": 0.00011959742550970986,
        "seek": 104692,
        "start": 1066.1200000000001,
        "temperature": 0,
        "text": " OK, that's it.",
        "tokens": [
          51324,
          2264,
          11,
          300,
          311,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23072811814605212,
        "compression_ratio": 1.1908396946564885,
        "end": 1074.1200000000001,
        "id": 248,
        "no_speech_prob": 0.00011959742550970986,
        "seek": 104692,
        "start": 1070.3200000000002,
        "temperature": 0,
        "text": " This is the whole Sketch.js.",
        "tokens": [
          51534,
          639,
          307,
          264,
          1379,
          49245,
          13,
          25530,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.23419854090763972,
        "compression_ratio": 1.4761904761904763,
        "end": 1083.52,
        "id": 249,
        "no_speech_prob": 0.0010484375525265932,
        "seek": 107412,
        "start": 1074.12,
        "temperature": 0,
        "text": " Next, finally, we are going to run this code.",
        "tokens": [
          50364,
          3087,
          11,
          2721,
          11,
          321,
          366,
          516,
          281,
          1190,
          341,
          3089,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.23419854090763972,
        "compression_ratio": 1.4761904761904763,
        "end": 1089.12,
        "id": 250,
        "no_speech_prob": 0.0010484375525265932,
        "seek": 107412,
        "start": 1083.52,
        "temperature": 0,
        "text": " We can do Python minus m simple HTTP server.",
        "tokens": [
          50834,
          492,
          393,
          360,
          15329,
          3175,
          275,
          2199,
          33283,
          7154,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23419854090763972,
        "compression_ratio": 1.4761904761904763,
        "end": 1091.32,
        "id": 251,
        "no_speech_prob": 0.0010484375525265932,
        "seek": 107412,
        "start": 1089.12,
        "temperature": 0,
        "text": " If you are using Python 3, you need",
        "tokens": [
          51114,
          759,
          291,
          366,
          1228,
          15329,
          805,
          11,
          291,
          643,
          51224
        ]
      },
      {
        "avg_logprob": -0.23419854090763972,
        "compression_ratio": 1.4761904761904763,
        "end": 1098.9199999999998,
        "id": 252,
        "no_speech_prob": 0.0010484375525265932,
        "seek": 107412,
        "start": 1091.32,
        "temperature": 0,
        "text": " to do Python minus m simple dot HTTP server.",
        "tokens": [
          51224,
          281,
          360,
          15329,
          3175,
          275,
          2199,
          5893,
          33283,
          7154,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.23419854090763972,
        "compression_ratio": 1.4761904761904763,
        "end": 1103.32,
        "id": 253,
        "no_speech_prob": 0.0010484375525265932,
        "seek": 107412,
        "start": 1098.9199999999998,
        "temperature": 0,
        "text": " Anyway, it starts a server at localhost 8000.",
        "tokens": [
          51604,
          5684,
          11,
          309,
          3719,
          257,
          7154,
          412,
          2654,
          6037,
          1649,
          1360,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.25805187225341797,
        "compression_ratio": 1.2741935483870968,
        "end": 1113.52,
        "id": 254,
        "no_speech_prob": 0.00021653379371855408,
        "seek": 110332,
        "start": 1103.52,
        "temperature": 0,
        "text": " So now if we go to our localhost 8000,",
        "tokens": [
          50374,
          407,
          586,
          498,
          321,
          352,
          281,
          527,
          2654,
          6037,
          1649,
          1360,
          11,
          50874
        ]
      },
      {
        "avg_logprob": -0.25805187225341797,
        "compression_ratio": 1.2741935483870968,
        "end": 1115.12,
        "id": 255,
        "no_speech_prob": 0.00021653379371855408,
        "seek": 110332,
        "start": 1113.52,
        "temperature": 0,
        "text": " we should be able to see something.",
        "tokens": [
          50874,
          321,
          820,
          312,
          1075,
          281,
          536,
          746,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.25805187225341797,
        "compression_ratio": 1.2741935483870968,
        "end": 1124.72,
        "id": 256,
        "no_speech_prob": 0.00021653379371855408,
        "seek": 110332,
        "start": 1121.9199999999998,
        "temperature": 0,
        "text": " So model is loaded.",
        "tokens": [
          51294,
          407,
          2316,
          307,
          13210,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.25805187225341797,
        "compression_ratio": 1.2741935483870968,
        "end": 1127.9199999999998,
        "id": 257,
        "no_speech_prob": 0.00021653379371855408,
        "seek": 110332,
        "start": 1124.72,
        "temperature": 0,
        "text": " This is the wrong style source.",
        "tokens": [
          51434,
          639,
          307,
          264,
          2085,
          3758,
          4009,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.25805187225341797,
        "compression_ratio": 1.2741935483870968,
        "end": 1129.32,
        "id": 258,
        "no_speech_prob": 0.00021653379371855408,
        "seek": 110332,
        "start": 1127.9199999999998,
        "temperature": 0,
        "text": " I just have to come in and try.",
        "tokens": [
          51594,
          286,
          445,
          362,
          281,
          808,
          294,
          293,
          853,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2678414308107816,
        "compression_ratio": 1.3951612903225807,
        "end": 1135.52,
        "id": 259,
        "no_speech_prob": 0.00020661752205342054,
        "seek": 112932,
        "start": 1129.32,
        "temperature": 0,
        "text": " That is so cool.",
        "tokens": [
          50364,
          663,
          307,
          370,
          1627,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.2678414308107816,
        "compression_ratio": 1.3951612903225807,
        "end": 1139.12,
        "id": 260,
        "no_speech_prob": 0.00020661752205342054,
        "seek": 112932,
        "start": 1135.52,
        "temperature": 0,
        "text": " And as you can see, this style has more colors.",
        "tokens": [
          50674,
          400,
          382,
          291,
          393,
          536,
          11,
          341,
          3758,
          575,
          544,
          4577,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.2678414308107816,
        "compression_ratio": 1.3951612903225807,
        "end": 1145.52,
        "id": 261,
        "no_speech_prob": 0.00020661752205342054,
        "seek": 112932,
        "start": 1139.12,
        "temperature": 0,
        "text": " So the result is a little bit better than the previous model.",
        "tokens": [
          50854,
          407,
          264,
          1874,
          307,
          257,
          707,
          857,
          1101,
          813,
          264,
          3894,
          2316,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.2678414308107816,
        "compression_ratio": 1.3951612903225807,
        "end": 1151.32,
        "id": 262,
        "no_speech_prob": 0.00020661752205342054,
        "seek": 112932,
        "start": 1145.52,
        "temperature": 0,
        "text": " And yes, this is the demo that we built today.",
        "tokens": [
          51174,
          400,
          2086,
          11,
          341,
          307,
          264,
          10723,
          300,
          321,
          3094,
          965,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.27183621366259075,
        "compression_ratio": 1.4339622641509433,
        "end": 1160.72,
        "id": 263,
        "no_speech_prob": 0.00022341322619467974,
        "seek": 115132,
        "start": 1152.32,
        "temperature": 0,
        "text": " OK, so this is all the resources that I used.",
        "tokens": [
          50414,
          2264,
          11,
          370,
          341,
          307,
          439,
          264,
          3593,
          300,
          286,
          1143,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.27183621366259075,
        "compression_ratio": 1.4339622641509433,
        "end": 1165.9199999999998,
        "id": 264,
        "no_speech_prob": 0.00022341322619467974,
        "seek": 115132,
        "start": 1160.72,
        "temperature": 0,
        "text": " This is Getty's paper from 2015.",
        "tokens": [
          50834,
          639,
          307,
          3240,
          874,
          311,
          3035,
          490,
          7546,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.27183621366259075,
        "compression_ratio": 1.4339622641509433,
        "end": 1170.72,
        "id": 265,
        "no_speech_prob": 0.00022341322619467974,
        "seek": 115132,
        "start": 1165.9199999999998,
        "temperature": 0,
        "text": " This is Gene Cogan's What Neural Networks Sees.",
        "tokens": [
          51094,
          639,
          307,
          18083,
          383,
          21576,
          311,
          708,
          1734,
          1807,
          12640,
          82,
          1100,
          279,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.27183621366259075,
        "compression_ratio": 1.4339622641509433,
        "end": 1175.32,
        "id": 266,
        "no_speech_prob": 0.00022341322619467974,
        "seek": 115132,
        "start": 1170.72,
        "temperature": 0,
        "text": " This is the transfer style tutorial from Spell.",
        "tokens": [
          51334,
          639,
          307,
          264,
          5003,
          3758,
          7073,
          490,
          3550,
          285,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.27183621366259075,
        "compression_ratio": 1.4339622641509433,
        "end": 1179.4199999999998,
        "id": 267,
        "no_speech_prob": 0.00022341322619467974,
        "seek": 115132,
        "start": 1175.32,
        "temperature": 0,
        "text": " And also for ML5.js, it has a style transfer tutorial",
        "tokens": [
          51564,
          400,
          611,
          337,
          21601,
          20,
          13,
          25530,
          11,
          309,
          575,
          257,
          3758,
          5003,
          7073,
          51769
        ]
      },
      {
        "avg_logprob": -0.192288045529966,
        "compression_ratio": 1.4776119402985075,
        "end": 1181.42,
        "id": 268,
        "no_speech_prob": 0.0028008206281811,
        "seek": 117942,
        "start": 1179.42,
        "temperature": 0,
        "text": " made by Chris.",
        "tokens": [
          50364,
          1027,
          538,
          6688,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.192288045529966,
        "compression_ratio": 1.4776119402985075,
        "end": 1184.8200000000002,
        "id": 269,
        "no_speech_prob": 0.0028008206281811,
        "seek": 117942,
        "start": 1181.42,
        "temperature": 0,
        "text": " And I recommend you to check that out, too.",
        "tokens": [
          50464,
          400,
          286,
          2748,
          291,
          281,
          1520,
          300,
          484,
          11,
          886,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.192288045529966,
        "compression_ratio": 1.4776119402985075,
        "end": 1187.8200000000002,
        "id": 270,
        "no_speech_prob": 0.0028008206281811,
        "seek": 117942,
        "start": 1184.8200000000002,
        "temperature": 0,
        "text": " And this is the link to ML5.js.",
        "tokens": [
          50634,
          400,
          341,
          307,
          264,
          2113,
          281,
          21601,
          20,
          13,
          25530,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.192288045529966,
        "compression_ratio": 1.4776119402985075,
        "end": 1191.72,
        "id": 271,
        "no_speech_prob": 0.0028008206281811,
        "seek": 117942,
        "start": 1187.8200000000002,
        "temperature": 0,
        "text": " And I also want to recommend this YouTube channel,",
        "tokens": [
          50784,
          400,
          286,
          611,
          528,
          281,
          2748,
          341,
          3088,
          2269,
          11,
          50979
        ]
      },
      {
        "avg_logprob": -0.192288045529966,
        "compression_ratio": 1.4776119402985075,
        "end": 1196.6200000000001,
        "id": 272,
        "no_speech_prob": 0.0028008206281811,
        "seek": 117942,
        "start": 1191.72,
        "temperature": 0,
        "text": " because I learned a lot of machine learning papers from it.",
        "tokens": [
          50979,
          570,
          286,
          3264,
          257,
          688,
          295,
          3479,
          2539,
          10577,
          490,
          309,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.192288045529966,
        "compression_ratio": 1.4776119402985075,
        "end": 1203.02,
        "id": 273,
        "no_speech_prob": 0.0028008206281811,
        "seek": 117942,
        "start": 1196.6200000000001,
        "temperature": 0,
        "text": " And I want to give credits to those two project creators.",
        "tokens": [
          51224,
          400,
          286,
          528,
          281,
          976,
          16816,
          281,
          729,
          732,
          1716,
          16039,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.192288045529966,
        "compression_ratio": 1.4776119402985075,
        "end": 1206.02,
        "id": 274,
        "no_speech_prob": 0.0028008206281811,
        "seek": 117942,
        "start": 1203.02,
        "temperature": 0,
        "text": " We used the TensorFlow implementation",
        "tokens": [
          51544,
          492,
          1143,
          264,
          37624,
          11420,
          51694
        ]
      },
      {
        "avg_logprob": -0.29936187267303466,
        "compression_ratio": 1.427027027027027,
        "end": 1210.42,
        "id": 275,
        "no_speech_prob": 0.0039453343488276005,
        "seek": 120602,
        "start": 1206.02,
        "temperature": 0,
        "text": " of the fast style transfer made by Logan Engstrom.",
        "tokens": [
          50364,
          295,
          264,
          2370,
          3758,
          5003,
          1027,
          538,
          22689,
          2469,
          38673,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.29936187267303466,
        "compression_ratio": 1.427027027027027,
        "end": 1214.22,
        "id": 276,
        "no_speech_prob": 0.0039453343488276005,
        "seek": 120602,
        "start": 1210.42,
        "temperature": 0,
        "text": " And we used the script to convert the TensorFlow SAFE",
        "tokens": [
          50584,
          400,
          321,
          1143,
          264,
          5755,
          281,
          7620,
          264,
          37624,
          16482,
          28182,
          50774
        ]
      },
      {
        "avg_logprob": -0.29936187267303466,
        "compression_ratio": 1.427027027027027,
        "end": 1220.32,
        "id": 277,
        "no_speech_prob": 0.0039453343488276005,
        "seek": 120602,
        "start": 1214.22,
        "temperature": 0,
        "text": " model to a format that we can use in TensorFlow.js and ML5.js.",
        "tokens": [
          50774,
          2316,
          281,
          257,
          7877,
          300,
          321,
          393,
          764,
          294,
          37624,
          13,
          25530,
          293,
          21601,
          20,
          13,
          25530,
          13,
          51079
        ]
      },
      {
        "avg_logprob": -0.29936187267303466,
        "compression_ratio": 1.427027027027027,
        "end": 1227.42,
        "id": 278,
        "no_speech_prob": 0.0039453343488276005,
        "seek": 120602,
        "start": 1220.32,
        "temperature": 0,
        "text": " It's made by Richiro Nakano.",
        "tokens": [
          51079,
          467,
          311,
          1027,
          538,
          497,
          480,
          5182,
          25779,
          3730,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.29936187267303466,
        "compression_ratio": 1.427027027027027,
        "end": 1231.42,
        "id": 279,
        "no_speech_prob": 0.0039453343488276005,
        "seek": 120602,
        "start": 1227.42,
        "temperature": 0,
        "text": " And to wrap up, today we trained a style transfer model",
        "tokens": [
          51434,
          400,
          281,
          7019,
          493,
          11,
          965,
          321,
          8895,
          257,
          3758,
          5003,
          2316,
          51634
        ]
      },
      {
        "avg_logprob": -0.29936187267303466,
        "compression_ratio": 1.427027027027027,
        "end": 1232.52,
        "id": 280,
        "no_speech_prob": 0.0039453343488276005,
        "seek": 120602,
        "start": 1231.42,
        "temperature": 0,
        "text": " with Spell.",
        "tokens": [
          51634,
          365,
          3550,
          285,
          13,
          51689
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1238.12,
        "id": 281,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1232.52,
        "temperature": 0,
        "text": " And we ran this model with ML5 in the browser.",
        "tokens": [
          50364,
          400,
          321,
          5872,
          341,
          2316,
          365,
          21601,
          20,
          294,
          264,
          11185,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1241.92,
        "id": 282,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1238.12,
        "temperature": 0,
        "text": " And you can check out the model here.",
        "tokens": [
          50644,
          400,
          291,
          393,
          1520,
          484,
          264,
          2316,
          510,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1243.92,
        "id": 283,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1241.92,
        "temperature": 0,
        "text": " And that's it.",
        "tokens": [
          50834,
          400,
          300,
          311,
          309,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1244.42,
        "id": 284,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1243.92,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50934,
          1057,
          558,
          13,
          50959
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1246.52,
        "id": 285,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1244.42,
        "temperature": 0,
        "text": " Thank you so much, Yining, for being a wonderful guest",
        "tokens": [
          50959,
          1044,
          291,
          370,
          709,
          11,
          398,
          1760,
          11,
          337,
          885,
          257,
          3715,
          8341,
          51064
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1247.96,
        "id": 286,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1246.52,
        "temperature": 0,
        "text": " on the coding train, for showing us",
        "tokens": [
          51064,
          322,
          264,
          17720,
          3847,
          11,
          337,
          4099,
          505,
          51136
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1250.32,
        "id": 287,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1247.96,
        "temperature": 0,
        "text": " how to train our own style transfer model,",
        "tokens": [
          51136,
          577,
          281,
          3847,
          527,
          1065,
          3758,
          5003,
          2316,
          11,
          51254
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1251.96,
        "id": 288,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1250.32,
        "temperature": 0,
        "text": " how to take that style transfer model",
        "tokens": [
          51254,
          577,
          281,
          747,
          300,
          3758,
          5003,
          2316,
          51336
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1255.24,
        "id": 289,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1251.96,
        "temperature": 0,
        "text": " and bring it into the browser, style our beautiful faces",
        "tokens": [
          51336,
          293,
          1565,
          309,
          666,
          264,
          11185,
          11,
          3758,
          527,
          2238,
          8475,
          51500
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1258.56,
        "id": 290,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1255.24,
        "temperature": 0,
        "text": " with the style of the image, with the image from the webcam,",
        "tokens": [
          51500,
          365,
          264,
          3758,
          295,
          264,
          3256,
          11,
          365,
          264,
          3256,
          490,
          264,
          39490,
          11,
          51666
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1259.24,
        "id": 291,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1258.56,
        "temperature": 0,
        "text": " all that stuff.",
        "tokens": [
          51666,
          439,
          300,
          1507,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2629428803920746,
        "compression_ratio": 1.8032786885245902,
        "end": 1261,
        "id": 292,
        "no_speech_prob": 0.003171684220433235,
        "seek": 123252,
        "start": 1259.24,
        "temperature": 0,
        "text": " So thank you to Yining.",
        "tokens": [
          51700,
          407,
          1309,
          291,
          281,
          398,
          1760,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1263.04,
        "id": 293,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1261,
        "temperature": 0,
        "text": " Thank you to Spell for sponsoring this.",
        "tokens": [
          50364,
          1044,
          291,
          281,
          3550,
          285,
          337,
          30311,
          341,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1264.84,
        "id": 294,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1263.04,
        "temperature": 0,
        "text": " I'm really curious, really curious",
        "tokens": [
          50466,
          286,
          478,
          534,
          6369,
          11,
          534,
          6369,
          50556
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1266.28,
        "id": 295,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1264.84,
        "temperature": 0,
        "text": " if people are able to follow this.",
        "tokens": [
          50556,
          498,
          561,
          366,
          1075,
          281,
          1524,
          341,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1267.92,
        "id": 296,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1266.28,
        "temperature": 0,
        "text": " And I really want to know what kind",
        "tokens": [
          50628,
          400,
          286,
          534,
          528,
          281,
          458,
          437,
          733,
          50710
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1270.64,
        "id": 297,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1267.92,
        "temperature": 0,
        "text": " of creative, weird image combinations",
        "tokens": [
          50710,
          295,
          5880,
          11,
          3657,
          3256,
          21267,
          50846
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1272.56,
        "id": 298,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1270.64,
        "temperature": 0,
        "text": " can you think of and try.",
        "tokens": [
          50846,
          393,
          291,
          519,
          295,
          293,
          853,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1274,
        "id": 299,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1272.56,
        "temperature": 0,
        "text": " So please, make some.",
        "tokens": [
          50942,
          407,
          1767,
          11,
          652,
          512,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1275.52,
        "id": 300,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1274,
        "temperature": 0,
        "text": " Train style transfer models.",
        "tokens": [
          51014,
          28029,
          3758,
          5003,
          5245,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1277.04,
        "id": 301,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1275.52,
        "temperature": 0,
        "text": " Style all sorts of images.",
        "tokens": [
          51090,
          27004,
          439,
          7527,
          295,
          5267,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1280.56,
        "id": 302,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1277.04,
        "temperature": 0,
        "text": " And share those with me on Twitter at hashtag this.style",
        "tokens": [
          51166,
          400,
          2073,
          729,
          365,
          385,
          322,
          5794,
          412,
          20379,
          341,
          13,
          15014,
          51342
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1282.4,
        "id": 303,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1280.56,
        "temperature": 0,
        "text": " or right here in the comments as well.",
        "tokens": [
          51342,
          420,
          558,
          510,
          294,
          264,
          3053,
          382,
          731,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1284.96,
        "id": 304,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1282.4,
        "temperature": 0,
        "text": " But I don't think you can post an image in the comments.",
        "tokens": [
          51434,
          583,
          286,
          500,
          380,
          519,
          291,
          393,
          2183,
          364,
          3256,
          294,
          264,
          3053,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1286.24,
        "id": 305,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1284.96,
        "temperature": 0,
        "text": " But you can link to it, I guess.",
        "tokens": [
          51562,
          583,
          291,
          393,
          2113,
          281,
          309,
          11,
          286,
          2041,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1287.84,
        "id": 306,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1286.24,
        "temperature": 0,
        "text": " So anyway, thank you.",
        "tokens": [
          51626,
          407,
          4033,
          11,
          1309,
          291,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.25663585536527317,
        "compression_ratio": 1.7366666666666666,
        "end": 1290.56,
        "id": 307,
        "no_speech_prob": 0.022972993552684784,
        "seek": 126100,
        "start": 1287.84,
        "temperature": 0,
        "text": " See you in future videos.",
        "tokens": [
          51706,
          3008,
          291,
          294,
          2027,
          2145,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.7935222148895263,
        "compression_ratio": 0.5,
        "end": 1292.12,
        "id": 308,
        "no_speech_prob": 0.23893555998802185,
        "seek": 129056,
        "start": 1290.56,
        "temperature": 0.4,
        "text": " Goodbye.",
        "tokens": [
          50364,
          15528,
          13,
          50442
        ]
      }
    ],
    "transcription": " All right, we are here in the third Spell video. Thank you to Spell for sponsoring. Sign up at spell.run slash coding train. OK, so if you watched the first video where I explained how to set up Spell, then you watch the second video which you trained your own style transfer model using TensorFlow and Python, running it in the cloud on spell.run. Now you're ready for that last step, downloading your trained model from Spell, bringing it into the browser using the ml5.js open source library, p5.js open source library. ml5, by the way, is built on top of TensorFlow.js. Got to mention all these libraries. All these libraries come together, and you can then take real time images from your webcam and style it with your style transfer model. So follow this tutorial. If you get this working, please, please, please share it with me, hashtag this.style on Twitter, share it in the comments here, or anywhere you can find to share it. I would love to know and see what you all make. OK, enjoy this video from Yining again. So far, we set up the environment. We downloaded the data set. We trained the model with the style Python script. We copied our trained model back to our local computer. And then last step is to convert the model to a format that we can use in TensorFlow.js and ml5.js. OK, let's do this. Oh, by the way, this is the trained model that we got on the desktop. OK, so if I go back to my old directory, which is live stream here, we're going to use the scripts that is from file style transfer deeplearn.js. Deeplearn.js is the formal name for TensorFlow.js. This repo is built by Richiro Nakano. His work is amazing. He recently contributed a new model called sketch RN to ml5.js too. You guys should definitely check out his work. But we're going to use his script to convert the TensorFlow model into a model that we can use in ml5.js. So the way that we're going to do it is to clone his GitHub repo. And then we're going inside to this GitHub repo. And we're going to put all those checkpoint files that we got into one of the folders inside of this GitHub repo, which is. So I'm just going to go to file style transfer deeplearn.js. Now just copy this folder to the root directory of this GitHub repo. And I just did. It's here. And then we're going to run two Python scripts. The first thing is to dump the checkpoints just to convert the format. So what we're going to do is copy paste this command. Let's edit this in the code editor first. Python script and run this script. And then the output directory is source slash checkpoint our folder name, which will be spell model. And then the checkpoint file is in the root directory of the GitHub repo. So it's dot slash spell model slash fns dot ckpt. This is the path to our model, which we saw before in this checkpoint file. This is the path to our checkpoint. That's why we have this name here. So now I'm just going to run this script. And then you can see it's done. So it actually created one checkpoint file and 49 other files. And we can go there to see what is the output. The output lives in source checkpoint. And we can see that the output is in the source checkpoint. And this is our model. And you can see that we got the manifest JSON. This tells us the structure of the graph. And also 49 files that tells us all those variables in each layer. And this is the format that we can use in ml5.js and TensorFlow.js. So now I'm just going to copy this model back to my desktop. Going to rename it and drag it to my desktop. So so far, we got two models. We have a TensorFlow saved model that can work in TensorFlow, of course. And then we also got another model that can work in ml5.js and TensorFlow.js. So this is what we got today. And the next step is to run this model in ml5.js. Here are two demos on ml5's website. And we also have this demo here that you can select different styles. You can upload the image. You can change your style here. And you can upload the image. I'm going to upload a photo, a photo of a cat. And then click this Transfer My Image. This is the transferred cat. You can also play it with different styles, too. Oh, I do like this one. And also, you can use webcam. And then click this button. And you can see the transferred version of the images from the webcam. So you can go there and check this demo out. But next, we're just going to run this model in our ml5 demo. So we can do this quickly. Here, we're just going to clone this GitHub repo. And then go inside to that folder, styleTransfer underscore spell. And we're going to open this folder in your code editor. And in its models folder, we're going to add our new models inside of this folder. So what I'm going to do is to find that GitHub repo. And inside of models, I'm going to copy paste this model in. I'm just going to rename it to Lotus, because the name of the art is called Lotus. So now we go back to our code editor. We have a new model here. And we can take a look at what is inside of the index HTML. So to build this demo, we need p5.js, mainly to get the video from the webcam. And also, we need p5 DOM library to make it easier to create DOM elements for us. And then in the end, we need the ml5 library. And we have some styles here. We can ignore them for now. And we're also running the Sketch.js. Script here. And in the body, we have header tag. We have p tag. And we are linking the source of the image, the art style image. And also, we are showing the art image. But I'm going to change this to the Lotus image. This is a pre-trained model. I'm going to add this image into this image folder. So here, we can say images slash Lotus. So we are going to show that image. And in the end, we have a div container to contain our canvas. And now we can go to, let's save this index HTML. And then we can go to Sketch.js. I'm just going to delete all the code here so we can do it ourselves one more time together. So to build this demo, we need three things. We need a video that can get the images from our webcam. So we have video. We also need the style transfer from ML5 library to allow us to transfer images. So I'm going to have another variable called style. And in the end, we need a variable to hold our output image. So we're going to do let result IMG. So this is the three things that we need. And in p5, there is a setup function. That will be called once at the beginning. So in this setup function, we're going to use p5.js to create a canvas that is 320 wide and 250 its height. And then we're going to use this p5 DOM library to put this canvas element inside of a div element whose ID is canvas container. OK, so we create a canvas. That's it. And then we're going to create the video. So p5 has this function called create capture. And if we pass the uppercase video in, it will try to get the video from your webcam. And we're also going to say video.height, because we don't really need the original video. We need the transferred video. So we're also going to say video height. And we're also going to create the result image. p5 DOM library has this. I just want to make it a little bit better. We're going to create this result image. You could start with this. And then we're going to say, OK, we're going to create this result image. It goes to create IMG. Pass the empty string there. And we're also going to hide this image. We're going to draw the image on the canvas, so we don't really need this image. And in the end, we're going to use ml5 to get the style transfer model, right? So style equals to ml5.styleTransfer. And we are going to pass in the path to the model. So it's models slash Lotus. OK. And then we can also tell the style transfer to look for inputs from our video. So we're passing the video. And also, we have a callback function saying, oh, if you finish loading this model, let me know. So this is a callback function called modelLoaded. We're going to define this function now. This is a callback function. So we're going to do function modelLoaded. Once the model is loaded, we can just ask the style transfer to transfer something. But at first, I want to change the text on this p tag into modelLoaded, just to let people know that the model is good to go. So I'm going to select an element. And this is a function from p5 DOM library to select an HTML element from the DOM. The ID is status. And I want to change its HTML to modelLoaded. OK. And then once the model is loaded, I'm going to ask the style to transfer something. So I'm going to say style.transfer. And I'm going to pass in another function called result. So this is a callback function. Once the model got anything back, this function will be called. So let's make up this function. Function got result. It will get two things. One is if there's any error during this process, it will put the error in this error variable. And another thing is the output, which is an image. So once we got the result, we are going to give the result image an attribute to hold this image.source. So we are going to say result image.attribute. We copy the source of this image, the source, to our result image. And after we got the result, we want to call this style.transfer again over and over again to see more result. So we are going to do style.transfer.result again. We are going to do style.transfer.result again. And one thing is missing because we did update the source for result image. But this result image is hidden. So we cannot see it. But p5 has a function called draw. It will run over and over again. In the draw function, we are going to draw this result image. So I'm just going to say image. It's lowercase i. Image result img from origin 0, 0. And the size is 320 to 240. OK, that's it. This is the whole Sketch.js. Next, finally, we are going to run this code. We can do Python minus m simple HTTP server. If you are using Python 3, you need to do Python minus m simple dot HTTP server. Anyway, it starts a server at localhost 8000. So now if we go to our localhost 8000, we should be able to see something. So model is loaded. This is the wrong style source. I just have to come in and try. That is so cool. And as you can see, this style has more colors. So the result is a little bit better than the previous model. And yes, this is the demo that we built today. OK, so this is all the resources that I used. This is Getty's paper from 2015. This is Gene Cogan's What Neural Networks Sees. This is the transfer style tutorial from Spell. And also for ML5.js, it has a style transfer tutorial made by Chris. And I recommend you to check that out, too. And this is the link to ML5.js. And I also want to recommend this YouTube channel, because I learned a lot of machine learning papers from it. And I want to give credits to those two project creators. We used the TensorFlow implementation of the fast style transfer made by Logan Engstrom. And we used the script to convert the TensorFlow SAFE model to a format that we can use in TensorFlow.js and ML5.js. It's made by Richiro Nakano. And to wrap up, today we trained a style transfer model with Spell. And we ran this model with ML5 in the browser. And you can check out the model here. And that's it. All right. Thank you so much, Yining, for being a wonderful guest on the coding train, for showing us how to train our own style transfer model, how to take that style transfer model and bring it into the browser, style our beautiful faces with the style of the image, with the image from the webcam, all that stuff. So thank you to Yining. Thank you to Spell for sponsoring this. I'm really curious, really curious if people are able to follow this. And I really want to know what kind of creative, weird image combinations can you think of and try. So please, make some. Train style transfer models. Style all sorts of images. And share those with me on Twitter at hashtag this.style or right here in the comments as well. But I don't think you can post an image in the comments. But you can link to it, I guess. So anyway, thank you. See you in future videos. Goodbye.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:45.147031Z",
  "started_at": "2023-09-26T21:16:37.897957Z",
  "completed_at": "2023-09-26T21:20:40.208965Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=S_I0SGAO73A",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 242.311008
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/mbxxn4jbczpdsksrahz53wo6ru/cancel",
    "get": "https://api.replicate.com/v1/predictions/mbxxn4jbczpdsksrahz53wo6ru"
  }
}