{
  "id": "3czs5gjblwaljrpzqyjiymws7a",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/mETDQDBwOi0.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/708933 [00:00<?, ?frames/s]\n  0%|          | 2888/708933 [00:03<12:21, 952.41frames/s]\n  1%|          | 5616/708933 [00:08<17:43, 661.29frames/s]\n  1%|          | 8280/708933 [00:12<19:05, 611.64frames/s]\n  2%|▏         | 10992/708933 [00:18<20:56, 555.68frames/s]\n  2%|▏         | 13140/708933 [00:21<20:13, 573.55frames/s]\n  2%|▏         | 15728/708933 [00:26<19:42, 586.41frames/s]\n  3%|▎         | 18484/708933 [00:33<23:17, 493.99frames/s]\n  3%|▎         | 20960/708933 [00:38<22:42, 505.12frames/s]\n  3%|▎         | 23942/708933 [00:43<21:27, 531.98frames/s]\n  4%|▍         | 26616/708933 [00:47<20:45, 548.02frames/s]\n  4%|▍         | 29324/708933 [00:52<20:09, 562.12frames/s]\n  5%|▍         | 32144/708933 [00:58<21:31, 524.03frames/s]\n  5%|▍         | 35104/708933 [01:02<19:31, 575.23frames/s]\n  5%|▌         | 37968/708933 [01:08<21:08, 528.91frames/s]\n  6%|▌         | 40904/708933 [01:15<21:56, 507.62frames/s]\n  6%|▌         | 43092/708933 [01:19<21:21, 519.65frames/s]\n  6%|▋         | 45620/708933 [01:23<20:42, 533.92frames/s]\n  7%|▋         | 48528/708933 [01:27<18:39, 589.98frames/s]\n  7%|▋         | 50908/708933 [01:31<19:03, 575.58frames/s]\n  7%|▋         | 52688/708933 [01:34<18:17, 598.11frames/s]\n  8%|▊         | 54940/708933 [01:37<17:39, 617.25frames/s]\n  8%|▊         | 57868/708933 [01:40<15:44, 689.31frames/s]\n  9%|▊         | 60848/708933 [01:45<15:47, 683.76frames/s]\n  9%|▉         | 63292/708933 [01:49<15:48, 680.99frames/s]\n  9%|▉         | 66292/708933 [01:52<14:49, 722.63frames/s]\n 10%|▉         | 68800/708933 [01:56<15:15, 698.90frames/s]\n 10%|█         | 71096/708933 [02:00<15:38, 679.76frames/s]\n 10%|█         | 73408/708933 [02:02<14:31, 729.39frames/s]\n 11%|█         | 76408/708933 [02:05<12:14, 861.55frames/s]\n 11%|█         | 78456/708933 [02:06<11:23, 922.71frames/s]\n 11%|█▏        | 80480/708933 [02:09<12:11, 859.55frames/s]\n 12%|█▏        | 83184/708933 [02:12<11:59, 869.50frames/s]\n 12%|█▏        | 85896/708933 [02:17<14:44, 704.13frames/s]\n 12%|█▏        | 88160/708933 [02:22<16:00, 646.55frames/s]\n 13%|█▎        | 90880/708933 [02:25<15:18, 672.86frames/s]\n 13%|█▎        | 93576/708933 [02:30<16:20, 627.38frames/s]\n 14%|█▎        | 96472/708933 [02:35<16:48, 607.08frames/s]\n 14%|█▍        | 98568/708933 [02:40<17:30, 581.02frames/s]\n 14%|█▍        | 101304/708933 [02:43<15:59, 633.56frames/s]\n 15%|█▍        | 103520/708933 [02:47<16:23, 615.35frames/s]\n 15%|█▍        | 106256/708933 [02:51<16:18, 615.93frames/s]\n 15%|█▌        | 109232/708933 [02:54<14:12, 703.16frames/s]\n 16%|█▌        | 112008/708933 [03:00<15:32, 640.26frames/s]\n 16%|█▌        | 114704/708933 [03:05<16:40, 594.01frames/s]\n 17%|█▋        | 117184/708933 [03:09<16:22, 602.27frames/s]\n 17%|█▋        | 119704/708933 [03:14<16:50, 583.30frames/s]\n 17%|█▋        | 122448/708933 [03:19<18:09, 538.21frames/s]\n 18%|█▊        | 125000/708933 [03:24<17:57, 541.98frames/s]\n 18%|█▊        | 127768/708933 [03:31<19:31, 496.08frames/s]\n 18%|█▊        | 130304/708933 [03:35<18:44, 514.36frames/s]\n 19%|█▊        | 132656/708933 [03:39<17:47, 539.93frames/s]\n 19%|█▉        | 135184/708933 [03:43<16:29, 579.64frames/s]\n 19%|█▉        | 137864/708933 [03:48<17:08, 555.11frames/s]\n 20%|█▉        | 140864/708933 [03:52<15:29, 611.31frames/s]\n 20%|██        | 143560/708933 [03:56<15:00, 628.02frames/s]\n 21%|██        | 145952/708933 [04:01<16:23, 572.15frames/s]\n 21%|██        | 148624/708933 [04:05<15:51, 588.99frames/s]\n 21%|██        | 150496/708933 [04:08<15:17, 608.73frames/s]\n 22%|██▏       | 153064/708933 [04:12<14:52, 622.49frames/s]\n 22%|██▏       | 155880/708933 [04:16<13:50, 665.73frames/s]\n 22%|██▏       | 158352/708933 [04:20<14:49, 619.22frames/s]\n 23%|██▎       | 161280/708933 [04:24<13:52, 657.49frames/s]\n 23%|██▎       | 162536/708933 [04:27<15:08, 601.25frames/s]\n 23%|██▎       | 164736/708933 [04:29<12:34, 721.45frames/s]\n 24%|██▎       | 167720/708933 [04:34<13:19, 677.13frames/s]\n 24%|██▍       | 170312/708933 [04:38<14:25, 622.26frames/s]\n 24%|██▍       | 173272/708933 [04:43<14:04, 634.28frames/s]\n 25%|██▍       | 175832/708933 [04:48<14:58, 593.45frames/s]\n 25%|██▌       | 178360/708933 [04:52<14:53, 594.11frames/s]\n 26%|██▌       | 180824/708933 [04:56<14:19, 614.53frames/s]\n 26%|██▌       | 183328/708933 [05:00<14:32, 602.39frames/s]\n 26%|██▌       | 185952/708933 [05:05<14:35, 597.43frames/s]\n 27%|██▋       | 188848/708933 [05:09<14:19, 604.93frames/s]\n 27%|██▋       | 191808/708933 [05:13<13:15, 650.07frames/s]\n 27%|██▋       | 194248/708933 [05:16<12:37, 679.38frames/s]\n 28%|██▊       | 196872/708933 [05:22<14:02, 607.93frames/s]\n 28%|██▊       | 198872/708933 [05:24<12:58, 655.42frames/s]\n 28%|██▊       | 201368/708933 [05:27<11:34, 730.67frames/s]\n 29%|██▉       | 203968/708933 [05:29<10:41, 787.03frames/s]\n 29%|██▉       | 206368/708933 [05:31<09:31, 879.11frames/s]\n 30%|██▉       | 209368/708933 [05:35<09:41, 859.54frames/s]\n 30%|██▉       | 212368/708933 [05:37<08:40, 954.39frames/s]\n 30%|███       | 214888/708933 [05:42<10:14, 804.33frames/s]\n 31%|███       | 216968/708933 [05:45<10:30, 780.14frames/s]\n 31%|███       | 218400/708933 [05:47<11:34, 706.05frames/s]\n 31%|███       | 221272/708933 [05:50<09:37, 843.89frames/s]\n 32%|███▏      | 224152/708933 [05:54<10:05, 800.38frames/s]\n 32%|███▏      | 227152/708933 [05:58<10:35, 758.18frames/s]\n 32%|███▏      | 229128/708933 [06:00<10:09, 787.00frames/s]\n 33%|███▎      | 231600/708933 [06:03<09:44, 816.04frames/s]\n 33%|███▎      | 234104/708933 [06:06<09:59, 792.36frames/s]\n 33%|███▎      | 236384/708933 [06:11<11:34, 680.71frames/s]\n 34%|███▎      | 239112/708933 [06:17<13:09, 595.12frames/s]\n 34%|███▍      | 241672/708933 [06:21<13:19, 584.56frames/s]\n 34%|███▍      | 244200/708933 [06:25<12:31, 618.30frames/s]\n 35%|███▍      | 246752/708933 [06:31<14:10, 543.64frames/s]\n 35%|███▌      | 249008/708933 [06:34<13:35, 563.69frames/s]\n 35%|███▌      | 251552/708933 [06:38<12:43, 599.27frames/s]\n 36%|███▌      | 253984/708933 [06:43<13:15, 571.80frames/s]\n 36%|███▌      | 256624/708933 [06:49<14:25, 522.33frames/s]\n 37%|███▋      | 259160/708933 [06:53<13:56, 537.88frames/s]\n 37%|███▋      | 261440/708933 [06:56<13:05, 569.47frames/s]\n 37%|███▋      | 264104/708933 [06:59<11:04, 669.69frames/s]\n 38%|███▊      | 266936/708933 [07:02<10:08, 726.26frames/s]\n 38%|███▊      | 269448/708933 [07:07<11:06, 659.69frames/s]\n 38%|███▊      | 271744/708933 [07:11<11:54, 611.61frames/s]\n 39%|███▉      | 274744/708933 [07:14<10:10, 710.97frames/s]\n 39%|███▉      | 277744/708933 [07:18<09:39, 744.63frames/s]\n 40%|███▉      | 280176/708933 [07:21<09:34, 746.26frames/s]\n 40%|███▉      | 283176/708933 [07:25<09:20, 759.23frames/s]\n 40%|████      | 285464/708933 [07:26<08:03, 876.30frames/s]\n 41%|████      | 287856/708933 [07:29<07:42, 910.73frames/s]\n 41%|████      | 290856/708933 [07:30<05:43, 1216.62frames/s]\n 41%|████▏     | 293704/708933 [07:34<07:34, 912.99frames/s] \n 42%|████▏     | 296360/708933 [07:39<08:58, 766.46frames/s]\n 42%|████▏     | 298776/708933 [07:42<08:49, 774.14frames/s]\n 42%|████▏     | 300992/708933 [07:45<08:20, 814.37frames/s]\n 43%|████▎     | 303784/708933 [07:50<10:08, 666.23frames/s]\n 43%|████▎     | 306304/708933 [07:55<10:59, 610.89frames/s]\n 44%|████▎     | 308912/708933 [08:00<11:29, 579.82frames/s]\n 44%|████▍     | 311008/708933 [08:05<12:20, 537.17frames/s]\n 44%|████▍     | 313536/708933 [08:09<11:46, 559.74frames/s]\n 45%|████▍     | 315864/708933 [08:14<12:05, 541.44frames/s]\n 45%|████▍     | 318432/708933 [08:20<12:55, 503.44frames/s]\n 45%|████▌     | 320304/708933 [08:23<12:53, 502.74frames/s]\n 45%|████▌     | 322512/708933 [08:25<10:27, 615.38frames/s]\n 46%|████▌     | 325368/708933 [08:29<10:11, 626.88frames/s]\n 46%|████▋     | 327976/708933 [08:33<09:51, 644.23frames/s]\n 47%|████▋     | 330552/708933 [08:38<10:28, 602.15frames/s]\n 47%|████▋     | 332880/708933 [08:41<09:22, 668.30frames/s]\n 47%|████▋     | 335776/708933 [08:45<09:01, 688.80frames/s]\n 48%|████▊     | 337888/708933 [08:47<08:46, 704.98frames/s]\n 48%|████▊     | 340384/708933 [08:51<09:06, 674.43frames/s]\n 48%|████▊     | 343080/708933 [08:56<09:08, 667.27frames/s]\n 49%|████▉     | 345776/708933 [08:59<08:40, 697.61frames/s]\n 49%|████▉     | 347872/708933 [09:03<09:09, 656.99frames/s]\n 49%|████▉     | 350168/708933 [09:04<07:44, 772.82frames/s]\n 50%|████▉     | 352864/708933 [09:09<08:37, 688.19frames/s]\n 50%|█████     | 355360/708933 [09:12<08:00, 735.44frames/s]\n 51%|█████     | 358056/708933 [09:18<09:27, 618.08frames/s]\n 51%|█████     | 360752/708933 [09:23<09:46, 593.98frames/s]\n 51%|█████▏    | 363536/708933 [09:26<08:20, 690.44frames/s]\n 52%|█████▏    | 366536/708933 [09:30<08:13, 693.54frames/s]\n 52%|█████▏    | 369536/708933 [09:33<07:25, 761.13frames/s]\n 53%|█████▎    | 372280/708933 [09:36<06:54, 811.72frames/s]\n 53%|█████▎    | 374808/708933 [09:39<07:13, 770.67frames/s]\n 53%|█████▎    | 377416/708933 [09:45<08:27, 653.80frames/s]\n 54%|█████▎    | 380368/708933 [09:49<08:19, 657.93frames/s]\n 54%|█████▍    | 383152/708933 [09:55<08:52, 611.27frames/s]\n 54%|█████▍    | 385656/708933 [09:59<08:42, 618.14frames/s]\n 55%|█████▍    | 388656/708933 [10:02<08:02, 663.55frames/s]\n 55%|█████▌    | 390992/708933 [10:06<08:01, 660.15frames/s]\n 56%|█████▌    | 393472/708933 [10:10<07:47, 674.27frames/s]\n 56%|█████▌    | 396032/708933 [10:14<08:20, 625.69frames/s]\n 56%|█████▌    | 397952/708933 [10:17<07:48, 663.14frames/s]\n 56%|█████▋    | 400152/708933 [10:19<06:49, 754.54frames/s]\n 57%|█████▋    | 402848/708933 [10:22<06:41, 761.76frames/s]\n 57%|█████▋    | 405120/708933 [10:25<06:52, 737.07frames/s]\n 58%|█████▊    | 408048/708933 [10:29<06:43, 746.26frames/s]\n 58%|█████▊    | 410520/708933 [10:34<07:38, 650.40frames/s]\n 58%|█████▊    | 413128/708933 [10:39<08:17, 594.86frames/s]\n 59%|█████▊    | 415016/708933 [10:43<08:27, 578.83frames/s]\n 59%|█████▉    | 417480/708933 [10:47<07:58, 608.52frames/s]\n 59%|█████▉    | 419976/708933 [10:52<08:35, 560.59frames/s]\n 60%|█████▉    | 421848/708933 [10:54<08:08, 587.79frames/s]\n 60%|█████▉    | 424224/708933 [10:59<08:06, 584.64frames/s]\n 60%|██████    | 426712/708933 [11:03<08:26, 557.50frames/s]\n 61%|██████    | 429552/708933 [11:08<08:02, 579.60frames/s]\n 61%|██████    | 432240/708933 [11:13<08:24, 548.44frames/s]\n 61%|██████▏   | 434968/708933 [11:19<08:45, 521.01frames/s]\n 62%|██████▏   | 437336/708933 [11:23<08:12, 551.49frames/s]\n 62%|██████▏   | 440192/708933 [11:27<07:27, 600.71frames/s]\n 62%|██████▏   | 442504/708933 [11:30<07:16, 610.82frames/s]\n 63%|██████▎   | 443336/708933 [11:32<07:29, 590.65frames/s]\n 63%|██████▎   | 445976/708933 [11:35<06:08, 712.87frames/s]\n 63%|██████▎   | 448728/708933 [11:40<06:58, 621.03frames/s]\n 64%|██████▎   | 451624/708933 [11:45<06:53, 622.39frames/s]\n 64%|██████▍   | 454136/708933 [11:49<07:10, 592.44frames/s]\n 64%|██████▍   | 456984/708933 [11:54<07:12, 582.51frames/s]\n 65%|██████▍   | 459656/708933 [11:59<07:16, 571.14frames/s]\n 65%|██████▌   | 462112/708933 [12:03<06:57, 591.22frames/s]\n 65%|██████▌   | 464264/708933 [12:06<06:41, 608.77frames/s]\n 66%|██████▌   | 467264/708933 [12:11<06:20, 635.12frames/s]\n 66%|██████▋   | 470264/708933 [12:15<06:02, 658.20frames/s]\n 67%|██████▋   | 472696/708933 [12:19<06:01, 653.80frames/s]\n 67%|██████▋   | 475504/708933 [12:22<05:18, 731.86frames/s]\n 67%|██████▋   | 477640/708933 [12:25<05:20, 722.78frames/s]\n 68%|██████▊   | 480424/708933 [12:30<05:45, 661.62frames/s]\n 68%|██████▊   | 483344/708933 [12:34<05:47, 648.48frames/s]\n 69%|██████▊   | 486112/708933 [12:40<06:16, 591.62frames/s]\n 69%|██████▉   | 488040/708933 [12:44<06:34, 560.30frames/s]\n 69%|██████▉   | 491040/708933 [12:47<05:25, 670.02frames/s]\n 70%|██████▉   | 493024/708933 [12:50<05:38, 637.68frames/s]\n 70%|██████▉   | 494640/708933 [12:53<05:38, 632.92frames/s]\n 70%|███████   | 497360/708933 [12:56<05:08, 685.14frames/s]\n 71%|███████   | 500360/708933 [12:58<03:57, 879.47frames/s]\n 71%|███████   | 503360/708933 [12:59<03:02, 1128.85frames/s]\n 71%|███████▏  | 505120/708933 [13:01<02:59, 1135.98frames/s]\n 72%|███████▏  | 507776/708933 [13:03<02:59, 1121.26frames/s]\n 72%|███████▏  | 510416/708933 [13:05<02:47, 1186.68frames/s]\n 72%|███████▏  | 512336/708933 [13:09<03:50, 851.31frames/s] \n 73%|███████▎  | 515336/708933 [13:12<03:31, 915.90frames/s]\n 73%|███████▎  | 518336/708933 [13:14<03:05, 1025.25frames/s]\n 74%|███████▎  | 521336/708933 [13:15<02:16, 1371.57frames/s]\n 74%|███████▎  | 521336/708933 [13:30<02:16, 1371.57frames/s]\n 74%|███████▍  | 524336/708933 [13:40<09:38, 319.05frames/s] \n 74%|███████▍  | 527336/708933 [13:45<08:10, 370.46frames/s]\n 75%|███████▍  | 529328/708933 [13:48<07:12, 415.50frames/s]\n 75%|███████▍  | 530696/708933 [13:50<06:30, 456.21frames/s]\n 75%|███████▌  | 532944/708933 [13:52<05:25, 541.17frames/s]\n 75%|███████▌  | 534832/708933 [13:54<04:41, 618.86frames/s]\n 76%|███████▌  | 535520/708933 [13:55<04:38, 622.82frames/s]\n 76%|███████▌  | 538608/708933 [13:57<03:27, 821.33frames/s]\n 76%|███████▋  | 541608/708933 [14:00<03:00, 926.62frames/s]\n 77%|███████▋  | 544120/708933 [14:02<02:53, 948.56frames/s]\n 77%|███████▋  | 546720/708933 [14:05<03:00, 898.32frames/s]\n 77%|███████▋  | 549168/708933 [14:10<03:35, 742.51frames/s]\n 78%|███████▊  | 551504/708933 [14:13<03:28, 754.53frames/s]\n 78%|███████▊  | 553912/708933 [14:17<03:49, 674.49frames/s]\n 78%|███████▊  | 556320/708933 [14:20<03:29, 728.36frames/s]\n 79%|███████▉  | 559320/708933 [14:22<02:50, 878.99frames/s]\n 79%|███████▉  | 562320/708933 [14:24<02:21, 1037.61frames/s]\n 80%|███████▉  | 564672/708933 [14:28<02:41, 892.32frames/s] \n 80%|████████  | 567672/708933 [14:30<02:29, 945.02frames/s]\n 80%|████████  | 570104/708933 [14:32<02:18, 1003.97frames/s]\n 81%|████████  | 571432/708933 [14:34<02:21, 973.12frames/s] \n 81%|████████  | 573064/708933 [14:35<02:07, 1069.26frames/s]\n 81%|████████▏ | 576064/708933 [14:37<01:48, 1222.74frames/s]\n 82%|████████▏ | 578712/708933 [14:40<01:57, 1111.47frames/s]\n 82%|████████▏ | 580448/708933 [14:42<02:10, 982.61frames/s] \n 82%|████████▏ | 581912/708933 [14:43<02:04, 1020.42frames/s]\n 82%|████████▏ | 582976/708933 [14:44<01:56, 1080.68frames/s]\n 82%|████████▏ | 584776/708933 [14:45<01:40, 1230.21frames/s]\n 83%|████████▎ | 587256/708933 [14:48<01:51, 1095.74frames/s]\n 83%|████████▎ | 589896/708933 [14:52<02:20, 847.73frames/s] \n 84%|████████▎ | 592328/708933 [14:57<02:42, 717.30frames/s]\n 84%|████████▍ | 594856/708933 [15:02<03:11, 596.27frames/s]\n 84%|████████▍ | 597584/708933 [15:09<03:28, 533.71frames/s]\n 85%|████████▍ | 600352/708933 [15:13<03:18, 545.88frames/s]\n 85%|████████▌ | 602704/708933 [15:17<03:10, 557.67frames/s]\n 85%|████████▌ | 605648/708933 [15:22<03:02, 567.44frames/s]\n 86%|████████▌ | 608480/708933 [15:28<03:07, 536.08frames/s]\n 86%|████████▌ | 610128/708933 [15:32<03:10, 520.00frames/s]\n 86%|████████▋ | 612584/708933 [15:36<02:54, 552.21frames/s]\n 87%|████████▋ | 615000/708933 [15:39<02:43, 575.19frames/s]\n 87%|████████▋ | 618000/708933 [15:44<02:31, 599.36frames/s]\n 88%|████████▊ | 620968/708933 [15:50<02:35, 564.44frames/s]\n 88%|████████▊ | 623344/708933 [15:54<02:27, 578.31frames/s]\n 88%|████████▊ | 625576/708933 [15:56<02:10, 636.91frames/s]\n 89%|████████▊ | 628080/708933 [16:01<02:11, 614.40frames/s]\n 89%|████████▉ | 630944/708933 [16:06<02:09, 601.93frames/s]\n 89%|████████▉ | 633696/708933 [16:11<02:12, 565.92frames/s]\n 90%|████████▉ | 635912/708933 [16:14<02:02, 595.44frames/s]\n 90%|█████████ | 638672/708933 [16:18<01:49, 640.24frames/s]\n 90%|█████████ | 641168/708933 [16:22<01:44, 645.94frames/s]\n 91%|█████████ | 643664/708933 [16:26<01:47, 608.68frames/s]\n 91%|█████████ | 646592/708933 [16:32<01:49, 569.98frames/s]\n 92%|█████████▏| 649456/708933 [16:37<01:40, 592.61frames/s]\n 92%|█████████▏| 652160/708933 [16:41<01:36, 587.77frames/s]\n 92%|█████████▏| 654968/708933 [16:46<01:31, 589.76frames/s]\n 93%|█████████▎| 657712/708933 [16:50<01:20, 632.93frames/s]\n 93%|█████████▎| 660480/708933 [16:55<01:22, 587.17frames/s]\n 93%|█████████▎| 662272/708933 [16:57<01:12, 647.68frames/s]\n 94%|█████████▎| 664600/708933 [17:00<01:03, 694.23frames/s]\n 94%|█████████▍| 667544/708933 [17:04<01:02, 666.06frames/s]\n 95%|█████████▍| 670008/708933 [17:09<01:02, 619.48frames/s]\n 95%|█████████▍| 671816/708933 [17:11<00:56, 651.26frames/s]\n 95%|█████████▌| 674064/708933 [17:14<00:47, 731.92frames/s]\n 95%|█████████▌| 676504/708933 [17:18<00:47, 678.64frames/s]\n 96%|█████████▌| 679288/708933 [17:22<00:43, 686.82frames/s]\n 96%|█████████▌| 681984/708933 [17:26<00:41, 653.23frames/s]\n 97%|█████████▋| 684192/708933 [17:30<00:39, 632.73frames/s]\n 97%|█████████▋| 686664/708933 [17:34<00:35, 631.74frames/s]\n 97%|█████████▋| 688648/708933 [17:37<00:30, 654.41frames/s]\n97%|█████████▋| 690933/708933 [17:40<00:26, 675.65frames/s]\n97%|█████████▋| 690933/708933 [17:40<00:27, 651.65frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.33784615993499756,
        "compression_ratio": 1.3865979381443299,
        "end": 17.12,
        "id": 0,
        "no_speech_prob": 0.004263199865818024,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Good morning! Again, it's the second Coding Train livestream of this week.",
        "tokens": [
          50364,
          2205,
          2446,
          0,
          3764,
          11,
          309,
          311,
          264,
          1150,
          383,
          8616,
          28029,
          29782,
          295,
          341,
          1243,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.33784615993499756,
        "compression_ratio": 1.3865979381443299,
        "end": 22.28,
        "id": 1,
        "no_speech_prob": 0.004263199865818024,
        "seek": 0,
        "start": 17.12,
        "temperature": 0,
        "text": " So I'm really going to try to just jump right into things, as opposed to what I did yesterday,",
        "tokens": [
          51220,
          407,
          286,
          478,
          534,
          516,
          281,
          853,
          281,
          445,
          3012,
          558,
          666,
          721,
          11,
          382,
          8851,
          281,
          437,
          286,
          630,
          5186,
          11,
          51478
        ]
      },
      {
        "avg_logprob": -0.33784615993499756,
        "compression_ratio": 1.3865979381443299,
        "end": 28.88,
        "id": 2,
        "no_speech_prob": 0.004263199865818024,
        "seek": 0,
        "start": 22.28,
        "temperature": 0,
        "text": " which was spend about 45 minutes talking arbitrarily about all sorts of random topics like schedule",
        "tokens": [
          51478,
          597,
          390,
          3496,
          466,
          6905,
          2077,
          1417,
          19071,
          3289,
          466,
          439,
          7527,
          295,
          4974,
          8378,
          411,
          7567,
          51808
        ]
      },
      {
        "avg_logprob": -0.30318815666332577,
        "compression_ratio": 1.6886446886446886,
        "end": 34.64,
        "id": 3,
        "no_speech_prob": 0.035668060183525085,
        "seek": 2888,
        "start": 28.88,
        "temperature": 0,
        "text": " and that sort of thing. I do have to say something important here, which is that as many of you",
        "tokens": [
          50364,
          293,
          300,
          1333,
          295,
          551,
          13,
          286,
          360,
          362,
          281,
          584,
          746,
          1021,
          510,
          11,
          597,
          307,
          300,
          382,
          867,
          295,
          291,
          50652
        ]
      },
      {
        "avg_logprob": -0.30318815666332577,
        "compression_ratio": 1.6886446886446886,
        "end": 39.44,
        "id": 4,
        "no_speech_prob": 0.035668060183525085,
        "seek": 2888,
        "start": 34.64,
        "temperature": 0,
        "text": " are interested in, I know, I don't know whether... many of you are just the loudest voices of",
        "tokens": [
          50652,
          366,
          3102,
          294,
          11,
          286,
          458,
          11,
          286,
          500,
          380,
          458,
          1968,
          485,
          867,
          295,
          291,
          366,
          445,
          264,
          6588,
          377,
          9802,
          295,
          50892
        ]
      },
      {
        "avg_logprob": -0.30318815666332577,
        "compression_ratio": 1.6886446886446886,
        "end": 44.78,
        "id": 5,
        "no_speech_prob": 0.035668060183525085,
        "seek": 2888,
        "start": 39.44,
        "temperature": 0,
        "text": " you, are interested in more tutorials on machine learning, in particular in the browser with",
        "tokens": [
          50892,
          291,
          11,
          366,
          3102,
          294,
          544,
          17616,
          322,
          3479,
          2539,
          11,
          294,
          1729,
          294,
          264,
          11185,
          365,
          51159
        ]
      },
      {
        "avg_logprob": -0.30318815666332577,
        "compression_ratio": 1.6886446886446886,
        "end": 50.04,
        "id": 6,
        "no_speech_prob": 0.035668060183525085,
        "seek": 2888,
        "start": 44.78,
        "temperature": 0,
        "text": " TensorFlow.js. So I'm getting to that. And I'd hoped that that would be the primary topic",
        "tokens": [
          51159,
          37624,
          13,
          25530,
          13,
          407,
          286,
          478,
          1242,
          281,
          300,
          13,
          400,
          286,
          1116,
          19737,
          300,
          300,
          576,
          312,
          264,
          6194,
          4829,
          51422
        ]
      },
      {
        "avg_logprob": -0.30318815666332577,
        "compression_ratio": 1.6886446886446886,
        "end": 56.16,
        "id": 7,
        "no_speech_prob": 0.035668060183525085,
        "seek": 2888,
        "start": 50.04,
        "temperature": 0,
        "text": " of today. But yesterday I started doing some tutorials on promises, and I want to finish",
        "tokens": [
          51422,
          295,
          965,
          13,
          583,
          5186,
          286,
          1409,
          884,
          512,
          17616,
          322,
          16403,
          11,
          293,
          286,
          528,
          281,
          2413,
          51728
        ]
      },
      {
        "avg_logprob": -0.27084853914048934,
        "compression_ratio": 1.6346863468634687,
        "end": 61.16,
        "id": 8,
        "no_speech_prob": 0.00831544678658247,
        "seek": 5616,
        "start": 56.16,
        "temperature": 0,
        "text": " that sequence first, because it will lay the foundation for certain things that I will",
        "tokens": [
          50364,
          300,
          8310,
          700,
          11,
          570,
          309,
          486,
          2360,
          264,
          7030,
          337,
          1629,
          721,
          300,
          286,
          486,
          50614
        ]
      },
      {
        "avg_logprob": -0.27084853914048934,
        "compression_ratio": 1.6346863468634687,
        "end": 68.52,
        "id": 9,
        "no_speech_prob": 0.00831544678658247,
        "seek": 5616,
        "start": 61.16,
        "temperature": 0,
        "text": " need when making some examples with TensorFlow.js. For example, in particular, the async keyword",
        "tokens": [
          50614,
          643,
          562,
          1455,
          512,
          5110,
          365,
          37624,
          13,
          25530,
          13,
          1171,
          1365,
          11,
          294,
          1729,
          11,
          264,
          382,
          34015,
          20428,
          50982
        ]
      },
      {
        "avg_logprob": -0.27084853914048934,
        "compression_ratio": 1.6346863468634687,
        "end": 73,
        "id": 10,
        "no_speech_prob": 0.00831544678658247,
        "seek": 5616,
        "start": 68.52,
        "temperature": 0,
        "text": " and the await keyword. Now, something very strange has been going on here in the studio,",
        "tokens": [
          50982,
          293,
          264,
          19670,
          20428,
          13,
          823,
          11,
          746,
          588,
          5861,
          575,
          668,
          516,
          322,
          510,
          294,
          264,
          6811,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.27084853914048934,
        "compression_ratio": 1.6346863468634687,
        "end": 78.67999999999999,
        "id": 11,
        "no_speech_prob": 0.00831544678658247,
        "seek": 5616,
        "start": 73,
        "temperature": 0,
        "text": " and which I can't really explain, because I... I don't... this room gets used by other",
        "tokens": [
          51206,
          293,
          597,
          286,
          393,
          380,
          534,
          2903,
          11,
          570,
          286,
          485,
          286,
          500,
          380,
          485,
          341,
          1808,
          2170,
          1143,
          538,
          661,
          51490
        ]
      },
      {
        "avg_logprob": -0.27084853914048934,
        "compression_ratio": 1.6346863468634687,
        "end": 82.8,
        "id": 12,
        "no_speech_prob": 0.00831544678658247,
        "seek": 5616,
        "start": 78.67999999999999,
        "temperature": 0,
        "text": " people, and of course other people should use this room. And I try to, as much time",
        "tokens": [
          51490,
          561,
          11,
          293,
          295,
          1164,
          661,
          561,
          820,
          764,
          341,
          1808,
          13,
          400,
          286,
          853,
          281,
          11,
          382,
          709,
          565,
          51696
        ]
      },
      {
        "avg_logprob": -0.24476449720321164,
        "compression_ratio": 1.603448275862069,
        "end": 88.24,
        "id": 13,
        "no_speech_prob": 0.30068355798721313,
        "seek": 8280,
        "start": 82.8,
        "temperature": 0,
        "text": " as I might have, looking for my marker. Help other people make use of this room. But usually",
        "tokens": [
          50364,
          382,
          286,
          1062,
          362,
          11,
          1237,
          337,
          452,
          15247,
          13,
          10773,
          661,
          561,
          652,
          764,
          295,
          341,
          1808,
          13,
          583,
          2673,
          50636
        ]
      },
      {
        "avg_logprob": -0.24476449720321164,
        "compression_ratio": 1.603448275862069,
        "end": 93,
        "id": 14,
        "no_speech_prob": 0.30068355798721313,
        "seek": 8280,
        "start": 88.24,
        "temperature": 0,
        "text": " I hear about it, and also it's the summer, so I didn't really think. But there's a marker",
        "tokens": [
          50636,
          286,
          1568,
          466,
          309,
          11,
          293,
          611,
          309,
          311,
          264,
          4266,
          11,
          370,
          286,
          994,
          380,
          534,
          519,
          13,
          583,
          456,
          311,
          257,
          15247,
          50874
        ]
      },
      {
        "avg_logprob": -0.24476449720321164,
        "compression_ratio": 1.603448275862069,
        "end": 98.34,
        "id": 15,
        "no_speech_prob": 0.30068355798721313,
        "seek": 8280,
        "start": 93,
        "temperature": 0,
        "text": " down here. Is this it? Strangely, the whiteboard was erased. It actually had some other writing",
        "tokens": [
          50874,
          760,
          510,
          13,
          1119,
          341,
          309,
          30,
          8251,
          656,
          736,
          11,
          264,
          2418,
          3787,
          390,
          38359,
          13,
          467,
          767,
          632,
          512,
          661,
          3579,
          51141
        ]
      },
      {
        "avg_logprob": -0.24476449720321164,
        "compression_ratio": 1.603448275862069,
        "end": 101.5,
        "id": 16,
        "no_speech_prob": 0.30068355798721313,
        "seek": 8280,
        "start": 98.34,
        "temperature": 0,
        "text": " on it. I erased it before I started live streaming. I just got to check to make sure everything",
        "tokens": [
          51141,
          322,
          309,
          13,
          286,
          38359,
          309,
          949,
          286,
          1409,
          1621,
          11791,
          13,
          286,
          445,
          658,
          281,
          1520,
          281,
          652,
          988,
          1203,
          51299
        ]
      },
      {
        "avg_logprob": -0.24476449720321164,
        "compression_ratio": 1.603448275862069,
        "end": 109.92,
        "id": 17,
        "no_speech_prob": 0.30068355798721313,
        "seek": 8280,
        "start": 101.5,
        "temperature": 0,
        "text": " looks and sounds okay. Ding choo choo. Nobody seems to be complaining. So yeah. All right.",
        "tokens": [
          51299,
          1542,
          293,
          3263,
          1392,
          13,
          20558,
          1586,
          78,
          1586,
          78,
          13,
          9297,
          2544,
          281,
          312,
          20740,
          13,
          407,
          1338,
          13,
          1057,
          558,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.2257588360760663,
        "compression_ratio": 1.5402298850574712,
        "end": 115.6,
        "id": 18,
        "no_speech_prob": 0.004829635377973318,
        "seek": 10992,
        "start": 109.92,
        "temperature": 0,
        "text": " So I don't know who was in here yesterday. If you are watching this and you were in here",
        "tokens": [
          50364,
          407,
          286,
          500,
          380,
          458,
          567,
          390,
          294,
          510,
          5186,
          13,
          759,
          291,
          366,
          1976,
          341,
          293,
          291,
          645,
          294,
          510,
          50648
        ]
      },
      {
        "avg_logprob": -0.2257588360760663,
        "compression_ratio": 1.5402298850574712,
        "end": 122.64,
        "id": 19,
        "no_speech_prob": 0.004829635377973318,
        "seek": 10992,
        "start": 115.6,
        "temperature": 0,
        "text": " yesterday, please send me a message. So let me make a list of what I want to cover today.",
        "tokens": [
          50648,
          5186,
          11,
          1767,
          2845,
          385,
          257,
          3636,
          13,
          407,
          718,
          385,
          652,
          257,
          1329,
          295,
          437,
          286,
          528,
          281,
          2060,
          965,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2257588360760663,
        "compression_ratio": 1.5402298850574712,
        "end": 131.4,
        "id": 20,
        "no_speech_prob": 0.004829635377973318,
        "seek": 10992,
        "start": 122.64,
        "temperature": 0,
        "text": " So yesterday I just did the basic, you know, what is a promise? And I looked at it in the",
        "tokens": [
          51000,
          407,
          5186,
          286,
          445,
          630,
          264,
          3875,
          11,
          291,
          458,
          11,
          437,
          307,
          257,
          6228,
          30,
          400,
          286,
          2956,
          412,
          309,
          294,
          264,
          51438
        ]
      },
      {
        "avg_logprob": -0.30755568063387306,
        "compression_ratio": 1.6359447004608294,
        "end": 141.44,
        "id": 21,
        "no_speech_prob": 0.21731629967689514,
        "seek": 13140,
        "start": 131.4,
        "temperature": 0,
        "text": " context of fetch. So using the fetch function to retrieve data from a URL and resolving",
        "tokens": [
          50364,
          4319,
          295,
          23673,
          13,
          407,
          1228,
          264,
          23673,
          2445,
          281,
          30254,
          1412,
          490,
          257,
          12905,
          293,
          49940,
          50866
        ]
      },
      {
        "avg_logprob": -0.30755568063387306,
        "compression_ratio": 1.6359447004608294,
        "end": 145.68,
        "id": 22,
        "no_speech_prob": 0.21731629967689514,
        "seek": 13140,
        "start": 141.44,
        "temperature": 0,
        "text": " the promise when the data comes in. That might not have been the best way to explain that,",
        "tokens": [
          50866,
          264,
          6228,
          562,
          264,
          1412,
          1487,
          294,
          13,
          663,
          1062,
          406,
          362,
          668,
          264,
          1151,
          636,
          281,
          2903,
          300,
          11,
          51078
        ]
      },
      {
        "avg_logprob": -0.30755568063387306,
        "compression_ratio": 1.6359447004608294,
        "end": 152.14000000000001,
        "id": 23,
        "no_speech_prob": 0.21731629967689514,
        "seek": 13140,
        "start": 145.68,
        "temperature": 0,
        "text": " but so be it. So and then I went off, off and off and off and off, trying to explain",
        "tokens": [
          51078,
          457,
          370,
          312,
          309,
          13,
          407,
          293,
          550,
          286,
          1437,
          766,
          11,
          766,
          293,
          766,
          293,
          766,
          293,
          766,
          11,
          1382,
          281,
          2903,
          51401
        ]
      },
      {
        "avg_logprob": -0.30755568063387306,
        "compression_ratio": 1.6359447004608294,
        "end": 157.28,
        "id": 24,
        "no_speech_prob": 0.21731629967689514,
        "seek": 13140,
        "start": 152.14000000000001,
        "temperature": 0,
        "text": " promise.all. And so many things I got wrong. Number one is I just kept saying promises.all,",
        "tokens": [
          51401,
          6228,
          13,
          336,
          13,
          400,
          370,
          867,
          721,
          286,
          658,
          2085,
          13,
          5118,
          472,
          307,
          286,
          445,
          4305,
          1566,
          16403,
          13,
          336,
          11,
          51658
        ]
      },
      {
        "avg_logprob": -0.24779183850316944,
        "compression_ratio": 1.8708708708708708,
        "end": 161.88,
        "id": 25,
        "no_speech_prob": 0.20179538428783417,
        "seek": 15728,
        "start": 157.28,
        "temperature": 0,
        "text": " and it's promise.all. Number two is I got into this thing where I was like, I have an",
        "tokens": [
          50364,
          293,
          309,
          311,
          6228,
          13,
          336,
          13,
          5118,
          732,
          307,
          286,
          658,
          666,
          341,
          551,
          689,
          286,
          390,
          411,
          11,
          286,
          362,
          364,
          50594
        ]
      },
      {
        "avg_logprob": -0.24779183850316944,
        "compression_ratio": 1.8708708708708708,
        "end": 166.48,
        "id": 26,
        "no_speech_prob": 0.20179538428783417,
        "seek": 15728,
        "start": 161.88,
        "temperature": 0,
        "text": " array of promises, and then I need to get a new array of promises from that array of",
        "tokens": [
          50594,
          10225,
          295,
          16403,
          11,
          293,
          550,
          286,
          643,
          281,
          483,
          257,
          777,
          10225,
          295,
          16403,
          490,
          300,
          10225,
          295,
          50824
        ]
      },
      {
        "avg_logprob": -0.24779183850316944,
        "compression_ratio": 1.8708708708708708,
        "end": 169.72,
        "id": 27,
        "no_speech_prob": 0.20179538428783417,
        "seek": 15728,
        "start": 166.48,
        "temperature": 0,
        "text": " promises. And there was this whole extra sequence. And then I used a loop and I tried to use",
        "tokens": [
          50824,
          16403,
          13,
          400,
          456,
          390,
          341,
          1379,
          2857,
          8310,
          13,
          400,
          550,
          286,
          1143,
          257,
          6367,
          293,
          286,
          3031,
          281,
          764,
          50986
        ]
      },
      {
        "avg_logprob": -0.24779183850316944,
        "compression_ratio": 1.8708708708708708,
        "end": 173.36,
        "id": 28,
        "no_speech_prob": 0.20179538428783417,
        "seek": 15728,
        "start": 169.72,
        "temperature": 0,
        "text": " the map function. It was kind of a mess. It was good. It was really good for me. I learned",
        "tokens": [
          50986,
          264,
          4471,
          2445,
          13,
          467,
          390,
          733,
          295,
          257,
          2082,
          13,
          467,
          390,
          665,
          13,
          467,
          390,
          534,
          665,
          337,
          385,
          13,
          286,
          3264,
          51168
        ]
      },
      {
        "avg_logprob": -0.24779183850316944,
        "compression_ratio": 1.8708708708708708,
        "end": 177.92000000000002,
        "id": 29,
        "no_speech_prob": 0.20179538428783417,
        "seek": 15728,
        "start": 173.36,
        "temperature": 0,
        "text": " a lot. And I also learned what people think about that, the way that I code, which is",
        "tokens": [
          51168,
          257,
          688,
          13,
          400,
          286,
          611,
          3264,
          437,
          561,
          519,
          466,
          300,
          11,
          264,
          636,
          300,
          286,
          3089,
          11,
          597,
          307,
          51396
        ]
      },
      {
        "avg_logprob": -0.24779183850316944,
        "compression_ratio": 1.8708708708708708,
        "end": 181.48,
        "id": 30,
        "no_speech_prob": 0.20179538428783417,
        "seek": 15728,
        "start": 177.92000000000002,
        "temperature": 0,
        "text": " often that's terrible. Why are you doing it that way? And then there's some people who",
        "tokens": [
          51396,
          2049,
          300,
          311,
          6237,
          13,
          1545,
          366,
          291,
          884,
          309,
          300,
          636,
          30,
          400,
          550,
          456,
          311,
          512,
          561,
          567,
          51574
        ]
      },
      {
        "avg_logprob": -0.24779183850316944,
        "compression_ratio": 1.8708708708708708,
        "end": 184.84,
        "id": 31,
        "no_speech_prob": 0.20179538428783417,
        "seek": 15728,
        "start": 181.48,
        "temperature": 0,
        "text": " have some other feedback like, yeah, you know, maybe it's not the best, but it kind of explains",
        "tokens": [
          51574,
          362,
          512,
          661,
          5824,
          411,
          11,
          1338,
          11,
          291,
          458,
          11,
          1310,
          309,
          311,
          406,
          264,
          1151,
          11,
          457,
          309,
          733,
          295,
          13948,
          51742
        ]
      },
      {
        "avg_logprob": -0.25613819974140056,
        "compression_ratio": 1.6682692307692308,
        "end": 191.04,
        "id": 32,
        "no_speech_prob": 0.2597961127758026,
        "seek": 18484,
        "start": 184.84,
        "temperature": 0,
        "text": " it. It works. So anyway, I'm going to take a mulligan on that. But I've thought about",
        "tokens": [
          50364,
          309,
          13,
          467,
          1985,
          13,
          407,
          4033,
          11,
          286,
          478,
          516,
          281,
          747,
          257,
          275,
          858,
          9552,
          322,
          300,
          13,
          583,
          286,
          600,
          1194,
          466,
          50674
        ]
      },
      {
        "avg_logprob": -0.25613819974140056,
        "compression_ratio": 1.6682692307692308,
        "end": 194.88,
        "id": 33,
        "no_speech_prob": 0.2597961127758026,
        "seek": 18484,
        "start": 191.04,
        "temperature": 0,
        "text": " this and I actually did some coding this morning before I came in here. So what I'm going to",
        "tokens": [
          50674,
          341,
          293,
          286,
          767,
          630,
          512,
          17720,
          341,
          2446,
          949,
          286,
          1361,
          294,
          510,
          13,
          407,
          437,
          286,
          478,
          516,
          281,
          50866
        ]
      },
      {
        "avg_logprob": -0.25613819974140056,
        "compression_ratio": 1.6682692307692308,
        "end": 200.48000000000002,
        "id": 34,
        "no_speech_prob": 0.2597961127758026,
        "seek": 18484,
        "start": 194.88,
        "temperature": 0,
        "text": " do next, I'm going to get to promise.all, but next I'm going to look at how to make",
        "tokens": [
          50866,
          360,
          958,
          11,
          286,
          478,
          516,
          281,
          483,
          281,
          6228,
          13,
          336,
          11,
          457,
          958,
          286,
          478,
          516,
          281,
          574,
          412,
          577,
          281,
          652,
          51146
        ]
      },
      {
        "avg_logprob": -0.25613819974140056,
        "compression_ratio": 1.6682692307692308,
        "end": 209.6,
        "id": 35,
        "no_speech_prob": 0.2597961127758026,
        "seek": 18484,
        "start": 200.48000000000002,
        "temperature": 0,
        "text": " your own promise. I promise you. How to, I wish I had, I have my keyboard over here.",
        "tokens": [
          51146,
          428,
          1065,
          6228,
          13,
          286,
          6228,
          291,
          13,
          1012,
          281,
          11,
          286,
          3172,
          286,
          632,
          11,
          286,
          362,
          452,
          10186,
          670,
          510,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.27817437501080267,
        "compression_ratio": 1.6567164179104477,
        "end": 214.96,
        "id": 36,
        "no_speech_prob": 0.05581839010119438,
        "seek": 20960,
        "start": 210.51999999999998,
        "temperature": 0,
        "text": " If I had really thought better of it, I would have, I would have come in with some promise",
        "tokens": [
          50410,
          759,
          286,
          632,
          534,
          1194,
          1101,
          295,
          309,
          11,
          286,
          576,
          362,
          11,
          286,
          576,
          362,
          808,
          294,
          365,
          512,
          6228,
          50632
        ]
      },
      {
        "avg_logprob": -0.27817437501080267,
        "compression_ratio": 1.6567164179104477,
        "end": 224.2,
        "id": 37,
        "no_speech_prob": 0.05581839010119438,
        "seek": 20960,
        "start": 214.96,
        "temperature": 0,
        "text": " related music, maybe later. How to make your own promise. I think the joke I made yesterday,",
        "tokens": [
          50632,
          4077,
          1318,
          11,
          1310,
          1780,
          13,
          1012,
          281,
          652,
          428,
          1065,
          6228,
          13,
          286,
          519,
          264,
          7647,
          286,
          1027,
          5186,
          11,
          51094
        ]
      },
      {
        "avg_logprob": -0.27817437501080267,
        "compression_ratio": 1.6567164179104477,
        "end": 230.07999999999998,
        "id": 38,
        "no_speech_prob": 0.05581839010119438,
        "seek": 20960,
        "start": 224.2,
        "temperature": 0,
        "text": " is this still, am I still on the board? Was that if I title a YouTube video or how to",
        "tokens": [
          51094,
          307,
          341,
          920,
          11,
          669,
          286,
          920,
          322,
          264,
          3150,
          30,
          3027,
          300,
          498,
          286,
          4876,
          257,
          3088,
          960,
          420,
          577,
          281,
          51388
        ]
      },
      {
        "avg_logprob": -0.27817437501080267,
        "compression_ratio": 1.6567164179104477,
        "end": 234.12,
        "id": 39,
        "no_speech_prob": 0.05581839010119438,
        "seek": 20960,
        "start": 230.07999999999998,
        "temperature": 0,
        "text": " keep your promises, maybe like people who are looking for self-help videos will come",
        "tokens": [
          51388,
          1066,
          428,
          16403,
          11,
          1310,
          411,
          561,
          567,
          366,
          1237,
          337,
          2698,
          12,
          37451,
          2145,
          486,
          808,
          51590
        ]
      },
      {
        "avg_logprob": -0.27817437501080267,
        "compression_ratio": 1.6567164179104477,
        "end": 239.42,
        "id": 40,
        "no_speech_prob": 0.05581839010119438,
        "seek": 20960,
        "start": 234.12,
        "temperature": 0,
        "text": " and find my channel and then they'll decide they want to learn to code. What is a promise",
        "tokens": [
          51590,
          293,
          915,
          452,
          2269,
          293,
          550,
          436,
          603,
          4536,
          436,
          528,
          281,
          1466,
          281,
          3089,
          13,
          708,
          307,
          257,
          6228,
          51855
        ]
      },
      {
        "avg_logprob": -0.23778522491455079,
        "compression_ratio": 1.6359447004608294,
        "end": 244.57999999999998,
        "id": 41,
        "no_speech_prob": 0.008315681479871273,
        "seek": 23942,
        "start": 239.5,
        "temperature": 0,
        "text": " fetch? How to make your promise. Okay. That's a weird thing that I wrote. How to make your",
        "tokens": [
          50368,
          23673,
          30,
          1012,
          281,
          652,
          428,
          6228,
          13,
          1033,
          13,
          663,
          311,
          257,
          3657,
          551,
          300,
          286,
          4114,
          13,
          1012,
          281,
          652,
          428,
          50622
        ]
      },
      {
        "avg_logprob": -0.23778522491455079,
        "compression_ratio": 1.6359447004608294,
        "end": 249.7,
        "id": 42,
        "no_speech_prob": 0.008315681479871273,
        "seek": 23942,
        "start": 244.57999999999998,
        "temperature": 0,
        "text": " promise. I don't know how I feel about that, but I'll leave it there. It's a little bit",
        "tokens": [
          50622,
          6228,
          13,
          286,
          500,
          380,
          458,
          577,
          286,
          841,
          466,
          300,
          11,
          457,
          286,
          603,
          1856,
          309,
          456,
          13,
          467,
          311,
          257,
          707,
          857,
          50878
        ]
      },
      {
        "avg_logprob": -0.23778522491455079,
        "compression_ratio": 1.6359447004608294,
        "end": 260.88,
        "id": 43,
        "no_speech_prob": 0.008315681479871273,
        "seek": 23942,
        "start": 249.7,
        "temperature": 0,
        "text": " weird, but fine. Then I want to look at async and await. And this is really what's often",
        "tokens": [
          50878,
          3657,
          11,
          457,
          2489,
          13,
          1396,
          286,
          528,
          281,
          574,
          412,
          382,
          34015,
          293,
          19670,
          13,
          400,
          341,
          307,
          534,
          437,
          311,
          2049,
          51437
        ]
      },
      {
        "avg_logprob": -0.23778522491455079,
        "compression_ratio": 1.6359447004608294,
        "end": 266.15999999999997,
        "id": 44,
        "no_speech_prob": 0.008315681479871273,
        "seek": 23942,
        "start": 260.88,
        "temperature": 0,
        "text": " referred to as syntax sugar. So there will be no new concepts, but there will be a less",
        "tokens": [
          51437,
          10839,
          281,
          382,
          28431,
          5076,
          13,
          407,
          456,
          486,
          312,
          572,
          777,
          10392,
          11,
          457,
          456,
          486,
          312,
          257,
          1570,
          51701
        ]
      },
      {
        "avg_logprob": -0.2352299454188583,
        "compression_ratio": 1.6428571428571428,
        "end": 272.32000000000005,
        "id": 45,
        "no_speech_prob": 0.14607489109039307,
        "seek": 26616,
        "start": 266.16,
        "temperature": 0,
        "text": " verbose way of writing a function that returns a promise using async and await. And then",
        "tokens": [
          50364,
          9595,
          541,
          636,
          295,
          3579,
          257,
          2445,
          300,
          11247,
          257,
          6228,
          1228,
          382,
          34015,
          293,
          19670,
          13,
          400,
          550,
          50672
        ]
      },
      {
        "avg_logprob": -0.2352299454188583,
        "compression_ratio": 1.6428571428571428,
        "end": 280.64000000000004,
        "id": 46,
        "no_speech_prob": 0.14607489109039307,
        "seek": 26616,
        "start": 272.32000000000005,
        "temperature": 0,
        "text": " the last piece of this, I think will be promise.all. So this is my new plan. If I can get through",
        "tokens": [
          50672,
          264,
          1036,
          2522,
          295,
          341,
          11,
          286,
          519,
          486,
          312,
          6228,
          13,
          336,
          13,
          407,
          341,
          307,
          452,
          777,
          1393,
          13,
          759,
          286,
          393,
          483,
          807,
          51088
        ]
      },
      {
        "avg_logprob": -0.2352299454188583,
        "compression_ratio": 1.6428571428571428,
        "end": 285.68,
        "id": 47,
        "no_speech_prob": 0.14607489109039307,
        "seek": 26616,
        "start": 280.64000000000004,
        "temperature": 0,
        "text": " all of this today, I'll be amazed. If I could get through all of this today and start to",
        "tokens": [
          51088,
          439,
          295,
          341,
          965,
          11,
          286,
          603,
          312,
          20507,
          13,
          759,
          286,
          727,
          483,
          807,
          439,
          295,
          341,
          965,
          293,
          722,
          281,
          51340
        ]
      },
      {
        "avg_logprob": -0.2352299454188583,
        "compression_ratio": 1.6428571428571428,
        "end": 293.24,
        "id": 48,
        "no_speech_prob": 0.14607489109039307,
        "seek": 26616,
        "start": 285.68,
        "temperature": 0,
        "text": " talk about TensorFlow.js, that will be a miracle. But have no fear. Whatever I don't get to,",
        "tokens": [
          51340,
          751,
          466,
          37624,
          13,
          25530,
          11,
          300,
          486,
          312,
          257,
          14660,
          13,
          583,
          362,
          572,
          4240,
          13,
          8541,
          286,
          500,
          380,
          483,
          281,
          11,
          51718
        ]
      },
      {
        "avg_logprob": -0.2409244453819999,
        "compression_ratio": 1.7532467532467533,
        "end": 297.76,
        "id": 49,
        "no_speech_prob": 0.13292349874973297,
        "seek": 29324,
        "start": 293.24,
        "temperature": 0,
        "text": " I will get to next time. I am here every week throughout the summer. I did say yesterday",
        "tokens": [
          50364,
          286,
          486,
          483,
          281,
          958,
          565,
          13,
          286,
          669,
          510,
          633,
          1243,
          3710,
          264,
          4266,
          13,
          286,
          630,
          584,
          5186,
          50590
        ]
      },
      {
        "avg_logprob": -0.2409244453819999,
        "compression_ratio": 1.7532467532467533,
        "end": 302.72,
        "id": 50,
        "no_speech_prob": 0.13292349874973297,
        "seek": 29324,
        "start": 297.76,
        "temperature": 0,
        "text": " that I was going to do twice a week live streams, and that's sort of true. But then I started",
        "tokens": [
          50590,
          300,
          286,
          390,
          516,
          281,
          360,
          6091,
          257,
          1243,
          1621,
          15842,
          11,
          293,
          300,
          311,
          1333,
          295,
          2074,
          13,
          583,
          550,
          286,
          1409,
          50838
        ]
      },
      {
        "avg_logprob": -0.2409244453819999,
        "compression_ratio": 1.7532467532467533,
        "end": 307.8,
        "id": 51,
        "no_speech_prob": 0.13292349874973297,
        "seek": 29324,
        "start": 302.72,
        "temperature": 0,
        "text": " looking at the calendar and there's a lot going on. And also, here I said I was going",
        "tokens": [
          50838,
          1237,
          412,
          264,
          12183,
          293,
          456,
          311,
          257,
          688,
          516,
          322,
          13,
          400,
          611,
          11,
          510,
          286,
          848,
          286,
          390,
          516,
          51092
        ]
      },
      {
        "avg_logprob": -0.2409244453819999,
        "compression_ratio": 1.7532467532467533,
        "end": 311.56,
        "id": 52,
        "no_speech_prob": 0.13292349874973297,
        "seek": 29324,
        "start": 307.8,
        "temperature": 0,
        "text": " to get started writing the material, and now I'm just rambling. But one thing I want to",
        "tokens": [
          51092,
          281,
          483,
          1409,
          3579,
          264,
          2527,
          11,
          293,
          586,
          286,
          478,
          445,
          367,
          19391,
          13,
          583,
          472,
          551,
          286,
          528,
          281,
          51280
        ]
      },
      {
        "avg_logprob": -0.2409244453819999,
        "compression_ratio": 1.7532467532467533,
        "end": 316.28000000000003,
        "id": 53,
        "no_speech_prob": 0.13292349874973297,
        "seek": 29324,
        "start": 311.56,
        "temperature": 0,
        "text": " say is that I think, and I'm sorry for using my YouTube channel as a personal therapy session",
        "tokens": [
          51280,
          584,
          307,
          300,
          286,
          519,
          11,
          293,
          286,
          478,
          2597,
          337,
          1228,
          452,
          3088,
          2269,
          382,
          257,
          2973,
          9492,
          5481,
          51516
        ]
      },
      {
        "avg_logprob": -0.2409244453819999,
        "compression_ratio": 1.7532467532467533,
        "end": 321.44,
        "id": 54,
        "no_speech_prob": 0.13292349874973297,
        "seek": 29324,
        "start": 316.28000000000003,
        "temperature": 0,
        "text": " for myself, but I'm realizing that there are some things I really want to accomplish this",
        "tokens": [
          51516,
          337,
          2059,
          11,
          457,
          286,
          478,
          16734,
          300,
          456,
          366,
          512,
          721,
          286,
          534,
          528,
          281,
          9021,
          341,
          51774
        ]
      },
      {
        "avg_logprob": -0.30230556445175344,
        "compression_ratio": 1.5972850678733033,
        "end": 336.08,
        "id": 55,
        "no_speech_prob": 0.14032667875289917,
        "seek": 32144,
        "start": 321.44,
        "temperature": 0,
        "text": " summer. Two of the, these are the things. I really want to, I really want to have a",
        "tokens": [
          50364,
          4266,
          13,
          4453,
          295,
          264,
          11,
          613,
          366,
          264,
          721,
          13,
          286,
          534,
          528,
          281,
          11,
          286,
          534,
          528,
          281,
          362,
          257,
          51096
        ]
      },
      {
        "avg_logprob": -0.30230556445175344,
        "compression_ratio": 1.5972850678733033,
        "end": 342.12,
        "id": 56,
        "no_speech_prob": 0.14032667875289917,
        "seek": 32144,
        "start": 336.08,
        "temperature": 0,
        "text": " second edition of this book out. And a version of it within JavaScript. So right now, this",
        "tokens": [
          51096,
          1150,
          11377,
          295,
          341,
          1446,
          484,
          13,
          400,
          257,
          3037,
          295,
          309,
          1951,
          15778,
          13,
          407,
          558,
          586,
          11,
          341,
          51398
        ]
      },
      {
        "avg_logprob": -0.30230556445175344,
        "compression_ratio": 1.5972850678733033,
        "end": 347.88,
        "id": 57,
        "no_speech_prob": 0.14032667875289917,
        "seek": 32144,
        "start": 342.12,
        "temperature": 0,
        "text": " book, The Nature of Code, is written in Java using the processing programming environment.",
        "tokens": [
          51398,
          1446,
          11,
          440,
          20159,
          295,
          15549,
          11,
          307,
          3720,
          294,
          10745,
          1228,
          264,
          9007,
          9410,
          2823,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.30230556445175344,
        "compression_ratio": 1.5972850678733033,
        "end": 351.04,
        "id": 58,
        "no_speech_prob": 0.14032667875289917,
        "seek": 32144,
        "start": 347.88,
        "temperature": 0,
        "text": " I have many updates that I've actually made to it, but I've just never gotten them onto",
        "tokens": [
          51686,
          286,
          362,
          867,
          9205,
          300,
          286,
          600,
          767,
          1027,
          281,
          309,
          11,
          457,
          286,
          600,
          445,
          1128,
          5768,
          552,
          3911,
          51844
        ]
      },
      {
        "avg_logprob": -0.23602676391601562,
        "compression_ratio": 1.7313915857605178,
        "end": 354.92,
        "id": 59,
        "no_speech_prob": 0.019716354086995125,
        "seek": 35104,
        "start": 351.04,
        "temperature": 0,
        "text": " the website and into the print version of the book. So I want to make that happen. I",
        "tokens": [
          50364,
          264,
          3144,
          293,
          666,
          264,
          4482,
          3037,
          295,
          264,
          1446,
          13,
          407,
          286,
          528,
          281,
          652,
          300,
          1051,
          13,
          286,
          50558
        ]
      },
      {
        "avg_logprob": -0.23602676391601562,
        "compression_ratio": 1.7313915857605178,
        "end": 360.08000000000004,
        "id": 60,
        "no_speech_prob": 0.019716354086995125,
        "seek": 35104,
        "start": 354.92,
        "temperature": 0,
        "text": " want to add a new chapter, which is about neuroevolution. And then I want to, once that's",
        "tokens": [
          50558,
          528,
          281,
          909,
          257,
          777,
          7187,
          11,
          597,
          307,
          466,
          16499,
          13379,
          3386,
          13,
          400,
          550,
          286,
          528,
          281,
          11,
          1564,
          300,
          311,
          50816
        ]
      },
      {
        "avg_logprob": -0.23602676391601562,
        "compression_ratio": 1.7313915857605178,
        "end": 364.84000000000003,
        "id": 61,
        "no_speech_prob": 0.019716354086995125,
        "seek": 35104,
        "start": 360.08000000000004,
        "temperature": 0,
        "text": " done, have a JavaScript version of the book. And if I'm live streaming all the time, I'll",
        "tokens": [
          50816,
          1096,
          11,
          362,
          257,
          15778,
          3037,
          295,
          264,
          1446,
          13,
          400,
          498,
          286,
          478,
          1621,
          11791,
          439,
          264,
          565,
          11,
          286,
          603,
          51054
        ]
      },
      {
        "avg_logprob": -0.23602676391601562,
        "compression_ratio": 1.7313915857605178,
        "end": 369.56,
        "id": 62,
        "no_speech_prob": 0.019716354086995125,
        "seek": 35104,
        "start": 364.84000000000003,
        "temperature": 0,
        "text": " never have any time to work on this. So number one is, who wants to help me with this? On",
        "tokens": [
          51054,
          1128,
          362,
          604,
          565,
          281,
          589,
          322,
          341,
          13,
          407,
          1230,
          472,
          307,
          11,
          567,
          2738,
          281,
          854,
          385,
          365,
          341,
          30,
          1282,
          51290
        ]
      },
      {
        "avg_logprob": -0.23602676391601562,
        "compression_ratio": 1.7313915857605178,
        "end": 373.28000000000003,
        "id": 63,
        "no_speech_prob": 0.019716354086995125,
        "seek": 35104,
        "start": 369.56,
        "temperature": 0,
        "text": " the one hand, I just kind of need to go off and work on it. But if you have some clever",
        "tokens": [
          51290,
          264,
          472,
          1011,
          11,
          286,
          445,
          733,
          295,
          643,
          281,
          352,
          766,
          293,
          589,
          322,
          309,
          13,
          583,
          498,
          291,
          362,
          512,
          13494,
          51476
        ]
      },
      {
        "avg_logprob": -0.23602676391601562,
        "compression_ratio": 1.7313915857605178,
        "end": 379.68,
        "id": 64,
        "no_speech_prob": 0.019716354086995125,
        "seek": 35104,
        "start": 373.28000000000003,
        "temperature": 0,
        "text": " ideas or want to look through my various GitHub repositories and help, I'm open to that. And",
        "tokens": [
          51476,
          3487,
          420,
          528,
          281,
          574,
          807,
          452,
          3683,
          23331,
          22283,
          2083,
          293,
          854,
          11,
          286,
          478,
          1269,
          281,
          300,
          13,
          400,
          51796
        ]
      },
      {
        "avg_logprob": -0.25487984551323783,
        "compression_ratio": 1.6199376947040498,
        "end": 384.8,
        "id": 65,
        "no_speech_prob": 0.031615253537893295,
        "seek": 37968,
        "start": 379.68,
        "temperature": 0,
        "text": " then I think that I need to, at some point, limit myself as much to focus, make sure I",
        "tokens": [
          50364,
          550,
          286,
          519,
          300,
          286,
          643,
          281,
          11,
          412,
          512,
          935,
          11,
          4948,
          2059,
          382,
          709,
          281,
          1879,
          11,
          652,
          988,
          286,
          50620
        ]
      },
      {
        "avg_logprob": -0.25487984551323783,
        "compression_ratio": 1.6199376947040498,
        "end": 389.64,
        "id": 66,
        "no_speech_prob": 0.031615253537893295,
        "seek": 37968,
        "start": 384.8,
        "temperature": 0,
        "text": " work. So keep me honest here. So this is the number one. And the other thing is, and let's",
        "tokens": [
          50620,
          589,
          13,
          407,
          1066,
          385,
          3245,
          510,
          13,
          407,
          341,
          307,
          264,
          1230,
          472,
          13,
          400,
          264,
          661,
          551,
          307,
          11,
          293,
          718,
          311,
          50862
        ]
      },
      {
        "avg_logprob": -0.25487984551323783,
        "compression_ratio": 1.6199376947040498,
        "end": 394,
        "id": 67,
        "no_speech_prob": 0.031615253537893295,
        "seek": 37968,
        "start": 389.64,
        "temperature": 0,
        "text": " see if I can get there now. The new URL, I haven't gotten HTTPS working yet. So I need",
        "tokens": [
          50862,
          536,
          498,
          286,
          393,
          483,
          456,
          586,
          13,
          440,
          777,
          12905,
          11,
          286,
          2378,
          380,
          5768,
          11751,
          51,
          6273,
          1364,
          1939,
          13,
          407,
          286,
          643,
          51080
        ]
      },
      {
        "avg_logprob": -0.25487984551323783,
        "compression_ratio": 1.6199376947040498,
        "end": 400.64,
        "id": 68,
        "no_speech_prob": 0.031615253537893295,
        "seek": 37968,
        "start": 394,
        "temperature": 0,
        "text": " to get HTTPS working for this domain. But ml5js, which is a friendly machine learning",
        "tokens": [
          51080,
          281,
          483,
          11751,
          51,
          6273,
          1364,
          337,
          341,
          9274,
          13,
          583,
          23271,
          20,
          25530,
          11,
          597,
          307,
          257,
          9208,
          3479,
          2539,
          51412
        ]
      },
      {
        "avg_logprob": -0.25487984551323783,
        "compression_ratio": 1.6199376947040498,
        "end": 405.16,
        "id": 69,
        "no_speech_prob": 0.031615253537893295,
        "seek": 37968,
        "start": 400.64,
        "temperature": 0,
        "text": " library written in JavaScript built on top of TensorFlow.js. This is a project that I",
        "tokens": [
          51412,
          6405,
          3720,
          294,
          15778,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          13,
          639,
          307,
          257,
          1716,
          300,
          286,
          51638
        ]
      },
      {
        "avg_logprob": -0.25487984551323783,
        "compression_ratio": 1.6199376947040498,
        "end": 409.04,
        "id": 70,
        "no_speech_prob": 0.031615253537893295,
        "seek": 37968,
        "start": 405.16,
        "temperature": 0,
        "text": " would like to spend a lot of time working on. The good news about this is, this has",
        "tokens": [
          51638,
          576,
          411,
          281,
          3496,
          257,
          688,
          295,
          565,
          1364,
          322,
          13,
          440,
          665,
          2583,
          466,
          341,
          307,
          11,
          341,
          575,
          51832
        ]
      },
      {
        "avg_logprob": -0.2633601917940028,
        "compression_ratio": 1.5701357466063348,
        "end": 414.28000000000003,
        "id": 71,
        "no_speech_prob": 0.031143207103013992,
        "seek": 40904,
        "start": 409.12,
        "temperature": 0,
        "text": " a whole group of people who are developing it. And it's an open source project. And you",
        "tokens": [
          50368,
          257,
          1379,
          1594,
          295,
          561,
          567,
          366,
          6416,
          309,
          13,
          400,
          309,
          311,
          364,
          1269,
          4009,
          1716,
          13,
          400,
          291,
          50626
        ]
      },
      {
        "avg_logprob": -0.2633601917940028,
        "compression_ratio": 1.5701357466063348,
        "end": 419.76000000000005,
        "id": 72,
        "no_speech_prob": 0.031143207103013992,
        "seek": 40904,
        "start": 414.28000000000003,
        "temperature": 0,
        "text": " can see some of them here. People who are contributing to this project. So this is,",
        "tokens": [
          50626,
          393,
          536,
          512,
          295,
          552,
          510,
          13,
          3432,
          567,
          366,
          19270,
          281,
          341,
          1716,
          13,
          407,
          341,
          307,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.2633601917940028,
        "compression_ratio": 1.5701357466063348,
        "end": 425.48,
        "id": 73,
        "no_speech_prob": 0.031143207103013992,
        "seek": 40904,
        "start": 419.76000000000005,
        "temperature": 0,
        "text": " even if I broke my other elbow and stopped working this summer, this would still happen.",
        "tokens": [
          50900,
          754,
          498,
          286,
          6902,
          452,
          661,
          18507,
          293,
          5936,
          1364,
          341,
          4266,
          11,
          341,
          576,
          920,
          1051,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2633601917940028,
        "compression_ratio": 1.5701357466063348,
        "end": 430.92,
        "id": 74,
        "no_speech_prob": 0.031143207103013992,
        "seek": 40904,
        "start": 425.48,
        "temperature": 0,
        "text": " But the nature of Codebook is something I really need to focus on. Live stream working",
        "tokens": [
          51186,
          583,
          264,
          3687,
          295,
          15549,
          2939,
          307,
          746,
          286,
          534,
          643,
          281,
          1879,
          322,
          13,
          10385,
          4309,
          1364,
          51458
        ]
      },
      {
        "avg_logprob": -0.2523041349468809,
        "compression_ratio": 1.530701754385965,
        "end": 441.24,
        "id": 75,
        "no_speech_prob": 0.5116376280784607,
        "seek": 43092,
        "start": 430.92,
        "temperature": 0,
        "text": " on it, problem solved. Huh? I don't know what that refers to. All right. Looking at",
        "tokens": [
          50364,
          322,
          309,
          11,
          1154,
          13041,
          13,
          8063,
          30,
          286,
          500,
          380,
          458,
          437,
          300,
          14942,
          281,
          13,
          1057,
          558,
          13,
          11053,
          412,
          50880
        ]
      },
      {
        "avg_logprob": -0.2523041349468809,
        "compression_ratio": 1.530701754385965,
        "end": 446.52000000000004,
        "id": 76,
        "no_speech_prob": 0.5116376280784607,
        "seek": 43092,
        "start": 441.24,
        "temperature": 0,
        "text": " the chat. It's spring. Yes, it is. Oh, you know, the other thing I really should do is",
        "tokens": [
          50880,
          264,
          5081,
          13,
          467,
          311,
          5587,
          13,
          1079,
          11,
          309,
          307,
          13,
          876,
          11,
          291,
          458,
          11,
          264,
          661,
          551,
          286,
          534,
          820,
          360,
          307,
          51144
        ]
      },
      {
        "avg_logprob": -0.2523041349468809,
        "compression_ratio": 1.530701754385965,
        "end": 450.88,
        "id": 77,
        "no_speech_prob": 0.5116376280784607,
        "seek": 43092,
        "start": 446.52000000000004,
        "temperature": 0,
        "text": " I really want to update my workflow this summer. So I want to start playing around with using",
        "tokens": [
          51144,
          286,
          534,
          528,
          281,
          5623,
          452,
          20993,
          341,
          4266,
          13,
          407,
          286,
          528,
          281,
          722,
          2433,
          926,
          365,
          1228,
          51362
        ]
      },
      {
        "avg_logprob": -0.2523041349468809,
        "compression_ratio": 1.530701754385965,
        "end": 456.20000000000005,
        "id": 78,
        "no_speech_prob": 0.5116376280784607,
        "seek": 43092,
        "start": 450.88,
        "temperature": 0,
        "text": " Visual Studio Code. I might use Atom here and there still. I want to use iTerm. It's",
        "tokens": [
          51362,
          23187,
          13500,
          15549,
          13,
          286,
          1062,
          764,
          1711,
          298,
          510,
          293,
          456,
          920,
          13,
          286,
          528,
          281,
          764,
          30882,
          966,
          13,
          467,
          311,
          51628
        ]
      },
      {
        "avg_logprob": -0.3972560658174403,
        "compression_ratio": 1.6255707762557077,
        "end": 462.24,
        "id": 79,
        "no_speech_prob": 0.6001163721084595,
        "seek": 45620,
        "start": 456.2,
        "temperature": 0,
        "text": " a different terminal. And I want to start to also I'm going to go back and start to",
        "tokens": [
          50364,
          257,
          819,
          14709,
          13,
          400,
          286,
          528,
          281,
          722,
          281,
          611,
          286,
          478,
          516,
          281,
          352,
          646,
          293,
          722,
          281,
          50666
        ]
      },
      {
        "avg_logprob": -0.3972560658174403,
        "compression_ratio": 1.6255707762557077,
        "end": 467.84,
        "id": 80,
        "no_speech_prob": 0.6001163721084595,
        "seek": 45620,
        "start": 462.24,
        "temperature": 0,
        "text": " do some very beginner videos again. It's been quite a while since I did my beginner learn",
        "tokens": [
          50666,
          360,
          512,
          588,
          22080,
          2145,
          797,
          13,
          467,
          311,
          668,
          1596,
          257,
          1339,
          1670,
          286,
          630,
          452,
          22080,
          1466,
          50946
        ]
      },
      {
        "avg_logprob": -0.3972560658174403,
        "compression_ratio": 1.6255707762557077,
        "end": 480.12,
        "id": 81,
        "no_speech_prob": 0.6001163721084595,
        "seek": 45620,
        "start": 467.84,
        "temperature": 0,
        "text": " to program from scratch videos. And those need some refreshing. Ah, interfere interference",
        "tokens": [
          50946,
          281,
          1461,
          490,
          8459,
          2145,
          13,
          400,
          729,
          643,
          512,
          19772,
          13,
          2438,
          11,
          23946,
          24497,
          51560
        ]
      },
      {
        "avg_logprob": -0.3972560658174403,
        "compression_ratio": 1.6255707762557077,
        "end": 485.28,
        "id": 82,
        "no_speech_prob": 0.6001163721084595,
        "seek": 45620,
        "start": 480.12,
        "temperature": 0,
        "text": " something and why writes, will you make some project Euler problems? It's pronounced Euler,",
        "tokens": [
          51560,
          746,
          293,
          983,
          13657,
          11,
          486,
          291,
          652,
          512,
          1716,
          462,
          26318,
          2740,
          30,
          467,
          311,
          23155,
          462,
          26318,
          11,
          51818
        ]
      },
      {
        "avg_logprob": -0.2905864522914694,
        "compression_ratio": 1.6027397260273972,
        "end": 489.08,
        "id": 83,
        "no_speech_prob": 0.03209884837269783,
        "seek": 48528,
        "start": 485.79999999999995,
        "temperature": 0,
        "text": " it's very interesting thing. Check it out. I am familiar with project Euler. I would",
        "tokens": [
          50390,
          309,
          311,
          588,
          1880,
          551,
          13,
          6881,
          309,
          484,
          13,
          286,
          669,
          4963,
          365,
          1716,
          462,
          26318,
          13,
          286,
          576,
          50554
        ]
      },
      {
        "avg_logprob": -0.2905864522914694,
        "compression_ratio": 1.6027397260273972,
        "end": 494.47999999999996,
        "id": 84,
        "no_speech_prob": 0.03209884837269783,
        "seek": 48528,
        "start": 489.08,
        "temperature": 0,
        "text": " have fun doing that. So that's not a bad idea. Oh, problem solved. Working on the book, I",
        "tokens": [
          50554,
          362,
          1019,
          884,
          300,
          13,
          407,
          300,
          311,
          406,
          257,
          1578,
          1558,
          13,
          876,
          11,
          1154,
          13041,
          13,
          18337,
          322,
          264,
          1446,
          11,
          286,
          50824
        ]
      },
      {
        "avg_logprob": -0.2905864522914694,
        "compression_ratio": 1.6027397260273972,
        "end": 501.15999999999997,
        "id": 85,
        "no_speech_prob": 0.03209884837269783,
        "seek": 48528,
        "start": 494.47999999999996,
        "temperature": 0,
        "text": " mean. Oh, live stream working on the book. I get it. Me, I am so me is making a good",
        "tokens": [
          50824,
          914,
          13,
          876,
          11,
          1621,
          4309,
          1364,
          322,
          264,
          1446,
          13,
          286,
          483,
          309,
          13,
          1923,
          11,
          286,
          669,
          370,
          385,
          307,
          1455,
          257,
          665,
          51158
        ]
      },
      {
        "avg_logprob": -0.2905864522914694,
        "compression_ratio": 1.6027397260273972,
        "end": 509.08,
        "id": 86,
        "no_speech_prob": 0.03209884837269783,
        "seek": 48528,
        "start": 501.15999999999997,
        "temperature": 0,
        "text": " point that I could just live stream my work sessions. It's not the worst idea. I definitely",
        "tokens": [
          51158,
          935,
          300,
          286,
          727,
          445,
          1621,
          4309,
          452,
          589,
          11081,
          13,
          467,
          311,
          406,
          264,
          5855,
          1558,
          13,
          286,
          2138,
          51554
        ]
      },
      {
        "avg_logprob": -0.3417178667508639,
        "compression_ratio": 1.4015151515151516,
        "end": 517.92,
        "id": 87,
        "no_speech_prob": 0.7400723695755005,
        "seek": 50908,
        "start": 509.08,
        "temperature": 0,
        "text": " would consider that. All right. The stream title says async instead of async. Let me",
        "tokens": [
          50364,
          576,
          1949,
          300,
          13,
          1057,
          558,
          13,
          440,
          4309,
          4876,
          1619,
          382,
          34015,
          2602,
          295,
          382,
          34015,
          13,
          961,
          385,
          50806
        ]
      },
      {
        "avg_logprob": -0.3417178667508639,
        "compression_ratio": 1.4015151515151516,
        "end": 526.88,
        "id": 88,
        "no_speech_prob": 0.7400723695755005,
        "seek": 50908,
        "start": 517.92,
        "temperature": 0,
        "text": " fix that. Let me fix that. Thank you for pointing that out. Where do I find that? Info and settings.",
        "tokens": [
          50806,
          3191,
          300,
          13,
          961,
          385,
          3191,
          300,
          13,
          1044,
          291,
          337,
          12166,
          300,
          484,
          13,
          2305,
          360,
          286,
          915,
          300,
          30,
          11537,
          78,
          293,
          6257,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.3249919679429796,
        "compression_ratio": 1.3968253968253967,
        "end": 540.92,
        "id": 89,
        "no_speech_prob": 0.08881298452615738,
        "seek": 52688,
        "start": 526.88,
        "temperature": 0,
        "text": " A, Y, A, S, Y. Thank you. Whoops. A, S, Y, N, C. Okay. Thanks for all the nice Vim. I'm",
        "tokens": [
          50364,
          316,
          11,
          398,
          11,
          316,
          11,
          318,
          11,
          398,
          13,
          1044,
          291,
          13,
          45263,
          13,
          316,
          11,
          318,
          11,
          398,
          11,
          426,
          11,
          383,
          13,
          1033,
          13,
          2561,
          337,
          439,
          264,
          1481,
          691,
          332,
          13,
          286,
          478,
          51066
        ]
      },
      {
        "avg_logprob": -0.3249919679429796,
        "compression_ratio": 1.3968253968253967,
        "end": 549.4,
        "id": 90,
        "no_speech_prob": 0.08881298452615738,
        "seek": 52688,
        "start": 540.92,
        "temperature": 0,
        "text": " not really a Vim. I wish I was like a Vim person, but you know me. I'm not a Vim person.",
        "tokens": [
          51066,
          406,
          534,
          257,
          691,
          332,
          13,
          286,
          3172,
          286,
          390,
          411,
          257,
          691,
          332,
          954,
          11,
          457,
          291,
          458,
          385,
          13,
          286,
          478,
          406,
          257,
          691,
          332,
          954,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.30588650703430176,
        "compression_ratio": 1.467741935483871,
        "end": 557.4,
        "id": 91,
        "no_speech_prob": 0.12591032683849335,
        "seek": 54940,
        "start": 549.4,
        "temperature": 0,
        "text": " I didn't grow up programming. And so I never found my way to those kind of old school tools.",
        "tokens": [
          50364,
          286,
          994,
          380,
          1852,
          493,
          9410,
          13,
          400,
          370,
          286,
          1128,
          1352,
          452,
          636,
          281,
          729,
          733,
          295,
          1331,
          1395,
          3873,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.30588650703430176,
        "compression_ratio": 1.467741935483871,
        "end": 572.04,
        "id": 92,
        "no_speech_prob": 0.12591032683849335,
        "seek": 54940,
        "start": 563.48,
        "temperature": 0,
        "text": " Okay. All right. So thanks to everyone saying hi in the chat. I appreciate all those messages.",
        "tokens": [
          51068,
          1033,
          13,
          1057,
          558,
          13,
          407,
          3231,
          281,
          1518,
          1566,
          4879,
          294,
          264,
          5081,
          13,
          286,
          4449,
          439,
          729,
          7897,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.30588650703430176,
        "compression_ratio": 1.467741935483871,
        "end": 578.68,
        "id": 93,
        "no_speech_prob": 0.12591032683849335,
        "seek": 54940,
        "start": 572.04,
        "temperature": 0,
        "text": " I think I'm just going to get started. So this first video is going to be how to make",
        "tokens": [
          51496,
          286,
          519,
          286,
          478,
          445,
          516,
          281,
          483,
          1409,
          13,
          407,
          341,
          700,
          960,
          307,
          516,
          281,
          312,
          577,
          281,
          652,
          51828
        ]
      },
      {
        "avg_logprob": -0.261652050596295,
        "compression_ratio": 1.5493562231759657,
        "end": 586.1999999999999,
        "id": 94,
        "no_speech_prob": 0.04672369360923767,
        "seek": 57868,
        "start": 578.68,
        "temperature": 0,
        "text": " your promise. All right. Let's come I didn't buy a new microphone. I still haven't found",
        "tokens": [
          50364,
          428,
          6228,
          13,
          1057,
          558,
          13,
          961,
          311,
          808,
          286,
          994,
          380,
          2256,
          257,
          777,
          10952,
          13,
          286,
          920,
          2378,
          380,
          1352,
          50740
        ]
      },
      {
        "avg_logprob": -0.261652050596295,
        "compression_ratio": 1.5493562231759657,
        "end": 591.8,
        "id": 95,
        "no_speech_prob": 0.04672369360923767,
        "seek": 57868,
        "start": 586.1999999999999,
        "temperature": 0,
        "text": " the old microphone. I think this one might be a little bit better, though. You tell me.",
        "tokens": [
          50740,
          264,
          1331,
          10952,
          13,
          286,
          519,
          341,
          472,
          1062,
          312,
          257,
          707,
          857,
          1101,
          11,
          1673,
          13,
          509,
          980,
          385,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.261652050596295,
        "compression_ratio": 1.5493562231759657,
        "end": 602.7199999999999,
        "id": 96,
        "no_speech_prob": 0.04672369360923767,
        "seek": 57868,
        "start": 591.8,
        "temperature": 0,
        "text": " So let me close a bunch of stuff. And I promise you. What is that song? And after all that's",
        "tokens": [
          51020,
          407,
          718,
          385,
          1998,
          257,
          3840,
          295,
          1507,
          13,
          400,
          286,
          6228,
          291,
          13,
          708,
          307,
          300,
          2153,
          30,
          400,
          934,
          439,
          300,
          311,
          51566
        ]
      },
      {
        "avg_logprob": -0.261652050596295,
        "compression_ratio": 1.5493562231759657,
        "end": 608.4799999999999,
        "id": 97,
        "no_speech_prob": 0.04672369360923767,
        "seek": 57868,
        "start": 602.7199999999999,
        "temperature": 0,
        "text": " been said and done. If I do my terrible singing, I don't think I get a copyright violation.",
        "tokens": [
          51566,
          668,
          848,
          293,
          1096,
          13,
          759,
          286,
          360,
          452,
          6237,
          6726,
          11,
          286,
          500,
          380,
          519,
          286,
          483,
          257,
          17996,
          22840,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.2476636446439303,
        "compression_ratio": 1.5271739130434783,
        "end": 613.48,
        "id": 98,
        "no_speech_prob": 0.013848272152245045,
        "seek": 60848,
        "start": 609.24,
        "temperature": 0,
        "text": " I think it's only if it's exactly the original track, but also because I'm terribly out of tune.",
        "tokens": [
          50402,
          286,
          519,
          309,
          311,
          787,
          498,
          309,
          311,
          2293,
          264,
          3380,
          2837,
          11,
          457,
          611,
          570,
          286,
          478,
          22903,
          484,
          295,
          10864,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2476636446439303,
        "compression_ratio": 1.5271739130434783,
        "end": 622.04,
        "id": 99,
        "no_speech_prob": 0.013848272152245045,
        "seek": 60848,
        "start": 613.48,
        "temperature": 0,
        "text": " This is an advantage to being out of tune. Let me move to the side. Desktop. I want to be",
        "tokens": [
          50614,
          639,
          307,
          364,
          5002,
          281,
          885,
          484,
          295,
          10864,
          13,
          961,
          385,
          1286,
          281,
          264,
          1252,
          13,
          49044,
          13,
          286,
          528,
          281,
          312,
          51042
        ]
      },
      {
        "avg_logprob": -0.2476636446439303,
        "compression_ratio": 1.5271739130434783,
        "end": 632.9200000000001,
        "id": 100,
        "no_speech_prob": 0.013848272152245045,
        "seek": 60848,
        "start": 622.04,
        "temperature": 0,
        "text": " working on promises. I'm going to move this away. Let's pretend we never did this. Let's go to",
        "tokens": [
          51042,
          1364,
          322,
          16403,
          13,
          286,
          478,
          516,
          281,
          1286,
          341,
          1314,
          13,
          961,
          311,
          11865,
          321,
          1128,
          630,
          341,
          13,
          961,
          311,
          352,
          281,
          51586
        ]
      },
      {
        "avg_logprob": -0.22293465137481688,
        "compression_ratio": 1.6257668711656441,
        "end": 639.68,
        "id": 101,
        "no_speech_prob": 0.05032592639327049,
        "seek": 63292,
        "start": 632.9599999999999,
        "temperature": 0,
        "text": " desktop. Promises. Let's put this away in the past. It's in the past. We're moving on to the",
        "tokens": [
          50366,
          14502,
          13,
          15833,
          3598,
          13,
          961,
          311,
          829,
          341,
          1314,
          294,
          264,
          1791,
          13,
          467,
          311,
          294,
          264,
          1791,
          13,
          492,
          434,
          2684,
          322,
          281,
          264,
          50702
        ]
      },
      {
        "avg_logprob": -0.22293465137481688,
        "compression_ratio": 1.6257668711656441,
        "end": 651.4399999999999,
        "id": 102,
        "no_speech_prob": 0.05032592639327049,
        "seek": 63292,
        "start": 639.68,
        "temperature": 0,
        "text": " future. And we're going to say O2 promises. Make your own. And I'm going to do this. Make your own.",
        "tokens": [
          50702,
          2027,
          13,
          400,
          321,
          434,
          516,
          281,
          584,
          422,
          17,
          16403,
          13,
          4387,
          428,
          1065,
          13,
          400,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          4387,
          428,
          1065,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.22293465137481688,
        "compression_ratio": 1.6257668711656441,
        "end": 659.36,
        "id": 103,
        "no_speech_prob": 0.05032592639327049,
        "seek": 63292,
        "start": 653.92,
        "temperature": 0,
        "text": " Quadrennial. And then I'm going to I must have Adam this open somewhere.",
        "tokens": [
          51414,
          29619,
          1095,
          77,
          831,
          13,
          400,
          550,
          286,
          478,
          516,
          281,
          286,
          1633,
          362,
          7938,
          341,
          1269,
          4079,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2847177372422329,
        "compression_ratio": 1.5,
        "end": 668.4799999999999,
        "id": 104,
        "no_speech_prob": 0.01566275767982006,
        "seek": 66292,
        "start": 663.4399999999999,
        "temperature": 0,
        "text": " Check the Slack channel. Mic is way better. That's good to hear. Maybe I'll just keep using this",
        "tokens": [
          50390,
          6881,
          264,
          37211,
          2269,
          13,
          5818,
          307,
          636,
          1101,
          13,
          663,
          311,
          665,
          281,
          1568,
          13,
          2704,
          286,
          603,
          445,
          1066,
          1228,
          341,
          50642
        ]
      },
      {
        "avg_logprob": -0.2847177372422329,
        "compression_ratio": 1.5,
        "end": 677.5999999999999,
        "id": 105,
        "no_speech_prob": 0.01566275767982006,
        "seek": 66292,
        "start": 668.4799999999999,
        "temperature": 0,
        "text": " mic. Old mic is better. I could do a straw poll for that. I'm not going to. Let's go here. We",
        "tokens": [
          50642,
          3123,
          13,
          8633,
          3123,
          307,
          1101,
          13,
          286,
          727,
          360,
          257,
          10099,
          6418,
          337,
          300,
          13,
          286,
          478,
          406,
          516,
          281,
          13,
          961,
          311,
          352,
          510,
          13,
          492,
          51098
        ]
      },
      {
        "avg_logprob": -0.2847177372422329,
        "compression_ratio": 1.5,
        "end": 688,
        "id": 106,
        "no_speech_prob": 0.01566275767982006,
        "seek": 66292,
        "start": 677.5999999999999,
        "temperature": 0,
        "text": " don't need any of this stuff. One thing is, here's a I shouldn't talk about this yet. I have a maybe",
        "tokens": [
          51098,
          500,
          380,
          643,
          604,
          295,
          341,
          1507,
          13,
          1485,
          551,
          307,
          11,
          510,
          311,
          257,
          286,
          4659,
          380,
          751,
          466,
          341,
          1939,
          13,
          286,
          362,
          257,
          1310,
          51618
        ]
      },
      {
        "avg_logprob": -0.22248666497725475,
        "compression_ratio": 1.43,
        "end": 698,
        "id": 107,
        "no_speech_prob": 0.08269456773996353,
        "seek": 68800,
        "start": 688.64,
        "temperature": 0,
        "text": " almost tentative plan to also live stream from home. That's a terrible idea, I think. But stay",
        "tokens": [
          50396,
          1920,
          7054,
          1166,
          1393,
          281,
          611,
          1621,
          4309,
          490,
          1280,
          13,
          663,
          311,
          257,
          6237,
          1558,
          11,
          286,
          519,
          13,
          583,
          1754,
          50864
        ]
      },
      {
        "avg_logprob": -0.22248666497725475,
        "compression_ratio": 1.43,
        "end": 704.48,
        "id": 108,
        "no_speech_prob": 0.08269456773996353,
        "seek": 68800,
        "start": 698,
        "temperature": 0,
        "text": " tuned. I need to buy a new computer to do that, though. That's the issue. And that is expensive.",
        "tokens": [
          50864,
          10870,
          13,
          286,
          643,
          281,
          2256,
          257,
          777,
          3820,
          281,
          360,
          300,
          11,
          1673,
          13,
          663,
          311,
          264,
          2734,
          13,
          400,
          300,
          307,
          5124,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.22248666497725475,
        "compression_ratio": 1.43,
        "end": 710.96,
        "id": 109,
        "no_speech_prob": 0.08269456773996353,
        "seek": 68800,
        "start": 705.12,
        "temperature": 0,
        "text": " I'm waiting until WWDC. Is that what it's called? Maybe I'll announce all the new stuff there.",
        "tokens": [
          51220,
          286,
          478,
          3806,
          1826,
          12040,
          25619,
          13,
          1119,
          300,
          437,
          309,
          311,
          1219,
          30,
          2704,
          286,
          603,
          7478,
          439,
          264,
          777,
          1507,
          456,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.3581591912035672,
        "compression_ratio": 1.3,
        "end": 720.1600000000001,
        "id": 110,
        "no_speech_prob": 0.015424426645040512,
        "seek": 71096,
        "start": 711.2800000000001,
        "temperature": 0,
        "text": " I could be on Saturday morning at 9 a.m. Let me work on nature of code book. It's complicated.",
        "tokens": [
          50380,
          286,
          727,
          312,
          322,
          8803,
          2446,
          412,
          1722,
          257,
          13,
          76,
          13,
          961,
          385,
          589,
          322,
          3687,
          295,
          3089,
          1446,
          13,
          467,
          311,
          6179,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.3581591912035672,
        "compression_ratio": 1.3,
        "end": 734.08,
        "id": 111,
        "no_speech_prob": 0.015424426645040512,
        "seek": 71096,
        "start": 723.36,
        "temperature": 0,
        "text": " Let's do this. I'm going to keep the P5 library base almost like as a security blanket.",
        "tokens": [
          50984,
          961,
          311,
          360,
          341,
          13,
          286,
          478,
          516,
          281,
          1066,
          264,
          430,
          20,
          6405,
          3096,
          1920,
          411,
          382,
          257,
          3825,
          17907,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2791060341729058,
        "compression_ratio": 1.4051724137931034,
        "end": 744.96,
        "id": 112,
        "no_speech_prob": 0.06464943289756775,
        "seek": 73408,
        "start": 735.0400000000001,
        "temperature": 0,
        "text": " I'm going to just do something. I just want to have this video start.",
        "tokens": [
          50412,
          286,
          478,
          516,
          281,
          445,
          360,
          746,
          13,
          286,
          445,
          528,
          281,
          362,
          341,
          960,
          722,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2791060341729058,
        "compression_ratio": 1.4051724137931034,
        "end": 762.24,
        "id": 113,
        "no_speech_prob": 0.06464943289756775,
        "seek": 73408,
        "start": 753.44,
        "temperature": 0,
        "text": " I just want to have an example, some example code. Ready to go. And say hello is not defined.",
        "tokens": [
          51332,
          286,
          445,
          528,
          281,
          362,
          364,
          1365,
          11,
          512,
          1365,
          3089,
          13,
          9944,
          281,
          352,
          13,
          400,
          584,
          7751,
          307,
          406,
          7642,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.3330768346786499,
        "compression_ratio": 1.1477272727272727,
        "end": 768.5600000000001,
        "id": 114,
        "no_speech_prob": 0.002434350084513426,
        "seek": 76408,
        "start": 765.0400000000001,
        "temperature": 0,
        "text": " I should say say hello.",
        "tokens": [
          50412,
          286,
          820,
          584,
          584,
          7751,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.3330768346786499,
        "compression_ratio": 1.1477272727272727,
        "end": 784.5600000000001,
        "id": 115,
        "no_speech_prob": 0.002434350084513426,
        "seek": 76408,
        "start": 779.9200000000001,
        "temperature": 0,
        "text": " All right. Here we go. This is really not good today. That's a little better.",
        "tokens": [
          51156,
          1057,
          558,
          13,
          1692,
          321,
          352,
          13,
          639,
          307,
          534,
          406,
          665,
          965,
          13,
          663,
          311,
          257,
          707,
          1101,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.23005737692622816,
        "compression_ratio": 1.3974358974358974,
        "end": 787.1999999999999,
        "id": 116,
        "no_speech_prob": 0.011868851259350777,
        "seek": 78456,
        "start": 785.4399999999999,
        "temperature": 0,
        "text": " Yeah. I can't really see it.",
        "tokens": [
          50408,
          865,
          13,
          286,
          393,
          380,
          534,
          536,
          309,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.23005737692622816,
        "compression_ratio": 1.3974358974358974,
        "end": 796.64,
        "id": 117,
        "no_speech_prob": 0.011868851259350777,
        "seek": 78456,
        "start": 790,
        "temperature": 0,
        "text": " By the way, if people have equipment suggestions for things that I should get to improve this",
        "tokens": [
          50636,
          3146,
          264,
          636,
          11,
          498,
          561,
          362,
          5927,
          13396,
          337,
          721,
          300,
          286,
          820,
          483,
          281,
          3470,
          341,
          50968
        ]
      },
      {
        "avg_logprob": -0.23005737692622816,
        "compression_ratio": 1.3974358974358974,
        "end": 804.8,
        "id": 118,
        "no_speech_prob": 0.011868851259350777,
        "seek": 78456,
        "start": 796.64,
        "temperature": 0,
        "text": " live stream, I'm definitely all ears. And a nose and a mouth. But I'd be happy for suggestions.",
        "tokens": [
          50968,
          1621,
          4309,
          11,
          286,
          478,
          2138,
          439,
          8798,
          13,
          400,
          257,
          6690,
          293,
          257,
          4525,
          13,
          583,
          286,
          1116,
          312,
          2055,
          337,
          13396,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.460382519346295,
        "compression_ratio": 1.4177215189873418,
        "end": 808.16,
        "id": 119,
        "no_speech_prob": 0.07158728688955307,
        "seek": 80480,
        "start": 804.9599999999999,
        "temperature": 0,
        "text": " All right. Let me cycle the camera. So that will",
        "tokens": [
          50372,
          1057,
          558,
          13,
          961,
          385,
          6586,
          264,
          2799,
          13,
          407,
          300,
          486,
          50532
        ]
      },
      {
        "avg_logprob": -0.460382519346295,
        "compression_ratio": 1.4177215189873418,
        "end": 820.7199999999999,
        "id": 120,
        "no_speech_prob": 0.07158728688955307,
        "seek": 80480,
        "start": 820.16,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51132,
          1057,
          558,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.460382519346295,
        "compression_ratio": 1.4177215189873418,
        "end": 828.88,
        "id": 121,
        "no_speech_prob": 0.07158728688955307,
        "seek": 80480,
        "start": 824,
        "temperature": 0,
        "text": " You know, I'm also having this lower back pain on this side. That's not going to mess up my",
        "tokens": [
          51324,
          509,
          458,
          11,
          286,
          478,
          611,
          1419,
          341,
          3126,
          646,
          1822,
          322,
          341,
          1252,
          13,
          663,
          311,
          406,
          516,
          281,
          2082,
          493,
          452,
          51568
        ]
      },
      {
        "avg_logprob": -0.460382519346295,
        "compression_ratio": 1.4177215189873418,
        "end": 831.8399999999999,
        "id": 122,
        "no_speech_prob": 0.07158728688955307,
        "seek": 80480,
        "start": 828.88,
        "temperature": 0,
        "text": " live stream. I don't think it's from I think it's probably from sitting.",
        "tokens": [
          51568,
          1621,
          4309,
          13,
          286,
          500,
          380,
          519,
          309,
          311,
          490,
          286,
          519,
          309,
          311,
          1391,
          490,
          3798,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.46382962978952297,
        "compression_ratio": 1.7569721115537849,
        "end": 838.72,
        "id": 123,
        "no_speech_prob": 0.014728018082678318,
        "seek": 83184,
        "start": 831.9200000000001,
        "temperature": 0,
        "text": " I don't actually sit and work very much. I'm either standing and talking or I'm running around",
        "tokens": [
          50368,
          286,
          500,
          380,
          767,
          1394,
          293,
          589,
          588,
          709,
          13,
          286,
          478,
          2139,
          4877,
          293,
          1417,
          420,
          286,
          478,
          2614,
          926,
          50708
        ]
      },
      {
        "avg_logprob": -0.46382962978952297,
        "compression_ratio": 1.7569721115537849,
        "end": 844.32,
        "id": 124,
        "no_speech_prob": 0.014728018082678318,
        "seek": 83184,
        "start": 839.6,
        "temperature": 0,
        "text": " talking to people and doing stuff. I don't actually sit and work. But yesterday and the day",
        "tokens": [
          50752,
          1417,
          281,
          561,
          293,
          884,
          1507,
          13,
          286,
          500,
          380,
          767,
          1394,
          293,
          589,
          13,
          583,
          5186,
          293,
          264,
          786,
          50988
        ]
      },
      {
        "avg_logprob": -0.46382962978952297,
        "compression_ratio": 1.7569721115537849,
        "end": 848.24,
        "id": 125,
        "no_speech_prob": 0.014728018082678318,
        "seek": 83184,
        "start": 844.32,
        "temperature": 0,
        "text": " before, I was kind of doing that for hours at a time. I think maybe I need to get up.",
        "tokens": [
          50988,
          949,
          11,
          286,
          390,
          733,
          295,
          884,
          300,
          337,
          2496,
          412,
          257,
          565,
          13,
          286,
          519,
          1310,
          286,
          643,
          281,
          483,
          493,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.46382962978952297,
        "compression_ratio": 1.7569721115537849,
        "end": 853.2,
        "id": 126,
        "no_speech_prob": 0.014728018082678318,
        "seek": 83184,
        "start": 848.24,
        "temperature": 0,
        "text": " Get a Sennheiser lavalier mic. I think that's what my other thing was. But I will check.",
        "tokens": [
          51184,
          3240,
          257,
          318,
          1857,
          675,
          6694,
          635,
          3337,
          811,
          3123,
          13,
          286,
          519,
          300,
          311,
          437,
          452,
          661,
          551,
          390,
          13,
          583,
          286,
          486,
          1520,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.46382962978952297,
        "compression_ratio": 1.7569721115537849,
        "end": 858.96,
        "id": 127,
        "no_speech_prob": 0.014728018082678318,
        "seek": 83184,
        "start": 856.24,
        "temperature": 0,
        "text": " So I'm going to answer one more question, then I'm going to go to the next one.",
        "tokens": [
          51584,
          407,
          286,
          478,
          516,
          281,
          1867,
          472,
          544,
          1168,
          11,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          958,
          472,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.25586913979571796,
        "compression_ratio": 1.5541125541125542,
        "end": 863.6800000000001,
        "id": 128,
        "no_speech_prob": 0.019716478884220123,
        "seek": 85896,
        "start": 859.9200000000001,
        "temperature": 0,
        "text": " So I'm going to answer one more question, then I'm going to move on. Koosh in the chat asks,",
        "tokens": [
          50412,
          407,
          286,
          478,
          516,
          281,
          1867,
          472,
          544,
          1168,
          11,
          550,
          286,
          478,
          516,
          281,
          1286,
          322,
          13,
          10509,
          3019,
          294,
          264,
          5081,
          8962,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.25586913979571796,
        "compression_ratio": 1.5541125541125542,
        "end": 867.52,
        "id": 129,
        "no_speech_prob": 0.019716478884220123,
        "seek": 85896,
        "start": 863.6800000000001,
        "temperature": 0,
        "text": " can we have a Discord where we can discuss our problem, the coding train?",
        "tokens": [
          50600,
          393,
          321,
          362,
          257,
          32623,
          689,
          321,
          393,
          2248,
          527,
          1154,
          11,
          264,
          17720,
          3847,
          30,
          50792
        ]
      },
      {
        "avg_logprob": -0.25586913979571796,
        "compression_ratio": 1.5541125541125542,
        "end": 875.44,
        "id": 130,
        "no_speech_prob": 0.019716478884220123,
        "seek": 85896,
        "start": 867.52,
        "temperature": 0,
        "text": " So let me just quickly say a few words about community while I'm here. So everyone watching",
        "tokens": [
          50792,
          407,
          718,
          385,
          445,
          2661,
          584,
          257,
          1326,
          2283,
          466,
          1768,
          1339,
          286,
          478,
          510,
          13,
          407,
          1518,
          1976,
          51188
        ]
      },
      {
        "avg_logprob": -0.25586913979571796,
        "compression_ratio": 1.5541125541125542,
        "end": 881.6,
        "id": 131,
        "no_speech_prob": 0.019716478884220123,
        "seek": 85896,
        "start": 875.44,
        "temperature": 0,
        "text": " the channel is welcome to self-organize and create their own forums or Discords or Reddit threads or",
        "tokens": [
          51188,
          264,
          2269,
          307,
          2928,
          281,
          2698,
          12,
          12372,
          1125,
          293,
          1884,
          641,
          1065,
          26998,
          420,
          413,
          5606,
          5703,
          420,
          32210,
          19314,
          420,
          51496
        ]
      },
      {
        "avg_logprob": -0.22238613646707417,
        "compression_ratio": 1.511111111111111,
        "end": 890.48,
        "id": 132,
        "no_speech_prob": 0.14030829071998596,
        "seek": 88160,
        "start": 881.6800000000001,
        "temperature": 0,
        "text": " whatever to talk about coding. And you're welcome to do that. I am currently keeping a...",
        "tokens": [
          50368,
          2035,
          281,
          751,
          466,
          17720,
          13,
          400,
          291,
          434,
          2928,
          281,
          360,
          300,
          13,
          286,
          669,
          4362,
          5145,
          257,
          485,
          50808
        ]
      },
      {
        "avg_logprob": -0.22238613646707417,
        "compression_ratio": 1.511111111111111,
        "end": 899.52,
        "id": 133,
        "no_speech_prob": 0.14030829071998596,
        "seek": 88160,
        "start": 893.84,
        "temperature": 0,
        "text": " I have an official coding train Slack channel. But the best way I found to manage that right now",
        "tokens": [
          50976,
          286,
          362,
          364,
          4783,
          17720,
          3847,
          37211,
          2269,
          13,
          583,
          264,
          1151,
          636,
          286,
          1352,
          281,
          3067,
          300,
          558,
          586,
          51260
        ]
      },
      {
        "avg_logprob": -0.22238613646707417,
        "compression_ratio": 1.511111111111111,
        "end": 905.2,
        "id": 134,
        "no_speech_prob": 0.14030829071998596,
        "seek": 88160,
        "start": 900.08,
        "temperature": 0,
        "text": " is through a membership to Patreon or sponsorship on the YouTube channel.",
        "tokens": [
          51288,
          307,
          807,
          257,
          16560,
          281,
          15692,
          420,
          42922,
          322,
          264,
          3088,
          2269,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.22238613646707417,
        "compression_ratio": 1.511111111111111,
        "end": 908.8000000000001,
        "id": 135,
        "no_speech_prob": 0.14030829071998596,
        "seek": 88160,
        "start": 905.2,
        "temperature": 0,
        "text": " So I don't want to... I've talked about it in several different videos already.",
        "tokens": [
          51544,
          407,
          286,
          500,
          380,
          528,
          281,
          485,
          286,
          600,
          2825,
          466,
          309,
          294,
          2940,
          819,
          2145,
          1217,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.22411200377318236,
        "compression_ratio": 1.6705426356589148,
        "end": 913.12,
        "id": 136,
        "no_speech_prob": 0.0003920316812582314,
        "seek": 90880,
        "start": 908.8,
        "temperature": 0,
        "text": " So you can find it. But that's basically... That's the one official... Then, of course,",
        "tokens": [
          50364,
          407,
          291,
          393,
          915,
          309,
          13,
          583,
          300,
          311,
          1936,
          485,
          663,
          311,
          264,
          472,
          4783,
          485,
          1396,
          11,
          295,
          1164,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.22411200377318236,
        "compression_ratio": 1.6705426356589148,
        "end": 917.76,
        "id": 137,
        "no_speech_prob": 0.0003920316812582314,
        "seek": 90880,
        "start": 913.12,
        "temperature": 0,
        "text": " there are the official coding train GitHub repositories. And I do want to mention,",
        "tokens": [
          50580,
          456,
          366,
          264,
          4783,
          17720,
          3847,
          23331,
          22283,
          2083,
          13,
          400,
          286,
          360,
          528,
          281,
          2152,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.22411200377318236,
        "compression_ratio": 1.6705426356589148,
        "end": 923.52,
        "id": 138,
        "no_speech_prob": 0.0003920316812582314,
        "seek": 90880,
        "start": 917.76,
        "temperature": 0,
        "text": " I really am remiss in not having done this sooner. But I just want to mention... And this...",
        "tokens": [
          50812,
          286,
          534,
          669,
          890,
          891,
          294,
          406,
          1419,
          1096,
          341,
          15324,
          13,
          583,
          286,
          445,
          528,
          281,
          2152,
          485,
          400,
          341,
          485,
          51100
        ]
      },
      {
        "avg_logprob": -0.22411200377318236,
        "compression_ratio": 1.6705426356589148,
        "end": 929.4399999999999,
        "id": 139,
        "no_speech_prob": 0.0003920316812582314,
        "seek": 90880,
        "start": 923.52,
        "temperature": 0,
        "text": " Maybe I'll come back to this when it's more finalized. But I also now have a code of conduct",
        "tokens": [
          51100,
          2704,
          286,
          603,
          808,
          646,
          281,
          341,
          562,
          309,
          311,
          544,
          2572,
          1602,
          13,
          583,
          286,
          611,
          586,
          362,
          257,
          3089,
          295,
          6018,
          51396
        ]
      },
      {
        "avg_logprob": -0.22411200377318236,
        "compression_ratio": 1.6705426356589148,
        "end": 935.76,
        "id": 140,
        "no_speech_prob": 0.0003920316812582314,
        "seek": 90880,
        "start": 931.04,
        "temperature": 0,
        "text": " repo. So this code of conduct applies to interactions in the YouTube chat,",
        "tokens": [
          51476,
          49040,
          13,
          407,
          341,
          3089,
          295,
          6018,
          13165,
          281,
          13280,
          294,
          264,
          3088,
          5081,
          11,
          51712
        ]
      },
      {
        "avg_logprob": -0.22177850474481997,
        "compression_ratio": 1.6476868327402134,
        "end": 940.72,
        "id": 141,
        "no_speech_prob": 0.00009169894474325702,
        "seek": 93576,
        "start": 935.76,
        "temperature": 0,
        "text": " YouTube comments, Slack channel, GitHub, participation in the coding train community.",
        "tokens": [
          50364,
          3088,
          3053,
          11,
          37211,
          2269,
          11,
          23331,
          11,
          13487,
          294,
          264,
          17720,
          3847,
          1768,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.22177850474481997,
        "compression_ratio": 1.6476868327402134,
        "end": 947.76,
        "id": 142,
        "no_speech_prob": 0.00009169894474325702,
        "seek": 93576,
        "start": 940.72,
        "temperature": 0,
        "text": " So if... Also, what this is really is... At the present is a copy of the p5.js code of conduct.",
        "tokens": [
          50612,
          407,
          498,
          485,
          2743,
          11,
          437,
          341,
          307,
          534,
          307,
          485,
          1711,
          264,
          1974,
          307,
          257,
          5055,
          295,
          264,
          280,
          20,
          13,
          25530,
          3089,
          295,
          6018,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22177850474481997,
        "compression_ratio": 1.6476868327402134,
        "end": 952.3199999999999,
        "id": 143,
        "no_speech_prob": 0.00009169894474325702,
        "seek": 93576,
        "start": 947.76,
        "temperature": 0,
        "text": " And so if anyone has experience with online communities and codes of conduct and wants",
        "tokens": [
          50964,
          400,
          370,
          498,
          2878,
          575,
          1752,
          365,
          2950,
          4456,
          293,
          14211,
          295,
          6018,
          293,
          2738,
          51192
        ]
      },
      {
        "avg_logprob": -0.22177850474481997,
        "compression_ratio": 1.6476868327402134,
        "end": 960.08,
        "id": 144,
        "no_speech_prob": 0.00009169894474325702,
        "seek": 93576,
        "start": 952.3199999999999,
        "temperature": 0,
        "text": " to contribute and help make this better and help me do better managing the community, I am, again,",
        "tokens": [
          51192,
          281,
          10586,
          293,
          854,
          652,
          341,
          1101,
          293,
          854,
          385,
          360,
          1101,
          11642,
          264,
          1768,
          11,
          286,
          669,
          11,
          797,
          11,
          51580
        ]
      },
      {
        "avg_logprob": -0.22177850474481997,
        "compression_ratio": 1.6476868327402134,
        "end": 964.72,
        "id": 145,
        "no_speech_prob": 0.00009169894474325702,
        "seek": 93576,
        "start": 960.08,
        "temperature": 0,
        "text": " all ears and a nose. You know, I have this... I need to get new lenses. Because even though I'm",
        "tokens": [
          51580,
          439,
          8798,
          293,
          257,
          6690,
          13,
          509,
          458,
          11,
          286,
          362,
          341,
          485,
          286,
          643,
          281,
          483,
          777,
          18059,
          13,
          1436,
          754,
          1673,
          286,
          478,
          51812
        ]
      },
      {
        "avg_logprob": -0.25975808230313385,
        "compression_ratio": 1.5147058823529411,
        "end": 970.08,
        "id": 146,
        "no_speech_prob": 0.0016228837193921208,
        "seek": 96472,
        "start": 964.72,
        "temperature": 0,
        "text": " blind, my lens is all scratched up right there and I can't actually see. And I have tickets to",
        "tokens": [
          50364,
          6865,
          11,
          452,
          6765,
          307,
          439,
          40513,
          493,
          558,
          456,
          293,
          286,
          393,
          380,
          767,
          536,
          13,
          400,
          286,
          362,
          12628,
          281,
          50632
        ]
      },
      {
        "avg_logprob": -0.25975808230313385,
        "compression_ratio": 1.5147058823529411,
        "end": 974.32,
        "id": 147,
        "no_speech_prob": 0.0016228837193921208,
        "seek": 96472,
        "start": 970.08,
        "temperature": 0,
        "text": " go see Solo this weekend. And if I don't have good glasses, I'm not gonna enjoy the movie. I",
        "tokens": [
          50632,
          352,
          536,
          26452,
          341,
          6711,
          13,
          400,
          498,
          286,
          500,
          380,
          362,
          665,
          10812,
          11,
          286,
          478,
          406,
          799,
          2103,
          264,
          3169,
          13,
          286,
          50844
        ]
      },
      {
        "avg_logprob": -0.25975808230313385,
        "compression_ratio": 1.5147058823529411,
        "end": 979.6800000000001,
        "id": 148,
        "no_speech_prob": 0.0016228837193921208,
        "seek": 96472,
        "start": 974.32,
        "temperature": 0,
        "text": " don't know how this is gonna happen. Okay. I gotta get started. So that's what I have to say.",
        "tokens": [
          50844,
          500,
          380,
          458,
          577,
          341,
          307,
          799,
          1051,
          13,
          1033,
          13,
          286,
          3428,
          483,
          1409,
          13,
          407,
          300,
          311,
          437,
          286,
          362,
          281,
          584,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.25975808230313385,
        "compression_ratio": 1.5147058823529411,
        "end": 985.6800000000001,
        "id": 149,
        "no_speech_prob": 0.0016228837193921208,
        "seek": 96472,
        "start": 983.52,
        "temperature": 0,
        "text": " All right. I promise you...",
        "tokens": [
          51304,
          1057,
          558,
          13,
          286,
          6228,
          291,
          485,
          51412
        ]
      },
      {
        "avg_logprob": -0.2587794999818544,
        "compression_ratio": 1.6287425149700598,
        "end": 996.2399999999999,
        "id": 150,
        "no_speech_prob": 0.2658357620239258,
        "seek": 98568,
        "start": 986.4,
        "temperature": 0,
        "text": " Hey, we've got a new sponsor, Mobius. Thank you. Once again, if you...",
        "tokens": [
          50400,
          1911,
          11,
          321,
          600,
          658,
          257,
          777,
          16198,
          11,
          37920,
          4872,
          13,
          1044,
          291,
          13,
          3443,
          797,
          11,
          498,
          291,
          485,
          50892
        ]
      },
      {
        "avg_logprob": -0.2587794999818544,
        "compression_ratio": 1.6287425149700598,
        "end": 1006.88,
        "id": 151,
        "no_speech_prob": 0.2658357620239258,
        "seek": 98568,
        "start": 1000.2399999999999,
        "temperature": 0,
        "text": " Once again, if you choose to sponsor this YouTube channel on YouTube, you will get a big green thing",
        "tokens": [
          51092,
          3443,
          797,
          11,
          498,
          291,
          2826,
          281,
          16198,
          341,
          3088,
          2269,
          322,
          3088,
          11,
          291,
          486,
          483,
          257,
          955,
          3092,
          551,
          51424
        ]
      },
      {
        "avg_logprob": -0.2587794999818544,
        "compression_ratio": 1.6287425149700598,
        "end": 1013.04,
        "id": 152,
        "no_speech_prob": 0.2658357620239258,
        "seek": 98568,
        "start": 1006.88,
        "temperature": 0,
        "text": " in the chat that says new sponsor. And I will say, oh, new sponsor. And then some badge appears next",
        "tokens": [
          51424,
          294,
          264,
          5081,
          300,
          1619,
          777,
          16198,
          13,
          400,
          286,
          486,
          584,
          11,
          1954,
          11,
          777,
          16198,
          13,
          400,
          550,
          512,
          25797,
          7038,
          958,
          51732
        ]
      },
      {
        "avg_logprob": -0.19262844683176064,
        "compression_ratio": 1.545,
        "end": 1020.3199999999999,
        "id": 153,
        "no_speech_prob": 0.010327916592359543,
        "seek": 101304,
        "start": 1013.04,
        "temperature": 0,
        "text": " to your name. Why not? Subscribe today. You will get a piece of graphics that appears next to your",
        "tokens": [
          50364,
          281,
          428,
          1315,
          13,
          1545,
          406,
          30,
          10611,
          965,
          13,
          509,
          486,
          483,
          257,
          2522,
          295,
          11837,
          300,
          7038,
          958,
          281,
          428,
          50728
        ]
      },
      {
        "avg_logprob": -0.19262844683176064,
        "compression_ratio": 1.545,
        "end": 1025.2,
        "id": 154,
        "no_speech_prob": 0.010327916592359543,
        "seek": 101304,
        "start": 1020.3199999999999,
        "temperature": 0,
        "text": " name. Why you would want that, I don't know. But hey, it's possible for you. All right. Thanks,",
        "tokens": [
          50728,
          1315,
          13,
          1545,
          291,
          576,
          528,
          300,
          11,
          286,
          500,
          380,
          458,
          13,
          583,
          4177,
          11,
          309,
          311,
          1944,
          337,
          291,
          13,
          1057,
          558,
          13,
          2561,
          11,
          50972
        ]
      },
      {
        "avg_logprob": -0.19262844683176064,
        "compression_ratio": 1.545,
        "end": 1030.8,
        "id": 155,
        "no_speech_prob": 0.010327916592359543,
        "seek": 101304,
        "start": 1025.2,
        "temperature": 0,
        "text": " everybody. That was my sponsored by the sponsors of the sponsored coding train sponsors.",
        "tokens": [
          50972,
          2201,
          13,
          663,
          390,
          452,
          16621,
          538,
          264,
          22593,
          295,
          264,
          16621,
          17720,
          3847,
          22593,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.19262844683176064,
        "compression_ratio": 1.545,
        "end": 1035.2,
        "id": 156,
        "no_speech_prob": 0.010327916592359543,
        "seek": 101304,
        "start": 1033.68,
        "temperature": 0,
        "text": " All right. Let's move on.",
        "tokens": [
          51396,
          1057,
          558,
          13,
          961,
          311,
          1286,
          322,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.22635772547771021,
        "compression_ratio": 1.5965665236051503,
        "end": 1047.04,
        "id": 157,
        "no_speech_prob": 0.015188664197921753,
        "seek": 103520,
        "start": 1035.2,
        "temperature": 0,
        "text": " Annabelle. By the way, there's also a thing. This is one thing I really like to explore. I know",
        "tokens": [
          50364,
          8860,
          455,
          4434,
          13,
          3146,
          264,
          636,
          11,
          456,
          311,
          611,
          257,
          551,
          13,
          639,
          307,
          472,
          551,
          286,
          534,
          411,
          281,
          6839,
          13,
          286,
          458,
          50956
        ]
      },
      {
        "avg_logprob": -0.22635772547771021,
        "compression_ratio": 1.5965665236051503,
        "end": 1051.76,
        "id": 158,
        "no_speech_prob": 0.015188664197921753,
        "seek": 103520,
        "start": 1047.04,
        "temperature": 0,
        "text": " Twitch has a lot of this. But I think there are ways that I can hook stuff up into the chat to",
        "tokens": [
          50956,
          22222,
          575,
          257,
          688,
          295,
          341,
          13,
          583,
          286,
          519,
          456,
          366,
          2098,
          300,
          286,
          393,
          6328,
          1507,
          493,
          666,
          264,
          5081,
          281,
          51192
        ]
      },
      {
        "avg_logprob": -0.22635772547771021,
        "compression_ratio": 1.5965665236051503,
        "end": 1056.72,
        "id": 159,
        "no_speech_prob": 0.015188664197921753,
        "seek": 103520,
        "start": 1051.76,
        "temperature": 0,
        "text": " various devices and things here. And I think that would be fun. But I also could do tutorials about",
        "tokens": [
          51192,
          3683,
          5759,
          293,
          721,
          510,
          13,
          400,
          286,
          519,
          300,
          576,
          312,
          1019,
          13,
          583,
          286,
          611,
          727,
          360,
          17616,
          466,
          51440
        ]
      },
      {
        "avg_logprob": -0.22635772547771021,
        "compression_ratio": 1.5965665236051503,
        "end": 1062.56,
        "id": 160,
        "no_speech_prob": 0.015188664197921753,
        "seek": 103520,
        "start": 1056.72,
        "temperature": 0,
        "text": " getting a light to turn on or something. So if anybody has experiences with that,",
        "tokens": [
          51440,
          1242,
          257,
          1442,
          281,
          1261,
          322,
          420,
          746,
          13,
          407,
          498,
          4472,
          575,
          5235,
          365,
          300,
          11,
          51732
        ]
      },
      {
        "avg_logprob": -0.21640816042500158,
        "compression_ratio": 1.436046511627907,
        "end": 1068.24,
        "id": 161,
        "no_speech_prob": 0.001367006916552782,
        "seek": 106256,
        "start": 1062.56,
        "temperature": 0,
        "text": " in particular with YouTube streaming, let me know. Okay.",
        "tokens": [
          50364,
          294,
          1729,
          365,
          3088,
          11791,
          11,
          718,
          385,
          458,
          13,
          1033,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.21640816042500158,
        "compression_ratio": 1.436046511627907,
        "end": 1086.08,
        "id": 162,
        "no_speech_prob": 0.001367006916552782,
        "seek": 106256,
        "start": 1078.56,
        "temperature": 0,
        "text": " Hello. Welcome to a second video on promises. Now, what I think if you watched the previous video,",
        "tokens": [
          51164,
          2425,
          13,
          4027,
          281,
          257,
          1150,
          960,
          322,
          16403,
          13,
          823,
          11,
          437,
          286,
          519,
          498,
          291,
          6337,
          264,
          3894,
          960,
          11,
          51540
        ]
      },
      {
        "avg_logprob": -0.21640816042500158,
        "compression_ratio": 1.436046511627907,
        "end": 1092.32,
        "id": 163,
        "no_speech_prob": 0.001367006916552782,
        "seek": 106256,
        "start": 1086.08,
        "temperature": 0,
        "text": " I talked about the idea of a promise, how to use a promise with this function called fetch,",
        "tokens": [
          51540,
          286,
          2825,
          466,
          264,
          1558,
          295,
          257,
          6228,
          11,
          577,
          281,
          764,
          257,
          6228,
          365,
          341,
          2445,
          1219,
          23673,
          11,
          51852
        ]
      },
      {
        "avg_logprob": -0.2134654542319795,
        "compression_ratio": 1.6319444444444444,
        "end": 1100.1599999999999,
        "id": 164,
        "no_speech_prob": 0.00019410828826949,
        "seek": 109232,
        "start": 1092.32,
        "temperature": 0,
        "text": " which retrieves data from a URL and a variety of other things. And I looked at how you when the",
        "tokens": [
          50364,
          597,
          19817,
          977,
          1412,
          490,
          257,
          12905,
          293,
          257,
          5673,
          295,
          661,
          721,
          13,
          400,
          286,
          2956,
          412,
          577,
          291,
          562,
          264,
          50756
        ]
      },
      {
        "avg_logprob": -0.2134654542319795,
        "compression_ratio": 1.6319444444444444,
        "end": 1106.3999999999999,
        "id": 165,
        "no_speech_prob": 0.00019410828826949,
        "seek": 109232,
        "start": 1100.1599999999999,
        "temperature": 0,
        "text": " promise finishes, how you use vend to execute code and how you use catch if there's an error.",
        "tokens": [
          50756,
          6228,
          23615,
          11,
          577,
          291,
          764,
          10169,
          281,
          14483,
          3089,
          293,
          577,
          291,
          764,
          3745,
          498,
          456,
          311,
          364,
          6713,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.2134654542319795,
        "compression_ratio": 1.6319444444444444,
        "end": 1110.48,
        "id": 166,
        "no_speech_prob": 0.00019410828826949,
        "seek": 109232,
        "start": 1106.3999999999999,
        "temperature": 0,
        "text": " And you can chain promises if there's a bunch of things happening in sequence. So that's what I",
        "tokens": [
          51068,
          400,
          291,
          393,
          5021,
          16403,
          498,
          456,
          311,
          257,
          3840,
          295,
          721,
          2737,
          294,
          8310,
          13,
          407,
          300,
          311,
          437,
          286,
          51272
        ]
      },
      {
        "avg_logprob": -0.2134654542319795,
        "compression_ratio": 1.6319444444444444,
        "end": 1114.72,
        "id": 167,
        "no_speech_prob": 0.00019410828826949,
        "seek": 109232,
        "start": 1110.48,
        "temperature": 0,
        "text": " tried to look at so far in the previous video. Now, I'm actually going to take a step back here",
        "tokens": [
          51272,
          3031,
          281,
          574,
          412,
          370,
          1400,
          294,
          264,
          3894,
          960,
          13,
          823,
          11,
          286,
          478,
          767,
          516,
          281,
          747,
          257,
          1823,
          646,
          510,
          51484
        ]
      },
      {
        "avg_logprob": -0.2134654542319795,
        "compression_ratio": 1.6319444444444444,
        "end": 1120.08,
        "id": 168,
        "no_speech_prob": 0.00019410828826949,
        "seek": 109232,
        "start": 1114.72,
        "temperature": 0,
        "text": " and in a way do something much simpler and probably less important. But maybe we'll give",
        "tokens": [
          51484,
          293,
          294,
          257,
          636,
          360,
          746,
          709,
          18587,
          293,
          1391,
          1570,
          1021,
          13,
          583,
          1310,
          321,
          603,
          976,
          51752
        ]
      },
      {
        "avg_logprob": -0.20466860135396323,
        "compression_ratio": 1.8122605363984674,
        "end": 1125.76,
        "id": 169,
        "no_speech_prob": 0.008984856307506561,
        "seek": 112008,
        "start": 1120.08,
        "temperature": 0,
        "text": " some good background foundational knowledge. So I'm going to talk about how to make your own",
        "tokens": [
          50364,
          512,
          665,
          3678,
          32195,
          3601,
          13,
          407,
          286,
          478,
          516,
          281,
          751,
          466,
          577,
          281,
          652,
          428,
          1065,
          50648
        ]
      },
      {
        "avg_logprob": -0.20466860135396323,
        "compression_ratio": 1.8122605363984674,
        "end": 1132.48,
        "id": 170,
        "no_speech_prob": 0.008984856307506561,
        "seek": 112008,
        "start": 1125.76,
        "temperature": 0,
        "text": " promise. And just in case, maybe you're here for like how to keep your own promises.",
        "tokens": [
          50648,
          6228,
          13,
          400,
          445,
          294,
          1389,
          11,
          1310,
          291,
          434,
          510,
          337,
          411,
          577,
          281,
          1066,
          428,
          1065,
          16403,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.20466860135396323,
        "compression_ratio": 1.8122605363984674,
        "end": 1136.8799999999999,
        "id": 171,
        "no_speech_prob": 0.008984856307506561,
        "seek": 112008,
        "start": 1133.28,
        "temperature": 0,
        "text": " And if you're here for like a self-help video, unfortunately, that's not what this is. But maybe",
        "tokens": [
          51024,
          400,
          498,
          291,
          434,
          510,
          337,
          411,
          257,
          2698,
          12,
          37451,
          960,
          11,
          7015,
          11,
          300,
          311,
          406,
          437,
          341,
          307,
          13,
          583,
          1310,
          51204
        ]
      },
      {
        "avg_logprob": -0.20466860135396323,
        "compression_ratio": 1.8122605363984674,
        "end": 1142.08,
        "id": 172,
        "no_speech_prob": 0.008984856307506561,
        "seek": 112008,
        "start": 1136.8799999999999,
        "temperature": 0,
        "text": " you want to learn about coding. You might want to go to the beginner ones, though. But maybe this",
        "tokens": [
          51204,
          291,
          528,
          281,
          1466,
          466,
          17720,
          13,
          509,
          1062,
          528,
          281,
          352,
          281,
          264,
          22080,
          2306,
          11,
          1673,
          13,
          583,
          1310,
          341,
          51464
        ]
      },
      {
        "avg_logprob": -0.20466860135396323,
        "compression_ratio": 1.8122605363984674,
        "end": 1147.04,
        "id": 173,
        "no_speech_prob": 0.008984856307506561,
        "seek": 112008,
        "start": 1142.08,
        "temperature": 0,
        "text": " could be the first video you watch. Anyway, how to make your own promise. So let's come with me over",
        "tokens": [
          51464,
          727,
          312,
          264,
          700,
          960,
          291,
          1159,
          13,
          5684,
          11,
          577,
          281,
          652,
          428,
          1065,
          6228,
          13,
          407,
          718,
          311,
          808,
          365,
          385,
          670,
          51712
        ]
      },
      {
        "avg_logprob": -0.1785384539900155,
        "compression_ratio": 1.6561085972850678,
        "end": 1154.32,
        "id": 174,
        "no_speech_prob": 0.0009399268892593682,
        "seek": 114704,
        "start": 1147.04,
        "temperature": 0,
        "text": " here. And so this is more relevant probably if you are the developer of a JavaScript library and",
        "tokens": [
          50364,
          510,
          13,
          400,
          370,
          341,
          307,
          544,
          7340,
          1391,
          498,
          291,
          366,
          264,
          10754,
          295,
          257,
          15778,
          6405,
          293,
          50728
        ]
      },
      {
        "avg_logprob": -0.1785384539900155,
        "compression_ratio": 1.6561085972850678,
        "end": 1159.52,
        "id": 175,
        "no_speech_prob": 0.0009399268892593682,
        "seek": 114704,
        "start": 1154.32,
        "temperature": 0,
        "text": " you want to support promises in your library. Most of the stuff that I'm going to do will involve",
        "tokens": [
          50728,
          291,
          528,
          281,
          1406,
          16403,
          294,
          428,
          6405,
          13,
          4534,
          295,
          264,
          1507,
          300,
          286,
          478,
          516,
          281,
          360,
          486,
          9494,
          50988
        ]
      },
      {
        "avg_logprob": -0.1785384539900155,
        "compression_ratio": 1.6561085972850678,
        "end": 1165.68,
        "id": 176,
        "no_speech_prob": 0.0009399268892593682,
        "seek": 114704,
        "start": 1159.52,
        "temperature": 0,
        "text": " making use of other libraries that give me promises. And I take those promises and hope",
        "tokens": [
          50988,
          1455,
          764,
          295,
          661,
          15148,
          300,
          976,
          385,
          16403,
          13,
          400,
          286,
          747,
          729,
          16403,
          293,
          1454,
          51296
        ]
      },
      {
        "avg_logprob": -0.1785384539900155,
        "compression_ratio": 1.6561085972850678,
        "end": 1171.84,
        "id": 177,
        "no_speech_prob": 0.0009399268892593682,
        "seek": 114704,
        "start": 1165.68,
        "temperature": 0,
        "text": " that they're kept. And also, I'm actually eventually going to get to this like new,",
        "tokens": [
          51296,
          300,
          436,
          434,
          4305,
          13,
          400,
          611,
          11,
          286,
          478,
          767,
          4728,
          516,
          281,
          483,
          281,
          341,
          411,
          777,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.23902266633276845,
        "compression_ratio": 1.5512820512820513,
        "end": 1180,
        "id": 178,
        "no_speech_prob": 0.000687844178173691,
        "seek": 117184,
        "start": 1171.84,
        "temperature": 0,
        "text": " I think these are a part of ES, I think it's 2793 and 402. It's not even a number.",
        "tokens": [
          50364,
          286,
          519,
          613,
          366,
          257,
          644,
          295,
          12564,
          11,
          286,
          519,
          309,
          311,
          7634,
          26372,
          293,
          3356,
          17,
          13,
          467,
          311,
          406,
          754,
          257,
          1230,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.23902266633276845,
        "compression_ratio": 1.5512820512820513,
        "end": 1186.1599999999999,
        "id": 179,
        "no_speech_prob": 0.000687844178173691,
        "seek": 117184,
        "start": 1181.12,
        "temperature": 0,
        "text": " 2009. That's anyway, I think it's actually just ES7. I was trying to make a joke there.",
        "tokens": [
          50828,
          11453,
          13,
          663,
          311,
          4033,
          11,
          286,
          519,
          309,
          311,
          767,
          445,
          12564,
          22,
          13,
          286,
          390,
          1382,
          281,
          652,
          257,
          7647,
          456,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.23902266633276845,
        "compression_ratio": 1.5512820512820513,
        "end": 1191.84,
        "id": 180,
        "no_speech_prob": 0.000687844178173691,
        "seek": 117184,
        "start": 1186.72,
        "temperature": 0,
        "text": " But I'm actually going to use async and await, the key words to write an asynchronous function",
        "tokens": [
          51108,
          583,
          286,
          478,
          767,
          516,
          281,
          764,
          382,
          34015,
          293,
          19670,
          11,
          264,
          2141,
          2283,
          281,
          2464,
          364,
          49174,
          2445,
          51364
        ]
      },
      {
        "avg_logprob": -0.23902266633276845,
        "compression_ratio": 1.5512820512820513,
        "end": 1197.04,
        "id": 181,
        "no_speech_prob": 0.000687844178173691,
        "seek": 117184,
        "start": 1191.84,
        "temperature": 0,
        "text": " that returns a promise. But I'm stepping through this stuff one step at a time. So come back over",
        "tokens": [
          51364,
          300,
          11247,
          257,
          6228,
          13,
          583,
          286,
          478,
          16821,
          807,
          341,
          1507,
          472,
          1823,
          412,
          257,
          565,
          13,
          407,
          808,
          646,
          670,
          51624
        ]
      },
      {
        "avg_logprob": -0.19527631647446575,
        "compression_ratio": 1.6701388888888888,
        "end": 1202.1599999999999,
        "id": 182,
        "no_speech_prob": 0.0780680701136589,
        "seek": 119704,
        "start": 1197.04,
        "temperature": 0,
        "text": " here with me. And so I've got a little p5 sketch. There's nothing about this that you need p5 for,",
        "tokens": [
          50364,
          510,
          365,
          385,
          13,
          400,
          370,
          286,
          600,
          658,
          257,
          707,
          280,
          20,
          12325,
          13,
          821,
          311,
          1825,
          466,
          341,
          300,
          291,
          643,
          280,
          20,
          337,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.19527631647446575,
        "compression_ratio": 1.6701388888888888,
        "end": 1206.8,
        "id": 183,
        "no_speech_prob": 0.0780680701136589,
        "seek": 119704,
        "start": 1202.1599999999999,
        "temperature": 0,
        "text": " but it's my comfort object. You know, when you're small and you have your little lovey that you",
        "tokens": [
          50620,
          457,
          309,
          311,
          452,
          3400,
          2657,
          13,
          509,
          458,
          11,
          562,
          291,
          434,
          1359,
          293,
          291,
          362,
          428,
          707,
          959,
          88,
          300,
          291,
          50852
        ]
      },
      {
        "avg_logprob": -0.19527631647446575,
        "compression_ratio": 1.6701388888888888,
        "end": 1214.24,
        "id": 184,
        "no_speech_prob": 0.0780680701136589,
        "seek": 119704,
        "start": 1206.8,
        "temperature": 0,
        "text": " sleep with, p5 is like my little lovey that I code with. And so what does this do? This in setup,",
        "tokens": [
          50852,
          2817,
          365,
          11,
          280,
          20,
          307,
          411,
          452,
          707,
          959,
          88,
          300,
          286,
          3089,
          365,
          13,
          400,
          370,
          437,
          775,
          341,
          360,
          30,
          639,
          294,
          8657,
          11,
          51224
        ]
      },
      {
        "avg_logprob": -0.19527631647446575,
        "compression_ratio": 1.6701388888888888,
        "end": 1218,
        "id": 185,
        "no_speech_prob": 0.0780680701136589,
        "seek": 119704,
        "start": 1214.24,
        "temperature": 0,
        "text": " I don't make a canvas, I called setTimeout. If you don't know what setTimeout is, I have a whole",
        "tokens": [
          51224,
          286,
          500,
          380,
          652,
          257,
          16267,
          11,
          286,
          1219,
          992,
          22233,
          346,
          13,
          759,
          291,
          500,
          380,
          458,
          437,
          992,
          22233,
          346,
          307,
          11,
          286,
          362,
          257,
          1379,
          51412
        ]
      },
      {
        "avg_logprob": -0.19527631647446575,
        "compression_ratio": 1.6701388888888888,
        "end": 1224.48,
        "id": 186,
        "no_speech_prob": 0.0780680701136589,
        "seek": 119704,
        "start": 1218,
        "temperature": 0,
        "text": " video about that, which executes a callback, the sayHello function 1000 milliseconds later,",
        "tokens": [
          51412,
          960,
          466,
          300,
          11,
          597,
          4454,
          1819,
          257,
          818,
          3207,
          11,
          264,
          584,
          15947,
          2445,
          9714,
          34184,
          1780,
          11,
          51736
        ]
      },
      {
        "avg_logprob": -0.18484308205398858,
        "compression_ratio": 1.5815899581589958,
        "end": 1229.3600000000001,
        "id": 187,
        "no_speech_prob": 0.001896892674267292,
        "seek": 122448,
        "start": 1224.48,
        "temperature": 0,
        "text": " and that makes a paragraph hello. So let me go to the browser. And you can see one second later,",
        "tokens": [
          50364,
          293,
          300,
          1669,
          257,
          18865,
          7751,
          13,
          407,
          718,
          385,
          352,
          281,
          264,
          11185,
          13,
          400,
          291,
          393,
          536,
          472,
          1150,
          1780,
          11,
          50608
        ]
      },
      {
        "avg_logprob": -0.18484308205398858,
        "compression_ratio": 1.5815899581589958,
        "end": 1236.32,
        "id": 188,
        "no_speech_prob": 0.001896892674267292,
        "seek": 122448,
        "start": 1229.3600000000001,
        "temperature": 0,
        "text": " boom, hello. And if I made this 5000 or 6000, you know, six seconds later, that hello is going to",
        "tokens": [
          50608,
          9351,
          11,
          7751,
          13,
          400,
          498,
          286,
          1027,
          341,
          23777,
          420,
          41789,
          11,
          291,
          458,
          11,
          2309,
          3949,
          1780,
          11,
          300,
          7751,
          307,
          516,
          281,
          50956
        ]
      },
      {
        "avg_logprob": -0.18484308205398858,
        "compression_ratio": 1.5815899581589958,
        "end": 1244.16,
        "id": 189,
        "no_speech_prob": 0.001896892674267292,
        "seek": 122448,
        "start": 1236.32,
        "temperature": 0,
        "text": " pop up. So this is the old the old way of doing it in JavaScript, we have a function that's",
        "tokens": [
          50956,
          1665,
          493,
          13,
          407,
          341,
          307,
          264,
          1331,
          264,
          1331,
          636,
          295,
          884,
          309,
          294,
          15778,
          11,
          321,
          362,
          257,
          2445,
          300,
          311,
          51348
        ]
      },
      {
        "avg_logprob": -0.18484308205398858,
        "compression_ratio": 1.5815899581589958,
        "end": 1250,
        "id": 190,
        "no_speech_prob": 0.001896892674267292,
        "seek": 122448,
        "start": 1244.16,
        "temperature": 0,
        "text": " asynchronous that we pass a callback. So what if I wanted to create a version of setTimeout",
        "tokens": [
          51348,
          49174,
          300,
          321,
          1320,
          257,
          818,
          3207,
          13,
          407,
          437,
          498,
          286,
          1415,
          281,
          1884,
          257,
          3037,
          295,
          992,
          22233,
          346,
          51640
        ]
      },
      {
        "avg_logprob": -0.17540151194522255,
        "compression_ratio": 1.87012987012987,
        "end": 1256.24,
        "id": 191,
        "no_speech_prob": 0.0011335473973304033,
        "seek": 125000,
        "start": 1250.64,
        "temperature": 0,
        "text": " that returned a promise instead. So I'm going to write my own. And again, this is really I don't",
        "tokens": [
          50396,
          300,
          8752,
          257,
          6228,
          2602,
          13,
          407,
          286,
          478,
          516,
          281,
          2464,
          452,
          1065,
          13,
          400,
          797,
          11,
          341,
          307,
          534,
          286,
          500,
          380,
          50676
        ]
      },
      {
        "avg_logprob": -0.17540151194522255,
        "compression_ratio": 1.87012987012987,
        "end": 1259.6,
        "id": 192,
        "no_speech_prob": 0.0011335473973304033,
        "seek": 125000,
        "start": 1256.24,
        "temperature": 0,
        "text": " know that this is something you need to do in a program, but this is going to give us some",
        "tokens": [
          50676,
          458,
          300,
          341,
          307,
          746,
          291,
          643,
          281,
          360,
          294,
          257,
          1461,
          11,
          457,
          341,
          307,
          516,
          281,
          976,
          505,
          512,
          50844
        ]
      },
      {
        "avg_logprob": -0.17540151194522255,
        "compression_ratio": 1.87012987012987,
        "end": 1264.32,
        "id": 193,
        "no_speech_prob": 0.0011335473973304033,
        "seek": 125000,
        "start": 1259.6,
        "temperature": 0,
        "text": " background. So I'm going to write a function and I'm going to this, by the way, is not my original",
        "tokens": [
          50844,
          3678,
          13,
          407,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          293,
          286,
          478,
          516,
          281,
          341,
          11,
          538,
          264,
          636,
          11,
          307,
          406,
          452,
          3380,
          51080
        ]
      },
      {
        "avg_logprob": -0.17540151194522255,
        "compression_ratio": 1.87012987012987,
        "end": 1268.08,
        "id": 194,
        "no_speech_prob": 0.0011335473973304033,
        "seek": 125000,
        "start": 1264.32,
        "temperature": 0,
        "text": " idea. I'm sure you can find lots of tutorials that show this exact same scenario. I probably",
        "tokens": [
          51080,
          1558,
          13,
          286,
          478,
          988,
          291,
          393,
          915,
          3195,
          295,
          17616,
          300,
          855,
          341,
          1900,
          912,
          9005,
          13,
          286,
          1391,
          51268
        ]
      },
      {
        "avg_logprob": -0.17540151194522255,
        "compression_ratio": 1.87012987012987,
        "end": 1273.12,
        "id": 195,
        "no_speech_prob": 0.0011335473973304033,
        "seek": 125000,
        "start": 1268.08,
        "temperature": 0,
        "text": " read a few of them. So I'm going to write a function called delay. I could also call it like",
        "tokens": [
          51268,
          1401,
          257,
          1326,
          295,
          552,
          13,
          407,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          1219,
          8577,
          13,
          286,
          727,
          611,
          818,
          309,
          411,
          51520
        ]
      },
      {
        "avg_logprob": -0.17540151194522255,
        "compression_ratio": 1.87012987012987,
        "end": 1277.68,
        "id": 196,
        "no_speech_prob": 0.0011335473973304033,
        "seek": 125000,
        "start": 1273.12,
        "temperature": 0,
        "text": " setTimeout promise, just to be explicit about what I'm doing. But I'm just going to give it a different",
        "tokens": [
          51520,
          992,
          22233,
          346,
          6228,
          11,
          445,
          281,
          312,
          13691,
          466,
          437,
          286,
          478,
          884,
          13,
          583,
          286,
          478,
          445,
          516,
          281,
          976,
          309,
          257,
          819,
          51748
        ]
      },
      {
        "avg_logprob": -0.21368530953284537,
        "compression_ratio": 1.737327188940092,
        "end": 1284.96,
        "id": 197,
        "no_speech_prob": 0.00040447909850627184,
        "seek": 127768,
        "start": 1277.68,
        "temperature": 0,
        "text": " name called delay. And what I want to do is I want that function to take an amount of time. So",
        "tokens": [
          50364,
          1315,
          1219,
          8577,
          13,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          300,
          2445,
          281,
          747,
          364,
          2372,
          295,
          565,
          13,
          407,
          50728
        ]
      },
      {
        "avg_logprob": -0.21368530953284537,
        "compression_ratio": 1.737327188940092,
        "end": 1291.6000000000001,
        "id": 198,
        "no_speech_prob": 0.00040447909850627184,
        "seek": 127768,
        "start": 1284.96,
        "temperature": 0,
        "text": " that function is going to so really what I'm doing here is like just this to start setTimeout.",
        "tokens": [
          50728,
          300,
          2445,
          307,
          516,
          281,
          370,
          534,
          437,
          286,
          478,
          884,
          510,
          307,
          411,
          445,
          341,
          281,
          722,
          992,
          22233,
          346,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.21368530953284537,
        "compression_ratio": 1.737327188940092,
        "end": 1298.3200000000002,
        "id": 199,
        "no_speech_prob": 0.00040447909850627184,
        "seek": 127768,
        "start": 1293.52,
        "temperature": 0,
        "text": " So at first, I've just like basically, this is completely insane what I've done, but I've written",
        "tokens": [
          51156,
          407,
          412,
          700,
          11,
          286,
          600,
          445,
          411,
          1936,
          11,
          341,
          307,
          2584,
          10838,
          437,
          286,
          600,
          1096,
          11,
          457,
          286,
          600,
          3720,
          51396
        ]
      },
      {
        "avg_logprob": -0.21368530953284537,
        "compression_ratio": 1.737327188940092,
        "end": 1303.04,
        "id": 200,
        "no_speech_prob": 0.00040447909850627184,
        "seek": 127768,
        "start": 1298.3200000000002,
        "temperature": 0,
        "text": " my own function called delay to just call setTimeout. And if I give that, you know, 1000.",
        "tokens": [
          51396,
          452,
          1065,
          2445,
          1219,
          8577,
          281,
          445,
          818,
          992,
          22233,
          346,
          13,
          400,
          498,
          286,
          976,
          300,
          11,
          291,
          458,
          11,
          9714,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.31725511318299826,
        "compression_ratio": 1.4751381215469612,
        "end": 1310,
        "id": 201,
        "no_speech_prob": 0.00004832530248677358,
        "seek": 130304,
        "start": 1303.68,
        "temperature": 0,
        "text": " There we go. But what I want to do is I want to do this. I want to say delay1000.then.",
        "tokens": [
          50396,
          821,
          321,
          352,
          13,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          360,
          341,
          13,
          286,
          528,
          281,
          584,
          8577,
          21199,
          13,
          19096,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.31725511318299826,
        "compression_ratio": 1.4751381215469612,
        "end": 1320.1599999999999,
        "id": 202,
        "no_speech_prob": 0.00004832530248677358,
        "seek": 130304,
        "start": 1311.84,
        "temperature": 0,
        "text": " And I'm going to use the arrow syntax here, createP, hello. So again, if the arrow syntax",
        "tokens": [
          50804,
          400,
          286,
          478,
          516,
          281,
          764,
          264,
          11610,
          28431,
          510,
          11,
          1884,
          47,
          11,
          7751,
          13,
          407,
          797,
          11,
          498,
          264,
          11610,
          28431,
          51220
        ]
      },
      {
        "avg_logprob": -0.31725511318299826,
        "compression_ratio": 1.4751381215469612,
        "end": 1326.56,
        "id": 203,
        "no_speech_prob": 0.00004832530248677358,
        "seek": 130304,
        "start": 1320.1599999999999,
        "temperature": 0,
        "text": " is not familiar to you, a new part of ES6 JavaScript, I have a video on that. And then I'm",
        "tokens": [
          51220,
          307,
          406,
          4963,
          281,
          291,
          11,
          257,
          777,
          644,
          295,
          12564,
          21,
          15778,
          11,
          286,
          362,
          257,
          960,
          322,
          300,
          13,
          400,
          550,
          286,
          478,
          51540
        ]
      },
      {
        "avg_logprob": -0.2274898677677303,
        "compression_ratio": 1.5280898876404494,
        "end": 1339.2,
        "id": 204,
        "no_speech_prob": 0.0015730905579403043,
        "seek": 132656,
        "start": 1327.52,
        "temperature": 0,
        "text": " going to say catch console.log error. So I want and I'm missing some stuff here. This doesn't",
        "tokens": [
          50412,
          516,
          281,
          584,
          3745,
          11076,
          13,
          4987,
          6713,
          13,
          407,
          286,
          528,
          293,
          286,
          478,
          5361,
          512,
          1507,
          510,
          13,
          639,
          1177,
          380,
          50996
        ]
      },
      {
        "avg_logprob": -0.2274898677677303,
        "compression_ratio": 1.5280898876404494,
        "end": 1346.1599999999999,
        "id": 205,
        "no_speech_prob": 0.0015730905579403043,
        "seek": 132656,
        "start": 1339.2,
        "temperature": 0,
        "text": " need semicolon. There we go. So this is what I want to do. I want to write my code like this.",
        "tokens": [
          50996,
          643,
          27515,
          38780,
          13,
          821,
          321,
          352,
          13,
          407,
          341,
          307,
          437,
          286,
          528,
          281,
          360,
          13,
          286,
          528,
          281,
          2464,
          452,
          3089,
          411,
          341,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2274898677677303,
        "compression_ratio": 1.5280898876404494,
        "end": 1351.84,
        "id": 206,
        "no_speech_prob": 0.0015730905579403043,
        "seek": 132656,
        "start": 1346.1599999999999,
        "temperature": 0,
        "text": " I want the delay function to delay for one second, return a promise. When it's done,",
        "tokens": [
          51344,
          286,
          528,
          264,
          8577,
          2445,
          281,
          8577,
          337,
          472,
          1150,
          11,
          2736,
          257,
          6228,
          13,
          1133,
          309,
          311,
          1096,
          11,
          51628
        ]
      },
      {
        "avg_logprob": -0.2137042454310826,
        "compression_ratio": 1.6988416988416988,
        "end": 1357.36,
        "id": 207,
        "no_speech_prob": 0.0000564979127375409,
        "seek": 135184,
        "start": 1351.84,
        "temperature": 0,
        "text": " create that paragraph. And if there was an error somehow, console.log the error. And yesterday,",
        "tokens": [
          50364,
          1884,
          300,
          18865,
          13,
          400,
          498,
          456,
          390,
          364,
          6713,
          6063,
          11,
          11076,
          13,
          4987,
          264,
          6713,
          13,
          400,
          5186,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.2137042454310826,
        "compression_ratio": 1.6988416988416988,
        "end": 1361.6799999999998,
        "id": 208,
        "no_speech_prob": 0.0000564979127375409,
        "seek": 135184,
        "start": 1357.36,
        "temperature": 0,
        "text": " someone was saying to me, I should say console.error, or I could put the error in the",
        "tokens": [
          50640,
          1580,
          390,
          1566,
          281,
          385,
          11,
          286,
          820,
          584,
          11076,
          13,
          260,
          2874,
          11,
          420,
          286,
          727,
          829,
          264,
          6713,
          294,
          264,
          50856
        ]
      },
      {
        "avg_logprob": -0.2137042454310826,
        "compression_ratio": 1.6988416988416988,
        "end": 1367.36,
        "id": 209,
        "no_speech_prob": 0.0000564979127375409,
        "seek": 135184,
        "start": 1363.84,
        "temperature": 0,
        "text": " DOM as well. So okay, so this is what I want to do. Now, this won't work right now,",
        "tokens": [
          50964,
          35727,
          382,
          731,
          13,
          407,
          1392,
          11,
          370,
          341,
          307,
          437,
          286,
          528,
          281,
          360,
          13,
          823,
          11,
          341,
          1582,
          380,
          589,
          558,
          586,
          11,
          51140
        ]
      },
      {
        "avg_logprob": -0.2137042454310826,
        "compression_ratio": 1.6988416988416988,
        "end": 1372.72,
        "id": 210,
        "no_speech_prob": 0.0000564979127375409,
        "seek": 135184,
        "start": 1368.24,
        "temperature": 0,
        "text": " because it's going to say cannot read property then of undefined, because there's nothing,",
        "tokens": [
          51184,
          570,
          309,
          311,
          516,
          281,
          584,
          2644,
          1401,
          4707,
          550,
          295,
          674,
          5666,
          2001,
          11,
          570,
          456,
          311,
          1825,
          11,
          51408
        ]
      },
      {
        "avg_logprob": -0.2137042454310826,
        "compression_ratio": 1.6988416988416988,
        "end": 1378.6399999999999,
        "id": 211,
        "no_speech_prob": 0.0000564979127375409,
        "seek": 135184,
        "start": 1372.72,
        "temperature": 0,
        "text": " there's no promise that's been returned. So what I need is my delay function has to",
        "tokens": [
          51408,
          456,
          311,
          572,
          6228,
          300,
          311,
          668,
          8752,
          13,
          407,
          437,
          286,
          643,
          307,
          452,
          8577,
          2445,
          575,
          281,
          51704
        ]
      },
      {
        "avg_logprob": -0.21609501506006995,
        "compression_ratio": 1.4565217391304348,
        "end": 1387.6000000000001,
        "id": 212,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 137864,
        "start": 1379.2800000000002,
        "temperature": 0,
        "text": " return a promise. Do I have to say new promise? ES8, hold on, time out.",
        "tokens": [
          50396,
          2736,
          257,
          6228,
          13,
          1144,
          286,
          362,
          281,
          584,
          777,
          6228,
          30,
          12564,
          23,
          11,
          1797,
          322,
          11,
          565,
          484,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.21609501506006995,
        "compression_ratio": 1.4565217391304348,
        "end": 1392.48,
        "id": 213,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 137864,
        "start": 1390.16,
        "temperature": 0,
        "text": " I shouldn't look at the chat in the middle of these tutorials.",
        "tokens": [
          50940,
          286,
          4659,
          380,
          574,
          412,
          264,
          5081,
          294,
          264,
          2808,
          295,
          613,
          17616,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.21609501506006995,
        "compression_ratio": 1.4565217391304348,
        "end": 1397.8400000000001,
        "id": 214,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 137864,
        "start": 1394.64,
        "temperature": 0,
        "text": " Oh, and you can't even see this. I went off the, but is this,",
        "tokens": [
          51164,
          876,
          11,
          293,
          291,
          393,
          380,
          754,
          536,
          341,
          13,
          286,
          1437,
          766,
          264,
          11,
          457,
          307,
          341,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.21609501506006995,
        "compression_ratio": 1.4565217391304348,
        "end": 1408.24,
        "id": 215,
        "no_speech_prob": 0.00011959840776398778,
        "seek": 137864,
        "start": 1399.76,
        "temperature": 0,
        "text": " is this, is async away part of ES8 or ES7? Who cares? Yes, new promise.",
        "tokens": [
          51420,
          307,
          341,
          11,
          307,
          382,
          34015,
          1314,
          644,
          295,
          12564,
          23,
          420,
          12564,
          22,
          30,
          2102,
          12310,
          30,
          1079,
          11,
          777,
          6228,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.26955665241588245,
        "compression_ratio": 1.5,
        "end": 1415.44,
        "id": 216,
        "no_speech_prob": 0.000008267863449873403,
        "seek": 140864,
        "start": 1409.1200000000001,
        "temperature": 0,
        "text": " Catch console. I know I don't need the error function for catch, but I thought",
        "tokens": [
          50388,
          23869,
          11076,
          13,
          286,
          458,
          286,
          500,
          380,
          643,
          264,
          6713,
          2445,
          337,
          3745,
          11,
          457,
          286,
          1194,
          50704
        ]
      },
      {
        "avg_logprob": -0.26955665241588245,
        "compression_ratio": 1.5,
        "end": 1419.0400000000002,
        "id": 217,
        "no_speech_prob": 0.000008267863449873403,
        "seek": 140864,
        "start": 1415.44,
        "temperature": 0,
        "text": " Gannon writes catch console.error. I thought that's going to be a little bit confusing",
        "tokens": [
          50704,
          460,
          16138,
          13657,
          3745,
          11076,
          13,
          260,
          2874,
          13,
          286,
          1194,
          300,
          311,
          516,
          281,
          312,
          257,
          707,
          857,
          13181,
          50884
        ]
      },
      {
        "avg_logprob": -0.26955665241588245,
        "compression_ratio": 1.5,
        "end": 1425.44,
        "id": 218,
        "no_speech_prob": 0.000008267863449873403,
        "seek": 140864,
        "start": 1419.0400000000002,
        "temperature": 0,
        "text": " for beginners, but. Okay, let me come back.",
        "tokens": [
          50884,
          337,
          26992,
          11,
          457,
          13,
          1033,
          11,
          718,
          385,
          808,
          646,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.26955665241588245,
        "compression_ratio": 1.5,
        "end": 1435.6000000000001,
        "id": 219,
        "no_speech_prob": 0.000008267863449873403,
        "seek": 140864,
        "start": 1428.96,
        "temperature": 0,
        "text": " Oh, it's ES2017, which is ES8, yes. Oh, I'm going to get flooded in the comments for that.",
        "tokens": [
          51380,
          876,
          11,
          309,
          311,
          12564,
          38987,
          11,
          597,
          307,
          12564,
          23,
          11,
          2086,
          13,
          876,
          11,
          286,
          478,
          516,
          281,
          483,
          31594,
          294,
          264,
          3053,
          337,
          300,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.20536256658619848,
        "compression_ratio": 1.5625,
        "end": 1443.28,
        "id": 220,
        "no_speech_prob": 0.000003785324452110217,
        "seek": 143560,
        "start": 1435.6,
        "temperature": 0,
        "text": " Crap, crud. I mean, how do I, you know how I was using the Giphy API and I like set the PG rating?",
        "tokens": [
          50364,
          383,
          4007,
          11,
          941,
          532,
          13,
          286,
          914,
          11,
          577,
          360,
          286,
          11,
          291,
          458,
          577,
          286,
          390,
          1228,
          264,
          460,
          647,
          3495,
          9362,
          293,
          286,
          411,
          992,
          264,
          40975,
          10990,
          30,
          50748
        ]
      },
      {
        "avg_logprob": -0.20536256658619848,
        "compression_ratio": 1.5625,
        "end": 1448.9599999999998,
        "id": 221,
        "no_speech_prob": 0.000003785324452110217,
        "seek": 143560,
        "start": 1443.28,
        "temperature": 0,
        "text": " Can I set the PG rating for myself? All right. Yes, the wrong camera, I know, I know. I'm 20",
        "tokens": [
          50748,
          1664,
          286,
          992,
          264,
          40975,
          10990,
          337,
          2059,
          30,
          1057,
          558,
          13,
          1079,
          11,
          264,
          2085,
          2799,
          11,
          286,
          458,
          11,
          286,
          458,
          13,
          286,
          478,
          945,
          51032
        ]
      },
      {
        "avg_logprob": -0.20536256658619848,
        "compression_ratio": 1.5625,
        "end": 1454.08,
        "id": 222,
        "no_speech_prob": 0.000003785324452110217,
        "seek": 143560,
        "start": 1448.9599999999998,
        "temperature": 0,
        "text": " seconds ahead of you in the future. All right. All right, so I forgot, I need to return a new",
        "tokens": [
          51032,
          3949,
          2286,
          295,
          291,
          294,
          264,
          2027,
          13,
          1057,
          558,
          13,
          1057,
          558,
          11,
          370,
          286,
          5298,
          11,
          286,
          643,
          281,
          2736,
          257,
          777,
          51288
        ]
      },
      {
        "avg_logprob": -0.20536256658619848,
        "compression_ratio": 1.5625,
        "end": 1459.52,
        "id": 223,
        "no_speech_prob": 0.000003785324452110217,
        "seek": 143560,
        "start": 1454.08,
        "temperature": 0,
        "text": " promise. So this is sort of, I'm kind of getting closer. Let's just see what happens now.",
        "tokens": [
          51288,
          6228,
          13,
          407,
          341,
          307,
          1333,
          295,
          11,
          286,
          478,
          733,
          295,
          1242,
          4966,
          13,
          961,
          311,
          445,
          536,
          437,
          2314,
          586,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.19805402958646734,
        "compression_ratio": 1.9068627450980393,
        "end": 1468.48,
        "id": 224,
        "no_speech_prob": 0.00023413561575580388,
        "seek": 145952,
        "start": 1460.48,
        "temperature": 0,
        "text": " Well, promise resolver is undefined. So if I want to make my own promise, how to make your own",
        "tokens": [
          50412,
          1042,
          11,
          6228,
          34480,
          307,
          674,
          5666,
          2001,
          13,
          407,
          498,
          286,
          528,
          281,
          652,
          452,
          1065,
          6228,
          11,
          577,
          281,
          652,
          428,
          1065,
          50812
        ]
      },
      {
        "avg_logprob": -0.19805402958646734,
        "compression_ratio": 1.9068627450980393,
        "end": 1475.2,
        "id": 225,
        "no_speech_prob": 0.00023413561575580388,
        "seek": 145952,
        "start": 1468.48,
        "temperature": 0,
        "text": " promise, in addition to just promising something, I have to provide pathways for resolution of that",
        "tokens": [
          50812,
          6228,
          11,
          294,
          4500,
          281,
          445,
          20257,
          746,
          11,
          286,
          362,
          281,
          2893,
          22988,
          337,
          8669,
          295,
          300,
          51148
        ]
      },
      {
        "avg_logprob": -0.19805402958646734,
        "compression_ratio": 1.9068627450980393,
        "end": 1481.52,
        "id": 226,
        "no_speech_prob": 0.00023413561575580388,
        "seek": 145952,
        "start": 1475.2,
        "temperature": 0,
        "text": " promise or rejection of that promise. So when I create the new promise, I have to say what happens",
        "tokens": [
          51148,
          6228,
          420,
          26044,
          295,
          300,
          6228,
          13,
          407,
          562,
          286,
          1884,
          264,
          777,
          6228,
          11,
          286,
          362,
          281,
          584,
          437,
          2314,
          51464
        ]
      },
      {
        "avg_logprob": -0.19805402958646734,
        "compression_ratio": 1.9068627450980393,
        "end": 1486.24,
        "id": 227,
        "no_speech_prob": 0.00023413561575580388,
        "seek": 145952,
        "start": 1481.52,
        "temperature": 0,
        "text": " when it's resolved and what happens when it's rejected. So first of all, something that I could",
        "tokens": [
          51464,
          562,
          309,
          311,
          20772,
          293,
          437,
          2314,
          562,
          309,
          311,
          15749,
          13,
          407,
          700,
          295,
          439,
          11,
          746,
          300,
          286,
          727,
          51700
        ]
      },
      {
        "avg_logprob": -0.27664613723754883,
        "compression_ratio": 1.352112676056338,
        "end": 1495.76,
        "id": 228,
        "no_speech_prob": 0.0005976686370559037,
        "seek": 148624,
        "start": 1486.32,
        "temperature": 0,
        "text": " actually do here just for fun. Actually, no. I'm thinking here. How did I do this? Well, let me,",
        "tokens": [
          50368,
          767,
          360,
          510,
          445,
          337,
          1019,
          13,
          5135,
          11,
          572,
          13,
          286,
          478,
          1953,
          510,
          13,
          1012,
          630,
          286,
          360,
          341,
          30,
          1042,
          11,
          718,
          385,
          11,
          50840
        ]
      },
      {
        "avg_logprob": -0.27664613723754883,
        "compression_ratio": 1.352112676056338,
        "end": 1504.96,
        "id": 229,
        "no_speech_prob": 0.0005976686370559037,
        "seek": 148624,
        "start": 1495.76,
        "temperature": 0,
        "text": " okay. So what goes in here? We need a function called deal with it, deal with promise, resolve,",
        "tokens": [
          50840,
          1392,
          13,
          407,
          437,
          1709,
          294,
          510,
          30,
          492,
          643,
          257,
          2445,
          1219,
          2028,
          365,
          309,
          11,
          2028,
          365,
          6228,
          11,
          14151,
          11,
          51300
        ]
      },
      {
        "avg_logprob": -0.18716553279331752,
        "compression_ratio": 1.716867469879518,
        "end": 1517.3600000000001,
        "id": 230,
        "no_speech_prob": 0.012241079472005367,
        "seek": 150496,
        "start": 1505.04,
        "temperature": 0,
        "text": " reject. Right? Oh, this is so weird. I'm totally blanking for a second. I did this this morning.",
        "tokens": [
          50368,
          8248,
          13,
          1779,
          30,
          876,
          11,
          341,
          307,
          370,
          3657,
          13,
          286,
          478,
          3879,
          8247,
          278,
          337,
          257,
          1150,
          13,
          286,
          630,
          341,
          341,
          2446,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.18716553279331752,
        "compression_ratio": 1.716867469879518,
        "end": 1524.64,
        "id": 231,
        "no_speech_prob": 0.012241079472005367,
        "seek": 150496,
        "start": 1517.3600000000001,
        "temperature": 0,
        "text": " I should go look at what I wrote. Just time out for a second. I just want to look at what I wrote",
        "tokens": [
          50984,
          286,
          820,
          352,
          574,
          412,
          437,
          286,
          4114,
          13,
          1449,
          565,
          484,
          337,
          257,
          1150,
          13,
          286,
          445,
          528,
          281,
          574,
          412,
          437,
          286,
          4114,
          51348
        ]
      },
      {
        "avg_logprob": -0.18716553279331752,
        "compression_ratio": 1.716867469879518,
        "end": 1530.64,
        "id": 232,
        "no_speech_prob": 0.012241079472005367,
        "seek": 150496,
        "start": 1524.64,
        "temperature": 0,
        "text": " this morning. I have it on this. New promise. Oh, yeah, yeah, yeah. This is totally right.",
        "tokens": [
          51348,
          341,
          2446,
          13,
          286,
          362,
          309,
          322,
          341,
          13,
          1873,
          6228,
          13,
          876,
          11,
          1338,
          11,
          1338,
          11,
          1338,
          13,
          639,
          307,
          3879,
          558,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2091525151179387,
        "compression_ratio": 1.706896551724138,
        "end": 1537.68,
        "id": 233,
        "no_speech_prob": 0.00018522562459111214,
        "seek": 153064,
        "start": 1530.8000000000002,
        "temperature": 0,
        "text": " Ah, I'm, okay. I don't know why. Okay. I'm doing it the right way. I just got confused for a second.",
        "tokens": [
          50372,
          2438,
          11,
          286,
          478,
          11,
          1392,
          13,
          286,
          500,
          380,
          458,
          983,
          13,
          1033,
          13,
          286,
          478,
          884,
          309,
          264,
          558,
          636,
          13,
          286,
          445,
          658,
          9019,
          337,
          257,
          1150,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.2091525151179387,
        "compression_ratio": 1.706896551724138,
        "end": 1552.48,
        "id": 234,
        "no_speech_prob": 0.00018522562459111214,
        "seek": 153064,
        "start": 1540.3200000000002,
        "temperature": 0,
        "text": " Okay. Then I want to pass that deal with promise function into the new promise. So the deal with",
        "tokens": [
          50848,
          1033,
          13,
          1396,
          286,
          528,
          281,
          1320,
          300,
          2028,
          365,
          6228,
          2445,
          666,
          264,
          777,
          6228,
          13,
          407,
          264,
          2028,
          365,
          51456
        ]
      },
      {
        "avg_logprob": -0.2091525151179387,
        "compression_ratio": 1.706896551724138,
        "end": 1558.8000000000002,
        "id": 235,
        "no_speech_prob": 0.00018522562459111214,
        "seek": 153064,
        "start": 1552.48,
        "temperature": 0,
        "text": " promise function is a function that I'm defining to handle resolution and rejection of the promise.",
        "tokens": [
          51456,
          6228,
          2445,
          307,
          257,
          2445,
          300,
          286,
          478,
          17827,
          281,
          4813,
          8669,
          293,
          26044,
          295,
          264,
          6228,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.18886902753044577,
        "compression_ratio": 1.6796536796536796,
        "end": 1565.84,
        "id": 236,
        "no_speech_prob": 0.0002341355284443125,
        "seek": 155880,
        "start": 1559.36,
        "temperature": 0,
        "text": " And that function is put, is returned with this new promise. But again, even though I like to",
        "tokens": [
          50392,
          400,
          300,
          2445,
          307,
          829,
          11,
          307,
          8752,
          365,
          341,
          777,
          6228,
          13,
          583,
          797,
          11,
          754,
          1673,
          286,
          411,
          281,
          50716
        ]
      },
      {
        "avg_logprob": -0.18886902753044577,
        "compression_ratio": 1.6796536796536796,
        "end": 1570.48,
        "id": 237,
        "no_speech_prob": 0.0002341355284443125,
        "seek": 155880,
        "start": 1565.84,
        "temperature": 0,
        "text": " write, no one's really going to write it this way. You're mostly going to see it as an anonymous",
        "tokens": [
          50716,
          2464,
          11,
          572,
          472,
          311,
          534,
          516,
          281,
          2464,
          309,
          341,
          636,
          13,
          509,
          434,
          5240,
          516,
          281,
          536,
          309,
          382,
          364,
          24932,
          50948
        ]
      },
      {
        "avg_logprob": -0.18886902753044577,
        "compression_ratio": 1.6796536796536796,
        "end": 1576.8,
        "id": 238,
        "no_speech_prob": 0.0002341355284443125,
        "seek": 155880,
        "start": 1570.48,
        "temperature": 0,
        "text": " function written right in here. And then, you know, if we're sticking with this ES6 arrow notation,",
        "tokens": [
          50948,
          2445,
          3720,
          558,
          294,
          510,
          13,
          400,
          550,
          11,
          291,
          458,
          11,
          498,
          321,
          434,
          13465,
          365,
          341,
          12564,
          21,
          11610,
          24657,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.18886902753044577,
        "compression_ratio": 1.6796536796536796,
        "end": 1583.52,
        "id": 239,
        "no_speech_prob": 0.0002341355284443125,
        "seek": 155880,
        "start": 1576.8,
        "temperature": 0,
        "text": " we would see it look like this. So now, this is most likely what you're going to see. I want this",
        "tokens": [
          51264,
          321,
          576,
          536,
          309,
          574,
          411,
          341,
          13,
          407,
          586,
          11,
          341,
          307,
          881,
          3700,
          437,
          291,
          434,
          516,
          281,
          536,
          13,
          286,
          528,
          341,
          51600
        ]
      },
      {
        "avg_logprob": -0.2578109373529273,
        "compression_ratio": 1.529100529100529,
        "end": 1589.2,
        "id": 240,
        "no_speech_prob": 0.014503350481390953,
        "seek": 158352,
        "start": 1583.92,
        "temperature": 0,
        "text": " function to return a new promise. And I need to provide pathways for how I resolve and reject",
        "tokens": [
          50384,
          2445,
          281,
          2736,
          257,
          777,
          6228,
          13,
          400,
          286,
          643,
          281,
          2893,
          22988,
          337,
          577,
          286,
          14151,
          293,
          8248,
          50648
        ]
      },
      {
        "avg_logprob": -0.2578109373529273,
        "compression_ratio": 1.529100529100529,
        "end": 1597.52,
        "id": 241,
        "no_speech_prob": 0.014503350481390953,
        "seek": 158352,
        "start": 1589.2,
        "temperature": 0,
        "text": " those promises. So here's what I could do. I'm going to put this. Set time out. Say hello. Time.",
        "tokens": [
          50648,
          729,
          16403,
          13,
          407,
          510,
          311,
          437,
          286,
          727,
          360,
          13,
          286,
          478,
          516,
          281,
          829,
          341,
          13,
          8928,
          565,
          484,
          13,
          6463,
          7751,
          13,
          6161,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2578109373529273,
        "compression_ratio": 1.529100529100529,
        "end": 1612.8,
        "id": 242,
        "no_speech_prob": 0.014503350481390953,
        "seek": 158352,
        "start": 1598.48,
        "temperature": 0,
        "text": " Then I'm actually going to, so, sorry. I need to, hold on. How did I do this? I usually don't look",
        "tokens": [
          51112,
          1396,
          286,
          478,
          767,
          516,
          281,
          11,
          370,
          11,
          2597,
          13,
          286,
          643,
          281,
          11,
          1797,
          322,
          13,
          1012,
          630,
          286,
          360,
          341,
          30,
          286,
          2673,
          500,
          380,
          574,
          51828
        ]
      },
      {
        "avg_logprob": -0.24434344999251828,
        "compression_ratio": 1.3706293706293706,
        "end": 1618.48,
        "id": 243,
        "no_speech_prob": 0.2813723087310791,
        "seek": 161280,
        "start": 1612.8,
        "temperature": 0,
        "text": " up my code because I'm usually figuring out. But I just want to look it up. Oh, yeah. Set time out",
        "tokens": [
          50364,
          493,
          452,
          3089,
          570,
          286,
          478,
          2673,
          15213,
          484,
          13,
          583,
          286,
          445,
          528,
          281,
          574,
          309,
          493,
          13,
          876,
          11,
          1338,
          13,
          8928,
          565,
          484,
          50648
        ]
      },
      {
        "avg_logprob": -0.24434344999251828,
        "compression_ratio": 1.3706293706293706,
        "end": 1625.36,
        "id": 244,
        "no_speech_prob": 0.2813723087310791,
        "seek": 161280,
        "start": 1618.48,
        "temperature": 0,
        "text": " a function. I just call resolve. Oh, yeah. Yeah, yeah, yeah. Okay. All right. I'm sorry. I got so",
        "tokens": [
          50648,
          257,
          2445,
          13,
          286,
          445,
          818,
          14151,
          13,
          876,
          11,
          1338,
          13,
          865,
          11,
          1338,
          11,
          1338,
          13,
          1033,
          13,
          1057,
          558,
          13,
          286,
          478,
          2597,
          13,
          286,
          658,
          370,
          50992
        ]
      },
      {
        "avg_logprob": -0.329089329160493,
        "compression_ratio": 1.1162790697674418,
        "end": 1647.36,
        "id": 245,
        "no_speech_prob": 0.2689245939254761,
        "seek": 162536,
        "start": 1625.36,
        "temperature": 0,
        "text": " confused. Let me just go back. This is going to go to the least. Just call resolve. I don't need",
        "tokens": [
          50364,
          9019,
          13,
          961,
          385,
          445,
          352,
          646,
          13,
          639,
          307,
          516,
          281,
          352,
          281,
          264,
          1935,
          13,
          1449,
          818,
          14151,
          13,
          286,
          500,
          380,
          643,
          51464
        ]
      },
      {
        "avg_logprob": -0.20891053086027092,
        "compression_ratio": 1.7981220657276995,
        "end": 1654.9599999999998,
        "id": 246,
        "no_speech_prob": 0.03621959686279297,
        "seek": 164736,
        "start": 1647.36,
        "temperature": 0,
        "text": " to return anything. Oh, right. Right. Right. Okay. All right. So what do I want to do?",
        "tokens": [
          50364,
          281,
          2736,
          1340,
          13,
          876,
          11,
          558,
          13,
          1779,
          13,
          1779,
          13,
          1033,
          13,
          1057,
          558,
          13,
          407,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          50744
        ]
      },
      {
        "avg_logprob": -0.20891053086027092,
        "compression_ratio": 1.7981220657276995,
        "end": 1664.8799999999999,
        "id": 247,
        "no_speech_prob": 0.03621959686279297,
        "seek": 164736,
        "start": 1656.24,
        "temperature": 0,
        "text": " What I want to do, sorry, is I want to call set time out. I want to call set time out with that",
        "tokens": [
          50808,
          708,
          286,
          528,
          281,
          360,
          11,
          2597,
          11,
          307,
          286,
          528,
          281,
          818,
          992,
          565,
          484,
          13,
          286,
          528,
          281,
          818,
          992,
          565,
          484,
          365,
          300,
          51240
        ]
      },
      {
        "avg_logprob": -0.20891053086027092,
        "compression_ratio": 1.7981220657276995,
        "end": 1669.52,
        "id": 248,
        "no_speech_prob": 0.03621959686279297,
        "seek": 164736,
        "start": 1664.8799999999999,
        "temperature": 0,
        "text": " amount of time. So I'm going to use the callback. But what is the callback? The callback is actually",
        "tokens": [
          51240,
          2372,
          295,
          565,
          13,
          407,
          286,
          478,
          516,
          281,
          764,
          264,
          818,
          3207,
          13,
          583,
          437,
          307,
          264,
          818,
          3207,
          30,
          440,
          818,
          3207,
          307,
          767,
          51472
        ]
      },
      {
        "avg_logprob": -0.20891053086027092,
        "compression_ratio": 1.7981220657276995,
        "end": 1677.1999999999998,
        "id": 249,
        "no_speech_prob": 0.03621959686279297,
        "seek": 164736,
        "start": 1669.52,
        "temperature": 0,
        "text": " just resolve. So, and I don't need this say hello function anymore because I'm going to handle what",
        "tokens": [
          51472,
          445,
          14151,
          13,
          407,
          11,
          293,
          286,
          500,
          380,
          643,
          341,
          584,
          7751,
          2445,
          3602,
          570,
          286,
          478,
          516,
          281,
          4813,
          437,
          51856
        ]
      },
      {
        "avg_logprob": -0.204610183022239,
        "compression_ratio": 1.6724137931034482,
        "end": 1682.56,
        "id": 250,
        "no_speech_prob": 0.0002131866931449622,
        "seek": 167720,
        "start": 1677.2,
        "temperature": 0,
        "text": " I want to do. I don't have a callback anymore. I'm going to handle what I want to do with the then.",
        "tokens": [
          50364,
          286,
          528,
          281,
          360,
          13,
          286,
          500,
          380,
          362,
          257,
          818,
          3207,
          3602,
          13,
          286,
          478,
          516,
          281,
          4813,
          437,
          286,
          528,
          281,
          360,
          365,
          264,
          550,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.204610183022239,
        "compression_ratio": 1.6724137931034482,
        "end": 1690.48,
        "id": 251,
        "no_speech_prob": 0.0002131866931449622,
        "seek": 167720,
        "start": 1683.28,
        "temperature": 0,
        "text": " So here, what I want to do is say, after this amount of time, resolve the promise. Okay. So",
        "tokens": [
          50668,
          407,
          510,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          584,
          11,
          934,
          341,
          2372,
          295,
          565,
          11,
          14151,
          264,
          6228,
          13,
          1033,
          13,
          407,
          51028
        ]
      },
      {
        "avg_logprob": -0.204610183022239,
        "compression_ratio": 1.6724137931034482,
        "end": 1697.2,
        "id": 252,
        "no_speech_prob": 0.0002131866931449622,
        "seek": 167720,
        "start": 1690.48,
        "temperature": 0,
        "text": " let's just see if this works. Yeah. It worked. Now, here's the thing. I might want to do more stuff",
        "tokens": [
          51028,
          718,
          311,
          445,
          536,
          498,
          341,
          1985,
          13,
          865,
          13,
          467,
          2732,
          13,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          286,
          1062,
          528,
          281,
          360,
          544,
          1507,
          51364
        ]
      },
      {
        "avg_logprob": -0.204610183022239,
        "compression_ratio": 1.6724137931034482,
        "end": 1703.1200000000001,
        "id": 253,
        "no_speech_prob": 0.0002131866931449622,
        "seek": 167720,
        "start": 1697.92,
        "temperature": 0,
        "text": " in here. And so this could actually be, I could actually also write this like this as a function",
        "tokens": [
          51400,
          294,
          510,
          13,
          400,
          370,
          341,
          727,
          767,
          312,
          11,
          286,
          727,
          767,
          611,
          2464,
          341,
          411,
          341,
          382,
          257,
          2445,
          51660
        ]
      },
      {
        "avg_logprob": -0.18455174390007467,
        "compression_ratio": 1.556,
        "end": 1708.08,
        "id": 254,
        "no_speech_prob": 0.00016093045996967703,
        "seek": 170312,
        "start": 1703.12,
        "temperature": 0,
        "text": " that executes resolve. And then other things could happen in here. But I think that's besides",
        "tokens": [
          50364,
          300,
          4454,
          1819,
          14151,
          13,
          400,
          550,
          661,
          721,
          727,
          1051,
          294,
          510,
          13,
          583,
          286,
          519,
          300,
          311,
          11868,
          50612
        ]
      },
      {
        "avg_logprob": -0.18455174390007467,
        "compression_ratio": 1.556,
        "end": 1715.1999999999998,
        "id": 255,
        "no_speech_prob": 0.00016093045996967703,
        "seek": 170312,
        "start": 1708.08,
        "temperature": 0,
        "text": " the point. I just want to call resolve because all I'm doing is waiting for a certain amount of time.",
        "tokens": [
          50612,
          264,
          935,
          13,
          286,
          445,
          528,
          281,
          818,
          14151,
          570,
          439,
          286,
          478,
          884,
          307,
          3806,
          337,
          257,
          1629,
          2372,
          295,
          565,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.18455174390007467,
        "compression_ratio": 1.556,
        "end": 1724.56,
        "id": 256,
        "no_speech_prob": 0.00016093045996967703,
        "seek": 170312,
        "start": 1715.1999999999998,
        "temperature": 0,
        "text": " But here's the thing. What if I were to say, also, in addition to delay 1000, delay, you know,",
        "tokens": [
          50968,
          583,
          510,
          311,
          264,
          551,
          13,
          708,
          498,
          286,
          645,
          281,
          584,
          11,
          611,
          11,
          294,
          4500,
          281,
          8577,
          9714,
          11,
          8577,
          11,
          291,
          458,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.18455174390007467,
        "compression_ratio": 1.556,
        "end": 1732.7199999999998,
        "id": 257,
        "no_speech_prob": 0.00016093045996967703,
        "seek": 170312,
        "start": 1726.3999999999999,
        "temperature": 0,
        "text": " promising, like this doesn't make any sense, right? You can't pass a string to the delay function.",
        "tokens": [
          51528,
          20257,
          11,
          411,
          341,
          1177,
          380,
          652,
          604,
          2020,
          11,
          558,
          30,
          509,
          393,
          380,
          1320,
          257,
          6798,
          281,
          264,
          8577,
          2445,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.17224282080974054,
        "compression_ratio": 1.6103896103896105,
        "end": 1738.16,
        "id": 258,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 173272,
        "start": 1732.72,
        "temperature": 0,
        "text": " It doesn't know how much time it's supposed to wait. So if I run this now, it sort of just worked",
        "tokens": [
          50364,
          467,
          1177,
          380,
          458,
          577,
          709,
          565,
          309,
          311,
          3442,
          281,
          1699,
          13,
          407,
          498,
          286,
          1190,
          341,
          586,
          11,
          309,
          1333,
          295,
          445,
          2732,
          50636
        ]
      },
      {
        "avg_logprob": -0.17224282080974054,
        "compression_ratio": 1.6103896103896105,
        "end": 1744.88,
        "id": 259,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 173272,
        "start": 1738.16,
        "temperature": 0,
        "text": " weirdly. But I want to make that an error. I want to reject the promise if I don't get a number.",
        "tokens": [
          50636,
          48931,
          13,
          583,
          286,
          528,
          281,
          652,
          300,
          364,
          6713,
          13,
          286,
          528,
          281,
          8248,
          264,
          6228,
          498,
          286,
          500,
          380,
          483,
          257,
          1230,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.17224282080974054,
        "compression_ratio": 1.6103896103896105,
        "end": 1749.84,
        "id": 260,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 173272,
        "start": 1744.88,
        "temperature": 0,
        "text": " So one thing I can do here is I can say if, and there's a function actually in JavaScript,",
        "tokens": [
          50972,
          407,
          472,
          551,
          286,
          393,
          360,
          510,
          307,
          286,
          393,
          584,
          498,
          11,
          293,
          456,
          311,
          257,
          2445,
          767,
          294,
          15778,
          11,
          51220
        ]
      },
      {
        "avg_logprob": -0.17224282080974054,
        "compression_ratio": 1.6103896103896105,
        "end": 1758.32,
        "id": 261,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 173272,
        "start": 1749.84,
        "temperature": 0,
        "text": " I believe it's isNAN. So isNAN stands for is not a number. So if time is not a number,",
        "tokens": [
          51220,
          286,
          1697,
          309,
          311,
          307,
          45,
          1770,
          13,
          407,
          307,
          45,
          1770,
          7382,
          337,
          307,
          406,
          257,
          1230,
          13,
          407,
          498,
          565,
          307,
          406,
          257,
          1230,
          11,
          51644
        ]
      },
      {
        "avg_logprob": -0.18790945755807978,
        "compression_ratio": 1.646788990825688,
        "end": 1765.4399999999998,
        "id": 262,
        "no_speech_prob": 0.0000033931444249901688,
        "seek": 175832,
        "start": 1758.32,
        "temperature": 0,
        "text": " I now want to reject that promise. Otherwise, I want to resolve the promise after a certain",
        "tokens": [
          50364,
          286,
          586,
          528,
          281,
          8248,
          300,
          6228,
          13,
          10328,
          11,
          286,
          528,
          281,
          14151,
          264,
          6228,
          934,
          257,
          1629,
          50720
        ]
      },
      {
        "avg_logprob": -0.18790945755807978,
        "compression_ratio": 1.646788990825688,
        "end": 1771.52,
        "id": 263,
        "no_speech_prob": 0.0000033931444249901688,
        "seek": 175832,
        "start": 1765.4399999999998,
        "temperature": 0,
        "text": " amount of time. So this is me taking the non-promise function setTimeout, which has a",
        "tokens": [
          50720,
          2372,
          295,
          565,
          13,
          407,
          341,
          307,
          385,
          1940,
          264,
          2107,
          12,
          28722,
          908,
          2445,
          992,
          22233,
          346,
          11,
          597,
          575,
          257,
          51024
        ]
      },
      {
        "avg_logprob": -0.18790945755807978,
        "compression_ratio": 1.646788990825688,
        "end": 1778,
        "id": 264,
        "no_speech_prob": 0.0000033931444249901688,
        "seek": 175832,
        "start": 1771.52,
        "temperature": 0,
        "text": " callback, and wrapping it in a new function that handles it with a promise. But better than just,",
        "tokens": [
          51024,
          818,
          3207,
          11,
          293,
          21993,
          309,
          294,
          257,
          777,
          2445,
          300,
          18722,
          309,
          365,
          257,
          6228,
          13,
          583,
          1101,
          813,
          445,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.18790945755807978,
        "compression_ratio": 1.646788990825688,
        "end": 1783.6,
        "id": 265,
        "no_speech_prob": 0.0000033931444249901688,
        "seek": 175832,
        "start": 1778,
        "temperature": 0,
        "text": " so this should work now. In other words, we should see, we see this like undefined,",
        "tokens": [
          51348,
          370,
          341,
          820,
          589,
          586,
          13,
          682,
          661,
          2283,
          11,
          321,
          820,
          536,
          11,
          321,
          536,
          341,
          411,
          674,
          5666,
          2001,
          11,
          51628
        ]
      },
      {
        "avg_logprob": -0.2618947330909439,
        "compression_ratio": 1.5297297297297296,
        "end": 1789.9199999999998,
        "id": 266,
        "no_speech_prob": 0.000025071585696423426,
        "seek": 178360,
        "start": 1783.6,
        "temperature": 0,
        "text": " sketch.js line nine, because, but I should really give it an error. So I should be able to say,",
        "tokens": [
          50364,
          12325,
          13,
          25530,
          1622,
          4949,
          11,
          570,
          11,
          457,
          286,
          820,
          534,
          976,
          309,
          364,
          6713,
          13,
          407,
          286,
          820,
          312,
          1075,
          281,
          584,
          11,
          50680
        ]
      },
      {
        "avg_logprob": -0.2618947330909439,
        "compression_ratio": 1.5297297297297296,
        "end": 1800.6399999999999,
        "id": 267,
        "no_speech_prob": 0.000025071585696423426,
        "seek": 178360,
        "start": 1790.6399999999999,
        "temperature": 0,
        "text": " I believe, reject new and pass an error, new error, you delay requires a valid number or something.",
        "tokens": [
          50716,
          286,
          1697,
          11,
          8248,
          777,
          293,
          1320,
          364,
          6713,
          11,
          777,
          6713,
          11,
          291,
          8577,
          7029,
          257,
          7363,
          1230,
          420,
          746,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.2618947330909439,
        "compression_ratio": 1.5297297297297296,
        "end": 1808.24,
        "id": 268,
        "no_speech_prob": 0.000025071585696423426,
        "seek": 178360,
        "start": 1801.1999999999998,
        "temperature": 0,
        "text": " So if I do this, and now let me just take this out here, right? So this now is the full",
        "tokens": [
          51244,
          407,
          498,
          286,
          360,
          341,
          11,
          293,
          586,
          718,
          385,
          445,
          747,
          341,
          484,
          510,
          11,
          558,
          30,
          407,
          341,
          586,
          307,
          264,
          1577,
          51596
        ]
      },
      {
        "avg_logprob": -0.2862643802288881,
        "compression_ratio": 1.6442307692307692,
        "end": 1816.88,
        "id": 269,
        "no_speech_prob": 0.00048785502440296113,
        "seek": 180824,
        "start": 1808.88,
        "temperature": 0,
        "text": " promise-if-if-if, promise-if-if-if, that's not a word, delay function. It returns the new promise,",
        "tokens": [
          50396,
          6228,
          12,
          351,
          12,
          351,
          12,
          351,
          11,
          6228,
          12,
          351,
          12,
          351,
          12,
          351,
          11,
          300,
          311,
          406,
          257,
          1349,
          11,
          8577,
          2445,
          13,
          467,
          11247,
          264,
          777,
          6228,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.2862643802288881,
        "compression_ratio": 1.6442307692307692,
        "end": 1824.48,
        "id": 270,
        "no_speech_prob": 0.00048785502440296113,
        "seek": 180824,
        "start": 1816.88,
        "temperature": 0,
        "text": " which is a function that handles resolution and rejection. And if it's passed not a number,",
        "tokens": [
          50796,
          597,
          307,
          257,
          2445,
          300,
          18722,
          8669,
          293,
          26044,
          13,
          400,
          498,
          309,
          311,
          4678,
          406,
          257,
          1230,
          11,
          51176
        ]
      },
      {
        "avg_logprob": -0.2862643802288881,
        "compression_ratio": 1.6442307692307692,
        "end": 1828.64,
        "id": 271,
        "no_speech_prob": 0.00048785502440296113,
        "seek": 180824,
        "start": 1824.48,
        "temperature": 0,
        "text": " it calls reject. Otherwise, it just calls resolve after a certain amount of time.",
        "tokens": [
          51176,
          309,
          5498,
          8248,
          13,
          10328,
          11,
          309,
          445,
          5498,
          14151,
          934,
          257,
          1629,
          2372,
          295,
          565,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2862643802288881,
        "compression_ratio": 1.6442307692307692,
        "end": 1833.28,
        "id": 272,
        "no_speech_prob": 0.00048785502440296113,
        "seek": 180824,
        "start": 1828.64,
        "temperature": 0,
        "text": " So let's run this. This is my, this is me calling it now, delay 1000.",
        "tokens": [
          51384,
          407,
          718,
          311,
          1190,
          341,
          13,
          639,
          307,
          452,
          11,
          341,
          307,
          385,
          5141,
          309,
          586,
          11,
          8577,
          9714,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.27811871742715644,
        "compression_ratio": 1.5774058577405858,
        "end": 1842.56,
        "id": 273,
        "no_speech_prob": 0.0005442117690108716,
        "seek": 183328,
        "start": 1833.52,
        "temperature": 0,
        "text": " There we go. Hello. And now if I say delay, blah, blah, we should see error. And you can see my",
        "tokens": [
          50376,
          821,
          321,
          352,
          13,
          2425,
          13,
          400,
          586,
          498,
          286,
          584,
          8577,
          11,
          12288,
          11,
          12288,
          11,
          321,
          820,
          536,
          6713,
          13,
          400,
          291,
          393,
          536,
          452,
          50828
        ]
      },
      {
        "avg_logprob": -0.27811871742715644,
        "compression_ratio": 1.5774058577405858,
        "end": 1848.3999999999999,
        "id": 274,
        "no_speech_prob": 0.0005442117690108716,
        "seek": 183328,
        "start": 1842.56,
        "temperature": 0,
        "text": " error here. Delay requires a valid number. So again, this is more likely something you would",
        "tokens": [
          50828,
          6713,
          510,
          13,
          5831,
          320,
          7029,
          257,
          7363,
          1230,
          13,
          407,
          797,
          11,
          341,
          307,
          544,
          3700,
          746,
          291,
          576,
          51120
        ]
      },
      {
        "avg_logprob": -0.27811871742715644,
        "compression_ratio": 1.5774058577405858,
        "end": 1853.2,
        "id": 275,
        "no_speech_prob": 0.0005442117690108716,
        "seek": 183328,
        "start": 1848.3999999999999,
        "temperature": 0,
        "text": " be doing as the author of a JavaScript library, and your library has asynchronous code that",
        "tokens": [
          51120,
          312,
          884,
          382,
          264,
          3793,
          295,
          257,
          15778,
          6405,
          11,
          293,
          428,
          6405,
          575,
          49174,
          3089,
          300,
          51360
        ]
      },
      {
        "avg_logprob": -0.27811871742715644,
        "compression_ratio": 1.5774058577405858,
        "end": 1859.52,
        "id": 276,
        "no_speech_prob": 0.0005442117690108716,
        "seek": 183328,
        "start": 1853.2,
        "temperature": 0,
        "text": " supports promises. Again, though, and I think I'm gonna do this in the next video, I am going to",
        "tokens": [
          51360,
          9346,
          16403,
          13,
          3764,
          11,
          1673,
          11,
          293,
          286,
          519,
          286,
          478,
          799,
          360,
          341,
          294,
          264,
          958,
          960,
          11,
          286,
          669,
          516,
          281,
          51676
        ]
      },
      {
        "avg_logprob": -0.3094868521088535,
        "compression_ratio": 1.5974025974025974,
        "end": 1865.12,
        "id": 277,
        "no_speech_prob": 0.051837462931871414,
        "seek": 185952,
        "start": 1860.24,
        "temperature": 0,
        "text": " actually completely rewrite that using, and I got it wrong, apologies to everyone. So just to be",
        "tokens": [
          50400,
          767,
          2584,
          28132,
          300,
          1228,
          11,
          293,
          286,
          658,
          309,
          2085,
          11,
          34929,
          281,
          1518,
          13,
          407,
          445,
          281,
          312,
          50644
        ]
      },
      {
        "avg_logprob": -0.3094868521088535,
        "compression_ratio": 1.5974025974025974,
        "end": 1876.6399999999999,
        "id": 278,
        "no_speech_prob": 0.051837462931871414,
        "seek": 185952,
        "start": 1865.12,
        "temperature": 0,
        "text": " clear, this is ES, this is so confusing. So let me think about this. ES5, I don't know this stuff.",
        "tokens": [
          50644,
          1850,
          11,
          341,
          307,
          12564,
          11,
          341,
          307,
          370,
          13181,
          13,
          407,
          718,
          385,
          519,
          466,
          341,
          13,
          12564,
          20,
          11,
          286,
          500,
          380,
          458,
          341,
          1507,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.3094868521088535,
        "compression_ratio": 1.5974025974025974,
        "end": 1880.6399999999999,
        "id": 279,
        "no_speech_prob": 0.051837462931871414,
        "seek": 185952,
        "start": 1876.6399999999999,
        "temperature": 0,
        "text": " I'm gonna write this out, then I'm gonna go check the chat, and I'll come back and correct it.",
        "tokens": [
          51220,
          286,
          478,
          799,
          2464,
          341,
          484,
          11,
          550,
          286,
          478,
          799,
          352,
          1520,
          264,
          5081,
          11,
          293,
          286,
          603,
          808,
          646,
          293,
          3006,
          309,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.3094868521088535,
        "compression_ratio": 1.5974025974025974,
        "end": 1888.48,
        "id": 280,
        "no_speech_prob": 0.051837462931871414,
        "seek": 185952,
        "start": 1880.6399999999999,
        "temperature": 0,
        "text": " So let me go backwards. This async and await is from ES8, which is JavaScript,",
        "tokens": [
          51420,
          407,
          718,
          385,
          352,
          12204,
          13,
          639,
          382,
          34015,
          293,
          19670,
          307,
          490,
          12564,
          23,
          11,
          597,
          307,
          15778,
          11,
          51812
        ]
      },
      {
        "avg_logprob": -0.2723439687705902,
        "compression_ratio": 1.4866310160427807,
        "end": 1901.04,
        "id": 281,
        "no_speech_prob": 0.000019833249098155648,
        "seek": 188848,
        "start": 1888.56,
        "temperature": 0,
        "text": " which is JavaScript, ES, ECMCA or something, EMCA specification 2017. This is ES8. ES6,",
        "tokens": [
          50368,
          597,
          307,
          15778,
          11,
          12564,
          11,
          19081,
          44,
          15515,
          420,
          746,
          11,
          16237,
          15515,
          31256,
          6591,
          13,
          639,
          307,
          12564,
          23,
          13,
          12564,
          21,
          11,
          50992
        ]
      },
      {
        "avg_logprob": -0.2723439687705902,
        "compression_ratio": 1.4866310160427807,
        "end": 1911.6,
        "id": 282,
        "no_speech_prob": 0.000019833249098155648,
        "seek": 188848,
        "start": 1901.68,
        "temperature": 0,
        "text": " which promises are a native of JavaScript as ES6 is ES2015, I think. And then ES5, I don't know",
        "tokens": [
          51024,
          597,
          16403,
          366,
          257,
          8470,
          295,
          15778,
          382,
          12564,
          21,
          307,
          12564,
          46081,
          11,
          286,
          519,
          13,
          400,
          550,
          12564,
          20,
          11,
          286,
          500,
          380,
          458,
          51520
        ]
      },
      {
        "avg_logprob": -0.2723439687705902,
        "compression_ratio": 1.4866310160427807,
        "end": 1918.08,
        "id": 283,
        "no_speech_prob": 0.000019833249098155648,
        "seek": 188848,
        "start": 1911.6,
        "temperature": 0,
        "text": " when, that's the kind of old JavaScript that with var. So things that are in ES6 are like var,",
        "tokens": [
          51520,
          562,
          11,
          300,
          311,
          264,
          733,
          295,
          1331,
          15778,
          300,
          365,
          1374,
          13,
          407,
          721,
          300,
          366,
          294,
          12564,
          21,
          366,
          411,
          1374,
          11,
          51844
        ]
      },
      {
        "avg_logprob": -0.3055027919029122,
        "compression_ratio": 1.2962962962962963,
        "end": 1922.8,
        "id": 284,
        "no_speech_prob": 0.0007436993764713407,
        "seek": 191808,
        "start": 1918.24,
        "temperature": 0,
        "text": " no, sorry, let. I'm totally off the board here. I don't think you can see what I'm writing.",
        "tokens": [
          50372,
          572,
          11,
          2597,
          11,
          718,
          13,
          286,
          478,
          3879,
          766,
          264,
          3150,
          510,
          13,
          286,
          500,
          380,
          519,
          291,
          393,
          536,
          437,
          286,
          478,
          3579,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.3055027919029122,
        "compression_ratio": 1.2962962962962963,
        "end": 1925.6799999999998,
        "id": 285,
        "no_speech_prob": 0.0007436993764713407,
        "seek": 191808,
        "start": 1924.56,
        "temperature": 0,
        "text": " Hold on. Let me just...",
        "tokens": [
          50688,
          6962,
          322,
          13,
          961,
          385,
          445,
          485,
          50744
        ]
      },
      {
        "avg_logprob": -0.3055027919029122,
        "compression_ratio": 1.2962962962962963,
        "end": 1942.48,
        "id": 286,
        "no_speech_prob": 0.0007436993764713407,
        "seek": 191808,
        "start": 1932.6399999999999,
        "temperature": 0,
        "text": " Are like let, const, arrow, ES5 is var, callbacks, promises. So JavaScript, this is the thing.",
        "tokens": [
          51092,
          2014,
          411,
          718,
          11,
          1817,
          11,
          11610,
          11,
          12564,
          20,
          307,
          1374,
          11,
          818,
          17758,
          11,
          16403,
          13,
          407,
          15778,
          11,
          341,
          307,
          264,
          551,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.24691535631815592,
        "compression_ratio": 1.6493055555555556,
        "end": 1948.24,
        "id": 287,
        "no_speech_prob": 0.011331360787153244,
        "seek": 194248,
        "start": 1942.48,
        "temperature": 0,
        "text": " JavaScript is like an always changing and evolving language. And as you know, watching this video in",
        "tokens": [
          50364,
          15778,
          307,
          411,
          364,
          1009,
          4473,
          293,
          21085,
          2856,
          13,
          400,
          382,
          291,
          458,
          11,
          1976,
          341,
          960,
          294,
          50652
        ]
      },
      {
        "avg_logprob": -0.24691535631815592,
        "compression_ratio": 1.6493055555555556,
        "end": 1955.76,
        "id": 288,
        "no_speech_prob": 0.011331360787153244,
        "seek": 194248,
        "start": 1948.24,
        "temperature": 0,
        "text": " the year 3122, my microphone just, none of this is relevant anymore. But thanks for watching anyway,",
        "tokens": [
          50652,
          264,
          1064,
          805,
          4762,
          17,
          11,
          452,
          10952,
          445,
          11,
          6022,
          295,
          341,
          307,
          7340,
          3602,
          13,
          583,
          3231,
          337,
          1976,
          4033,
          11,
          51028
        ]
      },
      {
        "avg_logprob": -0.24691535631815592,
        "compression_ratio": 1.6493055555555556,
        "end": 1959.28,
        "id": 289,
        "no_speech_prob": 0.011331360787153244,
        "seek": 194248,
        "start": 1955.76,
        "temperature": 0,
        "text": " about because you were here for a self-help video about how to keep your promises.",
        "tokens": [
          51028,
          466,
          570,
          291,
          645,
          510,
          337,
          257,
          2698,
          12,
          37451,
          960,
          466,
          577,
          281,
          1066,
          428,
          16403,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.24691535631815592,
        "compression_ratio": 1.6493055555555556,
        "end": 1963.84,
        "id": 290,
        "no_speech_prob": 0.011331360787153244,
        "seek": 194248,
        "start": 1959.28,
        "temperature": 0,
        "text": " All right, what was I talking, saying? I'm gonna come back. I'm in the next video. I probably got",
        "tokens": [
          51204,
          1057,
          558,
          11,
          437,
          390,
          286,
          1417,
          11,
          1566,
          30,
          286,
          478,
          799,
          808,
          646,
          13,
          286,
          478,
          294,
          264,
          958,
          960,
          13,
          286,
          1391,
          658,
          51432
        ]
      },
      {
        "avg_logprob": -0.24691535631815592,
        "compression_ratio": 1.6493055555555556,
        "end": 1968.72,
        "id": 291,
        "no_speech_prob": 0.011331360787153244,
        "seek": 194248,
        "start": 1963.84,
        "temperature": 0,
        "text": " this wrong. So in the next video, check this video's description for a link to the next one.",
        "tokens": [
          51432,
          341,
          2085,
          13,
          407,
          294,
          264,
          958,
          960,
          11,
          1520,
          341,
          960,
          311,
          3855,
          337,
          257,
          2113,
          281,
          264,
          958,
          472,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.24571912553575304,
        "compression_ratio": 1.2900763358778626,
        "end": 1972.88,
        "id": 292,
        "no_speech_prob": 0.00045120916911400855,
        "seek": 196872,
        "start": 1968.72,
        "temperature": 0,
        "text": " I will come and correct anything here and talk about async and await. Thanks for watching.",
        "tokens": [
          50364,
          286,
          486,
          808,
          293,
          3006,
          1340,
          510,
          293,
          751,
          466,
          382,
          34015,
          293,
          19670,
          13,
          2561,
          337,
          1976,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.24571912553575304,
        "compression_ratio": 1.2900763358778626,
        "end": 1988.72,
        "id": 293,
        "no_speech_prob": 0.00045120916911400855,
        "seek": 196872,
        "start": 1982.8,
        "temperature": 0,
        "text": " Be sure to, oh, I'm supposed to return reject? Did I get something wrong here?",
        "tokens": [
          51068,
          879,
          988,
          281,
          11,
          1954,
          11,
          286,
          478,
          3442,
          281,
          2736,
          8248,
          30,
          2589,
          286,
          483,
          746,
          2085,
          510,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.5810461979286343,
        "compression_ratio": 1.2301587301587302,
        "end": 1996.72,
        "id": 294,
        "no_speech_prob": 0.0034295953810214996,
        "seek": 198872,
        "start": 1989.68,
        "temperature": 0,
        "text": " I'm looking at the chat. ES latest. Yes. Did I get anything wrong about this?",
        "tokens": [
          50412,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          12564,
          6792,
          13,
          1079,
          13,
          2589,
          286,
          483,
          1340,
          2085,
          466,
          341,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.5810461979286343,
        "compression_ratio": 1.2301587301587302,
        "end": 2008.72,
        "id": 295,
        "no_speech_prob": 0.0034295953810214996,
        "seek": 198872,
        "start": 2000.72,
        "temperature": 0,
        "text": " ECMA script. ECMA script. Yeah. Script.",
        "tokens": [
          50964,
          19081,
          9998,
          5755,
          13,
          19081,
          9998,
          5755,
          13,
          865,
          13,
          15675,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.5810461979286343,
        "compression_ratio": 1.2301587301587302,
        "end": 2013.68,
        "id": 296,
        "no_speech_prob": 0.0034295953810214996,
        "seek": 198872,
        "start": 2012.24,
        "temperature": 0,
        "text": " No, just call the reject. Okay, good.",
        "tokens": [
          51540,
          883,
          11,
          445,
          818,
          264,
          8248,
          13,
          1033,
          11,
          665,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.5706128392900739,
        "compression_ratio": 1.4180327868852458,
        "end": 2019.68,
        "id": 297,
        "no_speech_prob": 0.0007915830356068909,
        "seek": 201368,
        "start": 2014.64,
        "temperature": 0,
        "text": " Great. All right. So now we are done with this.",
        "tokens": [
          50412,
          3769,
          13,
          1057,
          558,
          13,
          407,
          586,
          321,
          366,
          1096,
          365,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.5706128392900739,
        "compression_ratio": 1.4180327868852458,
        "end": 2027.68,
        "id": 298,
        "no_speech_prob": 0.0007915830356068909,
        "seek": 201368,
        "start": 2022.64,
        "temperature": 0,
        "text": " So now I'm gonna talk about async and await. Everybody ready for that?",
        "tokens": [
          50812,
          407,
          586,
          286,
          478,
          799,
          751,
          466,
          382,
          34015,
          293,
          19670,
          13,
          7646,
          1919,
          337,
          300,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.5706128392900739,
        "compression_ratio": 1.4180327868852458,
        "end": 2039.68,
        "id": 299,
        "no_speech_prob": 0.0007915830356068909,
        "seek": 201368,
        "start": 2033.68,
        "temperature": 0,
        "text": " Great. Okay. So, async and await. So, async and await.",
        "tokens": [
          51364,
          3769,
          13,
          1033,
          13,
          407,
          11,
          382,
          34015,
          293,
          19670,
          13,
          407,
          11,
          382,
          34015,
          293,
          19670,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.36217550329259923,
        "compression_ratio": 1.148936170212766,
        "end": 2043.68,
        "id": 300,
        "no_speech_prob": 0.001064956421032548,
        "seek": 203968,
        "start": 2039.68,
        "temperature": 0,
        "text": " Okay. Great. Okay.",
        "tokens": [
          50364,
          1033,
          13,
          3769,
          13,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.36217550329259923,
        "compression_ratio": 1.148936170212766,
        "end": 2063.6800000000003,
        "id": 301,
        "no_speech_prob": 0.001064956421032548,
        "seek": 203968,
        "start": 2054.56,
        "temperature": 0,
        "text": " All right. You are still setting the timeout in the error case is all. Oh, oh, oh. That's",
        "tokens": [
          51108,
          1057,
          558,
          13,
          509,
          366,
          920,
          3287,
          264,
          565,
          346,
          294,
          264,
          6713,
          1389,
          307,
          439,
          13,
          876,
          11,
          1954,
          11,
          1954,
          13,
          663,
          311,
          51564
        ]
      },
      {
        "avg_logprob": -0.27204122171773537,
        "compression_ratio": 1.4673913043478262,
        "end": 2074.48,
        "id": 302,
        "no_speech_prob": 0.003538078162819147,
        "seek": 206368,
        "start": 2064.48,
        "temperature": 0,
        "text": " an error. Yeah. So, interesting. No, reject. Oh, that's interesting. But it never, it stops,",
        "tokens": [
          50404,
          364,
          6713,
          13,
          865,
          13,
          407,
          11,
          1880,
          13,
          883,
          11,
          8248,
          13,
          876,
          11,
          300,
          311,
          1880,
          13,
          583,
          309,
          1128,
          11,
          309,
          10094,
          11,
          50904
        ]
      },
      {
        "avg_logprob": -0.27204122171773537,
        "compression_ratio": 1.4673913043478262,
        "end": 2081.68,
        "id": 303,
        "no_speech_prob": 0.003538078162819147,
        "seek": 206368,
        "start": 2075.8399999999997,
        "temperature": 0,
        "text": " the JavaScript program quits. So, I see. So, I should technically have this here.",
        "tokens": [
          50972,
          264,
          15778,
          1461,
          421,
          1208,
          13,
          407,
          11,
          286,
          536,
          13,
          407,
          11,
          286,
          820,
          12120,
          362,
          341,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.27204122171773537,
        "compression_ratio": 1.4673913043478262,
        "end": 2092.72,
        "id": 304,
        "no_speech_prob": 0.003538078162819147,
        "seek": 206368,
        "start": 2082.64,
        "temperature": 0,
        "text": " This is more correct. Yes? I see. So, maybe I'll just mention that at the beginning of the next",
        "tokens": [
          51312,
          639,
          307,
          544,
          3006,
          13,
          1079,
          30,
          286,
          536,
          13,
          407,
          11,
          1310,
          286,
          603,
          445,
          2152,
          300,
          412,
          264,
          2863,
          295,
          264,
          958,
          51816
        ]
      },
      {
        "avg_logprob": -0.20604817072550455,
        "compression_ratio": 1.3565891472868217,
        "end": 2109.12,
        "id": 305,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 209368,
        "start": 2094.56,
        "temperature": 0,
        "text": " video. Okay. I'm waiting for the chat to catch up with me to tell me if there's anything else",
        "tokens": [
          50408,
          960,
          13,
          1033,
          13,
          286,
          478,
          3806,
          337,
          264,
          5081,
          281,
          3745,
          493,
          365,
          385,
          281,
          980,
          385,
          498,
          456,
          311,
          1340,
          1646,
          51136
        ]
      },
      {
        "avg_logprob": -0.20604817072550455,
        "compression_ratio": 1.3565891472868217,
        "end": 2116.48,
        "id": 306,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 209368,
        "start": 2109.12,
        "temperature": 0,
        "text": " important that I'm forgetting. It's not even noon yet. Look how well we're doing.",
        "tokens": [
          51136,
          1021,
          300,
          286,
          478,
          25428,
          13,
          467,
          311,
          406,
          754,
          24040,
          1939,
          13,
          2053,
          577,
          731,
          321,
          434,
          884,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2167697001978294,
        "compression_ratio": 1.7116279069767442,
        "end": 2132.72,
        "id": 307,
        "no_speech_prob": 0.0005614781402982771,
        "seek": 212368,
        "start": 2123.68,
        "temperature": 0,
        "text": " Oh, you can only reject resolve once. So, it ignores the resolve after the reject,",
        "tokens": [
          50364,
          876,
          11,
          291,
          393,
          787,
          8248,
          14151,
          1564,
          13,
          407,
          11,
          309,
          5335,
          2706,
          264,
          14151,
          934,
          264,
          8248,
          11,
          50816
        ]
      },
      {
        "avg_logprob": -0.2167697001978294,
        "compression_ratio": 1.7116279069767442,
        "end": 2138.8799999999997,
        "id": 308,
        "no_speech_prob": 0.0005614781402982771,
        "seek": 212368,
        "start": 2132.72,
        "temperature": 0,
        "text": " but you are setting a weird timeout. Right. So, this code still, it runs through this code,",
        "tokens": [
          50816,
          457,
          291,
          366,
          3287,
          257,
          3657,
          565,
          346,
          13,
          1779,
          13,
          407,
          11,
          341,
          3089,
          920,
          11,
          309,
          6676,
          807,
          341,
          3089,
          11,
          51124
        ]
      },
      {
        "avg_logprob": -0.2167697001978294,
        "compression_ratio": 1.7116279069767442,
        "end": 2143.8399999999997,
        "id": 309,
        "no_speech_prob": 0.0005614781402982771,
        "seek": 212368,
        "start": 2138.8799999999997,
        "temperature": 0,
        "text": " but it won't actually call resolve because it's already been rejected. I see. So, I probably,",
        "tokens": [
          51124,
          457,
          309,
          1582,
          380,
          767,
          818,
          14151,
          570,
          309,
          311,
          1217,
          668,
          15749,
          13,
          286,
          536,
          13,
          407,
          11,
          286,
          1391,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.2167697001978294,
        "compression_ratio": 1.7116279069767442,
        "end": 2148.8799999999997,
        "id": 310,
        "no_speech_prob": 0.0005614781402982771,
        "seek": 212368,
        "start": 2144.3999999999996,
        "temperature": 0,
        "text": " this would actually make more sense to just write it this way. I think this is the way that I would",
        "tokens": [
          51400,
          341,
          576,
          767,
          652,
          544,
          2020,
          281,
          445,
          2464,
          309,
          341,
          636,
          13,
          286,
          519,
          341,
          307,
          264,
          636,
          300,
          286,
          576,
          51624
        ]
      },
      {
        "avg_logprob": -0.25164551031394083,
        "compression_ratio": 1.2808219178082192,
        "end": 2163.2000000000003,
        "id": 311,
        "no_speech_prob": 0.1460801362991333,
        "seek": 214888,
        "start": 2148.88,
        "temperature": 0,
        "text": " choose to write it. Okay? Yeah. Dan, can you explain what is new in ES8? No. I mean, not",
        "tokens": [
          50364,
          2826,
          281,
          2464,
          309,
          13,
          1033,
          30,
          865,
          13,
          3394,
          11,
          393,
          291,
          2903,
          437,
          307,
          777,
          294,
          12564,
          23,
          30,
          883,
          13,
          286,
          914,
          11,
          406,
          51080
        ]
      },
      {
        "avg_logprob": -0.25164551031394083,
        "compression_ratio": 1.2808219178082192,
        "end": 2169.6800000000003,
        "id": 312,
        "no_speech_prob": 0.1460801362991333,
        "seek": 214888,
        "start": 2163.2000000000003,
        "temperature": 0,
        "text": " because I don't want to, but I'm kind of catching up. So, what I'm about to do is talk about async",
        "tokens": [
          51080,
          570,
          286,
          500,
          380,
          528,
          281,
          11,
          457,
          286,
          478,
          733,
          295,
          16124,
          493,
          13,
          407,
          11,
          437,
          286,
          478,
          466,
          281,
          360,
          307,
          751,
          466,
          382,
          34015,
          51404
        ]
      },
      {
        "avg_logprob": -0.2762032057109632,
        "compression_ratio": 1.4566929133858268,
        "end": 2177.9199999999996,
        "id": 313,
        "no_speech_prob": 0.3345593512058258,
        "seek": 216968,
        "start": 2169.68,
        "temperature": 0,
        "text": " and await. I keep saying await because it's async. Async, await, await, and async. Async,",
        "tokens": [
          50364,
          293,
          19670,
          13,
          286,
          1066,
          1566,
          19670,
          570,
          309,
          311,
          382,
          34015,
          13,
          1018,
          34015,
          11,
          19670,
          11,
          19670,
          11,
          293,
          382,
          34015,
          13,
          1018,
          34015,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.2762032057109632,
        "compression_ratio": 1.4566929133858268,
        "end": 2184,
        "id": 314,
        "no_speech_prob": 0.3345593512058258,
        "seek": 216968,
        "start": 2177.9199999999996,
        "temperature": 0,
        "text": " await. But I'm at least going to talk about that. So, let me at the beginning of the next video",
        "tokens": [
          50776,
          19670,
          13,
          583,
          286,
          478,
          412,
          1935,
          516,
          281,
          751,
          466,
          300,
          13,
          407,
          11,
          718,
          385,
          412,
          264,
          2863,
          295,
          264,
          958,
          960,
          51080
        ]
      },
      {
        "avg_logprob": -0.34525223211808637,
        "compression_ratio": 1.2782608695652173,
        "end": 2191.36,
        "id": 315,
        "no_speech_prob": 0.15812526643276215,
        "seek": 218400,
        "start": 2184,
        "temperature": 0,
        "text": " just fix this. All right. Hold on one second here.",
        "tokens": [
          50364,
          445,
          3191,
          341,
          13,
          1057,
          558,
          13,
          6962,
          322,
          472,
          1150,
          510,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.34525223211808637,
        "compression_ratio": 1.2782608695652173,
        "end": 2212.72,
        "id": 316,
        "no_speech_prob": 0.15812526643276215,
        "seek": 218400,
        "start": 2206,
        "temperature": 0,
        "text": " By the way, when you watch this, I wonder, and all of you watching at home, or wherever you are,",
        "tokens": [
          51464,
          3146,
          264,
          636,
          11,
          562,
          291,
          1159,
          341,
          11,
          286,
          2441,
          11,
          293,
          439,
          295,
          291,
          1976,
          412,
          1280,
          11,
          420,
          8660,
          291,
          366,
          11,
          51800
        ]
      },
      {
        "avg_logprob": -0.2141358543844784,
        "compression_ratio": 1.518716577540107,
        "end": 2222.72,
        "id": 317,
        "no_speech_prob": 0.0008040758548304439,
        "seek": 221272,
        "start": 2213.2799999999997,
        "temperature": 0,
        "text": " I wonder if, because I have on my channel, if I go to YouTube.com slash the coding train, and I",
        "tokens": [
          50392,
          286,
          2441,
          498,
          11,
          570,
          286,
          362,
          322,
          452,
          2269,
          11,
          498,
          286,
          352,
          281,
          3088,
          13,
          1112,
          17330,
          264,
          17720,
          3847,
          11,
          293,
          286,
          50864
        ]
      },
      {
        "avg_logprob": -0.2141358543844784,
        "compression_ratio": 1.518716577540107,
        "end": 2234.3999999999996,
        "id": 318,
        "no_speech_prob": 0.0008040758548304439,
        "seek": 221272,
        "start": 2226.08,
        "temperature": 0,
        "text": " go here, go here, go here. Topics, right? So, this kind of fits in. Let me look at this playlist.",
        "tokens": [
          51032,
          352,
          510,
          11,
          352,
          510,
          11,
          352,
          510,
          13,
          8840,
          1167,
          11,
          558,
          30,
          407,
          11,
          341,
          733,
          295,
          9001,
          294,
          13,
          961,
          385,
          574,
          412,
          341,
          16788,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2141358543844784,
        "compression_ratio": 1.518716577540107,
        "end": 2241.52,
        "id": 319,
        "no_speech_prob": 0.0008040758548304439,
        "seek": 221272,
        "start": 2237.12,
        "temperature": 0,
        "text": " So, this is what I've got in this playlist so far. Let versus var, const, arrow functions,",
        "tokens": [
          51584,
          407,
          11,
          341,
          307,
          437,
          286,
          600,
          658,
          294,
          341,
          16788,
          370,
          1400,
          13,
          961,
          5717,
          1374,
          11,
          1817,
          11,
          11610,
          6828,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.23756382862726846,
        "compression_ratio": 1.5973451327433628,
        "end": 2248.72,
        "id": 320,
        "no_speech_prob": 0.0008167338091880083,
        "seek": 224152,
        "start": 2241.52,
        "temperature": 0,
        "text": " for of, higher order functions. But those aren't ES6, are they? Are the higher order functions",
        "tokens": [
          50364,
          337,
          295,
          11,
          2946,
          1668,
          6828,
          13,
          583,
          729,
          3212,
          380,
          12564,
          21,
          11,
          366,
          436,
          30,
          2014,
          264,
          2946,
          1668,
          6828,
          50724
        ]
      },
      {
        "avg_logprob": -0.23756382862726846,
        "compression_ratio": 1.5973451327433628,
        "end": 2253.28,
        "id": 321,
        "no_speech_prob": 0.0008167338091880083,
        "seek": 224152,
        "start": 2248.72,
        "temperature": 0,
        "text": " ES6? They existed before, didn't they? Maybe I'm using arrow functions with them. Anyway.",
        "tokens": [
          50724,
          12564,
          21,
          30,
          814,
          13135,
          949,
          11,
          994,
          380,
          436,
          30,
          2704,
          286,
          478,
          1228,
          11610,
          6828,
          365,
          552,
          13,
          5684,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.23756382862726846,
        "compression_ratio": 1.5973451327433628,
        "end": 2258.08,
        "id": 322,
        "no_speech_prob": 0.0008167338091880083,
        "seek": 224152,
        "start": 2254.32,
        "temperature": 0,
        "text": " So, this would make sense. This stuff would make sense to go in this video series. But I",
        "tokens": [
          51004,
          407,
          11,
          341,
          576,
          652,
          2020,
          13,
          639,
          1507,
          576,
          652,
          2020,
          281,
          352,
          294,
          341,
          960,
          2638,
          13,
          583,
          286,
          51192
        ]
      },
      {
        "avg_logprob": -0.23756382862726846,
        "compression_ratio": 1.5973451327433628,
        "end": 2265.7599999999998,
        "id": 323,
        "no_speech_prob": 0.0008167338091880083,
        "seek": 224152,
        "start": 2258.08,
        "temperature": 0,
        "text": " wonder if I should have 17 topics of JavaScript ES8. Maybe. So, let's think about that.",
        "tokens": [
          51192,
          2441,
          498,
          286,
          820,
          362,
          3282,
          8378,
          295,
          15778,
          12564,
          23,
          13,
          2704,
          13,
          407,
          11,
          718,
          311,
          519,
          466,
          300,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.35763603990728204,
        "compression_ratio": 1.21875,
        "end": 2278.32,
        "id": 324,
        "no_speech_prob": 0.0011513601057231426,
        "seek": 227152,
        "start": 2271.92,
        "temperature": 0,
        "text": " Return reject. I could also do. Thank you. All right. Here we go.",
        "tokens": [
          50384,
          24350,
          8248,
          13,
          286,
          727,
          611,
          360,
          13,
          1044,
          291,
          13,
          1057,
          558,
          13,
          1692,
          321,
          352,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.35763603990728204,
        "compression_ratio": 1.21875,
        "end": 2291.28,
        "id": 325,
        "no_speech_prob": 0.0011513601057231426,
        "seek": 227152,
        "start": 2283.7599999999998,
        "temperature": 0,
        "text": " Oh! Someone in the chat is mentioning bluebird.js is a nice promise library in JavaScript.",
        "tokens": [
          50976,
          876,
          0,
          8734,
          294,
          264,
          5081,
          307,
          18315,
          3344,
          18080,
          13,
          25530,
          307,
          257,
          1481,
          6228,
          6405,
          294,
          15778,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.22709970306931881,
        "compression_ratio": 1.2983870967741935,
        "end": 2300.32,
        "id": 326,
        "no_speech_prob": 0.014503276906907558,
        "seek": 229128,
        "start": 2291.44,
        "temperature": 0,
        "text": " Oh! I'm muted. Am I muted? No, I'm not muted. I'm not muted. Sorry.",
        "tokens": [
          50372,
          876,
          0,
          286,
          478,
          32808,
          13,
          2012,
          286,
          32808,
          30,
          883,
          11,
          286,
          478,
          406,
          32808,
          13,
          286,
          478,
          406,
          32808,
          13,
          4919,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.22709970306931881,
        "compression_ratio": 1.2983870967741935,
        "end": 2316,
        "id": 327,
        "no_speech_prob": 0.014503276906907558,
        "seek": 229128,
        "start": 2307.2000000000003,
        "temperature": 0,
        "text": " All right. It's time. ES8. I have never talked about ES8 before. But this video, I'm going to",
        "tokens": [
          51160,
          1057,
          558,
          13,
          467,
          311,
          565,
          13,
          12564,
          23,
          13,
          286,
          362,
          1128,
          2825,
          466,
          12564,
          23,
          949,
          13,
          583,
          341,
          960,
          11,
          286,
          478,
          516,
          281,
          51600
        ]
      },
      {
        "avg_logprob": -0.20580700652240075,
        "compression_ratio": 1.471502590673575,
        "end": 2324.88,
        "id": 328,
        "no_speech_prob": 0.0013250206829980016,
        "seek": 231600,
        "start": 2316,
        "temperature": 0,
        "text": " look at something called async and await. And it's part of ES8, which is ES2017. But anyway,",
        "tokens": [
          50364,
          574,
          412,
          746,
          1219,
          382,
          34015,
          293,
          19670,
          13,
          400,
          309,
          311,
          644,
          295,
          12564,
          23,
          11,
          597,
          307,
          12564,
          38987,
          13,
          583,
          4033,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.20580700652240075,
        "compression_ratio": 1.471502590673575,
        "end": 2335.2,
        "id": 329,
        "no_speech_prob": 0.0013250206829980016,
        "seek": 231600,
        "start": 2324.88,
        "temperature": 0,
        "text": " this is really what's often referred to as syntax sugar. So, basically, we're not going to get any",
        "tokens": [
          50808,
          341,
          307,
          534,
          437,
          311,
          2049,
          10839,
          281,
          382,
          28431,
          5076,
          13,
          407,
          11,
          1936,
          11,
          321,
          434,
          406,
          516,
          281,
          483,
          604,
          51324
        ]
      },
      {
        "avg_logprob": -0.20580700652240075,
        "compression_ratio": 1.471502590673575,
        "end": 2341.04,
        "id": 330,
        "no_speech_prob": 0.0013250206829980016,
        "seek": 231600,
        "start": 2335.2,
        "temperature": 0,
        "text": " new functionality. But we're going to have a different way to write an asynchronous function",
        "tokens": [
          51324,
          777,
          14980,
          13,
          583,
          321,
          434,
          516,
          281,
          362,
          257,
          819,
          636,
          281,
          2464,
          364,
          49174,
          2445,
          51616
        ]
      },
      {
        "avg_logprob": -0.16080029477778168,
        "compression_ratio": 1.553191489361702,
        "end": 2347.12,
        "id": 331,
        "no_speech_prob": 0.00015118195733521134,
        "seek": 234104,
        "start": 2341.04,
        "temperature": 0,
        "text": " that returns a promise that just makes things easier to follow and nicer. I think. I mean,",
        "tokens": [
          50364,
          300,
          11247,
          257,
          6228,
          300,
          445,
          1669,
          721,
          3571,
          281,
          1524,
          293,
          22842,
          13,
          286,
          519,
          13,
          286,
          914,
          11,
          50668
        ]
      },
      {
        "avg_logprob": -0.16080029477778168,
        "compression_ratio": 1.553191489361702,
        "end": 2352.8,
        "id": 332,
        "no_speech_prob": 0.00015118195733521134,
        "seek": 234104,
        "start": 2347.84,
        "temperature": 0,
        "text": " you can choose to decide whether it's better or not. But I think I like it. It's new for me.",
        "tokens": [
          50704,
          291,
          393,
          2826,
          281,
          4536,
          1968,
          309,
          311,
          1101,
          420,
          406,
          13,
          583,
          286,
          519,
          286,
          411,
          309,
          13,
          467,
          311,
          777,
          337,
          385,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.16080029477778168,
        "compression_ratio": 1.553191489361702,
        "end": 2358.16,
        "id": 333,
        "no_speech_prob": 0.00015118195733521134,
        "seek": 234104,
        "start": 2353.6,
        "temperature": 0,
        "text": " I haven't really worked with this until yesterday. So, let's see how this goes. All right. So,",
        "tokens": [
          50992,
          286,
          2378,
          380,
          534,
          2732,
          365,
          341,
          1826,
          5186,
          13,
          407,
          11,
          718,
          311,
          536,
          577,
          341,
          1709,
          13,
          1057,
          558,
          13,
          407,
          11,
          51220
        ]
      },
      {
        "avg_logprob": -0.16080029477778168,
        "compression_ratio": 1.553191489361702,
        "end": 2363.84,
        "id": 334,
        "no_speech_prob": 0.00015118195733521134,
        "seek": 234104,
        "start": 2358.16,
        "temperature": 0,
        "text": " just to review, if you watched the previous video, I wrote this function called delay.",
        "tokens": [
          51220,
          445,
          281,
          3131,
          11,
          498,
          291,
          6337,
          264,
          3894,
          960,
          11,
          286,
          4114,
          341,
          2445,
          1219,
          8577,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2690694662240835,
        "compression_ratio": 1.7392857142857143,
        "end": 2373.76,
        "id": 335,
        "no_speech_prob": 0.00017400525393895805,
        "seek": 236384,
        "start": 2364.8,
        "temperature": 0,
        "text": " This function called delay returns a new promise. And there's one mistake here. So, this isn't that",
        "tokens": [
          50412,
          639,
          2445,
          1219,
          8577,
          11247,
          257,
          777,
          6228,
          13,
          400,
          456,
          311,
          472,
          6146,
          510,
          13,
          407,
          11,
          341,
          1943,
          380,
          300,
          50860
        ]
      },
      {
        "avg_logprob": -0.2690694662240835,
        "compression_ratio": 1.7392857142857143,
        "end": 2379.04,
        "id": 336,
        "no_speech_prob": 0.00017400525393895805,
        "seek": 236384,
        "start": 2373.76,
        "temperature": 0,
        "text": " big of a deal. Once the promise is rejected, I really should stop and not do anything else. But",
        "tokens": [
          50860,
          955,
          295,
          257,
          2028,
          13,
          3443,
          264,
          6228,
          307,
          15749,
          11,
          286,
          534,
          820,
          1590,
          293,
          406,
          360,
          1340,
          1646,
          13,
          583,
          51124
        ]
      },
      {
        "avg_logprob": -0.2690694662240835,
        "compression_ratio": 1.7392857142857143,
        "end": 2383.1200000000003,
        "id": 337,
        "no_speech_prob": 0.00017400525393895805,
        "seek": 236384,
        "start": 2379.04,
        "temperature": 0,
        "text": " this code keeps going and calls this setTimeout. It won't resolve the promise, but it's still doing",
        "tokens": [
          51124,
          341,
          3089,
          5965,
          516,
          293,
          5498,
          341,
          992,
          22233,
          346,
          13,
          467,
          1582,
          380,
          14151,
          264,
          6228,
          11,
          457,
          309,
          311,
          920,
          884,
          51328
        ]
      },
      {
        "avg_logprob": -0.2690694662240835,
        "compression_ratio": 1.7392857142857143,
        "end": 2386.4,
        "id": 338,
        "no_speech_prob": 0.00017400525393895805,
        "seek": 236384,
        "start": 2383.1200000000003,
        "temperature": 0,
        "text": " this weird setTimeout. So, I could... There's some options here. I could say, like, return.",
        "tokens": [
          51328,
          341,
          3657,
          992,
          22233,
          346,
          13,
          407,
          11,
          286,
          727,
          485,
          821,
          311,
          512,
          3956,
          510,
          13,
          286,
          727,
          584,
          11,
          411,
          11,
          2736,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2690694662240835,
        "compression_ratio": 1.7392857142857143,
        "end": 2391.1200000000003,
        "id": 339,
        "no_speech_prob": 0.00017400525393895805,
        "seek": 236384,
        "start": 2387.44,
        "temperature": 0,
        "text": " I could also... I think what I'm just going to do for my... The way I like to do things is just put",
        "tokens": [
          51544,
          286,
          727,
          611,
          485,
          286,
          519,
          437,
          286,
          478,
          445,
          516,
          281,
          360,
          337,
          452,
          485,
          440,
          636,
          286,
          411,
          281,
          360,
          721,
          307,
          445,
          829,
          51728
        ]
      },
      {
        "avg_logprob": -0.19037304672540403,
        "compression_ratio": 1.7285067873303168,
        "end": 2397.6,
        "id": 340,
        "no_speech_prob": 0.00044421671191230416,
        "seek": 239112,
        "start": 2391.2,
        "temperature": 0,
        "text": " an else here. So, I'm going to add that. So, this function receives a number, creates a promise...",
        "tokens": [
          50368,
          364,
          1646,
          510,
          13,
          407,
          11,
          286,
          478,
          516,
          281,
          909,
          300,
          13,
          407,
          11,
          341,
          2445,
          20717,
          257,
          1230,
          11,
          7829,
          257,
          6228,
          485,
          50688
        ]
      },
      {
        "avg_logprob": -0.19037304672540403,
        "compression_ratio": 1.7285067873303168,
        "end": 2404.64,
        "id": 341,
        "no_speech_prob": 0.00044421671191230416,
        "seek": 239112,
        "start": 2397.6,
        "temperature": 0,
        "text": " Oh, it receives an argument. It receives a parameter. If the parameter is not a number,",
        "tokens": [
          50688,
          876,
          11,
          309,
          20717,
          364,
          6770,
          13,
          467,
          20717,
          257,
          13075,
          13,
          759,
          264,
          13075,
          307,
          406,
          257,
          1230,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.19037304672540403,
        "compression_ratio": 1.7285067873303168,
        "end": 2410.96,
        "id": 342,
        "no_speech_prob": 0.00044421671191230416,
        "seek": 239112,
        "start": 2404.64,
        "temperature": 0,
        "text": " it rejects the promise and throws an error. If it is, it calls setTimeout and resolves the promise.",
        "tokens": [
          51040,
          309,
          8248,
          82,
          264,
          6228,
          293,
          19251,
          364,
          6713,
          13,
          759,
          309,
          307,
          11,
          309,
          5498,
          992,
          22233,
          346,
          293,
          7923,
          977,
          264,
          6228,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.19037304672540403,
        "compression_ratio": 1.7285067873303168,
        "end": 2416.72,
        "id": 343,
        "no_speech_prob": 0.00044421671191230416,
        "seek": 239112,
        "start": 2410.96,
        "temperature": 0,
        "text": " That way I can say, after a certain delay, like 1,000 milliseconds, create a paragraph or catch",
        "tokens": [
          51356,
          663,
          636,
          286,
          393,
          584,
          11,
          934,
          257,
          1629,
          8577,
          11,
          411,
          502,
          11,
          1360,
          34184,
          11,
          1884,
          257,
          18865,
          420,
          3745,
          51644
        ]
      },
      {
        "avg_logprob": -0.17899168650309244,
        "compression_ratio": 1.9424460431654675,
        "end": 2426.48,
        "id": 344,
        "no_speech_prob": 0.0030278151389211416,
        "seek": 241672,
        "start": 2416.72,
        "temperature": 0,
        "text": " the error. So, now what I'm going to do is I'm going to write delay ES8. So, here's the thing.",
        "tokens": [
          50364,
          264,
          6713,
          13,
          407,
          11,
          586,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          2464,
          8577,
          12564,
          23,
          13,
          407,
          11,
          510,
          311,
          264,
          551,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.17899168650309244,
        "compression_ratio": 1.9424460431654675,
        "end": 2434.64,
        "id": 345,
        "no_speech_prob": 0.0030278151389211416,
        "seek": 241672,
        "start": 2426.48,
        "temperature": 0,
        "text": " If a function returns a promise... If a function returns a promise, and what returns a promise?",
        "tokens": [
          50852,
          759,
          257,
          2445,
          11247,
          257,
          6228,
          485,
          759,
          257,
          2445,
          11247,
          257,
          6228,
          11,
          293,
          437,
          11247,
          257,
          6228,
          30,
          51260
        ]
      },
      {
        "avg_logprob": -0.17899168650309244,
        "compression_ratio": 1.9424460431654675,
        "end": 2442,
        "id": 346,
        "no_speech_prob": 0.0030278151389211416,
        "seek": 241672,
        "start": 2436.08,
        "temperature": 0,
        "text": " The delay function returns a promise. So, I'm going to do something weird here.",
        "tokens": [
          51332,
          440,
          8577,
          2445,
          11247,
          257,
          6228,
          13,
          407,
          11,
          286,
          478,
          516,
          281,
          360,
          746,
          3657,
          510,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.26375588126804517,
        "compression_ratio": 1.789090909090909,
        "end": 2449.84,
        "id": 347,
        "no_speech_prob": 0.00007967293640831485,
        "seek": 244200,
        "start": 2442.32,
        "temperature": 0,
        "text": " So, what I want to do is call delay ES8. So, I'm writing a new function. I'm going to call that.",
        "tokens": [
          50380,
          407,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          818,
          8577,
          12564,
          23,
          13,
          407,
          11,
          286,
          478,
          3579,
          257,
          777,
          2445,
          13,
          286,
          478,
          516,
          281,
          818,
          300,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.26375588126804517,
        "compression_ratio": 1.789090909090909,
        "end": 2454.72,
        "id": 348,
        "no_speech_prob": 0.00007967293640831485,
        "seek": 244200,
        "start": 2449.84,
        "temperature": 0,
        "text": " This is going to stay exactly the same. This is going to stay exactly the same. Now, this is really",
        "tokens": [
          50756,
          639,
          307,
          516,
          281,
          1754,
          2293,
          264,
          912,
          13,
          639,
          307,
          516,
          281,
          1754,
          2293,
          264,
          912,
          13,
          823,
          11,
          341,
          307,
          534,
          51000
        ]
      },
      {
        "avg_logprob": -0.26375588126804517,
        "compression_ratio": 1.789090909090909,
        "end": 2460.08,
        "id": 349,
        "no_speech_prob": 0.00007967293640831485,
        "seek": 244200,
        "start": 2454.72,
        "temperature": 0,
        "text": " weird. And you know what? In the next video, I'm going to do this with the Wordnik and Giphy example.",
        "tokens": [
          51000,
          3657,
          13,
          400,
          291,
          458,
          437,
          30,
          682,
          264,
          958,
          960,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          365,
          264,
          8725,
          13123,
          293,
          460,
          647,
          3495,
          1365,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.26375588126804517,
        "compression_ratio": 1.789090909090909,
        "end": 2463.04,
        "id": 350,
        "no_speech_prob": 0.00007967293640831485,
        "seek": 244200,
        "start": 2460.08,
        "temperature": 0,
        "text": " That's going to make way more sense. I probably should just do that now. But I'm already going",
        "tokens": [
          51268,
          663,
          311,
          516,
          281,
          652,
          636,
          544,
          2020,
          13,
          286,
          1391,
          820,
          445,
          360,
          300,
          586,
          13,
          583,
          286,
          478,
          1217,
          516,
          51416
        ]
      },
      {
        "avg_logprob": -0.26375588126804517,
        "compression_ratio": 1.789090909090909,
        "end": 2467.52,
        "id": 351,
        "no_speech_prob": 0.00007967293640831485,
        "seek": 244200,
        "start": 2463.04,
        "temperature": 0,
        "text": " down this road. You can skip to the next video if you want. This is a little bit weird. You almost",
        "tokens": [
          51416,
          760,
          341,
          3060,
          13,
          509,
          393,
          10023,
          281,
          264,
          958,
          960,
          498,
          291,
          528,
          13,
          639,
          307,
          257,
          707,
          857,
          3657,
          13,
          509,
          1920,
          51640
        ]
      },
      {
        "avg_logprob": -0.2989223335362688,
        "compression_ratio": 1.5364583333333333,
        "end": 2474.08,
        "id": 352,
        "no_speech_prob": 0.0007554033654741943,
        "seek": 246752,
        "start": 2467.6,
        "temperature": 0,
        "text": " want to forget. Pretend that delay isn't a function that I wrote, but delay is a function that's part",
        "tokens": [
          50368,
          528,
          281,
          2870,
          13,
          9739,
          521,
          300,
          8577,
          1943,
          380,
          257,
          2445,
          300,
          286,
          4114,
          11,
          457,
          8577,
          307,
          257,
          2445,
          300,
          311,
          644,
          50692
        ]
      },
      {
        "avg_logprob": -0.2989223335362688,
        "compression_ratio": 1.5364583333333333,
        "end": 2483.04,
        "id": 353,
        "no_speech_prob": 0.0007554033654741943,
        "seek": 246752,
        "start": 2474.08,
        "temperature": 0,
        "text": " of some JavaScript library that I've imported. And delay returns a promise. So, I'm trying to think",
        "tokens": [
          50692,
          295,
          512,
          15778,
          6405,
          300,
          286,
          600,
          25524,
          13,
          400,
          8577,
          11247,
          257,
          6228,
          13,
          407,
          11,
          286,
          478,
          1382,
          281,
          519,
          51140
        ]
      },
      {
        "avg_logprob": -0.2989223335362688,
        "compression_ratio": 1.5364583333333333,
        "end": 2490.08,
        "id": 354,
        "no_speech_prob": 0.0007554033654741943,
        "seek": 246752,
        "start": 2483.04,
        "temperature": 0,
        "text": " of a better name for this than delay ES8. But I guess I'll keep that right now. So, what this",
        "tokens": [
          51140,
          295,
          257,
          1101,
          1315,
          337,
          341,
          813,
          8577,
          12564,
          23,
          13,
          583,
          286,
          2041,
          286,
          603,
          1066,
          300,
          558,
          586,
          13,
          407,
          11,
          437,
          341,
          51492
        ]
      },
      {
        "avg_logprob": -0.32837889744685245,
        "compression_ratio": 1.5824175824175823,
        "end": 2497.2799999999997,
        "id": 355,
        "no_speech_prob": 0.000021112482500029728,
        "seek": 249008,
        "start": 2490.4,
        "temperature": 0,
        "text": " allows me to do, if a function, this function, I'm taking a long time to get to this, returns a",
        "tokens": [
          50380,
          4045,
          385,
          281,
          360,
          11,
          498,
          257,
          2445,
          11,
          341,
          2445,
          11,
          286,
          478,
          1940,
          257,
          938,
          565,
          281,
          483,
          281,
          341,
          11,
          11247,
          257,
          50724
        ]
      },
      {
        "avg_logprob": -0.32837889744685245,
        "compression_ratio": 1.5824175824175823,
        "end": 2508.64,
        "id": 356,
        "no_speech_prob": 0.000021112482500029728,
        "seek": 249008,
        "start": 2497.2799999999997,
        "temperature": 0,
        "text": " promise. If that's the case, I can suddenly use this keyword await, meaning just wait for the",
        "tokens": [
          50724,
          6228,
          13,
          759,
          300,
          311,
          264,
          1389,
          11,
          286,
          393,
          5800,
          764,
          341,
          20428,
          19670,
          11,
          3620,
          445,
          1699,
          337,
          264,
          51292
        ]
      },
      {
        "avg_logprob": -0.32837889744685245,
        "compression_ratio": 1.5824175824175823,
        "end": 2515.52,
        "id": 357,
        "no_speech_prob": 0.000021112482500029728,
        "seek": 249008,
        "start": 2508.64,
        "temperature": 0,
        "text": " promise to resolve. It's almost like, it's kind of like writing blocking code. So, I can say await",
        "tokens": [
          51292,
          6228,
          281,
          14151,
          13,
          467,
          311,
          1920,
          411,
          11,
          309,
          311,
          733,
          295,
          411,
          3579,
          17776,
          3089,
          13,
          407,
          11,
          286,
          393,
          584,
          19670,
          51636
        ]
      },
      {
        "avg_logprob": -0.4161004396242516,
        "compression_ratio": 1.7695852534562213,
        "end": 2525.44,
        "id": 358,
        "no_speech_prob": 0.00009461262379772961,
        "seek": 251552,
        "start": 2515.6,
        "temperature": 0,
        "text": " delay time. Then I can return. Now, this is why I really want to do this with the fetch function",
        "tokens": [
          50368,
          8577,
          565,
          13,
          1396,
          286,
          393,
          2736,
          13,
          823,
          11,
          341,
          307,
          983,
          286,
          534,
          528,
          281,
          360,
          341,
          365,
          264,
          23673,
          2445,
          50860
        ]
      },
      {
        "avg_logprob": -0.4161004396242516,
        "compression_ratio": 1.7695852534562213,
        "end": 2531.84,
        "id": 359,
        "no_speech_prob": 0.00009461262379772961,
        "seek": 251552,
        "start": 2525.44,
        "temperature": 0,
        "text": " because there's so much more. This is like a very tiny little bit. But this now should, it's going",
        "tokens": [
          50860,
          570,
          456,
          311,
          370,
          709,
          544,
          13,
          639,
          307,
          411,
          257,
          588,
          5870,
          707,
          857,
          13,
          583,
          341,
          586,
          820,
          11,
          309,
          311,
          516,
          51180
        ]
      },
      {
        "avg_logprob": -0.4161004396242516,
        "compression_ratio": 1.7695852534562213,
        "end": 2535.84,
        "id": 360,
        "no_speech_prob": 0.00009461262379772961,
        "seek": 251552,
        "start": 2531.84,
        "temperature": 0,
        "text": " to make much more sense when I actually have to do more steps. I don't have to do anything. I'm",
        "tokens": [
          51180,
          281,
          652,
          709,
          544,
          2020,
          562,
          286,
          767,
          362,
          281,
          360,
          544,
          4439,
          13,
          286,
          500,
          380,
          362,
          281,
          360,
          1340,
          13,
          286,
          478,
          51380
        ]
      },
      {
        "avg_logprob": -0.4161004396242516,
        "compression_ratio": 1.7695852534562213,
        "end": 2539.84,
        "id": 361,
        "no_speech_prob": 0.00009461262379772961,
        "seek": 251552,
        "start": 2535.84,
        "temperature": 0,
        "text": " just awaiting that. I don't have to do anything else. So, I'm going to do this. I'm going to",
        "tokens": [
          51380,
          445,
          43759,
          300,
          13,
          286,
          500,
          380,
          362,
          281,
          360,
          1340,
          1646,
          13,
          407,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          286,
          478,
          516,
          281,
          51580
        ]
      },
      {
        "avg_logprob": -0.1750035706688376,
        "compression_ratio": 1.7672727272727273,
        "end": 2543.52,
        "id": 362,
        "no_speech_prob": 0.00023413535382132977,
        "seek": 253984,
        "start": 2539.92,
        "temperature": 0,
        "text": " It's going to make much more sense when I actually have to do more steps. I don't have to do",
        "tokens": [
          50368,
          467,
          311,
          516,
          281,
          652,
          709,
          544,
          2020,
          562,
          286,
          767,
          362,
          281,
          360,
          544,
          4439,
          13,
          286,
          500,
          380,
          362,
          281,
          360,
          50548
        ]
      },
      {
        "avg_logprob": -0.1750035706688376,
        "compression_ratio": 1.7672727272727273,
        "end": 2548.8,
        "id": 363,
        "no_speech_prob": 0.00023413535382132977,
        "seek": 253984,
        "start": 2543.52,
        "temperature": 0,
        "text": " anything. I'm just awaiting that. I don't have to do anything after. But this now will automatically",
        "tokens": [
          50548,
          1340,
          13,
          286,
          478,
          445,
          43759,
          300,
          13,
          286,
          500,
          380,
          362,
          281,
          360,
          1340,
          934,
          13,
          583,
          341,
          586,
          486,
          6772,
          50812
        ]
      },
      {
        "avg_logprob": -0.1750035706688376,
        "compression_ratio": 1.7672727272727273,
        "end": 2552.48,
        "id": 364,
        "no_speech_prob": 0.00023413535382132977,
        "seek": 253984,
        "start": 2548.8,
        "temperature": 0,
        "text": " return a promise. Now, I'm missing an important piece. Let's just run this and see what happens.",
        "tokens": [
          50812,
          2736,
          257,
          6228,
          13,
          823,
          11,
          286,
          478,
          5361,
          364,
          1021,
          2522,
          13,
          961,
          311,
          445,
          1190,
          341,
          293,
          536,
          437,
          2314,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.1750035706688376,
        "compression_ratio": 1.7672727272727273,
        "end": 2556.4,
        "id": 365,
        "no_speech_prob": 0.00023413535382132977,
        "seek": 253984,
        "start": 2552.48,
        "temperature": 0,
        "text": " I don't know if I like this video so far. I might have to rethink this. But I'm going. I'm going",
        "tokens": [
          50996,
          286,
          500,
          380,
          458,
          498,
          286,
          411,
          341,
          960,
          370,
          1400,
          13,
          286,
          1062,
          362,
          281,
          34595,
          341,
          13,
          583,
          286,
          478,
          516,
          13,
          286,
          478,
          516,
          51192
        ]
      },
      {
        "avg_logprob": -0.1750035706688376,
        "compression_ratio": 1.7672727272727273,
        "end": 2566.2400000000002,
        "id": 366,
        "no_speech_prob": 0.00023413535382132977,
        "seek": 253984,
        "start": 2556.4,
        "temperature": 0,
        "text": " with it. Let me refresh. Await is only valid in an async function. Oh, dear. So, here's the thing.",
        "tokens": [
          51192,
          365,
          309,
          13,
          961,
          385,
          15134,
          13,
          6381,
          1001,
          307,
          787,
          7363,
          294,
          364,
          382,
          34015,
          2445,
          13,
          876,
          11,
          6875,
          13,
          407,
          11,
          510,
          311,
          264,
          551,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2163131674941705,
        "compression_ratio": 1.7079646017699115,
        "end": 2572.24,
        "id": 367,
        "no_speech_prob": 0.00011061150871682912,
        "seek": 256624,
        "start": 2567.12,
        "temperature": 0,
        "text": " The await keyword, you can't just use it anywhere in your code. Like, oh, wait for this, then do",
        "tokens": [
          50408,
          440,
          19670,
          20428,
          11,
          291,
          393,
          380,
          445,
          764,
          309,
          4992,
          294,
          428,
          3089,
          13,
          1743,
          11,
          1954,
          11,
          1699,
          337,
          341,
          11,
          550,
          360,
          50664
        ]
      },
      {
        "avg_logprob": -0.2163131674941705,
        "compression_ratio": 1.7079646017699115,
        "end": 2578.72,
        "id": 368,
        "no_speech_prob": 0.00011061150871682912,
        "seek": 256624,
        "start": 2572.24,
        "temperature": 0,
        "text": " this, then wait for this. You have to write your own asynchronous function. Basically, you have to",
        "tokens": [
          50664,
          341,
          11,
          550,
          1699,
          337,
          341,
          13,
          509,
          362,
          281,
          2464,
          428,
          1065,
          49174,
          2445,
          13,
          8537,
          11,
          291,
          362,
          281,
          50988
        ]
      },
      {
        "avg_logprob": -0.2163131674941705,
        "compression_ratio": 1.7079646017699115,
        "end": 2585.6,
        "id": 369,
        "no_speech_prob": 0.00011061150871682912,
        "seek": 256624,
        "start": 2578.72,
        "temperature": 0,
        "text": " write a function that returns a promise. But rather than having to say new return new promise,",
        "tokens": [
          50988,
          2464,
          257,
          2445,
          300,
          11247,
          257,
          6228,
          13,
          583,
          2831,
          813,
          1419,
          281,
          584,
          777,
          2736,
          777,
          6228,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.2163131674941705,
        "compression_ratio": 1.7079646017699115,
        "end": 2591.6,
        "id": 370,
        "no_speech_prob": 0.00011061150871682912,
        "seek": 256624,
        "start": 2585.6,
        "temperature": 0,
        "text": " the async keyword just says, hey, do all that stuff kind of invisibly behind the scenes for me.",
        "tokens": [
          51332,
          264,
          382,
          34015,
          20428,
          445,
          1619,
          11,
          4177,
          11,
          360,
          439,
          300,
          1507,
          733,
          295,
          13308,
          3545,
          2261,
          264,
          8026,
          337,
          385,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.20825492011176217,
        "compression_ratio": 1.5934065934065933,
        "end": 2600.24,
        "id": 371,
        "no_speech_prob": 0.000009080476047529373,
        "seek": 259160,
        "start": 2592.4,
        "temperature": 0,
        "text": " So, now, if I come back over here and I tag this function, basically, tagging is the wrong word.",
        "tokens": [
          50404,
          407,
          11,
          586,
          11,
          498,
          286,
          808,
          646,
          670,
          510,
          293,
          286,
          6162,
          341,
          2445,
          11,
          1936,
          11,
          6162,
          3249,
          307,
          264,
          2085,
          1349,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.20825492011176217,
        "compression_ratio": 1.5934065934065933,
        "end": 2606.48,
        "id": 372,
        "no_speech_prob": 0.000009080476047529373,
        "seek": 259160,
        "start": 2600.24,
        "temperature": 0,
        "text": " But I modify by giving this function a modifier async. I say this is an asynchronous function.",
        "tokens": [
          50796,
          583,
          286,
          16927,
          538,
          2902,
          341,
          2445,
          257,
          38011,
          382,
          34015,
          13,
          286,
          584,
          341,
          307,
          364,
          49174,
          2445,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.20825492011176217,
        "compression_ratio": 1.5934065934065933,
        "end": 2614.4,
        "id": 373,
        "no_speech_prob": 0.000009080476047529373,
        "seek": 259160,
        "start": 2606.48,
        "temperature": 0,
        "text": " It's going to execute asynchronously and return a promise after however many calls to await that I",
        "tokens": [
          51108,
          467,
          311,
          516,
          281,
          14483,
          42642,
          5098,
          293,
          2736,
          257,
          6228,
          934,
          4461,
          867,
          5498,
          281,
          19670,
          300,
          286,
          51504
        ]
      },
      {
        "avg_logprob": -0.1798429298400879,
        "compression_ratio": 1.542857142857143,
        "end": 2634.4,
        "id": 374,
        "no_speech_prob": 0.0055548870004713535,
        "seek": 261440,
        "start": 2614.4,
        "temperature": 0,
        "text": " want. So, now, let me just hit refresh here. Oh, shoot. So, now, let me just hit refresh here.",
        "tokens": [
          50364,
          528,
          13,
          407,
          11,
          586,
          11,
          718,
          385,
          445,
          2045,
          15134,
          510,
          13,
          876,
          11,
          3076,
          13,
          407,
          11,
          586,
          11,
          718,
          385,
          445,
          2045,
          15134,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1798429298400879,
        "compression_ratio": 1.542857142857143,
        "end": 2641.04,
        "id": 375,
        "no_speech_prob": 0.0055548870004713535,
        "seek": 261440,
        "start": 2635.44,
        "temperature": 0,
        "text": " And this works again. So, this now is an asynchronous function. So,",
        "tokens": [
          51416,
          400,
          341,
          1985,
          797,
          13,
          407,
          11,
          341,
          586,
          307,
          364,
          49174,
          2445,
          13,
          407,
          11,
          51696
        ]
      },
      {
        "avg_logprob": -0.3000934657765858,
        "compression_ratio": 1.550561797752809,
        "end": 2648.64,
        "id": 376,
        "no_speech_prob": 0.000024300234144902788,
        "seek": 264104,
        "start": 2641.92,
        "temperature": 0,
        "text": " this and the reason why this is exciting is I can start to do this.",
        "tokens": [
          50408,
          341,
          293,
          264,
          1778,
          983,
          341,
          307,
          4670,
          307,
          286,
          393,
          722,
          281,
          360,
          341,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.3000934657765858,
        "compression_ratio": 1.550561797752809,
        "end": 2657.6,
        "id": 377,
        "no_speech_prob": 0.000024300234144902788,
        "seek": 264104,
        "start": 2653.36,
        "temperature": 0,
        "text": " So, I can sequence a bunch of things that are asynchronous.",
        "tokens": [
          50980,
          407,
          11,
          286,
          393,
          8310,
          257,
          3840,
          295,
          721,
          300,
          366,
          49174,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.3000934657765858,
        "compression_ratio": 1.550561797752809,
        "end": 2661.6,
        "id": 378,
        "no_speech_prob": 0.000024300234144902788,
        "seek": 264104,
        "start": 2658.24,
        "temperature": 0,
        "text": " That and some of these might actually return something.",
        "tokens": [
          51224,
          663,
          293,
          512,
          295,
          613,
          1062,
          767,
          2736,
          746,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.3000934657765858,
        "compression_ratio": 1.550561797752809,
        "end": 2669.36,
        "id": 379,
        "no_speech_prob": 0.000024300234144902788,
        "seek": 264104,
        "start": 2664.24,
        "temperature": 0,
        "text": " And this now, instead of having to chain all these different promises with then dot then dot",
        "tokens": [
          51524,
          400,
          341,
          586,
          11,
          2602,
          295,
          1419,
          281,
          5021,
          439,
          613,
          819,
          16403,
          365,
          550,
          5893,
          550,
          5893,
          51780
        ]
      },
      {
        "avg_logprob": -0.21337811763469988,
        "compression_ratio": 1.6973684210526316,
        "end": 2676.32,
        "id": 380,
        "no_speech_prob": 0.001244829618372023,
        "seek": 266936,
        "start": 2670,
        "temperature": 0,
        "text": " then dot then catch this, catch that, I can just do it all in one function. And that function will",
        "tokens": [
          50396,
          550,
          5893,
          550,
          3745,
          341,
          11,
          3745,
          300,
          11,
          286,
          393,
          445,
          360,
          309,
          439,
          294,
          472,
          2445,
          13,
          400,
          300,
          2445,
          486,
          50712
        ]
      },
      {
        "avg_logprob": -0.21337811763469988,
        "compression_ratio": 1.6973684210526316,
        "end": 2681.92,
        "id": 381,
        "no_speech_prob": 0.001244829618372023,
        "seek": 266936,
        "start": 2676.32,
        "temperature": 0,
        "text": " return a promise. So, I think I don't know how much I don't know if this was that useful to you.",
        "tokens": [
          50712,
          2736,
          257,
          6228,
          13,
          407,
          11,
          286,
          519,
          286,
          500,
          380,
          458,
          577,
          709,
          286,
          500,
          380,
          458,
          498,
          341,
          390,
          300,
          4420,
          281,
          291,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.21337811763469988,
        "compression_ratio": 1.6973684210526316,
        "end": 2686.08,
        "id": 382,
        "no_speech_prob": 0.001244829618372023,
        "seek": 266936,
        "start": 2682.48,
        "temperature": 0,
        "text": " Hopefully, it gives you kind of a sense. But I think a practical example will make a lot more",
        "tokens": [
          51020,
          10429,
          11,
          309,
          2709,
          291,
          733,
          295,
          257,
          2020,
          13,
          583,
          286,
          519,
          257,
          8496,
          1365,
          486,
          652,
          257,
          688,
          544,
          51200
        ]
      },
      {
        "avg_logprob": -0.21337811763469988,
        "compression_ratio": 1.6973684210526316,
        "end": 2694.48,
        "id": 383,
        "no_speech_prob": 0.001244829618372023,
        "seek": 266936,
        "start": 2686.08,
        "temperature": 0,
        "text": " sense. So, if you remember this particular example, look at what I had to do here. I had to fetch",
        "tokens": [
          51200,
          2020,
          13,
          407,
          11,
          498,
          291,
          1604,
          341,
          1729,
          1365,
          11,
          574,
          412,
          437,
          286,
          632,
          281,
          360,
          510,
          13,
          286,
          632,
          281,
          23673,
          51620
        ]
      },
      {
        "avg_logprob": -0.23258469321511008,
        "compression_ratio": 1.5911111111111111,
        "end": 2699.6,
        "id": 384,
        "no_speech_prob": 0.0004878557228948921,
        "seek": 269448,
        "start": 2694.48,
        "temperature": 0,
        "text": " from Wordnik, then get the response, convert it to JSON, then get the word out of that,",
        "tokens": [
          50364,
          490,
          8725,
          13123,
          11,
          550,
          483,
          264,
          4134,
          11,
          7620,
          309,
          281,
          31828,
          11,
          550,
          483,
          264,
          1349,
          484,
          295,
          300,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.23258469321511008,
        "compression_ratio": 1.5911111111111111,
        "end": 2705.84,
        "id": 385,
        "no_speech_prob": 0.0004878557228948921,
        "seek": 269448,
        "start": 2699.6,
        "temperature": 0,
        "text": " then go to another API. I'm going to rewrite all of this in an asynchronous function using await.",
        "tokens": [
          50620,
          550,
          352,
          281,
          1071,
          9362,
          13,
          286,
          478,
          516,
          281,
          28132,
          439,
          295,
          341,
          294,
          364,
          49174,
          2445,
          1228,
          19670,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.23258469321511008,
        "compression_ratio": 1.5911111111111111,
        "end": 2711.04,
        "id": 386,
        "no_speech_prob": 0.0004878557228948921,
        "seek": 269448,
        "start": 2705.84,
        "temperature": 0,
        "text": " And I think that's going to help make things make more sense. So, that's what's going to be",
        "tokens": [
          50932,
          400,
          286,
          519,
          300,
          311,
          516,
          281,
          854,
          652,
          721,
          652,
          544,
          2020,
          13,
          407,
          11,
          300,
          311,
          437,
          311,
          516,
          281,
          312,
          51192
        ]
      },
      {
        "avg_logprob": -0.23258469321511008,
        "compression_ratio": 1.5911111111111111,
        "end": 2717.44,
        "id": 387,
        "no_speech_prob": 0.0004878557228948921,
        "seek": 269448,
        "start": 2711.04,
        "temperature": 0,
        "text": " in the next video. Okay? See you there. Maybe, maybe not. Oh, actually, hold on.",
        "tokens": [
          51192,
          294,
          264,
          958,
          960,
          13,
          1033,
          30,
          3008,
          291,
          456,
          13,
          2704,
          11,
          1310,
          406,
          13,
          876,
          11,
          767,
          11,
          1797,
          322,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.36124582290649415,
        "compression_ratio": 1.417808219178082,
        "end": 2725.36,
        "id": 388,
        "no_speech_prob": 0.00048785549006424844,
        "seek": 271744,
        "start": 2717.84,
        "temperature": 0,
        "text": " No, no, no. Maybe I should go. Maren is making a good point that",
        "tokens": [
          50384,
          883,
          11,
          572,
          11,
          572,
          13,
          2704,
          286,
          820,
          352,
          13,
          376,
          4484,
          307,
          1455,
          257,
          665,
          935,
          300,
          50760
        ]
      },
      {
        "avg_logprob": -0.36124582290649415,
        "compression_ratio": 1.417808219178082,
        "end": 2737.28,
        "id": 389,
        "no_speech_prob": 0.00048785549006424844,
        "seek": 271744,
        "start": 2729.52,
        "temperature": 0,
        "text": " I could actually, like, await multiple things. But I think that's,",
        "tokens": [
          50968,
          286,
          727,
          767,
          11,
          411,
          11,
          19670,
          3866,
          721,
          13,
          583,
          286,
          519,
          300,
          311,
          11,
          51356
        ]
      },
      {
        "avg_logprob": -0.36124582290649415,
        "compression_ratio": 1.417808219178082,
        "end": 2746.48,
        "id": 390,
        "no_speech_prob": 0.00048785549006424844,
        "seek": 271744,
        "start": 2740,
        "temperature": 0,
        "text": " I think maybe that's sort of understood. Don't forget for await. All right.",
        "tokens": [
          51492,
          286,
          519,
          1310,
          300,
          311,
          1333,
          295,
          7320,
          13,
          1468,
          380,
          2870,
          337,
          19670,
          13,
          1057,
          558,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.24261628188096085,
        "compression_ratio": 1.481081081081081,
        "end": 2754.2400000000002,
        "id": 391,
        "no_speech_prob": 0.00002507156204956118,
        "seek": 274744,
        "start": 2748.4,
        "temperature": 0,
        "text": " Yeah, bad example since delay doesn't return any value. I agree. I don't know. Well, you tell me.",
        "tokens": [
          50412,
          865,
          11,
          1578,
          1365,
          1670,
          8577,
          1177,
          380,
          2736,
          604,
          2158,
          13,
          286,
          3986,
          13,
          286,
          500,
          380,
          458,
          13,
          1042,
          11,
          291,
          980,
          385,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.24261628188096085,
        "compression_ratio": 1.481081081081081,
        "end": 2766.7200000000003,
        "id": 392,
        "no_speech_prob": 0.00002507156204956118,
        "seek": 274744,
        "start": 2754.2400000000002,
        "temperature": 0,
        "text": " Do you think I should just cancel the idea of a separate tutorial? I don't know. I'm thinking.",
        "tokens": [
          50704,
          1144,
          291,
          519,
          286,
          820,
          445,
          10373,
          264,
          1558,
          295,
          257,
          4994,
          7073,
          30,
          286,
          500,
          380,
          458,
          13,
          286,
          478,
          1953,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.24261628188096085,
        "compression_ratio": 1.481081081081081,
        "end": 2772.2400000000002,
        "id": 393,
        "no_speech_prob": 0.00002507156204956118,
        "seek": 274744,
        "start": 2768.08,
        "temperature": 0,
        "text": " The good news is I'm churning through this. We don't have too much further to go.",
        "tokens": [
          51396,
          440,
          665,
          2583,
          307,
          286,
          478,
          417,
          10656,
          807,
          341,
          13,
          492,
          500,
          380,
          362,
          886,
          709,
          3052,
          281,
          352,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.27511828878651495,
        "compression_ratio": 1.4067796610169492,
        "end": 2784,
        "id": 394,
        "no_speech_prob": 0.003593527479097247,
        "seek": 277744,
        "start": 2777.84,
        "temperature": 0,
        "text": " I see people are giving me some feedback here. Let me think about this.",
        "tokens": [
          50384,
          286,
          536,
          561,
          366,
          2902,
          385,
          512,
          5824,
          510,
          13,
          961,
          385,
          519,
          466,
          341,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.27511828878651495,
        "compression_ratio": 1.4067796610169492,
        "end": 2794.2400000000002,
        "id": 395,
        "no_speech_prob": 0.003593527479097247,
        "seek": 277744,
        "start": 2787.84,
        "temperature": 0,
        "text": " Does something else help? Okay. All right. I think actually because I added this stuff in,",
        "tokens": [
          50884,
          4402,
          746,
          1646,
          854,
          30,
          1033,
          13,
          1057,
          558,
          13,
          286,
          519,
          767,
          570,
          286,
          3869,
          341,
          1507,
          294,
          11,
          51204
        ]
      },
      {
        "avg_logprob": -0.27511828878651495,
        "compression_ratio": 1.4067796610169492,
        "end": 2801.76,
        "id": 396,
        "no_speech_prob": 0.003593527479097247,
        "seek": 277744,
        "start": 2796.32,
        "temperature": 0,
        "text": " this is okay. I think I'm going to keep it. Don't cancel. Okay. Skip to TensorFlow.js.",
        "tokens": [
          51308,
          341,
          307,
          1392,
          13,
          286,
          519,
          286,
          478,
          516,
          281,
          1066,
          309,
          13,
          1468,
          380,
          10373,
          13,
          1033,
          13,
          46405,
          281,
          37624,
          13,
          25530,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.23960800630500517,
        "compression_ratio": 1.5284090909090908,
        "end": 2807.6800000000003,
        "id": 397,
        "no_speech_prob": 0.00985967181622982,
        "seek": 280176,
        "start": 2801.76,
        "temperature": 0,
        "text": " I appreciate that feedback. I'm going to keep going. Now what I want to do,",
        "tokens": [
          50364,
          286,
          4449,
          300,
          5824,
          13,
          286,
          478,
          516,
          281,
          1066,
          516,
          13,
          823,
          437,
          286,
          528,
          281,
          360,
          11,
          50660
        ]
      },
      {
        "avg_logprob": -0.23960800630500517,
        "compression_ratio": 1.5284090909090908,
        "end": 2812.4,
        "id": 398,
        "no_speech_prob": 0.00985967181622982,
        "seek": 280176,
        "start": 2809.44,
        "temperature": 0,
        "text": " oh, and you know what? I forgot to make a,",
        "tokens": [
          50748,
          1954,
          11,
          293,
          291,
          458,
          437,
          30,
          286,
          5298,
          281,
          652,
          257,
          11,
          50896
        ]
      },
      {
        "avg_logprob": -0.23960800630500517,
        "compression_ratio": 1.5284090909090908,
        "end": 2818.1600000000003,
        "id": 399,
        "no_speech_prob": 0.00985967181622982,
        "seek": 280176,
        "start": 2814.7200000000003,
        "temperature": 0,
        "text": " when I upload all this code, I kind of forgot. But that's okay.",
        "tokens": [
          51012,
          562,
          286,
          6580,
          439,
          341,
          3089,
          11,
          286,
          733,
          295,
          5298,
          13,
          583,
          300,
          311,
          1392,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.23960800630500517,
        "compression_ratio": 1.5284090909090908,
        "end": 2829.6800000000003,
        "id": 400,
        "no_speech_prob": 0.00985967181622982,
        "seek": 280176,
        "start": 2819.84,
        "temperature": 0,
        "text": " All right. Now what I'm going to do is I'm going to go to 01 promises, 03 async await.",
        "tokens": [
          51268,
          1057,
          558,
          13,
          823,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          352,
          281,
          23185,
          16403,
          11,
          43677,
          382,
          34015,
          19670,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.3618658505953275,
        "compression_ratio": 0.9868421052631579,
        "end": 2837.6800000000003,
        "id": 401,
        "no_speech_prob": 0.0060034822672605515,
        "seek": 283176,
        "start": 2832.0800000000004,
        "temperature": 0,
        "text": " And that's what I want to be editing now.",
        "tokens": [
          50380,
          400,
          300,
          311,
          437,
          286,
          528,
          281,
          312,
          10000,
          586,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.3618658505953275,
        "compression_ratio": 0.9868421052631579,
        "end": 2854.6400000000003,
        "id": 402,
        "no_speech_prob": 0.0060034822672605515,
        "seek": 283176,
        "start": 2850.7200000000003,
        "temperature": 0,
        "text": " Okay. And here I should be again.",
        "tokens": [
          51312,
          1033,
          13,
          400,
          510,
          286,
          820,
          312,
          797,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.4581227809824842,
        "compression_ratio": 1.1951219512195121,
        "end": 2858.56,
        "id": 403,
        "no_speech_prob": 0.0009110485552810133,
        "seek": 285464,
        "start": 2854.7999999999997,
        "temperature": 0,
        "text": " Just over and over again refreshing.",
        "tokens": [
          50372,
          1449,
          670,
          293,
          670,
          797,
          19772,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.4581227809824842,
        "compression_ratio": 1.1951219512195121,
        "end": 2870.56,
        "id": 404,
        "no_speech_prob": 0.0009110485552810133,
        "seek": 285464,
        "start": 2868.56,
        "temperature": 0,
        "text": " Oh, okay. That works for me. Water drip. Okay.",
        "tokens": [
          51060,
          876,
          11,
          1392,
          13,
          663,
          1985,
          337,
          385,
          13,
          8772,
          29376,
          13,
          1033,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.4581227809824842,
        "compression_ratio": 1.1951219512195121,
        "end": 2878.56,
        "id": 405,
        "no_speech_prob": 0.0009110485552810133,
        "seek": 285464,
        "start": 2874.64,
        "temperature": 0,
        "text": " All right. Here we are. Now I'm ready for the next bit of this.",
        "tokens": [
          51364,
          1057,
          558,
          13,
          1692,
          321,
          366,
          13,
          823,
          286,
          478,
          1919,
          337,
          264,
          958,
          857,
          295,
          341,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.5965396033393012,
        "compression_ratio": 0.8064516129032258,
        "end": 2886.48,
        "id": 406,
        "no_speech_prob": 0.02843315899372101,
        "seek": 287856,
        "start": 2878.56,
        "temperature": 0,
        "text": " Let me cycle the cameras.",
        "tokens": [
          50412,
          961,
          385,
          6586,
          264,
          8622,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.17798386679755318,
        "compression_ratio": 1.6074074074074074,
        "end": 2915.04,
        "id": 407,
        "no_speech_prob": 0.0026729728560894728,
        "seek": 290856,
        "start": 2908.64,
        "temperature": 0,
        "text": " All right. Here we are. Now I am going to once again in this video use async and await.",
        "tokens": [
          50368,
          1057,
          558,
          13,
          1692,
          321,
          366,
          13,
          823,
          286,
          669,
          516,
          281,
          1564,
          797,
          294,
          341,
          960,
          764,
          382,
          34015,
          293,
          19670,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.17798386679755318,
        "compression_ratio": 1.6074074074074074,
        "end": 2920.16,
        "id": 408,
        "no_speech_prob": 0.0026729728560894728,
        "seek": 290856,
        "start": 2915.7599999999998,
        "temperature": 0,
        "text": " But I'm going to use them in a much more practical way that will actually show you",
        "tokens": [
          50724,
          583,
          286,
          478,
          516,
          281,
          764,
          552,
          294,
          257,
          709,
          544,
          8496,
          636,
          300,
          486,
          767,
          855,
          291,
          50944
        ]
      },
      {
        "avg_logprob": -0.17798386679755318,
        "compression_ratio": 1.6074074074074074,
        "end": 2925.04,
        "id": 409,
        "no_speech_prob": 0.0026729728560894728,
        "seek": 290856,
        "start": 2920.16,
        "temperature": 0,
        "text": " something hopefully that you might at some point want to do in your own JavaScript thing.",
        "tokens": [
          50944,
          746,
          4696,
          300,
          291,
          1062,
          412,
          512,
          935,
          528,
          281,
          360,
          294,
          428,
          1065,
          15778,
          551,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.17798386679755318,
        "compression_ratio": 1.6074074074074074,
        "end": 2930.16,
        "id": 410,
        "no_speech_prob": 0.0026729728560894728,
        "seek": 290856,
        "start": 2925.04,
        "temperature": 0,
        "text": " So back over here, this is what I made in the first part of this series about promises.",
        "tokens": [
          51188,
          407,
          646,
          670,
          510,
          11,
          341,
          307,
          437,
          286,
          1027,
          294,
          264,
          700,
          644,
          295,
          341,
          2638,
          466,
          16403,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.17798386679755318,
        "compression_ratio": 1.6074074074074074,
        "end": 2937.04,
        "id": 411,
        "no_speech_prob": 0.0026729728560894728,
        "seek": 290856,
        "start": 2930.16,
        "temperature": 0,
        "text": " I made this particular JavaScript program. It asks the Wordnik API for a random word,",
        "tokens": [
          51444,
          286,
          1027,
          341,
          1729,
          15778,
          1461,
          13,
          467,
          8962,
          264,
          8725,
          13123,
          9362,
          337,
          257,
          4974,
          1349,
          11,
          51788
        ]
      },
      {
        "avg_logprob": -0.22064943133660084,
        "compression_ratio": 1.5555555555555556,
        "end": 2943.2,
        "id": 412,
        "no_speech_prob": 0.00147793791256845,
        "seek": 293704,
        "start": 2937.04,
        "temperature": 0,
        "text": " water drip. Then once it receives that random word, it goes and fetches a GIF from the GIPHY",
        "tokens": [
          50364,
          1281,
          29376,
          13,
          1396,
          1564,
          309,
          20717,
          300,
          4974,
          1349,
          11,
          309,
          1709,
          293,
          15136,
          3781,
          257,
          460,
          12775,
          490,
          264,
          460,
          9139,
          25501,
          50672
        ]
      },
      {
        "avg_logprob": -0.22064943133660084,
        "compression_ratio": 1.5555555555555556,
        "end": 2948.8,
        "id": 413,
        "no_speech_prob": 0.00147793791256845,
        "seek": 293704,
        "start": 2943.2,
        "temperature": 0,
        "text": " API and shows that GIF. So every time I refresh and sometimes no GIF comes back and I get an error,",
        "tokens": [
          50672,
          9362,
          293,
          3110,
          300,
          460,
          12775,
          13,
          407,
          633,
          565,
          286,
          15134,
          293,
          2171,
          572,
          460,
          12775,
          1487,
          646,
          293,
          286,
          483,
          364,
          6713,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.22064943133660084,
        "compression_ratio": 1.5555555555555556,
        "end": 2958.96,
        "id": 414,
        "no_speech_prob": 0.00147793791256845,
        "seek": 293704,
        "start": 2948.8,
        "temperature": 0,
        "text": " which is good. I feel like something was weird with those GIFs. And I'm going to regret showing",
        "tokens": [
          50952,
          597,
          307,
          665,
          13,
          286,
          841,
          411,
          746,
          390,
          3657,
          365,
          729,
          460,
          12775,
          82,
          13,
          400,
          286,
          478,
          516,
          281,
          10879,
          4099,
          51460
        ]
      },
      {
        "avg_logprob": -0.22064943133660084,
        "compression_ratio": 1.5555555555555556,
        "end": 2963.6,
        "id": 415,
        "no_speech_prob": 0.00147793791256845,
        "seek": 293704,
        "start": 2958.96,
        "temperature": 0,
        "text": " those. Do I still have the PG thing in here? No, I still have it rated PG. Maybe I should",
        "tokens": [
          51460,
          729,
          13,
          1144,
          286,
          920,
          362,
          264,
          40975,
          551,
          294,
          510,
          30,
          883,
          11,
          286,
          920,
          362,
          309,
          22103,
          40975,
          13,
          2704,
          286,
          820,
          51692
        ]
      },
      {
        "avg_logprob": -0.3106311559677124,
        "compression_ratio": 1.382608695652174,
        "end": 2972.96,
        "id": 416,
        "no_speech_prob": 0.09807668626308441,
        "seek": 296360,
        "start": 2963.6,
        "temperature": 0,
        "text": " just rate it G. Let's try that. Let me come back. I didn't like those GIFs.",
        "tokens": [
          50364,
          445,
          3314,
          309,
          460,
          13,
          961,
          311,
          853,
          300,
          13,
          961,
          385,
          808,
          646,
          13,
          286,
          994,
          380,
          411,
          729,
          460,
          12775,
          82,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.3106311559677124,
        "compression_ratio": 1.382608695652174,
        "end": 2987.7599999999998,
        "id": 417,
        "no_speech_prob": 0.09807668626308441,
        "seek": 296360,
        "start": 2982.3199999999997,
        "temperature": 0,
        "text": " I really have it. Whoa, what the? No, no, no, no, no, no, no, no. Okay. No, no, no.",
        "tokens": [
          51300,
          286,
          534,
          362,
          309,
          13,
          7521,
          11,
          437,
          264,
          30,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          1033,
          13,
          883,
          11,
          572,
          11,
          572,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.3408338297968325,
        "compression_ratio": 1.2105263157894737,
        "end": 2992.7200000000003,
        "id": 418,
        "no_speech_prob": 0.002800912829115987,
        "seek": 298776,
        "start": 2988.2400000000002,
        "temperature": 0,
        "text": " No. Why do I get such long...",
        "tokens": [
          50388,
          883,
          13,
          1545,
          360,
          286,
          483,
          1270,
          938,
          485,
          50612
        ]
      },
      {
        "avg_logprob": -0.3408338297968325,
        "compression_ratio": 1.2105263157894737,
        "end": 3006.8,
        "id": 419,
        "no_speech_prob": 0.002800912829115987,
        "seek": 298776,
        "start": 3004.4,
        "temperature": 0,
        "text": " All right, whatever that is, I have no idea. Let me come back. All right.",
        "tokens": [
          51196,
          1057,
          558,
          11,
          2035,
          300,
          307,
          11,
          286,
          362,
          572,
          1558,
          13,
          961,
          385,
          808,
          646,
          13,
          1057,
          558,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.3408338297968325,
        "compression_ratio": 1.2105263157894737,
        "end": 3009.92,
        "id": 420,
        "no_speech_prob": 0.002800912829115987,
        "seek": 298776,
        "start": 3008.6400000000003,
        "temperature": 0,
        "text": " I'm just going to start this over.",
        "tokens": [
          51408,
          286,
          478,
          445,
          516,
          281,
          722,
          341,
          670,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.29709642850435697,
        "compression_ratio": 1.7932330827067668,
        "end": 3016.7200000000003,
        "id": 421,
        "no_speech_prob": 0.006488221697509289,
        "seek": 300992,
        "start": 3010.32,
        "temperature": 0,
        "text": " Hello. All right. In this video, I am once again going to talk about async and await. But in this",
        "tokens": [
          50384,
          2425,
          13,
          1057,
          558,
          13,
          682,
          341,
          960,
          11,
          286,
          669,
          1564,
          797,
          516,
          281,
          751,
          466,
          382,
          34015,
          293,
          19670,
          13,
          583,
          294,
          341,
          50704
        ]
      },
      {
        "avg_logprob": -0.29709642850435697,
        "compression_ratio": 1.7932330827067668,
        "end": 3020.48,
        "id": 422,
        "no_speech_prob": 0.006488221697509289,
        "seek": 300992,
        "start": 3016.7200000000003,
        "temperature": 0,
        "text": " case, I'm going to use a much more practical example. So I'm going to return back to what I",
        "tokens": [
          50704,
          1389,
          11,
          286,
          478,
          516,
          281,
          764,
          257,
          709,
          544,
          8496,
          1365,
          13,
          407,
          286,
          478,
          516,
          281,
          2736,
          646,
          281,
          437,
          286,
          50892
        ]
      },
      {
        "avg_logprob": -0.29709642850435697,
        "compression_ratio": 1.7932330827067668,
        "end": 3026,
        "id": 423,
        "no_speech_prob": 0.006488221697509289,
        "seek": 300992,
        "start": 3020.48,
        "temperature": 0,
        "text": " did in the very first video about what is a promise and using fetch. And I'm going to revisit",
        "tokens": [
          50892,
          630,
          294,
          264,
          588,
          700,
          960,
          466,
          437,
          307,
          257,
          6228,
          293,
          1228,
          23673,
          13,
          400,
          286,
          478,
          516,
          281,
          32676,
          51168
        ]
      },
      {
        "avg_logprob": -0.29709642850435697,
        "compression_ratio": 1.7932330827067668,
        "end": 3032.32,
        "id": 424,
        "no_speech_prob": 0.006488221697509289,
        "seek": 300992,
        "start": 3026,
        "temperature": 0,
        "text": " this example. So what this example does is it goes out to the Wordnik API, goes out. It calls fetch",
        "tokens": [
          51168,
          341,
          1365,
          13,
          407,
          437,
          341,
          1365,
          775,
          307,
          309,
          1709,
          484,
          281,
          264,
          8725,
          13123,
          9362,
          11,
          1709,
          484,
          13,
          467,
          5498,
          23673,
          51484
        ]
      },
      {
        "avg_logprob": -0.29709642850435697,
        "compression_ratio": 1.7932330827067668,
        "end": 3037.84,
        "id": 425,
        "no_speech_prob": 0.006488221697509289,
        "seek": 300992,
        "start": 3032.32,
        "temperature": 0,
        "text": " on the Wordnik API, gets a random word. Once it has that random word, it then requests a GIF.",
        "tokens": [
          51484,
          322,
          264,
          8725,
          13123,
          9362,
          11,
          2170,
          257,
          4974,
          1349,
          13,
          3443,
          309,
          575,
          300,
          4974,
          1349,
          11,
          309,
          550,
          12475,
          257,
          460,
          12775,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.30953448902476915,
        "compression_ratio": 1.6554621848739495,
        "end": 3044.7200000000003,
        "id": 426,
        "no_speech_prob": 0.009412240236997604,
        "seek": 303784,
        "start": 3038.4,
        "temperature": 0,
        "text": " And we can see fetch returns a promise. And so I've chained a whole lot of promises. Fetch from",
        "tokens": [
          50392,
          400,
          321,
          393,
          536,
          23673,
          11247,
          257,
          6228,
          13,
          400,
          370,
          286,
          600,
          417,
          3563,
          257,
          1379,
          688,
          295,
          16403,
          13,
          479,
          7858,
          490,
          50708
        ]
      },
      {
        "avg_logprob": -0.30953448902476915,
        "compression_ratio": 1.6554621848739495,
        "end": 3050.32,
        "id": 427,
        "no_speech_prob": 0.009412240236997604,
        "seek": 303784,
        "start": 3044.7200000000003,
        "temperature": 0,
        "text": " the Wordnik API, then we get a response, convert the response to JSON. Then once you have the JSON,",
        "tokens": [
          50708,
          264,
          8725,
          13123,
          9362,
          11,
          550,
          321,
          483,
          257,
          4134,
          11,
          7620,
          264,
          4134,
          281,
          31828,
          13,
          1396,
          1564,
          291,
          362,
          264,
          31828,
          11,
          50988
        ]
      },
      {
        "avg_logprob": -0.30953448902476915,
        "compression_ratio": 1.6554621848739495,
        "end": 3057.52,
        "id": 428,
        "no_speech_prob": 0.009412240236997604,
        "seek": 303784,
        "start": 3050.32,
        "temperature": 0,
        "text": " put the word in the DOM, then go to GIPHY, then convert that to JSON, then make an image. And if",
        "tokens": [
          50988,
          829,
          264,
          1349,
          294,
          264,
          35727,
          11,
          550,
          352,
          281,
          460,
          9139,
          25501,
          11,
          550,
          7620,
          300,
          281,
          31828,
          11,
          550,
          652,
          364,
          3256,
          13,
          400,
          498,
          51348
        ]
      },
      {
        "avg_logprob": -0.30953448902476915,
        "compression_ratio": 1.6554621848739495,
        "end": 3063.04,
        "id": 429,
        "no_speech_prob": 0.009412240236997604,
        "seek": 303784,
        "start": 3057.52,
        "temperature": 0,
        "text": " there's any error anywhere on there, log the error. And maybe I want to say console.error error here.",
        "tokens": [
          51348,
          456,
          311,
          604,
          6713,
          4992,
          322,
          456,
          11,
          3565,
          264,
          6713,
          13,
          400,
          1310,
          286,
          528,
          281,
          584,
          11076,
          13,
          260,
          2874,
          6713,
          510,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.3093792029789516,
        "compression_ratio": 1.7180616740088106,
        "end": 3070.88,
        "id": 430,
        "no_speech_prob": 0.0016743842279538512,
        "seek": 306304,
        "start": 3063.2,
        "temperature": 0,
        "text": " All right. So now I want to change, I want to do this in a much nicer, syntactically sugary way",
        "tokens": [
          50372,
          1057,
          558,
          13,
          407,
          586,
          286,
          528,
          281,
          1319,
          11,
          286,
          528,
          281,
          360,
          341,
          294,
          257,
          709,
          22842,
          11,
          23980,
          578,
          984,
          22802,
          822,
          636,
          50756
        ]
      },
      {
        "avg_logprob": -0.3093792029789516,
        "compression_ratio": 1.7180616740088106,
        "end": 3076,
        "id": 431,
        "no_speech_prob": 0.0016743842279538512,
        "seek": 306304,
        "start": 3071.44,
        "temperature": 0,
        "text": " with async and await. So how do I do that? Well, the first thing that I want to do is just take",
        "tokens": [
          50784,
          365,
          382,
          34015,
          293,
          19670,
          13,
          407,
          577,
          360,
          286,
          360,
          300,
          30,
          1042,
          11,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          445,
          747,
          51012
        ]
      },
      {
        "avg_logprob": -0.3093792029789516,
        "compression_ratio": 1.7180616740088106,
        "end": 3082.72,
        "id": 432,
        "no_speech_prob": 0.0016743842279538512,
        "seek": 306304,
        "start": 3076,
        "temperature": 0,
        "text": " all of this code and put it in a separate function. So I'm going to say, I don't know what this is",
        "tokens": [
          51012,
          439,
          295,
          341,
          3089,
          293,
          829,
          309,
          294,
          257,
          4994,
          2445,
          13,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          500,
          380,
          458,
          437,
          341,
          307,
          51348
        ]
      },
      {
        "avg_logprob": -0.3093792029789516,
        "compression_ratio": 1.7180616740088106,
        "end": 3089.12,
        "id": 433,
        "no_speech_prob": 0.0016743842279538512,
        "seek": 306304,
        "start": 3082.72,
        "temperature": 0,
        "text": " like. I'm going to call this function word GIF. And I actually want to change a couple things here.",
        "tokens": [
          51348,
          411,
          13,
          286,
          478,
          516,
          281,
          818,
          341,
          2445,
          1349,
          460,
          12775,
          13,
          400,
          286,
          767,
          528,
          281,
          1319,
          257,
          1916,
          721,
          510,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.26647380579297786,
        "compression_ratio": 1.668122270742358,
        "end": 3094.88,
        "id": 434,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 308912,
        "start": 3089.12,
        "temperature": 0,
        "text": " What I want to do is I want to give it a, because I, actually, this isn't important right now. I'm",
        "tokens": [
          50364,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          976,
          309,
          257,
          11,
          570,
          286,
          11,
          767,
          11,
          341,
          1943,
          380,
          1021,
          558,
          586,
          13,
          286,
          478,
          50652
        ]
      },
      {
        "avg_logprob": -0.26647380579297786,
        "compression_ratio": 1.668122270742358,
        "end": 3099.04,
        "id": 435,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 308912,
        "start": 3094.88,
        "temperature": 0,
        "text": " going to add this in the next video. I want to show you what happens when you then need to call,",
        "tokens": [
          50652,
          516,
          281,
          909,
          341,
          294,
          264,
          958,
          960,
          13,
          286,
          528,
          281,
          855,
          291,
          437,
          2314,
          562,
          291,
          550,
          643,
          281,
          818,
          11,
          50860
        ]
      },
      {
        "avg_logprob": -0.26647380579297786,
        "compression_ratio": 1.668122270742358,
        "end": 3102.3199999999997,
        "id": 436,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 308912,
        "start": 3099.04,
        "temperature": 0,
        "text": " have multiple promises. But I'll come back to that. So we're just going to call this function",
        "tokens": [
          50860,
          362,
          3866,
          16403,
          13,
          583,
          286,
          603,
          808,
          646,
          281,
          300,
          13,
          407,
          321,
          434,
          445,
          516,
          281,
          818,
          341,
          2445,
          51024
        ]
      },
      {
        "avg_logprob": -0.26647380579297786,
        "compression_ratio": 1.668122270742358,
        "end": 3110.08,
        "id": 437,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 308912,
        "start": 3102.3199999999997,
        "temperature": 0,
        "text": " word GIF. So if I go in here and set up and call this word GIF function, we are going to see",
        "tokens": [
          51024,
          1349,
          460,
          12775,
          13,
          407,
          498,
          286,
          352,
          294,
          510,
          293,
          992,
          493,
          293,
          818,
          341,
          1349,
          460,
          12775,
          2445,
          11,
          321,
          366,
          516,
          281,
          536,
          51412
        ]
      },
      {
        "avg_logprob": -0.45856098646528265,
        "compression_ratio": 1.5668449197860963,
        "end": 3120.3199999999997,
        "id": 438,
        "no_speech_prob": 0.004399363417178392,
        "seek": 311008,
        "start": 3110.96,
        "temperature": 0,
        "text": " some GIFs. And sometimes there's an error, right? Okay. So now I want to make this, I want to use",
        "tokens": [
          50408,
          512,
          460,
          12775,
          82,
          13,
          400,
          2171,
          456,
          311,
          364,
          6713,
          11,
          558,
          30,
          1033,
          13,
          407,
          586,
          286,
          528,
          281,
          652,
          341,
          11,
          286,
          528,
          281,
          764,
          50876
        ]
      },
      {
        "avg_logprob": -0.45856098646528265,
        "compression_ratio": 1.5668449197860963,
        "end": 3130.3199999999997,
        "id": 439,
        "no_speech_prob": 0.004399363417178392,
        "seek": 311008,
        "start": 3120.3199999999997,
        "temperature": 0,
        "text": " await instead. In other words, I want to say await fetch wordnik API. And I'm going to say let data",
        "tokens": [
          50876,
          19670,
          2602,
          13,
          682,
          661,
          2283,
          11,
          286,
          528,
          281,
          584,
          19670,
          23673,
          1349,
          13123,
          9362,
          13,
          400,
          286,
          478,
          516,
          281,
          584,
          718,
          1412,
          51376
        ]
      },
      {
        "avg_logprob": -0.45856098646528265,
        "compression_ratio": 1.5668449197860963,
        "end": 3135.36,
        "id": 440,
        "no_speech_prob": 0.004399363417178392,
        "seek": 311008,
        "start": 3130.3199999999997,
        "temperature": 0,
        "text": " equals await. So this is, by the way, I can do this now. This is a nice, simple way to do this.",
        "tokens": [
          51376,
          6915,
          19670,
          13,
          407,
          341,
          307,
          11,
          538,
          264,
          636,
          11,
          286,
          393,
          360,
          341,
          586,
          13,
          639,
          307,
          257,
          1481,
          11,
          2199,
          636,
          281,
          360,
          341,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.2924749133656326,
        "compression_ratio": 1.6208333333333333,
        "end": 3141.04,
        "id": 441,
        "no_speech_prob": 0.08151572942733765,
        "seek": 313536,
        "start": 3135.36,
        "temperature": 0,
        "text": " Instead of all of this stuff, all I have to do, and I guess I call this response. I can actually",
        "tokens": [
          50364,
          7156,
          295,
          439,
          295,
          341,
          1507,
          11,
          439,
          286,
          362,
          281,
          360,
          11,
          293,
          286,
          2041,
          286,
          818,
          341,
          4134,
          13,
          286,
          393,
          767,
          50648
        ]
      },
      {
        "avg_logprob": -0.2924749133656326,
        "compression_ratio": 1.6208333333333333,
        "end": 3146.7200000000003,
        "id": 442,
        "no_speech_prob": 0.08151572942733765,
        "seek": 313536,
        "start": 3141.04,
        "temperature": 0,
        "text": " just await the result instead of having to fetch and call then. That's the new thing. But remember,",
        "tokens": [
          50648,
          445,
          19670,
          264,
          1874,
          2602,
          295,
          1419,
          281,
          23673,
          293,
          818,
          550,
          13,
          663,
          311,
          264,
          777,
          551,
          13,
          583,
          1604,
          11,
          50932
        ]
      },
      {
        "avg_logprob": -0.2924749133656326,
        "compression_ratio": 1.6208333333333333,
        "end": 3153.6,
        "id": 443,
        "no_speech_prob": 0.08151572942733765,
        "seek": 313536,
        "start": 3146.7200000000003,
        "temperature": 0,
        "text": " if I'm writing a function that uses await, I must make sure that I label that function async. So",
        "tokens": [
          50932,
          498,
          286,
          478,
          3579,
          257,
          2445,
          300,
          4960,
          19670,
          11,
          286,
          1633,
          652,
          988,
          300,
          286,
          7645,
          300,
          2445,
          382,
          34015,
          13,
          407,
          51276
        ]
      },
      {
        "avg_logprob": -0.2924749133656326,
        "compression_ratio": 1.6208333333333333,
        "end": 3158.6400000000003,
        "id": 444,
        "no_speech_prob": 0.08151572942733765,
        "seek": 313536,
        "start": 3153.6,
        "temperature": 0,
        "text": " that's my replacement here. And then guess what? Look at this. Oh my God. I could just say then",
        "tokens": [
          51276,
          300,
          311,
          452,
          14419,
          510,
          13,
          400,
          550,
          2041,
          437,
          30,
          2053,
          412,
          341,
          13,
          876,
          452,
          1265,
          13,
          286,
          727,
          445,
          584,
          550,
          51528
        ]
      },
      {
        "avg_logprob": -0.38788352335306037,
        "compression_ratio": 1.8715953307392996,
        "end": 3164.3199999999997,
        "id": 445,
        "no_speech_prob": 0.0019267202587798238,
        "seek": 315864,
        "start": 3158.96,
        "temperature": 0,
        "text": " await response.json. So all of this stuff that I had to chain with thens, I don't need to do that",
        "tokens": [
          50380,
          19670,
          4134,
          13,
          73,
          3015,
          13,
          407,
          439,
          295,
          341,
          1507,
          300,
          286,
          632,
          281,
          5021,
          365,
          550,
          82,
          11,
          286,
          500,
          380,
          643,
          281,
          360,
          300,
          50648
        ]
      },
      {
        "avg_logprob": -0.38788352335306037,
        "compression_ratio": 1.8715953307392996,
        "end": 3169.12,
        "id": 446,
        "no_speech_prob": 0.0019267202587798238,
        "seek": 315864,
        "start": 3164.3199999999997,
        "temperature": 0,
        "text": " anymore. I could just write them line by line by line in sequence and they'll all wait. This will",
        "tokens": [
          50648,
          3602,
          13,
          286,
          727,
          445,
          2464,
          552,
          1622,
          538,
          1622,
          538,
          1622,
          294,
          8310,
          293,
          436,
          603,
          439,
          1699,
          13,
          639,
          486,
          50888
        ]
      },
      {
        "avg_logprob": -0.38788352335306037,
        "compression_ratio": 1.8715953307392996,
        "end": 3174,
        "id": 447,
        "no_speech_prob": 0.0019267202587798238,
        "seek": 315864,
        "start": 3169.12,
        "temperature": 0,
        "text": " happen asynchronously because I've made it an async function. So I'm just going to keep going",
        "tokens": [
          50888,
          1051,
          42642,
          5098,
          570,
          286,
          600,
          1027,
          309,
          364,
          382,
          34015,
          2445,
          13,
          407,
          286,
          478,
          445,
          516,
          281,
          1066,
          516,
          51132
        ]
      },
      {
        "avg_logprob": -0.38788352335306037,
        "compression_ratio": 1.8715953307392996,
        "end": 3179.2799999999997,
        "id": 448,
        "no_speech_prob": 0.0019267202587798238,
        "seek": 315864,
        "start": 3174,
        "temperature": 0,
        "text": " here. Then I'm going to, and I'm going to call this response one. I don't love that, but just for",
        "tokens": [
          51132,
          510,
          13,
          1396,
          286,
          478,
          516,
          281,
          11,
          293,
          286,
          478,
          516,
          281,
          818,
          341,
          4134,
          472,
          13,
          286,
          500,
          380,
          959,
          300,
          11,
          457,
          445,
          337,
          51396
        ]
      },
      {
        "avg_logprob": -0.38788352335306037,
        "compression_ratio": 1.8715953307392996,
        "end": 3184.3199999999997,
        "id": 449,
        "no_speech_prob": 0.0019267202587798238,
        "seek": 315864,
        "start": 3179.2799999999997,
        "temperature": 0,
        "text": " the sake of argument here. So I'm going to call this response one. And then I'm going to say,",
        "tokens": [
          51396,
          264,
          9717,
          295,
          6770,
          510,
          13,
          407,
          286,
          478,
          516,
          281,
          818,
          341,
          4134,
          472,
          13,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          51648
        ]
      },
      {
        "avg_logprob": -0.2983852386474609,
        "compression_ratio": 1.5511363636363635,
        "end": 3189.84,
        "id": 450,
        "no_speech_prob": 0.008061736822128296,
        "seek": 318432,
        "start": 3185.2000000000003,
        "temperature": 0,
        "text": " I don't love that, but just for the sake of argument here, I'm now going to say",
        "tokens": [
          50408,
          286,
          500,
          380,
          959,
          300,
          11,
          457,
          445,
          337,
          264,
          9717,
          295,
          6770,
          510,
          11,
          286,
          478,
          586,
          516,
          281,
          584,
          50640
        ]
      },
      {
        "avg_logprob": -0.2983852386474609,
        "compression_ratio": 1.5511363636363635,
        "end": 3197.28,
        "id": 451,
        "no_speech_prob": 0.008061736822128296,
        "seek": 318432,
        "start": 3192.0800000000004,
        "temperature": 0,
        "text": " this now, await fetch GiphyApi plus that word. Then I'm going to, and I'm going to call this",
        "tokens": [
          50752,
          341,
          586,
          11,
          19670,
          23673,
          460,
          647,
          3495,
          32,
          22630,
          1804,
          300,
          1349,
          13,
          1396,
          286,
          478,
          516,
          281,
          11,
          293,
          286,
          478,
          516,
          281,
          818,
          341,
          51012
        ]
      },
      {
        "avg_logprob": -0.2983852386474609,
        "compression_ratio": 1.5511363636363635,
        "end": 3203.04,
        "id": 452,
        "no_speech_prob": 0.008061736822128296,
        "seek": 318432,
        "start": 3197.28,
        "temperature": 0,
        "text": " JSON one. Then I'm going to say, and these should all be const probably, await, and this is response",
        "tokens": [
          51012,
          31828,
          472,
          13,
          1396,
          286,
          478,
          516,
          281,
          584,
          11,
          293,
          613,
          820,
          439,
          312,
          1817,
          1391,
          11,
          19670,
          11,
          293,
          341,
          307,
          4134,
          51300
        ]
      },
      {
        "avg_logprob": -0.3544769605000814,
        "compression_ratio": 1.054945054945055,
        "end": 3225.12,
        "id": 453,
        "no_speech_prob": 0.04084421694278717,
        "seek": 320304,
        "start": 3203.04,
        "temperature": 0,
        "text": " one, response two.json. So that's all the steps. And then I want to say let image equal JSON two",
        "tokens": [
          50364,
          472,
          11,
          4134,
          732,
          13,
          73,
          3015,
          13,
          407,
          300,
          311,
          439,
          264,
          4439,
          13,
          400,
          550,
          286,
          528,
          281,
          584,
          718,
          3256,
          2681,
          31828,
          732,
          51468
        ]
      },
      {
        "avg_logprob": -0.21595748429445877,
        "compression_ratio": 1.6195121951219513,
        "end": 3229.2799999999997,
        "id": 454,
        "no_speech_prob": 0.0008040825487114489,
        "seek": 322512,
        "start": 3225.7599999999998,
        "temperature": 0,
        "text": " dot and all of this stuff. I want to get that GIF.",
        "tokens": [
          50396,
          5893,
          293,
          439,
          295,
          341,
          1507,
          13,
          286,
          528,
          281,
          483,
          300,
          460,
          12775,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.21595748429445877,
        "compression_ratio": 1.6195121951219513,
        "end": 3238.88,
        "id": 455,
        "no_speech_prob": 0.0008040825487114489,
        "seek": 322512,
        "start": 3232.7999999999997,
        "temperature": 0,
        "text": " And now, and I'm going to also say, I think what I want to do here is say let word equal JSON one",
        "tokens": [
          50748,
          400,
          586,
          11,
          293,
          286,
          478,
          516,
          281,
          611,
          584,
          11,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          584,
          718,
          1349,
          2681,
          31828,
          472,
          51052
        ]
      },
      {
        "avg_logprob": -0.21595748429445877,
        "compression_ratio": 1.6195121951219513,
        "end": 3244,
        "id": 456,
        "no_speech_prob": 0.0008040825487114489,
        "seek": 322512,
        "start": 3238.88,
        "temperature": 0,
        "text": " dot word. These are the things I want to get during these steps. So I'm going to put word here",
        "tokens": [
          51052,
          5893,
          1349,
          13,
          1981,
          366,
          264,
          721,
          286,
          528,
          281,
          483,
          1830,
          613,
          4439,
          13,
          407,
          286,
          478,
          516,
          281,
          829,
          1349,
          510,
          51308
        ]
      },
      {
        "avg_logprob": -0.21595748429445877,
        "compression_ratio": 1.6195121951219513,
        "end": 3253.68,
        "id": 457,
        "no_speech_prob": 0.0008040825487114489,
        "seek": 322512,
        "start": 3244,
        "temperature": 0,
        "text": " and then I could just return at the very end, an object with a word, word, image, image.",
        "tokens": [
          51308,
          293,
          550,
          286,
          727,
          445,
          2736,
          412,
          264,
          588,
          917,
          11,
          364,
          2657,
          365,
          257,
          1349,
          11,
          1349,
          11,
          3256,
          11,
          3256,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.22008489126182465,
        "compression_ratio": 1.5423728813559323,
        "end": 3263.2799999999997,
        "id": 458,
        "no_speech_prob": 0.00006709220178890973,
        "seek": 325368,
        "start": 3254.64,
        "temperature": 0,
        "text": " This should be like image URL probably. So let's call this, and I guess I'm going to be,",
        "tokens": [
          50412,
          639,
          820,
          312,
          411,
          3256,
          12905,
          1391,
          13,
          407,
          718,
          311,
          818,
          341,
          11,
          293,
          286,
          2041,
          286,
          478,
          516,
          281,
          312,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.22008489126182465,
        "compression_ratio": 1.5423728813559323,
        "end": 3274,
        "id": 459,
        "no_speech_prob": 0.00006709220178890973,
        "seek": 325368,
        "start": 3265.04,
        "temperature": 0,
        "text": " I guess I'm going to, let me just do this. I think this will be simpler. JSON one dot word.",
        "tokens": [
          50932,
          286,
          2041,
          286,
          478,
          516,
          281,
          11,
          718,
          385,
          445,
          360,
          341,
          13,
          286,
          519,
          341,
          486,
          312,
          18587,
          13,
          31828,
          472,
          5893,
          1349,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.22008489126182465,
        "compression_ratio": 1.5423728813559323,
        "end": 3279.7599999999998,
        "id": 460,
        "no_speech_prob": 0.00006709220178890973,
        "seek": 325368,
        "start": 3274,
        "temperature": 0,
        "text": " So now I've made this async function, we're called word GIF that, oh wait, oh wait, oh wait,",
        "tokens": [
          51380,
          407,
          586,
          286,
          600,
          1027,
          341,
          382,
          34015,
          2445,
          11,
          321,
          434,
          1219,
          1349,
          460,
          12775,
          300,
          11,
          1954,
          1699,
          11,
          1954,
          1699,
          11,
          1954,
          1699,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.19804775822270024,
        "compression_ratio": 1.6902654867256637,
        "end": 3285.6800000000003,
        "id": 461,
        "no_speech_prob": 0.00003071817627642304,
        "seek": 327976,
        "start": 3280.5600000000004,
        "temperature": 0,
        "text": " just go through that, all those steps. And when it's done, it returns an object with the data",
        "tokens": [
          50404,
          445,
          352,
          807,
          300,
          11,
          439,
          729,
          4439,
          13,
          400,
          562,
          309,
          311,
          1096,
          11,
          309,
          11247,
          364,
          2657,
          365,
          264,
          1412,
          50660
        ]
      },
      {
        "avg_logprob": -0.19804775822270024,
        "compression_ratio": 1.6902654867256637,
        "end": 3291.28,
        "id": 462,
        "no_speech_prob": 0.00003071817627642304,
        "seek": 327976,
        "start": 3285.6800000000003,
        "temperature": 0,
        "text": " that it's retrieved. Guess what? I can get rid of all of this, all of this, all of this. I don't",
        "tokens": [
          50660,
          300,
          309,
          311,
          19817,
          937,
          13,
          17795,
          437,
          30,
          286,
          393,
          483,
          3973,
          295,
          439,
          295,
          341,
          11,
          439,
          295,
          341,
          11,
          439,
          295,
          341,
          13,
          286,
          500,
          380,
          50940
        ]
      },
      {
        "avg_logprob": -0.19804775822270024,
        "compression_ratio": 1.6902654867256637,
        "end": 3298,
        "id": 463,
        "no_speech_prob": 0.00003071817627642304,
        "seek": 327976,
        "start": 3291.28,
        "temperature": 0,
        "text": " need, I don't need any of that anymore. None of this. And guess what? This, remember, this is just",
        "tokens": [
          50940,
          643,
          11,
          286,
          500,
          380,
          643,
          604,
          295,
          300,
          3602,
          13,
          14492,
          295,
          341,
          13,
          400,
          2041,
          437,
          30,
          639,
          11,
          1604,
          11,
          341,
          307,
          445,
          51276
        ]
      },
      {
        "avg_logprob": -0.19804775822270024,
        "compression_ratio": 1.6902654867256637,
        "end": 3305.5200000000004,
        "id": 464,
        "no_speech_prob": 0.00003071817627642304,
        "seek": 327976,
        "start": 3298,
        "temperature": 0,
        "text": " syntax sugar to wrap all of this stuff in a promise. So all I have to do now is say word GIF",
        "tokens": [
          51276,
          28431,
          5076,
          281,
          7019,
          439,
          295,
          341,
          1507,
          294,
          257,
          6228,
          13,
          407,
          439,
          286,
          362,
          281,
          360,
          586,
          307,
          584,
          1349,
          460,
          12775,
          51652
        ]
      },
      {
        "avg_logprob": -0.2692885215465839,
        "compression_ratio": 1.4692307692307693,
        "end": 3315.36,
        "id": 465,
        "no_speech_prob": 0.000008530314516974613,
        "seek": 330552,
        "start": 3305.52,
        "temperature": 0,
        "text": " dot then, and then I can say results, right? What comes back? An object with these things in it.",
        "tokens": [
          50364,
          5893,
          550,
          11,
          293,
          550,
          286,
          393,
          584,
          3542,
          11,
          558,
          30,
          708,
          1487,
          646,
          30,
          1107,
          2657,
          365,
          613,
          721,
          294,
          309,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.2692885215465839,
        "compression_ratio": 1.4692307692307693,
        "end": 3328.8,
        "id": 466,
        "no_speech_prob": 0.000008530314516974613,
        "seek": 330552,
        "start": 3315.36,
        "temperature": 0,
        "text": " And I can say create P results dot word, create image results dot image URL. So then, and then",
        "tokens": [
          50856,
          400,
          286,
          393,
          584,
          1884,
          430,
          3542,
          5893,
          1349,
          11,
          1884,
          3256,
          3542,
          5893,
          3256,
          12905,
          13,
          407,
          550,
          11,
          293,
          550,
          51528
        ]
      },
      {
        "avg_logprob": -0.30099132143217944,
        "compression_ratio": 1.6833333333333333,
        "end": 3339.76,
        "id": 467,
        "no_speech_prob": 0.0011879028752446175,
        "seek": 332880,
        "start": 3329.36,
        "temperature": 0,
        "text": " I can catch any error the same exact way, console dot error, error. So look at this. So look at this.",
        "tokens": [
          50392,
          286,
          393,
          3745,
          604,
          6713,
          264,
          912,
          1900,
          636,
          11,
          11076,
          5893,
          6713,
          11,
          6713,
          13,
          407,
          574,
          412,
          341,
          13,
          407,
          574,
          412,
          341,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.30099132143217944,
        "compression_ratio": 1.6833333333333333,
        "end": 3347.76,
        "id": 468,
        "no_speech_prob": 0.0011879028752446175,
        "seek": 332880,
        "start": 3339.76,
        "temperature": 0,
        "text": " Oh my goodness. Is this right? Could this possibly be right? Whoops. I'm looking, I'm looking.",
        "tokens": [
          50912,
          876,
          452,
          8387,
          13,
          1119,
          341,
          558,
          30,
          7497,
          341,
          6264,
          312,
          558,
          30,
          45263,
          13,
          286,
          478,
          1237,
          11,
          286,
          478,
          1237,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.30099132143217944,
        "compression_ratio": 1.6833333333333333,
        "end": 3357.76,
        "id": 469,
        "no_speech_prob": 0.0011879028752446175,
        "seek": 332880,
        "start": 3347.76,
        "temperature": 0,
        "text": " Sort of seems right. Sort of seems right. All right, here we go. Okay, so I can't believe I just did this.",
        "tokens": [
          51312,
          26149,
          295,
          2544,
          558,
          13,
          26149,
          295,
          2544,
          558,
          13,
          1057,
          558,
          11,
          510,
          321,
          352,
          13,
          1033,
          11,
          370,
          286,
          393,
          380,
          1697,
          286,
          445,
          630,
          341,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.25707346817542764,
        "compression_ratio": 1.3071895424836601,
        "end": 3363.92,
        "id": 470,
        "no_speech_prob": 0.0011879014782607555,
        "seek": 335776,
        "start": 3358.7200000000003,
        "temperature": 0,
        "text": " Are you following me? I got, I got lost in my own thoughts there. Let's just run this and see what happens.",
        "tokens": [
          50412,
          2014,
          291,
          3480,
          385,
          30,
          286,
          658,
          11,
          286,
          658,
          2731,
          294,
          452,
          1065,
          4598,
          456,
          13,
          961,
          311,
          445,
          1190,
          341,
          293,
          536,
          437,
          2314,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.25707346817542764,
        "compression_ratio": 1.3071895424836601,
        "end": 3378.88,
        "id": 471,
        "no_speech_prob": 0.0011879014782607555,
        "seek": 335776,
        "start": 3372.88,
        "temperature": 0,
        "text": " Cannot read property data of undefined sketch dot JS line 20. Let's see, what did I mess up?",
        "tokens": [
          51120,
          29866,
          310,
          1401,
          4707,
          1412,
          295,
          674,
          5666,
          2001,
          12325,
          5893,
          33063,
          1622,
          945,
          13,
          961,
          311,
          536,
          11,
          437,
          630,
          286,
          2082,
          493,
          30,
          51420
        ]
      },
      {
        "avg_logprob": -0.27683999321677466,
        "compression_ratio": 1.528301886792453,
        "end": 3391.84,
        "id": 472,
        "no_speech_prob": 0.00006502815813291818,
        "seek": 337888,
        "start": 3379.84,
        "temperature": 0,
        "text": " Oh, hold on. Maybe actually, oh, this is right. It worked actually. This, it's just printing out the error.",
        "tokens": [
          50412,
          876,
          11,
          1797,
          322,
          13,
          2704,
          767,
          11,
          1954,
          11,
          341,
          307,
          558,
          13,
          467,
          2732,
          767,
          13,
          639,
          11,
          309,
          311,
          445,
          14699,
          484,
          264,
          6713,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.27683999321677466,
        "compression_ratio": 1.528301886792453,
        "end": 3395.84,
        "id": 473,
        "no_speech_prob": 0.00006502815813291818,
        "seek": 337888,
        "start": 3391.84,
        "temperature": 0,
        "text": " There was no image. So I need to be better about handling the error, which I'm going to do in a second.",
        "tokens": [
          51012,
          821,
          390,
          572,
          3256,
          13,
          407,
          286,
          643,
          281,
          312,
          1101,
          466,
          13175,
          264,
          6713,
          11,
          597,
          286,
          478,
          516,
          281,
          360,
          294,
          257,
          1150,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.27683999321677466,
        "compression_ratio": 1.528301886792453,
        "end": 3403.84,
        "id": 474,
        "no_speech_prob": 0.00006502815813291818,
        "seek": 337888,
        "start": 3395.84,
        "temperature": 0,
        "text": " So let me change this. Let me change the Wordnik API to give me a word that's between three and five characters.",
        "tokens": [
          51212,
          407,
          718,
          385,
          1319,
          341,
          13,
          961,
          385,
          1319,
          264,
          8725,
          13123,
          9362,
          281,
          976,
          385,
          257,
          1349,
          300,
          311,
          1296,
          1045,
          293,
          1732,
          4342,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.27581200069851347,
        "compression_ratio": 1.5588235294117647,
        "end": 3414.8,
        "id": 475,
        "no_speech_prob": 0.0019267250318080187,
        "seek": 340384,
        "start": 3404.8,
        "temperature": 0,
        "text": " So I really make sure that I get a GIF. Okay. Well, let's just see. Something is missing. Something's going wrong here.",
        "tokens": [
          50412,
          407,
          286,
          534,
          652,
          988,
          300,
          286,
          483,
          257,
          460,
          12775,
          13,
          1033,
          13,
          1042,
          11,
          718,
          311,
          445,
          536,
          13,
          6595,
          307,
          5361,
          13,
          6595,
          311,
          516,
          2085,
          510,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.27581200069851347,
        "compression_ratio": 1.5588235294117647,
        "end": 3424.8,
        "id": 476,
        "no_speech_prob": 0.0019267250318080187,
        "seek": 340384,
        "start": 3417.6800000000003,
        "temperature": 0,
        "text": " Let's take a look at JSON1. No, the word came in. There's just no GIF associated with any of these words.",
        "tokens": [
          51056,
          961,
          311,
          747,
          257,
          574,
          412,
          31828,
          16,
          13,
          883,
          11,
          264,
          1349,
          1361,
          294,
          13,
          821,
          311,
          445,
          572,
          460,
          12775,
          6615,
          365,
          604,
          295,
          613,
          2283,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.27581200069851347,
        "compression_ratio": 1.5588235294117647,
        "end": 3430.8,
        "id": 477,
        "no_speech_prob": 0.0019267250318080187,
        "seek": 340384,
        "start": 3424.8,
        "temperature": 0,
        "text": " Really? There's got to be a GIF associated with fried. I think I might be missing something.",
        "tokens": [
          51412,
          4083,
          30,
          821,
          311,
          658,
          281,
          312,
          257,
          460,
          12775,
          6615,
          365,
          10425,
          13,
          286,
          519,
          286,
          1062,
          312,
          5361,
          746,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.20995006045779666,
        "compression_ratio": 1.3544973544973544,
        "end": 3445.76,
        "id": 478,
        "no_speech_prob": 0.00045831248280592263,
        "seek": 343080,
        "start": 3431.76,
        "temperature": 0,
        "text": " Giphy API. Let's look at JSON2. Oh, look at this. I just have this extra nonsense here.",
        "tokens": [
          50412,
          460,
          647,
          3495,
          9362,
          13,
          961,
          311,
          574,
          412,
          31828,
          17,
          13,
          876,
          11,
          574,
          412,
          341,
          13,
          286,
          445,
          362,
          341,
          2857,
          14925,
          510,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.20995006045779666,
        "compression_ratio": 1.3544973544973544,
        "end": 3453.76,
        "id": 479,
        "no_speech_prob": 0.00045831248280592263,
        "seek": 343080,
        "start": 3445.76,
        "temperature": 0,
        "text": " I had that in there by accident. When I was re-copy pasting things, I made a mistake.",
        "tokens": [
          51112,
          286,
          632,
          300,
          294,
          456,
          538,
          6398,
          13,
          1133,
          286,
          390,
          319,
          12,
          13084,
          88,
          1791,
          278,
          721,
          11,
          286,
          1027,
          257,
          6146,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.20995006045779666,
        "compression_ratio": 1.3544973544973544,
        "end": 3457.76,
        "id": 480,
        "no_speech_prob": 0.00045831248280592263,
        "seek": 343080,
        "start": 3453.76,
        "temperature": 0,
        "text": " So hopefully that little debugging helped you sort of see what to figure out here.",
        "tokens": [
          51512,
          407,
          4696,
          300,
          707,
          45592,
          4254,
          291,
          1333,
          295,
          536,
          437,
          281,
          2573,
          484,
          510,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.2554146566508729,
        "compression_ratio": 1.5549738219895288,
        "end": 3464.7200000000003,
        "id": 481,
        "no_speech_prob": 0.0018386628944426775,
        "seek": 345776,
        "start": 3458.7200000000003,
        "temperature": 0,
        "text": " It's nice, though, that this is so much easier to debug than if I had all that then stuff and all the functions",
        "tokens": [
          50412,
          467,
          311,
          1481,
          11,
          1673,
          11,
          300,
          341,
          307,
          370,
          709,
          3571,
          281,
          24083,
          813,
          498,
          286,
          632,
          439,
          300,
          550,
          1507,
          293,
          439,
          264,
          6828,
          50712
        ]
      },
      {
        "avg_logprob": -0.2554146566508729,
        "compression_ratio": 1.5549738219895288,
        "end": 3468.7200000000003,
        "id": 482,
        "no_speech_prob": 0.0018386628944426775,
        "seek": 345776,
        "start": 3464.7200000000003,
        "temperature": 0,
        "text": " in its inner, like anonymous function stuff. I can just really debug this much more easily now.",
        "tokens": [
          50712,
          294,
          1080,
          7284,
          11,
          411,
          24932,
          2445,
          1507,
          13,
          286,
          393,
          445,
          534,
          24083,
          341,
          709,
          544,
          3612,
          586,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.2554146566508729,
        "compression_ratio": 1.5549738219895288,
        "end": 3478.7200000000003,
        "id": 483,
        "no_speech_prob": 0.0018386628944426775,
        "seek": 345776,
        "start": 3468.7200000000003,
        "temperature": 0,
        "text": " All right. Let's try this again. There we go. So we haven't gotten a GIF yet. So why not?",
        "tokens": [
          50912,
          1057,
          558,
          13,
          961,
          311,
          853,
          341,
          797,
          13,
          821,
          321,
          352,
          13,
          407,
          321,
          2378,
          380,
          5768,
          257,
          460,
          12775,
          1939,
          13,
          407,
          983,
          406,
          30,
          51412
        ]
      },
      {
        "avg_logprob": -0.3351292774595063,
        "compression_ratio": 1.1756756756756757,
        "end": 3501.68,
        "id": 484,
        "no_speech_prob": 0.12420830875635147,
        "seek": 347872,
        "start": 3478.72,
        "temperature": 0,
        "text": " Let's look at this now. All right. Data index zero. Images. So data index zero. Images.",
        "tokens": [
          50364,
          961,
          311,
          574,
          412,
          341,
          586,
          13,
          1057,
          558,
          13,
          11888,
          8186,
          4018,
          13,
          4331,
          1660,
          13,
          407,
          1412,
          8186,
          4018,
          13,
          4331,
          1660,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.2485189250871247,
        "compression_ratio": 1.5847457627118644,
        "end": 3512.64,
        "id": 485,
        "no_speech_prob": 0.49993258714675903,
        "seek": 350168,
        "start": 3502.64,
        "temperature": 0,
        "text": " Why is that? Oh, I just called it image. Another mistake. I'm going to get this eventually.",
        "tokens": [
          50412,
          1545,
          307,
          300,
          30,
          876,
          11,
          286,
          445,
          1219,
          309,
          3256,
          13,
          3996,
          6146,
          13,
          286,
          478,
          516,
          281,
          483,
          341,
          4728,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.2485189250871247,
        "compression_ratio": 1.5847457627118644,
        "end": 3518.64,
        "id": 486,
        "no_speech_prob": 0.49993258714675903,
        "seek": 350168,
        "start": 3512.64,
        "temperature": 0,
        "text": " Results.image. So many little tiny errors because of all my naming weirdness.",
        "tokens": [
          50912,
          5015,
          33361,
          13,
          26624,
          13,
          407,
          867,
          707,
          5870,
          13603,
          570,
          295,
          439,
          452,
          25290,
          3657,
          1287,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.2485189250871247,
        "compression_ratio": 1.5847457627118644,
        "end": 3524.64,
        "id": 487,
        "no_speech_prob": 0.49993258714675903,
        "seek": 350168,
        "start": 3518.64,
        "temperature": 0,
        "text": " Here we go. Ready? So I called it this variable's image URL, and that's what goes into the image property",
        "tokens": [
          51212,
          1692,
          321,
          352,
          13,
          9944,
          30,
          407,
          286,
          1219,
          309,
          341,
          7006,
          311,
          3256,
          12905,
          11,
          293,
          300,
          311,
          437,
          1709,
          666,
          264,
          3256,
          4707,
          51512
        ]
      },
      {
        "avg_logprob": -0.2485189250871247,
        "compression_ratio": 1.5847457627118644,
        "end": 3528.64,
        "id": 488,
        "no_speech_prob": 0.49993258714675903,
        "seek": 350168,
        "start": 3524.64,
        "temperature": 0,
        "text": " of the object I'm returning. So that's the property I need to get out here. All right. Here we go.",
        "tokens": [
          51512,
          295,
          264,
          2657,
          286,
          478,
          12678,
          13,
          407,
          300,
          311,
          264,
          4707,
          286,
          643,
          281,
          483,
          484,
          510,
          13,
          1057,
          558,
          13,
          1692,
          321,
          352,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.25919540723164874,
        "compression_ratio": 1.4245810055865922,
        "end": 3533.6,
        "id": 489,
        "no_speech_prob": 0.00037409435026347637,
        "seek": 352864,
        "start": 3529.6,
        "temperature": 0,
        "text": " Feeling pretty good about this. Let me hit refresh.",
        "tokens": [
          50412,
          29945,
          1238,
          665,
          466,
          341,
          13,
          961,
          385,
          2045,
          15134,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.25919540723164874,
        "compression_ratio": 1.4245810055865922,
        "end": 3545.6,
        "id": 490,
        "no_speech_prob": 0.00037409435026347637,
        "seek": 352864,
        "start": 3538.64,
        "temperature": 0,
        "text": " All right. We did it, everybody. So this was now an example of writing a function called word GIF,",
        "tokens": [
          50864,
          1057,
          558,
          13,
          492,
          630,
          309,
          11,
          2201,
          13,
          407,
          341,
          390,
          586,
          364,
          1365,
          295,
          3579,
          257,
          2445,
          1219,
          1349,
          460,
          12775,
          11,
          51212
        ]
      },
      {
        "avg_logprob": -0.25919540723164874,
        "compression_ratio": 1.4245810055865922,
        "end": 3553.6,
        "id": 491,
        "no_speech_prob": 0.00037409435026347637,
        "seek": 352864,
        "start": 3545.6,
        "temperature": 0,
        "text": " and what that function does is it asynchronously steps through all of these different asynchronous calls",
        "tokens": [
          51212,
          293,
          437,
          300,
          2445,
          775,
          307,
          309,
          42642,
          5098,
          4439,
          807,
          439,
          295,
          613,
          819,
          49174,
          5498,
          51612
        ]
      },
      {
        "avg_logprob": -0.19857750516949277,
        "compression_ratio": 1.7262773722627738,
        "end": 3558.56,
        "id": 492,
        "no_speech_prob": 0.045351892709732056,
        "seek": 355360,
        "start": 3553.6,
        "temperature": 0,
        "text": " one at a time using the await keyword so that I can sequence them, and when it's done,",
        "tokens": [
          50364,
          472,
          412,
          257,
          565,
          1228,
          264,
          19670,
          20428,
          370,
          300,
          286,
          393,
          8310,
          552,
          11,
          293,
          562,
          309,
          311,
          1096,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.19857750516949277,
        "compression_ratio": 1.7262773722627738,
        "end": 3562.56,
        "id": 493,
        "no_speech_prob": 0.045351892709732056,
        "seek": 355360,
        "start": 3558.56,
        "temperature": 0,
        "text": " I have the data that I want, and I can send it back. If I'm going to write a...",
        "tokens": [
          50612,
          286,
          362,
          264,
          1412,
          300,
          286,
          528,
          11,
          293,
          286,
          393,
          2845,
          309,
          646,
          13,
          759,
          286,
          478,
          516,
          281,
          2464,
          257,
          485,
          50812
        ]
      },
      {
        "avg_logprob": -0.19857750516949277,
        "compression_ratio": 1.7262773722627738,
        "end": 3568.56,
        "id": 494,
        "no_speech_prob": 0.045351892709732056,
        "seek": 355360,
        "start": 3562.56,
        "temperature": 0,
        "text": " I can't just put await anywhere in my code. I can't just suddenly put await in setup, for example,",
        "tokens": [
          50812,
          286,
          393,
          380,
          445,
          829,
          19670,
          4992,
          294,
          452,
          3089,
          13,
          286,
          393,
          380,
          445,
          5800,
          829,
          19670,
          294,
          8657,
          11,
          337,
          1365,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.19857750516949277,
        "compression_ratio": 1.7262773722627738,
        "end": 3572.56,
        "id": 495,
        "no_speech_prob": 0.045351892709732056,
        "seek": 355360,
        "start": 3568.56,
        "temperature": 0,
        "text": " in p5 because I can't make setup an asynchronous function. If I put await, I've got to modify that function",
        "tokens": [
          51112,
          294,
          280,
          20,
          570,
          286,
          393,
          380,
          652,
          8657,
          364,
          49174,
          2445,
          13,
          759,
          286,
          829,
          19670,
          11,
          286,
          600,
          658,
          281,
          16927,
          300,
          2445,
          51312
        ]
      },
      {
        "avg_logprob": -0.19857750516949277,
        "compression_ratio": 1.7262773722627738,
        "end": 3580.56,
        "id": 496,
        "no_speech_prob": 0.045351892709732056,
        "seek": 355360,
        "start": 3572.56,
        "temperature": 0,
        "text": " to make it async. Okay. So what's left? This is... dare I say that this is maybe a useful tutorial?",
        "tokens": [
          51312,
          281,
          652,
          309,
          382,
          34015,
          13,
          1033,
          13,
          407,
          437,
          311,
          1411,
          30,
          639,
          307,
          485,
          8955,
          286,
          584,
          300,
          341,
          307,
          1310,
          257,
          4420,
          7073,
          30,
          51712
        ]
      },
      {
        "avg_logprob": -0.16469091839260525,
        "compression_ratio": 1.6814159292035398,
        "end": 3589.52,
        "id": 497,
        "no_speech_prob": 0.0008426353451795876,
        "seek": 358056,
        "start": 3581.52,
        "temperature": 0,
        "text": " I don't know. You tell me. But what's left is I'm now going to show you what if I want to have",
        "tokens": [
          50412,
          286,
          500,
          380,
          458,
          13,
          509,
          980,
          385,
          13,
          583,
          437,
          311,
          1411,
          307,
          286,
          478,
          586,
          516,
          281,
          855,
          291,
          437,
          498,
          286,
          528,
          281,
          362,
          50812
        ]
      },
      {
        "avg_logprob": -0.16469091839260525,
        "compression_ratio": 1.6814159292035398,
        "end": 3595.52,
        "id": 498,
        "no_speech_prob": 0.0008426353451795876,
        "seek": 358056,
        "start": 3589.52,
        "temperature": 0,
        "text": " 10 words and get all 10 words and GIFs all together, and I want to have something happen",
        "tokens": [
          50812,
          1266,
          2283,
          293,
          483,
          439,
          1266,
          2283,
          293,
          460,
          12775,
          82,
          439,
          1214,
          11,
          293,
          286,
          528,
          281,
          362,
          746,
          1051,
          51112
        ]
      },
      {
        "avg_logprob": -0.16469091839260525,
        "compression_ratio": 1.6814159292035398,
        "end": 3601.52,
        "id": 499,
        "no_speech_prob": 0.0008426353451795876,
        "seek": 358056,
        "start": 3595.52,
        "temperature": 0,
        "text": " when they're all done. That's what I'm going to need promise.all for, and that will be in the next video,",
        "tokens": [
          51112,
          562,
          436,
          434,
          439,
          1096,
          13,
          663,
          311,
          437,
          286,
          478,
          516,
          281,
          643,
          6228,
          13,
          336,
          337,
          11,
          293,
          300,
          486,
          312,
          294,
          264,
          958,
          960,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.16469091839260525,
        "compression_ratio": 1.6814159292035398,
        "end": 3607.52,
        "id": 500,
        "no_speech_prob": 0.0008426353451795876,
        "seek": 358056,
        "start": 3601.52,
        "temperature": 0,
        "text": " and that's the last one of this series on promises and async and await. All right. Thanks.",
        "tokens": [
          51412,
          293,
          300,
          311,
          264,
          1036,
          472,
          295,
          341,
          2638,
          322,
          16403,
          293,
          382,
          34015,
          293,
          19670,
          13,
          1057,
          558,
          13,
          2561,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.2923099994659424,
        "compression_ratio": 1.3055555555555556,
        "end": 3622.48,
        "id": 501,
        "no_speech_prob": 0.020645415410399437,
        "seek": 360752,
        "start": 3607.52,
        "temperature": 0,
        "text": " I'm like a chef. Okay. Can't you use ES6 enhanced object literal syntax there? Probably.",
        "tokens": [
          50364,
          286,
          478,
          411,
          257,
          10530,
          13,
          1033,
          13,
          1664,
          380,
          291,
          764,
          12564,
          21,
          21191,
          2657,
          20411,
          28431,
          456,
          30,
          9210,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.2923099994659424,
        "compression_ratio": 1.3055555555555556,
        "end": 3635.36,
        "id": 502,
        "no_speech_prob": 0.020645415410399437,
        "seek": 360752,
        "start": 3627.52,
        "temperature": 0,
        "text": " I could just do... yes. I absolutely could do the createP and the createImage stuff inside of here.",
        "tokens": [
          51364,
          286,
          727,
          445,
          360,
          485,
          2086,
          13,
          286,
          3122,
          727,
          360,
          264,
          1884,
          47,
          293,
          264,
          1884,
          31128,
          609,
          1507,
          1854,
          295,
          510,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.236474609375,
        "compression_ratio": 1.6273584905660377,
        "end": 3641.28,
        "id": 503,
        "no_speech_prob": 0.0019570044241845608,
        "seek": 363536,
        "start": 3635.36,
        "temperature": 0,
        "text": " I just don't really want to. I want that to be like a thing that's handled elsewhere just for",
        "tokens": [
          50364,
          286,
          445,
          500,
          380,
          534,
          528,
          281,
          13,
          286,
          528,
          300,
          281,
          312,
          411,
          257,
          551,
          300,
          311,
          18033,
          14517,
          445,
          337,
          50660
        ]
      },
      {
        "avg_logprob": -0.236474609375,
        "compression_ratio": 1.6273584905660377,
        "end": 3646.88,
        "id": 504,
        "no_speech_prob": 0.0019570044241845608,
        "seek": 363536,
        "start": 3641.92,
        "temperature": 0,
        "text": " kind of sanity's sake. I want this function just to be about retrieving the data and not using the",
        "tokens": [
          50692,
          733,
          295,
          47892,
          311,
          9717,
          13,
          286,
          528,
          341,
          2445,
          445,
          281,
          312,
          466,
          19817,
          798,
          264,
          1412,
          293,
          406,
          1228,
          264,
          50940
        ]
      },
      {
        "avg_logprob": -0.236474609375,
        "compression_ratio": 1.6273584905660377,
        "end": 3654.1600000000003,
        "id": 505,
        "no_speech_prob": 0.0019570044241845608,
        "seek": 363536,
        "start": 3646.88,
        "temperature": 0,
        "text": " data. But yes, that's absolutely correct. I don't know what an ES6 enhanced object literal syntax is.",
        "tokens": [
          50940,
          1412,
          13,
          583,
          2086,
          11,
          300,
          311,
          3122,
          3006,
          13,
          286,
          500,
          380,
          458,
          437,
          364,
          12564,
          21,
          21191,
          2657,
          20411,
          28431,
          307,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.236474609375,
        "compression_ratio": 1.6273584905660377,
        "end": 3660.2400000000002,
        "id": 506,
        "no_speech_prob": 0.0019570044241845608,
        "seek": 363536,
        "start": 3655.6,
        "temperature": 0,
        "text": " Oh, that's a thing you can do? Yeah. I see. I see.",
        "tokens": [
          51376,
          876,
          11,
          300,
          311,
          257,
          551,
          291,
          393,
          360,
          30,
          865,
          13,
          286,
          536,
          13,
          286,
          536,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.23663371981996478,
        "compression_ratio": 1.3314606741573034,
        "end": 3675.2000000000003,
        "id": 507,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 366536,
        "start": 3666.2400000000002,
        "temperature": 0,
        "text": " Okay. Wow. We actually might get to TensorFlow.js today, because I have until one o'clock,",
        "tokens": [
          50408,
          1033,
          13,
          3153,
          13,
          492,
          767,
          1062,
          483,
          281,
          37624,
          13,
          25530,
          965,
          11,
          570,
          286,
          362,
          1826,
          472,
          277,
          6,
          9023,
          11,
          50856
        ]
      },
      {
        "avg_logprob": -0.23663371981996478,
        "compression_ratio": 1.3314606741573034,
        "end": 3680.32,
        "id": 508,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 366536,
        "start": 3676.7200000000003,
        "temperature": 0,
        "text": " and I don't think promises.all is going to take very long now that I have this already.",
        "tokens": [
          50932,
          293,
          286,
          500,
          380,
          519,
          16403,
          13,
          336,
          307,
          516,
          281,
          747,
          588,
          938,
          586,
          300,
          286,
          362,
          341,
          1217,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.23663371981996478,
        "compression_ratio": 1.3314606741573034,
        "end": 3691.6800000000003,
        "id": 509,
        "no_speech_prob": 0.000007889257176429965,
        "seek": 366536,
        "start": 3686.08,
        "temperature": 0,
        "text": " Let me look up what this is. ES6 enhanced object literals.",
        "tokens": [
          51400,
          961,
          385,
          574,
          493,
          437,
          341,
          307,
          13,
          12564,
          21,
          21191,
          2657,
          2733,
          1124,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.27107022603352865,
        "compression_ratio": 1.3375,
        "end": 3705.84,
        "id": 510,
        "no_speech_prob": 0.0006666944245807827,
        "seek": 369536,
        "start": 3695.84,
        "temperature": 0,
        "text": " ES5. Oh, you could just do that. That's really interesting. I did not know that.",
        "tokens": [
          50388,
          12564,
          20,
          13,
          876,
          11,
          291,
          727,
          445,
          360,
          300,
          13,
          663,
          311,
          534,
          1880,
          13,
          286,
          630,
          406,
          458,
          300,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.27107022603352865,
        "compression_ratio": 1.3375,
        "end": 3714,
        "id": 511,
        "no_speech_prob": 0.0006666944245807827,
        "seek": 369536,
        "start": 3709.76,
        "temperature": 0,
        "text": " Okay. Good to know. Maybe I'll mention that.",
        "tokens": [
          51084,
          1033,
          13,
          2205,
          281,
          458,
          13,
          2704,
          286,
          603,
          2152,
          300,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.27107022603352865,
        "compression_ratio": 1.3375,
        "end": 3722.8,
        "id": 512,
        "no_speech_prob": 0.0006666944245807827,
        "seek": 369536,
        "start": 3718.4,
        "temperature": 0,
        "text": " Fractional asks, coding train, you planning to start any open source JS related projects",
        "tokens": [
          51516,
          1526,
          578,
          1966,
          8962,
          11,
          17720,
          3847,
          11,
          291,
          5038,
          281,
          722,
          604,
          1269,
          4009,
          33063,
          4077,
          4455,
          51736
        ]
      },
      {
        "avg_logprob": -0.2780560602115679,
        "compression_ratio": 1.5,
        "end": 3728.48,
        "id": 513,
        "no_speech_prob": 0.0071211764588952065,
        "seek": 372280,
        "start": 3722.8,
        "temperature": 0,
        "text": " that all viewers can join and contribute to? A small app or something. Let me take a minute to",
        "tokens": [
          50364,
          300,
          439,
          8499,
          393,
          3917,
          293,
          10586,
          281,
          30,
          316,
          1359,
          724,
          420,
          746,
          13,
          961,
          385,
          747,
          257,
          3456,
          281,
          50648
        ]
      },
      {
        "avg_logprob": -0.2780560602115679,
        "compression_ratio": 1.5,
        "end": 3736.32,
        "id": 514,
        "no_speech_prob": 0.0071211764588952065,
        "seek": 372280,
        "start": 3728.48,
        "temperature": 0,
        "text": " answer this question before I go to promise.all. I have in the past, and in fact, you can go through,",
        "tokens": [
          50648,
          1867,
          341,
          1168,
          949,
          286,
          352,
          281,
          6228,
          13,
          336,
          13,
          286,
          362,
          294,
          264,
          1791,
          11,
          293,
          294,
          1186,
          11,
          291,
          393,
          352,
          807,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.2780560602115679,
        "compression_ratio": 1.5,
        "end": 3748.0800000000004,
        "id": 515,
        "no_speech_prob": 0.0071211764588952065,
        "seek": 372280,
        "start": 3736.32,
        "temperature": 0,
        "text": " if you go to GitHub.com slash coding train, under I got it. Under repositories, you can actually see",
        "tokens": [
          51040,
          498,
          291,
          352,
          281,
          23331,
          13,
          1112,
          17330,
          17720,
          3847,
          11,
          833,
          286,
          658,
          309,
          13,
          6974,
          22283,
          2083,
          11,
          291,
          393,
          767,
          536,
          51628
        ]
      },
      {
        "avg_logprob": -0.22810465390564966,
        "compression_ratio": 1.6982456140350877,
        "end": 3752.4,
        "id": 516,
        "no_speech_prob": 0.007460163440555334,
        "seek": 374808,
        "start": 3748.08,
        "temperature": 0,
        "text": " there are a lot of repositories, and all of these are open source projects that people can contribute",
        "tokens": [
          50364,
          456,
          366,
          257,
          688,
          295,
          22283,
          2083,
          11,
          293,
          439,
          295,
          613,
          366,
          1269,
          4009,
          4455,
          300,
          561,
          393,
          10586,
          50580
        ]
      },
      {
        "avg_logprob": -0.22810465390564966,
        "compression_ratio": 1.6982456140350877,
        "end": 3757.2799999999997,
        "id": 517,
        "no_speech_prob": 0.007460163440555334,
        "seek": 374808,
        "start": 3752.4,
        "temperature": 0,
        "text": " to. This was one that was done officially for processing community day. As far as I know,",
        "tokens": [
          50580,
          281,
          13,
          639,
          390,
          472,
          300,
          390,
          1096,
          12053,
          337,
          9007,
          1768,
          786,
          13,
          1018,
          1400,
          382,
          286,
          458,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.22810465390564966,
        "compression_ratio": 1.6982456140350877,
        "end": 3762.48,
        "id": 518,
        "no_speech_prob": 0.007460163440555334,
        "seek": 374808,
        "start": 3757.2799999999997,
        "temperature": 0,
        "text": " there's going to be another processing community day next, I believe, probably next January 2019,",
        "tokens": [
          50824,
          456,
          311,
          516,
          281,
          312,
          1071,
          9007,
          1768,
          786,
          958,
          11,
          286,
          1697,
          11,
          1391,
          958,
          7061,
          6071,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.22810465390564966,
        "compression_ratio": 1.6982456140350877,
        "end": 3767.44,
        "id": 519,
        "no_speech_prob": 0.007460163440555334,
        "seek": 374808,
        "start": 3762.48,
        "temperature": 0,
        "text": " but don't quote me on that. There's the 12 o'clock project, which was a port of John Midas 12 o'clock",
        "tokens": [
          51084,
          457,
          500,
          380,
          6513,
          385,
          322,
          300,
          13,
          821,
          311,
          264,
          2272,
          277,
          6,
          9023,
          1716,
          11,
          597,
          390,
          257,
          2436,
          295,
          2619,
          7033,
          296,
          2272,
          277,
          6,
          9023,
          51332
        ]
      },
      {
        "avg_logprob": -0.22810465390564966,
        "compression_ratio": 1.6982456140350877,
        "end": 3774.16,
        "id": 520,
        "no_speech_prob": 0.007460163440555334,
        "seek": 374808,
        "start": 3767.44,
        "temperature": 0,
        "text": " design. There's an issue that I have, which is that it takes time and work to manage an open",
        "tokens": [
          51332,
          1715,
          13,
          821,
          311,
          364,
          2734,
          300,
          286,
          362,
          11,
          597,
          307,
          300,
          309,
          2516,
          565,
          293,
          589,
          281,
          3067,
          364,
          1269,
          51668
        ]
      },
      {
        "avg_logprob": -0.28338984853213595,
        "compression_ratio": 1.596638655462185,
        "end": 3784.08,
        "id": 521,
        "no_speech_prob": 0.0024723566602915525,
        "seek": 377416,
        "start": 3774.16,
        "temperature": 0,
        "text": " source project, and I have in the past employed people to help manage GitHub repositories. I also",
        "tokens": [
          50364,
          4009,
          1716,
          11,
          293,
          286,
          362,
          294,
          264,
          1791,
          20115,
          561,
          281,
          854,
          3067,
          23331,
          22283,
          2083,
          13,
          286,
          611,
          50860
        ]
      },
      {
        "avg_logprob": -0.28338984853213595,
        "compression_ratio": 1.596638655462185,
        "end": 3790.48,
        "id": 522,
        "no_speech_prob": 0.0024723566602915525,
        "seek": 377416,
        "start": 3784.08,
        "temperature": 0,
        "text": " have had people just volunteer to do it, and there are plenty of volunteers like meiamsome, and",
        "tokens": [
          50860,
          362,
          632,
          561,
          445,
          13835,
          281,
          360,
          309,
          11,
          293,
          456,
          366,
          7140,
          295,
          14352,
          411,
          385,
          2918,
          82,
          423,
          11,
          293,
          51180
        ]
      },
      {
        "avg_logprob": -0.28338984853213595,
        "compression_ratio": 1.596638655462185,
        "end": 3798.24,
        "id": 523,
        "no_speech_prob": 0.0024723566602915525,
        "seek": 377416,
        "start": 3790.48,
        "temperature": 0,
        "text": " neilsweb, and Alka, Ada. I'm mentioning just off the top of my head some contributors from the",
        "tokens": [
          51180,
          408,
          4174,
          826,
          65,
          11,
          293,
          967,
          2330,
          11,
          32276,
          13,
          286,
          478,
          18315,
          445,
          766,
          264,
          1192,
          295,
          452,
          1378,
          512,
          45627,
          490,
          264,
          51568
        ]
      },
      {
        "avg_logprob": -0.28338984853213595,
        "compression_ratio": 1.596638655462185,
        "end": 3803.68,
        "id": 524,
        "no_speech_prob": 0.0024723566602915525,
        "seek": 377416,
        "start": 3798.24,
        "temperature": 0,
        "text": " patron community who have done a lot of work. Website being kind of like a primary one that",
        "tokens": [
          51568,
          21843,
          1768,
          567,
          362,
          1096,
          257,
          688,
          295,
          589,
          13,
          45347,
          642,
          885,
          733,
          295,
          411,
          257,
          6194,
          472,
          300,
          51840
        ]
      },
      {
        "avg_logprob": -0.20992762355481165,
        "compression_ratio": 1.7421875,
        "end": 3807.68,
        "id": 525,
        "no_speech_prob": 0.0008968918700702488,
        "seek": 380368,
        "start": 3803.68,
        "temperature": 0,
        "text": " has a lot of activity. I don't have a good system, but you can see this is what happens.",
        "tokens": [
          50364,
          575,
          257,
          688,
          295,
          5191,
          13,
          286,
          500,
          380,
          362,
          257,
          665,
          1185,
          11,
          457,
          291,
          393,
          536,
          341,
          307,
          437,
          2314,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20992762355481165,
        "compression_ratio": 1.7421875,
        "end": 3814.64,
        "id": 526,
        "no_speech_prob": 0.0008968918700702488,
        "seek": 380368,
        "start": 3808.3999999999996,
        "temperature": 0,
        "text": " I have this GitHub tutorial on GitHub, and I think a rainbow poem.",
        "tokens": [
          50600,
          286,
          362,
          341,
          23331,
          7073,
          322,
          23331,
          11,
          293,
          286,
          519,
          257,
          18526,
          13065,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.20992762355481165,
        "compression_ratio": 1.7421875,
        "end": 3822.3199999999997,
        "id": 527,
        "no_speech_prob": 0.0008968918700702488,
        "seek": 380368,
        "start": 3816.96,
        "temperature": 0,
        "text": " This has 313 open pull requests, because it's a video tutorial about how to make a pull request,",
        "tokens": [
          51028,
          639,
          575,
          805,
          7668,
          1269,
          2235,
          12475,
          11,
          570,
          309,
          311,
          257,
          960,
          7073,
          466,
          577,
          281,
          652,
          257,
          2235,
          5308,
          11,
          51296
        ]
      },
      {
        "avg_logprob": -0.20992762355481165,
        "compression_ratio": 1.7421875,
        "end": 3827.2799999999997,
        "id": 528,
        "no_speech_prob": 0.0008968918700702488,
        "seek": 380368,
        "start": 3822.3199999999997,
        "temperature": 0,
        "text": " and then I ask people to make the pull request, and then, you know, for a while, I was merging",
        "tokens": [
          51296,
          293,
          550,
          286,
          1029,
          561,
          281,
          652,
          264,
          2235,
          5308,
          11,
          293,
          550,
          11,
          291,
          458,
          11,
          337,
          257,
          1339,
          11,
          286,
          390,
          44559,
          51544
        ]
      },
      {
        "avg_logprob": -0.20992762355481165,
        "compression_ratio": 1.7421875,
        "end": 3831.52,
        "id": 529,
        "no_speech_prob": 0.0008968918700702488,
        "seek": 380368,
        "start": 3827.2799999999997,
        "temperature": 0,
        "text": " them and checking them every day, and then I like I think actually I was doing this all the way up",
        "tokens": [
          51544,
          552,
          293,
          8568,
          552,
          633,
          786,
          11,
          293,
          550,
          286,
          411,
          286,
          519,
          767,
          286,
          390,
          884,
          341,
          439,
          264,
          636,
          493,
          51756
        ]
      },
      {
        "avg_logprob": -0.26152597315171183,
        "compression_ratio": 1.5384615384615385,
        "end": 3836.48,
        "id": 530,
        "no_speech_prob": 0.0015729267615824938,
        "seek": 383152,
        "start": 3831.52,
        "temperature": 0,
        "text": " to last summer when I broke my elbow. This might have happened way before last summer, but I didn't",
        "tokens": [
          50364,
          281,
          1036,
          4266,
          562,
          286,
          6902,
          452,
          18507,
          13,
          639,
          1062,
          362,
          2011,
          636,
          949,
          1036,
          4266,
          11,
          457,
          286,
          994,
          380,
          50612
        ]
      },
      {
        "avg_logprob": -0.26152597315171183,
        "compression_ratio": 1.5384615384615385,
        "end": 3842.72,
        "id": 531,
        "no_speech_prob": 0.0015729267615824938,
        "seek": 383152,
        "start": 3836.48,
        "temperature": 0,
        "text": " do it for a few weeks, and then once I came back to it, I was like, I can't. I can't. It's too much.",
        "tokens": [
          50612,
          360,
          309,
          337,
          257,
          1326,
          3259,
          11,
          293,
          550,
          1564,
          286,
          1361,
          646,
          281,
          309,
          11,
          286,
          390,
          411,
          11,
          286,
          393,
          380,
          13,
          286,
          393,
          380,
          13,
          467,
          311,
          886,
          709,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.26152597315171183,
        "compression_ratio": 1.5384615384615385,
        "end": 3856.56,
        "id": 532,
        "no_speech_prob": 0.0015729267615824938,
        "seek": 383152,
        "start": 3843.36,
        "temperature": 0,
        "text": " So I need a way to vet people to enforce the code of conduct, and volunteer to manage some of these",
        "tokens": [
          50956,
          407,
          286,
          643,
          257,
          636,
          281,
          12423,
          561,
          281,
          24825,
          264,
          3089,
          295,
          6018,
          11,
          293,
          13835,
          281,
          3067,
          512,
          295,
          613,
          51616
        ]
      },
      {
        "avg_logprob": -0.2896741154682205,
        "compression_ratio": 1.6323529411764706,
        "end": 3862.16,
        "id": 533,
        "no_speech_prob": 0.020963581278920174,
        "seek": 385656,
        "start": 3856.56,
        "temperature": 0,
        "text": " repos. So anyway, that's my example. Slightly bad example. As none of the code subsequent to each",
        "tokens": [
          50364,
          1085,
          329,
          13,
          407,
          4033,
          11,
          300,
          311,
          452,
          1365,
          13,
          318,
          44872,
          1578,
          1365,
          13,
          1018,
          6022,
          295,
          264,
          3089,
          19962,
          281,
          1184,
          50644
        ]
      },
      {
        "avg_logprob": -0.2896741154682205,
        "compression_ratio": 1.6323529411764706,
        "end": 3866.48,
        "id": 534,
        "no_speech_prob": 0.020963581278920174,
        "seek": 385656,
        "start": 3862.16,
        "temperature": 0,
        "text": " await runs async, because each relies on the result of the previous await, so execution is",
        "tokens": [
          50644,
          19670,
          6676,
          382,
          34015,
          11,
          570,
          1184,
          30910,
          322,
          264,
          1874,
          295,
          264,
          3894,
          19670,
          11,
          370,
          15058,
          307,
          50860
        ]
      },
      {
        "avg_logprob": -0.2896741154682205,
        "compression_ratio": 1.6323529411764706,
        "end": 3871.2,
        "id": 535,
        "no_speech_prob": 0.020963581278920174,
        "seek": 385656,
        "start": 3866.48,
        "temperature": 0,
        "text": " still held up until the results arrive, writes David Smith. That's interesting.",
        "tokens": [
          50860,
          920,
          5167,
          493,
          1826,
          264,
          3542,
          8881,
          11,
          13657,
          4389,
          8538,
          13,
          663,
          311,
          1880,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.2896741154682205,
        "compression_ratio": 1.6323529411764706,
        "end": 3878.48,
        "id": 536,
        "no_speech_prob": 0.020963581278920174,
        "seek": 385656,
        "start": 3874.96,
        "temperature": 0,
        "text": " So, David Smith, are you saying that my example is slightly bad?",
        "tokens": [
          51284,
          407,
          11,
          4389,
          8538,
          11,
          366,
          291,
          1566,
          300,
          452,
          1365,
          307,
          4748,
          1578,
          30,
          51460
        ]
      },
      {
        "avg_logprob": -0.44717233831232245,
        "compression_ratio": 1.4216867469879517,
        "end": 3894.72,
        "id": 537,
        "no_speech_prob": 0.0009399272967129946,
        "seek": 388656,
        "start": 3886.72,
        "temperature": 0,
        "text": " So, I, oh, and Meredith, sorry, if you're in the Slack channel, I forgot your name.",
        "tokens": [
          50372,
          407,
          11,
          286,
          11,
          1954,
          11,
          293,
          6124,
          292,
          355,
          11,
          2597,
          11,
          498,
          291,
          434,
          294,
          264,
          37211,
          2269,
          11,
          286,
          5298,
          428,
          1315,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.44717233831232245,
        "compression_ratio": 1.4216867469879517,
        "end": 3898.72,
        "id": 538,
        "no_speech_prob": 0.0009399272967129946,
        "seek": 388656,
        "start": 3894.72,
        "temperature": 0,
        "text": " It's only because I'm afraid of mispronouncing it.",
        "tokens": [
          50772,
          467,
          311,
          787,
          570,
          286,
          478,
          4638,
          295,
          3346,
          1424,
          266,
          1733,
          2175,
          309,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.44717233831232245,
        "compression_ratio": 1.4216867469879517,
        "end": 3909.92,
        "id": 539,
        "no_speech_prob": 0.0009399272967129946,
        "seek": 388656,
        "start": 3904.72,
        "temperature": 0,
        "text": " Yes, I certainly could in the same way. I mean, one thing, I don't want to go off too off topic here,",
        "tokens": [
          51272,
          1079,
          11,
          286,
          3297,
          727,
          294,
          264,
          912,
          636,
          13,
          286,
          914,
          11,
          472,
          551,
          11,
          286,
          500,
          380,
          528,
          281,
          352,
          766,
          886,
          766,
          4829,
          510,
          11,
          51532
        ]
      },
      {
        "avg_logprob": -0.42334582707653307,
        "compression_ratio": 1.4635416666666667,
        "end": 3917.12,
        "id": 540,
        "no_speech_prob": 0.0055545116774737835,
        "seek": 390992,
        "start": 3910.88,
        "temperature": 0,
        "text": " but I'm not opposed to, you know, sending out stickers to people who help contribute a certain",
        "tokens": [
          50412,
          457,
          286,
          478,
          406,
          8851,
          281,
          11,
          291,
          458,
          11,
          7750,
          484,
          21019,
          281,
          561,
          567,
          854,
          10586,
          257,
          1629,
          50724
        ]
      },
      {
        "avg_logprob": -0.42334582707653307,
        "compression_ratio": 1.4635416666666667,
        "end": 3923.12,
        "id": 541,
        "no_speech_prob": 0.0055545116774737835,
        "seek": 390992,
        "start": 3917.12,
        "temperature": 0,
        "text": " amount, or even, you know, membership to the sponsor group or whatever as well. But, okay.",
        "tokens": [
          50724,
          2372,
          11,
          420,
          754,
          11,
          291,
          458,
          11,
          16560,
          281,
          264,
          16198,
          1594,
          420,
          2035,
          382,
          731,
          13,
          583,
          11,
          1392,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.42334582707653307,
        "compression_ratio": 1.4635416666666667,
        "end": 3934.7200000000003,
        "id": 542,
        "no_speech_prob": 0.0055545116774737835,
        "seek": 390992,
        "start": 3927.92,
        "temperature": 0,
        "text": " You should do something that can run while the request is running. Oh, yes. Right. So, the idea",
        "tokens": [
          51264,
          509,
          820,
          360,
          746,
          300,
          393,
          1190,
          1339,
          264,
          5308,
          307,
          2614,
          13,
          876,
          11,
          2086,
          13,
          1779,
          13,
          407,
          11,
          264,
          1558,
          51604
        ]
      },
      {
        "avg_logprob": -0.31552650814964656,
        "compression_ratio": 1.7824074074074074,
        "end": 3941.52,
        "id": 543,
        "no_speech_prob": 0.001032206229865551,
        "seek": 393472,
        "start": 3935.52,
        "temperature": 0,
        "text": " here is that what I could do is, you know, I could show like a loading screen that then finishes",
        "tokens": [
          50404,
          510,
          307,
          300,
          437,
          286,
          727,
          360,
          307,
          11,
          291,
          458,
          11,
          286,
          727,
          855,
          411,
          257,
          15114,
          2568,
          300,
          550,
          23615,
          50704
        ]
      },
      {
        "avg_logprob": -0.31552650814964656,
        "compression_ratio": 1.7824074074074074,
        "end": 3947.9199999999996,
        "id": 544,
        "no_speech_prob": 0.001032206229865551,
        "seek": 393472,
        "start": 3941.52,
        "temperature": 0,
        "text": " once it's done. So, like, I don't know that I need to do this, but like, like, maybe what David",
        "tokens": [
          50704,
          1564,
          309,
          311,
          1096,
          13,
          407,
          11,
          411,
          11,
          286,
          500,
          380,
          458,
          300,
          286,
          643,
          281,
          360,
          341,
          11,
          457,
          411,
          11,
          411,
          11,
          1310,
          437,
          4389,
          51024
        ]
      },
      {
        "avg_logprob": -0.31552650814964656,
        "compression_ratio": 1.7824074074074074,
        "end": 3954.3199999999997,
        "id": 545,
        "no_speech_prob": 0.001032206229865551,
        "seek": 393472,
        "start": 3947.9199999999996,
        "temperature": 0,
        "text": " Smith is suggesting, if I say like loading is true, and then if I actually had a draw loop, if",
        "tokens": [
          51024,
          8538,
          307,
          18094,
          11,
          498,
          286,
          584,
          411,
          15114,
          307,
          2074,
          11,
          293,
          550,
          498,
          286,
          767,
          632,
          257,
          2642,
          6367,
          11,
          498,
          51344
        ]
      },
      {
        "avg_logprob": -0.31552650814964656,
        "compression_ratio": 1.7824074074074074,
        "end": 3960.3199999999997,
        "id": 546,
        "no_speech_prob": 0.001032206229865551,
        "seek": 393472,
        "start": 3954.3199999999997,
        "temperature": 0,
        "text": " loading, I would like draw a loading bar, and then I would set loading equal false here, and then",
        "tokens": [
          51344,
          15114,
          11,
          286,
          576,
          411,
          2642,
          257,
          15114,
          2159,
          11,
          293,
          550,
          286,
          576,
          992,
          15114,
          2681,
          7908,
          510,
          11,
          293,
          550,
          51644
        ]
      },
      {
        "avg_logprob": -0.45573972619098163,
        "compression_ratio": 1.2677165354330708,
        "end": 3967.28,
        "id": 547,
        "no_speech_prob": 0.0002653014671523124,
        "seek": 396032,
        "start": 3960.56,
        "temperature": 0,
        "text": " I would show something else once it's loaded. Okay. So, but points taken that I didn't go the",
        "tokens": [
          50376,
          286,
          576,
          855,
          746,
          1646,
          1564,
          309,
          311,
          13210,
          13,
          1033,
          13,
          407,
          11,
          457,
          2793,
          2726,
          300,
          286,
          994,
          380,
          352,
          264,
          50712
        ]
      },
      {
        "avg_logprob": -0.45573972619098163,
        "compression_ratio": 1.2677165354330708,
        "end": 3979.52,
        "id": 548,
        "no_speech_prob": 0.0002653014671523124,
        "seek": 396032,
        "start": 3967.28,
        "temperature": 0,
        "text": " next step. Maybe I'll mention that as an exercise. Okay. All right.",
        "tokens": [
          50712,
          958,
          1823,
          13,
          2704,
          286,
          603,
          2152,
          300,
          382,
          364,
          5380,
          13,
          1033,
          13,
          1057,
          558,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.6394441877092634,
        "compression_ratio": 1.1978021978021978,
        "end": 3982.72,
        "id": 549,
        "no_speech_prob": 0.0022871862165629864,
        "seek": 397952,
        "start": 3979.68,
        "temperature": 0,
        "text": " Let's do promise.all.",
        "tokens": [
          50372,
          961,
          311,
          360,
          6228,
          13,
          336,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.6394441877092634,
        "compression_ratio": 1.1978021978021978,
        "end": 4001.52,
        "id": 550,
        "no_speech_prob": 0.0022871862165629864,
        "seek": 397952,
        "start": 3995.52,
        "temperature": 0,
        "text": " All right. And then I could do a loading bar with promise.all. That's a little bit more",
        "tokens": [
          51164,
          1057,
          558,
          13,
          400,
          550,
          286,
          727,
          360,
          257,
          15114,
          2159,
          365,
          6228,
          13,
          336,
          13,
          663,
          311,
          257,
          707,
          857,
          544,
          51464
        ]
      },
      {
        "avg_logprob": -0.3610799867812901,
        "compression_ratio": 1.4438202247191012,
        "end": 4009.6,
        "id": 551,
        "no_speech_prob": 0.00018235425523016602,
        "seek": 400152,
        "start": 4002.48,
        "temperature": 0,
        "text": " complicated. All right. And then I could do a loading bar with promise.all. That would",
        "tokens": [
          50412,
          6179,
          13,
          1057,
          558,
          13,
          400,
          550,
          286,
          727,
          360,
          257,
          15114,
          2159,
          365,
          6228,
          13,
          336,
          13,
          663,
          576,
          50768
        ]
      },
      {
        "avg_logprob": -0.3610799867812901,
        "compression_ratio": 1.4438202247191012,
        "end": 4014.72,
        "id": 552,
        "no_speech_prob": 0.00018235425523016602,
        "seek": 400152,
        "start": 4009.6,
        "temperature": 0,
        "text": " actually make sense because I have to do a lot of them. But anyway. Okay.",
        "tokens": [
          50768,
          767,
          652,
          2020,
          570,
          286,
          362,
          281,
          360,
          257,
          688,
          295,
          552,
          13,
          583,
          4033,
          13,
          1033,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.3610799867812901,
        "compression_ratio": 1.4438202247191012,
        "end": 4028.48,
        "id": 553,
        "no_speech_prob": 0.00018235425523016602,
        "seek": 400152,
        "start": 4022.8,
        "temperature": 0,
        "text": " It's a stage before the all makes sense. If you do a way, okay, I got to move off from the chat.",
        "tokens": [
          51428,
          467,
          311,
          257,
          3233,
          949,
          264,
          439,
          1669,
          2020,
          13,
          759,
          291,
          360,
          257,
          636,
          11,
          1392,
          11,
          286,
          658,
          281,
          1286,
          766,
          490,
          264,
          5081,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.23189625269930128,
        "compression_ratio": 1.415,
        "end": 4032.08,
        "id": 554,
        "no_speech_prob": 0.009559355676174164,
        "seek": 402848,
        "start": 4028.48,
        "temperature": 0,
        "text": " I'm very interested, which is kind of the issue. Let me just check to make sure there's no",
        "tokens": [
          50364,
          286,
          478,
          588,
          3102,
          11,
          597,
          307,
          733,
          295,
          264,
          2734,
          13,
          961,
          385,
          445,
          1520,
          281,
          652,
          988,
          456,
          311,
          572,
          50544
        ]
      },
      {
        "avg_logprob": -0.23189625269930128,
        "compression_ratio": 1.415,
        "end": 4039.52,
        "id": 555,
        "no_speech_prob": 0.009559355676174164,
        "seek": 402848,
        "start": 4032.08,
        "temperature": 0,
        "text": " emergencies going on here that I need to respond to. Oh, CodingTrain tweeted, I started a live",
        "tokens": [
          50544,
          43483,
          516,
          322,
          510,
          300,
          286,
          643,
          281,
          4196,
          281,
          13,
          876,
          11,
          383,
          8616,
          51,
          7146,
          25646,
          11,
          286,
          1409,
          257,
          1621,
          50916
        ]
      },
      {
        "avg_logprob": -0.23189625269930128,
        "compression_ratio": 1.415,
        "end": 4051.2,
        "id": 556,
        "no_speech_prob": 0.009559355676174164,
        "seek": 402848,
        "start": 4039.52,
        "temperature": 0,
        "text": " stream on YouTube. Okay. Yeah, that is a good point about sequential asynchronous versus parallel",
        "tokens": [
          50916,
          4309,
          322,
          3088,
          13,
          1033,
          13,
          865,
          11,
          300,
          307,
          257,
          665,
          935,
          466,
          42881,
          49174,
          5717,
          8952,
          51500
        ]
      },
      {
        "avg_logprob": -0.22278337593538217,
        "compression_ratio": 1.4948453608247423,
        "end": 4057.9199999999996,
        "id": 557,
        "no_speech_prob": 0.005220087710767984,
        "seek": 405120,
        "start": 4051.2,
        "temperature": 0,
        "text": " asynchronous. If I wanted to do during, but I'm just, I'm not going to, there's a lot more to",
        "tokens": [
          50364,
          49174,
          13,
          759,
          286,
          1415,
          281,
          360,
          1830,
          11,
          457,
          286,
          478,
          445,
          11,
          286,
          478,
          406,
          516,
          281,
          11,
          456,
          311,
          257,
          688,
          544,
          281,
          50700
        ]
      },
      {
        "avg_logprob": -0.22278337593538217,
        "compression_ratio": 1.4948453608247423,
        "end": 4070.56,
        "id": 558,
        "no_speech_prob": 0.005220087710767984,
        "seek": 405120,
        "start": 4057.9199999999996,
        "temperature": 0,
        "text": " this and I'm trying to stay in a friendly place. All right. All right. Welcome back. This, for the",
        "tokens": [
          50700,
          341,
          293,
          286,
          478,
          1382,
          281,
          1754,
          294,
          257,
          9208,
          1081,
          13,
          1057,
          558,
          13,
          1057,
          558,
          13,
          4027,
          646,
          13,
          639,
          11,
          337,
          264,
          51332
        ]
      },
      {
        "avg_logprob": -0.22278337593538217,
        "compression_ratio": 1.4948453608247423,
        "end": 4080.48,
        "id": 559,
        "no_speech_prob": 0.005220087710767984,
        "seek": 405120,
        "start": 4070.56,
        "temperature": 0,
        "text": " moment, for the time being, is the last video in my series on promises in ES6 and async and await",
        "tokens": [
          51332,
          1623,
          11,
          337,
          264,
          565,
          885,
          11,
          307,
          264,
          1036,
          960,
          294,
          452,
          2638,
          322,
          16403,
          294,
          12564,
          21,
          293,
          382,
          34015,
          293,
          19670,
          51828
        ]
      },
      {
        "avg_logprob": -0.23208907672337123,
        "compression_ratio": 1.697508896797153,
        "end": 4085.76,
        "id": 560,
        "no_speech_prob": 0.0007672883803024888,
        "seek": 408048,
        "start": 4080.48,
        "temperature": 0,
        "text": " in ES8. Now, many people who are watching the live version of this, you might be watching the",
        "tokens": [
          50364,
          294,
          12564,
          23,
          13,
          823,
          11,
          867,
          561,
          567,
          366,
          1976,
          264,
          1621,
          3037,
          295,
          341,
          11,
          291,
          1062,
          312,
          1976,
          264,
          50628
        ]
      },
      {
        "avg_logprob": -0.23208907672337123,
        "compression_ratio": 1.697508896797153,
        "end": 4090.2400000000002,
        "id": 561,
        "no_speech_prob": 0.0007672883803024888,
        "seek": 408048,
        "start": 4085.76,
        "temperature": 0,
        "text": " recorded version, are making lots of excellent comments about things that I'm not demonstrating.",
        "tokens": [
          50628,
          8287,
          3037,
          11,
          366,
          1455,
          3195,
          295,
          7103,
          3053,
          466,
          721,
          300,
          286,
          478,
          406,
          29889,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.23208907672337123,
        "compression_ratio": 1.697508896797153,
        "end": 4095.6,
        "id": 562,
        "no_speech_prob": 0.0007672883803024888,
        "seek": 408048,
        "start": 4090.2400000000002,
        "temperature": 0,
        "text": " For example, what if I want things to happen, like on the interim during various stages of this?",
        "tokens": [
          50852,
          1171,
          1365,
          11,
          437,
          498,
          286,
          528,
          721,
          281,
          1051,
          11,
          411,
          322,
          264,
          33500,
          1830,
          3683,
          10232,
          295,
          341,
          30,
          51120
        ]
      },
      {
        "avg_logprob": -0.23208907672337123,
        "compression_ratio": 1.697508896797153,
        "end": 4100.64,
        "id": 563,
        "no_speech_prob": 0.0007672883803024888,
        "seek": 408048,
        "start": 4095.6,
        "temperature": 0,
        "text": " Or I want to show like a loading bar. I want my asynchronous calls to be happening in parallel",
        "tokens": [
          51120,
          1610,
          286,
          528,
          281,
          855,
          411,
          257,
          15114,
          2159,
          13,
          286,
          528,
          452,
          49174,
          5498,
          281,
          312,
          2737,
          294,
          8952,
          51372
        ]
      },
      {
        "avg_logprob": -0.23208907672337123,
        "compression_ratio": 1.697508896797153,
        "end": 4105.2,
        "id": 564,
        "no_speech_prob": 0.0007672883803024888,
        "seek": 408048,
        "start": 4100.64,
        "temperature": 0,
        "text": " instead of waiting for all of this to be done and then just showing the results. Those are all",
        "tokens": [
          51372,
          2602,
          295,
          3806,
          337,
          439,
          295,
          341,
          281,
          312,
          1096,
          293,
          550,
          445,
          4099,
          264,
          3542,
          13,
          3950,
          366,
          439,
          51600
        ]
      },
      {
        "avg_logprob": -0.1854281667935646,
        "compression_ratio": 1.7208480565371025,
        "end": 4110,
        "id": 565,
        "no_speech_prob": 0.00941229797899723,
        "seek": 410520,
        "start": 4105.2,
        "temperature": 0,
        "text": " really good questions. So I'm trying to stay in sort of a simple place to demonstrate the basic",
        "tokens": [
          50364,
          534,
          665,
          1651,
          13,
          407,
          286,
          478,
          1382,
          281,
          1754,
          294,
          1333,
          295,
          257,
          2199,
          1081,
          281,
          11698,
          264,
          3875,
          50604
        ]
      },
      {
        "avg_logprob": -0.1854281667935646,
        "compression_ratio": 1.7208480565371025,
        "end": 4115.12,
        "id": 566,
        "no_speech_prob": 0.00941229797899723,
        "seek": 410520,
        "start": 4110,
        "temperature": 0,
        "text": " idea, but I would leave some of those as exercises to you and maybe I can come back and continue this",
        "tokens": [
          50604,
          1558,
          11,
          457,
          286,
          576,
          1856,
          512,
          295,
          729,
          382,
          11900,
          281,
          291,
          293,
          1310,
          286,
          393,
          808,
          646,
          293,
          2354,
          341,
          50860
        ]
      },
      {
        "avg_logprob": -0.1854281667935646,
        "compression_ratio": 1.7208480565371025,
        "end": 4118.72,
        "id": 567,
        "no_speech_prob": 0.00941229797899723,
        "seek": 410520,
        "start": 4115.12,
        "temperature": 0,
        "text": " series if there are some key things that I've missed. So please give me your feedback in the",
        "tokens": [
          50860,
          2638,
          498,
          456,
          366,
          512,
          2141,
          721,
          300,
          286,
          600,
          6721,
          13,
          407,
          1767,
          976,
          385,
          428,
          5824,
          294,
          264,
          51040
        ]
      },
      {
        "avg_logprob": -0.1854281667935646,
        "compression_ratio": 1.7208480565371025,
        "end": 4124.5599999999995,
        "id": 568,
        "no_speech_prob": 0.00941229797899723,
        "seek": 410520,
        "start": 4118.72,
        "temperature": 0,
        "text": " comments. But what I want to show in this particular video is what if I want to make multiple calls to",
        "tokens": [
          51040,
          3053,
          13,
          583,
          437,
          286,
          528,
          281,
          855,
          294,
          341,
          1729,
          960,
          307,
          437,
          498,
          286,
          528,
          281,
          652,
          3866,
          5498,
          281,
          51332
        ]
      },
      {
        "avg_logprob": -0.1854281667935646,
        "compression_ratio": 1.7208480565371025,
        "end": 4131.28,
        "id": 569,
        "no_speech_prob": 0.00941229797899723,
        "seek": 410520,
        "start": 4124.5599999999995,
        "temperature": 0,
        "text": " word gif and I want them, I want to be able to retain sort of something about the sequence of",
        "tokens": [
          51332,
          1349,
          290,
          351,
          293,
          286,
          528,
          552,
          11,
          286,
          528,
          281,
          312,
          1075,
          281,
          18340,
          1333,
          295,
          746,
          466,
          264,
          8310,
          295,
          51668
        ]
      },
      {
        "avg_logprob": -0.22247869090030067,
        "compression_ratio": 1.5280898876404494,
        "end": 4137.36,
        "id": 570,
        "no_speech_prob": 0.0017007124843075871,
        "seek": 413128,
        "start": 4131.28,
        "temperature": 0,
        "text": " those calls. So for example, something I absolutely could do is I could just do this twice, right?",
        "tokens": [
          50364,
          729,
          5498,
          13,
          407,
          337,
          1365,
          11,
          746,
          286,
          3122,
          727,
          360,
          307,
          286,
          727,
          445,
          360,
          341,
          6091,
          11,
          558,
          30,
          50668
        ]
      },
      {
        "avg_logprob": -0.22247869090030067,
        "compression_ratio": 1.5280898876404494,
        "end": 4142.4,
        "id": 571,
        "no_speech_prob": 0.0017007124843075871,
        "seek": 413128,
        "start": 4137.36,
        "temperature": 0,
        "text": " And in fact, I can still leave the catch at the end. So I can actually do this.",
        "tokens": [
          50668,
          400,
          294,
          1186,
          11,
          286,
          393,
          920,
          1856,
          264,
          3745,
          412,
          264,
          917,
          13,
          407,
          286,
          393,
          767,
          360,
          341,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.22247869090030067,
        "compression_ratio": 1.5280898876404494,
        "end": 4150.16,
        "id": 572,
        "no_speech_prob": 0.0017007124843075871,
        "seek": 413128,
        "start": 4144.8,
        "temperature": 0,
        "text": " I think, right, because this returns. Oh no, I would have to say, right, this is a little bit",
        "tokens": [
          51040,
          286,
          519,
          11,
          558,
          11,
          570,
          341,
          11247,
          13,
          876,
          572,
          11,
          286,
          576,
          362,
          281,
          584,
          11,
          558,
          11,
          341,
          307,
          257,
          707,
          857,
          51308
        ]
      },
      {
        "avg_logprob": -0.24654146341177133,
        "compression_ratio": 1.6136363636363635,
        "end": 4164,
        "id": 573,
        "no_speech_prob": 0.011331658810377121,
        "seek": 415016,
        "start": 4150.16,
        "temperature": 0,
        "text": " goofy, but I could say return word gif inside of here and then I could say then do another one.",
        "tokens": [
          50364,
          42995,
          11,
          457,
          286,
          727,
          584,
          2736,
          1349,
          290,
          351,
          1854,
          295,
          510,
          293,
          550,
          286,
          727,
          584,
          550,
          360,
          1071,
          472,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.24654146341177133,
        "compression_ratio": 1.6136363636363635,
        "end": 4168.72,
        "id": 574,
        "no_speech_prob": 0.011331658810377121,
        "seek": 415016,
        "start": 4164,
        "temperature": 0,
        "text": " Right, so this is just me doing two. This is a little bit weird and I need to finish off the",
        "tokens": [
          51056,
          1779,
          11,
          370,
          341,
          307,
          445,
          385,
          884,
          732,
          13,
          639,
          307,
          257,
          707,
          857,
          3657,
          293,
          286,
          643,
          281,
          2413,
          766,
          264,
          51292
        ]
      },
      {
        "avg_logprob": -0.24654146341177133,
        "compression_ratio": 1.6136363636363635,
        "end": 4174.8,
        "id": 575,
        "no_speech_prob": 0.011331658810377121,
        "seek": 415016,
        "start": 4168.72,
        "temperature": 0,
        "text": " code here and I need a dot here. So this is the way of chain, this is kind of without the await",
        "tokens": [
          51292,
          3089,
          510,
          293,
          286,
          643,
          257,
          5893,
          510,
          13,
          407,
          341,
          307,
          264,
          636,
          295,
          5021,
          11,
          341,
          307,
          733,
          295,
          1553,
          264,
          19670,
          51596
        ]
      },
      {
        "avg_logprob": -0.2004124378335887,
        "compression_ratio": 1.6820083682008369,
        "end": 4182,
        "id": 576,
        "no_speech_prob": 0.0007437000167556107,
        "seek": 417480,
        "start": 4174.8,
        "temperature": 0,
        "text": " thing. This is the way of chaining promises. So first I call word gif, I show the results, I return",
        "tokens": [
          50364,
          551,
          13,
          639,
          307,
          264,
          636,
          295,
          417,
          3686,
          16403,
          13,
          407,
          700,
          286,
          818,
          1349,
          290,
          351,
          11,
          286,
          855,
          264,
          3542,
          11,
          286,
          2736,
          50724
        ]
      },
      {
        "avg_logprob": -0.2004124378335887,
        "compression_ratio": 1.6820083682008369,
        "end": 4186.96,
        "id": 577,
        "no_speech_prob": 0.0007437000167556107,
        "seek": 417480,
        "start": 4182,
        "temperature": 0,
        "text": " the next call to word gif, which is a new promise, and then I show those results. So let's run this",
        "tokens": [
          50724,
          264,
          958,
          818,
          281,
          1349,
          290,
          351,
          11,
          597,
          307,
          257,
          777,
          6228,
          11,
          293,
          550,
          286,
          855,
          729,
          3542,
          13,
          407,
          718,
          311,
          1190,
          341,
          50972
        ]
      },
      {
        "avg_logprob": -0.2004124378335887,
        "compression_ratio": 1.6820083682008369,
        "end": 4193.52,
        "id": 578,
        "no_speech_prob": 0.0007437000167556107,
        "seek": 417480,
        "start": 4186.96,
        "temperature": 0,
        "text": " and see if we get two. Oops, sorry, I'm in a different place. We see two and they happen one after the",
        "tokens": [
          50972,
          293,
          536,
          498,
          321,
          483,
          732,
          13,
          21726,
          11,
          2597,
          11,
          286,
          478,
          294,
          257,
          819,
          1081,
          13,
          492,
          536,
          732,
          293,
          436,
          1051,
          472,
          934,
          264,
          51300
        ]
      },
      {
        "avg_logprob": -0.2004124378335887,
        "compression_ratio": 1.6820083682008369,
        "end": 4199.76,
        "id": 579,
        "no_speech_prob": 0.0007437000167556107,
        "seek": 417480,
        "start": 4193.52,
        "temperature": 0,
        "text": " other and sometimes I'm going to get an error if there's no gif. Okay, now here's the thing. I want",
        "tokens": [
          51300,
          661,
          293,
          2171,
          286,
          478,
          516,
          281,
          483,
          364,
          6713,
          498,
          456,
          311,
          572,
          290,
          351,
          13,
          1033,
          11,
          586,
          510,
          311,
          264,
          551,
          13,
          286,
          528,
          51612
        ]
      },
      {
        "avg_logprob": -0.19382783716375176,
        "compression_ratio": 1.467153284671533,
        "end": 4207.04,
        "id": 580,
        "no_speech_prob": 0.0002913696225732565,
        "seek": 419976,
        "start": 4199.76,
        "temperature": 0,
        "text": " to change something about the word gif function. I want to make this have an argument num and that's",
        "tokens": [
          50364,
          281,
          1319,
          746,
          466,
          264,
          1349,
          290,
          351,
          2445,
          13,
          286,
          528,
          281,
          652,
          341,
          362,
          364,
          6770,
          1031,
          293,
          300,
          311,
          50728
        ]
      },
      {
        "avg_logprob": -0.19382783716375176,
        "compression_ratio": 1.467153284671533,
        "end": 4218.4800000000005,
        "id": 581,
        "no_speech_prob": 0.0002913696225732565,
        "seek": 419976,
        "start": 4207.04,
        "temperature": 0,
        "text": " going to be the number of, sorry, I'm spacing, the number of letters that I want. So I'm going to go",
        "tokens": [
          50728,
          516,
          281,
          312,
          264,
          1230,
          295,
          11,
          2597,
          11,
          286,
          478,
          27739,
          11,
          264,
          1230,
          295,
          7825,
          300,
          286,
          528,
          13,
          407,
          286,
          478,
          516,
          281,
          352,
          51300
        ]
      },
      {
        "avg_logprob": -0.21763405270046657,
        "compression_ratio": 1.6216216216216217,
        "end": 4231.12,
        "id": 582,
        "no_speech_prob": 0.03358792886137962,
        "seek": 421848,
        "start": 4218.48,
        "temperature": 0,
        "text": " to the Wordnik API and I'm going to take this out and I'm going to say when I'm calling that, I'm going",
        "tokens": [
          50364,
          281,
          264,
          8725,
          13123,
          9362,
          293,
          286,
          478,
          516,
          281,
          747,
          341,
          484,
          293,
          286,
          478,
          516,
          281,
          584,
          562,
          286,
          478,
          5141,
          300,
          11,
          286,
          478,
          516,
          50996
        ]
      },
      {
        "avg_logprob": -0.21763405270046657,
        "compression_ratio": 1.6216216216216217,
        "end": 4238.16,
        "id": 583,
        "no_speech_prob": 0.03358792886137962,
        "seek": 421848,
        "start": 4231.12,
        "temperature": 0,
        "text": " to say plus. So I'm just adding, there's a nice way I should use those. What's that called in ES6,",
        "tokens": [
          50996,
          281,
          584,
          1804,
          13,
          407,
          286,
          478,
          445,
          5127,
          11,
          456,
          311,
          257,
          1481,
          636,
          286,
          820,
          764,
          729,
          13,
          708,
          311,
          300,
          1219,
          294,
          12564,
          21,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.21763405270046657,
        "compression_ratio": 1.6216216216216217,
        "end": 4242.24,
        "id": 584,
        "no_speech_prob": 0.03358792886137962,
        "seek": 421848,
        "start": 4238.16,
        "temperature": 0,
        "text": " the string thing? I'll have to make a video on that, but I'm going to do it my highly manual way.",
        "tokens": [
          51348,
          264,
          6798,
          551,
          30,
          286,
          603,
          362,
          281,
          652,
          257,
          960,
          322,
          300,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          309,
          452,
          5405,
          9688,
          636,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.25578787520125107,
        "compression_ratio": 1.7312775330396475,
        "end": 4249.599999999999,
        "id": 585,
        "no_speech_prob": 0.003707218449562788,
        "seek": 424224,
        "start": 4243.2,
        "temperature": 0,
        "text": " I'm just adding in the minimum and maximum length as a number. So hopefully you can follow what I'm",
        "tokens": [
          50412,
          286,
          478,
          445,
          5127,
          294,
          264,
          7285,
          293,
          6674,
          4641,
          382,
          257,
          1230,
          13,
          407,
          4696,
          291,
          393,
          1524,
          437,
          286,
          478,
          50732
        ]
      },
      {
        "avg_logprob": -0.25578787520125107,
        "compression_ratio": 1.7312775330396475,
        "end": 4255.5199999999995,
        "id": 586,
        "no_speech_prob": 0.003707218449562788,
        "seek": 424224,
        "start": 4249.599999999999,
        "temperature": 0,
        "text": " doing here because I'm, all right. So what I'm doing is I'm just modifying the call to the Wordnik API",
        "tokens": [
          50732,
          884,
          510,
          570,
          286,
          478,
          11,
          439,
          558,
          13,
          407,
          437,
          286,
          478,
          884,
          307,
          286,
          478,
          445,
          42626,
          264,
          818,
          281,
          264,
          8725,
          13123,
          9362,
          51028
        ]
      },
      {
        "avg_logprob": -0.25578787520125107,
        "compression_ratio": 1.7312775330396475,
        "end": 4263.2,
        "id": 587,
        "no_speech_prob": 0.003707218449562788,
        "seek": 424224,
        "start": 4255.5199999999995,
        "temperature": 0,
        "text": " to specify a number of characters. So I'm going to say Wordnik 4 and then Wordnik 5. Sorry, not Wordnik,",
        "tokens": [
          51028,
          281,
          16500,
          257,
          1230,
          295,
          4342,
          13,
          407,
          286,
          478,
          516,
          281,
          584,
          8725,
          13123,
          1017,
          293,
          550,
          8725,
          13123,
          1025,
          13,
          4919,
          11,
          406,
          8725,
          13123,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.25578787520125107,
        "compression_ratio": 1.7312775330396475,
        "end": 4267.12,
        "id": 588,
        "no_speech_prob": 0.003707218449562788,
        "seek": 424224,
        "start": 4263.2,
        "temperature": 0,
        "text": " Wordgif 4, Wordgif 5. So I should get a four letter word and then a five letter word.",
        "tokens": [
          51412,
          8725,
          70,
          351,
          1017,
          11,
          8725,
          70,
          351,
          1025,
          13,
          407,
          286,
          820,
          483,
          257,
          1451,
          5063,
          1349,
          293,
          550,
          257,
          1732,
          5063,
          1349,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.3124713512382122,
        "compression_ratio": 1.6623376623376624,
        "end": 4276.5599999999995,
        "id": 589,
        "no_speech_prob": 0.0000028130170903750695,
        "seek": 426712,
        "start": 4267.84,
        "temperature": 0,
        "text": " Four letters, all right, I got an error. Four letters, five letters. Okay, so that this works,",
        "tokens": [
          50400,
          7451,
          7825,
          11,
          439,
          558,
          11,
          286,
          658,
          364,
          6713,
          13,
          7451,
          7825,
          11,
          1732,
          7825,
          13,
          1033,
          11,
          370,
          300,
          341,
          1985,
          11,
          50836
        ]
      },
      {
        "avg_logprob": -0.3124713512382122,
        "compression_ratio": 1.6623376623376624,
        "end": 4281.76,
        "id": 590,
        "no_speech_prob": 0.0000028130170903750695,
        "seek": 426712,
        "start": 4276.5599999999995,
        "temperature": 0,
        "text": " four letters, five letters in sequence. So why am I doing this? So one thing I want to point out",
        "tokens": [
          50836,
          1451,
          7825,
          11,
          1732,
          7825,
          294,
          8310,
          13,
          407,
          983,
          669,
          286,
          884,
          341,
          30,
          407,
          472,
          551,
          286,
          528,
          281,
          935,
          484,
          51096
        ]
      },
      {
        "avg_logprob": -0.3124713512382122,
        "compression_ratio": 1.6623376623376624,
        "end": 4286.48,
        "id": 591,
        "no_speech_prob": 0.0000028130170903750695,
        "seek": 426712,
        "start": 4281.76,
        "temperature": 0,
        "text": " about sequence versus parallel, I know I'm going to get the promise that all. Interestingly enough,",
        "tokens": [
          51096,
          466,
          8310,
          5717,
          8952,
          11,
          286,
          458,
          286,
          478,
          516,
          281,
          483,
          264,
          6228,
          300,
          439,
          13,
          30564,
          1547,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.3124713512382122,
        "compression_ratio": 1.6623376623376624,
        "end": 4295.5199999999995,
        "id": 592,
        "no_speech_prob": 0.0000028130170903750695,
        "seek": 426712,
        "start": 4286.48,
        "temperature": 0,
        "text": " what if I didn't chain these? So let's take out the second one and just leave this first one",
        "tokens": [
          51332,
          437,
          498,
          286,
          994,
          380,
          5021,
          613,
          30,
          407,
          718,
          311,
          747,
          484,
          264,
          1150,
          472,
          293,
          445,
          1856,
          341,
          700,
          472,
          51784
        ]
      },
      {
        "avg_logprob": -0.2816131405714082,
        "compression_ratio": 1.848360655737705,
        "end": 4298.8,
        "id": 593,
        "no_speech_prob": 0.00004985951818525791,
        "seek": 429552,
        "start": 4295.6,
        "temperature": 0,
        "text": " and now I'm going to actually just completely duplicate this code",
        "tokens": [
          50368,
          293,
          586,
          286,
          478,
          516,
          281,
          767,
          445,
          2584,
          23976,
          341,
          3089,
          50528
        ]
      },
      {
        "avg_logprob": -0.2816131405714082,
        "compression_ratio": 1.848360655737705,
        "end": 4306.240000000001,
        "id": 594,
        "no_speech_prob": 0.00004985951818525791,
        "seek": 429552,
        "start": 4301.120000000001,
        "temperature": 0,
        "text": " and say, I'm going to say three and four, three and four. Let's run this now. So now they're not",
        "tokens": [
          50644,
          293,
          584,
          11,
          286,
          478,
          516,
          281,
          584,
          1045,
          293,
          1451,
          11,
          1045,
          293,
          1451,
          13,
          961,
          311,
          1190,
          341,
          586,
          13,
          407,
          586,
          436,
          434,
          406,
          50900
        ]
      },
      {
        "avg_logprob": -0.2816131405714082,
        "compression_ratio": 1.848360655737705,
        "end": 4310.56,
        "id": 595,
        "no_speech_prob": 0.00004985951818525791,
        "seek": 429552,
        "start": 4306.240000000001,
        "temperature": 0,
        "text": " chained. So I'm not waiting to do the second one until the first one comes back. I'm just saying,",
        "tokens": [
          50900,
          417,
          3563,
          13,
          407,
          286,
          478,
          406,
          3806,
          281,
          360,
          264,
          1150,
          472,
          1826,
          264,
          700,
          472,
          1487,
          646,
          13,
          286,
          478,
          445,
          1566,
          11,
          51116
        ]
      },
      {
        "avg_logprob": -0.2816131405714082,
        "compression_ratio": 1.848360655737705,
        "end": 4315.200000000001,
        "id": 596,
        "no_speech_prob": 0.00004985951818525791,
        "seek": 429552,
        "start": 4310.56,
        "temperature": 0,
        "text": " do these in parallel, do both of them. And when they both come back, create the paragraphs in",
        "tokens": [
          51116,
          360,
          613,
          294,
          8952,
          11,
          360,
          1293,
          295,
          552,
          13,
          400,
          562,
          436,
          1293,
          808,
          646,
          11,
          1884,
          264,
          48910,
          294,
          51348
        ]
      },
      {
        "avg_logprob": -0.2816131405714082,
        "compression_ratio": 1.848360655737705,
        "end": 4322.400000000001,
        "id": 597,
        "no_speech_prob": 0.00004985951818525791,
        "seek": 429552,
        "start": 4315.200000000001,
        "temperature": 0,
        "text": " the image. So let's look at this. Three, four, three, four, three, three, four. So interestingly",
        "tokens": [
          51348,
          264,
          3256,
          13,
          407,
          718,
          311,
          574,
          412,
          341,
          13,
          6244,
          11,
          1451,
          11,
          1045,
          11,
          1451,
          11,
          1045,
          11,
          1045,
          11,
          1451,
          13,
          407,
          25873,
          51708
        ]
      },
      {
        "avg_logprob": -0.2753760308930368,
        "compression_ratio": 1.758490566037736,
        "end": 4328,
        "id": 598,
        "no_speech_prob": 0.000051442180847516283,
        "seek": 432240,
        "start": 4322.48,
        "temperature": 0,
        "text": " enough, let me, let's, I'm sort of surprised. I'm going to just try now with a five as well.",
        "tokens": [
          50368,
          1547,
          11,
          718,
          385,
          11,
          718,
          311,
          11,
          286,
          478,
          1333,
          295,
          6100,
          13,
          286,
          478,
          516,
          281,
          445,
          853,
          586,
          365,
          257,
          1732,
          382,
          731,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2753760308930368,
        "compression_ratio": 1.758490566037736,
        "end": 4336,
        "id": 599,
        "no_speech_prob": 0.000051442180847516283,
        "seek": 432240,
        "start": 4330.16,
        "temperature": 0,
        "text": " Look at this, four, three, five. So when they're happening in parallel, what I'm saying, just like",
        "tokens": [
          50752,
          2053,
          412,
          341,
          11,
          1451,
          11,
          1045,
          11,
          1732,
          13,
          407,
          562,
          436,
          434,
          2737,
          294,
          8952,
          11,
          437,
          286,
          478,
          1566,
          11,
          445,
          411,
          51044
        ]
      },
      {
        "avg_logprob": -0.2753760308930368,
        "compression_ratio": 1.758490566037736,
        "end": 4340.4,
        "id": 600,
        "no_speech_prob": 0.000051442180847516283,
        "seek": 432240,
        "start": 4336,
        "temperature": 0,
        "text": " do this, do this, do this, just start them all. I'm not necessarily going to be sure about the",
        "tokens": [
          51044,
          360,
          341,
          11,
          360,
          341,
          11,
          360,
          341,
          11,
          445,
          722,
          552,
          439,
          13,
          286,
          478,
          406,
          4725,
          516,
          281,
          312,
          988,
          466,
          264,
          51264
        ]
      },
      {
        "avg_logprob": -0.2753760308930368,
        "compression_ratio": 1.758490566037736,
        "end": 4345.599999999999,
        "id": 601,
        "no_speech_prob": 0.000051442180847516283,
        "seek": 432240,
        "start": 4340.4,
        "temperature": 0,
        "text": " order that they come back in. So one way to deal with that is to chain them like I did. There's",
        "tokens": [
          51264,
          1668,
          300,
          436,
          808,
          646,
          294,
          13,
          407,
          472,
          636,
          281,
          2028,
          365,
          300,
          307,
          281,
          5021,
          552,
          411,
          286,
          630,
          13,
          821,
          311,
          51524
        ]
      },
      {
        "avg_logprob": -0.2753760308930368,
        "compression_ratio": 1.758490566037736,
        "end": 4349.679999999999,
        "id": 602,
        "no_speech_prob": 0.000051442180847516283,
        "seek": 432240,
        "start": 4345.599999999999,
        "temperature": 0,
        "text": " another way to deal with that. If I want to say like, wait till everything is done,",
        "tokens": [
          51524,
          1071,
          636,
          281,
          2028,
          365,
          300,
          13,
          759,
          286,
          528,
          281,
          584,
          411,
          11,
          1699,
          4288,
          1203,
          307,
          1096,
          11,
          51728
        ]
      },
      {
        "avg_logprob": -0.33607814186497736,
        "compression_ratio": 1.7610062893081762,
        "end": 4357.280000000001,
        "id": 603,
        "no_speech_prob": 0.00013552042946685106,
        "seek": 434968,
        "start": 4349.84,
        "temperature": 0,
        "text": " and then show the results. And that's where promise.all comes in. So promise.all requires",
        "tokens": [
          50372,
          293,
          550,
          855,
          264,
          3542,
          13,
          400,
          300,
          311,
          689,
          6228,
          13,
          336,
          1487,
          294,
          13,
          407,
          6228,
          13,
          336,
          7029,
          50744
        ]
      },
      {
        "avg_logprob": -0.33607814186497736,
        "compression_ratio": 1.7610062893081762,
        "end": 4364.64,
        "id": 604,
        "no_speech_prob": 0.00013552042946685106,
        "seek": 434968,
        "start": 4358.4800000000005,
        "temperature": 0,
        "text": " an array. So let me, let's just, so let's just pretend I have something like called promises.",
        "tokens": [
          50804,
          364,
          10225,
          13,
          407,
          718,
          385,
          11,
          718,
          311,
          445,
          11,
          370,
          718,
          311,
          445,
          11865,
          286,
          362,
          746,
          411,
          1219,
          16403,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.33607814186497736,
        "compression_ratio": 1.7610062893081762,
        "end": 4373.360000000001,
        "id": 605,
        "no_speech_prob": 0.00013552042946685106,
        "seek": 434968,
        "start": 4366.240000000001,
        "temperature": 0,
        "text": " And it has, it's an array of three promises. If there is an array of three promises, I can write",
        "tokens": [
          51192,
          400,
          309,
          575,
          11,
          309,
          311,
          364,
          10225,
          295,
          1045,
          16403,
          13,
          759,
          456,
          307,
          364,
          10225,
          295,
          1045,
          16403,
          11,
          286,
          393,
          2464,
          51548
        ]
      },
      {
        "avg_logprob": -0.22020760978140483,
        "compression_ratio": 1.6449704142011834,
        "end": 4382.48,
        "id": 606,
        "no_speech_prob": 0.0001039104608935304,
        "seek": 437336,
        "start": 4373.5199999999995,
        "temperature": 0,
        "text": " If there is an array of three promises, I can write promise.all, pass in promises, that array,",
        "tokens": [
          50372,
          759,
          456,
          307,
          364,
          10225,
          295,
          1045,
          16403,
          11,
          286,
          393,
          2464,
          6228,
          13,
          336,
          11,
          1320,
          294,
          16403,
          11,
          300,
          10225,
          11,
          50820
        ]
      },
      {
        "avg_logprob": -0.22020760978140483,
        "compression_ratio": 1.6449704142011834,
        "end": 4395.04,
        "id": 607,
        "no_speech_prob": 0.0001039104608935304,
        "seek": 437336,
        "start": 4382.48,
        "temperature": 0,
        "text": " and then add, sorry, the then and the catch. So hold on, I'm, I'm, this is hard. I have to think",
        "tokens": [
          50820,
          293,
          550,
          909,
          11,
          2597,
          11,
          264,
          550,
          293,
          264,
          3745,
          13,
          407,
          1797,
          322,
          11,
          286,
          478,
          11,
          286,
          478,
          11,
          341,
          307,
          1152,
          13,
          286,
          362,
          281,
          519,
          51448
        ]
      },
      {
        "avg_logprob": -0.22020760978140483,
        "compression_ratio": 1.6449704142011834,
        "end": 4401.92,
        "id": 608,
        "no_speech_prob": 0.0001039104608935304,
        "seek": 437336,
        "start": 4395.04,
        "temperature": 0,
        "text": " about this while I'm doing it. Promise.all promises, then, and this gets a function of",
        "tokens": [
          51448,
          466,
          341,
          1339,
          286,
          478,
          884,
          309,
          13,
          34878,
          13,
          336,
          16403,
          11,
          550,
          11,
          293,
          341,
          2170,
          257,
          2445,
          295,
          51792
        ]
      },
      {
        "avg_logprob": -0.20439967131003356,
        "compression_ratio": 1.4894736842105263,
        "end": 4407.36,
        "id": 609,
        "no_speech_prob": 0.0012255655601620674,
        "seek": 440192,
        "start": 4401.92,
        "temperature": 0,
        "text": " what to do when it comes back. And this gets a function, which is pretty much, you know,",
        "tokens": [
          50364,
          437,
          281,
          360,
          562,
          309,
          1487,
          646,
          13,
          400,
          341,
          2170,
          257,
          2445,
          11,
          597,
          307,
          1238,
          709,
          11,
          291,
          458,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.20439967131003356,
        "compression_ratio": 1.4894736842105263,
        "end": 4416.24,
        "id": 610,
        "no_speech_prob": 0.0012255655601620674,
        "seek": 440192,
        "start": 4407.36,
        "temperature": 0,
        "text": " if there is an error. Okay, so I think this is the skeleton of what I want. I have some syntax",
        "tokens": [
          50636,
          498,
          456,
          307,
          364,
          6713,
          13,
          1033,
          11,
          370,
          286,
          519,
          341,
          307,
          264,
          25204,
          295,
          437,
          286,
          528,
          13,
          286,
          362,
          512,
          28431,
          51080
        ]
      },
      {
        "avg_logprob": -0.20439967131003356,
        "compression_ratio": 1.4894736842105263,
        "end": 4425.04,
        "id": 611,
        "no_speech_prob": 0.0012255655601620674,
        "seek": 440192,
        "start": 4416.24,
        "temperature": 0,
        "text": " errors here. Maybe a semicolon. Looking, looking, looking. Oh, well, this should say error. Console",
        "tokens": [
          51080,
          13603,
          510,
          13,
          2704,
          257,
          27515,
          38780,
          13,
          11053,
          11,
          1237,
          11,
          1237,
          13,
          876,
          11,
          731,
          11,
          341,
          820,
          584,
          6713,
          13,
          44152,
          51520
        ]
      },
      {
        "avg_logprob": -0.3349262052966702,
        "compression_ratio": 1.0681818181818181,
        "end": 4433.36,
        "id": 612,
        "no_speech_prob": 0.15404492616653442,
        "seek": 442504,
        "start": 4425.04,
        "temperature": 0,
        "text": " log error. What's wrong here? What am I missing? Ah, this needs, there we go. No. Does it just",
        "tokens": [
          50364,
          3565,
          6713,
          13,
          708,
          311,
          2085,
          510,
          30,
          708,
          669,
          286,
          5361,
          30,
          2438,
          11,
          341,
          2203,
          11,
          456,
          321,
          352,
          13,
          883,
          13,
          4402,
          309,
          445,
          50780
        ]
      },
      {
        "avg_logprob": -0.3238148181996447,
        "compression_ratio": 1.2115384615384615,
        "end": 4451.679999999999,
        "id": 613,
        "no_speech_prob": 0.1623690128326416,
        "seek": 443336,
        "start": 4433.36,
        "temperature": 0,
        "text": " want, oh, there's no, yep. What's wrong?",
        "tokens": [
          50364,
          528,
          11,
          1954,
          11,
          456,
          311,
          572,
          11,
          18633,
          13,
          708,
          311,
          2085,
          30,
          51280
        ]
      },
      {
        "avg_logprob": -0.3238148181996447,
        "compression_ratio": 1.2115384615384615,
        "end": 4459.759999999999,
        "id": 614,
        "no_speech_prob": 0.1623690128326416,
        "seek": 443336,
        "start": 4454.719999999999,
        "temperature": 0,
        "text": " Wait a minute, let's see. No, I know, that's not the problem. I don't see what it is.",
        "tokens": [
          51432,
          3802,
          257,
          3456,
          11,
          718,
          311,
          536,
          13,
          883,
          11,
          286,
          458,
          11,
          300,
          311,
          406,
          264,
          1154,
          13,
          286,
          500,
          380,
          536,
          437,
          309,
          307,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.25477133178710937,
        "compression_ratio": 1.8387096774193548,
        "end": 4466.72,
        "id": 615,
        "no_speech_prob": 0.000052252264140406623,
        "seek": 445976,
        "start": 4460.24,
        "temperature": 0,
        "text": " Oh, no, this is right. That's where that goes. That's the, that's closing setup.",
        "tokens": [
          50388,
          876,
          11,
          572,
          11,
          341,
          307,
          558,
          13,
          663,
          311,
          689,
          300,
          1709,
          13,
          663,
          311,
          264,
          11,
          300,
          311,
          10377,
          8657,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.25477133178710937,
        "compression_ratio": 1.8387096774193548,
        "end": 4472.96,
        "id": 616,
        "no_speech_prob": 0.000052252264140406623,
        "seek": 445976,
        "start": 4469.52,
        "temperature": 0,
        "text": " Okay, this is actually correct. This curly bracket, I don't know why I was, I had a little",
        "tokens": [
          50852,
          1033,
          11,
          341,
          307,
          767,
          3006,
          13,
          639,
          32066,
          16904,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          390,
          11,
          286,
          632,
          257,
          707,
          51024
        ]
      },
      {
        "avg_logprob": -0.25477133178710937,
        "compression_ratio": 1.8387096774193548,
        "end": 4476.320000000001,
        "id": 617,
        "no_speech_prob": 0.000052252264140406623,
        "seek": 445976,
        "start": 4472.96,
        "temperature": 0,
        "text": " brain malfunction there where I thought it was supposed to be there, but this is actually closing",
        "tokens": [
          51024,
          3567,
          50229,
          456,
          689,
          286,
          1194,
          309,
          390,
          3442,
          281,
          312,
          456,
          11,
          457,
          341,
          307,
          767,
          10377,
          51192
        ]
      },
      {
        "avg_logprob": -0.25477133178710937,
        "compression_ratio": 1.8387096774193548,
        "end": 4482.320000000001,
        "id": 618,
        "no_speech_prob": 0.000052252264140406623,
        "seek": 445976,
        "start": 4476.320000000001,
        "temperature": 0,
        "text": " setup, so this is in the correct spot. So this is the skeleton. The idea is, and by the way,",
        "tokens": [
          51192,
          8657,
          11,
          370,
          341,
          307,
          294,
          264,
          3006,
          4008,
          13,
          407,
          341,
          307,
          264,
          25204,
          13,
          440,
          1558,
          307,
          11,
          293,
          538,
          264,
          636,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.25477133178710937,
        "compression_ratio": 1.8387096774193548,
        "end": 4487.280000000001,
        "id": 619,
        "no_speech_prob": 0.000052252264140406623,
        "seek": 445976,
        "start": 4482.320000000001,
        "temperature": 0,
        "text": " I, this, this is really a problem. This needs to have an argument. The idea, the skeleton is,",
        "tokens": [
          51492,
          286,
          11,
          341,
          11,
          341,
          307,
          534,
          257,
          1154,
          13,
          639,
          2203,
          281,
          362,
          364,
          6770,
          13,
          440,
          1558,
          11,
          264,
          25204,
          307,
          11,
          51740
        ]
      },
      {
        "avg_logprob": -0.23942012231326798,
        "compression_ratio": 1.7534246575342465,
        "end": 4493.92,
        "id": 620,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 448728,
        "start": 4487.44,
        "temperature": 0,
        "text": " the idea, the skeleton is, if I create an array of three promises, I can say, when all of the",
        "tokens": [
          50372,
          264,
          1558,
          11,
          264,
          25204,
          307,
          11,
          498,
          286,
          1884,
          364,
          10225,
          295,
          1045,
          16403,
          11,
          286,
          393,
          584,
          11,
          562,
          439,
          295,
          264,
          50696
        ]
      },
      {
        "avg_logprob": -0.23942012231326798,
        "compression_ratio": 1.7534246575342465,
        "end": 4500.24,
        "id": 621,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 448728,
        "start": 4493.92,
        "temperature": 0,
        "text": " promises are complete and resolved, give me the result of all those promises in an array of the",
        "tokens": [
          50696,
          16403,
          366,
          3566,
          293,
          20772,
          11,
          976,
          385,
          264,
          1874,
          295,
          439,
          729,
          16403,
          294,
          364,
          10225,
          295,
          264,
          51012
        ]
      },
      {
        "avg_logprob": -0.23942012231326798,
        "compression_ratio": 1.7534246575342465,
        "end": 4506.08,
        "id": 622,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 448728,
        "start": 4500.24,
        "temperature": 0,
        "text": " same order as the original promises. That's the idea of promise.all. So what are these promises?",
        "tokens": [
          51012,
          912,
          1668,
          382,
          264,
          3380,
          16403,
          13,
          663,
          311,
          264,
          1558,
          295,
          6228,
          13,
          336,
          13,
          407,
          437,
          366,
          613,
          16403,
          30,
          51304
        ]
      },
      {
        "avg_logprob": -0.23942012231326798,
        "compression_ratio": 1.7534246575342465,
        "end": 4516.24,
        "id": 623,
        "no_speech_prob": 0.000025867428121273406,
        "seek": 448728,
        "start": 4506.719999999999,
        "temperature": 0,
        "text": " Well, they could be this. Word, gif, three. Word, gif, four. And certainly I could create them in",
        "tokens": [
          51336,
          1042,
          11,
          436,
          727,
          312,
          341,
          13,
          8725,
          11,
          290,
          351,
          11,
          1045,
          13,
          8725,
          11,
          290,
          351,
          11,
          1451,
          13,
          400,
          3297,
          286,
          727,
          1884,
          552,
          294,
          51812
        ]
      },
      {
        "avg_logprob": -0.18440508842468262,
        "compression_ratio": 1.5895196506550218,
        "end": 4521.76,
        "id": 624,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 451624,
        "start": 4516.24,
        "temperature": 0,
        "text": " a loop or with separate variables, but just to do this, word, gif, five. So this is the idea here.",
        "tokens": [
          50364,
          257,
          6367,
          420,
          365,
          4994,
          9102,
          11,
          457,
          445,
          281,
          360,
          341,
          11,
          1349,
          11,
          290,
          351,
          11,
          1732,
          13,
          407,
          341,
          307,
          264,
          1558,
          510,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.18440508842468262,
        "compression_ratio": 1.5895196506550218,
        "end": 4527.28,
        "id": 625,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 451624,
        "start": 4521.76,
        "temperature": 0,
        "text": " Let me give myself a little bit more space. That what I can do here is just say, hey,",
        "tokens": [
          50640,
          961,
          385,
          976,
          2059,
          257,
          707,
          857,
          544,
          1901,
          13,
          663,
          437,
          286,
          393,
          360,
          510,
          307,
          445,
          584,
          11,
          4177,
          11,
          50916
        ]
      },
      {
        "avg_logprob": -0.18440508842468262,
        "compression_ratio": 1.5895196506550218,
        "end": 4533.2,
        "id": 626,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 451624,
        "start": 4527.28,
        "temperature": 0,
        "text": " I want to make three promises. I want three word gif things. When all of those are done,",
        "tokens": [
          50916,
          286,
          528,
          281,
          652,
          1045,
          16403,
          13,
          286,
          528,
          1045,
          1349,
          290,
          351,
          721,
          13,
          1133,
          439,
          295,
          729,
          366,
          1096,
          11,
          51212
        ]
      },
      {
        "avg_logprob": -0.18440508842468262,
        "compression_ratio": 1.5895196506550218,
        "end": 4541.36,
        "id": 627,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 451624,
        "start": 4533.2,
        "temperature": 0,
        "text": " show me the results, and now this is, I'm just going to use a, like a regular loop because",
        "tokens": [
          51212,
          855,
          385,
          264,
          3542,
          11,
          293,
          586,
          341,
          307,
          11,
          286,
          478,
          445,
          516,
          281,
          764,
          257,
          11,
          411,
          257,
          3890,
          6367,
          570,
          51620
        ]
      },
      {
        "avg_logprob": -0.2618107922309268,
        "compression_ratio": 1.6824034334763949,
        "end": 4546.88,
        "id": 628,
        "no_speech_prob": 0.000005507605237653479,
        "seek": 454136,
        "start": 4542.32,
        "temperature": 0,
        "text": " instead of a for of loop, I'm not sure why, but that's how I feel right now. So now I can do a loop",
        "tokens": [
          50412,
          2602,
          295,
          257,
          337,
          295,
          6367,
          11,
          286,
          478,
          406,
          988,
          983,
          11,
          457,
          300,
          311,
          577,
          286,
          841,
          558,
          586,
          13,
          407,
          586,
          286,
          393,
          360,
          257,
          6367,
          50640
        ]
      },
      {
        "avg_logprob": -0.2618107922309268,
        "compression_ratio": 1.6824034334763949,
        "end": 4555.44,
        "id": 629,
        "no_speech_prob": 0.000005507605237653479,
        "seek": 454136,
        "start": 4546.88,
        "temperature": 0,
        "text": " to go through all of the results, and then I could say data equal results, index i, and then what do",
        "tokens": [
          50640,
          281,
          352,
          807,
          439,
          295,
          264,
          3542,
          11,
          293,
          550,
          286,
          727,
          584,
          1412,
          2681,
          3542,
          11,
          8186,
          741,
          11,
          293,
          550,
          437,
          360,
          51068
        ]
      },
      {
        "avg_logprob": -0.2618107922309268,
        "compression_ratio": 1.6824034334763949,
        "end": 4562.08,
        "id": 630,
        "no_speech_prob": 0.000005507605237653479,
        "seek": 454136,
        "start": 4555.44,
        "temperature": 0,
        "text": " I want to do? Actually, let's just put this in here. The difference is I'm saying results, index i,",
        "tokens": [
          51068,
          286,
          528,
          281,
          360,
          30,
          5135,
          11,
          718,
          311,
          445,
          829,
          341,
          294,
          510,
          13,
          440,
          2649,
          307,
          286,
          478,
          1566,
          3542,
          11,
          8186,
          741,
          11,
          51400
        ]
      },
      {
        "avg_logprob": -0.2618107922309268,
        "compression_ratio": 1.6824034334763949,
        "end": 4569.839999999999,
        "id": 631,
        "no_speech_prob": 0.000005507605237653479,
        "seek": 454136,
        "start": 4562.08,
        "temperature": 0,
        "text": " results, index i. Right? So the idea here is now, this is exactly what I had before. Sorry,",
        "tokens": [
          51400,
          3542,
          11,
          8186,
          741,
          13,
          1779,
          30,
          407,
          264,
          1558,
          510,
          307,
          586,
          11,
          341,
          307,
          2293,
          437,
          286,
          632,
          949,
          13,
          4919,
          11,
          51788
        ]
      },
      {
        "avg_logprob": -0.22694110011195276,
        "compression_ratio": 1.778688524590164,
        "end": 4574.64,
        "id": 632,
        "no_speech_prob": 0.000004425490715220803,
        "seek": 456984,
        "start": 4569.84,
        "temperature": 0,
        "text": " it took me a little while to get to this. This is exactly what I had before. The difference is",
        "tokens": [
          50364,
          309,
          1890,
          385,
          257,
          707,
          1339,
          281,
          483,
          281,
          341,
          13,
          639,
          307,
          2293,
          437,
          286,
          632,
          949,
          13,
          440,
          2649,
          307,
          50604
        ]
      },
      {
        "avg_logprob": -0.22694110011195276,
        "compression_ratio": 1.778688524590164,
        "end": 4580.56,
        "id": 633,
        "no_speech_prob": 0.000004425490715220803,
        "seek": 456984,
        "start": 4575.2,
        "temperature": 0,
        "text": " I am putting all the promises in an array. I'm not handling them with their each, their own then or",
        "tokens": [
          50632,
          286,
          669,
          3372,
          439,
          264,
          16403,
          294,
          364,
          10225,
          13,
          286,
          478,
          406,
          13175,
          552,
          365,
          641,
          1184,
          11,
          641,
          1065,
          550,
          420,
          50900
        ]
      },
      {
        "avg_logprob": -0.22694110011195276,
        "compression_ratio": 1.778688524590164,
        "end": 4585.12,
        "id": 634,
        "no_speech_prob": 0.000004425490715220803,
        "seek": 456984,
        "start": 4580.56,
        "temperature": 0,
        "text": " in separate blocks. I'm just putting all the promises, right? Word gif returns a promise.",
        "tokens": [
          50900,
          294,
          4994,
          8474,
          13,
          286,
          478,
          445,
          3372,
          439,
          264,
          16403,
          11,
          558,
          30,
          8725,
          290,
          351,
          11247,
          257,
          6228,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.22694110011195276,
        "compression_ratio": 1.778688524590164,
        "end": 4588.88,
        "id": 635,
        "no_speech_prob": 0.000004425490715220803,
        "seek": 456984,
        "start": 4585.92,
        "temperature": 0,
        "text": " Remember this code? Oh, this, this I can totally delete now.",
        "tokens": [
          51168,
          5459,
          341,
          3089,
          30,
          876,
          11,
          341,
          11,
          341,
          286,
          393,
          3879,
          12097,
          586,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.22694110011195276,
        "compression_ratio": 1.778688524590164,
        "end": 4596.56,
        "id": 636,
        "no_speech_prob": 0.000004425490715220803,
        "seek": 456984,
        "start": 4591.76,
        "temperature": 0,
        "text": " Remember this async function we wrote? The async function with awaits returns a promise.",
        "tokens": [
          51460,
          5459,
          341,
          382,
          34015,
          2445,
          321,
          4114,
          30,
          440,
          382,
          34015,
          2445,
          365,
          45955,
          11247,
          257,
          6228,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.27605022702898296,
        "compression_ratio": 1.6954314720812182,
        "end": 4602.240000000001,
        "id": 637,
        "no_speech_prob": 0.00003321417898405343,
        "seek": 459656,
        "start": 4596.96,
        "temperature": 0,
        "text": " When the promise is resolved, you get this particular object. So now when all of the",
        "tokens": [
          50384,
          1133,
          264,
          6228,
          307,
          20772,
          11,
          291,
          483,
          341,
          1729,
          2657,
          13,
          407,
          586,
          562,
          439,
          295,
          264,
          50648
        ]
      },
      {
        "avg_logprob": -0.27605022702898296,
        "compression_ratio": 1.6954314720812182,
        "end": 4607.360000000001,
        "id": 638,
        "no_speech_prob": 0.00003321417898405343,
        "seek": 459656,
        "start": 4602.240000000001,
        "temperature": 0,
        "text": " promises are resolved, then I have all of the resolutions in an array called results,",
        "tokens": [
          50648,
          16403,
          366,
          20772,
          11,
          550,
          286,
          362,
          439,
          295,
          264,
          32179,
          294,
          364,
          10225,
          1219,
          3542,
          11,
          50904
        ]
      },
      {
        "avg_logprob": -0.27605022702898296,
        "compression_ratio": 1.6954314720812182,
        "end": 4611.200000000001,
        "id": 639,
        "no_speech_prob": 0.00003321417898405343,
        "seek": 459656,
        "start": 4607.360000000001,
        "temperature": 0,
        "text": " and I can go through them one at a time. And they should be in the same exact order",
        "tokens": [
          50904,
          293,
          286,
          393,
          352,
          807,
          552,
          472,
          412,
          257,
          565,
          13,
          400,
          436,
          820,
          312,
          294,
          264,
          912,
          1900,
          1668,
          51096
        ]
      },
      {
        "avg_logprob": -0.27605022702898296,
        "compression_ratio": 1.6954314720812182,
        "end": 4621.120000000001,
        "id": 640,
        "no_speech_prob": 0.00003321417898405343,
        "seek": 459656,
        "start": 4611.200000000001,
        "temperature": 0,
        "text": " as the array, original array. Did I do this correctly? Did I do this correctly?",
        "tokens": [
          51096,
          382,
          264,
          10225,
          11,
          3380,
          10225,
          13,
          2589,
          286,
          360,
          341,
          8944,
          30,
          2589,
          286,
          360,
          341,
          8944,
          30,
          51592
        ]
      },
      {
        "avg_logprob": -0.25907826078110846,
        "compression_ratio": 1.391304347826087,
        "end": 4622.08,
        "id": 641,
        "no_speech_prob": 0.006797499023377895,
        "seek": 462112,
        "start": 4621.2,
        "temperature": 0,
        "text": " Did I do this correctly?",
        "tokens": [
          50368,
          2589,
          286,
          360,
          341,
          8944,
          30,
          50412
        ]
      },
      {
        "avg_logprob": -0.25907826078110846,
        "compression_ratio": 1.391304347826087,
        "end": 4635.04,
        "id": 642,
        "no_speech_prob": 0.006797499023377895,
        "seek": 462112,
        "start": 4624.64,
        "temperature": 0,
        "text": " Ah, shoot. Sketch.js line 49. What did I do? Line 49? Am I even in the right? Yeah, I'm in the right.",
        "tokens": [
          50540,
          2438,
          11,
          3076,
          13,
          49245,
          13,
          25530,
          1622,
          16513,
          13,
          708,
          630,
          286,
          360,
          30,
          14670,
          16513,
          30,
          2012,
          286,
          754,
          294,
          264,
          558,
          30,
          865,
          11,
          286,
          478,
          294,
          264,
          558,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.25907826078110846,
        "compression_ratio": 1.391304347826087,
        "end": 4642.64,
        "id": 643,
        "no_speech_prob": 0.006797499023377895,
        "seek": 462112,
        "start": 4636.16,
        "temperature": 0,
        "text": " 49. Hold on. I must not have, I didn't save. I didn't save. Save.",
        "tokens": [
          51116,
          16513,
          13,
          6962,
          322,
          13,
          286,
          1633,
          406,
          362,
          11,
          286,
          994,
          380,
          3155,
          13,
          286,
          994,
          380,
          3155,
          13,
          15541,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.2223480741182963,
        "compression_ratio": 1.5135135135135136,
        "end": 4649.04,
        "id": 644,
        "no_speech_prob": 0.0014103538123890758,
        "seek": 464264,
        "start": 4643.360000000001,
        "temperature": 0,
        "text": " Try this again. This is like wasted time in the video, but.",
        "tokens": [
          50400,
          6526,
          341,
          797,
          13,
          639,
          307,
          411,
          19496,
          565,
          294,
          264,
          960,
          11,
          457,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.2223480741182963,
        "compression_ratio": 1.5135135135135136,
        "end": 4656.88,
        "id": 645,
        "no_speech_prob": 0.0014103538123890758,
        "seek": 464264,
        "start": 4651.68,
        "temperature": 0,
        "text": " Whoa, line 20 now. Should never use that drum sound effect. Oh, I just have an extra curly",
        "tokens": [
          50816,
          7521,
          11,
          1622,
          945,
          586,
          13,
          6454,
          1128,
          764,
          300,
          10206,
          1626,
          1802,
          13,
          876,
          11,
          286,
          445,
          362,
          364,
          2857,
          32066,
          51076
        ]
      },
      {
        "avg_logprob": -0.2223480741182963,
        "compression_ratio": 1.5135135135135136,
        "end": 4664.400000000001,
        "id": 646,
        "no_speech_prob": 0.0014103538123890758,
        "seek": 464264,
        "start": 4656.88,
        "temperature": 0,
        "text": " bracket. Thank you. There we go. So when they're done, all three of them happen at once.",
        "tokens": [
          51076,
          16904,
          13,
          1044,
          291,
          13,
          821,
          321,
          352,
          13,
          407,
          562,
          436,
          434,
          1096,
          11,
          439,
          1045,
          295,
          552,
          1051,
          412,
          1564,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.2223480741182963,
        "compression_ratio": 1.5135135135135136,
        "end": 4671.68,
        "id": 647,
        "no_speech_prob": 0.0014103538123890758,
        "seek": 464264,
        "start": 4665.52,
        "temperature": 0,
        "text": " And they're always in the right order. Three, four, five. Three, four, five. Let's get an error.",
        "tokens": [
          51508,
          400,
          436,
          434,
          1009,
          294,
          264,
          558,
          1668,
          13,
          6244,
          11,
          1451,
          11,
          1732,
          13,
          6244,
          11,
          1451,
          11,
          1732,
          13,
          961,
          311,
          483,
          364,
          6713,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.23212231980993392,
        "compression_ratio": 1.5727272727272728,
        "end": 4682.08,
        "id": 648,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 467264,
        "start": 4672.8,
        "temperature": 0,
        "text": " I'm sure we'll get errors if we give longer words. So let's just see what happens with an error.",
        "tokens": [
          50372,
          286,
          478,
          988,
          321,
          603,
          483,
          13603,
          498,
          321,
          976,
          2854,
          2283,
          13,
          407,
          718,
          311,
          445,
          536,
          437,
          2314,
          365,
          364,
          6713,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.23212231980993392,
        "compression_ratio": 1.5727272727272728,
        "end": 4692.160000000001,
        "id": 649,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 467264,
        "start": 4685.12,
        "temperature": 0,
        "text": " Didn't get an. How are we not getting any errors? There we go. Now, interestingly enough,",
        "tokens": [
          50988,
          11151,
          380,
          483,
          364,
          13,
          1012,
          366,
          321,
          406,
          1242,
          604,
          13603,
          30,
          821,
          321,
          352,
          13,
          823,
          11,
          25873,
          1547,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.23212231980993392,
        "compression_ratio": 1.5727272727272728,
        "end": 4694.88,
        "id": 650,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 467264,
        "start": 4692.160000000001,
        "temperature": 0,
        "text": " is there, I really should stop because this video should be done,",
        "tokens": [
          51340,
          307,
          456,
          11,
          286,
          534,
          820,
          1590,
          570,
          341,
          960,
          820,
          312,
          1096,
          11,
          51476
        ]
      },
      {
        "avg_logprob": -0.23212231980993392,
        "compression_ratio": 1.5727272727272728,
        "end": 4699.200000000001,
        "id": 651,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 467264,
        "start": 4694.88,
        "temperature": 0,
        "text": " but is there a way that I, I just want to look at that results array if I get an error. Oops.",
        "tokens": [
          51476,
          457,
          307,
          456,
          257,
          636,
          300,
          286,
          11,
          286,
          445,
          528,
          281,
          574,
          412,
          300,
          3542,
          10225,
          498,
          286,
          483,
          364,
          6713,
          13,
          21726,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.22872557123023343,
        "compression_ratio": 1.5621621621621622,
        "end": 4709.84,
        "id": 652,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 470264,
        "start": 4702.88,
        "temperature": 0,
        "text": " Do I at least get. Yeah, I guess I don't. Well, timeout for a second.",
        "tokens": [
          50376,
          1144,
          286,
          412,
          1935,
          483,
          13,
          865,
          11,
          286,
          2041,
          286,
          500,
          380,
          13,
          1042,
          11,
          565,
          346,
          337,
          257,
          1150,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.22872557123023343,
        "compression_ratio": 1.5621621621621622,
        "end": 4716.400000000001,
        "id": 653,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 470264,
        "start": 4711.68,
        "temperature": 0,
        "text": " So here's the thing. I guess if I want to handle these individually and have the ones that succeed,",
        "tokens": [
          50816,
          407,
          510,
          311,
          264,
          551,
          13,
          286,
          2041,
          498,
          286,
          528,
          281,
          4813,
          613,
          16652,
          293,
          362,
          264,
          2306,
          300,
          7754,
          11,
          51052
        ]
      },
      {
        "avg_logprob": -0.22872557123023343,
        "compression_ratio": 1.5621621621621622,
        "end": 4721.04,
        "id": 654,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 470264,
        "start": 4716.400000000001,
        "temperature": 0,
        "text": " succeed, and the ones that fail, fail, I can't use this solution. Is that correct?",
        "tokens": [
          51052,
          7754,
          11,
          293,
          264,
          2306,
          300,
          3061,
          11,
          3061,
          11,
          286,
          393,
          380,
          764,
          341,
          3827,
          13,
          1119,
          300,
          3006,
          30,
          51284
        ]
      },
      {
        "avg_logprob": -0.22872557123023343,
        "compression_ratio": 1.5621621621621622,
        "end": 4726.96,
        "id": 655,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 470264,
        "start": 4725.52,
        "temperature": 0,
        "text": " I need some help with this question.",
        "tokens": [
          51508,
          286,
          643,
          512,
          854,
          365,
          341,
          1168,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.22663507790401063,
        "compression_ratio": 1.3984962406015038,
        "end": 4736.72,
        "id": 656,
        "no_speech_prob": 0.000013631345609610435,
        "seek": 472696,
        "start": 4726.96,
        "temperature": 0,
        "text": " 1220. I'm going to have to get some water.",
        "tokens": [
          50364,
          2272,
          2009,
          13,
          286,
          478,
          516,
          281,
          362,
          281,
          483,
          512,
          1281,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.22663507790401063,
        "compression_ratio": 1.3984962406015038,
        "end": 4747.92,
        "id": 657,
        "no_speech_prob": 0.000013631345609610435,
        "seek": 472696,
        "start": 4743.44,
        "temperature": 0,
        "text": " You don't get results on the error ever. So if I wanted to do,",
        "tokens": [
          51188,
          509,
          500,
          380,
          483,
          3542,
          322,
          264,
          6713,
          1562,
          13,
          407,
          498,
          286,
          1415,
          281,
          360,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.22663507790401063,
        "compression_ratio": 1.3984962406015038,
        "end": 4755.04,
        "id": 658,
        "no_speech_prob": 0.000013631345609610435,
        "seek": 472696,
        "start": 4750.88,
        "temperature": 0,
        "text": " if I wanted to do like a hundred of them, this doesn't really make sense, right?",
        "tokens": [
          51560,
          498,
          286,
          1415,
          281,
          360,
          411,
          257,
          3262,
          295,
          552,
          11,
          341,
          1177,
          380,
          534,
          652,
          2020,
          11,
          558,
          30,
          51768
        ]
      },
      {
        "avg_logprob": -0.3720377967471168,
        "compression_ratio": 1.3246753246753247,
        "end": 4758.4,
        "id": 659,
        "no_speech_prob": 0.000011300802725600079,
        "seek": 475504,
        "start": 4755.44,
        "temperature": 0,
        "text": " I would really want to sequence it, not use promised at all, right?",
        "tokens": [
          50384,
          286,
          576,
          534,
          528,
          281,
          8310,
          309,
          11,
          406,
          764,
          10768,
          412,
          439,
          11,
          558,
          30,
          50532
        ]
      },
      {
        "avg_logprob": -0.3720377967471168,
        "compression_ratio": 1.3246753246753247,
        "end": 4762.56,
        "id": 660,
        "no_speech_prob": 0.000011300802725600079,
        "seek": 475504,
        "start": 4760.64,
        "temperature": 0,
        "text": " Okay. So I think I was.",
        "tokens": [
          50644,
          1033,
          13,
          407,
          286,
          519,
          286,
          390,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.3720377967471168,
        "compression_ratio": 1.3246753246753247,
        "end": 4770.08,
        "id": 661,
        "no_speech_prob": 0.000011300802725600079,
        "seek": 475504,
        "start": 4766.96,
        "temperature": 0,
        "text": " Oh, I forgot to show try and catch in here, but that's fine.",
        "tokens": [
          50960,
          876,
          11,
          286,
          5298,
          281,
          855,
          853,
          293,
          3745,
          294,
          510,
          11,
          457,
          300,
          311,
          2489,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.3720377967471168,
        "compression_ratio": 1.3246753246753247,
        "end": 4776.4,
        "id": 662,
        "no_speech_prob": 0.000011300802725600079,
        "seek": 475504,
        "start": 4772.4,
        "temperature": 0,
        "text": " That could come another time. All or nothing. Okay.",
        "tokens": [
          51232,
          663,
          727,
          808,
          1071,
          565,
          13,
          1057,
          420,
          1825,
          13,
          1033,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.26690925870622906,
        "compression_ratio": 1.6638655462184875,
        "end": 4777.5199999999995,
        "id": 663,
        "no_speech_prob": 0.000014285515135270543,
        "seek": 477640,
        "start": 4776.48,
        "temperature": 0,
        "text": " All or nothing. Okay.",
        "tokens": [
          50368,
          1057,
          420,
          1825,
          13,
          1033,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.26690925870622906,
        "compression_ratio": 1.6638655462184875,
        "end": 4786.4,
        "id": 664,
        "no_speech_prob": 0.000014285515135270543,
        "seek": 477640,
        "start": 4782,
        "temperature": 0,
        "text": " All right. So I got an error. So here's the thing. This promise that all might not actually",
        "tokens": [
          50644,
          1057,
          558,
          13,
          407,
          286,
          658,
          364,
          6713,
          13,
          407,
          510,
          311,
          264,
          551,
          13,
          639,
          6228,
          300,
          439,
          1062,
          406,
          767,
          50864
        ]
      },
      {
        "avg_logprob": -0.26690925870622906,
        "compression_ratio": 1.6638655462184875,
        "end": 4791.839999999999,
        "id": 665,
        "no_speech_prob": 0.000014285515135270543,
        "seek": 477640,
        "start": 4786.4,
        "temperature": 0,
        "text": " be such a great solution for this because promise.all is all or nothing. So any of those",
        "tokens": [
          50864,
          312,
          1270,
          257,
          869,
          3827,
          337,
          341,
          570,
          6228,
          13,
          336,
          307,
          439,
          420,
          1825,
          13,
          407,
          604,
          295,
          729,
          51136
        ]
      },
      {
        "avg_logprob": -0.26690925870622906,
        "compression_ratio": 1.6638655462184875,
        "end": 4796.5599999999995,
        "id": 666,
        "no_speech_prob": 0.000014285515135270543,
        "seek": 477640,
        "start": 4791.839999999999,
        "temperature": 0,
        "text": " promises have an error, then I don't get any of the results. So if what I wanted to do here was",
        "tokens": [
          51136,
          16403,
          362,
          364,
          6713,
          11,
          550,
          286,
          500,
          380,
          483,
          604,
          295,
          264,
          3542,
          13,
          407,
          498,
          437,
          286,
          1415,
          281,
          360,
          510,
          390,
          51372
        ]
      },
      {
        "avg_logprob": -0.26690925870622906,
        "compression_ratio": 1.6638655462184875,
        "end": 4804.24,
        "id": 667,
        "no_speech_prob": 0.000014285515135270543,
        "seek": 477640,
        "start": 4796.5599999999995,
        "temperature": 0,
        "text": " create a for loop, you know, let I equal zero eyes, less than 100. I plus, plus, and I have like,",
        "tokens": [
          51372,
          1884,
          257,
          337,
          6367,
          11,
          291,
          458,
          11,
          718,
          286,
          2681,
          4018,
          2575,
          11,
          1570,
          813,
          2319,
          13,
          286,
          1804,
          11,
          1804,
          11,
          293,
          286,
          362,
          411,
          11,
          51756
        ]
      },
      {
        "avg_logprob": -0.2631156065753687,
        "compression_ratio": 1.5815899581589958,
        "end": 4814.32,
        "id": 668,
        "no_speech_prob": 3.3596776916056115e-7,
        "seek": 480424,
        "start": 4804.24,
        "temperature": 0,
        "text": " let promises equal an array. And then say promises.push word gif, you know, for, for I.",
        "tokens": [
          50364,
          718,
          16403,
          2681,
          364,
          10225,
          13,
          400,
          550,
          584,
          16403,
          13,
          79,
          1498,
          1349,
          290,
          351,
          11,
          291,
          458,
          11,
          337,
          11,
          337,
          286,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2631156065753687,
        "compression_ratio": 1.5815899581589958,
        "end": 4822.5599999999995,
        "id": 669,
        "no_speech_prob": 3.3596776916056115e-7,
        "seek": 480424,
        "start": 4816.719999999999,
        "temperature": 0,
        "text": " Right. This is now going to work and it should show me a hundred word gifs. But if any one of",
        "tokens": [
          50988,
          1779,
          13,
          639,
          307,
          586,
          516,
          281,
          589,
          293,
          309,
          820,
          855,
          385,
          257,
          3262,
          1349,
          290,
          18290,
          13,
          583,
          498,
          604,
          472,
          295,
          51280
        ]
      },
      {
        "avg_logprob": -0.2631156065753687,
        "compression_ratio": 1.5815899581589958,
        "end": 4828.96,
        "id": 670,
        "no_speech_prob": 3.3596776916056115e-7,
        "seek": 480424,
        "start": 4822.5599999999995,
        "temperature": 0,
        "text": " those words does not have a proper gif associated with it, I'm not going to get anything. So let's",
        "tokens": [
          51280,
          729,
          2283,
          775,
          406,
          362,
          257,
          2296,
          290,
          351,
          6615,
          365,
          309,
          11,
          286,
          478,
          406,
          516,
          281,
          483,
          1340,
          13,
          407,
          718,
          311,
          51600
        ]
      },
      {
        "avg_logprob": -0.2631156065753687,
        "compression_ratio": 1.5815899581589958,
        "end": 4833.44,
        "id": 671,
        "no_speech_prob": 3.3596776916056115e-7,
        "seek": 480424,
        "start": 4828.96,
        "temperature": 0,
        "text": " see. It's doing them all. What this is actually a great exercise now for you to do a loading bar.",
        "tokens": [
          51600,
          536,
          13,
          467,
          311,
          884,
          552,
          439,
          13,
          708,
          341,
          307,
          767,
          257,
          869,
          5380,
          586,
          337,
          291,
          281,
          360,
          257,
          15114,
          2159,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.19889200195785642,
        "compression_ratio": 1.6701388888888888,
        "end": 4839.599999999999,
        "id": 672,
        "no_speech_prob": 0.00023050613526720554,
        "seek": 483344,
        "start": 4834,
        "temperature": 0,
        "text": " Because this takes a while. And actually I got lucky. I guess like all 100 of them worked. But",
        "tokens": [
          50392,
          1436,
          341,
          2516,
          257,
          1339,
          13,
          400,
          767,
          286,
          658,
          6356,
          13,
          286,
          2041,
          411,
          439,
          2319,
          295,
          552,
          2732,
          13,
          583,
          50672
        ]
      },
      {
        "avg_logprob": -0.19889200195785642,
        "compression_ratio": 1.6701388888888888,
        "end": 4843.919999999999,
        "id": 673,
        "no_speech_prob": 0.00023050613526720554,
        "seek": 483344,
        "start": 4839.599999999999,
        "temperature": 0,
        "text": " if I want to see them like appearing as they come in, I want to do them more in parallel. I want to",
        "tokens": [
          50672,
          498,
          286,
          528,
          281,
          536,
          552,
          411,
          19870,
          382,
          436,
          808,
          294,
          11,
          286,
          528,
          281,
          360,
          552,
          544,
          294,
          8952,
          13,
          286,
          528,
          281,
          50888
        ]
      },
      {
        "avg_logprob": -0.19889200195785642,
        "compression_ratio": 1.6701388888888888,
        "end": 4848.48,
        "id": 674,
        "no_speech_prob": 0.00023050613526720554,
        "seek": 483344,
        "start": 4843.919999999999,
        "temperature": 0,
        "text": " sequence them. But hopefully you've seen the range of ideas here. So I'd encourage you to take this",
        "tokens": [
          50888,
          8310,
          552,
          13,
          583,
          4696,
          291,
          600,
          1612,
          264,
          3613,
          295,
          3487,
          510,
          13,
          407,
          286,
          1116,
          5373,
          291,
          281,
          747,
          341,
          51116
        ]
      },
      {
        "avg_logprob": -0.19889200195785642,
        "compression_ratio": 1.6701388888888888,
        "end": 4853.28,
        "id": 675,
        "no_speech_prob": 0.00023050613526720554,
        "seek": 483344,
        "start": 4848.48,
        "temperature": 0,
        "text": " code, play with it, maybe back out of the promise.all thing. What can you add a loading bar?",
        "tokens": [
          51116,
          3089,
          11,
          862,
          365,
          309,
          11,
          1310,
          646,
          484,
          295,
          264,
          6228,
          13,
          336,
          551,
          13,
          708,
          393,
          291,
          909,
          257,
          15114,
          2159,
          30,
          51356
        ]
      },
      {
        "avg_logprob": -0.19889200195785642,
        "compression_ratio": 1.6701388888888888,
        "end": 4861.12,
        "id": 676,
        "no_speech_prob": 0.00023050613526720554,
        "seek": 483344,
        "start": 4853.28,
        "temperature": 0,
        "text": " How can you like load them cleverly and try some other stuff with it? And I also, I think I'm",
        "tokens": [
          51356,
          1012,
          393,
          291,
          411,
          3677,
          552,
          13494,
          356,
          293,
          853,
          512,
          661,
          1507,
          365,
          309,
          30,
          400,
          286,
          611,
          11,
          286,
          519,
          286,
          478,
          51748
        ]
      },
      {
        "avg_logprob": -0.20373001527250484,
        "compression_ratio": 1.5806451612903225,
        "end": 4866.8,
        "id": 677,
        "no_speech_prob": 0.0009697420755401254,
        "seek": 486112,
        "start": 4861.12,
        "temperature": 0,
        "text": " forgetting, I guess I'll do this in another video if I can remember. I also can use try and catch",
        "tokens": [
          50364,
          25428,
          11,
          286,
          2041,
          286,
          603,
          360,
          341,
          294,
          1071,
          960,
          498,
          286,
          393,
          1604,
          13,
          286,
          611,
          393,
          764,
          853,
          293,
          3745,
          50648
        ]
      },
      {
        "avg_logprob": -0.20373001527250484,
        "compression_ratio": 1.5806451612903225,
        "end": 4872.4,
        "id": 678,
        "no_speech_prob": 0.0009697420755401254,
        "seek": 486112,
        "start": 4866.8,
        "temperature": 0,
        "text": " inside of this async function if I want to handle the errors in a slightly more custom way. I think",
        "tokens": [
          50648,
          1854,
          295,
          341,
          382,
          34015,
          2445,
          498,
          286,
          528,
          281,
          4813,
          264,
          13603,
          294,
          257,
          4748,
          544,
          2375,
          636,
          13,
          286,
          519,
          50928
        ]
      },
      {
        "avg_logprob": -0.20373001527250484,
        "compression_ratio": 1.5806451612903225,
        "end": 4876.64,
        "id": 679,
        "no_speech_prob": 0.0009697420755401254,
        "seek": 486112,
        "start": 4872.4,
        "temperature": 0,
        "text": " that's correct. But if that's not correct, eventually I'll make a video about try and catch.",
        "tokens": [
          50928,
          300,
          311,
          3006,
          13,
          583,
          498,
          300,
          311,
          406,
          3006,
          11,
          4728,
          286,
          603,
          652,
          257,
          960,
          466,
          853,
          293,
          3745,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.20373001527250484,
        "compression_ratio": 1.5806451612903225,
        "end": 4880.4,
        "id": 680,
        "no_speech_prob": 0.0009697420755401254,
        "seek": 486112,
        "start": 4877.2,
        "temperature": 0,
        "text": " All right. Thanks for watching this series on, oops.",
        "tokens": [
          51168,
          1057,
          558,
          13,
          2561,
          337,
          1976,
          341,
          2638,
          322,
          11,
          34166,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.33843754077779836,
        "compression_ratio": 1.4210526315789473,
        "end": 4886.48,
        "id": 681,
        "no_speech_prob": 0.010169033892452717,
        "seek": 488040,
        "start": 4880.5599999999995,
        "temperature": 0,
        "text": " Thanks for watching this series on promises. I think I now have made a video tutorial that",
        "tokens": [
          50372,
          2561,
          337,
          1976,
          341,
          2638,
          322,
          16403,
          13,
          286,
          519,
          286,
          586,
          362,
          1027,
          257,
          960,
          7073,
          300,
          50668
        ]
      },
      {
        "avg_logprob": -0.33843754077779836,
        "compression_ratio": 1.4210526315789473,
        "end": 4891.5199999999995,
        "id": 682,
        "no_speech_prob": 0.010169033892452717,
        "seek": 488040,
        "start": 4886.48,
        "temperature": 0,
        "text": " follows this list. Leave me your comments and your questions and all that sort of stuff. And",
        "tokens": [
          50668,
          10002,
          341,
          1329,
          13,
          9825,
          385,
          428,
          3053,
          293,
          428,
          1651,
          293,
          439,
          300,
          1333,
          295,
          1507,
          13,
          400,
          50920
        ]
      },
      {
        "avg_logprob": -0.33843754077779836,
        "compression_ratio": 1.4210526315789473,
        "end": 4901.679999999999,
        "id": 683,
        "no_speech_prob": 0.010169033892452717,
        "seek": 488040,
        "start": 4891.5199999999995,
        "temperature": 0,
        "text": " I'll see you again sometime. Goodbye. All right, everybody.",
        "tokens": [
          50920,
          286,
          603,
          536,
          291,
          797,
          15053,
          13,
          15528,
          13,
          1057,
          558,
          11,
          2201,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.28345311152470576,
        "compression_ratio": 1.4891304347826086,
        "end": 4919.839999999999,
        "id": 684,
        "no_speech_prob": 0.05582229793071747,
        "seek": 491040,
        "start": 4911.04,
        "temperature": 0,
        "text": " Oh, yes. Map. Higher order functions would certainly. But I think that I, I think I stayed",
        "tokens": [
          50396,
          876,
          11,
          2086,
          13,
          22053,
          13,
          31997,
          1668,
          6828,
          576,
          3297,
          13,
          583,
          286,
          519,
          300,
          286,
          11,
          286,
          519,
          286,
          9181,
          50836
        ]
      },
      {
        "avg_logprob": -0.28345311152470576,
        "compression_ratio": 1.4891304347826086,
        "end": 4924.639999999999,
        "id": 685,
        "no_speech_prob": 0.05582229793071747,
        "seek": 491040,
        "start": 4919.839999999999,
        "temperature": 0,
        "text": " in my lane here. Like I was very, I feel like yesterday I went, I didn't, I was, I went off",
        "tokens": [
          50836,
          294,
          452,
          12705,
          510,
          13,
          1743,
          286,
          390,
          588,
          11,
          286,
          841,
          411,
          5186,
          286,
          1437,
          11,
          286,
          994,
          380,
          11,
          286,
          390,
          11,
          286,
          1437,
          766,
          51076
        ]
      },
      {
        "avg_logprob": -0.28345311152470576,
        "compression_ratio": 1.4891304347826086,
        "end": 4930.24,
        "id": 686,
        "no_speech_prob": 0.05582229793071747,
        "seek": 491040,
        "start": 4925.839999999999,
        "temperature": 0,
        "text": " target. And I got to stay in my lane which is like the basics and the fundamental concepts.",
        "tokens": [
          51136,
          3779,
          13,
          400,
          286,
          658,
          281,
          1754,
          294,
          452,
          12705,
          597,
          307,
          411,
          264,
          14688,
          293,
          264,
          8088,
          10392,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.24970436096191406,
        "compression_ratio": 1.2638888888888888,
        "end": 4941.599999999999,
        "id": 687,
        "no_speech_prob": 0.0222858265042305,
        "seek": 493024,
        "start": 4931.2,
        "temperature": 0,
        "text": " And I think to the extent that it's helpful. Yeah. Right. TensorFlow.js. I know. Which is",
        "tokens": [
          50412,
          400,
          286,
          519,
          281,
          264,
          8396,
          300,
          309,
          311,
          4961,
          13,
          865,
          13,
          1779,
          13,
          37624,
          13,
          25530,
          13,
          286,
          458,
          13,
          3013,
          307,
          50932
        ]
      },
      {
        "avg_logprob": -0.24970436096191406,
        "compression_ratio": 1.2638888888888888,
        "end": 4946.4,
        "id": 688,
        "no_speech_prob": 0.0222858265042305,
        "seek": 493024,
        "start": 4941.599999999999,
        "temperature": 0,
        "text": " bad for me to start with this as I'm. So, first of all, I definitely need to get some water.",
        "tokens": [
          50932,
          1578,
          337,
          385,
          281,
          722,
          365,
          341,
          382,
          286,
          478,
          13,
          407,
          11,
          700,
          295,
          439,
          11,
          286,
          2138,
          643,
          281,
          483,
          512,
          1281,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.2411264419555664,
        "compression_ratio": 1.3790849673202614,
        "end": 4952,
        "id": 689,
        "no_speech_prob": 0.033589016646146774,
        "seek": 494640,
        "start": 4947.28,
        "temperature": 0,
        "text": " So, if you don't mind, I am going to leave you.",
        "tokens": [
          50408,
          407,
          11,
          498,
          291,
          500,
          380,
          1575,
          11,
          286,
          669,
          516,
          281,
          1856,
          291,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2411264419555664,
        "compression_ratio": 1.3790849673202614,
        "end": 4964.48,
        "id": 690,
        "no_speech_prob": 0.033589016646146774,
        "seek": 494640,
        "start": 4961.2,
        "temperature": 0,
        "text": " How would I, I was going to like let this go for a long time. But let me.",
        "tokens": [
          51104,
          1012,
          576,
          286,
          11,
          286,
          390,
          516,
          281,
          411,
          718,
          341,
          352,
          337,
          257,
          938,
          565,
          13,
          583,
          718,
          385,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.2411264419555664,
        "compression_ratio": 1.3790849673202614,
        "end": 4973.599999999999,
        "id": 691,
        "no_speech_prob": 0.033589016646146774,
        "seek": 494640,
        "start": 4968.48,
        "temperature": 0,
        "text": " Oh, if I use a try catch on the image URL, you can use promise.all return a no GIF image.",
        "tokens": [
          51468,
          876,
          11,
          498,
          286,
          764,
          257,
          853,
          3745,
          322,
          264,
          3256,
          12905,
          11,
          291,
          393,
          764,
          6228,
          13,
          336,
          2736,
          257,
          572,
          460,
          12775,
          3256,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.34708941777547203,
        "compression_ratio": 1.0555555555555556,
        "end": 4993.200000000001,
        "id": 692,
        "no_speech_prob": 0.022628717124462128,
        "seek": 497360,
        "start": 4973.6,
        "temperature": 0,
        "text": " Right. I see. So, in other words, like this. Let me just try this. Catch. Because maybe I will.",
        "tokens": [
          50400,
          1779,
          13,
          286,
          536,
          13,
          407,
          11,
          294,
          661,
          2283,
          11,
          411,
          341,
          13,
          961,
          385,
          445,
          853,
          341,
          13,
          23869,
          13,
          1436,
          1310,
          286,
          486,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.3737223678165012,
        "compression_ratio": 0.96875,
        "end": 5025.200000000001,
        "id": 693,
        "no_speech_prob": 0.16882072389125824,
        "seek": 500360,
        "start": 5003.6,
        "temperature": 0,
        "text": " So, I just want to experiment with this idea. Would this work?",
        "tokens": [
          50396,
          407,
          11,
          286,
          445,
          528,
          281,
          5120,
          365,
          341,
          1558,
          13,
          6068,
          341,
          589,
          30,
          51444
        ]
      },
      {
        "avg_logprob": -0.5295761915353628,
        "compression_ratio": 1.0416666666666667,
        "end": 5037.200000000001,
        "id": 694,
        "no_speech_prob": 0.04271773621439934,
        "seek": 503360,
        "start": 5034.56,
        "temperature": 0,
        "text": " I think I need to do this.",
        "tokens": [
          50412,
          286,
          519,
          286,
          643,
          281,
          360,
          341,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.5295761915353628,
        "compression_ratio": 1.0416666666666667,
        "end": 5051.200000000001,
        "id": 695,
        "no_speech_prob": 0.04271773621439934,
        "seek": 503360,
        "start": 5046.160000000001,
        "temperature": 0,
        "text": " I'm just going to leave this blank for a second.",
        "tokens": [
          50992,
          286,
          478,
          445,
          516,
          281,
          1856,
          341,
          8247,
          337,
          257,
          1150,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2723674178123474,
        "compression_ratio": 1.3555555555555556,
        "end": 5072.24,
        "id": 696,
        "no_speech_prob": 0.0006263325922191143,
        "seek": 505120,
        "start": 5051.2,
        "temperature": 0,
        "text": " Ah. Interesting. So, that's a great. So, I should really do this. I should add another video.",
        "tokens": [
          50364,
          2438,
          13,
          14711,
          13,
          407,
          11,
          300,
          311,
          257,
          869,
          13,
          407,
          11,
          286,
          820,
          534,
          360,
          341,
          13,
          286,
          820,
          909,
          1071,
          960,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2723674178123474,
        "compression_ratio": 1.3555555555555556,
        "end": 5077.76,
        "id": 697,
        "no_speech_prob": 0.0006263325922191143,
        "seek": 505120,
        "start": 5072.24,
        "temperature": 0,
        "text": " Right. Give me feedback about this. What, is there anything particularly weird about this",
        "tokens": [
          51416,
          1779,
          13,
          5303,
          385,
          5824,
          466,
          341,
          13,
          708,
          11,
          307,
          456,
          1340,
          4098,
          3657,
          466,
          341,
          51692
        ]
      },
      {
        "avg_logprob": -0.43449767860206395,
        "compression_ratio": 1.125,
        "end": 5084.8,
        "id": 698,
        "no_speech_prob": 0.04208620265126228,
        "seek": 507776,
        "start": 5077.76,
        "temperature": 0,
        "text": " that's totally wrong?",
        "tokens": [
          50364,
          300,
          311,
          3879,
          2085,
          30,
          50716
        ]
      },
      {
        "avg_logprob": -0.43449767860206395,
        "compression_ratio": 1.125,
        "end": 5104.16,
        "id": 699,
        "no_speech_prob": 0.04208620265126228,
        "seek": 507776,
        "start": 5098.96,
        "temperature": 0,
        "text": " So, Amr in the chat, the Slack group, asked how is threading handled in JS? What I mean is what",
        "tokens": [
          51424,
          407,
          11,
          2012,
          81,
          294,
          264,
          5081,
          11,
          264,
          37211,
          1594,
          11,
          2351,
          577,
          307,
          7207,
          278,
          18033,
          294,
          33063,
          30,
          708,
          286,
          914,
          307,
          437,
          51684
        ]
      },
      {
        "avg_logprob": -0.2785500762283161,
        "compression_ratio": 1.6050420168067228,
        "end": 5108.16,
        "id": 700,
        "no_speech_prob": 0.027584053575992584,
        "seek": 510416,
        "start": 5104.16,
        "temperature": 0,
        "text": " happens if a variable is shared in more than one promise action? Here's the good news. Good news,",
        "tokens": [
          50364,
          2314,
          498,
          257,
          7006,
          307,
          5507,
          294,
          544,
          813,
          472,
          6228,
          3069,
          30,
          1692,
          311,
          264,
          665,
          2583,
          13,
          2205,
          2583,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.2785500762283161,
        "compression_ratio": 1.6050420168067228,
        "end": 5114.16,
        "id": 701,
        "no_speech_prob": 0.027584053575992584,
        "seek": 510416,
        "start": 5108.16,
        "temperature": 0,
        "text": " bad news. There is no threading in JS. JavaScript is single threaded. So, there is no way to have",
        "tokens": [
          50564,
          1578,
          2583,
          13,
          821,
          307,
          572,
          7207,
          278,
          294,
          33063,
          13,
          15778,
          307,
          2167,
          47493,
          13,
          407,
          11,
          456,
          307,
          572,
          636,
          281,
          362,
          50864
        ]
      },
      {
        "avg_logprob": -0.2785500762283161,
        "compression_ratio": 1.6050420168067228,
        "end": 5118.88,
        "id": 702,
        "no_speech_prob": 0.027584053575992584,
        "seek": 510416,
        "start": 5114.16,
        "temperature": 0,
        "text": " that conflict. And the way this asynchronous stuff works is there's a good article about that that",
        "tokens": [
          50864,
          300,
          6596,
          13,
          400,
          264,
          636,
          341,
          49174,
          1507,
          1985,
          307,
          456,
          311,
          257,
          665,
          7222,
          466,
          300,
          300,
          51100
        ]
      },
      {
        "avg_logprob": -0.2785500762283161,
        "compression_ratio": 1.6050420168067228,
        "end": 5123.36,
        "id": 703,
        "no_speech_prob": 0.027584053575992584,
        "seek": 510416,
        "start": 5118.88,
        "temperature": 0,
        "text": " people have been sharing. Somebody could share it in both chats. That would be helpful.",
        "tokens": [
          51100,
          561,
          362,
          668,
          5414,
          13,
          13463,
          727,
          2073,
          309,
          294,
          1293,
          38057,
          13,
          663,
          576,
          312,
          4961,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.3200965092099946,
        "compression_ratio": 1.4962962962962962,
        "end": 5135.12,
        "id": 704,
        "no_speech_prob": 0.002115665003657341,
        "seek": 512336,
        "start": 5123.36,
        "temperature": 0,
        "text": " Is this how do people feel about this? Should I demonstrate this in a last ditch video that",
        "tokens": [
          50364,
          1119,
          341,
          577,
          360,
          561,
          841,
          466,
          341,
          30,
          6454,
          286,
          11698,
          341,
          294,
          257,
          1036,
          25325,
          960,
          300,
          50952
        ]
      },
      {
        "avg_logprob": -0.3200965092099946,
        "compression_ratio": 1.4962962962962962,
        "end": 5144.88,
        "id": 705,
        "no_speech_prob": 0.002115665003657341,
        "seek": 512336,
        "start": 5135.12,
        "temperature": 0,
        "text": " shows try and catch? Let me go get some water. I'm going to get some water. I'm muting myself.",
        "tokens": [
          50952,
          3110,
          853,
          293,
          3745,
          30,
          961,
          385,
          352,
          483,
          512,
          1281,
          13,
          286,
          478,
          516,
          281,
          483,
          512,
          1281,
          13,
          286,
          478,
          5839,
          278,
          2059,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.3200965092099946,
        "compression_ratio": 1.4962962962962962,
        "end": 5148.32,
        "id": 706,
        "no_speech_prob": 0.002115665003657341,
        "seek": 512336,
        "start": 5147.759999999999,
        "temperature": 0,
        "text": " I'm not muting.",
        "tokens": [
          51584,
          286,
          478,
          406,
          5839,
          278,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.3526947715065696,
        "compression_ratio": 1.2966101694915255,
        "end": 5159.5199999999995,
        "id": 707,
        "no_speech_prob": 0.039038095623254776,
        "seek": 515336,
        "start": 5154.32,
        "temperature": 0,
        "text": " I'll look in the Slack channel when I come back. If there's any good feedback about this code,",
        "tokens": [
          50412,
          286,
          603,
          574,
          294,
          264,
          37211,
          2269,
          562,
          286,
          808,
          646,
          13,
          759,
          456,
          311,
          604,
          665,
          5824,
          466,
          341,
          3089,
          11,
          50672
        ]
      },
      {
        "avg_logprob": -0.3526947715065696,
        "compression_ratio": 1.2966101694915255,
        "end": 5164.88,
        "id": 708,
        "no_speech_prob": 0.039038095623254776,
        "seek": 515336,
        "start": 5159.5199999999995,
        "temperature": 0,
        "text": " put it there and don't chat after it. That's how I see it.",
        "tokens": [
          50672,
          829,
          309,
          456,
          293,
          500,
          380,
          5081,
          934,
          309,
          13,
          663,
          311,
          577,
          286,
          536,
          309,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.9230323791503906,
        "compression_ratio": 0.2727272727272727,
        "end": 5188.88,
        "id": 709,
        "no_speech_prob": 0.9299409985542297,
        "seek": 518336,
        "start": 5183.36,
        "temperature": 0,
        "text": " So,",
        "tokens": [
          50364,
          407,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.29647742377387154,
        "compression_ratio": 1.0217391304347827,
        "end": 5400.88,
        "id": 710,
        "no_speech_prob": 0.0966879278421402,
        "seek": 539336,
        "start": 5394.32,
        "temperature": 0,
        "text": " do.",
        "tokens": [
          50412,
          360,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.29647742377387154,
        "compression_ratio": 1.0217391304347827,
        "end": 5420.639999999999,
        "id": 711,
        "no_speech_prob": 0.0966879278421402,
        "seek": 539336,
        "start": 5414.24,
        "temperature": 0,
        "text": " Okay. Here I am back. So, I've thought about this. It's 1230. I only have until 1 o'clock.",
        "tokens": [
          51408,
          1033,
          13,
          1692,
          286,
          669,
          646,
          13,
          407,
          11,
          286,
          600,
          1194,
          466,
          341,
          13,
          467,
          311,
          2272,
          3446,
          13,
          286,
          787,
          362,
          1826,
          502,
          277,
          6,
          9023,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.21993831025452173,
        "compression_ratio": 1.6753731343283582,
        "end": 5429.36,
        "id": 712,
        "no_speech_prob": 0.0003053482505492866,
        "seek": 542336,
        "start": 5423.92,
        "temperature": 0,
        "text": " I don't think it's wise to try to do the layers API or the TensorFlow.js",
        "tokens": [
          50392,
          286,
          500,
          380,
          519,
          309,
          311,
          10829,
          281,
          853,
          281,
          360,
          264,
          7914,
          9362,
          420,
          264,
          37624,
          13,
          25530,
          50664
        ]
      },
      {
        "avg_logprob": -0.21993831025452173,
        "compression_ratio": 1.6753731343283582,
        "end": 5436.48,
        "id": 713,
        "no_speech_prob": 0.0003053482505492866,
        "seek": 542336,
        "start": 5430,
        "temperature": 0,
        "text": " linear regression example with time pressure and also my brain is starting to melt a little bit.",
        "tokens": [
          50696,
          8213,
          24590,
          1365,
          365,
          565,
          3321,
          293,
          611,
          452,
          3567,
          307,
          2891,
          281,
          10083,
          257,
          707,
          857,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.21993831025452173,
        "compression_ratio": 1.6753731343283582,
        "end": 5442.08,
        "id": 714,
        "no_speech_prob": 0.0003053482505492866,
        "seek": 542336,
        "start": 5436.48,
        "temperature": 0,
        "text": " So, here's the thing. I have good news, bad news. Bad news is I'm going to wrap up soon and I'm",
        "tokens": [
          51020,
          407,
          11,
          510,
          311,
          264,
          551,
          13,
          286,
          362,
          665,
          2583,
          11,
          1578,
          2583,
          13,
          11523,
          2583,
          307,
          286,
          478,
          516,
          281,
          7019,
          493,
          2321,
          293,
          286,
          478,
          51300
        ]
      },
      {
        "avg_logprob": -0.21993831025452173,
        "compression_ratio": 1.6753731343283582,
        "end": 5448.96,
        "id": 715,
        "no_speech_prob": 0.0003053482505492866,
        "seek": 542336,
        "start": 5442.08,
        "temperature": 0,
        "text": " going to not do TensorFlow.js right now. The good news is I'm going to create an event for today",
        "tokens": [
          51300,
          516,
          281,
          406,
          360,
          37624,
          13,
          25530,
          558,
          586,
          13,
          440,
          665,
          2583,
          307,
          286,
          478,
          516,
          281,
          1884,
          364,
          2280,
          337,
          965,
          51644
        ]
      },
      {
        "avg_logprob": -0.21993831025452173,
        "compression_ratio": 1.6753731343283582,
        "end": 5453.2,
        "id": 716,
        "no_speech_prob": 0.0003053482505492866,
        "seek": 542336,
        "start": 5448.96,
        "temperature": 0,
        "text": " and I will come back for an additional hour. I do technically am free between 4 and 5.",
        "tokens": [
          51644,
          293,
          286,
          486,
          808,
          646,
          337,
          364,
          4497,
          1773,
          13,
          286,
          360,
          12120,
          669,
          1737,
          1296,
          1017,
          293,
          1025,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.24843756357828775,
        "compression_ratio": 1.4210526315789473,
        "end": 5461.28,
        "id": 717,
        "no_speech_prob": 0.0009850005153566599,
        "seek": 545336,
        "start": 5454.32,
        "temperature": 0,
        "text": " You can hear me now, right? Okay. So, let me do this right now. Otherwise, I'll change my mind",
        "tokens": [
          50412,
          509,
          393,
          1568,
          385,
          586,
          11,
          558,
          30,
          1033,
          13,
          407,
          11,
          718,
          385,
          360,
          341,
          558,
          586,
          13,
          10328,
          11,
          286,
          603,
          1319,
          452,
          1575,
          50760
        ]
      },
      {
        "avg_logprob": -0.24843756357828775,
        "compression_ratio": 1.4210526315789473,
        "end": 5473.28,
        "id": 718,
        "no_speech_prob": 0.0009850005153566599,
        "seek": 545336,
        "start": 5461.28,
        "temperature": 0,
        "text": " about it after I leave. So, I'm going to creator studio and I'm going to and then I'm going to",
        "tokens": [
          50760,
          466,
          309,
          934,
          286,
          1856,
          13,
          407,
          11,
          286,
          478,
          516,
          281,
          14181,
          6811,
          293,
          286,
          478,
          516,
          281,
          293,
          550,
          286,
          478,
          516,
          281,
          51360
        ]
      },
      {
        "avg_logprob": -0.3300686518351237,
        "compression_ratio": 1.0681818181818181,
        "end": 5486.96,
        "id": 719,
        "no_speech_prob": 0.023689065128564835,
        "seek": 547328,
        "start": 5473.28,
        "temperature": 0,
        "text": " talk about the try catch. I'll do that before I go. Whoops. So, bring back the timer. Hold on.",
        "tokens": [
          50364,
          751,
          466,
          264,
          853,
          3745,
          13,
          286,
          603,
          360,
          300,
          949,
          286,
          352,
          13,
          45263,
          13,
          407,
          11,
          1565,
          646,
          264,
          19247,
          13,
          6962,
          322,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.37062180042266846,
        "compression_ratio": 1.3140495867768596,
        "end": 5492.96,
        "id": 720,
        "no_speech_prob": 0.00591103732585907,
        "seek": 548696,
        "start": 5487.2,
        "temperature": 0,
        "text": " Under events. Ah! Shoot. Live streaming.",
        "tokens": [
          50376,
          6974,
          3931,
          13,
          2438,
          0,
          19760,
          13,
          10385,
          11791,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.37062180042266846,
        "compression_ratio": 1.3140495867768596,
        "end": 5504,
        "id": 721,
        "no_speech_prob": 0.00591103732585907,
        "seek": 548696,
        "start": 5497.12,
        "temperature": 0,
        "text": " Events. So, there is an option to no. New live event.",
        "tokens": [
          50872,
          45314,
          13,
          407,
          11,
          456,
          307,
          364,
          3614,
          281,
          572,
          13,
          1873,
          1621,
          2280,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.37062180042266846,
        "compression_ratio": 1.3140495867768596,
        "end": 5509.44,
        "id": 722,
        "no_speech_prob": 0.00591103732585907,
        "seek": 548696,
        "start": 5506.4,
        "temperature": 0,
        "text": " I want to create a new event from the settings of the other one.",
        "tokens": [
          51336,
          286,
          528,
          281,
          1884,
          257,
          777,
          2280,
          490,
          264,
          6257,
          295,
          264,
          661,
          472,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.40922877367805033,
        "compression_ratio": 1.118279569892473,
        "end": 5517.2,
        "id": 723,
        "no_speech_prob": 0.05749248340725899,
        "seek": 550944,
        "start": 5510.4,
        "temperature": 0,
        "text": " I saw that option once in YouTube. Maybe I can't do that one that's actually live.",
        "tokens": [
          50412,
          286,
          1866,
          300,
          3614,
          1564,
          294,
          3088,
          13,
          2704,
          286,
          393,
          380,
          360,
          300,
          472,
          300,
          311,
          767,
          1621,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.40922877367805033,
        "compression_ratio": 1.118279569892473,
        "end": 5528.32,
        "id": 724,
        "no_speech_prob": 0.05749248340725899,
        "seek": 550944,
        "start": 5526.879999999999,
        "temperature": 0,
        "text": " I'll, you know, okay.",
        "tokens": [
          51236,
          286,
          603,
          11,
          291,
          458,
          11,
          1392,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.5884822845458985,
        "compression_ratio": 0.813953488372093,
        "end": 5535.2,
        "id": 725,
        "no_speech_prob": 0.3380463719367981,
        "seek": 552832,
        "start": 5528.32,
        "temperature": 0,
        "text": " I'm just going to do it here. Okay.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          360,
          309,
          510,
          13,
          1033,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.7146698633829752,
        "compression_ratio": 0.38461538461538464,
        "end": 5536.08,
        "id": 726,
        "no_speech_prob": 0.191908597946167,
        "seek": 553520,
        "start": 5535.2,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50408
        ]
      },
      {
        "avg_logprob": -0.5500960350036621,
        "compression_ratio": 1.0344827586206897,
        "end": 5538.96,
        "id": 727,
        "no_speech_prob": 0.2941593527793884,
        "seek": 553608,
        "start": 5536.96,
        "temperature": 0,
        "text": " Um...",
        "tokens": [
          50408,
          3301,
          485,
          50508
        ]
      },
      {
        "avg_logprob": -0.5500960350036621,
        "compression_ratio": 1.0344827586206897,
        "end": 5565.5199999999995,
        "id": 728,
        "no_speech_prob": 0.2941593527793884,
        "seek": 553608,
        "start": 5550.8,
        "temperature": 0,
        "text": " I promise you today 4pm Eastern end time 5pm. I'm like a live streaming addict here.",
        "tokens": [
          51100,
          286,
          6228,
          291,
          965,
          1017,
          14395,
          12901,
          917,
          565,
          1025,
          14395,
          13,
          286,
          478,
          411,
          257,
          1621,
          11791,
          22072,
          510,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.3667213284239477,
        "compression_ratio": 1.2661870503597121,
        "end": 5571.2,
        "id": 729,
        "no_speech_prob": 0.0035934848710894585,
        "seek": 556608,
        "start": 5566.5599999999995,
        "temperature": 0,
        "text": " Public advanced settings. Enable slow mode.",
        "tokens": [
          50388,
          9489,
          7339,
          6257,
          13,
          2193,
          712,
          2964,
          4391,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.3667213284239477,
        "compression_ratio": 1.2661870503597121,
        "end": 5580.4,
        "id": 730,
        "no_speech_prob": 0.0035934848710894585,
        "seek": 556608,
        "start": 5575.04,
        "temperature": 0,
        "text": " Video. Recording date. Language is English.",
        "tokens": [
          50812,
          9777,
          13,
          9647,
          3357,
          4002,
          13,
          24445,
          307,
          3669,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.3667213284239477,
        "compression_ratio": 1.2661870503597121,
        "end": 5594.4,
        "id": 731,
        "no_speech_prob": 0.0035934848710894585,
        "seek": 556608,
        "start": 5589.92,
        "temperature": 0,
        "text": " Where's the one where it says, like, I guess I can fix this. Make this archive unlisted.",
        "tokens": [
          51556,
          2305,
          311,
          264,
          472,
          689,
          309,
          1619,
          11,
          411,
          11,
          286,
          2041,
          286,
          393,
          3191,
          341,
          13,
          4387,
          341,
          23507,
          517,
          34890,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.28725558636235254,
        "compression_ratio": 1.3025210084033614,
        "end": 5600.88,
        "id": 732,
        "no_speech_prob": 0.0008969117770902812,
        "seek": 559608,
        "start": 5596.88,
        "temperature": 0,
        "text": " So, create event.",
        "tokens": [
          50404,
          407,
          11,
          1884,
          2280,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.28725558636235254,
        "compression_ratio": 1.3025210084033614,
        "end": 5613.44,
        "id": 733,
        "no_speech_prob": 0.0008969117770902812,
        "seek": 559608,
        "start": 5607.68,
        "temperature": 0,
        "text": " So, I guess I can take off this back in five minutes thing. So, there should be now,",
        "tokens": [
          50944,
          407,
          11,
          286,
          2041,
          286,
          393,
          747,
          766,
          341,
          646,
          294,
          1732,
          2077,
          551,
          13,
          407,
          11,
          456,
          820,
          312,
          586,
          11,
          51232
        ]
      },
      {
        "avg_logprob": -0.28725558636235254,
        "compression_ratio": 1.3025210084033614,
        "end": 5621.2,
        "id": 734,
        "no_speech_prob": 0.0008969117770902812,
        "seek": 559608,
        "start": 5615.44,
        "temperature": 0,
        "text": " if I go to, oh, not here. YouTube, the coding train.",
        "tokens": [
          51332,
          498,
          286,
          352,
          281,
          11,
          1954,
          11,
          406,
          510,
          13,
          3088,
          11,
          264,
          17720,
          3847,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.469629370647928,
        "compression_ratio": 1.3609467455621302,
        "end": 5629.04,
        "id": 735,
        "no_speech_prob": 0.00006922177999513224,
        "seek": 562120,
        "start": 5621.36,
        "temperature": 0,
        "text": " I say 1pm. Ugh. That's not right. Info and settings.",
        "tokens": [
          50372,
          286,
          584,
          502,
          14395,
          13,
          16506,
          13,
          663,
          311,
          406,
          558,
          13,
          11537,
          78,
          293,
          6257,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.469629370647928,
        "compression_ratio": 1.3609467455621302,
        "end": 5641.679999999999,
        "id": 736,
        "no_speech_prob": 0.00006922177999513224,
        "seek": 562120,
        "start": 5632.32,
        "temperature": 0,
        "text": " 4pm to 5pm Eastern. I guess maybe my YouTube thinks I'm in Pacific time because that's 1pm",
        "tokens": [
          50920,
          1017,
          14395,
          281,
          1025,
          14395,
          12901,
          13,
          286,
          2041,
          1310,
          452,
          3088,
          7309,
          286,
          478,
          294,
          13335,
          565,
          570,
          300,
          311,
          502,
          14395,
          51388
        ]
      },
      {
        "avg_logprob": -0.469629370647928,
        "compression_ratio": 1.3609467455621302,
        "end": 5647.2,
        "id": 737,
        "no_speech_prob": 0.00006922177999513224,
        "seek": 562120,
        "start": 5641.679999999999,
        "temperature": 0,
        "text": " Pacific time. It definitely says here in the page. But anyway, I'm going to come back.",
        "tokens": [
          51388,
          13335,
          565,
          13,
          467,
          2138,
          1619,
          510,
          294,
          264,
          3028,
          13,
          583,
          4033,
          11,
          286,
          478,
          516,
          281,
          808,
          646,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.45355383863726867,
        "compression_ratio": 1.6853448275862069,
        "end": 5652.32,
        "id": 738,
        "no_speech_prob": 0.003884402336552739,
        "seek": 564720,
        "start": 5647.76,
        "temperature": 0,
        "text": " By the way, in case you want to know to get a notification when this actually happens,",
        "tokens": [
          50392,
          3146,
          264,
          636,
          11,
          294,
          1389,
          291,
          528,
          281,
          458,
          281,
          483,
          257,
          11554,
          562,
          341,
          767,
          2314,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.45355383863726867,
        "compression_ratio": 1.6853448275862069,
        "end": 5657.76,
        "id": 739,
        "no_speech_prob": 0.003884402336552739,
        "seek": 564720,
        "start": 5653.5199999999995,
        "temperature": 0,
        "text": " you should I guess this is I'm logged in as myself. I can't click subscribe.",
        "tokens": [
          50680,
          291,
          820,
          286,
          2041,
          341,
          307,
          286,
          478,
          27231,
          294,
          382,
          2059,
          13,
          286,
          393,
          380,
          2052,
          3022,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.45355383863726867,
        "compression_ratio": 1.6853448275862069,
        "end": 5661.76,
        "id": 740,
        "no_speech_prob": 0.003884402336552739,
        "seek": 564720,
        "start": 5658.32,
        "temperature": 0,
        "text": " Somewhere here you can click subscribe. You can click submit reminder.",
        "tokens": [
          50920,
          34500,
          510,
          291,
          393,
          2052,
          3022,
          13,
          509,
          393,
          2052,
          10315,
          13548,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.45355383863726867,
        "compression_ratio": 1.6853448275862069,
        "end": 5668.24,
        "id": 741,
        "no_speech_prob": 0.003884402336552739,
        "seek": 564720,
        "start": 5663.2,
        "temperature": 0,
        "text": " There's a way for me to view as something. But whatever. Let me just go to I'm just curious.",
        "tokens": [
          51164,
          821,
          311,
          257,
          636,
          337,
          385,
          281,
          1910,
          382,
          746,
          13,
          583,
          2035,
          13,
          961,
          385,
          445,
          352,
          281,
          286,
          478,
          445,
          6369,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.45355383863726867,
        "compression_ratio": 1.6853448275862069,
        "end": 5671.679999999999,
        "id": 742,
        "no_speech_prob": 0.003884402336552739,
        "seek": 564720,
        "start": 5668.24,
        "temperature": 0,
        "text": " I'm just curious what does this look like if I'm not logged in.",
        "tokens": [
          51416,
          286,
          478,
          445,
          6369,
          437,
          775,
          341,
          574,
          411,
          498,
          286,
          478,
          406,
          27231,
          294,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.6534742325071304,
        "compression_ratio": 1.5298507462686568,
        "end": 5678.56,
        "id": 743,
        "no_speech_prob": 0.007345680613070726,
        "seek": 567168,
        "start": 5672.240000000001,
        "temperature": 0,
        "text": " So, yeah. Sponsor, subscribe, alarm bell and set reminder. This is going to happen later.",
        "tokens": [
          50392,
          407,
          11,
          1338,
          13,
          1738,
          892,
          284,
          11,
          3022,
          11,
          14183,
          4549,
          293,
          992,
          13548,
          13,
          639,
          307,
          516,
          281,
          1051,
          1780,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.6534742325071304,
        "compression_ratio": 1.5298507462686568,
        "end": 5687.4400000000005,
        "id": 744,
        "no_speech_prob": 0.007345680613070726,
        "seek": 567168,
        "start": 5680.56,
        "temperature": 0,
        "text": " Now, go back to the code. Let me go back to the Slack channel.",
        "tokens": [
          50808,
          823,
          11,
          352,
          646,
          281,
          264,
          3089,
          13,
          961,
          385,
          352,
          646,
          281,
          264,
          37211,
          2269,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.6534742325071304,
        "compression_ratio": 1.5298507462686568,
        "end": 5695.04,
        "id": 745,
        "no_speech_prob": 0.007345680613070726,
        "seek": 567168,
        "start": 5689.4400000000005,
        "temperature": 0,
        "text": " Okay. So, I'm going to go back to the Slack channel.",
        "tokens": [
          51252,
          1033,
          13,
          407,
          11,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          37211,
          2269,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.27923284530639647,
        "compression_ratio": 1.5165289256198347,
        "end": 5704.08,
        "id": 746,
        "no_speech_prob": 0.026759006083011627,
        "seek": 569504,
        "start": 5695.84,
        "temperature": 0,
        "text": " Let me go back to the Slack channel. Okay. So, I'm going to read through this comment.",
        "tokens": [
          50404,
          961,
          385,
          352,
          646,
          281,
          264,
          37211,
          2269,
          13,
          1033,
          13,
          407,
          11,
          286,
          478,
          516,
          281,
          1401,
          807,
          341,
          2871,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.27923284530639647,
        "compression_ratio": 1.5165289256198347,
        "end": 5707.68,
        "id": 747,
        "no_speech_prob": 0.026759006083011627,
        "seek": 569504,
        "start": 5704.08,
        "temperature": 0,
        "text": " Only one bit of code is ever executed at once. So, in synchronous lines of code,",
        "tokens": [
          50816,
          5686,
          472,
          857,
          295,
          3089,
          307,
          1562,
          17577,
          412,
          1564,
          13,
          407,
          11,
          294,
          44743,
          3876,
          295,
          3089,
          11,
          50996
        ]
      },
      {
        "avg_logprob": -0.27923284530639647,
        "compression_ratio": 1.5165289256198347,
        "end": 5712.88,
        "id": 748,
        "no_speech_prob": 0.026759006083011627,
        "seek": 569504,
        "start": 5707.68,
        "temperature": 0,
        "text": " you can oh, yeah, that's the answer to that other question. Madden writes I would put let image URL",
        "tokens": [
          50996,
          291,
          393,
          1954,
          11,
          1338,
          11,
          300,
          311,
          264,
          1867,
          281,
          300,
          661,
          1168,
          13,
          5326,
          1556,
          13657,
          286,
          576,
          829,
          718,
          3256,
          12905,
          51256
        ]
      },
      {
        "avg_logprob": -0.27923284530639647,
        "compression_ratio": 1.5165289256198347,
        "end": 5719.12,
        "id": 749,
        "no_speech_prob": 0.026759006083011627,
        "seek": 569504,
        "start": 5712.88,
        "temperature": 0,
        "text": " equal no image and have the catch just for logging the error. Yes. That's a good idea. I like that.",
        "tokens": [
          51256,
          2681,
          572,
          3256,
          293,
          362,
          264,
          3745,
          445,
          337,
          27991,
          264,
          6713,
          13,
          1079,
          13,
          663,
          311,
          257,
          665,
          1558,
          13,
          286,
          411,
          300,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.28020043806596234,
        "compression_ratio": 1.4052287581699345,
        "end": 5725.28,
        "id": 750,
        "no_speech_prob": 0.000351438153302297,
        "seek": 571912,
        "start": 5719.12,
        "temperature": 0,
        "text": " You can also catch on the promise return from word GIF which might make more sense from an",
        "tokens": [
          50364,
          509,
          393,
          611,
          3745,
          322,
          264,
          6228,
          2736,
          490,
          1349,
          460,
          12775,
          597,
          1062,
          652,
          544,
          2020,
          490,
          364,
          50672
        ]
      },
      {
        "avg_logprob": -0.28020043806596234,
        "compression_ratio": 1.4052287581699345,
        "end": 5734.5599999999995,
        "id": 751,
        "no_speech_prob": 0.000351438153302297,
        "seek": 571912,
        "start": 5725.28,
        "temperature": 0,
        "text": " error catching standpoint. Oh, you mean like catch it here?",
        "tokens": [
          50672,
          6713,
          16124,
          15827,
          13,
          876,
          11,
          291,
          914,
          411,
          3745,
          309,
          510,
          30,
          51136
        ]
      },
      {
        "avg_logprob": -0.28020043806596234,
        "compression_ratio": 1.4052287581699345,
        "end": 5743.2,
        "id": 752,
        "no_speech_prob": 0.000351438153302297,
        "seek": 571912,
        "start": 5740.16,
        "temperature": 0,
        "text": " Like actually put a catch here and then not add it to the array?",
        "tokens": [
          51416,
          1743,
          767,
          829,
          257,
          3745,
          510,
          293,
          550,
          406,
          909,
          309,
          281,
          264,
          10225,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.3745062828063965,
        "compression_ratio": 1.1964285714285714,
        "end": 5750.08,
        "id": 753,
        "no_speech_prob": 0.0005527780740521848,
        "seek": 574320,
        "start": 5743.679999999999,
        "temperature": 0,
        "text": " Okay. But that feels confusing. Also, you need to do catch E with a",
        "tokens": [
          50388,
          1033,
          13,
          583,
          300,
          3417,
          13181,
          13,
          2743,
          11,
          291,
          643,
          281,
          360,
          3745,
          462,
          365,
          257,
          50708
        ]
      },
      {
        "avg_logprob": -0.3745062828063965,
        "compression_ratio": 1.1964285714285714,
        "end": 5756.32,
        "id": 754,
        "no_speech_prob": 0.0005527780740521848,
        "seek": 574320,
        "start": 5753.28,
        "temperature": 0,
        "text": " catch without an argument. So, this",
        "tokens": [
          50868,
          3745,
          1553,
          364,
          6770,
          13,
          407,
          11,
          341,
          51020
        ]
      },
      {
        "avg_logprob": -0.3745062828063965,
        "compression_ratio": 1.1964285714285714,
        "end": 5765.679999999999,
        "id": 755,
        "no_speech_prob": 0.0005527780740521848,
        "seek": 574320,
        "start": 5762.24,
        "temperature": 0,
        "text": " I kind of like this idea also.",
        "tokens": [
          51316,
          286,
          733,
          295,
          411,
          341,
          1558,
          611,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.25477237701416017,
        "compression_ratio": 1.1071428571428572,
        "end": 5776.639999999999,
        "id": 756,
        "no_speech_prob": 0.004133881069719791,
        "seek": 577320,
        "start": 5774.08,
        "temperature": 0,
        "text": " Let me just try this.",
        "tokens": [
          50408,
          961,
          385,
          445,
          853,
          341,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.25477237701416017,
        "compression_ratio": 1.1071428571428572,
        "end": 5786.639999999999,
        "id": 757,
        "no_speech_prob": 0.004133881069719791,
        "seek": 577320,
        "start": 5783.679999999999,
        "temperature": 0,
        "text": " Oh, right. That's right. That's the error. Okay.",
        "tokens": [
          50888,
          876,
          11,
          558,
          13,
          663,
          311,
          558,
          13,
          663,
          311,
          264,
          6713,
          13,
          1033,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.25477237701416017,
        "compression_ratio": 1.1071428571428572,
        "end": 5795.679999999999,
        "id": 758,
        "no_speech_prob": 0.004133881069719791,
        "seek": 577320,
        "start": 5793.76,
        "temperature": 0,
        "text": " No image for this GIF.",
        "tokens": [
          51392,
          883,
          3256,
          337,
          341,
          460,
          12775,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.21202571575458234,
        "compression_ratio": 1.4010695187165776,
        "end": 5813.04,
        "id": 759,
        "no_speech_prob": 0.0005976689280942082,
        "seek": 580320,
        "start": 5803.76,
        "temperature": 0,
        "text": " Great. Okay. So, this makes sense. I'm going to do it this way for simplicity",
        "tokens": [
          50392,
          3769,
          13,
          1033,
          13,
          407,
          11,
          341,
          1669,
          2020,
          13,
          286,
          478,
          516,
          281,
          360,
          309,
          341,
          636,
          337,
          25632,
          50856
        ]
      },
      {
        "avg_logprob": -0.21202571575458234,
        "compression_ratio": 1.4010695187165776,
        "end": 5821.92,
        "id": 760,
        "no_speech_prob": 0.0005976689280942082,
        "seek": 580320,
        "start": 5813.04,
        "temperature": 0,
        "text": " because I don't want to muck with this up here. Hey, just in time, coding garden with CJ is on",
        "tokens": [
          50856,
          570,
          286,
          500,
          380,
          528,
          281,
          275,
          1134,
          365,
          341,
          493,
          510,
          13,
          1911,
          11,
          445,
          294,
          565,
          11,
          17720,
          7431,
          365,
          42285,
          307,
          322,
          51300
        ]
      },
      {
        "avg_logprob": -0.21202571575458234,
        "compression_ratio": 1.4010695187165776,
        "end": 5826.72,
        "id": 761,
        "no_speech_prob": 0.0005976689280942082,
        "seek": 580320,
        "start": 5821.92,
        "temperature": 0,
        "text": " now. So, when I leave, you can go watch that. It's a YouTube channel. I subscribe to you.",
        "tokens": [
          51300,
          586,
          13,
          407,
          11,
          562,
          286,
          1856,
          11,
          291,
          393,
          352,
          1159,
          300,
          13,
          467,
          311,
          257,
          3088,
          2269,
          13,
          286,
          3022,
          281,
          291,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.24879400079900568,
        "compression_ratio": 1.375,
        "end": 5829.76,
        "id": 762,
        "no_speech_prob": 0.003593596164137125,
        "seek": 582672,
        "start": 5827.280000000001,
        "temperature": 0,
        "text": " I have some more water. All right.",
        "tokens": [
          50392,
          286,
          362,
          512,
          544,
          1281,
          13,
          1057,
          558,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.24879400079900568,
        "compression_ratio": 1.375,
        "end": 5844.56,
        "id": 763,
        "no_speech_prob": 0.003593596164137125,
        "seek": 582672,
        "start": 5841.280000000001,
        "temperature": 0,
        "text": " All right. I'm going to do it my way even though there's other ways of doing it.",
        "tokens": [
          51092,
          1057,
          558,
          13,
          286,
          478,
          516,
          281,
          360,
          309,
          452,
          636,
          754,
          1673,
          456,
          311,
          661,
          2098,
          295,
          884,
          309,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.24879400079900568,
        "compression_ratio": 1.375,
        "end": 5850,
        "id": 764,
        "no_speech_prob": 0.003593596164137125,
        "seek": 582672,
        "start": 5846.320000000001,
        "temperature": 0,
        "text": " So, now what I want to do is go out of this and put it back.",
        "tokens": [
          51344,
          407,
          11,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          352,
          484,
          295,
          341,
          293,
          829,
          309,
          646,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2651521487113757,
        "compression_ratio": 1.3425925925925926,
        "end": 5860,
        "id": 765,
        "no_speech_prob": 0.0008426412823610008,
        "seek": 585672,
        "start": 5857.04,
        "temperature": 0,
        "text": " Maybe I'll mention the what was that thing called again?",
        "tokens": [
          50380,
          2704,
          286,
          603,
          2152,
          264,
          437,
          390,
          300,
          551,
          1219,
          797,
          30,
          50528
        ]
      },
      {
        "avg_logprob": -0.2651521487113757,
        "compression_ratio": 1.3425925925925926,
        "end": 5881.04,
        "id": 766,
        "no_speech_prob": 0.0008426412823610008,
        "seek": 585672,
        "start": 5875.04,
        "temperature": 0,
        "text": " What was that thing called when see this is why I can't do the TensorFlow.js videos now.",
        "tokens": [
          51280,
          708,
          390,
          300,
          551,
          1219,
          562,
          536,
          341,
          307,
          983,
          286,
          393,
          380,
          360,
          264,
          37624,
          13,
          25530,
          2145,
          586,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.39056215967450825,
        "compression_ratio": 1.1590909090909092,
        "end": 5885.28,
        "id": 767,
        "no_speech_prob": 0.0008167362539097667,
        "seek": 588104,
        "start": 5881.92,
        "temperature": 0,
        "text": " Enhanced object literal or something. Oh, yeah.",
        "tokens": [
          50408,
          2193,
          3451,
          1232,
          2657,
          20411,
          420,
          746,
          13,
          876,
          11,
          1338,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.39056215967450825,
        "compression_ratio": 1.1590909090909092,
        "end": 5894.32,
        "id": 768,
        "no_speech_prob": 0.0008167362539097667,
        "seek": 588104,
        "start": 5891.04,
        "temperature": 0,
        "text": " Is there a documentation on the Mozilla documentation?",
        "tokens": [
          50864,
          1119,
          456,
          257,
          14333,
          322,
          264,
          3335,
          26403,
          14333,
          30,
          51028
        ]
      },
      {
        "avg_logprob": -0.6049331029256185,
        "compression_ratio": 0.8461538461538461,
        "end": 5895.599999999999,
        "id": 769,
        "no_speech_prob": 0.14996075630187988,
        "seek": 589432,
        "start": 5894.32,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.6049331029256185,
        "compression_ratio": 0.8461538461538461,
        "end": 5910.639999999999,
        "id": 770,
        "no_speech_prob": 0.14996075630187988,
        "seek": 589432,
        "start": 5909.36,
        "temperature": 0,
        "text": " Yeah, this is the enhanced.",
        "tokens": [
          51116,
          865,
          11,
          341,
          307,
          264,
          21191,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.28774521085951066,
        "compression_ratio": 1.2906976744186047,
        "end": 5931.280000000001,
        "id": 771,
        "no_speech_prob": 0.06559988111257553,
        "seek": 591064,
        "start": 5910.64,
        "temperature": 0,
        "text": " Okay. All right. All right. Oh, property is null. Yeah, I agree. I agree with that. Okay.",
        "tokens": [
          50364,
          1033,
          13,
          1057,
          558,
          13,
          1057,
          558,
          13,
          876,
          11,
          4707,
          307,
          18184,
          13,
          865,
          11,
          286,
          3986,
          13,
          286,
          3986,
          365,
          300,
          13,
          1033,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.28774521085951066,
        "compression_ratio": 1.2906976744186047,
        "end": 5935.52,
        "id": 772,
        "no_speech_prob": 0.06559988111257553,
        "seek": 591064,
        "start": 5934.64,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          51564,
          1057,
          558,
          11,
          2201,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.2692230224609375,
        "compression_ratio": 1.36875,
        "end": 5943.200000000001,
        "id": 773,
        "no_speech_prob": 0.0007672900101169944,
        "seek": 594064,
        "start": 5941.6,
        "temperature": 0,
        "text": " I think I'm good, right?",
        "tokens": [
          50412,
          286,
          519,
          286,
          478,
          665,
          11,
          558,
          30,
          50492
        ]
      },
      {
        "avg_logprob": -0.2692230224609375,
        "compression_ratio": 1.36875,
        "end": 5962.240000000001,
        "id": 774,
        "no_speech_prob": 0.0007672900101169944,
        "seek": 594064,
        "start": 5952.240000000001,
        "temperature": 0,
        "text": " All right. Okay. All right. Here we go, everybody. Let me recycle the cameras. This is going to be",
        "tokens": [
          50944,
          1057,
          558,
          13,
          1033,
          13,
          1057,
          558,
          13,
          1692,
          321,
          352,
          11,
          2201,
          13,
          961,
          385,
          32162,
          264,
          8622,
          13,
          639,
          307,
          516,
          281,
          312,
          51444
        ]
      },
      {
        "avg_logprob": -0.2692230224609375,
        "compression_ratio": 1.36875,
        "end": 5967.12,
        "id": 775,
        "no_speech_prob": 0.0007672900101169944,
        "seek": 594064,
        "start": 5962.240000000001,
        "temperature": 0,
        "text": " the last thing for today because I have run out of steam and somehow I committed to coming back",
        "tokens": [
          51444,
          264,
          1036,
          551,
          337,
          965,
          570,
          286,
          362,
          1190,
          484,
          295,
          11952,
          293,
          6063,
          286,
          7784,
          281,
          1348,
          646,
          51688
        ]
      },
      {
        "avg_logprob": -0.2705237914104851,
        "compression_ratio": 1.2797202797202798,
        "end": 5976.88,
        "id": 776,
        "no_speech_prob": 0.038463886827230453,
        "seek": 596712,
        "start": 5967.12,
        "temperature": 0,
        "text": " for an hour to do something on TensorFlow.js. That was a bad idea. Maybe I'll get a few new",
        "tokens": [
          50364,
          337,
          364,
          1773,
          281,
          360,
          746,
          322,
          37624,
          13,
          25530,
          13,
          663,
          390,
          257,
          1578,
          1558,
          13,
          2704,
          286,
          603,
          483,
          257,
          1326,
          777,
          50852
        ]
      },
      {
        "avg_logprob": -0.2705237914104851,
        "compression_ratio": 1.2797202797202798,
        "end": 5984.48,
        "id": 777,
        "no_speech_prob": 0.038463886827230453,
        "seek": 596712,
        "start": 5976.88,
        "temperature": 0,
        "text": " sponsors this afternoon for doing the extra effort. Okay. Marin is right about line 28 now.",
        "tokens": [
          50852,
          22593,
          341,
          6499,
          337,
          884,
          264,
          2857,
          4630,
          13,
          1033,
          13,
          43016,
          307,
          558,
          466,
          1622,
          7562,
          586,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.31979320049285886,
        "compression_ratio": 0.8431372549019608,
        "end": 5999.12,
        "id": 778,
        "no_speech_prob": 0.134739950299263,
        "seek": 598448,
        "start": 5984.48,
        "temperature": 0,
        "text": " Huh? Oh, yeah. Thank you. 26. Got it. Okay.",
        "tokens": [
          50364,
          8063,
          30,
          876,
          11,
          1338,
          13,
          1044,
          291,
          13,
          7551,
          13,
          5803,
          309,
          13,
          1033,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.5363764762878418,
        "compression_ratio": 0.5555555555555556,
        "end": 6009.76,
        "id": 779,
        "no_speech_prob": 0.22536325454711914,
        "seek": 599912,
        "start": 5999.12,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.462325382232666,
        "compression_ratio": 0.7894736842105263,
        "end": 6027.76,
        "id": 780,
        "no_speech_prob": 0.11918826401233673,
        "seek": 600976,
        "start": 6009.76,
        "temperature": 0,
        "text": " Oh, it can't be zero. Let's do",
        "tokens": [
          50364,
          876,
          11,
          309,
          393,
          380,
          312,
          4018,
          13,
          961,
          311,
          360,
          51264
        ]
      },
      {
        "avg_logprob": -0.31202281605113635,
        "compression_ratio": 1.3381294964028776,
        "end": 6042.72,
        "id": 781,
        "no_speech_prob": 0.05834389105439186,
        "seek": 602776,
        "start": 6028,
        "temperature": 0,
        "text": " a... All right. Here we go. I feel sleepy. I need to eat lunch. I'm getting a little tired.",
        "tokens": [
          50376,
          257,
          485,
          1057,
          558,
          13,
          1692,
          321,
          352,
          13,
          286,
          841,
          24908,
          13,
          286,
          643,
          281,
          1862,
          6349,
          13,
          286,
          478,
          1242,
          257,
          707,
          5868,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.31202281605113635,
        "compression_ratio": 1.3381294964028776,
        "end": 6052.56,
        "id": 782,
        "no_speech_prob": 0.05834389105439186,
        "seek": 602776,
        "start": 6047.76,
        "temperature": 0,
        "text": " Just when you thought it was safe to go back in the water, the swim with the promises. I don't",
        "tokens": [
          51364,
          1449,
          562,
          291,
          1194,
          309,
          390,
          3273,
          281,
          352,
          646,
          294,
          264,
          1281,
          11,
          264,
          7110,
          365,
          264,
          16403,
          13,
          286,
          500,
          380,
          51604
        ]
      },
      {
        "avg_logprob": -0.21143224615799752,
        "compression_ratio": 1.628099173553719,
        "end": 6057.92,
        "id": 783,
        "no_speech_prob": 0.012431511655449867,
        "seek": 605256,
        "start": 6052.56,
        "temperature": 0,
        "text": " know. Anyway, I do want to add something to this list. You're watching this. There's another video",
        "tokens": [
          50364,
          458,
          13,
          5684,
          11,
          286,
          360,
          528,
          281,
          909,
          746,
          281,
          341,
          1329,
          13,
          509,
          434,
          1976,
          341,
          13,
          821,
          311,
          1071,
          960,
          50632
        ]
      },
      {
        "avg_logprob": -0.21143224615799752,
        "compression_ratio": 1.628099173553719,
        "end": 6064.160000000001,
        "id": 784,
        "no_speech_prob": 0.012431511655449867,
        "seek": 605256,
        "start": 6057.92,
        "temperature": 0,
        "text": " here. I want to talk just really quickly and show you one thing about try and catch. If you remember",
        "tokens": [
          50632,
          510,
          13,
          286,
          528,
          281,
          751,
          445,
          534,
          2661,
          293,
          855,
          291,
          472,
          551,
          466,
          853,
          293,
          3745,
          13,
          759,
          291,
          1604,
          50944
        ]
      },
      {
        "avg_logprob": -0.21143224615799752,
        "compression_ratio": 1.628099173553719,
        "end": 6071.68,
        "id": 785,
        "no_speech_prob": 0.012431511655449867,
        "seek": 605256,
        "start": 6064.160000000001,
        "temperature": 0,
        "text": " where I left off with promise.all, what I had is I have this particular... I kind of made some",
        "tokens": [
          50944,
          689,
          286,
          1411,
          766,
          365,
          6228,
          13,
          336,
          11,
          437,
          286,
          632,
          307,
          286,
          362,
          341,
          1729,
          485,
          286,
          733,
          295,
          1027,
          512,
          51320
        ]
      },
      {
        "avg_logprob": -0.21143224615799752,
        "compression_ratio": 1.628099173553719,
        "end": 6078.96,
        "id": 786,
        "no_speech_prob": 0.012431511655449867,
        "seek": 605256,
        "start": 6071.68,
        "temperature": 0,
        "text": " modifications in between the last video and this one, but I have this particular JavaScript program",
        "tokens": [
          51320,
          26881,
          294,
          1296,
          264,
          1036,
          960,
          293,
          341,
          472,
          11,
          457,
          286,
          362,
          341,
          1729,
          15778,
          1461,
          51684
        ]
      },
      {
        "avg_logprob": -0.25955335058347145,
        "compression_ratio": 1.5506072874493928,
        "end": 6086.16,
        "id": 787,
        "no_speech_prob": 0.00016093069280032068,
        "seek": 607896,
        "start": 6078.96,
        "temperature": 0,
        "text": " using the p5.js library that makes a bunch of calls to Wordnik and the Giphy API. When everything",
        "tokens": [
          50364,
          1228,
          264,
          280,
          20,
          13,
          25530,
          6405,
          300,
          1669,
          257,
          3840,
          295,
          5498,
          281,
          8725,
          13123,
          293,
          264,
          460,
          647,
          3495,
          9362,
          13,
          1133,
          1203,
          50724
        ]
      },
      {
        "avg_logprob": -0.25955335058347145,
        "compression_ratio": 1.5506072874493928,
        "end": 6092.4800000000005,
        "id": 788,
        "no_speech_prob": 0.00016093069280032068,
        "seek": 607896,
        "start": 6086.16,
        "temperature": 0,
        "text": " is done and it's finished with all those calls, they're all promises, I get back some results,",
        "tokens": [
          50724,
          307,
          1096,
          293,
          309,
          311,
          4335,
          365,
          439,
          729,
          5498,
          11,
          436,
          434,
          439,
          16403,
          11,
          286,
          483,
          646,
          512,
          3542,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.25955335058347145,
        "compression_ratio": 1.5506072874493928,
        "end": 6098.72,
        "id": 789,
        "no_speech_prob": 0.00016093069280032068,
        "seek": 607896,
        "start": 6092.4800000000005,
        "temperature": 0,
        "text": " and I place them all in the DOM with a paragraph element and image elements. Now, the problem here,",
        "tokens": [
          51040,
          293,
          286,
          1081,
          552,
          439,
          294,
          264,
          35727,
          365,
          257,
          18865,
          4478,
          293,
          3256,
          4959,
          13,
          823,
          11,
          264,
          1154,
          510,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.25955335058347145,
        "compression_ratio": 1.5506072874493928,
        "end": 6103.28,
        "id": 790,
        "no_speech_prob": 0.00016093069280032068,
        "seek": 607896,
        "start": 6098.72,
        "temperature": 0,
        "text": " and again, promise.all is not necessarily the best solution for this anyway, but since I'm",
        "tokens": [
          51352,
          293,
          797,
          11,
          6228,
          13,
          336,
          307,
          406,
          4725,
          264,
          1151,
          3827,
          337,
          341,
          4033,
          11,
          457,
          1670,
          286,
          478,
          51580
        ]
      },
      {
        "avg_logprob": -0.19115355610847473,
        "compression_ratio": 1.762081784386617,
        "end": 6108.8,
        "id": 791,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 610328,
        "start": 6103.28,
        "temperature": 0,
        "text": " demonstrating it, the main issue here is if any of those, it's all or nothing, if any single one",
        "tokens": [
          50364,
          29889,
          309,
          11,
          264,
          2135,
          2734,
          510,
          307,
          498,
          604,
          295,
          729,
          11,
          309,
          311,
          439,
          420,
          1825,
          11,
          498,
          604,
          2167,
          472,
          50640
        ]
      },
      {
        "avg_logprob": -0.19115355610847473,
        "compression_ratio": 1.762081784386617,
        "end": 6112.48,
        "id": 792,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 610328,
        "start": 6108.8,
        "temperature": 0,
        "text": " of those has an error, like there isn't a GIF associated with that word available in the Giphy",
        "tokens": [
          50640,
          295,
          729,
          575,
          364,
          6713,
          11,
          411,
          456,
          1943,
          380,
          257,
          460,
          12775,
          6615,
          365,
          300,
          1349,
          2435,
          294,
          264,
          460,
          647,
          3495,
          50824
        ]
      },
      {
        "avg_logprob": -0.19115355610847473,
        "compression_ratio": 1.762081784386617,
        "end": 6118.24,
        "id": 793,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 610328,
        "start": 6112.48,
        "temperature": 0,
        "text": " API, the whole thing doesn't do it. It doesn't do anything. So just about every time I run this,",
        "tokens": [
          50824,
          9362,
          11,
          264,
          1379,
          551,
          1177,
          380,
          360,
          309,
          13,
          467,
          1177,
          380,
          360,
          1340,
          13,
          407,
          445,
          466,
          633,
          565,
          286,
          1190,
          341,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.19115355610847473,
        "compression_ratio": 1.762081784386617,
        "end": 6125.28,
        "id": 794,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 610328,
        "start": 6118.24,
        "temperature": 0,
        "text": " I'm not getting anything. Now, let me just make it work by let me just get like three of them,",
        "tokens": [
          51112,
          286,
          478,
          406,
          1242,
          1340,
          13,
          823,
          11,
          718,
          385,
          445,
          652,
          309,
          589,
          538,
          718,
          385,
          445,
          483,
          411,
          1045,
          295,
          552,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19115355610847473,
        "compression_ratio": 1.762081784386617,
        "end": 6128.5599999999995,
        "id": 795,
        "no_speech_prob": 0.00019110389985144138,
        "seek": 610328,
        "start": 6125.28,
        "temperature": 0,
        "text": " and let me just say they're all going to be three-letter words. I think this will probably",
        "tokens": [
          51464,
          293,
          718,
          385,
          445,
          584,
          436,
          434,
          439,
          516,
          281,
          312,
          1045,
          12,
          21248,
          2283,
          13,
          286,
          519,
          341,
          486,
          1391,
          51628
        ]
      },
      {
        "avg_logprob": -0.19105637414114815,
        "compression_ratio": 1.8832684824902723,
        "end": 6133.6,
        "id": 796,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 612856,
        "start": 6128.56,
        "temperature": 0,
        "text": " work. Right. So I got three GIFs with three three-letter words. So you can see that that worked,",
        "tokens": [
          50364,
          589,
          13,
          1779,
          13,
          407,
          286,
          658,
          1045,
          460,
          12775,
          82,
          365,
          1045,
          1045,
          12,
          21248,
          2283,
          13,
          407,
          291,
          393,
          536,
          300,
          300,
          2732,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.19105637414114815,
        "compression_ratio": 1.8832684824902723,
        "end": 6138.96,
        "id": 797,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 612856,
        "start": 6133.6,
        "temperature": 0,
        "text": " but what I want is I want it to work anyway, and I want to see a two-letter word, a three-letter",
        "tokens": [
          50616,
          457,
          437,
          286,
          528,
          307,
          286,
          528,
          309,
          281,
          589,
          4033,
          11,
          293,
          286,
          528,
          281,
          536,
          257,
          732,
          12,
          21248,
          1349,
          11,
          257,
          1045,
          12,
          21248,
          50884
        ]
      },
      {
        "avg_logprob": -0.19105637414114815,
        "compression_ratio": 1.8832684824902723,
        "end": 6144.64,
        "id": 798,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 612856,
        "start": 6138.96,
        "temperature": 0,
        "text": " word, four, five, six, seven, and so let's do that. Oh, whoa, it actually worked. So that was the first",
        "tokens": [
          50884,
          1349,
          11,
          1451,
          11,
          1732,
          11,
          2309,
          11,
          3407,
          11,
          293,
          370,
          718,
          311,
          360,
          300,
          13,
          876,
          11,
          13310,
          11,
          309,
          767,
          2732,
          13,
          407,
          300,
          390,
          264,
          700,
          51168
        ]
      },
      {
        "avg_logprob": -0.19105637414114815,
        "compression_ratio": 1.8832684824902723,
        "end": 6151.52,
        "id": 799,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 612856,
        "start": 6144.64,
        "temperature": 0,
        "text": " time that worked, but most of the time we're going to get an error. So there's a way around this,",
        "tokens": [
          51168,
          565,
          300,
          2732,
          11,
          457,
          881,
          295,
          264,
          565,
          321,
          434,
          516,
          281,
          483,
          364,
          6713,
          13,
          407,
          456,
          311,
          257,
          636,
          926,
          341,
          11,
          51512
        ]
      },
      {
        "avg_logprob": -0.19105637414114815,
        "compression_ratio": 1.8832684824902723,
        "end": 6155.84,
        "id": 800,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 612856,
        "start": 6151.52,
        "temperature": 0,
        "text": " and it is not a way around this, but there's another concept that could help here that's",
        "tokens": [
          51512,
          293,
          309,
          307,
          406,
          257,
          636,
          926,
          341,
          11,
          457,
          456,
          311,
          1071,
          3410,
          300,
          727,
          854,
          510,
          300,
          311,
          51728
        ]
      },
      {
        "avg_logprob": -0.18391637802124022,
        "compression_ratio": 1.7545454545454546,
        "end": 6161.68,
        "id": 801,
        "no_speech_prob": 0.0000015779614841449074,
        "seek": 615584,
        "start": 6155.84,
        "temperature": 0,
        "text": " important, which is try and catch. So a place that I could use, what I want to do is individually",
        "tokens": [
          50364,
          1021,
          11,
          597,
          307,
          853,
          293,
          3745,
          13,
          407,
          257,
          1081,
          300,
          286,
          727,
          764,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          16652,
          50656
        ]
      },
      {
        "avg_logprob": -0.18391637802124022,
        "compression_ratio": 1.7545454545454546,
        "end": 6171.2,
        "id": 802,
        "no_speech_prob": 0.0000015779614841449074,
        "seek": 615584,
        "start": 6161.68,
        "temperature": 0,
        "text": " handle error messages differently, and a way that I can do that here is by, I can handle the",
        "tokens": [
          50656,
          4813,
          6713,
          7897,
          7614,
          11,
          293,
          257,
          636,
          300,
          286,
          393,
          360,
          300,
          510,
          307,
          538,
          11,
          286,
          393,
          4813,
          264,
          51132
        ]
      },
      {
        "avg_logprob": -0.18391637802124022,
        "compression_ratio": 1.7545454545454546,
        "end": 6176,
        "id": 803,
        "no_speech_prob": 0.0000015779614841449074,
        "seek": 615584,
        "start": 6171.2,
        "temperature": 0,
        "text": " error message myself and not cause it to fail by using a try catch here. So the first thing I'm",
        "tokens": [
          51132,
          6713,
          3636,
          2059,
          293,
          406,
          3082,
          309,
          281,
          3061,
          538,
          1228,
          257,
          853,
          3745,
          510,
          13,
          407,
          264,
          700,
          551,
          286,
          478,
          51372
        ]
      },
      {
        "avg_logprob": -0.18391637802124022,
        "compression_ratio": 1.7545454545454546,
        "end": 6183.52,
        "id": 804,
        "no_speech_prob": 0.0000015779614841449074,
        "seek": 615584,
        "start": 6176,
        "temperature": 0,
        "text": " going to do is I'm actually just going to say let image URL equal null. So I'm going to assume that",
        "tokens": [
          51372,
          516,
          281,
          360,
          307,
          286,
          478,
          767,
          445,
          516,
          281,
          584,
          718,
          3256,
          12905,
          2681,
          18184,
          13,
          407,
          286,
          478,
          516,
          281,
          6552,
          300,
          51748
        ]
      },
      {
        "avg_logprob": -0.21650929170496325,
        "compression_ratio": 1.8867924528301887,
        "end": 6192.56,
        "id": 805,
        "no_speech_prob": 0.0000012878952020400902,
        "seek": 618352,
        "start": 6183.52,
        "temperature": 0,
        "text": " I'm starting with the idea that there isn't an image URL. Then I'm going to try to get the image URL",
        "tokens": [
          50364,
          286,
          478,
          2891,
          365,
          264,
          1558,
          300,
          456,
          1943,
          380,
          364,
          3256,
          12905,
          13,
          1396,
          286,
          478,
          516,
          281,
          853,
          281,
          483,
          264,
          3256,
          12905,
          50816
        ]
      },
      {
        "avg_logprob": -0.21650929170496325,
        "compression_ratio": 1.8867924528301887,
        "end": 6201.6,
        "id": 806,
        "no_speech_prob": 0.0000012878952020400902,
        "seek": 618352,
        "start": 6194.4800000000005,
        "temperature": 0,
        "text": " from the, sorry, I'm going to try to get the image URL, I'm getting sleepy after making all these",
        "tokens": [
          50912,
          490,
          264,
          11,
          2597,
          11,
          286,
          478,
          516,
          281,
          853,
          281,
          483,
          264,
          3256,
          12905,
          11,
          286,
          478,
          1242,
          24908,
          934,
          1455,
          439,
          613,
          51268
        ]
      },
      {
        "avg_logprob": -0.21650929170496325,
        "compression_ratio": 1.8867924528301887,
        "end": 6207.040000000001,
        "id": 807,
        "no_speech_prob": 0.0000012878952020400902,
        "seek": 618352,
        "start": 6201.6,
        "temperature": 0,
        "text": " videos, I'm going to try to get the image URL from the data. Now it might not exist, that's fine, I'm",
        "tokens": [
          51268,
          2145,
          11,
          286,
          478,
          516,
          281,
          853,
          281,
          483,
          264,
          3256,
          12905,
          490,
          264,
          1412,
          13,
          823,
          309,
          1062,
          406,
          2514,
          11,
          300,
          311,
          2489,
          11,
          286,
          478,
          51540
        ]
      },
      {
        "avg_logprob": -0.19739820246110884,
        "compression_ratio": 1.5887096774193548,
        "end": 6214.08,
        "id": 808,
        "no_speech_prob": 0.00004985953637515195,
        "seek": 620704,
        "start": 6207.04,
        "temperature": 0,
        "text": " just going to try. Then I'm going to return JSON1.word and image URL. Now this will be null if this",
        "tokens": [
          50364,
          445,
          516,
          281,
          853,
          13,
          1396,
          286,
          478,
          516,
          281,
          2736,
          31828,
          16,
          13,
          7462,
          293,
          3256,
          12905,
          13,
          823,
          341,
          486,
          312,
          18184,
          498,
          341,
          50716
        ]
      },
      {
        "avg_logprob": -0.19739820246110884,
        "compression_ratio": 1.5887096774193548,
        "end": 6221.5199999999995,
        "id": 809,
        "no_speech_prob": 0.00004985953637515195,
        "seek": 620704,
        "start": 6214.08,
        "temperature": 0,
        "text": " doesn't work. So I can now go up, whoops, I can go back up in my code and I can say, hey, if results",
        "tokens": [
          50716,
          1177,
          380,
          589,
          13,
          407,
          286,
          393,
          586,
          352,
          493,
          11,
          567,
          3370,
          11,
          286,
          393,
          352,
          646,
          493,
          294,
          452,
          3089,
          293,
          286,
          393,
          584,
          11,
          4177,
          11,
          498,
          3542,
          51088
        ]
      },
      {
        "avg_logprob": -0.19739820246110884,
        "compression_ratio": 1.5887096774193548,
        "end": 6231.12,
        "id": 810,
        "no_speech_prob": 0.00004985953637515195,
        "seek": 620704,
        "start": 6221.5199999999995,
        "temperature": 0,
        "text": " index i.image equals null, you know, as long as it's not null, do this. So this now should let",
        "tokens": [
          51088,
          8186,
          741,
          13,
          26624,
          6915,
          18184,
          11,
          291,
          458,
          11,
          382,
          938,
          382,
          309,
          311,
          406,
          18184,
          11,
          360,
          341,
          13,
          407,
          341,
          586,
          820,
          718,
          51568
        ]
      },
      {
        "avg_logprob": -0.19739820246110884,
        "compression_ratio": 1.5887096774193548,
        "end": 6236.48,
        "id": 811,
        "no_speech_prob": 0.00004985953637515195,
        "seek": 620704,
        "start": 6231.12,
        "temperature": 0,
        "text": " everything keep going and it will only just skip making an image where there wasn't one. Let's see",
        "tokens": [
          51568,
          1203,
          1066,
          516,
          293,
          309,
          486,
          787,
          445,
          10023,
          1455,
          364,
          3256,
          689,
          456,
          2067,
          380,
          472,
          13,
          961,
          311,
          536,
          51836
        ]
      },
      {
        "avg_logprob": -0.19284510791749881,
        "compression_ratio": 1.6736111111111112,
        "end": 6244.639999999999,
        "id": 812,
        "no_speech_prob": 0.0001609303435543552,
        "seek": 623648,
        "start": 6236.48,
        "temperature": 0,
        "text": " if that works. Okay, ah, all right, so fine. I was thinking I could demonstrate this without a catch",
        "tokens": [
          50364,
          498,
          300,
          1985,
          13,
          1033,
          11,
          3716,
          11,
          439,
          558,
          11,
          370,
          2489,
          13,
          286,
          390,
          1953,
          286,
          727,
          11698,
          341,
          1553,
          257,
          3745,
          50772
        ]
      },
      {
        "avg_logprob": -0.19284510791749881,
        "compression_ratio": 1.6736111111111112,
        "end": 6249.839999999999,
        "id": 813,
        "no_speech_prob": 0.0001609303435543552,
        "seek": 623648,
        "start": 6245.28,
        "temperature": 0,
        "text": " and then show you the catch next. I thought there might be like a default catch, but clearly",
        "tokens": [
          50804,
          293,
          550,
          855,
          291,
          264,
          3745,
          958,
          13,
          286,
          1194,
          456,
          1062,
          312,
          411,
          257,
          7576,
          3745,
          11,
          457,
          4448,
          51032
        ]
      },
      {
        "avg_logprob": -0.19284510791749881,
        "compression_ratio": 1.6736111111111112,
        "end": 6254.48,
        "id": 814,
        "no_speech_prob": 0.0001609303435543552,
        "seek": 623648,
        "start": 6249.839999999999,
        "temperature": 0,
        "text": " there's not. That makes sense, right? So, and there's a finally thing too, I'll have to come",
        "tokens": [
          51032,
          456,
          311,
          406,
          13,
          663,
          1669,
          2020,
          11,
          558,
          30,
          407,
          11,
          293,
          456,
          311,
          257,
          2721,
          551,
          886,
          11,
          286,
          603,
          362,
          281,
          808,
          51264
        ]
      },
      {
        "avg_logprob": -0.19284510791749881,
        "compression_ratio": 1.6736111111111112,
        "end": 6259.12,
        "id": 815,
        "no_speech_prob": 0.0001609303435543552,
        "seek": 623648,
        "start": 6254.48,
        "temperature": 0,
        "text": " back to that another time. But what it's saying is like, hey, hey, if you're going to try something,",
        "tokens": [
          51264,
          646,
          281,
          300,
          1071,
          565,
          13,
          583,
          437,
          309,
          311,
          1566,
          307,
          411,
          11,
          4177,
          11,
          4177,
          11,
          498,
          291,
          434,
          516,
          281,
          853,
          746,
          11,
          51496
        ]
      },
      {
        "avg_logprob": -0.19284510791749881,
        "compression_ratio": 1.6736111111111112,
        "end": 6264.799999999999,
        "id": 816,
        "no_speech_prob": 0.0001609303435543552,
        "seek": 623648,
        "start": 6260,
        "temperature": 0,
        "text": " I can try it, but you got to tell me what to do if things go wrong. Like you're in charge now,",
        "tokens": [
          51540,
          286,
          393,
          853,
          309,
          11,
          457,
          291,
          658,
          281,
          980,
          385,
          437,
          281,
          360,
          498,
          721,
          352,
          2085,
          13,
          1743,
          291,
          434,
          294,
          4602,
          586,
          11,
          51780
        ]
      },
      {
        "avg_logprob": -0.20743447381096916,
        "compression_ratio": 1.7577639751552796,
        "end": 6269.52,
        "id": 817,
        "no_speech_prob": 0.000006540435151691781,
        "seek": 626480,
        "start": 6264.8,
        "temperature": 0,
        "text": " like the error isn't just going to be handled however it's going to be handled. So I need to",
        "tokens": [
          50364,
          411,
          264,
          6713,
          1943,
          380,
          445,
          516,
          281,
          312,
          18033,
          4461,
          309,
          311,
          516,
          281,
          312,
          18033,
          13,
          407,
          286,
          643,
          281,
          50600
        ]
      },
      {
        "avg_logprob": -0.20743447381096916,
        "compression_ratio": 1.7577639751552796,
        "end": 6275.92,
        "id": 818,
        "no_speech_prob": 0.000006540435151691781,
        "seek": 626480,
        "start": 6269.52,
        "temperature": 0,
        "text": " actually say catch and the catch actually gets inside of here, it's like a function, it's not",
        "tokens": [
          50600,
          767,
          584,
          3745,
          293,
          264,
          3745,
          767,
          2170,
          1854,
          295,
          510,
          11,
          309,
          311,
          411,
          257,
          2445,
          11,
          309,
          311,
          406,
          50920
        ]
      },
      {
        "avg_logprob": -0.20743447381096916,
        "compression_ratio": 1.7577639751552796,
        "end": 6281.28,
        "id": 819,
        "no_speech_prob": 0.000006540435151691781,
        "seek": 626480,
        "start": 6276.8,
        "temperature": 0,
        "text": " an argument and I could call that error. So I'm actually going to catch that error. I'm going to",
        "tokens": [
          50964,
          364,
          6770,
          293,
          286,
          727,
          818,
          300,
          6713,
          13,
          407,
          286,
          478,
          767,
          516,
          281,
          3745,
          300,
          6713,
          13,
          286,
          478,
          516,
          281,
          51188
        ]
      },
      {
        "avg_logprob": -0.2355382069047675,
        "compression_ratio": 1.5,
        "end": 6295.2,
        "id": 820,
        "no_speech_prob": 0.044016338884830475,
        "seek": 628128,
        "start": 6281.28,
        "temperature": 0,
        "text": " say console.log, no image found for JSON, oops, for JSON1.word. And then I'm also going to just",
        "tokens": [
          50364,
          584,
          11076,
          13,
          4987,
          11,
          572,
          3256,
          1352,
          337,
          31828,
          11,
          34166,
          11,
          337,
          31828,
          16,
          13,
          7462,
          13,
          400,
          550,
          286,
          478,
          611,
          516,
          281,
          445,
          51060
        ]
      },
      {
        "avg_logprob": -0.2355382069047675,
        "compression_ratio": 1.5,
        "end": 6301.5199999999995,
        "id": 821,
        "no_speech_prob": 0.044016338884830475,
        "seek": 628128,
        "start": 6295.2,
        "temperature": 0,
        "text": " say console.error. I might as well print out that error as well. And let's just call it err,",
        "tokens": [
          51060,
          584,
          11076,
          13,
          260,
          2874,
          13,
          286,
          1062,
          382,
          731,
          4482,
          484,
          300,
          6713,
          382,
          731,
          13,
          400,
          718,
          311,
          445,
          818,
          309,
          1189,
          81,
          11,
          51376
        ]
      },
      {
        "avg_logprob": -0.2355382069047675,
        "compression_ratio": 1.5,
        "end": 6305.84,
        "id": 822,
        "no_speech_prob": 0.044016338884830475,
        "seek": 628128,
        "start": 6301.5199999999995,
        "temperature": 0,
        "text": " just so we have things named differently. So I think this is right now. Now what I'm doing is",
        "tokens": [
          51376,
          445,
          370,
          321,
          362,
          721,
          4926,
          7614,
          13,
          407,
          286,
          519,
          341,
          307,
          558,
          586,
          13,
          823,
          437,
          286,
          478,
          884,
          307,
          51592
        ]
      },
      {
        "avg_logprob": -0.22096105368740587,
        "compression_ratio": 1.4845360824742269,
        "end": 6315.360000000001,
        "id": 823,
        "no_speech_prob": 0.00003426848343224265,
        "seek": 630584,
        "start": 6305.84,
        "temperature": 0,
        "text": " I'm saying, hey, let me try to grab the image URL, if it doesn't exist, just spit something out to",
        "tokens": [
          50364,
          286,
          478,
          1566,
          11,
          4177,
          11,
          718,
          385,
          853,
          281,
          4444,
          264,
          3256,
          12905,
          11,
          498,
          309,
          1177,
          380,
          2514,
          11,
          445,
          22127,
          746,
          484,
          281,
          50840
        ]
      },
      {
        "avg_logprob": -0.22096105368740587,
        "compression_ratio": 1.4845360824742269,
        "end": 6324.400000000001,
        "id": 824,
        "no_speech_prob": 0.00003426848343224265,
        "seek": 630584,
        "start": 6315.360000000001,
        "temperature": 0,
        "text": " the console and but keep going. So let's see if this works now. Whoa, right, it didn't find it for",
        "tokens": [
          50840,
          264,
          11076,
          293,
          457,
          1066,
          516,
          13,
          407,
          718,
          311,
          536,
          498,
          341,
          1985,
          586,
          13,
          7521,
          11,
          558,
          11,
          309,
          994,
          380,
          915,
          309,
          337,
          51292
        ]
      },
      {
        "avg_logprob": -0.22096105368740587,
        "compression_ratio": 1.4845360824742269,
        "end": 6330,
        "id": 825,
        "no_speech_prob": 0.00003426848343224265,
        "seek": 630584,
        "start": 6324.400000000001,
        "temperature": 0,
        "text": " any of them, weird. Okay, so I got a mistake somewhere, because it only didn't find it for",
        "tokens": [
          51292,
          604,
          295,
          552,
          11,
          3657,
          13,
          1033,
          11,
          370,
          286,
          658,
          257,
          6146,
          4079,
          11,
          570,
          309,
          787,
          994,
          380,
          915,
          309,
          337,
          51572
        ]
      },
      {
        "avg_logprob": -0.23552813113314433,
        "compression_ratio": 1.638655462184874,
        "end": 6340.72,
        "id": 826,
        "no_speech_prob": 0.0040701208636164665,
        "seek": 633000,
        "start": 6330,
        "temperature": 0,
        "text": " one of them. I think I've got something wrong somewhere. Oh, what did I do here? If, this is",
        "tokens": [
          50364,
          472,
          295,
          552,
          13,
          286,
          519,
          286,
          600,
          658,
          746,
          2085,
          4079,
          13,
          876,
          11,
          437,
          630,
          286,
          360,
          510,
          30,
          759,
          11,
          341,
          307,
          50900
        ]
      },
      {
        "avg_logprob": -0.23552813113314433,
        "compression_ratio": 1.638655462184874,
        "end": 6345.04,
        "id": 827,
        "no_speech_prob": 0.0040701208636164665,
        "seek": 633000,
        "start": 6340.72,
        "temperature": 0,
        "text": " like total nonsense. This is what I need to eat lunch people, I should not be making this video",
        "tokens": [
          50900,
          411,
          3217,
          14925,
          13,
          639,
          307,
          437,
          286,
          643,
          281,
          1862,
          6349,
          561,
          11,
          286,
          820,
          406,
          312,
          1455,
          341,
          960,
          51116
        ]
      },
      {
        "avg_logprob": -0.23552813113314433,
        "compression_ratio": 1.638655462184874,
        "end": 6351.2,
        "id": 828,
        "no_speech_prob": 0.0040701208636164665,
        "seek": 633000,
        "start": 6345.04,
        "temperature": 0,
        "text": " tutorial right now. That was total nonsense what I wrote before. What I'm saying is, as long as the",
        "tokens": [
          51116,
          7073,
          558,
          586,
          13,
          663,
          390,
          3217,
          14925,
          437,
          286,
          4114,
          949,
          13,
          708,
          286,
          478,
          1566,
          307,
          11,
          382,
          938,
          382,
          264,
          51424
        ]
      },
      {
        "avg_logprob": -0.23552813113314433,
        "compression_ratio": 1.638655462184874,
        "end": 6358.24,
        "id": 829,
        "no_speech_prob": 0.0040701208636164665,
        "seek": 633000,
        "start": 6351.2,
        "temperature": 0,
        "text": " results image is not null, not image equal to null, that makes no sense at all. Let's try that again.",
        "tokens": [
          51424,
          3542,
          3256,
          307,
          406,
          18184,
          11,
          406,
          3256,
          2681,
          281,
          18184,
          11,
          300,
          1669,
          572,
          2020,
          412,
          439,
          13,
          961,
          311,
          853,
          300,
          797,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.22263918424907483,
        "compression_ratio": 1.7949640287769784,
        "end": 6365.6,
        "id": 830,
        "no_speech_prob": 0.000020145664166193455,
        "seek": 636000,
        "start": 6360,
        "temperature": 0,
        "text": " Great. Now they all, unfortunately, they all worked. But you can see now it worked, but no image found",
        "tokens": [
          50364,
          3769,
          13,
          823,
          436,
          439,
          11,
          7015,
          11,
          436,
          439,
          2732,
          13,
          583,
          291,
          393,
          536,
          586,
          309,
          2732,
          11,
          457,
          572,
          3256,
          1352,
          50644
        ]
      },
      {
        "avg_logprob": -0.22263918424907483,
        "compression_ratio": 1.7949640287769784,
        "end": 6371.68,
        "id": 831,
        "no_speech_prob": 0.000020145664166193455,
        "seek": 636000,
        "start": 6365.6,
        "temperature": 0,
        "text": " for fueler. And we should see that fueler is still here, but just no image is associated with it. So",
        "tokens": [
          50644,
          337,
          6616,
          260,
          13,
          400,
          321,
          820,
          536,
          300,
          6616,
          260,
          307,
          920,
          510,
          11,
          457,
          445,
          572,
          3256,
          307,
          6615,
          365,
          309,
          13,
          407,
          50948
        ]
      },
      {
        "avg_logprob": -0.22263918424907483,
        "compression_ratio": 1.7949640287769784,
        "end": 6377.2,
        "id": 832,
        "no_speech_prob": 0.000020145664166193455,
        "seek": 636000,
        "start": 6371.68,
        "temperature": 0,
        "text": " no image found for fueler, no image found for whatever that word is. And so now this goes through,",
        "tokens": [
          50948,
          572,
          3256,
          1352,
          337,
          6616,
          260,
          11,
          572,
          3256,
          1352,
          337,
          2035,
          300,
          1349,
          307,
          13,
          400,
          370,
          586,
          341,
          1709,
          807,
          11,
          51224
        ]
      },
      {
        "avg_logprob": -0.22263918424907483,
        "compression_ratio": 1.7949640287769784,
        "end": 6382.88,
        "id": 833,
        "no_speech_prob": 0.000020145664166193455,
        "seek": 636000,
        "start": 6377.2,
        "temperature": 0,
        "text": " but I can sort of see what are the things where it doesn't work. Okay, so I have talked to you about,",
        "tokens": [
          51224,
          457,
          286,
          393,
          1333,
          295,
          536,
          437,
          366,
          264,
          721,
          689,
          309,
          1177,
          380,
          589,
          13,
          1033,
          11,
          370,
          286,
          362,
          2825,
          281,
          291,
          466,
          11,
          51508
        ]
      },
      {
        "avg_logprob": -0.22263918424907483,
        "compression_ratio": 1.7949640287769784,
        "end": 6389.68,
        "id": 834,
        "no_speech_prob": 0.000020145664166193455,
        "seek": 636000,
        "start": 6382.88,
        "temperature": 0,
        "text": " now I added this last little bit about try and catch. Here's the thing, just while we're here,",
        "tokens": [
          51508,
          586,
          286,
          3869,
          341,
          1036,
          707,
          857,
          466,
          853,
          293,
          3745,
          13,
          1692,
          311,
          264,
          551,
          11,
          445,
          1339,
          321,
          434,
          510,
          11,
          51848
        ]
      },
      {
        "avg_logprob": -0.22719850540161132,
        "compression_ratio": 1.6318681318681318,
        "end": 6394.8,
        "id": 835,
        "no_speech_prob": 0.000009516243153484538,
        "seek": 638968,
        "start": 6389.68,
        "temperature": 0,
        "text": " let me just fix, just fix tiny little things, tiny little things. Because while we're here in ES6",
        "tokens": [
          50364,
          718,
          385,
          445,
          3191,
          11,
          445,
          3191,
          5870,
          707,
          721,
          11,
          5870,
          707,
          721,
          13,
          1436,
          1339,
          321,
          434,
          510,
          294,
          12564,
          21,
          50620
        ]
      },
      {
        "avg_logprob": -0.22719850540161132,
        "compression_ratio": 1.6318681318681318,
        "end": 6402.88,
        "id": 836,
        "no_speech_prob": 0.000009516243153484538,
        "seek": 638968,
        "start": 6394.8,
        "temperature": 0,
        "text": " and ES8 land, there is something called enhanced object initialization. Is that what it's called?",
        "tokens": [
          50620,
          293,
          12564,
          23,
          2117,
          11,
          456,
          307,
          746,
          1219,
          21191,
          2657,
          5883,
          2144,
          13,
          1119,
          300,
          437,
          309,
          311,
          1219,
          30,
          51024
        ]
      },
      {
        "avg_logprob": -0.22719850540161132,
        "compression_ratio": 1.6318681318681318,
        "end": 6413.4400000000005,
        "id": 837,
        "no_speech_prob": 0.000009516243153484538,
        "seek": 638968,
        "start": 6403.6,
        "temperature": 0,
        "text": " Enhanced object literals in ES6. So something that I can actually do here, oh, weird. I don't want to",
        "tokens": [
          51060,
          2193,
          3451,
          1232,
          2657,
          2733,
          1124,
          294,
          12564,
          21,
          13,
          407,
          746,
          300,
          286,
          393,
          767,
          360,
          510,
          11,
          1954,
          11,
          3657,
          13,
          286,
          500,
          380,
          528,
          281,
          51552
        ]
      },
      {
        "avg_logprob": -0.2593400244619332,
        "compression_ratio": 1.3154362416107384,
        "end": 6427.04,
        "id": 838,
        "no_speech_prob": 0.03676845505833626,
        "seek": 641344,
        "start": 6413.44,
        "temperature": 0,
        "text": " talk about this now. Let's not put that in here. It's fine. Yeah. Oh, too many people use try catch",
        "tokens": [
          50364,
          751,
          466,
          341,
          586,
          13,
          961,
          311,
          406,
          829,
          300,
          294,
          510,
          13,
          467,
          311,
          2489,
          13,
          865,
          13,
          876,
          11,
          886,
          867,
          561,
          764,
          853,
          3745,
          51044
        ]
      },
      {
        "avg_logprob": -0.2593400244619332,
        "compression_ratio": 1.3154362416107384,
        "end": 6435.759999999999,
        "id": 839,
        "no_speech_prob": 0.03676845505833626,
        "seek": 641344,
        "start": 6427.04,
        "temperature": 0,
        "text": " rather than defensive programming, which is lazy. Weird edit point. I'm getting some interesting",
        "tokens": [
          51044,
          2831,
          813,
          16468,
          9410,
          11,
          597,
          307,
          14847,
          13,
          32033,
          8129,
          935,
          13,
          286,
          478,
          1242,
          512,
          1880,
          51480
        ]
      },
      {
        "avg_logprob": -0.20295379088097013,
        "compression_ratio": 1.6074380165289257,
        "end": 6443.84,
        "id": 840,
        "no_speech_prob": 0.015663325786590576,
        "seek": 643576,
        "start": 6435.76,
        "temperature": 0,
        "text": " feedback on the chat that things like people use try catch too much and that try catch is useful,",
        "tokens": [
          50364,
          5824,
          322,
          264,
          5081,
          300,
          721,
          411,
          561,
          764,
          853,
          3745,
          886,
          709,
          293,
          300,
          853,
          3745,
          307,
          4420,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.20295379088097013,
        "compression_ratio": 1.6074380165289257,
        "end": 6448.96,
        "id": 841,
        "no_speech_prob": 0.015663325786590576,
        "seek": 643576,
        "start": 6443.84,
        "temperature": 0,
        "text": " but it should be used as a last resort if all your other stuff fails. So again, I'm not necessarily",
        "tokens": [
          50768,
          457,
          309,
          820,
          312,
          1143,
          382,
          257,
          1036,
          19606,
          498,
          439,
          428,
          661,
          1507,
          18199,
          13,
          407,
          797,
          11,
          286,
          478,
          406,
          4725,
          51024
        ]
      },
      {
        "avg_logprob": -0.20295379088097013,
        "compression_ratio": 1.6074380165289257,
        "end": 6456.64,
        "id": 842,
        "no_speech_prob": 0.015663325786590576,
        "seek": 643576,
        "start": 6448.96,
        "temperature": 0,
        "text": " suggesting that the way that I've done this is the optimal way to create this word GIF generator. I",
        "tokens": [
          51024,
          18094,
          300,
          264,
          636,
          300,
          286,
          600,
          1096,
          341,
          307,
          264,
          16252,
          636,
          281,
          1884,
          341,
          1349,
          460,
          12775,
          19265,
          13,
          286,
          51408
        ]
      },
      {
        "avg_logprob": -0.20295379088097013,
        "compression_ratio": 1.6074380165289257,
        "end": 6460.8,
        "id": 843,
        "no_speech_prob": 0.015663325786590576,
        "seek": 643576,
        "start": 6456.64,
        "temperature": 0,
        "text": " mean, ultimately, if I wanted to do that, I'd probably want to not just like have a hundred",
        "tokens": [
          51408,
          914,
          11,
          6284,
          11,
          498,
          286,
          1415,
          281,
          360,
          300,
          11,
          286,
          1116,
          1391,
          528,
          281,
          406,
          445,
          411,
          362,
          257,
          3262,
          51616
        ]
      },
      {
        "avg_logprob": -0.19159904969941585,
        "compression_ratio": 1.7058823529411764,
        "end": 6465.68,
        "id": 844,
        "no_speech_prob": 0.0012843033764511347,
        "seek": 646080,
        "start": 6460.8,
        "temperature": 0,
        "text": " promises that all happen all at once. I'd want to animate and sequence and make things interactive,",
        "tokens": [
          50364,
          16403,
          300,
          439,
          1051,
          439,
          412,
          1564,
          13,
          286,
          1116,
          528,
          281,
          36439,
          293,
          8310,
          293,
          652,
          721,
          15141,
          11,
          50608
        ]
      },
      {
        "avg_logprob": -0.19159904969941585,
        "compression_ratio": 1.7058823529411764,
        "end": 6469.04,
        "id": 845,
        "no_speech_prob": 0.0012843033764511347,
        "seek": 646080,
        "start": 6465.68,
        "temperature": 0,
        "text": " and maybe I type in a word, all sorts of possibilities. But I'm trying to show you",
        "tokens": [
          50608,
          293,
          1310,
          286,
          2010,
          294,
          257,
          1349,
          11,
          439,
          7527,
          295,
          12178,
          13,
          583,
          286,
          478,
          1382,
          281,
          855,
          291,
          50776
        ]
      },
      {
        "avg_logprob": -0.19159904969941585,
        "compression_ratio": 1.7058823529411764,
        "end": 6474.400000000001,
        "id": 846,
        "no_speech_prob": 0.0012843033764511347,
        "seek": 646080,
        "start": 6469.04,
        "temperature": 0,
        "text": " the bits and pieces and features. So the important thing here, I think, is that you can write",
        "tokens": [
          50776,
          264,
          9239,
          293,
          3755,
          293,
          4122,
          13,
          407,
          264,
          1021,
          551,
          510,
          11,
          286,
          519,
          11,
          307,
          300,
          291,
          393,
          2464,
          51044
        ]
      },
      {
        "avg_logprob": -0.19159904969941585,
        "compression_ratio": 1.7058823529411764,
        "end": 6480.8,
        "id": 847,
        "no_speech_prob": 0.0012843033764511347,
        "seek": 646080,
        "start": 6475.52,
        "temperature": 0,
        "text": " an asynchronous function that returns a promise without ever saying promise by using the await",
        "tokens": [
          51100,
          364,
          49174,
          2445,
          300,
          11247,
          257,
          6228,
          1553,
          1562,
          1566,
          6228,
          538,
          1228,
          264,
          19670,
          51364
        ]
      },
      {
        "avg_logprob": -0.19159904969941585,
        "compression_ratio": 1.7058823529411764,
        "end": 6489.4400000000005,
        "id": 848,
        "no_speech_prob": 0.0012843033764511347,
        "seek": 646080,
        "start": 6480.8,
        "temperature": 0,
        "text": " keyword and the async keyword. You can use promise.all to execute some code when a whole lot",
        "tokens": [
          51364,
          20428,
          293,
          264,
          382,
          34015,
          20428,
          13,
          509,
          393,
          764,
          6228,
          13,
          336,
          281,
          14483,
          512,
          3089,
          562,
          257,
          1379,
          688,
          51796
        ]
      },
      {
        "avg_logprob": -0.24344435045796056,
        "compression_ratio": 1.821705426356589,
        "end": 6493.679999999999,
        "id": 849,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 648944,
        "start": 6489.44,
        "temperature": 0,
        "text": " of promises are finished and the results will always come in in the same order as the array.",
        "tokens": [
          50364,
          295,
          16403,
          366,
          4335,
          293,
          264,
          3542,
          486,
          1009,
          808,
          294,
          294,
          264,
          912,
          1668,
          382,
          264,
          10225,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.24344435045796056,
        "compression_ratio": 1.821705426356589,
        "end": 6500.719999999999,
        "id": 850,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 648944,
        "start": 6494.96,
        "temperature": 0,
        "text": " But you can also sequence promises with dot then, dot then, dot then, dot then.",
        "tokens": [
          50640,
          583,
          291,
          393,
          611,
          8310,
          16403,
          365,
          5893,
          550,
          11,
          5893,
          550,
          11,
          5893,
          550,
          11,
          5893,
          550,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.24344435045796056,
        "compression_ratio": 1.821705426356589,
        "end": 6505.04,
        "id": 851,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 648944,
        "start": 6500.719999999999,
        "temperature": 0,
        "text": " So there's some other things that I should do. I should use enhanced object literals, which is",
        "tokens": [
          50928,
          407,
          456,
          311,
          512,
          661,
          721,
          300,
          286,
          820,
          360,
          13,
          286,
          820,
          764,
          21191,
          2657,
          2733,
          1124,
          11,
          597,
          307,
          51144
        ]
      },
      {
        "avg_logprob": -0.24344435045796056,
        "compression_ratio": 1.821705426356589,
        "end": 6509.679999999999,
        "id": 852,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 648944,
        "start": 6505.04,
        "temperature": 0,
        "text": " like an ES6 feature. Maybe I'll come back and talk about that in a video. That thing with the strings.",
        "tokens": [
          51144,
          411,
          364,
          12564,
          21,
          4111,
          13,
          2704,
          286,
          603,
          808,
          646,
          293,
          751,
          466,
          300,
          294,
          257,
          960,
          13,
          663,
          551,
          365,
          264,
          13985,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.24344435045796056,
        "compression_ratio": 1.821705426356589,
        "end": 6516.96,
        "id": 853,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 648944,
        "start": 6509.679999999999,
        "temperature": 0,
        "text": " What's the thing with the strings? Strings, ES6, literals. There's like a thing. Template literals.",
        "tokens": [
          51376,
          708,
          311,
          264,
          551,
          365,
          264,
          13985,
          30,
          8251,
          1109,
          11,
          12564,
          21,
          11,
          2733,
          1124,
          13,
          821,
          311,
          411,
          257,
          551,
          13,
          39563,
          473,
          2733,
          1124,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.22954811033655387,
        "compression_ratio": 1.3522727272727273,
        "end": 6523.44,
        "id": 854,
        "no_speech_prob": 0.00007602458936162293,
        "seek": 651696,
        "start": 6516.96,
        "temperature": 0,
        "text": " I should use that. So somebody remind me in another video, I'll talk about some other ES6",
        "tokens": [
          50364,
          286,
          820,
          764,
          300,
          13,
          407,
          2618,
          4160,
          385,
          294,
          1071,
          960,
          11,
          286,
          603,
          751,
          466,
          512,
          661,
          12564,
          21,
          50688
        ]
      },
      {
        "avg_logprob": -0.22954811033655387,
        "compression_ratio": 1.3522727272727273,
        "end": 6527.6,
        "id": 855,
        "no_speech_prob": 0.00007602458936162293,
        "seek": 651696,
        "start": 6523.44,
        "temperature": 0,
        "text": " features like template literals and enhanced object literals. Now just go look up those",
        "tokens": [
          50688,
          4122,
          411,
          12379,
          2733,
          1124,
          293,
          21191,
          2657,
          2733,
          1124,
          13,
          823,
          445,
          352,
          574,
          493,
          729,
          50896
        ]
      },
      {
        "avg_logprob": -0.22954811033655387,
        "compression_ratio": 1.3522727272727273,
        "end": 6539.12,
        "id": 856,
        "no_speech_prob": 0.00007602458936162293,
        "seek": 651696,
        "start": 6527.6,
        "temperature": 0,
        "text": " things on your own. Little tidbits here. Goodbye. All right.",
        "tokens": [
          50896,
          721,
          322,
          428,
          1065,
          13,
          8022,
          9422,
          34010,
          510,
          13,
          15528,
          13,
          1057,
          558,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.27796470344840707,
        "compression_ratio": 1.4615384615384615,
        "end": 6556,
        "id": 857,
        "no_speech_prob": 0.08755739033222198,
        "seek": 653912,
        "start": 6539.12,
        "temperature": 0,
        "text": " All right. Okay. I'm done. It's 1250. I'm going to answer a few questions that come in from the chat.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          1033,
          13,
          286,
          478,
          1096,
          13,
          467,
          311,
          2272,
          2803,
          13,
          286,
          478,
          516,
          281,
          1867,
          257,
          1326,
          1651,
          300,
          808,
          294,
          490,
          264,
          5081,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.27796470344840707,
        "compression_ratio": 1.4615384615384615,
        "end": 6561.12,
        "id": 858,
        "no_speech_prob": 0.08755739033222198,
        "seek": 653912,
        "start": 6556,
        "temperature": 0,
        "text": " Thank you to all the sponsors and patrons of the coding train. This really motivates me.",
        "tokens": [
          51208,
          1044,
          291,
          281,
          439,
          264,
          22593,
          293,
          27559,
          295,
          264,
          17720,
          3847,
          13,
          639,
          534,
          42569,
          385,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.27796470344840707,
        "compression_ratio": 1.4615384615384615,
        "end": 6566.72,
        "id": 859,
        "no_speech_prob": 0.08755739033222198,
        "seek": 653912,
        "start": 6561.12,
        "temperature": 0,
        "text": " I'm like a numbers person. So the funding helps, but also just sort of like the numbers stuff.",
        "tokens": [
          51464,
          286,
          478,
          411,
          257,
          3547,
          954,
          13,
          407,
          264,
          6137,
          3665,
          11,
          457,
          611,
          445,
          1333,
          295,
          411,
          264,
          3547,
          1507,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.25533918055092414,
        "compression_ratio": 1.5921787709497206,
        "end": 6577.04,
        "id": 860,
        "no_speech_prob": 0.03621915355324745,
        "seek": 656672,
        "start": 6567.68,
        "temperature": 0,
        "text": " Appreciate it. And I'm going to come back for today. So actually, I'm going to put up a little",
        "tokens": [
          50412,
          37601,
          309,
          13,
          400,
          286,
          478,
          516,
          281,
          808,
          646,
          337,
          965,
          13,
          407,
          767,
          11,
          286,
          478,
          516,
          281,
          829,
          493,
          257,
          707,
          50880
        ]
      },
      {
        "avg_logprob": -0.25533918055092414,
        "compression_ratio": 1.5921787709497206,
        "end": 6581.76,
        "id": 861,
        "no_speech_prob": 0.03621915355324745,
        "seek": 656672,
        "start": 6577.04,
        "temperature": 0,
        "text": " straw poll. No, I won't because I'm not going to listen to it probably. So the things I want to",
        "tokens": [
          50880,
          10099,
          6418,
          13,
          883,
          11,
          286,
          1582,
          380,
          570,
          286,
          478,
          406,
          516,
          281,
          2140,
          281,
          309,
          1391,
          13,
          407,
          264,
          721,
          286,
          528,
          281,
          51116
        ]
      },
      {
        "avg_logprob": -0.25533918055092414,
        "compression_ratio": 1.5921787709497206,
        "end": 6591.68,
        "id": 862,
        "no_speech_prob": 0.03621915355324745,
        "seek": 656672,
        "start": 6581.76,
        "temperature": 0,
        "text": " talk about, the things that I want to do TensorFlow.js wise is I was going to, I think I'm not",
        "tokens": [
          51116,
          751,
          466,
          11,
          264,
          721,
          300,
          286,
          528,
          281,
          360,
          37624,
          13,
          25530,
          10829,
          307,
          286,
          390,
          516,
          281,
          11,
          286,
          519,
          286,
          478,
          406,
          51612
        ]
      },
      {
        "avg_logprob": -0.17329884501336848,
        "compression_ratio": 1.6514522821576763,
        "end": 6597.12,
        "id": 863,
        "no_speech_prob": 0.29743367433547974,
        "seek": 659168,
        "start": 6591.68,
        "temperature": 0,
        "text": " going to do this today. There's currently a bug in TensorFlow.js associated with the from pixels.",
        "tokens": [
          50364,
          516,
          281,
          360,
          341,
          965,
          13,
          821,
          311,
          4362,
          257,
          7426,
          294,
          37624,
          13,
          25530,
          6615,
          365,
          264,
          490,
          18668,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.17329884501336848,
        "compression_ratio": 1.6514522821576763,
        "end": 6601.52,
        "id": 864,
        "no_speech_prob": 0.29743367433547974,
        "seek": 659168,
        "start": 6597.12,
        "temperature": 0,
        "text": " So I think I'm not going to come back and do that. Maybe what I'll do is I'll do the linear regression",
        "tokens": [
          50636,
          407,
          286,
          519,
          286,
          478,
          406,
          516,
          281,
          808,
          646,
          293,
          360,
          300,
          13,
          2704,
          437,
          286,
          603,
          360,
          307,
          286,
          603,
          360,
          264,
          8213,
          24590,
          50856
        ]
      },
      {
        "avg_logprob": -0.17329884501336848,
        "compression_ratio": 1.6514522821576763,
        "end": 6610.64,
        "id": 865,
        "no_speech_prob": 0.29743367433547974,
        "seek": 659168,
        "start": 6601.52,
        "temperature": 0,
        "text": " example. And if I can do that and talk about the layers API, I'll be happy. I probably could only",
        "tokens": [
          50856,
          1365,
          13,
          400,
          498,
          286,
          393,
          360,
          300,
          293,
          751,
          466,
          264,
          7914,
          9362,
          11,
          286,
          603,
          312,
          2055,
          13,
          286,
          1391,
          727,
          787,
          51312
        ]
      },
      {
        "avg_logprob": -0.17329884501336848,
        "compression_ratio": 1.6514522821576763,
        "end": 6616.64,
        "id": 866,
        "no_speech_prob": 0.29743367433547974,
        "seek": 659168,
        "start": 6610.64,
        "temperature": 0,
        "text": " do, I was going to just do linear regression with TensorFlow.js as like a kind of baseline example.",
        "tokens": [
          51312,
          360,
          11,
          286,
          390,
          516,
          281,
          445,
          360,
          8213,
          24590,
          365,
          37624,
          13,
          25530,
          382,
          411,
          257,
          733,
          295,
          20518,
          1365,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2259254746764671,
        "compression_ratio": 1.5806451612903225,
        "end": 6620.64,
        "id": 867,
        "no_speech_prob": 0.03461609035730362,
        "seek": 661664,
        "start": 6616.64,
        "temperature": 0,
        "text": " Layers API. The next thing would be XOR and image classification and other stuff.",
        "tokens": [
          50364,
          20084,
          433,
          9362,
          13,
          440,
          958,
          551,
          576,
          312,
          1783,
          2483,
          293,
          3256,
          21538,
          293,
          661,
          1507,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2259254746764671,
        "compression_ratio": 1.5806451612903225,
        "end": 6622.64,
        "id": 868,
        "no_speech_prob": 0.03461609035730362,
        "seek": 661664,
        "start": 6621.200000000001,
        "temperature": 0,
        "text": " But I think that's what I'll start with.",
        "tokens": [
          50592,
          583,
          286,
          519,
          300,
          311,
          437,
          286,
          603,
          722,
          365,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2259254746764671,
        "compression_ratio": 1.5806451612903225,
        "end": 6633.200000000001,
        "id": 869,
        "no_speech_prob": 0.03461609035730362,
        "seek": 661664,
        "start": 6626.56,
        "temperature": 0,
        "text": " What's the best way to sponsor? Patreon or YouTube? I don't know. It's really up to you.",
        "tokens": [
          50860,
          708,
          311,
          264,
          1151,
          636,
          281,
          16198,
          30,
          15692,
          420,
          3088,
          30,
          286,
          500,
          380,
          458,
          13,
          467,
          311,
          534,
          493,
          281,
          291,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.2259254746764671,
        "compression_ratio": 1.5806451612903225,
        "end": 6636,
        "id": 870,
        "no_speech_prob": 0.03461609035730362,
        "seek": 661664,
        "start": 6633.200000000001,
        "temperature": 0,
        "text": " And you can always cancel one and switch to the other one if you don't like it. I mean,",
        "tokens": [
          51192,
          400,
          291,
          393,
          1009,
          10373,
          472,
          293,
          3679,
          281,
          264,
          661,
          472,
          498,
          291,
          500,
          380,
          411,
          309,
          13,
          286,
          914,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.2259254746764671,
        "compression_ratio": 1.5806451612903225,
        "end": 6642,
        "id": 871,
        "no_speech_prob": 0.03461609035730362,
        "seek": 661664,
        "start": 6636.64,
        "temperature": 0,
        "text": " probably in theory, I would get more. YouTube takes 30%. Patreon in theory doesn't take 30%,",
        "tokens": [
          51364,
          1391,
          294,
          5261,
          11,
          286,
          576,
          483,
          544,
          13,
          3088,
          2516,
          2217,
          6856,
          15692,
          294,
          5261,
          1177,
          380,
          747,
          2217,
          8923,
          51632
        ]
      },
      {
        "avg_logprob": -0.2259254746764671,
        "compression_ratio": 1.5806451612903225,
        "end": 6645.92,
        "id": 872,
        "no_speech_prob": 0.03461609035730362,
        "seek": 661664,
        "start": 6642,
        "temperature": 0,
        "text": " but the fee structure there is completely opaque to me. So I honestly have no idea. I almost like",
        "tokens": [
          51632,
          457,
          264,
          12054,
          3877,
          456,
          307,
          2584,
          42687,
          281,
          385,
          13,
          407,
          286,
          6095,
          362,
          572,
          1558,
          13,
          286,
          1920,
          411,
          51828
        ]
      },
      {
        "avg_logprob": -0.20060905302413787,
        "compression_ratio": 1.495798319327731,
        "end": 6652.16,
        "id": 873,
        "no_speech_prob": 0.08035095036029816,
        "seek": 664592,
        "start": 6645.92,
        "temperature": 0,
        "text": " it better that it's just clearly 30%, even though that's kind of high. So I don't know.",
        "tokens": [
          50364,
          309,
          1101,
          300,
          309,
          311,
          445,
          4448,
          2217,
          8923,
          754,
          1673,
          300,
          311,
          733,
          295,
          1090,
          13,
          407,
          286,
          500,
          380,
          458,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.20060905302413787,
        "compression_ratio": 1.495798319327731,
        "end": 6656.4,
        "id": 874,
        "no_speech_prob": 0.08035095036029816,
        "seek": 664592,
        "start": 6652.16,
        "temperature": 0,
        "text": " YouTube thing is nice. If you want to sponsor for more than $5, you have to use Patreon.",
        "tokens": [
          50676,
          3088,
          551,
          307,
          1481,
          13,
          759,
          291,
          528,
          281,
          16198,
          337,
          544,
          813,
          1848,
          20,
          11,
          291,
          362,
          281,
          764,
          15692,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.20060905302413787,
        "compression_ratio": 1.495798319327731,
        "end": 6662.24,
        "id": 875,
        "no_speech_prob": 0.08035095036029816,
        "seek": 664592,
        "start": 6657.68,
        "temperature": 0,
        "text": " If I also sponsor on YouTube as well as on Patreon, will that get me the $10 Patreon",
        "tokens": [
          50952,
          759,
          286,
          611,
          16198,
          322,
          3088,
          382,
          731,
          382,
          322,
          15692,
          11,
          486,
          300,
          483,
          385,
          264,
          1848,
          3279,
          15692,
          51180
        ]
      },
      {
        "avg_logprob": -0.20060905302413787,
        "compression_ratio": 1.495798319327731,
        "end": 6674.56,
        "id": 876,
        "no_speech_prob": 0.08035095036029816,
        "seek": 664592,
        "start": 6662.24,
        "temperature": 0,
        "text": " rewards? Sure. Why not? Why not? Let's have an offline Slack DM discussion about that. But I'm",
        "tokens": [
          51180,
          17203,
          30,
          4894,
          13,
          1545,
          406,
          30,
          1545,
          406,
          30,
          961,
          311,
          362,
          364,
          21857,
          37211,
          15322,
          5017,
          466,
          300,
          13,
          583,
          286,
          478,
          51796
        ]
      },
      {
        "avg_logprob": -0.23112376231067586,
        "compression_ratio": 1.48559670781893,
        "end": 6678.64,
        "id": 877,
        "no_speech_prob": 0.002287010895088315,
        "seek": 667456,
        "start": 6674.56,
        "temperature": 0,
        "text": " happy to do whatever is fair. How is ITP different from a normal university with some standard",
        "tokens": [
          50364,
          2055,
          281,
          360,
          2035,
          307,
          3143,
          13,
          1012,
          307,
          6783,
          47,
          819,
          490,
          257,
          2710,
          5454,
          365,
          512,
          3832,
          50568
        ]
      },
      {
        "avg_logprob": -0.23112376231067586,
        "compression_ratio": 1.48559670781893,
        "end": 6685.4400000000005,
        "id": 878,
        "no_speech_prob": 0.002287010895088315,
        "seek": 667456,
        "start": 6678.64,
        "temperature": 0,
        "text": " courses? That's a great question from Jaffrey. So first of all, let me just be clear.",
        "tokens": [
          50568,
          7712,
          30,
          663,
          311,
          257,
          869,
          1168,
          490,
          508,
          2518,
          7950,
          13,
          407,
          700,
          295,
          439,
          11,
          718,
          385,
          445,
          312,
          1850,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.23112376231067586,
        "compression_ratio": 1.48559670781893,
        "end": 6695.120000000001,
        "id": 879,
        "no_speech_prob": 0.002287010895088315,
        "seek": 667456,
        "start": 6686.400000000001,
        "temperature": 0,
        "text": " ITP.nyu.edu. There are two programs. ITP, two-year master's program. IMA, four-year",
        "tokens": [
          50956,
          6783,
          47,
          13,
          1634,
          84,
          13,
          22938,
          13,
          821,
          366,
          732,
          4268,
          13,
          6783,
          47,
          11,
          732,
          12,
          5294,
          4505,
          311,
          1461,
          13,
          286,
          9998,
          11,
          1451,
          12,
          5294,
          51392
        ]
      },
      {
        "avg_logprob": -0.23112376231067586,
        "compression_ratio": 1.48559670781893,
        "end": 6701.6,
        "id": 880,
        "no_speech_prob": 0.002287010895088315,
        "seek": 667456,
        "start": 6695.120000000001,
        "temperature": 0,
        "text": " undergraduate program. IMA is a BFA, Bachelor of Fine Arts. ITP is some degree that I don't know",
        "tokens": [
          51392,
          19113,
          1461,
          13,
          286,
          9998,
          307,
          257,
          363,
          19684,
          11,
          23193,
          295,
          12024,
          12407,
          13,
          6783,
          47,
          307,
          512,
          4314,
          300,
          286,
          500,
          380,
          458,
          51716
        ]
      },
      {
        "avg_logprob": -0.2405862808227539,
        "compression_ratio": 1.5491803278688525,
        "end": 6706.64,
        "id": 881,
        "no_speech_prob": 0.0000033931257803487824,
        "seek": 670160,
        "start": 6701.68,
        "temperature": 0,
        "text": " what it is. Never heard of. No. It's an MPS, Master of Professional... Master's in Probably",
        "tokens": [
          50368,
          437,
          309,
          307,
          13,
          7344,
          2198,
          295,
          13,
          883,
          13,
          467,
          311,
          364,
          376,
          6273,
          11,
          6140,
          295,
          30011,
          485,
          6140,
          311,
          294,
          9210,
          50616
        ]
      },
      {
        "avg_logprob": -0.2405862808227539,
        "compression_ratio": 1.5491803278688525,
        "end": 6713.84,
        "id": 882,
        "no_speech_prob": 0.0000033931257803487824,
        "seek": 670160,
        "start": 6706.64,
        "temperature": 0,
        "text": " Something. I think that's what it is. But I would say that... And I can speak to more about ITP",
        "tokens": [
          50616,
          6595,
          13,
          286,
          519,
          300,
          311,
          437,
          309,
          307,
          13,
          583,
          286,
          576,
          584,
          300,
          485,
          400,
          286,
          393,
          1710,
          281,
          544,
          466,
          6783,
          47,
          50976
        ]
      },
      {
        "avg_logprob": -0.2405862808227539,
        "compression_ratio": 1.5491803278688525,
        "end": 6724.56,
        "id": 883,
        "no_speech_prob": 0.0000033931257803487824,
        "seek": 670160,
        "start": 6715.6,
        "temperature": 0,
        "text": " being an ITP alum and having worked at ITP for 15 years now. IMA is a new program starting this",
        "tokens": [
          51064,
          885,
          364,
          6783,
          47,
          12064,
          293,
          1419,
          2732,
          412,
          6783,
          47,
          337,
          2119,
          924,
          586,
          13,
          286,
          9998,
          307,
          257,
          777,
          1461,
          2891,
          341,
          51512
        ]
      },
      {
        "avg_logprob": -0.2405862808227539,
        "compression_ratio": 1.5491803278688525,
        "end": 6729.68,
        "id": 884,
        "no_speech_prob": 0.0000033931257803487824,
        "seek": 670160,
        "start": 6724.56,
        "temperature": 0,
        "text": " fall. And IMA in many ways, it's probably a bit more traditional in the academic sense as it's",
        "tokens": [
          51512,
          2100,
          13,
          400,
          286,
          9998,
          294,
          867,
          2098,
          11,
          309,
          311,
          1391,
          257,
          857,
          544,
          5164,
          294,
          264,
          7778,
          2020,
          382,
          309,
          311,
          51768
        ]
      },
      {
        "avg_logprob": -0.24484451000507063,
        "compression_ratio": 1.4866310160427807,
        "end": 6735.04,
        "id": 885,
        "no_speech_prob": 0.0000026841371436603367,
        "seek": 672968,
        "start": 6729.68,
        "temperature": 0,
        "text": " an undergraduate BFA program. Non-traditional probably in spirit and culture, I would hope.",
        "tokens": [
          50364,
          364,
          19113,
          363,
          19684,
          1461,
          13,
          8774,
          12,
          43831,
          2628,
          1391,
          294,
          3797,
          293,
          3713,
          11,
          286,
          576,
          1454,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.24484451000507063,
        "compression_ratio": 1.4866310160427807,
        "end": 6749.12,
        "id": 886,
        "no_speech_prob": 0.0000026841371436603367,
        "seek": 672968,
        "start": 6736,
        "temperature": 0,
        "text": " So I would say ITP is a program about making more so than about sort of theory. And it's",
        "tokens": [
          50680,
          407,
          286,
          576,
          584,
          6783,
          47,
          307,
          257,
          1461,
          466,
          1455,
          544,
          370,
          813,
          466,
          1333,
          295,
          5261,
          13,
          400,
          309,
          311,
          51336
        ]
      },
      {
        "avg_logprob": -0.24484451000507063,
        "compression_ratio": 1.4866310160427807,
        "end": 6757.12,
        "id": 887,
        "no_speech_prob": 0.0000026841371436603367,
        "seek": 672968,
        "start": 6749.84,
        "temperature": 0,
        "text": " very interdisciplinary. And it's pass-fail. And a lot of what, to me, the magic of ITP is not the",
        "tokens": [
          51372,
          588,
          38280,
          13,
          400,
          309,
          311,
          1320,
          12,
          69,
          864,
          13,
          400,
          257,
          688,
          295,
          437,
          11,
          281,
          385,
          11,
          264,
          5585,
          295,
          6783,
          47,
          307,
          406,
          264,
          51736
        ]
      },
      {
        "avg_logprob": -0.26388973659939235,
        "compression_ratio": 1.618320610687023,
        "end": 6760.96,
        "id": 888,
        "no_speech_prob": 0.0002234141284134239,
        "seek": 675712,
        "start": 6757.12,
        "temperature": 0,
        "text": " courses that you're taking. It's the community and being here. And I would encourage you to watch",
        "tokens": [
          50364,
          7712,
          300,
          291,
          434,
          1940,
          13,
          467,
          311,
          264,
          1768,
          293,
          885,
          510,
          13,
          400,
          286,
          576,
          5373,
          291,
          281,
          1159,
          50556
        ]
      },
      {
        "avg_logprob": -0.26388973659939235,
        "compression_ratio": 1.618320610687023,
        "end": 6767.5199999999995,
        "id": 889,
        "no_speech_prob": 0.0002234141284134239,
        "seek": 675712,
        "start": 6760.96,
        "temperature": 0,
        "text": " my ITP show videos, which will give you a sense. Welcome new sponsor, Merin. Thank you, Merin.",
        "tokens": [
          50556,
          452,
          6783,
          47,
          855,
          2145,
          11,
          597,
          486,
          976,
          291,
          257,
          2020,
          13,
          4027,
          777,
          16198,
          11,
          6124,
          259,
          13,
          1044,
          291,
          11,
          6124,
          259,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.26388973659939235,
        "compression_ratio": 1.618320610687023,
        "end": 6773.5199999999995,
        "id": 890,
        "no_speech_prob": 0.0002234141284134239,
        "seek": 675712,
        "start": 6767.5199999999995,
        "temperature": 0,
        "text": " Double sponsor. Welcome. There are now only two double sponsors, Me, I Am So Me and Merin.",
        "tokens": [
          50884,
          16633,
          16198,
          13,
          4027,
          13,
          821,
          366,
          586,
          787,
          732,
          3834,
          22593,
          11,
          1923,
          11,
          286,
          2012,
          407,
          1923,
          293,
          6124,
          259,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.26388973659939235,
        "compression_ratio": 1.618320610687023,
        "end": 6778,
        "id": 891,
        "no_speech_prob": 0.0002234141284134239,
        "seek": 675712,
        "start": 6775.36,
        "temperature": 0,
        "text": " No, Me, I Am So Me is another bug in From Pixels.",
        "tokens": [
          51276,
          883,
          11,
          1923,
          11,
          286,
          2012,
          407,
          1923,
          307,
          1071,
          7426,
          294,
          3358,
          18652,
          1625,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.26388973659939235,
        "compression_ratio": 1.618320610687023,
        "end": 6784.8,
        "id": 892,
        "no_speech_prob": 0.0002234141284134239,
        "seek": 675712,
        "start": 6780.64,
        "temperature": 0,
        "text": " I don't want to get lost. Oh, that song ended. Oh, no, I just paused it. Let me just look.",
        "tokens": [
          51540,
          286,
          500,
          380,
          528,
          281,
          483,
          2731,
          13,
          876,
          11,
          300,
          2153,
          4590,
          13,
          876,
          11,
          572,
          11,
          286,
          445,
          46860,
          309,
          13,
          961,
          385,
          445,
          574,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.2504860560099284,
        "compression_ratio": 1.1368421052631579,
        "end": 6797.4400000000005,
        "id": 893,
        "no_speech_prob": 0.000021782247131341137,
        "seek": 678480,
        "start": 6784.8,
        "temperature": 0,
        "text": " There's another. Let me just look really quickly. There's another From Pixels bug.",
        "tokens": [
          50364,
          821,
          311,
          1071,
          13,
          961,
          385,
          445,
          574,
          534,
          2661,
          13,
          821,
          311,
          1071,
          3358,
          18652,
          1625,
          7426,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2504860560099284,
        "compression_ratio": 1.1368421052631579,
        "end": 6802.72,
        "id": 894,
        "no_speech_prob": 0.000021782247131341137,
        "seek": 678480,
        "start": 6800.8,
        "temperature": 0,
        "text": " It's in just in point 11.",
        "tokens": [
          51164,
          467,
          311,
          294,
          445,
          294,
          935,
          2975,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.33362115662673425,
        "compression_ratio": 1.2714285714285714,
        "end": 6815.68,
        "id": 895,
        "no_speech_prob": 0.0008426393033005297,
        "seek": 680272,
        "start": 6802.8,
        "temperature": 0,
        "text": " Yep, it's this one. This particular bug. So this is a From Pixels bug in 0.11.1.",
        "tokens": [
          50368,
          7010,
          11,
          309,
          311,
          341,
          472,
          13,
          639,
          1729,
          7426,
          13,
          407,
          341,
          307,
          257,
          3358,
          18652,
          1625,
          7426,
          294,
          1958,
          13,
          5348,
          13,
          16,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.33362115662673425,
        "compression_ratio": 1.2714285714285714,
        "end": 6826,
        "id": 896,
        "no_speech_prob": 0.0008426393033005297,
        "seek": 680272,
        "start": 6818.4800000000005,
        "temperature": 0,
        "text": " Sensei, oh, one more question. Sensei Clock Clo asks, hey, Dan, I wondered how you started coding",
        "tokens": [
          51152,
          33123,
          72,
          11,
          1954,
          11,
          472,
          544,
          1168,
          13,
          33123,
          72,
          31901,
          547,
          31901,
          8962,
          11,
          4177,
          11,
          3394,
          11,
          286,
          17055,
          577,
          291,
          1409,
          17720,
          51528
        ]
      },
      {
        "avg_logprob": -0.22649205647982085,
        "compression_ratio": 1.6363636363636365,
        "end": 6835.36,
        "id": 897,
        "no_speech_prob": 0.0028448114171624184,
        "seek": 682600,
        "start": 6826,
        "temperature": 0,
        "text": " train. All right. I got an answer for this one. Vimeo, Shiftman. So if you go look at this",
        "tokens": [
          50364,
          3847,
          13,
          1057,
          558,
          13,
          286,
          658,
          364,
          1867,
          337,
          341,
          472,
          13,
          691,
          1312,
          78,
          11,
          1160,
          351,
          83,
          1601,
          13,
          407,
          498,
          291,
          352,
          574,
          412,
          341,
          50832
        ]
      },
      {
        "avg_logprob": -0.22649205647982085,
        "compression_ratio": 1.6363636363636365,
        "end": 6846.64,
        "id": 898,
        "no_speech_prob": 0.0028448114171624184,
        "seek": 682600,
        "start": 6837.92,
        "temperature": 0,
        "text": " now deprecated Vimeo channel, you will see a lot of the videos that I have on YouTube here.",
        "tokens": [
          50960,
          586,
          1367,
          13867,
          770,
          691,
          1312,
          78,
          2269,
          11,
          291,
          486,
          536,
          257,
          688,
          295,
          264,
          2145,
          300,
          286,
          362,
          322,
          3088,
          510,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.22649205647982085,
        "compression_ratio": 1.6363636363636365,
        "end": 6851.76,
        "id": 899,
        "no_speech_prob": 0.0028448114171624184,
        "seek": 682600,
        "start": 6847.2,
        "temperature": 0,
        "text": " So originally, I was just making these videos and publishing them on Vimeo. And I was really doing",
        "tokens": [
          51424,
          407,
          7993,
          11,
          286,
          390,
          445,
          1455,
          613,
          2145,
          293,
          17832,
          552,
          322,
          691,
          1312,
          78,
          13,
          400,
          286,
          390,
          534,
          884,
          51652
        ]
      },
      {
        "avg_logprob": -0.22649205647982085,
        "compression_ratio": 1.6363636363636365,
        "end": 6855.44,
        "id": 900,
        "no_speech_prob": 0.0028448114171624184,
        "seek": 682600,
        "start": 6851.76,
        "temperature": 0,
        "text": " it just as for the courses that I was teaching and then putting them online, hoping other people",
        "tokens": [
          51652,
          309,
          445,
          382,
          337,
          264,
          7712,
          300,
          286,
          390,
          4571,
          293,
          550,
          3372,
          552,
          2950,
          11,
          7159,
          661,
          561,
          51836
        ]
      },
      {
        "avg_logprob": -0.19847840808686756,
        "compression_ratio": 1.625,
        "end": 6860.4,
        "id": 901,
        "no_speech_prob": 0.0006166164530441165,
        "seek": 685544,
        "start": 6855.44,
        "temperature": 0,
        "text": " would watch. And I should try to find somewhere I have an email from somebody who said, could you",
        "tokens": [
          50364,
          576,
          1159,
          13,
          400,
          286,
          820,
          853,
          281,
          915,
          4079,
          286,
          362,
          364,
          3796,
          490,
          2618,
          567,
          848,
          11,
          727,
          291,
          50612
        ]
      },
      {
        "avg_logprob": -0.19847840808686756,
        "compression_ratio": 1.625,
        "end": 6866.08,
        "id": 902,
        "no_speech_prob": 0.0006166164530441165,
        "seek": 685544,
        "start": 6860.4,
        "temperature": 0,
        "text": " upload your videos to YouTube? I want to watch them on 2X. And I did that, I think, in like September",
        "tokens": [
          50612,
          6580,
          428,
          2145,
          281,
          3088,
          30,
          286,
          528,
          281,
          1159,
          552,
          322,
          568,
          55,
          13,
          400,
          286,
          630,
          300,
          11,
          286,
          519,
          11,
          294,
          411,
          7216,
          50896
        ]
      },
      {
        "avg_logprob": -0.19847840808686756,
        "compression_ratio": 1.625,
        "end": 6873.839999999999,
        "id": 903,
        "no_speech_prob": 0.0006166164530441165,
        "seek": 685544,
        "start": 6866.08,
        "temperature": 0,
        "text": " 2015. And I had I just took all of the videos. So I guess the 253 videos I had on Vimeo and I",
        "tokens": [
          50896,
          7546,
          13,
          400,
          286,
          632,
          286,
          445,
          1890,
          439,
          295,
          264,
          2145,
          13,
          407,
          286,
          2041,
          264,
          3552,
          18,
          2145,
          286,
          632,
          322,
          691,
          1312,
          78,
          293,
          286,
          51284
        ]
      },
      {
        "avg_logprob": -0.19847840808686756,
        "compression_ratio": 1.625,
        "end": 6880.08,
        "id": 904,
        "no_speech_prob": 0.0006166164530441165,
        "seek": 685544,
        "start": 6873.839999999999,
        "temperature": 0,
        "text": " uploaded them all to YouTube. And then I discovered that I could also live stream at some point.",
        "tokens": [
          51284,
          17135,
          552,
          439,
          281,
          3088,
          13,
          400,
          550,
          286,
          6941,
          300,
          286,
          727,
          611,
          1621,
          4309,
          412,
          512,
          935,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.278326541819471,
        "compression_ratio": 1.3255813953488371,
        "end": 6887.36,
        "id": 905,
        "no_speech_prob": 0.002980896970257163,
        "seek": 688008,
        "start": 6880.08,
        "temperature": 0,
        "text": " So something that you can amuse yourself with watching is if you go to the coding train and",
        "tokens": [
          50364,
          407,
          746,
          300,
          291,
          393,
          669,
          438,
          1803,
          365,
          1976,
          307,
          498,
          291,
          352,
          281,
          264,
          17720,
          3847,
          293,
          50728
        ]
      },
      {
        "avg_logprob": -0.278326541819471,
        "compression_ratio": 1.3255813953488371,
        "end": 6898.16,
        "id": 906,
        "no_speech_prob": 0.002980896970257163,
        "seek": 688008,
        "start": 6888.24,
        "temperature": 0,
        "text": " under, let's see, playlists. And unlisted live streams. Don't look at that one.",
        "tokens": [
          50772,
          833,
          11,
          718,
          311,
          536,
          11,
          862,
          36693,
          13,
          400,
          517,
          34890,
          1621,
          15842,
          13,
          1468,
          380,
          574,
          412,
          300,
          472,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.44172595796130953,
        "compression_ratio": 1.3017241379310345,
        "end": 6913.28,
        "id": 907,
        "no_speech_prob": 0.007121365983039141,
        "seek": 689816,
        "start": 6898.16,
        "temperature": 0,
        "text": " I shouldn't be live. I probably shouldn't log into my YouTube live stream. I stream archive.",
        "tokens": [
          50364,
          286,
          4659,
          380,
          312,
          1621,
          13,
          286,
          1391,
          4659,
          380,
          3565,
          666,
          452,
          3088,
          1621,
          4309,
          13,
          286,
          4309,
          23507,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.44172595796130953,
        "compression_ratio": 1.3017241379310345,
        "end": 6920.639999999999,
        "id": 908,
        "no_speech_prob": 0.007121365983039141,
        "seek": 689816,
        "start": 6914.72,
        "temperature": 0,
        "text": " Yeah, this one. Live stream number one, September 4, 2015.",
        "tokens": [
          51192,
          865,
          11,
          341,
          472,
          13,
          10385,
          4309,
          1230,
          472,
          11,
          7216,
          1017,
          11,
          7546,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.3103857145204649,
        "compression_ratio": 1.7195767195767195,
        "end": 6926.08,
        "id": 909,
        "no_speech_prob": 0.009559077210724354,
        "seek": 692064,
        "start": 6921.200000000001,
        "temperature": 0,
        "text": " And this is me, I think, live streaming through Google Hangouts. I think.",
        "tokens": [
          50392,
          400,
          341,
          307,
          385,
          11,
          286,
          519,
          11,
          1621,
          11791,
          807,
          3329,
          14070,
          7711,
          13,
          286,
          519,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.3103857145204649,
        "compression_ratio": 1.7195767195767195,
        "end": 6936.320000000001,
        "id": 910,
        "no_speech_prob": 0.009559077210724354,
        "seek": 692064,
        "start": 6930.08,
        "temperature": 0,
        "text": " I don't know. But this is, you can watch this. Somewhere there's a live stream that I did through",
        "tokens": [
          50836,
          286,
          500,
          380,
          458,
          13,
          583,
          341,
          307,
          11,
          291,
          393,
          1159,
          341,
          13,
          34500,
          456,
          311,
          257,
          1621,
          4309,
          300,
          286,
          630,
          807,
          51148
        ]
      },
      {
        "avg_logprob": -0.3103857145204649,
        "compression_ratio": 1.7195767195767195,
        "end": 6940.08,
        "id": 911,
        "no_speech_prob": 0.009559077210724354,
        "seek": 692064,
        "start": 6936.320000000001,
        "temperature": 0,
        "text": " Google Hangouts. That's not what this is. This looks like it's actually live streamed, live streamed.",
        "tokens": [
          51148,
          3329,
          14070,
          7711,
          13,
          663,
          311,
          406,
          437,
          341,
          307,
          13,
          639,
          1542,
          411,
          309,
          311,
          767,
          1621,
          4309,
          292,
          11,
          1621,
          4309,
          292,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.3103857145204649,
        "compression_ratio": 1.7195767195767195,
        "end": 6945.04,
        "id": 912,
        "no_speech_prob": 0.009559077210724354,
        "seek": 692064,
        "start": 6940.8,
        "temperature": 0,
        "text": " But anyway, so that's kind of a bit of the history.",
        "tokens": [
          51372,
          583,
          4033,
          11,
          370,
          300,
          311,
          733,
          295,
          257,
          857,
          295,
          264,
          2503,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.40112159992086477,
        "compression_ratio": 1.541237113402062,
        "end": 6953.2,
        "id": 913,
        "no_speech_prob": 0.0036499439738690853,
        "seek": 694504,
        "start": 6945.76,
        "temperature": 0,
        "text": " History. Looks like there was maybe another sponsor. Is that still just Madden?",
        "tokens": [
          50400,
          12486,
          13,
          10027,
          411,
          456,
          390,
          1310,
          1071,
          16198,
          13,
          1119,
          300,
          920,
          445,
          376,
          345,
          1556,
          30,
          50772
        ]
      },
      {
        "avg_logprob": -0.40112159992086477,
        "compression_ratio": 1.541237113402062,
        "end": 6954.96,
        "id": 914,
        "no_speech_prob": 0.0036499439738690853,
        "seek": 694504,
        "start": 6953.84,
        "temperature": 0,
        "text": " No, that's just Madden. Okay.",
        "tokens": [
          50804,
          883,
          11,
          300,
          311,
          445,
          5326,
          1556,
          13,
          1033,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.40112159992086477,
        "compression_ratio": 1.541237113402062,
        "end": 6968.88,
        "id": 915,
        "no_speech_prob": 0.0036499439738690853,
        "seek": 694504,
        "start": 6962.88,
        "temperature": 0,
        "text": " Thank you, everybody, for tuning in. I have a bunch of things, a bunch, a bunch of things I",
        "tokens": [
          51256,
          1044,
          291,
          11,
          2201,
          11,
          337,
          15164,
          294,
          13,
          286,
          362,
          257,
          3840,
          295,
          721,
          11,
          257,
          3840,
          11,
          257,
          3840,
          295,
          721,
          286,
          51556
        ]
      },
      {
        "avg_logprob": -0.40112159992086477,
        "compression_ratio": 1.541237113402062,
        "end": 6972.88,
        "id": 916,
        "no_speech_prob": 0.0036499439738690853,
        "seek": 694504,
        "start": 6968.88,
        "temperature": 0,
        "text": " have to do today. It's coming back at four. Things are going to be tricky, but I think it's worth",
        "tokens": [
          51556,
          362,
          281,
          360,
          965,
          13,
          467,
          311,
          1348,
          646,
          412,
          1451,
          13,
          9514,
          366,
          516,
          281,
          312,
          12414,
          11,
          457,
          286,
          519,
          309,
          311,
          3163,
          51756
        ]
      },
      {
        "avg_logprob": -0.2713160421334061,
        "compression_ratio": 1.6355932203389831,
        "end": 6978.08,
        "id": 917,
        "no_speech_prob": 0.00781578291207552,
        "seek": 697288,
        "start": 6972.88,
        "temperature": 0,
        "text": " doing. It will only be for an hour. So, hopefully, I can at least do linear regression with TensorFlow.js.",
        "tokens": [
          50364,
          884,
          13,
          467,
          486,
          787,
          312,
          337,
          364,
          1773,
          13,
          407,
          11,
          4696,
          11,
          286,
          393,
          412,
          1935,
          360,
          8213,
          24590,
          365,
          37624,
          13,
          25530,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.2713160421334061,
        "compression_ratio": 1.6355932203389831,
        "end": 6982.88,
        "id": 918,
        "no_speech_prob": 0.00781578291207552,
        "seek": 697288,
        "start": 6978.72,
        "temperature": 0,
        "text": " How are you able to learn so much programming language? I don't know. I don't know that I know",
        "tokens": [
          50656,
          1012,
          366,
          291,
          1075,
          281,
          1466,
          370,
          709,
          9410,
          2856,
          30,
          286,
          500,
          380,
          458,
          13,
          286,
          500,
          380,
          458,
          300,
          286,
          458,
          50864
        ]
      },
      {
        "avg_logprob": -0.2713160421334061,
        "compression_ratio": 1.6355932203389831,
        "end": 6987.68,
        "id": 919,
        "no_speech_prob": 0.00781578291207552,
        "seek": 697288,
        "start": 6982.88,
        "temperature": 0,
        "text": " so much programming language. I think it's just doing and trying and actually teaching it has",
        "tokens": [
          50864,
          370,
          709,
          9410,
          2856,
          13,
          286,
          519,
          309,
          311,
          445,
          884,
          293,
          1382,
          293,
          767,
          4571,
          309,
          575,
          51104
        ]
      },
      {
        "avg_logprob": -0.2713160421334061,
        "compression_ratio": 1.6355932203389831,
        "end": 6999.84,
        "id": 920,
        "no_speech_prob": 0.00781578291207552,
        "seek": 697288,
        "start": 6987.68,
        "temperature": 0,
        "text": " helped me learn a lot. Okay. Thank you so much, everybody. I just, just, okay, sorry. Stop",
        "tokens": [
          51104,
          4254,
          385,
          1466,
          257,
          688,
          13,
          1033,
          13,
          1044,
          291,
          370,
          709,
          11,
          2201,
          13,
          286,
          445,
          11,
          445,
          11,
          1392,
          11,
          2597,
          13,
          5535,
          51712
        ]
      },
      {
        "avg_logprob": -0.2298055276638124,
        "compression_ratio": 1.5846994535519126,
        "end": 7005.52,
        "id": 921,
        "no_speech_prob": 0.0057301754131913185,
        "seek": 699984,
        "start": 6999.84,
        "temperature": 0,
        "text": " torturing me, people. I'm going to go now. I don't know. Maybe I'm torturing people too much with",
        "tokens": [
          50364,
          10806,
          1345,
          385,
          11,
          561,
          13,
          286,
          478,
          516,
          281,
          352,
          586,
          13,
          286,
          500,
          380,
          458,
          13,
          2704,
          286,
          478,
          10806,
          1345,
          561,
          886,
          709,
          365,
          50648
        ]
      },
      {
        "avg_logprob": -0.2298055276638124,
        "compression_ratio": 1.5846994535519126,
        "end": 7009.2,
        "id": 922,
        "no_speech_prob": 0.0057301754131913185,
        "seek": 699984,
        "start": 7005.52,
        "temperature": 0,
        "text": " playing that outro every time. So, I think maybe I'll, maybe I won't do the outro, especially",
        "tokens": [
          50648,
          2433,
          300,
          13170,
          633,
          565,
          13,
          407,
          11,
          286,
          519,
          1310,
          286,
          603,
          11,
          1310,
          286,
          1582,
          380,
          360,
          264,
          13170,
          11,
          2318,
          50832
        ]
      },
      {
        "avg_logprob": -0.2298055276638124,
        "compression_ratio": 1.5846994535519126,
        "end": 7021.92,
        "id": 923,
        "no_speech_prob": 0.0057301754131913185,
        "seek": 699984,
        "start": 7009.2,
        "temperature": 0,
        "text": " since I'm coming back. Oh, the Coding Train wallpaper. I think on the Coding Train GitHub website,",
        "tokens": [
          50832,
          1670,
          286,
          478,
          1348,
          646,
          13,
          876,
          11,
          264,
          383,
          8616,
          28029,
          43293,
          13,
          286,
          519,
          322,
          264,
          383,
          8616,
          28029,
          23331,
          3144,
          11,
          51468
        ]
      },
      {
        "avg_logprob": -0.2462531466816747,
        "compression_ratio": 1.5544041450777202,
        "end": 7034.4,
        "id": 924,
        "no_speech_prob": 0.010169494897127151,
        "seek": 702192,
        "start": 7021.92,
        "temperature": 0,
        "text": " issues, so, yeah, I mean, it doesn't, you have to dig into this issue and find maybe a link that I put",
        "tokens": [
          50364,
          2663,
          11,
          370,
          11,
          1338,
          11,
          286,
          914,
          11,
          309,
          1177,
          380,
          11,
          291,
          362,
          281,
          2528,
          666,
          341,
          2734,
          293,
          915,
          1310,
          257,
          2113,
          300,
          286,
          829,
          50988
        ]
      },
      {
        "avg_logprob": -0.2462531466816747,
        "compression_ratio": 1.5544041450777202,
        "end": 7042.4,
        "id": 925,
        "no_speech_prob": 0.010169494897127151,
        "seek": 702192,
        "start": 7034.4,
        "temperature": 0,
        "text": " somewhere in here. Oh, yeah, the files are on GitHub, but it should, there should be like a more",
        "tokens": [
          50988,
          4079,
          294,
          510,
          13,
          876,
          11,
          1338,
          11,
          264,
          7098,
          366,
          322,
          23331,
          11,
          457,
          309,
          820,
          11,
          456,
          820,
          312,
          411,
          257,
          544,
          51388
        ]
      },
      {
        "avg_logprob": -0.2462531466816747,
        "compression_ratio": 1.5544041450777202,
        "end": 7046.64,
        "id": 926,
        "no_speech_prob": 0.010169494897127151,
        "seek": 702192,
        "start": 7042.4,
        "temperature": 0,
        "text": " obvious place to download it, but, yeah. So, if you read through this issue, you'll see where it is.",
        "tokens": [
          51388,
          6322,
          1081,
          281,
          5484,
          309,
          11,
          457,
          11,
          1338,
          13,
          407,
          11,
          498,
          291,
          1401,
          807,
          341,
          2734,
          11,
          291,
          603,
          536,
          689,
          309,
          307,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.34261218288488554,
        "compression_ratio": 1.3223684210526316,
        "end": 7059.12,
        "id": 927,
        "no_speech_prob": 0.0014324614312499762,
        "seek": 704664,
        "start": 7047.04,
        "temperature": 0,
        "text": " Do I play Fortnite? Last question. I have not. My son, who is nine, plays Fortnite. Is that where",
        "tokens": [
          50384,
          1144,
          286,
          862,
          28712,
          30,
          5264,
          1168,
          13,
          286,
          362,
          406,
          13,
          1222,
          1872,
          11,
          567,
          307,
          4949,
          11,
          5749,
          28712,
          13,
          1119,
          300,
          689,
          50988
        ]
      },
      {
        "avg_logprob": -0.34261218288488554,
        "compression_ratio": 1.3223684210526316,
        "end": 7066.4800000000005,
        "id": 928,
        "no_speech_prob": 0.0014324614312499762,
        "seek": 704664,
        "start": 7059.12,
        "temperature": 0,
        "text": " everyone does the like pickle thing from, which I can't do? Anyway, I got to go. This live chat will be",
        "tokens": [
          50988,
          1518,
          775,
          264,
          411,
          31433,
          551,
          490,
          11,
          597,
          286,
          393,
          380,
          360,
          30,
          5684,
          11,
          286,
          658,
          281,
          352,
          13,
          639,
          1621,
          5081,
          486,
          312,
          51356
        ]
      },
      {
        "avg_logprob": -0.3351432743357189,
        "compression_ratio": 1.5031055900621118,
        "end": 7076.5599999999995,
        "id": 929,
        "no_speech_prob": 0.01566171832382679,
        "seek": 706648,
        "start": 7066.959999999999,
        "temperature": 0,
        "text": " that this live chat, the live chats are always archived. So, you come back and watch the",
        "tokens": [
          50388,
          300,
          341,
          1621,
          5081,
          11,
          264,
          1621,
          38057,
          366,
          1009,
          3912,
          3194,
          13,
          407,
          11,
          291,
          808,
          646,
          293,
          1159,
          264,
          50868
        ]
      },
      {
        "avg_logprob": -0.3351432743357189,
        "compression_ratio": 1.5031055900621118,
        "end": 7082.24,
        "id": 930,
        "no_speech_prob": 0.01566171832382679,
        "seek": 706648,
        "start": 7076.5599999999995,
        "temperature": 0,
        "text": " archive of the stream, the live chats play along. Okay, I got to go. Goodbye, everybody. Thank you.",
        "tokens": [
          50868,
          23507,
          295,
          264,
          4309,
          11,
          264,
          1621,
          38057,
          862,
          2051,
          13,
          1033,
          11,
          286,
          658,
          281,
          352,
          13,
          15528,
          11,
          2201,
          13,
          1044,
          291,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.3351432743357189,
        "compression_ratio": 1.5031055900621118,
        "end": 7089.04,
        "id": 931,
        "no_speech_prob": 0.01566171832382679,
        "seek": 706648,
        "start": 7082.24,
        "temperature": 0,
        "text": " I will see you, I think, this afternoon for one hour.",
        "tokens": [
          51152,
          286,
          486,
          536,
          291,
          11,
          286,
          519,
          11,
          341,
          6499,
          337,
          472,
          1773,
          13,
          51492
        ]
      }
    ],
    "transcription": " Good morning! Again, it's the second Coding Train livestream of this week. So I'm really going to try to just jump right into things, as opposed to what I did yesterday, which was spend about 45 minutes talking arbitrarily about all sorts of random topics like schedule and that sort of thing. I do have to say something important here, which is that as many of you are interested in, I know, I don't know whether... many of you are just the loudest voices of you, are interested in more tutorials on machine learning, in particular in the browser with TensorFlow.js. So I'm getting to that. And I'd hoped that that would be the primary topic of today. But yesterday I started doing some tutorials on promises, and I want to finish that sequence first, because it will lay the foundation for certain things that I will need when making some examples with TensorFlow.js. For example, in particular, the async keyword and the await keyword. Now, something very strange has been going on here in the studio, and which I can't really explain, because I... I don't... this room gets used by other people, and of course other people should use this room. And I try to, as much time as I might have, looking for my marker. Help other people make use of this room. But usually I hear about it, and also it's the summer, so I didn't really think. But there's a marker down here. Is this it? Strangely, the whiteboard was erased. It actually had some other writing on it. I erased it before I started live streaming. I just got to check to make sure everything looks and sounds okay. Ding choo choo. Nobody seems to be complaining. So yeah. All right. So I don't know who was in here yesterday. If you are watching this and you were in here yesterday, please send me a message. So let me make a list of what I want to cover today. So yesterday I just did the basic, you know, what is a promise? And I looked at it in the context of fetch. So using the fetch function to retrieve data from a URL and resolving the promise when the data comes in. That might not have been the best way to explain that, but so be it. So and then I went off, off and off and off and off, trying to explain promise.all. And so many things I got wrong. Number one is I just kept saying promises.all, and it's promise.all. Number two is I got into this thing where I was like, I have an array of promises, and then I need to get a new array of promises from that array of promises. And there was this whole extra sequence. And then I used a loop and I tried to use the map function. It was kind of a mess. It was good. It was really good for me. I learned a lot. And I also learned what people think about that, the way that I code, which is often that's terrible. Why are you doing it that way? And then there's some people who have some other feedback like, yeah, you know, maybe it's not the best, but it kind of explains it. It works. So anyway, I'm going to take a mulligan on that. But I've thought about this and I actually did some coding this morning before I came in here. So what I'm going to do next, I'm going to get to promise.all, but next I'm going to look at how to make your own promise. I promise you. How to, I wish I had, I have my keyboard over here. If I had really thought better of it, I would have, I would have come in with some promise related music, maybe later. How to make your own promise. I think the joke I made yesterday, is this still, am I still on the board? Was that if I title a YouTube video or how to keep your promises, maybe like people who are looking for self-help videos will come and find my channel and then they'll decide they want to learn to code. What is a promise fetch? How to make your promise. Okay. That's a weird thing that I wrote. How to make your promise. I don't know how I feel about that, but I'll leave it there. It's a little bit weird, but fine. Then I want to look at async and await. And this is really what's often referred to as syntax sugar. So there will be no new concepts, but there will be a less verbose way of writing a function that returns a promise using async and await. And then the last piece of this, I think will be promise.all. So this is my new plan. If I can get through all of this today, I'll be amazed. If I could get through all of this today and start to talk about TensorFlow.js, that will be a miracle. But have no fear. Whatever I don't get to, I will get to next time. I am here every week throughout the summer. I did say yesterday that I was going to do twice a week live streams, and that's sort of true. But then I started looking at the calendar and there's a lot going on. And also, here I said I was going to get started writing the material, and now I'm just rambling. But one thing I want to say is that I think, and I'm sorry for using my YouTube channel as a personal therapy session for myself, but I'm realizing that there are some things I really want to accomplish this summer. Two of the, these are the things. I really want to, I really want to have a second edition of this book out. And a version of it within JavaScript. So right now, this book, The Nature of Code, is written in Java using the processing programming environment. I have many updates that I've actually made to it, but I've just never gotten them onto the website and into the print version of the book. So I want to make that happen. I want to add a new chapter, which is about neuroevolution. And then I want to, once that's done, have a JavaScript version of the book. And if I'm live streaming all the time, I'll never have any time to work on this. So number one is, who wants to help me with this? On the one hand, I just kind of need to go off and work on it. But if you have some clever ideas or want to look through my various GitHub repositories and help, I'm open to that. And then I think that I need to, at some point, limit myself as much to focus, make sure I work. So keep me honest here. So this is the number one. And the other thing is, and let's see if I can get there now. The new URL, I haven't gotten HTTPS working yet. So I need to get HTTPS working for this domain. But ml5js, which is a friendly machine learning library written in JavaScript built on top of TensorFlow.js. This is a project that I would like to spend a lot of time working on. The good news about this is, this has a whole group of people who are developing it. And it's an open source project. And you can see some of them here. People who are contributing to this project. So this is, even if I broke my other elbow and stopped working this summer, this would still happen. But the nature of Codebook is something I really need to focus on. Live stream working on it, problem solved. Huh? I don't know what that refers to. All right. Looking at the chat. It's spring. Yes, it is. Oh, you know, the other thing I really should do is I really want to update my workflow this summer. So I want to start playing around with using Visual Studio Code. I might use Atom here and there still. I want to use iTerm. It's a different terminal. And I want to start to also I'm going to go back and start to do some very beginner videos again. It's been quite a while since I did my beginner learn to program from scratch videos. And those need some refreshing. Ah, interfere interference something and why writes, will you make some project Euler problems? It's pronounced Euler, it's very interesting thing. Check it out. I am familiar with project Euler. I would have fun doing that. So that's not a bad idea. Oh, problem solved. Working on the book, I mean. Oh, live stream working on the book. I get it. Me, I am so me is making a good point that I could just live stream my work sessions. It's not the worst idea. I definitely would consider that. All right. The stream title says async instead of async. Let me fix that. Let me fix that. Thank you for pointing that out. Where do I find that? Info and settings. A, Y, A, S, Y. Thank you. Whoops. A, S, Y, N, C. Okay. Thanks for all the nice Vim. I'm not really a Vim. I wish I was like a Vim person, but you know me. I'm not a Vim person. I didn't grow up programming. And so I never found my way to those kind of old school tools. Okay. All right. So thanks to everyone saying hi in the chat. I appreciate all those messages. I think I'm just going to get started. So this first video is going to be how to make your promise. All right. Let's come I didn't buy a new microphone. I still haven't found the old microphone. I think this one might be a little bit better, though. You tell me. So let me close a bunch of stuff. And I promise you. What is that song? And after all that's been said and done. If I do my terrible singing, I don't think I get a copyright violation. I think it's only if it's exactly the original track, but also because I'm terribly out of tune. This is an advantage to being out of tune. Let me move to the side. Desktop. I want to be working on promises. I'm going to move this away. Let's pretend we never did this. Let's go to desktop. Promises. Let's put this away in the past. It's in the past. We're moving on to the future. And we're going to say O2 promises. Make your own. And I'm going to do this. Make your own. Quadrennial. And then I'm going to I must have Adam this open somewhere. Check the Slack channel. Mic is way better. That's good to hear. Maybe I'll just keep using this mic. Old mic is better. I could do a straw poll for that. I'm not going to. Let's go here. We don't need any of this stuff. One thing is, here's a I shouldn't talk about this yet. I have a maybe almost tentative plan to also live stream from home. That's a terrible idea, I think. But stay tuned. I need to buy a new computer to do that, though. That's the issue. And that is expensive. I'm waiting until WWDC. Is that what it's called? Maybe I'll announce all the new stuff there. I could be on Saturday morning at 9 a.m. Let me work on nature of code book. It's complicated. Let's do this. I'm going to keep the P5 library base almost like as a security blanket. I'm going to just do something. I just want to have this video start. I just want to have an example, some example code. Ready to go. And say hello is not defined. I should say say hello. All right. Here we go. This is really not good today. That's a little better. Yeah. I can't really see it. By the way, if people have equipment suggestions for things that I should get to improve this live stream, I'm definitely all ears. And a nose and a mouth. But I'd be happy for suggestions. All right. Let me cycle the camera. So that will All right. You know, I'm also having this lower back pain on this side. That's not going to mess up my live stream. I don't think it's from I think it's probably from sitting. I don't actually sit and work very much. I'm either standing and talking or I'm running around talking to people and doing stuff. I don't actually sit and work. But yesterday and the day before, I was kind of doing that for hours at a time. I think maybe I need to get up. Get a Sennheiser lavalier mic. I think that's what my other thing was. But I will check. So I'm going to answer one more question, then I'm going to go to the next one. So I'm going to answer one more question, then I'm going to move on. Koosh in the chat asks, can we have a Discord where we can discuss our problem, the coding train? So let me just quickly say a few words about community while I'm here. So everyone watching the channel is welcome to self-organize and create their own forums or Discords or Reddit threads or whatever to talk about coding. And you're welcome to do that. I am currently keeping a... I have an official coding train Slack channel. But the best way I found to manage that right now is through a membership to Patreon or sponsorship on the YouTube channel. So I don't want to... I've talked about it in several different videos already. So you can find it. But that's basically... That's the one official... Then, of course, there are the official coding train GitHub repositories. And I do want to mention, I really am remiss in not having done this sooner. But I just want to mention... And this... Maybe I'll come back to this when it's more finalized. But I also now have a code of conduct repo. So this code of conduct applies to interactions in the YouTube chat, YouTube comments, Slack channel, GitHub, participation in the coding train community. So if... Also, what this is really is... At the present is a copy of the p5.js code of conduct. And so if anyone has experience with online communities and codes of conduct and wants to contribute and help make this better and help me do better managing the community, I am, again, all ears and a nose. You know, I have this... I need to get new lenses. Because even though I'm blind, my lens is all scratched up right there and I can't actually see. And I have tickets to go see Solo this weekend. And if I don't have good glasses, I'm not gonna enjoy the movie. I don't know how this is gonna happen. Okay. I gotta get started. So that's what I have to say. All right. I promise you... Hey, we've got a new sponsor, Mobius. Thank you. Once again, if you... Once again, if you choose to sponsor this YouTube channel on YouTube, you will get a big green thing in the chat that says new sponsor. And I will say, oh, new sponsor. And then some badge appears next to your name. Why not? Subscribe today. You will get a piece of graphics that appears next to your name. Why you would want that, I don't know. But hey, it's possible for you. All right. Thanks, everybody. That was my sponsored by the sponsors of the sponsored coding train sponsors. All right. Let's move on. Annabelle. By the way, there's also a thing. This is one thing I really like to explore. I know Twitch has a lot of this. But I think there are ways that I can hook stuff up into the chat to various devices and things here. And I think that would be fun. But I also could do tutorials about getting a light to turn on or something. So if anybody has experiences with that, in particular with YouTube streaming, let me know. Okay. Hello. Welcome to a second video on promises. Now, what I think if you watched the previous video, I talked about the idea of a promise, how to use a promise with this function called fetch, which retrieves data from a URL and a variety of other things. And I looked at how you when the promise finishes, how you use vend to execute code and how you use catch if there's an error. And you can chain promises if there's a bunch of things happening in sequence. So that's what I tried to look at so far in the previous video. Now, I'm actually going to take a step back here and in a way do something much simpler and probably less important. But maybe we'll give some good background foundational knowledge. So I'm going to talk about how to make your own promise. And just in case, maybe you're here for like how to keep your own promises. And if you're here for like a self-help video, unfortunately, that's not what this is. But maybe you want to learn about coding. You might want to go to the beginner ones, though. But maybe this could be the first video you watch. Anyway, how to make your own promise. So let's come with me over here. And so this is more relevant probably if you are the developer of a JavaScript library and you want to support promises in your library. Most of the stuff that I'm going to do will involve making use of other libraries that give me promises. And I take those promises and hope that they're kept. And also, I'm actually eventually going to get to this like new, I think these are a part of ES, I think it's 2793 and 402. It's not even a number. 2009. That's anyway, I think it's actually just ES7. I was trying to make a joke there. But I'm actually going to use async and await, the key words to write an asynchronous function that returns a promise. But I'm stepping through this stuff one step at a time. So come back over here with me. And so I've got a little p5 sketch. There's nothing about this that you need p5 for, but it's my comfort object. You know, when you're small and you have your little lovey that you sleep with, p5 is like my little lovey that I code with. And so what does this do? This in setup, I don't make a canvas, I called setTimeout. If you don't know what setTimeout is, I have a whole video about that, which executes a callback, the sayHello function 1000 milliseconds later, and that makes a paragraph hello. So let me go to the browser. And you can see one second later, boom, hello. And if I made this 5000 or 6000, you know, six seconds later, that hello is going to pop up. So this is the old the old way of doing it in JavaScript, we have a function that's asynchronous that we pass a callback. So what if I wanted to create a version of setTimeout that returned a promise instead. So I'm going to write my own. And again, this is really I don't know that this is something you need to do in a program, but this is going to give us some background. So I'm going to write a function and I'm going to this, by the way, is not my original idea. I'm sure you can find lots of tutorials that show this exact same scenario. I probably read a few of them. So I'm going to write a function called delay. I could also call it like setTimeout promise, just to be explicit about what I'm doing. But I'm just going to give it a different name called delay. And what I want to do is I want that function to take an amount of time. So that function is going to so really what I'm doing here is like just this to start setTimeout. So at first, I've just like basically, this is completely insane what I've done, but I've written my own function called delay to just call setTimeout. And if I give that, you know, 1000. There we go. But what I want to do is I want to do this. I want to say delay1000.then. And I'm going to use the arrow syntax here, createP, hello. So again, if the arrow syntax is not familiar to you, a new part of ES6 JavaScript, I have a video on that. And then I'm going to say catch console.log error. So I want and I'm missing some stuff here. This doesn't need semicolon. There we go. So this is what I want to do. I want to write my code like this. I want the delay function to delay for one second, return a promise. When it's done, create that paragraph. And if there was an error somehow, console.log the error. And yesterday, someone was saying to me, I should say console.error, or I could put the error in the DOM as well. So okay, so this is what I want to do. Now, this won't work right now, because it's going to say cannot read property then of undefined, because there's nothing, there's no promise that's been returned. So what I need is my delay function has to return a promise. Do I have to say new promise? ES8, hold on, time out. I shouldn't look at the chat in the middle of these tutorials. Oh, and you can't even see this. I went off the, but is this, is this, is async away part of ES8 or ES7? Who cares? Yes, new promise. Catch console. I know I don't need the error function for catch, but I thought Gannon writes catch console.error. I thought that's going to be a little bit confusing for beginners, but. Okay, let me come back. Oh, it's ES2017, which is ES8, yes. Oh, I'm going to get flooded in the comments for that. Crap, crud. I mean, how do I, you know how I was using the Giphy API and I like set the PG rating? Can I set the PG rating for myself? All right. Yes, the wrong camera, I know, I know. I'm 20 seconds ahead of you in the future. All right. All right, so I forgot, I need to return a new promise. So this is sort of, I'm kind of getting closer. Let's just see what happens now. Well, promise resolver is undefined. So if I want to make my own promise, how to make your own promise, in addition to just promising something, I have to provide pathways for resolution of that promise or rejection of that promise. So when I create the new promise, I have to say what happens when it's resolved and what happens when it's rejected. So first of all, something that I could actually do here just for fun. Actually, no. I'm thinking here. How did I do this? Well, let me, okay. So what goes in here? We need a function called deal with it, deal with promise, resolve, reject. Right? Oh, this is so weird. I'm totally blanking for a second. I did this this morning. I should go look at what I wrote. Just time out for a second. I just want to look at what I wrote this morning. I have it on this. New promise. Oh, yeah, yeah, yeah. This is totally right. Ah, I'm, okay. I don't know why. Okay. I'm doing it the right way. I just got confused for a second. Okay. Then I want to pass that deal with promise function into the new promise. So the deal with promise function is a function that I'm defining to handle resolution and rejection of the promise. And that function is put, is returned with this new promise. But again, even though I like to write, no one's really going to write it this way. You're mostly going to see it as an anonymous function written right in here. And then, you know, if we're sticking with this ES6 arrow notation, we would see it look like this. So now, this is most likely what you're going to see. I want this function to return a new promise. And I need to provide pathways for how I resolve and reject those promises. So here's what I could do. I'm going to put this. Set time out. Say hello. Time. Then I'm actually going to, so, sorry. I need to, hold on. How did I do this? I usually don't look up my code because I'm usually figuring out. But I just want to look it up. Oh, yeah. Set time out a function. I just call resolve. Oh, yeah. Yeah, yeah, yeah. Okay. All right. I'm sorry. I got so confused. Let me just go back. This is going to go to the least. Just call resolve. I don't need to return anything. Oh, right. Right. Right. Okay. All right. So what do I want to do? What I want to do, sorry, is I want to call set time out. I want to call set time out with that amount of time. So I'm going to use the callback. But what is the callback? The callback is actually just resolve. So, and I don't need this say hello function anymore because I'm going to handle what I want to do. I don't have a callback anymore. I'm going to handle what I want to do with the then. So here, what I want to do is say, after this amount of time, resolve the promise. Okay. So let's just see if this works. Yeah. It worked. Now, here's the thing. I might want to do more stuff in here. And so this could actually be, I could actually also write this like this as a function that executes resolve. And then other things could happen in here. But I think that's besides the point. I just want to call resolve because all I'm doing is waiting for a certain amount of time. But here's the thing. What if I were to say, also, in addition to delay 1000, delay, you know, promising, like this doesn't make any sense, right? You can't pass a string to the delay function. It doesn't know how much time it's supposed to wait. So if I run this now, it sort of just worked weirdly. But I want to make that an error. I want to reject the promise if I don't get a number. So one thing I can do here is I can say if, and there's a function actually in JavaScript, I believe it's isNAN. So isNAN stands for is not a number. So if time is not a number, I now want to reject that promise. Otherwise, I want to resolve the promise after a certain amount of time. So this is me taking the non-promise function setTimeout, which has a callback, and wrapping it in a new function that handles it with a promise. But better than just, so this should work now. In other words, we should see, we see this like undefined, sketch.js line nine, because, but I should really give it an error. So I should be able to say, I believe, reject new and pass an error, new error, you delay requires a valid number or something. So if I do this, and now let me just take this out here, right? So this now is the full promise-if-if-if, promise-if-if-if, that's not a word, delay function. It returns the new promise, which is a function that handles resolution and rejection. And if it's passed not a number, it calls reject. Otherwise, it just calls resolve after a certain amount of time. So let's run this. This is my, this is me calling it now, delay 1000. There we go. Hello. And now if I say delay, blah, blah, we should see error. And you can see my error here. Delay requires a valid number. So again, this is more likely something you would be doing as the author of a JavaScript library, and your library has asynchronous code that supports promises. Again, though, and I think I'm gonna do this in the next video, I am going to actually completely rewrite that using, and I got it wrong, apologies to everyone. So just to be clear, this is ES, this is so confusing. So let me think about this. ES5, I don't know this stuff. I'm gonna write this out, then I'm gonna go check the chat, and I'll come back and correct it. So let me go backwards. This async and await is from ES8, which is JavaScript, which is JavaScript, ES, ECMCA or something, EMCA specification 2017. This is ES8. ES6, which promises are a native of JavaScript as ES6 is ES2015, I think. And then ES5, I don't know when, that's the kind of old JavaScript that with var. So things that are in ES6 are like var, no, sorry, let. I'm totally off the board here. I don't think you can see what I'm writing. Hold on. Let me just... Are like let, const, arrow, ES5 is var, callbacks, promises. So JavaScript, this is the thing. JavaScript is like an always changing and evolving language. And as you know, watching this video in the year 3122, my microphone just, none of this is relevant anymore. But thanks for watching anyway, about because you were here for a self-help video about how to keep your promises. All right, what was I talking, saying? I'm gonna come back. I'm in the next video. I probably got this wrong. So in the next video, check this video's description for a link to the next one. I will come and correct anything here and talk about async and await. Thanks for watching. Be sure to, oh, I'm supposed to return reject? Did I get something wrong here? I'm looking at the chat. ES latest. Yes. Did I get anything wrong about this? ECMA script. ECMA script. Yeah. Script. No, just call the reject. Okay, good. Great. All right. So now we are done with this. So now I'm gonna talk about async and await. Everybody ready for that? Great. Okay. So, async and await. So, async and await. Okay. Great. Okay. All right. You are still setting the timeout in the error case is all. Oh, oh, oh. That's an error. Yeah. So, interesting. No, reject. Oh, that's interesting. But it never, it stops, the JavaScript program quits. So, I see. So, I should technically have this here. This is more correct. Yes? I see. So, maybe I'll just mention that at the beginning of the next video. Okay. I'm waiting for the chat to catch up with me to tell me if there's anything else important that I'm forgetting. It's not even noon yet. Look how well we're doing. Oh, you can only reject resolve once. So, it ignores the resolve after the reject, but you are setting a weird timeout. Right. So, this code still, it runs through this code, but it won't actually call resolve because it's already been rejected. I see. So, I probably, this would actually make more sense to just write it this way. I think this is the way that I would choose to write it. Okay? Yeah. Dan, can you explain what is new in ES8? No. I mean, not because I don't want to, but I'm kind of catching up. So, what I'm about to do is talk about async and await. I keep saying await because it's async. Async, await, await, and async. Async, await. But I'm at least going to talk about that. So, let me at the beginning of the next video just fix this. All right. Hold on one second here. By the way, when you watch this, I wonder, and all of you watching at home, or wherever you are, I wonder if, because I have on my channel, if I go to YouTube.com slash the coding train, and I go here, go here, go here. Topics, right? So, this kind of fits in. Let me look at this playlist. So, this is what I've got in this playlist so far. Let versus var, const, arrow functions, for of, higher order functions. But those aren't ES6, are they? Are the higher order functions ES6? They existed before, didn't they? Maybe I'm using arrow functions with them. Anyway. So, this would make sense. This stuff would make sense to go in this video series. But I wonder if I should have 17 topics of JavaScript ES8. Maybe. So, let's think about that. Return reject. I could also do. Thank you. All right. Here we go. Oh! Someone in the chat is mentioning bluebird.js is a nice promise library in JavaScript. Oh! I'm muted. Am I muted? No, I'm not muted. I'm not muted. Sorry. All right. It's time. ES8. I have never talked about ES8 before. But this video, I'm going to look at something called async and await. And it's part of ES8, which is ES2017. But anyway, this is really what's often referred to as syntax sugar. So, basically, we're not going to get any new functionality. But we're going to have a different way to write an asynchronous function that returns a promise that just makes things easier to follow and nicer. I think. I mean, you can choose to decide whether it's better or not. But I think I like it. It's new for me. I haven't really worked with this until yesterday. So, let's see how this goes. All right. So, just to review, if you watched the previous video, I wrote this function called delay. This function called delay returns a new promise. And there's one mistake here. So, this isn't that big of a deal. Once the promise is rejected, I really should stop and not do anything else. But this code keeps going and calls this setTimeout. It won't resolve the promise, but it's still doing this weird setTimeout. So, I could... There's some options here. I could say, like, return. I could also... I think what I'm just going to do for my... The way I like to do things is just put an else here. So, I'm going to add that. So, this function receives a number, creates a promise... Oh, it receives an argument. It receives a parameter. If the parameter is not a number, it rejects the promise and throws an error. If it is, it calls setTimeout and resolves the promise. That way I can say, after a certain delay, like 1,000 milliseconds, create a paragraph or catch the error. So, now what I'm going to do is I'm going to write delay ES8. So, here's the thing. If a function returns a promise... If a function returns a promise, and what returns a promise? The delay function returns a promise. So, I'm going to do something weird here. So, what I want to do is call delay ES8. So, I'm writing a new function. I'm going to call that. This is going to stay exactly the same. This is going to stay exactly the same. Now, this is really weird. And you know what? In the next video, I'm going to do this with the Wordnik and Giphy example. That's going to make way more sense. I probably should just do that now. But I'm already going down this road. You can skip to the next video if you want. This is a little bit weird. You almost want to forget. Pretend that delay isn't a function that I wrote, but delay is a function that's part of some JavaScript library that I've imported. And delay returns a promise. So, I'm trying to think of a better name for this than delay ES8. But I guess I'll keep that right now. So, what this allows me to do, if a function, this function, I'm taking a long time to get to this, returns a promise. If that's the case, I can suddenly use this keyword await, meaning just wait for the promise to resolve. It's almost like, it's kind of like writing blocking code. So, I can say await delay time. Then I can return. Now, this is why I really want to do this with the fetch function because there's so much more. This is like a very tiny little bit. But this now should, it's going to make much more sense when I actually have to do more steps. I don't have to do anything. I'm just awaiting that. I don't have to do anything else. So, I'm going to do this. I'm going to It's going to make much more sense when I actually have to do more steps. I don't have to do anything. I'm just awaiting that. I don't have to do anything after. But this now will automatically return a promise. Now, I'm missing an important piece. Let's just run this and see what happens. I don't know if I like this video so far. I might have to rethink this. But I'm going. I'm going with it. Let me refresh. Await is only valid in an async function. Oh, dear. So, here's the thing. The await keyword, you can't just use it anywhere in your code. Like, oh, wait for this, then do this, then wait for this. You have to write your own asynchronous function. Basically, you have to write a function that returns a promise. But rather than having to say new return new promise, the async keyword just says, hey, do all that stuff kind of invisibly behind the scenes for me. So, now, if I come back over here and I tag this function, basically, tagging is the wrong word. But I modify by giving this function a modifier async. I say this is an asynchronous function. It's going to execute asynchronously and return a promise after however many calls to await that I want. So, now, let me just hit refresh here. Oh, shoot. So, now, let me just hit refresh here. And this works again. So, this now is an asynchronous function. So, this and the reason why this is exciting is I can start to do this. So, I can sequence a bunch of things that are asynchronous. That and some of these might actually return something. And this now, instead of having to chain all these different promises with then dot then dot then dot then catch this, catch that, I can just do it all in one function. And that function will return a promise. So, I think I don't know how much I don't know if this was that useful to you. Hopefully, it gives you kind of a sense. But I think a practical example will make a lot more sense. So, if you remember this particular example, look at what I had to do here. I had to fetch from Wordnik, then get the response, convert it to JSON, then get the word out of that, then go to another API. I'm going to rewrite all of this in an asynchronous function using await. And I think that's going to help make things make more sense. So, that's what's going to be in the next video. Okay? See you there. Maybe, maybe not. Oh, actually, hold on. No, no, no. Maybe I should go. Maren is making a good point that I could actually, like, await multiple things. But I think that's, I think maybe that's sort of understood. Don't forget for await. All right. Yeah, bad example since delay doesn't return any value. I agree. I don't know. Well, you tell me. Do you think I should just cancel the idea of a separate tutorial? I don't know. I'm thinking. The good news is I'm churning through this. We don't have too much further to go. I see people are giving me some feedback here. Let me think about this. Does something else help? Okay. All right. I think actually because I added this stuff in, this is okay. I think I'm going to keep it. Don't cancel. Okay. Skip to TensorFlow.js. I appreciate that feedback. I'm going to keep going. Now what I want to do, oh, and you know what? I forgot to make a, when I upload all this code, I kind of forgot. But that's okay. All right. Now what I'm going to do is I'm going to go to 01 promises, 03 async await. And that's what I want to be editing now. Okay. And here I should be again. Just over and over again refreshing. Oh, okay. That works for me. Water drip. Okay. All right. Here we are. Now I'm ready for the next bit of this. Let me cycle the cameras. All right. Here we are. Now I am going to once again in this video use async and await. But I'm going to use them in a much more practical way that will actually show you something hopefully that you might at some point want to do in your own JavaScript thing. So back over here, this is what I made in the first part of this series about promises. I made this particular JavaScript program. It asks the Wordnik API for a random word, water drip. Then once it receives that random word, it goes and fetches a GIF from the GIPHY API and shows that GIF. So every time I refresh and sometimes no GIF comes back and I get an error, which is good. I feel like something was weird with those GIFs. And I'm going to regret showing those. Do I still have the PG thing in here? No, I still have it rated PG. Maybe I should just rate it G. Let's try that. Let me come back. I didn't like those GIFs. I really have it. Whoa, what the? No, no, no, no, no, no, no, no. Okay. No, no, no. No. Why do I get such long... All right, whatever that is, I have no idea. Let me come back. All right. I'm just going to start this over. Hello. All right. In this video, I am once again going to talk about async and await. But in this case, I'm going to use a much more practical example. So I'm going to return back to what I did in the very first video about what is a promise and using fetch. And I'm going to revisit this example. So what this example does is it goes out to the Wordnik API, goes out. It calls fetch on the Wordnik API, gets a random word. Once it has that random word, it then requests a GIF. And we can see fetch returns a promise. And so I've chained a whole lot of promises. Fetch from the Wordnik API, then we get a response, convert the response to JSON. Then once you have the JSON, put the word in the DOM, then go to GIPHY, then convert that to JSON, then make an image. And if there's any error anywhere on there, log the error. And maybe I want to say console.error error here. All right. So now I want to change, I want to do this in a much nicer, syntactically sugary way with async and await. So how do I do that? Well, the first thing that I want to do is just take all of this code and put it in a separate function. So I'm going to say, I don't know what this is like. I'm going to call this function word GIF. And I actually want to change a couple things here. What I want to do is I want to give it a, because I, actually, this isn't important right now. I'm going to add this in the next video. I want to show you what happens when you then need to call, have multiple promises. But I'll come back to that. So we're just going to call this function word GIF. So if I go in here and set up and call this word GIF function, we are going to see some GIFs. And sometimes there's an error, right? Okay. So now I want to make this, I want to use await instead. In other words, I want to say await fetch wordnik API. And I'm going to say let data equals await. So this is, by the way, I can do this now. This is a nice, simple way to do this. Instead of all of this stuff, all I have to do, and I guess I call this response. I can actually just await the result instead of having to fetch and call then. That's the new thing. But remember, if I'm writing a function that uses await, I must make sure that I label that function async. So that's my replacement here. And then guess what? Look at this. Oh my God. I could just say then await response.json. So all of this stuff that I had to chain with thens, I don't need to do that anymore. I could just write them line by line by line in sequence and they'll all wait. This will happen asynchronously because I've made it an async function. So I'm just going to keep going here. Then I'm going to, and I'm going to call this response one. I don't love that, but just for the sake of argument here. So I'm going to call this response one. And then I'm going to say, I don't love that, but just for the sake of argument here, I'm now going to say this now, await fetch GiphyApi plus that word. Then I'm going to, and I'm going to call this JSON one. Then I'm going to say, and these should all be const probably, await, and this is response one, response two.json. So that's all the steps. And then I want to say let image equal JSON two dot and all of this stuff. I want to get that GIF. And now, and I'm going to also say, I think what I want to do here is say let word equal JSON one dot word. These are the things I want to get during these steps. So I'm going to put word here and then I could just return at the very end, an object with a word, word, image, image. This should be like image URL probably. So let's call this, and I guess I'm going to be, I guess I'm going to, let me just do this. I think this will be simpler. JSON one dot word. So now I've made this async function, we're called word GIF that, oh wait, oh wait, oh wait, just go through that, all those steps. And when it's done, it returns an object with the data that it's retrieved. Guess what? I can get rid of all of this, all of this, all of this. I don't need, I don't need any of that anymore. None of this. And guess what? This, remember, this is just syntax sugar to wrap all of this stuff in a promise. So all I have to do now is say word GIF dot then, and then I can say results, right? What comes back? An object with these things in it. And I can say create P results dot word, create image results dot image URL. So then, and then I can catch any error the same exact way, console dot error, error. So look at this. So look at this. Oh my goodness. Is this right? Could this possibly be right? Whoops. I'm looking, I'm looking. Sort of seems right. Sort of seems right. All right, here we go. Okay, so I can't believe I just did this. Are you following me? I got, I got lost in my own thoughts there. Let's just run this and see what happens. Cannot read property data of undefined sketch dot JS line 20. Let's see, what did I mess up? Oh, hold on. Maybe actually, oh, this is right. It worked actually. This, it's just printing out the error. There was no image. So I need to be better about handling the error, which I'm going to do in a second. So let me change this. Let me change the Wordnik API to give me a word that's between three and five characters. So I really make sure that I get a GIF. Okay. Well, let's just see. Something is missing. Something's going wrong here. Let's take a look at JSON1. No, the word came in. There's just no GIF associated with any of these words. Really? There's got to be a GIF associated with fried. I think I might be missing something. Giphy API. Let's look at JSON2. Oh, look at this. I just have this extra nonsense here. I had that in there by accident. When I was re-copy pasting things, I made a mistake. So hopefully that little debugging helped you sort of see what to figure out here. It's nice, though, that this is so much easier to debug than if I had all that then stuff and all the functions in its inner, like anonymous function stuff. I can just really debug this much more easily now. All right. Let's try this again. There we go. So we haven't gotten a GIF yet. So why not? Let's look at this now. All right. Data index zero. Images. So data index zero. Images. Why is that? Oh, I just called it image. Another mistake. I'm going to get this eventually. Results.image. So many little tiny errors because of all my naming weirdness. Here we go. Ready? So I called it this variable's image URL, and that's what goes into the image property of the object I'm returning. So that's the property I need to get out here. All right. Here we go. Feeling pretty good about this. Let me hit refresh. All right. We did it, everybody. So this was now an example of writing a function called word GIF, and what that function does is it asynchronously steps through all of these different asynchronous calls one at a time using the await keyword so that I can sequence them, and when it's done, I have the data that I want, and I can send it back. If I'm going to write a... I can't just put await anywhere in my code. I can't just suddenly put await in setup, for example, in p5 because I can't make setup an asynchronous function. If I put await, I've got to modify that function to make it async. Okay. So what's left? This is... dare I say that this is maybe a useful tutorial? I don't know. You tell me. But what's left is I'm now going to show you what if I want to have 10 words and get all 10 words and GIFs all together, and I want to have something happen when they're all done. That's what I'm going to need promise.all for, and that will be in the next video, and that's the last one of this series on promises and async and await. All right. Thanks. I'm like a chef. Okay. Can't you use ES6 enhanced object literal syntax there? Probably. I could just do... yes. I absolutely could do the createP and the createImage stuff inside of here. I just don't really want to. I want that to be like a thing that's handled elsewhere just for kind of sanity's sake. I want this function just to be about retrieving the data and not using the data. But yes, that's absolutely correct. I don't know what an ES6 enhanced object literal syntax is. Oh, that's a thing you can do? Yeah. I see. I see. Okay. Wow. We actually might get to TensorFlow.js today, because I have until one o'clock, and I don't think promises.all is going to take very long now that I have this already. Let me look up what this is. ES6 enhanced object literals. ES5. Oh, you could just do that. That's really interesting. I did not know that. Okay. Good to know. Maybe I'll mention that. Fractional asks, coding train, you planning to start any open source JS related projects that all viewers can join and contribute to? A small app or something. Let me take a minute to answer this question before I go to promise.all. I have in the past, and in fact, you can go through, if you go to GitHub.com slash coding train, under I got it. Under repositories, you can actually see there are a lot of repositories, and all of these are open source projects that people can contribute to. This was one that was done officially for processing community day. As far as I know, there's going to be another processing community day next, I believe, probably next January 2019, but don't quote me on that. There's the 12 o'clock project, which was a port of John Midas 12 o'clock design. There's an issue that I have, which is that it takes time and work to manage an open source project, and I have in the past employed people to help manage GitHub repositories. I also have had people just volunteer to do it, and there are plenty of volunteers like meiamsome, and neilsweb, and Alka, Ada. I'm mentioning just off the top of my head some contributors from the patron community who have done a lot of work. Website being kind of like a primary one that has a lot of activity. I don't have a good system, but you can see this is what happens. I have this GitHub tutorial on GitHub, and I think a rainbow poem. This has 313 open pull requests, because it's a video tutorial about how to make a pull request, and then I ask people to make the pull request, and then, you know, for a while, I was merging them and checking them every day, and then I like I think actually I was doing this all the way up to last summer when I broke my elbow. This might have happened way before last summer, but I didn't do it for a few weeks, and then once I came back to it, I was like, I can't. I can't. It's too much. So I need a way to vet people to enforce the code of conduct, and volunteer to manage some of these repos. So anyway, that's my example. Slightly bad example. As none of the code subsequent to each await runs async, because each relies on the result of the previous await, so execution is still held up until the results arrive, writes David Smith. That's interesting. So, David Smith, are you saying that my example is slightly bad? So, I, oh, and Meredith, sorry, if you're in the Slack channel, I forgot your name. It's only because I'm afraid of mispronouncing it. Yes, I certainly could in the same way. I mean, one thing, I don't want to go off too off topic here, but I'm not opposed to, you know, sending out stickers to people who help contribute a certain amount, or even, you know, membership to the sponsor group or whatever as well. But, okay. You should do something that can run while the request is running. Oh, yes. Right. So, the idea here is that what I could do is, you know, I could show like a loading screen that then finishes once it's done. So, like, I don't know that I need to do this, but like, like, maybe what David Smith is suggesting, if I say like loading is true, and then if I actually had a draw loop, if loading, I would like draw a loading bar, and then I would set loading equal false here, and then I would show something else once it's loaded. Okay. So, but points taken that I didn't go the next step. Maybe I'll mention that as an exercise. Okay. All right. Let's do promise.all. All right. And then I could do a loading bar with promise.all. That's a little bit more complicated. All right. And then I could do a loading bar with promise.all. That would actually make sense because I have to do a lot of them. But anyway. Okay. It's a stage before the all makes sense. If you do a way, okay, I got to move off from the chat. I'm very interested, which is kind of the issue. Let me just check to make sure there's no emergencies going on here that I need to respond to. Oh, CodingTrain tweeted, I started a live stream on YouTube. Okay. Yeah, that is a good point about sequential asynchronous versus parallel asynchronous. If I wanted to do during, but I'm just, I'm not going to, there's a lot more to this and I'm trying to stay in a friendly place. All right. All right. Welcome back. This, for the moment, for the time being, is the last video in my series on promises in ES6 and async and await in ES8. Now, many people who are watching the live version of this, you might be watching the recorded version, are making lots of excellent comments about things that I'm not demonstrating. For example, what if I want things to happen, like on the interim during various stages of this? Or I want to show like a loading bar. I want my asynchronous calls to be happening in parallel instead of waiting for all of this to be done and then just showing the results. Those are all really good questions. So I'm trying to stay in sort of a simple place to demonstrate the basic idea, but I would leave some of those as exercises to you and maybe I can come back and continue this series if there are some key things that I've missed. So please give me your feedback in the comments. But what I want to show in this particular video is what if I want to make multiple calls to word gif and I want them, I want to be able to retain sort of something about the sequence of those calls. So for example, something I absolutely could do is I could just do this twice, right? And in fact, I can still leave the catch at the end. So I can actually do this. I think, right, because this returns. Oh no, I would have to say, right, this is a little bit goofy, but I could say return word gif inside of here and then I could say then do another one. Right, so this is just me doing two. This is a little bit weird and I need to finish off the code here and I need a dot here. So this is the way of chain, this is kind of without the await thing. This is the way of chaining promises. So first I call word gif, I show the results, I return the next call to word gif, which is a new promise, and then I show those results. So let's run this and see if we get two. Oops, sorry, I'm in a different place. We see two and they happen one after the other and sometimes I'm going to get an error if there's no gif. Okay, now here's the thing. I want to change something about the word gif function. I want to make this have an argument num and that's going to be the number of, sorry, I'm spacing, the number of letters that I want. So I'm going to go to the Wordnik API and I'm going to take this out and I'm going to say when I'm calling that, I'm going to say plus. So I'm just adding, there's a nice way I should use those. What's that called in ES6, the string thing? I'll have to make a video on that, but I'm going to do it my highly manual way. I'm just adding in the minimum and maximum length as a number. So hopefully you can follow what I'm doing here because I'm, all right. So what I'm doing is I'm just modifying the call to the Wordnik API to specify a number of characters. So I'm going to say Wordnik 4 and then Wordnik 5. Sorry, not Wordnik, Wordgif 4, Wordgif 5. So I should get a four letter word and then a five letter word. Four letters, all right, I got an error. Four letters, five letters. Okay, so that this works, four letters, five letters in sequence. So why am I doing this? So one thing I want to point out about sequence versus parallel, I know I'm going to get the promise that all. Interestingly enough, what if I didn't chain these? So let's take out the second one and just leave this first one and now I'm going to actually just completely duplicate this code and say, I'm going to say three and four, three and four. Let's run this now. So now they're not chained. So I'm not waiting to do the second one until the first one comes back. I'm just saying, do these in parallel, do both of them. And when they both come back, create the paragraphs in the image. So let's look at this. Three, four, three, four, three, three, four. So interestingly enough, let me, let's, I'm sort of surprised. I'm going to just try now with a five as well. Look at this, four, three, five. So when they're happening in parallel, what I'm saying, just like do this, do this, do this, just start them all. I'm not necessarily going to be sure about the order that they come back in. So one way to deal with that is to chain them like I did. There's another way to deal with that. If I want to say like, wait till everything is done, and then show the results. And that's where promise.all comes in. So promise.all requires an array. So let me, let's just, so let's just pretend I have something like called promises. And it has, it's an array of three promises. If there is an array of three promises, I can write If there is an array of three promises, I can write promise.all, pass in promises, that array, and then add, sorry, the then and the catch. So hold on, I'm, I'm, this is hard. I have to think about this while I'm doing it. Promise.all promises, then, and this gets a function of what to do when it comes back. And this gets a function, which is pretty much, you know, if there is an error. Okay, so I think this is the skeleton of what I want. I have some syntax errors here. Maybe a semicolon. Looking, looking, looking. Oh, well, this should say error. Console log error. What's wrong here? What am I missing? Ah, this needs, there we go. No. Does it just want, oh, there's no, yep. What's wrong? Wait a minute, let's see. No, I know, that's not the problem. I don't see what it is. Oh, no, this is right. That's where that goes. That's the, that's closing setup. Okay, this is actually correct. This curly bracket, I don't know why I was, I had a little brain malfunction there where I thought it was supposed to be there, but this is actually closing setup, so this is in the correct spot. So this is the skeleton. The idea is, and by the way, I, this, this is really a problem. This needs to have an argument. The idea, the skeleton is, the idea, the skeleton is, if I create an array of three promises, I can say, when all of the promises are complete and resolved, give me the result of all those promises in an array of the same order as the original promises. That's the idea of promise.all. So what are these promises? Well, they could be this. Word, gif, three. Word, gif, four. And certainly I could create them in a loop or with separate variables, but just to do this, word, gif, five. So this is the idea here. Let me give myself a little bit more space. That what I can do here is just say, hey, I want to make three promises. I want three word gif things. When all of those are done, show me the results, and now this is, I'm just going to use a, like a regular loop because instead of a for of loop, I'm not sure why, but that's how I feel right now. So now I can do a loop to go through all of the results, and then I could say data equal results, index i, and then what do I want to do? Actually, let's just put this in here. The difference is I'm saying results, index i, results, index i. Right? So the idea here is now, this is exactly what I had before. Sorry, it took me a little while to get to this. This is exactly what I had before. The difference is I am putting all the promises in an array. I'm not handling them with their each, their own then or in separate blocks. I'm just putting all the promises, right? Word gif returns a promise. Remember this code? Oh, this, this I can totally delete now. Remember this async function we wrote? The async function with awaits returns a promise. When the promise is resolved, you get this particular object. So now when all of the promises are resolved, then I have all of the resolutions in an array called results, and I can go through them one at a time. And they should be in the same exact order as the array, original array. Did I do this correctly? Did I do this correctly? Did I do this correctly? Ah, shoot. Sketch.js line 49. What did I do? Line 49? Am I even in the right? Yeah, I'm in the right. 49. Hold on. I must not have, I didn't save. I didn't save. Save. Try this again. This is like wasted time in the video, but. Whoa, line 20 now. Should never use that drum sound effect. Oh, I just have an extra curly bracket. Thank you. There we go. So when they're done, all three of them happen at once. And they're always in the right order. Three, four, five. Three, four, five. Let's get an error. I'm sure we'll get errors if we give longer words. So let's just see what happens with an error. Didn't get an. How are we not getting any errors? There we go. Now, interestingly enough, is there, I really should stop because this video should be done, but is there a way that I, I just want to look at that results array if I get an error. Oops. Do I at least get. Yeah, I guess I don't. Well, timeout for a second. So here's the thing. I guess if I want to handle these individually and have the ones that succeed, succeed, and the ones that fail, fail, I can't use this solution. Is that correct? I need some help with this question. 1220. I'm going to have to get some water. You don't get results on the error ever. So if I wanted to do, if I wanted to do like a hundred of them, this doesn't really make sense, right? I would really want to sequence it, not use promised at all, right? Okay. So I think I was. Oh, I forgot to show try and catch in here, but that's fine. That could come another time. All or nothing. Okay. All or nothing. Okay. All right. So I got an error. So here's the thing. This promise that all might not actually be such a great solution for this because promise.all is all or nothing. So any of those promises have an error, then I don't get any of the results. So if what I wanted to do here was create a for loop, you know, let I equal zero eyes, less than 100. I plus, plus, and I have like, let promises equal an array. And then say promises.push word gif, you know, for, for I. Right. This is now going to work and it should show me a hundred word gifs. But if any one of those words does not have a proper gif associated with it, I'm not going to get anything. So let's see. It's doing them all. What this is actually a great exercise now for you to do a loading bar. Because this takes a while. And actually I got lucky. I guess like all 100 of them worked. But if I want to see them like appearing as they come in, I want to do them more in parallel. I want to sequence them. But hopefully you've seen the range of ideas here. So I'd encourage you to take this code, play with it, maybe back out of the promise.all thing. What can you add a loading bar? How can you like load them cleverly and try some other stuff with it? And I also, I think I'm forgetting, I guess I'll do this in another video if I can remember. I also can use try and catch inside of this async function if I want to handle the errors in a slightly more custom way. I think that's correct. But if that's not correct, eventually I'll make a video about try and catch. All right. Thanks for watching this series on, oops. Thanks for watching this series on promises. I think I now have made a video tutorial that follows this list. Leave me your comments and your questions and all that sort of stuff. And I'll see you again sometime. Goodbye. All right, everybody. Oh, yes. Map. Higher order functions would certainly. But I think that I, I think I stayed in my lane here. Like I was very, I feel like yesterday I went, I didn't, I was, I went off target. And I got to stay in my lane which is like the basics and the fundamental concepts. And I think to the extent that it's helpful. Yeah. Right. TensorFlow.js. I know. Which is bad for me to start with this as I'm. So, first of all, I definitely need to get some water. So, if you don't mind, I am going to leave you. How would I, I was going to like let this go for a long time. But let me. Oh, if I use a try catch on the image URL, you can use promise.all return a no GIF image. Right. I see. So, in other words, like this. Let me just try this. Catch. Because maybe I will. So, I just want to experiment with this idea. Would this work? I think I need to do this. I'm just going to leave this blank for a second. Ah. Interesting. So, that's a great. So, I should really do this. I should add another video. Right. Give me feedback about this. What, is there anything particularly weird about this that's totally wrong? So, Amr in the chat, the Slack group, asked how is threading handled in JS? What I mean is what happens if a variable is shared in more than one promise action? Here's the good news. Good news, bad news. There is no threading in JS. JavaScript is single threaded. So, there is no way to have that conflict. And the way this asynchronous stuff works is there's a good article about that that people have been sharing. Somebody could share it in both chats. That would be helpful. Is this how do people feel about this? Should I demonstrate this in a last ditch video that shows try and catch? Let me go get some water. I'm going to get some water. I'm muting myself. I'm not muting. I'll look in the Slack channel when I come back. If there's any good feedback about this code, put it there and don't chat after it. That's how I see it. So, do. Okay. Here I am back. So, I've thought about this. It's 1230. I only have until 1 o'clock. I don't think it's wise to try to do the layers API or the TensorFlow.js linear regression example with time pressure and also my brain is starting to melt a little bit. So, here's the thing. I have good news, bad news. Bad news is I'm going to wrap up soon and I'm going to not do TensorFlow.js right now. The good news is I'm going to create an event for today and I will come back for an additional hour. I do technically am free between 4 and 5. You can hear me now, right? Okay. So, let me do this right now. Otherwise, I'll change my mind about it after I leave. So, I'm going to creator studio and I'm going to and then I'm going to talk about the try catch. I'll do that before I go. Whoops. So, bring back the timer. Hold on. Under events. Ah! Shoot. Live streaming. Events. So, there is an option to no. New live event. I want to create a new event from the settings of the other one. I saw that option once in YouTube. Maybe I can't do that one that's actually live. I'll, you know, okay. I'm just going to do it here. Okay. Okay. Um... I promise you today 4pm Eastern end time 5pm. I'm like a live streaming addict here. Public advanced settings. Enable slow mode. Video. Recording date. Language is English. Where's the one where it says, like, I guess I can fix this. Make this archive unlisted. So, create event. So, I guess I can take off this back in five minutes thing. So, there should be now, if I go to, oh, not here. YouTube, the coding train. I say 1pm. Ugh. That's not right. Info and settings. 4pm to 5pm Eastern. I guess maybe my YouTube thinks I'm in Pacific time because that's 1pm Pacific time. It definitely says here in the page. But anyway, I'm going to come back. By the way, in case you want to know to get a notification when this actually happens, you should I guess this is I'm logged in as myself. I can't click subscribe. Somewhere here you can click subscribe. You can click submit reminder. There's a way for me to view as something. But whatever. Let me just go to I'm just curious. I'm just curious what does this look like if I'm not logged in. So, yeah. Sponsor, subscribe, alarm bell and set reminder. This is going to happen later. Now, go back to the code. Let me go back to the Slack channel. Okay. So, I'm going to go back to the Slack channel. Let me go back to the Slack channel. Okay. So, I'm going to read through this comment. Only one bit of code is ever executed at once. So, in synchronous lines of code, you can oh, yeah, that's the answer to that other question. Madden writes I would put let image URL equal no image and have the catch just for logging the error. Yes. That's a good idea. I like that. You can also catch on the promise return from word GIF which might make more sense from an error catching standpoint. Oh, you mean like catch it here? Like actually put a catch here and then not add it to the array? Okay. But that feels confusing. Also, you need to do catch E with a catch without an argument. So, this I kind of like this idea also. Let me just try this. Oh, right. That's right. That's the error. Okay. No image for this GIF. Great. Okay. So, this makes sense. I'm going to do it this way for simplicity because I don't want to muck with this up here. Hey, just in time, coding garden with CJ is on now. So, when I leave, you can go watch that. It's a YouTube channel. I subscribe to you. I have some more water. All right. All right. I'm going to do it my way even though there's other ways of doing it. So, now what I want to do is go out of this and put it back. Maybe I'll mention the what was that thing called again? What was that thing called when see this is why I can't do the TensorFlow.js videos now. Enhanced object literal or something. Oh, yeah. Is there a documentation on the Mozilla documentation? Okay. Yeah, this is the enhanced. Okay. All right. All right. Oh, property is null. Yeah, I agree. I agree with that. Okay. All right, everybody. I think I'm good, right? All right. Okay. All right. Here we go, everybody. Let me recycle the cameras. This is going to be the last thing for today because I have run out of steam and somehow I committed to coming back for an hour to do something on TensorFlow.js. That was a bad idea. Maybe I'll get a few new sponsors this afternoon for doing the extra effort. Okay. Marin is right about line 28 now. Huh? Oh, yeah. Thank you. 26. Got it. Okay. All right. Oh, it can't be zero. Let's do a... All right. Here we go. I feel sleepy. I need to eat lunch. I'm getting a little tired. Just when you thought it was safe to go back in the water, the swim with the promises. I don't know. Anyway, I do want to add something to this list. You're watching this. There's another video here. I want to talk just really quickly and show you one thing about try and catch. If you remember where I left off with promise.all, what I had is I have this particular... I kind of made some modifications in between the last video and this one, but I have this particular JavaScript program using the p5.js library that makes a bunch of calls to Wordnik and the Giphy API. When everything is done and it's finished with all those calls, they're all promises, I get back some results, and I place them all in the DOM with a paragraph element and image elements. Now, the problem here, and again, promise.all is not necessarily the best solution for this anyway, but since I'm demonstrating it, the main issue here is if any of those, it's all or nothing, if any single one of those has an error, like there isn't a GIF associated with that word available in the Giphy API, the whole thing doesn't do it. It doesn't do anything. So just about every time I run this, I'm not getting anything. Now, let me just make it work by let me just get like three of them, and let me just say they're all going to be three-letter words. I think this will probably work. Right. So I got three GIFs with three three-letter words. So you can see that that worked, but what I want is I want it to work anyway, and I want to see a two-letter word, a three-letter word, four, five, six, seven, and so let's do that. Oh, whoa, it actually worked. So that was the first time that worked, but most of the time we're going to get an error. So there's a way around this, and it is not a way around this, but there's another concept that could help here that's important, which is try and catch. So a place that I could use, what I want to do is individually handle error messages differently, and a way that I can do that here is by, I can handle the error message myself and not cause it to fail by using a try catch here. So the first thing I'm going to do is I'm actually just going to say let image URL equal null. So I'm going to assume that I'm starting with the idea that there isn't an image URL. Then I'm going to try to get the image URL from the, sorry, I'm going to try to get the image URL, I'm getting sleepy after making all these videos, I'm going to try to get the image URL from the data. Now it might not exist, that's fine, I'm just going to try. Then I'm going to return JSON1.word and image URL. Now this will be null if this doesn't work. So I can now go up, whoops, I can go back up in my code and I can say, hey, if results index i.image equals null, you know, as long as it's not null, do this. So this now should let everything keep going and it will only just skip making an image where there wasn't one. Let's see if that works. Okay, ah, all right, so fine. I was thinking I could demonstrate this without a catch and then show you the catch next. I thought there might be like a default catch, but clearly there's not. That makes sense, right? So, and there's a finally thing too, I'll have to come back to that another time. But what it's saying is like, hey, hey, if you're going to try something, I can try it, but you got to tell me what to do if things go wrong. Like you're in charge now, like the error isn't just going to be handled however it's going to be handled. So I need to actually say catch and the catch actually gets inside of here, it's like a function, it's not an argument and I could call that error. So I'm actually going to catch that error. I'm going to say console.log, no image found for JSON, oops, for JSON1.word. And then I'm also going to just say console.error. I might as well print out that error as well. And let's just call it err, just so we have things named differently. So I think this is right now. Now what I'm doing is I'm saying, hey, let me try to grab the image URL, if it doesn't exist, just spit something out to the console and but keep going. So let's see if this works now. Whoa, right, it didn't find it for any of them, weird. Okay, so I got a mistake somewhere, because it only didn't find it for one of them. I think I've got something wrong somewhere. Oh, what did I do here? If, this is like total nonsense. This is what I need to eat lunch people, I should not be making this video tutorial right now. That was total nonsense what I wrote before. What I'm saying is, as long as the results image is not null, not image equal to null, that makes no sense at all. Let's try that again. Great. Now they all, unfortunately, they all worked. But you can see now it worked, but no image found for fueler. And we should see that fueler is still here, but just no image is associated with it. So no image found for fueler, no image found for whatever that word is. And so now this goes through, but I can sort of see what are the things where it doesn't work. Okay, so I have talked to you about, now I added this last little bit about try and catch. Here's the thing, just while we're here, let me just fix, just fix tiny little things, tiny little things. Because while we're here in ES6 and ES8 land, there is something called enhanced object initialization. Is that what it's called? Enhanced object literals in ES6. So something that I can actually do here, oh, weird. I don't want to talk about this now. Let's not put that in here. It's fine. Yeah. Oh, too many people use try catch rather than defensive programming, which is lazy. Weird edit point. I'm getting some interesting feedback on the chat that things like people use try catch too much and that try catch is useful, but it should be used as a last resort if all your other stuff fails. So again, I'm not necessarily suggesting that the way that I've done this is the optimal way to create this word GIF generator. I mean, ultimately, if I wanted to do that, I'd probably want to not just like have a hundred promises that all happen all at once. I'd want to animate and sequence and make things interactive, and maybe I type in a word, all sorts of possibilities. But I'm trying to show you the bits and pieces and features. So the important thing here, I think, is that you can write an asynchronous function that returns a promise without ever saying promise by using the await keyword and the async keyword. You can use promise.all to execute some code when a whole lot of promises are finished and the results will always come in in the same order as the array. But you can also sequence promises with dot then, dot then, dot then, dot then. So there's some other things that I should do. I should use enhanced object literals, which is like an ES6 feature. Maybe I'll come back and talk about that in a video. That thing with the strings. What's the thing with the strings? Strings, ES6, literals. There's like a thing. Template literals. I should use that. So somebody remind me in another video, I'll talk about some other ES6 features like template literals and enhanced object literals. Now just go look up those things on your own. Little tidbits here. Goodbye. All right. All right. Okay. I'm done. It's 1250. I'm going to answer a few questions that come in from the chat. Thank you to all the sponsors and patrons of the coding train. This really motivates me. I'm like a numbers person. So the funding helps, but also just sort of like the numbers stuff. Appreciate it. And I'm going to come back for today. So actually, I'm going to put up a little straw poll. No, I won't because I'm not going to listen to it probably. So the things I want to talk about, the things that I want to do TensorFlow.js wise is I was going to, I think I'm not going to do this today. There's currently a bug in TensorFlow.js associated with the from pixels. So I think I'm not going to come back and do that. Maybe what I'll do is I'll do the linear regression example. And if I can do that and talk about the layers API, I'll be happy. I probably could only do, I was going to just do linear regression with TensorFlow.js as like a kind of baseline example. Layers API. The next thing would be XOR and image classification and other stuff. But I think that's what I'll start with. What's the best way to sponsor? Patreon or YouTube? I don't know. It's really up to you. And you can always cancel one and switch to the other one if you don't like it. I mean, probably in theory, I would get more. YouTube takes 30%. Patreon in theory doesn't take 30%, but the fee structure there is completely opaque to me. So I honestly have no idea. I almost like it better that it's just clearly 30%, even though that's kind of high. So I don't know. YouTube thing is nice. If you want to sponsor for more than $5, you have to use Patreon. If I also sponsor on YouTube as well as on Patreon, will that get me the $10 Patreon rewards? Sure. Why not? Why not? Let's have an offline Slack DM discussion about that. But I'm happy to do whatever is fair. How is ITP different from a normal university with some standard courses? That's a great question from Jaffrey. So first of all, let me just be clear. ITP.nyu.edu. There are two programs. ITP, two-year master's program. IMA, four-year undergraduate program. IMA is a BFA, Bachelor of Fine Arts. ITP is some degree that I don't know what it is. Never heard of. No. It's an MPS, Master of Professional... Master's in Probably Something. I think that's what it is. But I would say that... And I can speak to more about ITP being an ITP alum and having worked at ITP for 15 years now. IMA is a new program starting this fall. And IMA in many ways, it's probably a bit more traditional in the academic sense as it's an undergraduate BFA program. Non-traditional probably in spirit and culture, I would hope. So I would say ITP is a program about making more so than about sort of theory. And it's very interdisciplinary. And it's pass-fail. And a lot of what, to me, the magic of ITP is not the courses that you're taking. It's the community and being here. And I would encourage you to watch my ITP show videos, which will give you a sense. Welcome new sponsor, Merin. Thank you, Merin. Double sponsor. Welcome. There are now only two double sponsors, Me, I Am So Me and Merin. No, Me, I Am So Me is another bug in From Pixels. I don't want to get lost. Oh, that song ended. Oh, no, I just paused it. Let me just look. There's another. Let me just look really quickly. There's another From Pixels bug. It's in just in point 11. Yep, it's this one. This particular bug. So this is a From Pixels bug in 0.11.1. Sensei, oh, one more question. Sensei Clock Clo asks, hey, Dan, I wondered how you started coding train. All right. I got an answer for this one. Vimeo, Shiftman. So if you go look at this now deprecated Vimeo channel, you will see a lot of the videos that I have on YouTube here. So originally, I was just making these videos and publishing them on Vimeo. And I was really doing it just as for the courses that I was teaching and then putting them online, hoping other people would watch. And I should try to find somewhere I have an email from somebody who said, could you upload your videos to YouTube? I want to watch them on 2X. And I did that, I think, in like September 2015. And I had I just took all of the videos. So I guess the 253 videos I had on Vimeo and I uploaded them all to YouTube. And then I discovered that I could also live stream at some point. So something that you can amuse yourself with watching is if you go to the coding train and under, let's see, playlists. And unlisted live streams. Don't look at that one. I shouldn't be live. I probably shouldn't log into my YouTube live stream. I stream archive. Yeah, this one. Live stream number one, September 4, 2015. And this is me, I think, live streaming through Google Hangouts. I think. I don't know. But this is, you can watch this. Somewhere there's a live stream that I did through Google Hangouts. That's not what this is. This looks like it's actually live streamed, live streamed. But anyway, so that's kind of a bit of the history. History. Looks like there was maybe another sponsor. Is that still just Madden? No, that's just Madden. Okay. Thank you, everybody, for tuning in. I have a bunch of things, a bunch, a bunch of things I have to do today. It's coming back at four. Things are going to be tricky, but I think it's worth doing. It will only be for an hour. So, hopefully, I can at least do linear regression with TensorFlow.js. How are you able to learn so much programming language? I don't know. I don't know that I know so much programming language. I think it's just doing and trying and actually teaching it has helped me learn a lot. Okay. Thank you so much, everybody. I just, just, okay, sorry. Stop torturing me, people. I'm going to go now. I don't know. Maybe I'm torturing people too much with playing that outro every time. So, I think maybe I'll, maybe I won't do the outro, especially since I'm coming back. Oh, the Coding Train wallpaper. I think on the Coding Train GitHub website, issues, so, yeah, I mean, it doesn't, you have to dig into this issue and find maybe a link that I put somewhere in here. Oh, yeah, the files are on GitHub, but it should, there should be like a more obvious place to download it, but, yeah. So, if you read through this issue, you'll see where it is. Do I play Fortnite? Last question. I have not. My son, who is nine, plays Fortnite. Is that where everyone does the like pickle thing from, which I can't do? Anyway, I got to go. This live chat will be that this live chat, the live chats are always archived. So, you come back and watch the archive of the stream, the live chats play along. Okay, I got to go. Goodbye, everybody. Thank you. I will see you, I think, this afternoon for one hour.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:51.974453Z",
  "started_at": "2023-09-26T21:19:29.442069Z",
  "completed_at": "2023-09-26T21:37:27.154314Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=mETDQDBwOi0",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1077.712245
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/3czs5gjblwaljrpzqyjiymws7a/cancel",
    "get": "https://api.replicate.com/v1/predictions/3czs5gjblwaljrpzqyjiymws7a"
  }
}