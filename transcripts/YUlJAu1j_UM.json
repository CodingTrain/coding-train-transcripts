{
  "id": "nwlsombbxpfdbc7b3upogcp2pm",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/YUlJAu1j_UM.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/716198 [00:00<?, ?frames/s]\n  0%|          | 2790/716198 [00:05<22:16, 533.97frames/s]\n  1%|          | 5640/716198 [00:10<21:50, 542.29frames/s]\n  1%|          | 8180/716198 [00:14<20:26, 577.24frames/s]\n  1%|▏         | 10700/716198 [00:19<21:02, 558.67frames/s]\n  2%|▏         | 13380/716198 [00:23<19:31, 599.74frames/s]\n  2%|▏         | 16040/716198 [00:28<20:16, 575.37frames/s]\n  3%|▎         | 18480/716198 [00:33<21:59, 528.82frames/s]\n  3%|▎         | 21150/716198 [00:38<21:57, 527.45frames/s]\n  3%|▎         | 24140/716198 [00:44<22:04, 522.63frames/s]\n  4%|▍         | 26870/716198 [00:50<22:38, 507.32frames/s]\n  4%|▍         | 29540/716198 [00:54<21:58, 520.85frames/s]\n  5%|▍         | 32260/716198 [00:59<20:53, 545.81frames/s]\n  5%|▍         | 34960/716198 [01:04<20:50, 544.94frames/s]\n  5%|▌         | 37660/716198 [01:10<22:41, 498.28frames/s]\n  6%|▌         | 40660/716198 [01:11<16:16, 691.89frames/s]\n  6%|▌         | 40660/716198 [01:27<16:16, 691.89frames/s]\n  6%|▌         | 43660/716198 [01:48<54:11, 206.82frames/s]\n  6%|▋         | 46460/716198 [01:51<41:23, 269.71frames/s]\n  7%|▋         | 49360/716198 [01:56<35:02, 317.22frames/s]\n  7%|▋         | 52160/716198 [02:00<29:38, 373.43frames/s]\n  8%|▊         | 55160/716198 [02:06<26:25, 417.02frames/s]\n  8%|▊         | 58160/716198 [02:17<30:18, 361.86frames/s]\n  8%|▊         | 60860/716198 [02:20<25:31, 427.89frames/s]\n  9%|▉         | 63760/716198 [02:24<22:05, 492.09frames/s]\n  9%|▉         | 66660/716198 [02:27<19:32, 553.95frames/s]\n 10%|▉         | 69360/716198 [02:31<18:03, 596.87frames/s]\n 10%|█         | 72160/716198 [02:36<17:50, 601.80frames/s]\n 10%|█         | 74960/716198 [02:40<17:47, 600.92frames/s]\n 11%|█         | 77860/716198 [02:47<19:15, 552.64frames/s]\n 11%|█         | 79960/716198 [02:51<20:06, 527.17frames/s]\n 12%|█▏        | 82560/716198 [02:55<18:11, 580.46frames/s]\n 12%|█▏        | 85360/716198 [03:01<20:03, 524.31frames/s]\n 12%|█▏        | 88060/716198 [03:06<19:41, 531.47frames/s]\n 13%|█▎        | 90760/716198 [03:10<18:40, 558.03frames/s]\n 13%|█▎        | 93060/716198 [03:14<18:25, 563.48frames/s]\n 13%|█▎        | 95960/716198 [03:20<19:28, 530.92frames/s]\n 14%|█▍        | 98760/716198 [03:26<19:53, 517.22frames/s]\n 14%|█▍        | 101660/716198 [03:31<19:00, 538.77frames/s]\n 15%|█▍        | 104460/716198 [03:36<18:36, 548.14frames/s]\n 15%|█▍        | 107160/716198 [03:40<18:12, 557.63frames/s]\n 15%|█▌        | 109160/716198 [03:43<17:14, 586.55frames/s]\n 15%|█▌        | 110460/716198 [03:46<18:00, 560.62frames/s]\n 16%|█▌        | 113260/716198 [03:50<16:01, 627.03frames/s]\n 16%|█▌        | 114860/716198 [03:52<15:49, 633.26frames/s]\n 16%|█▋        | 117660/716198 [03:56<14:38, 681.29frames/s]\n 17%|█▋        | 119660/716198 [04:01<17:59, 552.45frames/s]\n 17%|█▋        | 121760/716198 [04:05<18:04, 548.33frames/s]\n 17%|█▋        | 124360/716198 [04:10<18:43, 526.81frames/s]\n 18%|█▊        | 126960/716198 [04:14<17:02, 576.14frames/s]\n 18%|█▊        | 129860/716198 [04:19<16:33, 590.25frames/s]\n 18%|█▊        | 130960/716198 [04:21<17:35, 554.58frames/s]\n 19%|█▊        | 133760/716198 [04:25<15:28, 627.40frames/s]\n 19%|█▉        | 135960/716198 [04:30<17:10, 563.14frames/s]\n 19%|█▉        | 138160/716198 [04:34<17:31, 549.67frames/s]\n 20%|█▉        | 140060/716198 [04:38<18:22, 522.56frames/s]\n 20%|█▉        | 142560/716198 [04:41<16:26, 581.20frames/s]\n 20%|██        | 145260/716198 [04:46<16:26, 578.74frames/s]\n 21%|██        | 147560/716198 [04:50<16:36, 570.76frames/s]\n 21%|██        | 149560/716198 [04:54<16:59, 555.89frames/s]\n 21%|██▏       | 152260/716198 [04:59<17:09, 547.86frames/s]\n 22%|██▏       | 155060/716198 [05:03<15:52, 589.05frames/s]\n 22%|██▏       | 158060/716198 [05:07<14:28, 642.91frames/s]\n 22%|██▏       | 160460/716198 [05:10<13:16, 697.59frames/s]\n 23%|██▎       | 163260/716198 [05:15<14:40, 628.13frames/s]\n 23%|██▎       | 165560/716198 [05:20<15:39, 586.32frames/s]\n 23%|██▎       | 168260/716198 [05:25<16:27, 555.04frames/s]\n 24%|██▍       | 170760/716198 [05:29<16:02, 566.83frames/s]\n 24%|██▍       | 173560/716198 [05:35<16:17, 554.86frames/s]\n 25%|██▍       | 176560/716198 [05:38<14:15, 630.79frames/s]\n 25%|██▌       | 179560/716198 [05:43<14:49, 603.60frames/s]\n 25%|██▌       | 182060/716198 [05:49<15:58, 557.02frames/s]\n 26%|██▌       | 184760/716198 [05:55<17:13, 514.15frames/s]\n 26%|██▌       | 187560/716198 [06:01<17:37, 499.89frames/s]\n 27%|██▋       | 190460/716198 [06:08<18:16, 479.38frames/s]\n 27%|██▋       | 192960/716198 [06:13<17:58, 485.08frames/s]\n 27%|██▋       | 195860/716198 [06:18<17:33, 494.07frames/s]\n 28%|██▊       | 198160/716198 [06:23<17:46, 485.56frames/s]\n 28%|██▊       | 200560/716198 [06:28<17:07, 501.83frames/s]\n 28%|██▊       | 203160/716198 [06:32<16:32, 516.70frames/s]\n 29%|██▉       | 206060/716198 [06:38<16:54, 503.04frames/s]\n 29%|██▉       | 208760/716198 [06:44<16:50, 502.14frames/s]\n 30%|██▉       | 211760/716198 [06:48<15:34, 539.74frames/s]\n 30%|██▉       | 214460/716198 [06:53<15:34, 537.14frames/s]\n 30%|███       | 217160/716198 [06:58<15:27, 538.17frames/s]\n 31%|███       | 219860/716198 [07:05<16:39, 496.37frames/s]\n 31%|███       | 222460/716198 [07:10<16:13, 507.36frames/s]\n 31%|███▏      | 225360/716198 [07:16<16:45, 488.31frames/s]\n 32%|███▏      | 228260/716198 [07:22<16:19, 498.15frames/s]\n 32%|███▏      | 231060/716198 [07:27<15:53, 508.68frames/s]\n 33%|███▎      | 233760/716198 [07:33<16:39, 482.72frames/s]\n 33%|███▎      | 236660/716198 [07:37<14:46, 541.08frames/s]\n 33%|███▎      | 239360/716198 [07:43<15:10, 523.55frames/s]\n 34%|███▍      | 242160/716198 [07:49<16:04, 491.51frames/s]\n 34%|███▍      | 244860/716198 [07:55<16:21, 480.37frames/s]\n 35%|███▍      | 247760/716198 [08:02<16:46, 465.58frames/s]\n 35%|███▍      | 250460/716198 [08:07<16:16, 477.14frames/s]\n 35%|███▌      | 253260/716198 [08:13<16:13, 475.39frames/s]\n 36%|███▌      | 256160/716198 [08:19<16:02, 477.88frames/s]\n 36%|███▌      | 258960/716198 [08:25<16:11, 470.53frames/s]\n 37%|███▋      | 261660/716198 [08:31<16:15, 466.05frames/s]\n 37%|███▋      | 264360/716198 [08:36<15:36, 482.43frames/s]\n 37%|███▋      | 267060/716198 [08:42<15:24, 485.58frames/s]\n 38%|███▊      | 269660/716198 [08:47<15:24, 482.75frames/s]\n 38%|███▊      | 272560/716198 [08:53<15:04, 490.50frames/s]\n 38%|███▊      | 275560/716198 [08:57<12:59, 565.37frames/s]\n 39%|███▉      | 278160/716198 [09:03<14:02, 519.73frames/s]\n 39%|███▉      | 280860/716198 [09:07<13:10, 550.87frames/s]\n 40%|███▉      | 283760/716198 [09:11<12:18, 585.21frames/s]\n 40%|████      | 286560/716198 [09:16<12:17, 582.71frames/s]\n 40%|████      | 289460/716198 [09:24<14:28, 491.44frames/s]\n 41%|████      | 292460/716198 [09:30<14:08, 499.32frames/s]\n 41%|████      | 295260/716198 [09:35<14:04, 498.65frames/s]\n 42%|████▏     | 297960/716198 [09:43<15:33, 448.13frames/s]\n 42%|████▏     | 300560/716198 [09:47<14:00, 494.69frames/s]\n 42%|████▏     | 303360/716198 [09:52<13:17, 517.81frames/s]\n 43%|████▎     | 306060/716198 [09:57<13:31, 505.60frames/s]\n 43%|████▎     | 308660/716198 [10:03<13:56, 487.19frames/s]\n 43%|████▎     | 311460/716198 [10:09<14:24, 468.30frames/s]\n 44%|████▍     | 314260/716198 [10:16<14:44, 454.30frames/s]\n 44%|████▍     | 317160/716198 [10:22<14:14, 467.17frames/s]\n 45%|████▍     | 320060/716198 [10:28<14:22, 459.33frames/s]\n 45%|████▌     | 322860/716198 [10:35<14:49, 442.12frames/s]\n 45%|████▌     | 325660/716198 [10:43<15:34, 417.88frames/s]\n 46%|████▌     | 328260/716198 [10:49<15:21, 421.14frames/s]\n 46%|████▌     | 331160/716198 [10:52<12:50, 499.61frames/s]\n 47%|████▋     | 333960/716198 [10:57<11:58, 532.22frames/s]\n 47%|████▋     | 336660/716198 [11:01<11:10, 566.06frames/s]\n 47%|████▋     | 339460/716198 [11:06<11:14, 558.36frames/s]\n 48%|████▊     | 342260/716198 [11:12<11:31, 540.69frames/s]\n 48%|████▊     | 344960/716198 [11:18<12:17, 503.18frames/s]\n 49%|████▊     | 347760/716198 [11:25<13:04, 469.41frames/s]\n 49%|████▉     | 350460/716198 [11:29<11:42, 520.74frames/s]\n 49%|████▉     | 353360/716198 [11:34<11:41, 517.12frames/s]\n 50%|████▉     | 356360/716198 [11:37<09:42, 617.53frames/s]\n 50%|█████     | 359360/716198 [11:41<08:51, 671.44frames/s]\n 51%|█████     | 362060/716198 [11:45<09:15, 637.73frames/s]\n 51%|█████     | 364860/716198 [11:51<09:37, 607.86frames/s]\n 51%|█████▏    | 367860/716198 [11:54<08:47, 659.92frames/s]\n 52%|█████▏    | 370860/716198 [11:58<08:26, 681.21frames/s]\n 52%|█████▏    | 373660/716198 [12:02<08:24, 679.50frames/s]\n 53%|█████▎    | 376360/716198 [12:06<08:06, 698.99frames/s]\n 53%|█████▎    | 379260/716198 [12:12<08:55, 629.50frames/s]\n 53%|█████▎    | 382060/716198 [12:15<08:04, 689.08frames/s]\n 54%|█████▍    | 384960/716198 [12:19<07:50, 704.76frames/s]\n 54%|█████▍    | 387960/716198 [12:22<07:07, 767.92frames/s]\n 55%|█████▍    | 390660/716198 [12:25<07:01, 771.54frames/s]\n 55%|█████▍    | 393560/716198 [12:31<08:07, 661.20frames/s]\n 55%|█████▌    | 396060/716198 [12:36<08:48, 606.26frames/s]\n 56%|█████▌    | 398560/716198 [12:41<09:21, 566.10frames/s]\n 56%|█████▌    | 401460/716198 [12:47<09:47, 536.11frames/s]\n 56%|█████▋    | 404260/716198 [12:54<10:13, 508.14frames/s]\n 57%|█████▋    | 406960/716198 [12:58<09:38, 534.98frames/s]\n 57%|█████▋    | 409760/716198 [13:04<10:14, 498.83frames/s]\n 58%|█████▊    | 412660/716198 [13:11<10:48, 468.00frames/s]\n 58%|█████▊    | 415560/716198 [13:18<10:42, 467.71frames/s]\n 58%|█████▊    | 418460/716198 [13:24<10:38, 466.65frames/s]\n 59%|█████▉    | 421360/716198 [13:31<11:03, 444.21frames/s]\n 59%|█████▉    | 424160/716198 [13:36<10:11, 477.71frames/s]\n 60%|█████▉    | 426760/716198 [13:41<09:58, 483.46frames/s]\n 60%|█████▉    | 429560/716198 [13:48<10:17, 464.10frames/s]\n 60%|██████    | 432260/716198 [13:54<10:33, 448.55frames/s]\n 61%|██████    | 435060/716198 [14:00<09:59, 468.65frames/s]\n 61%|██████    | 437960/716198 [14:06<10:05, 459.67frames/s]\n 62%|██████▏   | 440660/716198 [14:13<10:21, 443.29frames/s]\n 62%|██████▏   | 443460/716198 [14:20<10:28, 433.61frames/s]\n 62%|██████▏   | 446260/716198 [14:25<10:00, 449.74frames/s]\n 63%|██████▎   | 449160/716198 [14:31<09:28, 469.39frames/s]\n 63%|██████▎   | 451860/716198 [14:37<09:26, 466.25frames/s]\n 63%|██████▎   | 454360/716198 [14:42<09:22, 465.60frames/s]\n 64%|██████▍   | 457360/716198 [14:47<08:19, 517.79frames/s]\n 64%|██████▍   | 460060/716198 [14:53<08:53, 480.50frames/s]\n 65%|██████▍   | 463060/716198 [14:59<08:40, 486.69frames/s]\n 65%|██████▌   | 465860/716198 [15:06<08:51, 470.85frames/s]\n 65%|██████▌   | 468860/716198 [15:13<09:10, 449.57frames/s]\n 66%|██████▌   | 471760/716198 [15:19<08:57, 454.89frames/s]\n 66%|██████▌   | 474460/716198 [15:24<08:23, 480.14frames/s]\n 67%|██████▋   | 477060/716198 [15:30<08:26, 472.12frames/s]\n 67%|██████▋   | 479860/716198 [15:35<08:12, 479.79frames/s]\n 67%|██████▋   | 482460/716198 [15:40<07:49, 498.32frames/s]\n 68%|██████▊   | 485160/716198 [15:45<07:42, 499.46frames/s]\n 68%|██████▊   | 488060/716198 [15:50<06:54, 550.05frames/s]\n 68%|██████▊   | 490460/716198 [15:55<07:15, 518.78frames/s]\n 69%|██████▉   | 493260/716198 [16:00<07:03, 526.62frames/s]\n 69%|██████▉   | 495760/716198 [16:04<06:37, 554.62frames/s]\n 70%|██████▉   | 498260/716198 [16:09<06:54, 525.92frames/s]\n 70%|██████▉   | 501060/716198 [16:15<06:57, 514.71frames/s]\n 70%|███████   | 503660/716198 [16:19<06:35, 536.93frames/s]\n 71%|███████   | 506460/716198 [16:26<06:54, 506.46frames/s]\n 71%|███████   | 509360/716198 [16:31<06:39, 517.43frames/s]\n 71%|███████▏  | 511060/716198 [16:34<06:40, 511.84frames/s]\n 72%|███████▏  | 513760/716198 [16:37<05:44, 587.99frames/s]\n 72%|███████▏  | 516660/716198 [16:42<05:27, 609.06frames/s]\n 72%|███████▏  | 518760/716198 [16:46<05:36, 587.46frames/s]\n 73%|███████▎  | 521560/716198 [16:50<05:17, 613.53frames/s]\n 73%|███████▎  | 524360/716198 [16:56<05:48, 550.08frames/s]\n 74%|███████▎  | 527160/716198 [17:01<05:42, 551.92frames/s]\n 74%|███████▍  | 530060/716198 [17:07<05:39, 548.45frames/s]\n 74%|███████▍  | 532760/716198 [17:12<05:49, 524.72frames/s]\n 75%|███████▍  | 535260/716198 [17:16<05:21, 562.88frames/s]\n 75%|███████▌  | 538260/716198 [17:20<04:54, 604.77frames/s]\n 76%|███████▌  | 541060/716198 [17:25<04:59, 585.56frames/s]\n 76%|███████▌  | 543660/716198 [17:29<04:33, 630.55frames/s]\n 76%|███████▋  | 546460/716198 [17:33<04:33, 619.94frames/s]\n 77%|███████▋  | 548560/716198 [17:37<04:32, 614.32frames/s]\n 77%|███████▋  | 551560/716198 [17:40<03:52, 707.28frames/s]\n 77%|███████▋  | 554160/716198 [17:43<03:42, 729.10frames/s]\n 78%|███████▊  | 556960/716198 [17:47<03:37, 730.94frames/s]\n 78%|███████▊  | 559560/716198 [17:52<04:04, 640.18frames/s]\n 78%|███████▊  | 562160/716198 [17:57<04:19, 593.48frames/s]\n 79%|███████▉  | 564660/716198 [18:02<04:33, 554.82frames/s]\n 79%|███████▉  | 567560/716198 [18:08<04:34, 542.25frames/s]\n 80%|███████▉  | 570260/716198 [18:13<04:31, 538.34frames/s]\n 80%|███████▉  | 572760/716198 [18:17<04:12, 569.10frames/s]\n 80%|████████  | 575360/716198 [18:21<04:02, 580.46frames/s]\n 81%|████████  | 578060/716198 [18:24<03:32, 651.13frames/s]\n 81%|████████  | 580560/716198 [18:30<04:04, 554.51frames/s]\n 81%|████████▏ | 583460/716198 [18:37<04:13, 524.05frames/s]\n 82%|████████▏ | 586160/716198 [18:41<04:03, 534.86frames/s]\n 82%|████████▏ | 588860/716198 [18:48<04:20, 489.34frames/s]\n 83%|████████▎ | 591660/716198 [18:55<04:29, 462.08frames/s]\n 83%|████████▎ | 594560/716198 [19:02<04:32, 446.65frames/s]\n 83%|████████▎ | 597160/716198 [19:08<04:29, 440.90frames/s]\n 84%|████████▍ | 600060/716198 [19:14<04:21, 444.93frames/s]\n 84%|████████▍ | 602760/716198 [19:20<04:16, 442.79frames/s]\n 85%|████████▍ | 605560/716198 [19:26<04:02, 455.35frames/s]\n 85%|████████▍ | 608260/716198 [19:31<03:44, 480.45frames/s]\n 85%|████████▌ | 611060/716198 [19:34<03:01, 578.13frames/s]\n 86%|████████▌ | 613660/716198 [19:38<03:01, 565.48frames/s]\n 86%|████████▌ | 616460/716198 [19:43<02:54, 573.19frames/s]\n 86%|████████▋ | 619060/716198 [19:47<02:44, 590.10frames/s]\n 87%|████████▋ | 621860/716198 [19:53<02:46, 564.90frames/s]\n 87%|████████▋ | 624760/716198 [19:59<02:56, 518.07frames/s]\n 88%|████████▊ | 627660/716198 [20:05<02:49, 523.30frames/s]\n 88%|████████▊ | 630460/716198 [20:10<02:41, 529.26frames/s]\n 88%|████████▊ | 633260/716198 [20:16<02:42, 510.01frames/s]\n 89%|████████▉ | 635860/716198 [20:23<02:52, 465.33frames/s]\n 89%|████████▉ | 638560/716198 [20:27<02:36, 495.46frames/s]\n 90%|████████▉ | 641360/716198 [20:34<02:41, 463.22frames/s]\n 90%|████████▉ | 644160/716198 [20:42<02:51, 419.96frames/s]\n 90%|█████████ | 646560/716198 [20:49<02:50, 408.91frames/s]\n 91%|█████████ | 649460/716198 [20:52<02:18, 481.88frames/s]\n 91%|█████████ | 652260/716198 [21:03<02:47, 380.80frames/s]\n 91%|█████████▏| 655160/716198 [21:10<02:37, 387.07frames/s]\n 92%|█████████▏| 657860/716198 [21:19<02:39, 366.30frames/s]\n 92%|█████████▏| 660660/716198 [21:26<02:32, 364.92frames/s]\n 93%|█████████▎| 663560/716198 [21:35<02:27, 356.43frames/s]\n 93%|█████████▎| 666160/716198 [21:41<02:11, 379.86frames/s]\n 93%|█████████▎| 668760/716198 [21:47<01:59, 395.49frames/s]\n 94%|█████████▍| 671560/716198 [21:51<01:41, 438.42frames/s]\n 94%|█████████▍| 674360/716198 [21:58<01:36, 432.23frames/s]\n 95%|█████████▍| 677060/716198 [22:03<01:26, 453.65frames/s]\n 95%|█████████▍| 679960/716198 [22:09<01:18, 463.31frames/s]\n 95%|█████████▌| 682760/716198 [22:24<01:44, 321.32frames/s]\n 96%|█████████▌| 685460/716198 [22:30<01:26, 357.05frames/s]\n 96%|█████████▌| 688260/716198 [22:36<01:11, 389.14frames/s]\n 96%|█████████▋| 690960/716198 [22:40<00:57, 435.58frames/s]\n 97%|█████████▋| 693860/716198 [22:46<00:49, 451.35frames/s]\n 97%|█████████▋| 696660/716198 [22:53<00:45, 426.25frames/s]\n 98%|█████████▊| 699560/716198 [22:59<00:37, 438.41frames/s]\n 98%|█████████▊| 702360/716198 [23:05<00:29, 461.57frames/s]\n 98%|█████████▊| 705160/716198 [23:10<00:23, 473.95frames/s]\n 99%|█████████▉| 707860/716198 [23:17<00:18, 457.86frames/s]\n 99%|█████████▉| 710660/716198 [23:22<00:11, 473.56frames/s]\n100%|█████████▉| 713460/716198 [23:28<00:05, 472.48frames/s]\n100%|██████████| 716198/716198 [23:33<00:00, 508.55frames/s]\n100%|██████████| 716198/716198 [23:33<00:00, 506.86frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2947192836452175,
        "compression_ratio": 1.6294820717131475,
        "end": 6.5,
        "id": 0,
        "no_speech_prob": 0.002472271677106619,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Can you hear me right? Let's try to pick the time of the week when I am most exhausted.",
        "tokens": [
          50364,
          1664,
          291,
          1568,
          385,
          558,
          30,
          961,
          311,
          853,
          281,
          1888,
          264,
          565,
          295,
          264,
          1243,
          562,
          286,
          669,
          881,
          17992,
          13,
          50689
        ]
      },
      {
        "avg_logprob": -0.2947192836452175,
        "compression_ratio": 1.6294820717131475,
        "end": 9.9,
        "id": 1,
        "no_speech_prob": 0.002472271677106619,
        "seek": 0,
        "start": 6.5,
        "temperature": 0,
        "text": " And that's when I'll livestream on YouTube.",
        "tokens": [
          50689,
          400,
          300,
          311,
          562,
          286,
          603,
          29782,
          322,
          3088,
          13,
          50859
        ]
      },
      {
        "avg_logprob": -0.2947192836452175,
        "compression_ratio": 1.6294820717131475,
        "end": 13.200000000000001,
        "id": 2,
        "no_speech_prob": 0.002472271677106619,
        "seek": 0,
        "start": 9.9,
        "temperature": 0,
        "text": " That's what time it is right now. I have to say that, you know,",
        "tokens": [
          50859,
          663,
          311,
          437,
          565,
          309,
          307,
          558,
          586,
          13,
          286,
          362,
          281,
          584,
          300,
          11,
          291,
          458,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.2947192836452175,
        "compression_ratio": 1.6294820717131475,
        "end": 19,
        "id": 3,
        "no_speech_prob": 0.002472271677106619,
        "seek": 0,
        "start": 13.200000000000001,
        "temperature": 0,
        "text": " if you will just bear with me and allow me to have a little therapy with you,",
        "tokens": [
          51024,
          498,
          291,
          486,
          445,
          6155,
          365,
          385,
          293,
          2089,
          385,
          281,
          362,
          257,
          707,
          9492,
          365,
          291,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2947192836452175,
        "compression_ratio": 1.6294820717131475,
        "end": 23,
        "id": 4,
        "no_speech_prob": 0.002472271677106619,
        "seek": 0,
        "start": 19,
        "temperature": 0,
        "text": " few dozen people who happen to be watching this right now,",
        "tokens": [
          51314,
          1326,
          16654,
          561,
          567,
          1051,
          281,
          312,
          1976,
          341,
          558,
          586,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.2947192836452175,
        "compression_ratio": 1.6294820717131475,
        "end": 27.900000000000002,
        "id": 5,
        "no_speech_prob": 0.002472271677106619,
        "seek": 0,
        "start": 23,
        "temperature": 0,
        "text": " I would say that this week and through the next six or seven or eight weeks,",
        "tokens": [
          51514,
          286,
          576,
          584,
          300,
          341,
          1243,
          293,
          807,
          264,
          958,
          2309,
          420,
          3407,
          420,
          3180,
          3259,
          11,
          51759
        ]
      },
      {
        "avg_logprob": -0.26705495151904746,
        "compression_ratio": 1.668103448275862,
        "end": 33.4,
        "id": 6,
        "no_speech_prob": 0.006691227667033672,
        "seek": 2790,
        "start": 27.9,
        "temperature": 0,
        "text": " somewhere to the middle of May are probably the busiest weeks for me of the whole year.",
        "tokens": [
          50364,
          4079,
          281,
          264,
          2808,
          295,
          1891,
          366,
          1391,
          264,
          1255,
          6495,
          3259,
          337,
          385,
          295,
          264,
          1379,
          1064,
          13,
          50639
        ]
      },
      {
        "avg_logprob": -0.26705495151904746,
        "compression_ratio": 1.668103448275862,
        "end": 38.8,
        "id": 7,
        "no_speech_prob": 0.006691227667033672,
        "seek": 2790,
        "start": 33.4,
        "temperature": 0,
        "text": " So I'm here and I'll probably be here next Friday.",
        "tokens": [
          50639,
          407,
          286,
          478,
          510,
          293,
          286,
          603,
          1391,
          312,
          510,
          958,
          6984,
          13,
          50909
        ]
      },
      {
        "avg_logprob": -0.26705495151904746,
        "compression_ratio": 1.668103448275862,
        "end": 41.8,
        "id": 8,
        "no_speech_prob": 0.006691227667033672,
        "seek": 2790,
        "start": 38.8,
        "temperature": 0,
        "text": " But I'm only going to be here the Friday after that.",
        "tokens": [
          50909,
          583,
          286,
          478,
          787,
          516,
          281,
          312,
          510,
          264,
          6984,
          934,
          300,
          13,
          51059
        ]
      },
      {
        "avg_logprob": -0.26705495151904746,
        "compression_ratio": 1.668103448275862,
        "end": 47.8,
        "id": 9,
        "no_speech_prob": 0.006691227667033672,
        "seek": 2790,
        "start": 41.8,
        "temperature": 0,
        "text": " But you will see I might miss a Friday, but I'm looking forward to springtime end of May, June,",
        "tokens": [
          51059,
          583,
          291,
          486,
          536,
          286,
          1062,
          1713,
          257,
          6984,
          11,
          457,
          286,
          478,
          1237,
          2128,
          281,
          5587,
          3766,
          917,
          295,
          1891,
          11,
          6928,
          11,
          51359
        ]
      },
      {
        "avg_logprob": -0.26705495151904746,
        "compression_ratio": 1.668103448275862,
        "end": 49.8,
        "id": 10,
        "no_speech_prob": 0.006691227667033672,
        "seek": 2790,
        "start": 47.8,
        "temperature": 0,
        "text": " and hopefully then you'll be seeing a lot more of me.",
        "tokens": [
          51359,
          293,
          4696,
          550,
          291,
          603,
          312,
          2577,
          257,
          688,
          544,
          295,
          385,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.26705495151904746,
        "compression_ratio": 1.668103448275862,
        "end": 56.4,
        "id": 11,
        "no_speech_prob": 0.006691227667033672,
        "seek": 2790,
        "start": 49.8,
        "temperature": 0,
        "text": " So if I seem a little wobbly, a little tired,",
        "tokens": [
          51459,
          407,
          498,
          286,
          1643,
          257,
          707,
          33775,
          25021,
          11,
          257,
          707,
          5868,
          11,
          51789
        ]
      },
      {
        "avg_logprob": -0.21763921071247883,
        "compression_ratio": 1.4903846153846154,
        "end": 58.9,
        "id": 12,
        "no_speech_prob": 0.00025314665981568396,
        "seek": 5640,
        "start": 56.4,
        "temperature": 0,
        "text": " if you don't see me on a Friday, know that everything is fine,",
        "tokens": [
          50364,
          498,
          291,
          500,
          380,
          536,
          385,
          322,
          257,
          6984,
          11,
          458,
          300,
          1203,
          307,
          2489,
          11,
          50489
        ]
      },
      {
        "avg_logprob": -0.21763921071247883,
        "compression_ratio": 1.4903846153846154,
        "end": 68.7,
        "id": 13,
        "no_speech_prob": 0.00025314665981568396,
        "seek": 5640,
        "start": 58.9,
        "temperature": 0,
        "text": " but I do have this like a job thing that I do and it's a busy time of year here at New York University.",
        "tokens": [
          50489,
          457,
          286,
          360,
          362,
          341,
          411,
          257,
          1691,
          551,
          300,
          286,
          360,
          293,
          309,
          311,
          257,
          5856,
          565,
          295,
          1064,
          510,
          412,
          1873,
          3609,
          3535,
          13,
          50979
        ]
      },
      {
        "avg_logprob": -0.21763921071247883,
        "compression_ratio": 1.4903846153846154,
        "end": 73.4,
        "id": 14,
        "no_speech_prob": 0.00025314665981568396,
        "seek": 5640,
        "start": 68.7,
        "temperature": 0,
        "text": " Okay. So first of all, I have a very important announcement to make.",
        "tokens": [
          50979,
          1033,
          13,
          407,
          700,
          295,
          439,
          11,
          286,
          362,
          257,
          588,
          1021,
          12847,
          281,
          652,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21763921071247883,
        "compression_ratio": 1.4903846153846154,
        "end": 81.8,
        "id": 15,
        "no_speech_prob": 0.00025314665981568396,
        "seek": 5640,
        "start": 73.4,
        "temperature": 0,
        "text": " I have some new hydration technology that I have been working on all week,",
        "tokens": [
          51214,
          286,
          362,
          512,
          777,
          43631,
          2899,
          300,
          286,
          362,
          668,
          1364,
          322,
          439,
          1243,
          11,
          51634
        ]
      },
      {
        "avg_logprob": -0.26447124870455996,
        "compression_ratio": 1.6123348017621146,
        "end": 86.8,
        "id": 16,
        "no_speech_prob": 0.03963708505034447,
        "seek": 8180,
        "start": 81.8,
        "temperature": 0,
        "text": " asking for recommendations, typing in credit card information onto Amazon.",
        "tokens": [
          50364,
          3365,
          337,
          10434,
          11,
          18444,
          294,
          5397,
          2920,
          1589,
          3911,
          6795,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.26447124870455996,
        "compression_ratio": 1.6123348017621146,
        "end": 88.3,
        "id": 17,
        "no_speech_prob": 0.03963708505034447,
        "seek": 8180,
        "start": 86.8,
        "temperature": 0,
        "text": " Actually, you don't have to type in the credit card information.",
        "tokens": [
          50614,
          5135,
          11,
          291,
          500,
          380,
          362,
          281,
          2010,
          294,
          264,
          5397,
          2920,
          1589,
          13,
          50689
        ]
      },
      {
        "avg_logprob": -0.26447124870455996,
        "compression_ratio": 1.6123348017621146,
        "end": 88.8,
        "id": 18,
        "no_speech_prob": 0.03963708505034447,
        "seek": 8180,
        "start": 88.3,
        "temperature": 0,
        "text": " It remembers it.",
        "tokens": [
          50689,
          467,
          26228,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.26447124870455996,
        "compression_ratio": 1.6123348017621146,
        "end": 98.5,
        "id": 19,
        "no_speech_prob": 0.03963708505034447,
        "seek": 8180,
        "start": 88.8,
        "temperature": 0,
        "text": " But I present to you a purple water bottle.",
        "tokens": [
          50714,
          583,
          286,
          1974,
          281,
          291,
          257,
          9656,
          1281,
          7817,
          13,
          51199
        ]
      },
      {
        "avg_logprob": -0.26447124870455996,
        "compression_ratio": 1.6123348017621146,
        "end": 101.6,
        "id": 20,
        "no_speech_prob": 0.03963708505034447,
        "seek": 8180,
        "start": 98.5,
        "temperature": 0,
        "text": " Okay. The nice thing about this is it's a little less dangerous.",
        "tokens": [
          51199,
          1033,
          13,
          440,
          1481,
          551,
          466,
          341,
          307,
          309,
          311,
          257,
          707,
          1570,
          5795,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.26447124870455996,
        "compression_ratio": 1.6123348017621146,
        "end": 104.3,
        "id": 21,
        "no_speech_prob": 0.03963708505034447,
        "seek": 8180,
        "start": 101.6,
        "temperature": 0,
        "text": " I don't know if you remember I had a pitcher one week.",
        "tokens": [
          51354,
          286,
          500,
          380,
          458,
          498,
          291,
          1604,
          286,
          632,
          257,
          42147,
          472,
          1243,
          13,
          51489
        ]
      },
      {
        "avg_logprob": -0.26447124870455996,
        "compression_ratio": 1.6123348017621146,
        "end": 107,
        "id": 22,
        "no_speech_prob": 0.03963708505034447,
        "seek": 8180,
        "start": 104.3,
        "temperature": 0,
        "text": " So this is good. I'm going to step off stage.",
        "tokens": [
          51489,
          407,
          341,
          307,
          665,
          13,
          286,
          478,
          516,
          281,
          1823,
          766,
          3233,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.21711387634277343,
        "compression_ratio": 1.456989247311828,
        "end": 109.7,
        "id": 23,
        "no_speech_prob": 0.08509144186973572,
        "seek": 10700,
        "start": 107,
        "temperature": 0,
        "text": " I'm off stage right now. It's not really a stage.",
        "tokens": [
          50364,
          286,
          478,
          766,
          3233,
          558,
          586,
          13,
          467,
          311,
          406,
          534,
          257,
          3233,
          13,
          50499
        ]
      },
      {
        "avg_logprob": -0.21711387634277343,
        "compression_ratio": 1.456989247311828,
        "end": 118.1,
        "id": 24,
        "no_speech_prob": 0.08509144186973572,
        "seek": 10700,
        "start": 109.7,
        "temperature": 0,
        "text": " And drink some water. Okay.",
        "tokens": [
          50499,
          400,
          2822,
          512,
          1281,
          13,
          1033,
          13,
          50919
        ]
      },
      {
        "avg_logprob": -0.21711387634277343,
        "compression_ratio": 1.456989247311828,
        "end": 126.6,
        "id": 25,
        "no_speech_prob": 0.08509144186973572,
        "seek": 10700,
        "start": 118.1,
        "temperature": 0,
        "text": " Now, I have to get moving here because I've got to leave in about an hour and a half.",
        "tokens": [
          50919,
          823,
          11,
          286,
          362,
          281,
          483,
          2684,
          510,
          570,
          286,
          600,
          658,
          281,
          1856,
          294,
          466,
          364,
          1773,
          293,
          257,
          1922,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.21711387634277343,
        "compression_ratio": 1.456989247311828,
        "end": 133.8,
        "id": 26,
        "no_speech_prob": 0.08509144186973572,
        "seek": 10700,
        "start": 126.6,
        "temperature": 0,
        "text": " And you know, first of all, I think it's one hour is a pretty good amount of time for a weekly live stream.",
        "tokens": [
          51344,
          400,
          291,
          458,
          11,
          700,
          295,
          439,
          11,
          286,
          519,
          309,
          311,
          472,
          1773,
          307,
          257,
          1238,
          665,
          2372,
          295,
          565,
          337,
          257,
          12460,
          1621,
          4309,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.2456057386578254,
        "compression_ratio": 1.5778688524590163,
        "end": 139.70000000000002,
        "id": 27,
        "no_speech_prob": 0.07695398479700089,
        "seek": 13380,
        "start": 133.8,
        "temperature": 0,
        "text": " I would say. I like to do two hours if I can. Two and a half hours even sometimes.",
        "tokens": [
          50364,
          286,
          576,
          584,
          13,
          286,
          411,
          281,
          360,
          732,
          2496,
          498,
          286,
          393,
          13,
          4453,
          293,
          257,
          1922,
          2496,
          754,
          2171,
          13,
          50659
        ]
      },
      {
        "avg_logprob": -0.2456057386578254,
        "compression_ratio": 1.5778688524590163,
        "end": 144.70000000000002,
        "id": 28,
        "no_speech_prob": 0.07695398479700089,
        "seek": 13380,
        "start": 139.70000000000002,
        "temperature": 0,
        "text": " Been having a thing where like the last few weeks I did like five or six hours each Friday.",
        "tokens": [
          50659,
          32839,
          1419,
          257,
          551,
          689,
          411,
          264,
          1036,
          1326,
          3259,
          286,
          630,
          411,
          1732,
          420,
          2309,
          2496,
          1184,
          6984,
          13,
          50909
        ]
      },
      {
        "avg_logprob": -0.2456057386578254,
        "compression_ratio": 1.5778688524590163,
        "end": 152.60000000000002,
        "id": 29,
        "no_speech_prob": 0.07695398479700089,
        "seek": 13380,
        "start": 144.70000000000002,
        "temperature": 0,
        "text": " So, audio up. Maybe turn your audio up because I see lots of green.",
        "tokens": [
          50909,
          407,
          11,
          6278,
          493,
          13,
          2704,
          1261,
          428,
          6278,
          493,
          570,
          286,
          536,
          3195,
          295,
          3092,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.2456057386578254,
        "compression_ratio": 1.5778688524590163,
        "end": 156.4,
        "id": 30,
        "no_speech_prob": 0.07695398479700089,
        "seek": 13380,
        "start": 152.60000000000002,
        "temperature": 0,
        "text": " I see people asking if the stream has crashed. Everything looks like it's working for me.",
        "tokens": [
          51304,
          286,
          536,
          561,
          3365,
          498,
          264,
          4309,
          575,
          24190,
          13,
          5471,
          1542,
          411,
          309,
          311,
          1364,
          337,
          385,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2456057386578254,
        "compression_ratio": 1.5778688524590163,
        "end": 160.4,
        "id": 31,
        "no_speech_prob": 0.07695398479700089,
        "seek": 13380,
        "start": 156.4,
        "temperature": 0,
        "text": " So I don't have a lot of time today, but I have two.",
        "tokens": [
          51494,
          407,
          286,
          500,
          380,
          362,
          257,
          688,
          295,
          565,
          965,
          11,
          457,
          286,
          362,
          732,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.1874231873897084,
        "compression_ratio": 1.7093023255813953,
        "end": 165.20000000000002,
        "id": 32,
        "no_speech_prob": 0.3520772457122803,
        "seek": 16040,
        "start": 160.4,
        "temperature": 0,
        "text": " I'm going to try to over the next several weeks get started with content more quickly.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          853,
          281,
          670,
          264,
          958,
          2940,
          3259,
          483,
          1409,
          365,
          2701,
          544,
          2661,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.1874231873897084,
        "compression_ratio": 1.7093023255813953,
        "end": 168,
        "id": 33,
        "no_speech_prob": 0.3520772457122803,
        "seek": 16040,
        "start": 165.20000000000002,
        "temperature": 0,
        "text": " I still would like to do something where I share work from the community,",
        "tokens": [
          50604,
          286,
          920,
          576,
          411,
          281,
          360,
          746,
          689,
          286,
          2073,
          589,
          490,
          264,
          1768,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.1874231873897084,
        "compression_ratio": 1.7093023255813953,
        "end": 170.3,
        "id": 34,
        "no_speech_prob": 0.3520772457122803,
        "seek": 16040,
        "start": 168,
        "temperature": 0,
        "text": " but I'm going to put that aside just for today.",
        "tokens": [
          50744,
          457,
          286,
          478,
          516,
          281,
          829,
          300,
          7359,
          445,
          337,
          965,
          13,
          50859
        ]
      },
      {
        "avg_logprob": -0.1874231873897084,
        "compression_ratio": 1.7093023255813953,
        "end": 173.1,
        "id": 35,
        "no_speech_prob": 0.3520772457122803,
        "seek": 16040,
        "start": 170.3,
        "temperature": 0,
        "text": " Hopefully next week I'll have more time to do that.",
        "tokens": [
          50859,
          10429,
          958,
          1243,
          286,
          603,
          362,
          544,
          565,
          281,
          360,
          300,
          13,
          50999
        ]
      },
      {
        "avg_logprob": -0.1874231873897084,
        "compression_ratio": 1.7093023255813953,
        "end": 179.5,
        "id": 36,
        "no_speech_prob": 0.3520772457122803,
        "seek": 16040,
        "start": 173.1,
        "temperature": 0,
        "text": " And I'm going to try to pick essentially one project to do each week.",
        "tokens": [
          50999,
          400,
          286,
          478,
          516,
          281,
          853,
          281,
          1888,
          4476,
          472,
          1716,
          281,
          360,
          1184,
          1243,
          13,
          51319
        ]
      },
      {
        "avg_logprob": -0.1874231873897084,
        "compression_ratio": 1.7093023255813953,
        "end": 184.8,
        "id": 37,
        "no_speech_prob": 0.3520772457122803,
        "seek": 16040,
        "start": 179.5,
        "temperature": 0,
        "text": " I don't know what I mean by project, but one thing to focus on as opposed to trying to do four or five things.",
        "tokens": [
          51319,
          286,
          500,
          380,
          458,
          437,
          286,
          914,
          538,
          1716,
          11,
          457,
          472,
          551,
          281,
          1879,
          322,
          382,
          8851,
          281,
          1382,
          281,
          360,
          1451,
          420,
          1732,
          721,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.31213942028227304,
        "compression_ratio": 1.584,
        "end": 194.20000000000002,
        "id": 38,
        "no_speech_prob": 0.0488506481051445,
        "seek": 18480,
        "start": 184.9,
        "temperature": 0,
        "text": " And then I will hopefully as things calm down and my schedule opens up a bit more in May and June,",
        "tokens": [
          50369,
          400,
          550,
          286,
          486,
          4696,
          382,
          721,
          7151,
          760,
          293,
          452,
          7567,
          9870,
          493,
          257,
          857,
          544,
          294,
          1891,
          293,
          6928,
          11,
          50834
        ]
      },
      {
        "avg_logprob": -0.31213942028227304,
        "compression_ratio": 1.584,
        "end": 198.9,
        "id": 39,
        "no_speech_prob": 0.0488506481051445,
        "seek": 18480,
        "start": 194.20000000000002,
        "temperature": 0,
        "text": " maybe I'll get some do some more other stuff and extra live streams and all sorts of that sort of stuff.",
        "tokens": [
          50834,
          1310,
          286,
          603,
          483,
          512,
          360,
          512,
          544,
          661,
          1507,
          293,
          2857,
          1621,
          15842,
          293,
          439,
          7527,
          295,
          300,
          1333,
          295,
          1507,
          13,
          51069
        ]
      },
      {
        "avg_logprob": -0.31213942028227304,
        "compression_ratio": 1.584,
        "end": 199.9,
        "id": 40,
        "no_speech_prob": 0.0488506481051445,
        "seek": 18480,
        "start": 198.9,
        "temperature": 0,
        "text": " Hopefully I'll have some more guests.",
        "tokens": [
          51069,
          10429,
          286,
          603,
          362,
          512,
          544,
          9804,
          13,
          51119
        ]
      },
      {
        "avg_logprob": -0.31213942028227304,
        "compression_ratio": 1.584,
        "end": 208.4,
        "id": 41,
        "no_speech_prob": 0.0488506481051445,
        "seek": 18480,
        "start": 199.9,
        "temperature": 0,
        "text": " If you didn't watch, Saran Yitbarek was on this week talking about how to give a good tech talk.",
        "tokens": [
          51119,
          759,
          291,
          994,
          380,
          1159,
          11,
          6894,
          282,
          398,
          270,
          30682,
          74,
          390,
          322,
          341,
          1243,
          1417,
          466,
          577,
          281,
          976,
          257,
          665,
          7553,
          751,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.31213942028227304,
        "compression_ratio": 1.584,
        "end": 211.5,
        "id": 42,
        "no_speech_prob": 0.0488506481051445,
        "seek": 18480,
        "start": 208.4,
        "temperature": 0,
        "text": " Sum it up in one sentence like think about it as a story.",
        "tokens": [
          51544,
          8626,
          309,
          493,
          294,
          472,
          8174,
          411,
          519,
          466,
          309,
          382,
          257,
          1657,
          13,
          51699
        ]
      },
      {
        "avg_logprob": -0.3116741180419922,
        "compression_ratio": 1.6666666666666667,
        "end": 218.6,
        "id": 43,
        "no_speech_prob": 0.020021405071020126,
        "seek": 21150,
        "start": 211.5,
        "temperature": 0,
        "text": " I deal with this all the time here, I guess with listening to people present about their work here at NYU.",
        "tokens": [
          50364,
          286,
          2028,
          365,
          341,
          439,
          264,
          565,
          510,
          11,
          286,
          2041,
          365,
          4764,
          281,
          561,
          1974,
          466,
          641,
          589,
          510,
          412,
          42682,
          13,
          50719
        ]
      },
      {
        "avg_logprob": -0.3116741180419922,
        "compression_ratio": 1.6666666666666667,
        "end": 223.6,
        "id": 44,
        "no_speech_prob": 0.020021405071020126,
        "seek": 21150,
        "start": 218.6,
        "temperature": 0,
        "text": " And one thing that I think is a pitfall is you get up, you want to talk about your project and you say,",
        "tokens": [
          50719,
          400,
          472,
          551,
          300,
          286,
          519,
          307,
          257,
          10147,
          6691,
          307,
          291,
          483,
          493,
          11,
          291,
          528,
          281,
          751,
          466,
          428,
          1716,
          293,
          291,
          584,
          11,
          50969
        ]
      },
      {
        "avg_logprob": -0.3116741180419922,
        "compression_ratio": 1.6666666666666667,
        "end": 225.4,
        "id": 45,
        "no_speech_prob": 0.020021405071020126,
        "seek": 21150,
        "start": 223.6,
        "temperature": 0,
        "text": " okay, so I made this thing.",
        "tokens": [
          50969,
          1392,
          11,
          370,
          286,
          1027,
          341,
          551,
          13,
          51059
        ]
      },
      {
        "avg_logprob": -0.3116741180419922,
        "compression_ratio": 1.6666666666666667,
        "end": 232.7,
        "id": 46,
        "no_speech_prob": 0.020021405071020126,
        "seek": 21150,
        "start": 225.4,
        "temperature": 0,
        "text": " I did it with Illustrator and then with pen and then purple and pink colors.",
        "tokens": [
          51059,
          286,
          630,
          309,
          365,
          37788,
          19802,
          293,
          550,
          365,
          3435,
          293,
          550,
          9656,
          293,
          7022,
          4577,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.3116741180419922,
        "compression_ratio": 1.6666666666666667,
        "end": 235.6,
        "id": 47,
        "no_speech_prob": 0.020021405071020126,
        "seek": 21150,
        "start": 232.7,
        "temperature": 0,
        "text": " This doesn't work for wallpaper.",
        "tokens": [
          51424,
          639,
          1177,
          380,
          589,
          337,
          43293,
          13,
          51569
        ]
      },
      {
        "avg_logprob": -0.3116741180419922,
        "compression_ratio": 1.6666666666666667,
        "end": 236.9,
        "id": 48,
        "no_speech_prob": 0.020021405071020126,
        "seek": 21150,
        "start": 235.6,
        "temperature": 0,
        "text": " Here's my website.",
        "tokens": [
          51569,
          1692,
          311,
          452,
          3144,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.3116741180419922,
        "compression_ratio": 1.6666666666666667,
        "end": 241.4,
        "id": 49,
        "no_speech_prob": 0.020021405071020126,
        "seek": 21150,
        "start": 236.9,
        "temperature": 0,
        "text": " I made it with jQuery, but then I had to use a node server because I wanted web sockets",
        "tokens": [
          51634,
          286,
          1027,
          309,
          365,
          361,
          35550,
          11,
          457,
          550,
          286,
          632,
          281,
          764,
          257,
          9984,
          7154,
          570,
          286,
          1415,
          3670,
          370,
          11984,
          51859
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 244.6,
        "id": 50,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 241.4,
        "temperature": 0,
        "text": " because the thing about web sockets is they can talk real time in two directions.",
        "tokens": [
          50364,
          570,
          264,
          551,
          466,
          3670,
          370,
          11984,
          307,
          436,
          393,
          751,
          957,
          565,
          294,
          732,
          11095,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 250.4,
        "id": 51,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 244.6,
        "temperature": 0,
        "text": " And instead of this is my story, this is who I am, this is why I care about this idea",
        "tokens": [
          50524,
          400,
          2602,
          295,
          341,
          307,
          452,
          1657,
          11,
          341,
          307,
          567,
          286,
          669,
          11,
          341,
          307,
          983,
          286,
          1127,
          466,
          341,
          1558,
          50814
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 253.4,
        "id": 52,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 250.4,
        "temperature": 0,
        "text": " and this is the thing that I want to communicate to you today.",
        "tokens": [
          50814,
          293,
          341,
          307,
          264,
          551,
          300,
          286,
          528,
          281,
          7890,
          281,
          291,
          965,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 257.5,
        "id": 53,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 253.4,
        "temperature": 0,
        "text": " So anyway, I'm off topic.",
        "tokens": [
          50964,
          407,
          4033,
          11,
          286,
          478,
          766,
          4829,
          13,
          51169
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 262.1,
        "id": 54,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 257.5,
        "temperature": 0,
        "text": " Toot Toot is absolutely right.",
        "tokens": [
          51169,
          1407,
          310,
          1407,
          310,
          307,
          3122,
          558,
          13,
          51399
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 265.9,
        "id": 55,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 262.1,
        "temperature": 0,
        "text": " Okay, Dan in the chat asks, oh, hey, first of all, hi Dan.",
        "tokens": [
          51399,
          1033,
          11,
          3394,
          294,
          264,
          5081,
          8962,
          11,
          1954,
          11,
          4177,
          11,
          700,
          295,
          439,
          11,
          4879,
          3394,
          13,
          51589
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 267.2,
        "id": 56,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 265.9,
        "temperature": 0,
        "text": " My name is also Dan.",
        "tokens": [
          51589,
          1222,
          1315,
          307,
          611,
          3394,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.26897064978335083,
        "compression_ratio": 1.6244897959183673,
        "end": 268.7,
        "id": 57,
        "no_speech_prob": 0.002287157578393817,
        "seek": 24140,
        "start": 267.2,
        "temperature": 0,
        "text": " How long are you live tonight?",
        "tokens": [
          51654,
          1012,
          938,
          366,
          291,
          1621,
          4440,
          30,
          51729
        ]
      },
      {
        "avg_logprob": -0.3335318811161002,
        "compression_ratio": 1.5084033613445378,
        "end": 270.09999999999997,
        "id": 58,
        "no_speech_prob": 0.08508092910051346,
        "seek": 26870,
        "start": 268.8,
        "temperature": 0,
        "text": " Let's say 530 p.m.",
        "tokens": [
          50369,
          961,
          311,
          584,
          1025,
          3446,
          280,
          13,
          76,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.3335318811161002,
        "compression_ratio": 1.5084033613445378,
        "end": 272.09999999999997,
        "id": 59,
        "no_speech_prob": 0.08508092910051346,
        "seek": 26870,
        "start": 270.09999999999997,
        "temperature": 0,
        "text": " That is about one hour and 25 minutes from now.",
        "tokens": [
          50434,
          663,
          307,
          466,
          472,
          1773,
          293,
          3552,
          2077,
          490,
          586,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.3335318811161002,
        "compression_ratio": 1.5084033613445378,
        "end": 281.2,
        "id": 60,
        "no_speech_prob": 0.08508092910051346,
        "seek": 26870,
        "start": 272.09999999999997,
        "temperature": 0,
        "text": " Okay, but as all of you know, there are always, after this is over, an archive is always uploaded",
        "tokens": [
          50534,
          1033,
          11,
          457,
          382,
          439,
          295,
          291,
          458,
          11,
          456,
          366,
          1009,
          11,
          934,
          341,
          307,
          670,
          11,
          364,
          23507,
          307,
          1009,
          17135,
          50989
        ]
      },
      {
        "avg_logprob": -0.3335318811161002,
        "compression_ratio": 1.5084033613445378,
        "end": 288,
        "id": 61,
        "no_speech_prob": 0.08508092910051346,
        "seek": 26870,
        "start": 281.2,
        "temperature": 0,
        "text": " and shorter edited versions of the stuff that I do in this one and a half hour time period",
        "tokens": [
          50989,
          293,
          11639,
          23016,
          9606,
          295,
          264,
          1507,
          300,
          286,
          360,
          294,
          341,
          472,
          293,
          257,
          1922,
          1773,
          565,
          2896,
          51329
        ]
      },
      {
        "avg_logprob": -0.3335318811161002,
        "compression_ratio": 1.5084033613445378,
        "end": 291.4,
        "id": 62,
        "no_speech_prob": 0.08508092910051346,
        "seek": 26870,
        "start": 288,
        "temperature": 0,
        "text": " are also put together and uploaded separately.",
        "tokens": [
          51329,
          366,
          611,
          829,
          1214,
          293,
          17135,
          14759,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.3335318811161002,
        "compression_ratio": 1.5084033613445378,
        "end": 293.4,
        "id": 63,
        "no_speech_prob": 0.08508092910051346,
        "seek": 26870,
        "start": 291.4,
        "temperature": 0,
        "text": " Because why not just have redundant content?",
        "tokens": [
          51499,
          1436,
          983,
          406,
          445,
          362,
          40997,
          2701,
          30,
          51599
        ]
      },
      {
        "avg_logprob": -0.3335318811161002,
        "compression_ratio": 1.5084033613445378,
        "end": 295.4,
        "id": 64,
        "no_speech_prob": 0.08508092910051346,
        "seek": 26870,
        "start": 293.4,
        "temperature": 0,
        "text": " More views.",
        "tokens": [
          51599,
          5048,
          6809,
          13,
          51699
        ]
      },
      {
        "avg_logprob": -0.31597847990937283,
        "compression_ratio": 1.5401785714285714,
        "end": 299.29999999999995,
        "id": 65,
        "no_speech_prob": 0.19928236305713654,
        "seek": 29540,
        "start": 296.09999999999997,
        "temperature": 0,
        "text": " So what did I want to say?",
        "tokens": [
          50399,
          407,
          437,
          630,
          286,
          528,
          281,
          584,
          30,
          50559
        ]
      },
      {
        "avg_logprob": -0.31597847990937283,
        "compression_ratio": 1.5401785714285714,
        "end": 304.59999999999997,
        "id": 66,
        "no_speech_prob": 0.19928236305713654,
        "seek": 29540,
        "start": 299.29999999999995,
        "temperature": 0,
        "text": " In fact, last week I've been behind on so many things that I haven't even released two videos,",
        "tokens": [
          50559,
          682,
          1186,
          11,
          1036,
          1243,
          286,
          600,
          668,
          2261,
          322,
          370,
          867,
          721,
          300,
          286,
          2378,
          380,
          754,
          4736,
          732,
          2145,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.31597847990937283,
        "compression_ratio": 1.5401785714285714,
        "end": 312.29999999999995,
        "id": 67,
        "no_speech_prob": 0.19928236305713654,
        "seek": 29540,
        "start": 304.59999999999997,
        "temperature": 0,
        "text": " two edited versions of, and one of them is not edited at all because it was my palm coding challenge",
        "tokens": [
          50824,
          732,
          23016,
          9606,
          295,
          11,
          293,
          472,
          295,
          552,
          307,
          406,
          23016,
          412,
          439,
          570,
          309,
          390,
          452,
          17018,
          17720,
          3430,
          51209
        ]
      },
      {
        "avg_logprob": -0.31597847990937283,
        "compression_ratio": 1.5401785714285714,
        "end": 314.59999999999997,
        "id": 68,
        "no_speech_prob": 0.19928236305713654,
        "seek": 29540,
        "start": 312.29999999999995,
        "temperature": 0,
        "text": " which took me a little over one hour.",
        "tokens": [
          51209,
          597,
          1890,
          385,
          257,
          707,
          670,
          472,
          1773,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.31597847990937283,
        "compression_ratio": 1.5401785714285714,
        "end": 322.59999999999997,
        "id": 69,
        "no_speech_prob": 0.19928236305713654,
        "seek": 29540,
        "start": 314.59999999999997,
        "temperature": 0,
        "text": " I see people, everybody's having sort of issues, but book of random numbers, please.",
        "tokens": [
          51324,
          286,
          536,
          561,
          11,
          2201,
          311,
          1419,
          1333,
          295,
          2663,
          11,
          457,
          1446,
          295,
          4974,
          3547,
          11,
          1767,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.28297722693717126,
        "compression_ratio": 1.6859903381642511,
        "end": 327.3,
        "id": 70,
        "no_speech_prob": 0.02556120790541172,
        "seek": 32260,
        "start": 322.8,
        "temperature": 0,
        "text": " I don't have my, unfortunately I don't have my sound effects today.",
        "tokens": [
          50374,
          286,
          500,
          380,
          362,
          452,
          11,
          7015,
          286,
          500,
          380,
          362,
          452,
          1626,
          5065,
          965,
          13,
          50599
        ]
      },
      {
        "avg_logprob": -0.28297722693717126,
        "compression_ratio": 1.6859903381642511,
        "end": 331.3,
        "id": 71,
        "no_speech_prob": 0.02556120790541172,
        "seek": 32260,
        "start": 327.3,
        "temperature": 0,
        "text": " Actually, while I get set up here for a second, I'm going to let you guys in on something.",
        "tokens": [
          50599,
          5135,
          11,
          1339,
          286,
          483,
          992,
          493,
          510,
          337,
          257,
          1150,
          11,
          286,
          478,
          516,
          281,
          718,
          291,
          1074,
          294,
          322,
          746,
          13,
          50799
        ]
      },
      {
        "avg_logprob": -0.28297722693717126,
        "compression_ratio": 1.6859903381642511,
        "end": 340.6,
        "id": 72,
        "no_speech_prob": 0.02556120790541172,
        "seek": 32260,
        "start": 331.3,
        "temperature": 0,
        "text": " I was noticing, I know that everyone is a big fan of the, I don't know that everyone is a big fan,",
        "tokens": [
          50799,
          286,
          390,
          21814,
          11,
          286,
          458,
          300,
          1518,
          307,
          257,
          955,
          3429,
          295,
          264,
          11,
          286,
          500,
          380,
          458,
          300,
          1518,
          307,
          257,
          955,
          3429,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.28297722693717126,
        "compression_ratio": 1.6859903381642511,
        "end": 342.6,
        "id": 73,
        "no_speech_prob": 0.02556120790541172,
        "seek": 32260,
        "start": 340.6,
        "temperature": 0,
        "text": " some people enjoy the This.song.",
        "tokens": [
          51264,
          512,
          561,
          2103,
          264,
          639,
          13,
          38762,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.28297722693717126,
        "compression_ratio": 1.6859903381642511,
        "end": 349.6,
        "id": 74,
        "no_speech_prob": 0.02556120790541172,
        "seek": 32260,
        "start": 342.6,
        "temperature": 0,
        "text": " There's, little known to you, there is a second This.song.",
        "tokens": [
          51364,
          821,
          311,
          11,
          707,
          2570,
          281,
          291,
          11,
          456,
          307,
          257,
          1150,
          639,
          13,
          38762,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 352.6,
        "id": 75,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 349.6,
        "temperature": 0,
        "text": " And actually, I don't know if this was actually the first This.song,",
        "tokens": [
          50364,
          400,
          767,
          11,
          286,
          500,
          380,
          458,
          498,
          341,
          390,
          767,
          264,
          700,
          639,
          13,
          38762,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 357.1,
        "id": 76,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 352.6,
        "temperature": 0,
        "text": " but F Looper also made, the Perlinois song that I often play by F Looper,",
        "tokens": [
          50514,
          457,
          479,
          6130,
          7192,
          611,
          1027,
          11,
          264,
          3026,
          75,
          15936,
          2153,
          300,
          286,
          2049,
          862,
          538,
          479,
          6130,
          7192,
          11,
          50739
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 362.6,
        "id": 77,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 357.1,
        "temperature": 0,
        "text": " F Looper also made a version of the This.song, which I will now play for you while I,",
        "tokens": [
          50739,
          479,
          6130,
          7192,
          611,
          1027,
          257,
          3037,
          295,
          264,
          639,
          13,
          38762,
          11,
          597,
          286,
          486,
          586,
          862,
          337,
          291,
          1339,
          286,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 366.6,
        "id": 78,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 362.6,
        "temperature": 0,
        "text": " oh, sorry, it's not at the beginning.",
        "tokens": [
          51014,
          1954,
          11,
          2597,
          11,
          309,
          311,
          406,
          412,
          264,
          2863,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 368.6,
        "id": 79,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 366.6,
        "temperature": 0,
        "text": " As always, I always forget the This.song.",
        "tokens": [
          51214,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          639,
          13,
          38762,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 370.6,
        "id": 80,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 368.6,
        "temperature": 0,
        "text": " While I get set up here.",
        "tokens": [
          51314,
          3987,
          286,
          483,
          992,
          493,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 373.6,
        "id": 81,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 370.6,
        "temperature": 0,
        "text": " This. This. This. This. The This.song.",
        "tokens": [
          51414,
          639,
          13,
          639,
          13,
          639,
          13,
          639,
          13,
          440,
          639,
          13,
          38762,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 374.6,
        "id": 82,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 373.6,
        "temperature": 0,
        "text": " Never forget the This.song.",
        "tokens": [
          51564,
          7344,
          2870,
          264,
          639,
          13,
          38762,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.33956566692268764,
        "compression_ratio": 1.8354430379746836,
        "end": 376.6,
        "id": 83,
        "no_speech_prob": 0.0636829361319542,
        "seek": 34960,
        "start": 374.6,
        "temperature": 0,
        "text": " Somebody compose that song for me.",
        "tokens": [
          51614,
          13463,
          35925,
          300,
          2153,
          337,
          385,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.26535264650980633,
        "compression_ratio": 0.6875,
        "end": 378.6,
        "id": 84,
        "no_speech_prob": 0.5256757736206055,
        "seek": 37660,
        "start": 377.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26535264650980633,
        "compression_ratio": 0.6875,
        "end": 403.6,
        "id": 85,
        "no_speech_prob": 0.5256757736206055,
        "seek": 37660,
        "start": 402.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -1.0669312795003256,
        "compression_ratio": 0.9466666666666667,
        "end": 408.6,
        "id": 86,
        "no_speech_prob": 0.02427280694246292,
        "seek": 40660,
        "start": 407.6,
        "temperature": 1,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -1.0669312795003256,
        "compression_ratio": 0.9466666666666667,
        "end": 431.6,
        "id": 87,
        "no_speech_prob": 0.02427280694246292,
        "seek": 40660,
        "start": 430.5,
        "temperature": 1,
        "text": " Alright, it's funny cause I can't really hear it.",
        "tokens": [
          51559,
          967,
          81,
          910,
          83,
          11,
          309,
          311,
          4074,
          3082,
          286,
          393,
          380,
          534,
          1568,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -1.0669312795003256,
        "compression_ratio": 0.9466666666666667,
        "end": 433.1,
        "id": 88,
        "no_speech_prob": 0.02427280694246292,
        "seek": 40660,
        "start": 431.6,
        "temperature": 1,
        "text": " Is it too loud?",
        "tokens": [
          51614,
          1119,
          309,
          886,
          6588,
          30,
          51689
        ]
      },
      {
        "avg_logprob": -0.2973071599410752,
        "compression_ratio": 1.3070866141732282,
        "end": 440.6,
        "id": 89,
        "no_speech_prob": 0.0041323765181005,
        "seek": 43660,
        "start": 436.6,
        "temperature": 0,
        "text": " I made it a little louder, but maybe I shouldn't have.",
        "tokens": [
          50364,
          286,
          1027,
          309,
          257,
          707,
          22717,
          11,
          457,
          1310,
          286,
          4659,
          380,
          362,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2973071599410752,
        "compression_ratio": 1.3070866141732282,
        "end": 458.6,
        "id": 90,
        "no_speech_prob": 0.0041323765181005,
        "seek": 43660,
        "start": 456.6,
        "temperature": 0,
        "text": " Alright, I think I'm ready.",
        "tokens": [
          51364,
          2798,
          11,
          286,
          519,
          286,
          478,
          1919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2973071599410752,
        "compression_ratio": 1.3070866141732282,
        "end": 461.6,
        "id": 91,
        "no_speech_prob": 0.0041323765181005,
        "seek": 43660,
        "start": 459.6,
        "temperature": 0,
        "text": " So, it's too quiet if anything.",
        "tokens": [
          51514,
          407,
          11,
          309,
          311,
          886,
          5677,
          498,
          1340,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2973071599410752,
        "compression_ratio": 1.3070866141732282,
        "end": 463.6,
        "id": 92,
        "no_speech_prob": 0.0041323765181005,
        "seek": 43660,
        "start": 461.6,
        "temperature": 0,
        "text": " Okay, so it's not too loud.",
        "tokens": [
          51614,
          1033,
          11,
          370,
          309,
          311,
          406,
          886,
          6588,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2973071599410752,
        "compression_ratio": 1.3070866141732282,
        "end": 464.6,
        "id": 93,
        "no_speech_prob": 0.0041323765181005,
        "seek": 43660,
        "start": 463.6,
        "temperature": 0,
        "text": " Louder, a little quiet.",
        "tokens": [
          51714,
          7272,
          1068,
          11,
          257,
          707,
          5677,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 469.6,
        "id": 94,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 464.6,
        "temperature": 0,
        "text": " Okay, so what am I going to do today in this short amount of time that I have?",
        "tokens": [
          50364,
          1033,
          11,
          370,
          437,
          669,
          286,
          516,
          281,
          360,
          965,
          294,
          341,
          2099,
          2372,
          295,
          565,
          300,
          286,
          362,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 471.6,
        "id": 95,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 469.6,
        "temperature": 0,
        "text": " I would like to do two things.",
        "tokens": [
          50614,
          286,
          576,
          411,
          281,
          360,
          732,
          721,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 474.6,
        "id": 96,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 471.6,
        "temperature": 0,
        "text": " One is, as a lot of you have requested and know,",
        "tokens": [
          50714,
          1485,
          307,
          11,
          382,
          257,
          688,
          295,
          291,
          362,
          16436,
          293,
          458,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 479.6,
        "id": 97,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 474.6,
        "temperature": 0,
        "text": " I am teaching a course here at ITP at NYU called Intelligence and Learning.",
        "tokens": [
          50864,
          286,
          669,
          4571,
          257,
          1164,
          510,
          412,
          6783,
          47,
          412,
          42682,
          1219,
          27274,
          293,
          15205,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 483.6,
        "id": 98,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 479.6,
        "temperature": 0,
        "text": " So, I'm going to do a, what I hope is just a 15,",
        "tokens": [
          51114,
          407,
          11,
          286,
          478,
          516,
          281,
          360,
          257,
          11,
          437,
          286,
          1454,
          307,
          445,
          257,
          2119,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 486.6,
        "id": 99,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 483.6,
        "temperature": 0,
        "text": " translated to three hours,",
        "tokens": [
          51314,
          16805,
          281,
          1045,
          2496,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 490.6,
        "id": 100,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 486.6,
        "temperature": 0,
        "text": " a 15 to 20 minute introduction to that course,",
        "tokens": [
          51464,
          257,
          2119,
          281,
          945,
          3456,
          9339,
          281,
          300,
          1164,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.20011662628691076,
        "compression_ratio": 1.6224899598393574,
        "end": 493.6,
        "id": 101,
        "no_speech_prob": 0.03306321054697037,
        "seek": 46460,
        "start": 490.6,
        "temperature": 0,
        "text": " what topics I'm going to cover in that course,",
        "tokens": [
          51664,
          437,
          8378,
          286,
          478,
          516,
          281,
          2060,
          294,
          300,
          1164,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.20732788509792752,
        "compression_ratio": 1.7333333333333334,
        "end": 496.6,
        "id": 102,
        "no_speech_prob": 0.0001420205953763798,
        "seek": 49360,
        "start": 493.6,
        "temperature": 0,
        "text": " what are my goals and sort of themes behind that course,",
        "tokens": [
          50364,
          437,
          366,
          452,
          5493,
          293,
          1333,
          295,
          13544,
          2261,
          300,
          1164,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20732788509792752,
        "compression_ratio": 1.7333333333333334,
        "end": 499.6,
        "id": 103,
        "no_speech_prob": 0.0001420205953763798,
        "seek": 49360,
        "start": 496.6,
        "temperature": 0,
        "text": " what are some of the references that I'm using for the course,",
        "tokens": [
          50514,
          437,
          366,
          512,
          295,
          264,
          15400,
          300,
          286,
          478,
          1228,
          337,
          264,
          1164,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.20732788509792752,
        "compression_ratio": 1.7333333333333334,
        "end": 503.6,
        "id": 104,
        "no_speech_prob": 0.0001420205953763798,
        "seek": 49360,
        "start": 499.6,
        "temperature": 0,
        "text": " and then, so I'm going to do that.",
        "tokens": [
          50664,
          293,
          550,
          11,
          370,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20732788509792752,
        "compression_ratio": 1.7333333333333334,
        "end": 513.6,
        "id": 105,
        "no_speech_prob": 0.0001420205953763798,
        "seek": 49360,
        "start": 503.6,
        "temperature": 0,
        "text": " And then after that, I am going to do a quick introduction to week one of the course,",
        "tokens": [
          50864,
          400,
          550,
          934,
          300,
          11,
          286,
          669,
          516,
          281,
          360,
          257,
          1702,
          9339,
          281,
          1243,
          472,
          295,
          264,
          1164,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.20732788509792752,
        "compression_ratio": 1.7333333333333334,
        "end": 518.6,
        "id": 106,
        "no_speech_prob": 0.0001420205953763798,
        "seek": 49360,
        "start": 513.6,
        "temperature": 0,
        "text": " which involves search, graph systems and search algorithms.",
        "tokens": [
          51364,
          597,
          11626,
          3164,
          11,
          4295,
          3652,
          293,
          3164,
          14642,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20732788509792752,
        "compression_ratio": 1.7333333333333334,
        "end": 521.6,
        "id": 107,
        "no_speech_prob": 0.0001420205953763798,
        "seek": 49360,
        "start": 518.6,
        "temperature": 0,
        "text": " And then I've already made videos on,",
        "tokens": [
          51614,
          400,
          550,
          286,
          600,
          1217,
          1027,
          2145,
          322,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 525.6,
        "id": 108,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 521.6,
        "temperature": 0,
        "text": " the next videos that would go in the sequence would be binary tree,",
        "tokens": [
          50364,
          264,
          958,
          2145,
          300,
          576,
          352,
          294,
          264,
          8310,
          576,
          312,
          17434,
          4230,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 531.6,
        "id": 109,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 525.6,
        "temperature": 0,
        "text": " maze generation, A-star, traveling salesperson, those videos.",
        "tokens": [
          50564,
          33032,
          5125,
          11,
          316,
          12,
          9710,
          11,
          9712,
          5763,
          10813,
          11,
          729,
          2145,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 535.6,
        "id": 110,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 531.6,
        "temperature": 0,
        "text": " And then I want to do one new video,",
        "tokens": [
          50864,
          400,
          550,
          286,
          528,
          281,
          360,
          472,
          777,
          960,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 538.6,
        "id": 111,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 535.6,
        "temperature": 0,
        "text": " one new tutorial for this material on breadth-first search.",
        "tokens": [
          51064,
          472,
          777,
          7073,
          337,
          341,
          2527,
          322,
          35862,
          12,
          29581,
          3164,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 541.6,
        "id": 112,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 538.6,
        "temperature": 0,
        "text": " And then if I have time, I'll do a quick five minute,",
        "tokens": [
          51214,
          400,
          550,
          498,
          286,
          362,
          565,
          11,
          286,
          603,
          360,
          257,
          1702,
          1732,
          3456,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 544.6,
        "id": 113,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 541.6,
        "temperature": 0,
        "text": " like here's some ideas for an exercise that you could do for next week.",
        "tokens": [
          51364,
          411,
          510,
          311,
          512,
          3487,
          337,
          364,
          5380,
          300,
          291,
          727,
          360,
          337,
          958,
          1243,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 548.6,
        "id": 114,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 544.6,
        "temperature": 0,
        "text": " So, that's my plan.",
        "tokens": [
          51514,
          407,
          11,
          300,
          311,
          452,
          1393,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22469278284021327,
        "compression_ratio": 1.5863453815261044,
        "end": 549.6,
        "id": 115,
        "no_speech_prob": 0.00017951878544408828,
        "seek": 52160,
        "start": 548.6,
        "temperature": 0,
        "text": " Let me come over here.",
        "tokens": [
          51714,
          961,
          385,
          808,
          670,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.8593721389770508,
        "compression_ratio": 0.38461538461538464,
        "end": 552.6,
        "id": 116,
        "no_speech_prob": 0.992251455783844,
        "seek": 55160,
        "start": 551.6,
        "temperature": 0.2,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16176906530407892,
        "compression_ratio": 1.4710144927536233,
        "end": 594.6,
        "id": 117,
        "no_speech_prob": 0.20163759589195251,
        "seek": 58160,
        "start": 582.6,
        "temperature": 0,
        "text": " Got it.",
        "tokens": [
          50414,
          5803,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16176906530407892,
        "compression_ratio": 1.4710144927536233,
        "end": 595.6,
        "id": 118,
        "no_speech_prob": 0.20163759589195251,
        "seek": 58160,
        "start": 594.6,
        "temperature": 0,
        "text": " Sound is off on the whiteboard.",
        "tokens": [
          51014,
          14673,
          307,
          766,
          322,
          264,
          2418,
          3787,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16176906530407892,
        "compression_ratio": 1.4710144927536233,
        "end": 597.6,
        "id": 119,
        "no_speech_prob": 0.20163759589195251,
        "seek": 58160,
        "start": 595.6,
        "temperature": 0,
        "text": " Thank you guys for letting me know that.",
        "tokens": [
          51064,
          1044,
          291,
          1074,
          337,
          8295,
          385,
          458,
          300,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16176906530407892,
        "compression_ratio": 1.4710144927536233,
        "end": 598.6,
        "id": 120,
        "no_speech_prob": 0.20163759589195251,
        "seek": 58160,
        "start": 597.6,
        "temperature": 0,
        "text": " I'm going to fix that.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          3191,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16176906530407892,
        "compression_ratio": 1.4710144927536233,
        "end": 603.6,
        "id": 121,
        "no_speech_prob": 0.20163759589195251,
        "seek": 58160,
        "start": 598.6,
        "temperature": 0,
        "text": " Hold on a second.",
        "tokens": [
          51214,
          6962,
          322,
          257,
          1150,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16176906530407892,
        "compression_ratio": 1.4710144927536233,
        "end": 605.6,
        "id": 122,
        "no_speech_prob": 0.20163759589195251,
        "seek": 58160,
        "start": 603.6,
        "temperature": 0,
        "text": " I have to switch to the whiteboard.",
        "tokens": [
          51464,
          286,
          362,
          281,
          3679,
          281,
          264,
          2418,
          3787,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16176906530407892,
        "compression_ratio": 1.4710144927536233,
        "end": 608.6,
        "id": 123,
        "no_speech_prob": 0.20163759589195251,
        "seek": 58160,
        "start": 605.6,
        "temperature": 0,
        "text": " It's going to take me 30 seconds to fix this.",
        "tokens": [
          51564,
          467,
          311,
          516,
          281,
          747,
          385,
          2217,
          3949,
          281,
          3191,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 610.6,
        "id": 124,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 608.6,
        "temperature": 0,
        "text": " The funny thing is, I bet you, I'll keep playing.",
        "tokens": [
          50364,
          440,
          4074,
          551,
          307,
          11,
          286,
          778,
          291,
          11,
          286,
          603,
          1066,
          2433,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 612.6,
        "id": 125,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 610.6,
        "temperature": 0,
        "text": " No, let me just fix this quickly.",
        "tokens": [
          50464,
          883,
          11,
          718,
          385,
          445,
          3191,
          341,
          2661,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 625.6,
        "id": 126,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 612.6,
        "temperature": 0,
        "text": " Test, test.",
        "tokens": [
          50564,
          9279,
          11,
          1500,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 626.6,
        "id": 127,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 625.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 630.6,
        "id": 128,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 626.6,
        "temperature": 0,
        "text": " So, you should have audio for me now in the whiteboard shot.",
        "tokens": [
          51264,
          407,
          11,
          291,
          820,
          362,
          6278,
          337,
          385,
          586,
          294,
          264,
          2418,
          3787,
          3347,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 631.6,
        "id": 129,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 630.6,
        "temperature": 0,
        "text": " Yes?",
        "tokens": [
          51464,
          1079,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 633.6,
        "id": 130,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 631.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 636.6,
        "id": 131,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 633.6,
        "temperature": 0,
        "text": " And then, still have audio here.",
        "tokens": [
          51614,
          400,
          550,
          11,
          920,
          362,
          6278,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2344659658578726,
        "compression_ratio": 1.3503184713375795,
        "end": 637.6,
        "id": 132,
        "no_speech_prob": 0.10667314380407333,
        "seek": 60860,
        "start": 636.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51764,
          1033,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 638.6,
        "id": 133,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 637.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 639.6,
        "id": 134,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 638.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 648.6,
        "id": 135,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 639.6,
        "temperature": 0,
        "text": " That should be good now.",
        "tokens": [
          50464,
          663,
          820,
          312,
          665,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 651.6,
        "id": 136,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 648.6,
        "temperature": 0,
        "text": " I'm afraid to take the top off of this because I'm going to knock it over.",
        "tokens": [
          50914,
          286,
          478,
          4638,
          281,
          747,
          264,
          1192,
          766,
          295,
          341,
          570,
          286,
          478,
          516,
          281,
          6728,
          309,
          670,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 657.6,
        "id": 137,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 651.6,
        "temperature": 0,
        "text": " It'll be a little bit easier to drink if I did.",
        "tokens": [
          51064,
          467,
          603,
          312,
          257,
          707,
          857,
          3571,
          281,
          2822,
          498,
          286,
          630,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 662.6,
        "id": 138,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 657.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 663.6,
        "id": 139,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 662.6,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51614,
          961,
          311,
          536,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19757488795689174,
        "compression_ratio": 1.4078947368421053,
        "end": 666.6,
        "id": 140,
        "no_speech_prob": 0.003538072807714343,
        "seek": 63760,
        "start": 663.6,
        "temperature": 0,
        "text": " Okay, so I've got to get moving here.",
        "tokens": [
          51664,
          1033,
          11,
          370,
          286,
          600,
          658,
          281,
          483,
          2684,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 668.6,
        "id": 141,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 666.6,
        "temperature": 0,
        "text": " I'm sure the cameras are about to shut off.",
        "tokens": [
          50364,
          286,
          478,
          988,
          264,
          8622,
          366,
          466,
          281,
          5309,
          766,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 669.6,
        "id": 142,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 668.6,
        "temperature": 0,
        "text": " I'm not about to.",
        "tokens": [
          50464,
          286,
          478,
          406,
          466,
          281,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 670.6,
        "id": 143,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 669.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 673.6,
        "id": 144,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 670.6,
        "temperature": 0,
        "text": " So, this is the syllabus for the course.",
        "tokens": [
          50564,
          407,
          11,
          341,
          307,
          264,
          48077,
          337,
          264,
          1164,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 677.6,
        "id": 145,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 673.6,
        "temperature": 0,
        "text": " Let me give this a little bit.",
        "tokens": [
          50714,
          961,
          385,
          976,
          341,
          257,
          707,
          857,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 686.6,
        "id": 146,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 677.6,
        "temperature": 0,
        "text": " Do this, I think.",
        "tokens": [
          50914,
          1144,
          341,
          11,
          286,
          519,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 687.6,
        "id": 147,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 686.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22559986616435804,
        "compression_ratio": 1.4539473684210527,
        "end": 693.6,
        "id": 148,
        "no_speech_prob": 0.43392133712768555,
        "seek": 66660,
        "start": 687.6,
        "temperature": 0,
        "text": " I think what I want to do is have this example available.",
        "tokens": [
          51414,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          307,
          362,
          341,
          1365,
          2435,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 696.6,
        "id": 149,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 694.6,
        "temperature": 0,
        "text": " I want to discuss this.",
        "tokens": [
          50414,
          286,
          528,
          281,
          2248,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 698.6,
        "id": 150,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 696.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 704.6,
        "id": 151,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 698.6,
        "temperature": 0,
        "text": " And then, I also want to have this.",
        "tokens": [
          50614,
          400,
          550,
          11,
          286,
          611,
          528,
          281,
          362,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 705.6,
        "id": 152,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 704.6,
        "temperature": 0,
        "text": " Nope, nope, nope, wrong thing.",
        "tokens": [
          50914,
          12172,
          11,
          23444,
          11,
          23444,
          11,
          2085,
          551,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 707.6,
        "id": 153,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 705.6,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          50964,
          4919,
          11,
          2201,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 712.6,
        "id": 154,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 707.6,
        "temperature": 0,
        "text": " Almost ready here.",
        "tokens": [
          51064,
          12627,
          1919,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 714.6,
        "id": 155,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 712.6,
        "temperature": 0,
        "text": " It's not really readable, is it?",
        "tokens": [
          51314,
          467,
          311,
          406,
          534,
          49857,
          11,
          307,
          309,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 717.6,
        "id": 156,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 714.6,
        "temperature": 0,
        "text": " I wish, well, it will be what it will be.",
        "tokens": [
          51414,
          286,
          3172,
          11,
          731,
          11,
          309,
          486,
          312,
          437,
          309,
          486,
          312,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 719.6,
        "id": 157,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 717.6,
        "temperature": 0,
        "text": " I will zoom in on things.",
        "tokens": [
          51564,
          286,
          486,
          8863,
          294,
          322,
          721,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22092072168986002,
        "compression_ratio": 1.5375722543352601,
        "end": 721.6,
        "id": 158,
        "no_speech_prob": 0.4570576548576355,
        "seek": 69360,
        "start": 719.6,
        "temperature": 0,
        "text": " So, that's going to have to do.",
        "tokens": [
          51664,
          407,
          11,
          300,
          311,
          516,
          281,
          362,
          281,
          360,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 722.6,
        "id": 159,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 721.6,
        "temperature": 0,
        "text": " And same for here.",
        "tokens": [
          50364,
          400,
          912,
          337,
          510,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 727.6,
        "id": 160,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 722.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 729.6,
        "id": 161,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 727.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 731.6,
        "id": 162,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 729.6,
        "temperature": 0,
        "text": " This is the real live stream experience.",
        "tokens": [
          50764,
          639,
          307,
          264,
          957,
          1621,
          4309,
          1752,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 732.6,
        "id": 163,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 731.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 734.6,
        "id": 164,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 732.6,
        "temperature": 0,
        "text": " Everything, the audio is working fine now, correct?",
        "tokens": [
          50914,
          5471,
          11,
          264,
          6278,
          307,
          1364,
          2489,
          586,
          11,
          3006,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 736.6,
        "id": 165,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 734.6,
        "temperature": 0,
        "text": " I'm seeing old messages, I think.",
        "tokens": [
          51014,
          286,
          478,
          2577,
          1331,
          7897,
          11,
          286,
          519,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 739.6,
        "id": 166,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 736.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 744.6,
        "id": 167,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 739.6,
        "temperature": 0,
        "text": " So, what's going to do, what's going to cover big O notation?",
        "tokens": [
          51264,
          407,
          11,
          437,
          311,
          516,
          281,
          360,
          11,
          437,
          311,
          516,
          281,
          2060,
          955,
          422,
          24657,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 745.6,
        "id": 168,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 744.6,
        "temperature": 0,
        "text": " I don't think I'm going to get to that today.",
        "tokens": [
          51514,
          286,
          500,
          380,
          519,
          286,
          478,
          516,
          281,
          483,
          281,
          300,
          965,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1987110742247931,
        "compression_ratio": 1.5851063829787233,
        "end": 749.6,
        "id": 169,
        "no_speech_prob": 0.04958753287792206,
        "seek": 72160,
        "start": 745.6,
        "temperature": 0,
        "text": " That's okay, though.",
        "tokens": [
          51564,
          663,
          311,
          1392,
          11,
          1673,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 751.6,
        "id": 170,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 749.6,
        "temperature": 0,
        "text": " Yeah, we're not doing all this today.",
        "tokens": [
          50364,
          865,
          11,
          321,
          434,
          406,
          884,
          439,
          341,
          965,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 755.6,
        "id": 171,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 751.6,
        "temperature": 0,
        "text": " But this is my schedule for the next seven weeks.",
        "tokens": [
          50464,
          583,
          341,
          307,
          452,
          7567,
          337,
          264,
          958,
          3407,
          3259,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 758.6,
        "id": 172,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 755.6,
        "temperature": 0,
        "text": " I'll probably be slower to get to it on the YouTube channel.",
        "tokens": [
          50664,
          286,
          603,
          1391,
          312,
          14009,
          281,
          483,
          281,
          309,
          322,
          264,
          3088,
          2269,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 762.6,
        "id": 173,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 758.6,
        "temperature": 0,
        "text": " So, maybe you might consider this the schedule over the next ten weeks or so.",
        "tokens": [
          50814,
          407,
          11,
          1310,
          291,
          1062,
          1949,
          341,
          264,
          7567,
          670,
          264,
          958,
          2064,
          3259,
          420,
          370,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 764.6,
        "id": 174,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 762.6,
        "temperature": 0,
        "text": " But I'm going to do my best.",
        "tokens": [
          51014,
          583,
          286,
          478,
          516,
          281,
          360,
          452,
          1151,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 767.6,
        "id": 175,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 764.6,
        "temperature": 0,
        "text": " But this is my schedule in preparing materials and information.",
        "tokens": [
          51114,
          583,
          341,
          307,
          452,
          7567,
          294,
          10075,
          5319,
          293,
          1589,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 771.6,
        "id": 176,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 767.6,
        "temperature": 0,
        "text": " So, if you want to follow along with this GitHub repository, there will be stuff each week.",
        "tokens": [
          51264,
          407,
          11,
          498,
          291,
          528,
          281,
          1524,
          2051,
          365,
          341,
          23331,
          25841,
          11,
          456,
          486,
          312,
          1507,
          1184,
          1243,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 773.6,
        "id": 177,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 771.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 777.6,
        "id": 178,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 773.6,
        "temperature": 0,
        "text": " So, boy, one of these days.",
        "tokens": [
          51564,
          407,
          11,
          3237,
          11,
          472,
          295,
          613,
          1708,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20268265169058272,
        "compression_ratio": 1.6830985915492958,
        "end": 778.6,
        "id": 179,
        "no_speech_prob": 0.19679974019527435,
        "seek": 74960,
        "start": 777.6,
        "temperature": 0,
        "text": " You know what I was going to do?",
        "tokens": [
          51764,
          509,
          458,
          437,
          286,
          390,
          516,
          281,
          360,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 782.6,
        "id": 180,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 778.6,
        "temperature": 0,
        "text": " I had this idea that I would prepare slides for this quick introduction.",
        "tokens": [
          50364,
          286,
          632,
          341,
          1558,
          300,
          286,
          576,
          5940,
          9788,
          337,
          341,
          1702,
          9339,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 786.6,
        "id": 181,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 782.6,
        "temperature": 0,
        "text": " And then I'd be organized and I'd have, like, a plan for it.",
        "tokens": [
          50564,
          400,
          550,
          286,
          1116,
          312,
          9983,
          293,
          286,
          1116,
          362,
          11,
          411,
          11,
          257,
          1393,
          337,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 790.6,
        "id": 182,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 786.6,
        "temperature": 0,
        "text": " Oh, well, next time.",
        "tokens": [
          50764,
          876,
          11,
          731,
          11,
          958,
          565,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 792.6,
        "id": 183,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 790.6,
        "temperature": 0,
        "text": " You know those courses that are on Coursera?",
        "tokens": [
          50964,
          509,
          458,
          729,
          7712,
          300,
          366,
          322,
          383,
          5067,
          1663,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 793.6,
        "id": 184,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 792.6,
        "temperature": 0,
        "text": " They're very organized.",
        "tokens": [
          51064,
          814,
          434,
          588,
          9983,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 795.6,
        "id": 185,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 793.6,
        "temperature": 0,
        "text": " I highly recommend them.",
        "tokens": [
          51114,
          286,
          5405,
          2748,
          552,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 797.6,
        "id": 186,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 795.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17345319191614786,
        "compression_ratio": 1.4666666666666666,
        "end": 799.6,
        "id": 187,
        "no_speech_prob": 0.0055547659285366535,
        "seek": 77860,
        "start": 797.6,
        "temperature": 0,
        "text": " So, here we're going to do, I'm going to get started.",
        "tokens": [
          51314,
          407,
          11,
          510,
          321,
          434,
          516,
          281,
          360,
          11,
          286,
          478,
          516,
          281,
          483,
          1409,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22068886134935461,
        "compression_ratio": 1.4081632653061225,
        "end": 812.6,
        "id": 188,
        "no_speech_prob": 0.01771126314997673,
        "seek": 79960,
        "start": 800.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22068886134935461,
        "compression_ratio": 1.4081632653061225,
        "end": 816.6,
        "id": 189,
        "no_speech_prob": 0.01771126314997673,
        "seek": 79960,
        "start": 812.6,
        "temperature": 0,
        "text": " I just pressed some buttons on the cameras to see if that happened.",
        "tokens": [
          51014,
          286,
          445,
          17355,
          512,
          9905,
          322,
          264,
          8622,
          281,
          536,
          498,
          300,
          2011,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22068886134935461,
        "compression_ratio": 1.4081632653061225,
        "end": 818.6,
        "id": 190,
        "no_speech_prob": 0.01771126314997673,
        "seek": 79960,
        "start": 816.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22068886134935461,
        "compression_ratio": 1.4081632653061225,
        "end": 821.6,
        "id": 191,
        "no_speech_prob": 0.01771126314997673,
        "seek": 79960,
        "start": 818.6,
        "temperature": 0,
        "text": " I don't know what the best thing ‑‑ I guess I'm going to leave this right here.",
        "tokens": [
          51314,
          286,
          500,
          380,
          458,
          437,
          264,
          1151,
          551,
          220,
          27392,
          27392,
          286,
          2041,
          286,
          478,
          516,
          281,
          1856,
          341,
          558,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22068886134935461,
        "compression_ratio": 1.4081632653061225,
        "end": 823.6,
        "id": 192,
        "no_speech_prob": 0.01771126314997673,
        "seek": 79960,
        "start": 821.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22068886134935461,
        "compression_ratio": 1.4081632653061225,
        "end": 824.6,
        "id": 193,
        "no_speech_prob": 0.01771126314997673,
        "seek": 79960,
        "start": 823.6,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51564,
          1692,
          321,
          352,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22068886134935461,
        "compression_ratio": 1.4081632653061225,
        "end": 825.6,
        "id": 194,
        "no_speech_prob": 0.01771126314997673,
        "seek": 79960,
        "start": 824.6,
        "temperature": 0,
        "text": " I'm going to get started.",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          483,
          1409,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.199350288446001,
        "compression_ratio": 1.6849315068493151,
        "end": 832.6,
        "id": 195,
        "no_speech_prob": 0.8242408037185669,
        "seek": 82560,
        "start": 826.6,
        "temperature": 0,
        "text": " Hey, so those of you in the chat, if anybody wants to do me some help,",
        "tokens": [
          50414,
          1911,
          11,
          370,
          729,
          295,
          291,
          294,
          264,
          5081,
          11,
          498,
          4472,
          2738,
          281,
          360,
          385,
          512,
          854,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.199350288446001,
        "compression_ratio": 1.6849315068493151,
        "end": 835.6,
        "id": 196,
        "no_speech_prob": 0.8242408037185669,
        "seek": 82560,
        "start": 832.6,
        "temperature": 0,
        "text": " oh, this is not going well.",
        "tokens": [
          50714,
          1954,
          11,
          341,
          307,
          406,
          516,
          731,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.199350288446001,
        "compression_ratio": 1.6849315068493151,
        "end": 839.6,
        "id": 197,
        "no_speech_prob": 0.8242408037185669,
        "seek": 82560,
        "start": 835.6,
        "temperature": 0,
        "text": " If anybody wants to help me out a little bit, one thing you could do is kind of just keep track of the time.",
        "tokens": [
          50864,
          759,
          4472,
          2738,
          281,
          854,
          385,
          484,
          257,
          707,
          857,
          11,
          472,
          551,
          291,
          727,
          360,
          307,
          733,
          295,
          445,
          1066,
          2837,
          295,
          264,
          565,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.199350288446001,
        "compression_ratio": 1.6849315068493151,
        "end": 841.6,
        "id": 198,
        "no_speech_prob": 0.8242408037185669,
        "seek": 82560,
        "start": 839.6,
        "temperature": 0,
        "text": " It's something that I don't do a very good job of.",
        "tokens": [
          51064,
          467,
          311,
          746,
          300,
          286,
          500,
          380,
          360,
          257,
          588,
          665,
          1691,
          295,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.199350288446001,
        "compression_ratio": 1.6849315068493151,
        "end": 845.6,
        "id": 199,
        "no_speech_prob": 0.8242408037185669,
        "seek": 82560,
        "start": 841.6,
        "temperature": 0,
        "text": " I prefer for my videos to be between 20 and 30 minutes long.",
        "tokens": [
          51164,
          286,
          4382,
          337,
          452,
          2145,
          281,
          312,
          1296,
          945,
          293,
          2217,
          2077,
          938,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.199350288446001,
        "compression_ratio": 1.6849315068493151,
        "end": 849.6,
        "id": 200,
        "no_speech_prob": 0.8242408037185669,
        "seek": 82560,
        "start": 845.6,
        "temperature": 0,
        "text": " And then when I have a longer topic, to break them into parts.",
        "tokens": [
          51364,
          400,
          550,
          562,
          286,
          362,
          257,
          2854,
          4829,
          11,
          281,
          1821,
          552,
          666,
          3166,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.199350288446001,
        "compression_ratio": 1.6849315068493151,
        "end": 853.6,
        "id": 201,
        "no_speech_prob": 0.8242408037185669,
        "seek": 82560,
        "start": 849.6,
        "temperature": 0,
        "text": " So, you know, it's a little hard to keep track because sometimes I'll pause and then I'll edit out the pause.",
        "tokens": [
          51564,
          407,
          11,
          291,
          458,
          11,
          309,
          311,
          257,
          707,
          1152,
          281,
          1066,
          2837,
          570,
          2171,
          286,
          603,
          10465,
          293,
          550,
          286,
          603,
          8129,
          484,
          264,
          10465,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 855.6,
        "id": 202,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 853.6,
        "temperature": 0,
        "text": " But, you know, you might have a sense of that.",
        "tokens": [
          50364,
          583,
          11,
          291,
          458,
          11,
          291,
          1062,
          362,
          257,
          2020,
          295,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 865.6,
        "id": 203,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 855.6,
        "temperature": 0,
        "text": " If anybody wants to kind of send me a little nudge, hey, it's been 20 minutes, let me know.",
        "tokens": [
          50464,
          759,
          4472,
          2738,
          281,
          733,
          295,
          2845,
          385,
          257,
          707,
          297,
          16032,
          11,
          4177,
          11,
          309,
          311,
          668,
          945,
          2077,
          11,
          718,
          385,
          458,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 867.6,
        "id": 204,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 865.6,
        "temperature": 0,
        "text": " If only I had a JavaScript timer.",
        "tokens": [
          50964,
          759,
          787,
          286,
          632,
          257,
          15778,
          19247,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 871.6,
        "id": 205,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 867.6,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51064,
          865,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 876.6,
        "id": 206,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 871.6,
        "temperature": 0,
        "text": " If only I had a timer or some sort of computing device that could keep track of the time.",
        "tokens": [
          51264,
          759,
          787,
          286,
          632,
          257,
          19247,
          420,
          512,
          1333,
          295,
          15866,
          4302,
          300,
          727,
          1066,
          2837,
          295,
          264,
          565,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 878.6,
        "id": 207,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 876.6,
        "temperature": 0,
        "text": " I'm just ‑‑ I'm not ‑‑ okay.",
        "tokens": [
          51514,
          286,
          478,
          445,
          45217,
          286,
          478,
          406,
          45217,
          1392,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 879.6,
        "id": 208,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 878.6,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51614,
          1692,
          321,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21457705130943885,
        "compression_ratio": 1.4615384615384615,
        "end": 880.6,
        "id": 209,
        "no_speech_prob": 0.0015011728974059224,
        "seek": 85360,
        "start": 879.6,
        "temperature": 0,
        "text": " 4.15.",
        "tokens": [
          51664,
          1017,
          13,
          5211,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23734266493055556,
        "compression_ratio": 1.3970588235294117,
        "end": 884.6,
        "id": 210,
        "no_speech_prob": 0.07476204633712769,
        "seek": 88060,
        "start": 881.6,
        "temperature": 0,
        "text": " I do not need to look at my phone.",
        "tokens": [
          50414,
          286,
          360,
          406,
          643,
          281,
          574,
          412,
          452,
          2593,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23734266493055556,
        "compression_ratio": 1.3970588235294117,
        "end": 886.6,
        "id": 211,
        "no_speech_prob": 0.07476204633712769,
        "seek": 88060,
        "start": 884.6,
        "temperature": 0,
        "text": " Too many random unnecessary alerts.",
        "tokens": [
          50564,
          11395,
          867,
          4974,
          19350,
          28061,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23734266493055556,
        "compression_ratio": 1.3970588235294117,
        "end": 888.6,
        "id": 212,
        "no_speech_prob": 0.07476204633712769,
        "seek": 88060,
        "start": 886.6,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50664,
          1692,
          321,
          352,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23734266493055556,
        "compression_ratio": 1.3970588235294117,
        "end": 902.6,
        "id": 213,
        "no_speech_prob": 0.07476204633712769,
        "seek": 88060,
        "start": 888.6,
        "temperature": 0,
        "text": " Hello, welcome to the first video in a new course, I don't know, series, set of videos that I am here, me, Dan Shiffman,",
        "tokens": [
          50764,
          2425,
          11,
          2928,
          281,
          264,
          700,
          960,
          294,
          257,
          777,
          1164,
          11,
          286,
          500,
          380,
          458,
          11,
          2638,
          11,
          992,
          295,
          2145,
          300,
          286,
          669,
          510,
          11,
          385,
          11,
          3394,
          1160,
          3661,
          1601,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.23734266493055556,
        "compression_ratio": 1.3970588235294117,
        "end": 905.6,
        "id": 214,
        "no_speech_prob": 0.07476204633712769,
        "seek": 88060,
        "start": 902.6,
        "temperature": 0,
        "text": " presenting to you on my YouTube channel, The Coding Dream.",
        "tokens": [
          51464,
          15578,
          281,
          291,
          322,
          452,
          3088,
          2269,
          11,
          440,
          383,
          8616,
          12105,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23734266493055556,
        "compression_ratio": 1.3970588235294117,
        "end": 906.6,
        "id": 215,
        "no_speech_prob": 0.07476204633712769,
        "seek": 88060,
        "start": 905.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23734266493055556,
        "compression_ratio": 1.3970588235294117,
        "end": 907.6,
        "id": 216,
        "no_speech_prob": 0.07476204633712769,
        "seek": 88060,
        "start": 906.6,
        "temperature": 0,
        "text": " So what is this?",
        "tokens": [
          51664,
          407,
          437,
          307,
          341,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.22169438804068217,
        "compression_ratio": 1.626865671641791,
        "end": 914.6,
        "id": 217,
        "no_speech_prob": 0.5543946027755737,
        "seek": 90760,
        "start": 908.6,
        "temperature": 0,
        "text": " You might be aware, you might remember me from such videos as The Nature of Code.",
        "tokens": [
          50414,
          509,
          1062,
          312,
          3650,
          11,
          291,
          1062,
          1604,
          385,
          490,
          1270,
          2145,
          382,
          440,
          20159,
          295,
          15549,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22169438804068217,
        "compression_ratio": 1.626865671641791,
        "end": 916.6,
        "id": 218,
        "no_speech_prob": 0.5543946027755737,
        "seek": 90760,
        "start": 914.6,
        "temperature": 0,
        "text": " I have a playlist of videos.",
        "tokens": [
          50714,
          286,
          362,
          257,
          16788,
          295,
          2145,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22169438804068217,
        "compression_ratio": 1.626865671641791,
        "end": 919.6,
        "id": 219,
        "no_speech_prob": 0.5543946027755737,
        "seek": 90760,
        "start": 916.6,
        "temperature": 0,
        "text": " Most of these videos were recorded probably several years ago.",
        "tokens": [
          50814,
          4534,
          295,
          613,
          2145,
          645,
          8287,
          1391,
          2940,
          924,
          2057,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22169438804068217,
        "compression_ratio": 1.626865671641791,
        "end": 926.6,
        "id": 220,
        "no_speech_prob": 0.5543946027755737,
        "seek": 90760,
        "start": 919.6,
        "temperature": 0,
        "text": " They cover ‑‑ I'm going to zoom in here, all of these topics one through eight.",
        "tokens": [
          50964,
          814,
          2060,
          45217,
          286,
          478,
          516,
          281,
          8863,
          294,
          510,
          11,
          439,
          295,
          613,
          8378,
          472,
          807,
          3180,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22169438804068217,
        "compression_ratio": 1.626865671641791,
        "end": 930.6,
        "id": 221,
        "no_speech_prob": 0.5543946027755737,
        "seek": 90760,
        "start": 926.6,
        "temperature": 0,
        "text": " And I have a book which covers all of these topics one through eight.",
        "tokens": [
          51314,
          400,
          286,
          362,
          257,
          1446,
          597,
          10538,
          439,
          295,
          613,
          8378,
          472,
          807,
          3180,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 938.6,
        "id": 222,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 930.6,
        "temperature": 0,
        "text": " I have been teaching a class about this stuff for a bunch of years, many years, almost like seven or eight years, in fact.",
        "tokens": [
          50364,
          286,
          362,
          668,
          4571,
          257,
          1508,
          466,
          341,
          1507,
          337,
          257,
          3840,
          295,
          924,
          11,
          867,
          924,
          11,
          1920,
          411,
          3407,
          420,
          3180,
          924,
          11,
          294,
          1186,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 943.6,
        "id": 223,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 938.6,
        "temperature": 0,
        "text": " And so this year I am trying something new with this course and therefore also on this YouTube channel.",
        "tokens": [
          50764,
          400,
          370,
          341,
          1064,
          286,
          669,
          1382,
          746,
          777,
          365,
          341,
          1164,
          293,
          4412,
          611,
          322,
          341,
          3088,
          2269,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 946.6,
        "id": 224,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 943.6,
        "temperature": 0,
        "text": " Now, what is this new thing that I'm trying?",
        "tokens": [
          51014,
          823,
          11,
          437,
          307,
          341,
          777,
          551,
          300,
          286,
          478,
          1382,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 952.6,
        "id": 225,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 946.6,
        "temperature": 0,
        "text": " What always happens when I teach this course is if it's a full semester course at a kind of university‑like place,",
        "tokens": [
          51164,
          708,
          1009,
          2314,
          562,
          286,
          2924,
          341,
          1164,
          307,
          498,
          309,
          311,
          257,
          1577,
          11894,
          1164,
          412,
          257,
          733,
          295,
          5454,
          27392,
          4092,
          1081,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 955.6,
        "id": 226,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 952.6,
        "temperature": 0,
        "text": " there are ‑‑ where am I?",
        "tokens": [
          51464,
          456,
          366,
          45217,
          689,
          669,
          286,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 956.6,
        "id": 227,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 955.6,
        "temperature": 0,
        "text": " Over here.",
        "tokens": [
          51614,
          4886,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 957.6,
        "id": 228,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 956.6,
        "temperature": 0,
        "text": " There are these ten topics.",
        "tokens": [
          51664,
          821,
          366,
          613,
          2064,
          8378,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 958.6,
        "id": 229,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 957.6,
        "temperature": 0,
        "text": " Oh, you can't see the bottom.",
        "tokens": [
          51714,
          876,
          11,
          291,
          393,
          380,
          536,
          264,
          2767,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23003807352549993,
        "compression_ratio": 1.6402640264026402,
        "end": 959.6,
        "id": 230,
        "no_speech_prob": 0.17104148864746094,
        "seek": 93060,
        "start": 958.6,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51764,
          961,
          311,
          536,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2056144129845404,
        "compression_ratio": 1.7083333333333333,
        "end": 960.6,
        "id": 231,
        "no_speech_prob": 0.00006814789958298206,
        "seek": 95960,
        "start": 959.6,
        "temperature": 0,
        "text": " I'm not zoomed properly.",
        "tokens": [
          50364,
          286,
          478,
          406,
          8863,
          292,
          6108,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2056144129845404,
        "compression_ratio": 1.7083333333333333,
        "end": 961.6,
        "id": 232,
        "no_speech_prob": 0.00006814789958298206,
        "seek": 95960,
        "start": 960.6,
        "temperature": 0,
        "text": " Okay, there we go.",
        "tokens": [
          50414,
          1033,
          11,
          456,
          321,
          352,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2056144129845404,
        "compression_ratio": 1.7083333333333333,
        "end": 963.6,
        "id": 233,
        "no_speech_prob": 0.00006814789958298206,
        "seek": 95960,
        "start": 961.6,
        "temperature": 0,
        "text": " There are these ten topics.",
        "tokens": [
          50464,
          821,
          366,
          613,
          2064,
          8378,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2056144129845404,
        "compression_ratio": 1.7083333333333333,
        "end": 972.6,
        "id": 234,
        "no_speech_prob": 0.00006814789958298206,
        "seek": 95960,
        "start": 963.6,
        "temperature": 0,
        "text": " And what happens is, you know, this here, the first half of it, is really about physics simulation, animation, moving things on the screen,",
        "tokens": [
          50564,
          400,
          437,
          2314,
          307,
          11,
          291,
          458,
          11,
          341,
          510,
          11,
          264,
          700,
          1922,
          295,
          309,
          11,
          307,
          534,
          466,
          10649,
          16575,
          11,
          9603,
          11,
          2684,
          721,
          322,
          264,
          2568,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.2056144129845404,
        "compression_ratio": 1.7083333333333333,
        "end": 976.6,
        "id": 235,
        "no_speech_prob": 0.00006814789958298206,
        "seek": 95960,
        "start": 972.6,
        "temperature": 0,
        "text": " and all the kind of stuff you can do with that.",
        "tokens": [
          51014,
          293,
          439,
          264,
          733,
          295,
          1507,
          291,
          393,
          360,
          365,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2056144129845404,
        "compression_ratio": 1.7083333333333333,
        "end": 980.6,
        "id": 236,
        "no_speech_prob": 0.00006814789958298206,
        "seek": 95960,
        "start": 976.6,
        "temperature": 0,
        "text": " And by the time we get to this, people are on their way and they've been overloaded.",
        "tokens": [
          51214,
          400,
          538,
          264,
          565,
          321,
          483,
          281,
          341,
          11,
          561,
          366,
          322,
          641,
          636,
          293,
          436,
          600,
          668,
          28777,
          292,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2056144129845404,
        "compression_ratio": 1.7083333333333333,
        "end": 987.6,
        "id": 237,
        "no_speech_prob": 0.00006814789958298206,
        "seek": 95960,
        "start": 980.6,
        "temperature": 0,
        "text": " They're trying to learn all this stuff that what's here in nine and ten, chapters nine and ten, gets lost.",
        "tokens": [
          51414,
          814,
          434,
          1382,
          281,
          1466,
          439,
          341,
          1507,
          300,
          437,
          311,
          510,
          294,
          4949,
          293,
          2064,
          11,
          20013,
          4949,
          293,
          2064,
          11,
          2170,
          2731,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18717688434528854,
        "compression_ratio": 1.7114624505928853,
        "end": 997.6,
        "id": 238,
        "no_speech_prob": 0.0010322161251679063,
        "seek": 98760,
        "start": 987.6,
        "temperature": 0,
        "text": " So what I'm doing this year and starting right now is I would like to take what's in this book here, nine and ten, chapters nine and ten,",
        "tokens": [
          50364,
          407,
          437,
          286,
          478,
          884,
          341,
          1064,
          293,
          2891,
          558,
          586,
          307,
          286,
          576,
          411,
          281,
          747,
          437,
          311,
          294,
          341,
          1446,
          510,
          11,
          4949,
          293,
          2064,
          11,
          20013,
          4949,
          293,
          2064,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.18717688434528854,
        "compression_ratio": 1.7114624505928853,
        "end": 1006.6,
        "id": 239,
        "no_speech_prob": 0.0010322161251679063,
        "seek": 98760,
        "start": 997.6,
        "temperature": 0,
        "text": " and expand the material out to something that would be several, you know, many sessions about seven, five or six or seven or eight, I have no idea,",
        "tokens": [
          50864,
          293,
          5268,
          264,
          2527,
          484,
          281,
          746,
          300,
          576,
          312,
          2940,
          11,
          291,
          458,
          11,
          867,
          11081,
          466,
          3407,
          11,
          1732,
          420,
          2309,
          420,
          3407,
          420,
          3180,
          11,
          286,
          362,
          572,
          1558,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.18717688434528854,
        "compression_ratio": 1.7114624505928853,
        "end": 1014.6,
        "id": 240,
        "no_speech_prob": 0.0010322161251679063,
        "seek": 98760,
        "start": 1006.6,
        "temperature": 0,
        "text": " some amount of sessions of content where I take a closer look at topics related to, and here's the title of this course,",
        "tokens": [
          51314,
          512,
          2372,
          295,
          11081,
          295,
          2701,
          689,
          286,
          747,
          257,
          4966,
          574,
          412,
          8378,
          4077,
          281,
          11,
          293,
          510,
          311,
          264,
          4876,
          295,
          341,
          1164,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.18717688434528854,
        "compression_ratio": 1.7114624505928853,
        "end": 1016.6,
        "id": 241,
        "no_speech_prob": 0.0010322161251679063,
        "seek": 98760,
        "start": 1014.6,
        "temperature": 0,
        "text": " intelligence and learning.",
        "tokens": [
          51714,
          7599,
          293,
          2539,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.25538590269268685,
        "compression_ratio": 1.7510729613733906,
        "end": 1019.6,
        "id": 242,
        "no_speech_prob": 0.0023595881648361683,
        "seek": 101660,
        "start": 1016.6,
        "temperature": 0,
        "text": " So I'm going to come over here and I'm going to write that down.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          808,
          670,
          510,
          293,
          286,
          478,
          516,
          281,
          2464,
          300,
          760,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25538590269268685,
        "compression_ratio": 1.7510729613733906,
        "end": 1027.6,
        "id": 243,
        "no_speech_prob": 0.0023595881648361683,
        "seek": 101660,
        "start": 1019.6,
        "temperature": 0,
        "text": " This is like what people who are teachers, I've been watching some like open courseware, you know, you have a big chalkboard and then you just like make a point and you write it down.",
        "tokens": [
          50514,
          639,
          307,
          411,
          437,
          561,
          567,
          366,
          6023,
          11,
          286,
          600,
          668,
          1976,
          512,
          411,
          1269,
          1164,
          3039,
          11,
          291,
          458,
          11,
          291,
          362,
          257,
          955,
          28660,
          3787,
          293,
          550,
          291,
          445,
          411,
          652,
          257,
          935,
          293,
          291,
          2464,
          309,
          760,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25538590269268685,
        "compression_ratio": 1.7510729613733906,
        "end": 1028.6,
        "id": 244,
        "no_speech_prob": 0.0023595881648361683,
        "seek": 101660,
        "start": 1027.6,
        "temperature": 0,
        "text": " So I'm going to do that.",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.25538590269268685,
        "compression_ratio": 1.7510729613733906,
        "end": 1033.6,
        "id": 245,
        "no_speech_prob": 0.0023595881648361683,
        "seek": 101660,
        "start": 1028.6,
        "temperature": 0,
        "text": " Intelligence and learning.",
        "tokens": [
          50964,
          27274,
          293,
          2539,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25538590269268685,
        "compression_ratio": 1.7510729613733906,
        "end": 1044.6,
        "id": 246,
        "no_speech_prob": 0.0023595881648361683,
        "seek": 101660,
        "start": 1033.6,
        "temperature": 0,
        "text": " Now, I am specific, first of all, I'm specifically not calling this a course, like artificial intelligence.",
        "tokens": [
          51214,
          823,
          11,
          286,
          669,
          2685,
          11,
          700,
          295,
          439,
          11,
          286,
          478,
          4682,
          406,
          5141,
          341,
          257,
          1164,
          11,
          411,
          11677,
          7599,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1755916518394393,
        "compression_ratio": 1.7677725118483412,
        "end": 1053.6,
        "id": 247,
        "no_speech_prob": 0.004331367556005716,
        "seek": 104460,
        "start": 1045.6,
        "temperature": 0,
        "text": " Nor am I calling this a course, like introduction to machine learning.",
        "tokens": [
          50414,
          6966,
          669,
          286,
          5141,
          341,
          257,
          1164,
          11,
          411,
          9339,
          281,
          3479,
          2539,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1755916518394393,
        "compression_ratio": 1.7677725118483412,
        "end": 1060.6,
        "id": 248,
        "no_speech_prob": 0.004331367556005716,
        "seek": 104460,
        "start": 1053.6,
        "temperature": 0,
        "text": " Nor am I saying it's a course called, say, introduction to deep learning.",
        "tokens": [
          50814,
          6966,
          669,
          286,
          1566,
          309,
          311,
          257,
          1164,
          1219,
          11,
          584,
          11,
          9339,
          281,
          2452,
          2539,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1755916518394393,
        "compression_ratio": 1.7677725118483412,
        "end": 1063.6,
        "id": 249,
        "no_speech_prob": 0.004331367556005716,
        "seek": 104460,
        "start": 1060.6,
        "temperature": 0,
        "text": " So what's one reason why I'm not calling it that?",
        "tokens": [
          51164,
          407,
          437,
          311,
          472,
          1778,
          983,
          286,
          478,
          406,
          5141,
          309,
          300,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.1755916518394393,
        "compression_ratio": 1.7677725118483412,
        "end": 1065.6,
        "id": 250,
        "no_speech_prob": 0.004331367556005716,
        "seek": 104460,
        "start": 1063.6,
        "temperature": 0,
        "text": " Well, first of all, I'm afraid of all these things.",
        "tokens": [
          51314,
          1042,
          11,
          700,
          295,
          439,
          11,
          286,
          478,
          4638,
          295,
          439,
          613,
          721,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1755916518394393,
        "compression_ratio": 1.7677725118483412,
        "end": 1071.6,
        "id": 251,
        "no_speech_prob": 0.004331367556005716,
        "seek": 104460,
        "start": 1065.6,
        "temperature": 0,
        "text": " So I feel like if I call it, this is a course on artificial intelligence or machine learning, that's a little bit scary to me.",
        "tokens": [
          51414,
          407,
          286,
          841,
          411,
          498,
          286,
          818,
          309,
          11,
          341,
          307,
          257,
          1164,
          322,
          11677,
          7599,
          420,
          3479,
          2539,
          11,
          300,
          311,
          257,
          707,
          857,
          6958,
          281,
          385,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25802227488735263,
        "compression_ratio": 1.5220125786163523,
        "end": 1081.6,
        "id": 252,
        "no_speech_prob": 0.046720027923583984,
        "seek": 107160,
        "start": 1072.6,
        "temperature": 0,
        "text": " You know, but also I want to make the point in this course and that about, let me ask you a question for a second.",
        "tokens": [
          50414,
          509,
          458,
          11,
          457,
          611,
          286,
          528,
          281,
          652,
          264,
          935,
          294,
          341,
          1164,
          293,
          300,
          466,
          11,
          718,
          385,
          1029,
          291,
          257,
          1168,
          337,
          257,
          1150,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.25802227488735263,
        "compression_ratio": 1.5220125786163523,
        "end": 1091.6,
        "id": 253,
        "no_speech_prob": 0.046720027923583984,
        "seek": 107160,
        "start": 1081.6,
        "temperature": 0,
        "text": " What's the difference between a computer that is intelligent or a computer that appears intelligent or has a piece of software?",
        "tokens": [
          50864,
          708,
          311,
          264,
          2649,
          1296,
          257,
          3820,
          300,
          307,
          13232,
          420,
          257,
          3820,
          300,
          7038,
          13232,
          420,
          575,
          257,
          2522,
          295,
          4722,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.20120794122869318,
        "compression_ratio": 1.6240601503759398,
        "end": 1092.6,
        "id": 254,
        "no_speech_prob": 0.06008361652493477,
        "seek": 109160,
        "start": 1091.6,
        "temperature": 0,
        "text": " Let's say it's a piece of software.",
        "tokens": [
          50364,
          961,
          311,
          584,
          309,
          311,
          257,
          2522,
          295,
          4722,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20120794122869318,
        "compression_ratio": 1.6240601503759398,
        "end": 1102.6,
        "id": 255,
        "no_speech_prob": 0.06008361652493477,
        "seek": 109160,
        "start": 1092.6,
        "temperature": 0,
        "text": " What's the difference between a piece of software that is intelligent versus a piece of software that emanates, that gives off, that has the illusion of intelligence?",
        "tokens": [
          50414,
          708,
          311,
          264,
          2649,
          1296,
          257,
          2522,
          295,
          4722,
          300,
          307,
          13232,
          5717,
          257,
          2522,
          295,
          4722,
          300,
          28211,
          1024,
          11,
          300,
          2709,
          766,
          11,
          300,
          575,
          264,
          18854,
          295,
          7599,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.20120794122869318,
        "compression_ratio": 1.6240601503759398,
        "end": 1104.6,
        "id": 256,
        "no_speech_prob": 0.06008361652493477,
        "seek": 109160,
        "start": 1102.6,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.28084222475687665,
        "compression_ratio": 1.4427083333333333,
        "end": 1120.6,
        "id": 257,
        "no_speech_prob": 0.16234657168388367,
        "seek": 110460,
        "start": 1105.6,
        "temperature": 0,
        "text": " And so what this course to me is about is creating systems, examples, interactivity, projects, strange useless experiments that relate to the concept of my computer program.",
        "tokens": [
          50414,
          400,
          370,
          437,
          341,
          1164,
          281,
          385,
          307,
          466,
          307,
          4084,
          3652,
          11,
          5110,
          11,
          4648,
          4253,
          11,
          4455,
          11,
          5861,
          14115,
          12050,
          300,
          10961,
          281,
          264,
          3410,
          295,
          452,
          3820,
          1461,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.28084222475687665,
        "compression_ratio": 1.4427083333333333,
        "end": 1123.6,
        "id": 258,
        "no_speech_prob": 0.16234657168388367,
        "seek": 110460,
        "start": 1120.6,
        "temperature": 0,
        "text": " Oh crap.",
        "tokens": [
          51164,
          876,
          12426,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.28084222475687665,
        "compression_ratio": 1.4427083333333333,
        "end": 1127.6,
        "id": 259,
        "no_speech_prob": 0.16234657168388367,
        "seek": 110460,
        "start": 1123.6,
        "temperature": 0,
        "text": " The other computer does.",
        "tokens": [
          51314,
          440,
          661,
          3820,
          775,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.28084222475687665,
        "compression_ratio": 1.4427083333333333,
        "end": 1129.6,
        "id": 260,
        "no_speech_prob": 0.16234657168388367,
        "seek": 110460,
        "start": 1127.6,
        "temperature": 0,
        "text": " I didn't like what I was saying.",
        "tokens": [
          51514,
          286,
          994,
          380,
          411,
          437,
          286,
          390,
          1566,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.28084222475687665,
        "compression_ratio": 1.4427083333333333,
        "end": 1132.6,
        "id": 261,
        "no_speech_prob": 0.16234657168388367,
        "seek": 110460,
        "start": 1129.6,
        "temperature": 0,
        "text": " And I'm taking a break for a second.",
        "tokens": [
          51614,
          400,
          286,
          478,
          1940,
          257,
          1821,
          337,
          257,
          1150,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.27639559904734295,
        "compression_ratio": 1.3725490196078431,
        "end": 1137.6,
        "id": 262,
        "no_speech_prob": 0.005641754250973463,
        "seek": 113260,
        "start": 1133.6,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27639559904734295,
        "compression_ratio": 1.3725490196078431,
        "end": 1139.6,
        "id": 263,
        "no_speech_prob": 0.005641754250973463,
        "seek": 113260,
        "start": 1137.6,
        "temperature": 0,
        "text": " I'm going to come back to that.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.27639559904734295,
        "compression_ratio": 1.3725490196078431,
        "end": 1141.6,
        "id": 264,
        "no_speech_prob": 0.005641754250973463,
        "seek": 113260,
        "start": 1139.6,
        "temperature": 0,
        "text": " Mateo is going to do some magic editing.",
        "tokens": [
          50714,
          6789,
          68,
          78,
          307,
          516,
          281,
          360,
          512,
          5585,
          10000,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.27639559904734295,
        "compression_ratio": 1.3725490196078431,
        "end": 1148.6,
        "id": 265,
        "no_speech_prob": 0.005641754250973463,
        "seek": 113260,
        "start": 1141.6,
        "temperature": 0,
        "text": " I'm going to go from after I'm afraid of all this stuff.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          352,
          490,
          934,
          286,
          478,
          4638,
          295,
          439,
          341,
          1507,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24792801843930598,
        "compression_ratio": 1.5309278350515463,
        "end": 1168.6,
        "id": 266,
        "no_speech_prob": 0.22538380324840546,
        "seek": 114860,
        "start": 1149.6,
        "temperature": 0,
        "text": " The other reason that I want to call this course just intelligence and learning is as I've always done with my materials, I'm not necessarily looking to create a perfect scientific simulation of the...",
        "tokens": [
          50414,
          440,
          661,
          1778,
          300,
          286,
          528,
          281,
          818,
          341,
          1164,
          445,
          7599,
          293,
          2539,
          307,
          382,
          286,
          600,
          1009,
          1096,
          365,
          452,
          5319,
          11,
          286,
          478,
          406,
          4725,
          1237,
          281,
          1884,
          257,
          2176,
          8134,
          16575,
          295,
          264,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.24792801843930598,
        "compression_ratio": 1.5309278350515463,
        "end": 1172.6,
        "id": 267,
        "no_speech_prob": 0.22538380324840546,
        "seek": 114860,
        "start": 1168.6,
        "temperature": 0,
        "text": " Give me one more chance.",
        "tokens": [
          51364,
          5303,
          385,
          472,
          544,
          2931,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24792801843930598,
        "compression_ratio": 1.5309278350515463,
        "end": 1174.6,
        "id": 268,
        "no_speech_prob": 0.22538380324840546,
        "seek": 114860,
        "start": 1172.6,
        "temperature": 0,
        "text": " You're not over here.",
        "tokens": [
          51564,
          509,
          434,
          406,
          670,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24792801843930598,
        "compression_ratio": 1.5309278350515463,
        "end": 1175.6,
        "id": 269,
        "no_speech_prob": 0.22538380324840546,
        "seek": 114860,
        "start": 1174.6,
        "temperature": 0,
        "text": " Everybody bear with me.",
        "tokens": [
          51664,
          7646,
          6155,
          365,
          385,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24792801843930598,
        "compression_ratio": 1.5309278350515463,
        "end": 1176.6,
        "id": 270,
        "no_speech_prob": 0.22538380324840546,
        "seek": 114860,
        "start": 1175.6,
        "temperature": 0,
        "text": " Give me one more chance.",
        "tokens": [
          51714,
          5303,
          385,
          472,
          544,
          2931,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1178.6,
        "id": 271,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1176.6,
        "temperature": 0,
        "text": " This is what happens Friday at 4 o'clock.",
        "tokens": [
          50364,
          639,
          307,
          437,
          2314,
          6984,
          412,
          1017,
          277,
          6,
          9023,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1179.6,
        "id": 272,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1178.6,
        "temperature": 0,
        "text": " I'm going to get through this.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          483,
          807,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1180.6,
        "id": 273,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1179.6,
        "temperature": 0,
        "text": " This is the kind of stuff I really struggle with.",
        "tokens": [
          50514,
          639,
          307,
          264,
          733,
          295,
          1507,
          286,
          534,
          7799,
          365,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1182.6,
        "id": 274,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1180.6,
        "temperature": 0,
        "text": " I'd much rather just be coding right now.",
        "tokens": [
          50564,
          286,
          1116,
          709,
          2831,
          445,
          312,
          17720,
          558,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1184.6,
        "id": 275,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1182.6,
        "temperature": 0,
        "text": " But the thing is I'm going to move more quickly.",
        "tokens": [
          50664,
          583,
          264,
          551,
          307,
          286,
          478,
          516,
          281,
          1286,
          544,
          2661,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1186.6,
        "id": 276,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1184.6,
        "temperature": 0,
        "text": " The answer is to move more quickly.",
        "tokens": [
          50764,
          440,
          1867,
          307,
          281,
          1286,
          544,
          2661,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1187.6,
        "id": 277,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1186.6,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50864,
          1044,
          291,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1189.6,
        "id": 278,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1187.6,
        "temperature": 0,
        "text": " Thank you for your patience, live audience.",
        "tokens": [
          50914,
          1044,
          291,
          337,
          428,
          14826,
          11,
          1621,
          4034,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1192.6,
        "id": 279,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1189.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19352116584777831,
        "compression_ratio": 1.646153846153846,
        "end": 1196.6,
        "id": 280,
        "no_speech_prob": 0.24794884026050568,
        "seek": 117660,
        "start": 1192.6,
        "temperature": 0,
        "text": " So the other reason why I want to call it intelligence and learning is I want to take the broadest approach possible.",
        "tokens": [
          51164,
          407,
          264,
          661,
          1778,
          983,
          286,
          528,
          281,
          818,
          309,
          7599,
          293,
          2539,
          307,
          286,
          528,
          281,
          747,
          264,
          4152,
          377,
          3109,
          1944,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24151448505680737,
        "compression_ratio": 1.6275303643724697,
        "end": 1214.6,
        "id": 281,
        "no_speech_prob": 0.5697355270385742,
        "seek": 119660,
        "start": 1197.6,
        "temperature": 0,
        "text": " So you watching this course, whether it's you implement the latest and greatest perfect machine learning neural network, convolutional recurrent magical system thing that does something you read about in some academic paper or you make some crazy project where it seems like the computer is playing this goofy game with you and how could it possibly be doing that.",
        "tokens": [
          50414,
          407,
          291,
          1976,
          341,
          1164,
          11,
          1968,
          309,
          311,
          291,
          4445,
          264,
          6792,
          293,
          6636,
          2176,
          3479,
          2539,
          18161,
          3209,
          11,
          45216,
          304,
          18680,
          1753,
          12066,
          1185,
          551,
          300,
          775,
          746,
          291,
          1401,
          466,
          294,
          512,
          7778,
          3035,
          420,
          291,
          652,
          512,
          3219,
          1716,
          689,
          309,
          2544,
          411,
          264,
          3820,
          307,
          2433,
          341,
          42995,
          1216,
          365,
          291,
          293,
          577,
          727,
          309,
          6264,
          312,
          884,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24151448505680737,
        "compression_ratio": 1.6275303643724697,
        "end": 1217.6,
        "id": 282,
        "no_speech_prob": 0.5697355270385742,
        "seek": 119660,
        "start": 1214.6,
        "temperature": 0,
        "text": " So there's a lot of space in between.",
        "tokens": [
          51264,
          407,
          456,
          311,
          257,
          688,
          295,
          1901,
          294,
          1296,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1226.6,
        "id": 283,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1218.6,
        "temperature": 0,
        "text": " And for me I want to just really take a broad approach to this not just look at only neural networks and machine learning and not just look at only these topics in artificial intelligence.",
        "tokens": [
          50414,
          400,
          337,
          385,
          286,
          528,
          281,
          445,
          534,
          747,
          257,
          4152,
          3109,
          281,
          341,
          406,
          445,
          574,
          412,
          787,
          18161,
          9590,
          293,
          3479,
          2539,
          293,
          406,
          445,
          574,
          412,
          787,
          613,
          8378,
          294,
          11677,
          7599,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1227.6,
        "id": 284,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1226.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1229.6,
        "id": 285,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1227.6,
        "temperature": 0,
        "text": " So first of all, I'm kind of blending all these terms.",
        "tokens": [
          50864,
          407,
          700,
          295,
          439,
          11,
          286,
          478,
          733,
          295,
          23124,
          439,
          613,
          2115,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1232.6,
        "id": 286,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1229.6,
        "temperature": 0,
        "text": " Let's try to at least define them.",
        "tokens": [
          50964,
          961,
          311,
          853,
          281,
          412,
          1935,
          6964,
          552,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1237.6,
        "id": 287,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1232.6,
        "temperature": 0,
        "text": " So let's ‑‑ I saw this chart in a book somewhere.",
        "tokens": [
          51114,
          407,
          718,
          311,
          220,
          27392,
          27392,
          286,
          1866,
          341,
          6927,
          294,
          257,
          1446,
          4079,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1239.6,
        "id": 288,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1237.6,
        "temperature": 0,
        "text": " So I'm going to recreate it.",
        "tokens": [
          51364,
          407,
          286,
          478,
          516,
          281,
          25833,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1241.6,
        "id": 289,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1239.6,
        "temperature": 0,
        "text": " So artificial intelligence is a topic.",
        "tokens": [
          51464,
          407,
          11677,
          7599,
          307,
          257,
          4829,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22777355028235394,
        "compression_ratio": 1.753968253968254,
        "end": 1243.6,
        "id": 290,
        "no_speech_prob": 0.09944957494735718,
        "seek": 121760,
        "start": 1241.6,
        "temperature": 0,
        "text": " So what is artificial intelligence?",
        "tokens": [
          51564,
          407,
          437,
          307,
          11677,
          7599,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.23744659919243355,
        "compression_ratio": 1.5023923444976077,
        "end": 1249.6,
        "id": 291,
        "no_speech_prob": 0.07368361204862595,
        "seek": 124360,
        "start": 1243.6,
        "temperature": 0,
        "text": " Well, I actually just recently watched a lecture by a professor at MIT, Patrick Winston.",
        "tokens": [
          50364,
          1042,
          11,
          286,
          767,
          445,
          3938,
          6337,
          257,
          7991,
          538,
          257,
          8304,
          412,
          13100,
          11,
          13980,
          33051,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23744659919243355,
        "compression_ratio": 1.5023923444976077,
        "end": 1266.6,
        "id": 292,
        "no_speech_prob": 0.07368361204862595,
        "seek": 124360,
        "start": 1249.6,
        "temperature": 0,
        "text": " Patrick Winston I think says at the opening of the lecture, models ‑‑ someone will correct me if I'm wrong ‑‑ for thinking, perception, and action.",
        "tokens": [
          50664,
          13980,
          33051,
          286,
          519,
          1619,
          412,
          264,
          5193,
          295,
          264,
          7991,
          11,
          5245,
          45217,
          1580,
          486,
          3006,
          385,
          498,
          286,
          478,
          2085,
          45217,
          337,
          1953,
          11,
          12860,
          11,
          293,
          3069,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23744659919243355,
        "compression_ratio": 1.5023923444976077,
        "end": 1268.6,
        "id": 293,
        "no_speech_prob": 0.07368361204862595,
        "seek": 124360,
        "start": 1266.6,
        "temperature": 0,
        "text": " So this is a very broad term.",
        "tokens": [
          51514,
          407,
          341,
          307,
          257,
          588,
          4152,
          1433,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23744659919243355,
        "compression_ratio": 1.5023923444976077,
        "end": 1269.6,
        "id": 294,
        "no_speech_prob": 0.07368361204862595,
        "seek": 124360,
        "start": 1268.6,
        "temperature": 0,
        "text": " So let's think about this for a second.",
        "tokens": [
          51614,
          407,
          718,
          311,
          519,
          466,
          341,
          337,
          257,
          1150,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24942827224731445,
        "compression_ratio": 1.6115702479338843,
        "end": 1272.6,
        "id": 295,
        "no_speech_prob": 0.36647847294807434,
        "seek": 126960,
        "start": 1270.6,
        "temperature": 0,
        "text": " So I'm going to go back to some of my other examples.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          512,
          295,
          452,
          661,
          5110,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24942827224731445,
        "compression_ratio": 1.6115702479338843,
        "end": 1274.6,
        "id": 296,
        "no_speech_prob": 0.36647847294807434,
        "seek": 126960,
        "start": 1272.6,
        "temperature": 0,
        "text": " I'm going to come over here.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          808,
          670,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24942827224731445,
        "compression_ratio": 1.6115702479338843,
        "end": 1294.6,
        "id": 297,
        "no_speech_prob": 0.36647847294807434,
        "seek": 126960,
        "start": 1274.6,
        "temperature": 0,
        "text": " And I'm going to open it where if we were following along with the sort of ‑‑ if we stopped here at week six or session six or chapter six, whatever you want to call it, and I ran this flocking simulation, I could ask the question, is this artificial intelligence?",
        "tokens": [
          50614,
          400,
          286,
          478,
          516,
          281,
          1269,
          309,
          689,
          498,
          321,
          645,
          3480,
          2051,
          365,
          264,
          1333,
          295,
          45217,
          498,
          321,
          5936,
          510,
          412,
          1243,
          2309,
          420,
          5481,
          2309,
          420,
          7187,
          2309,
          11,
          2035,
          291,
          528,
          281,
          818,
          309,
          11,
          293,
          286,
          5872,
          341,
          2591,
          25723,
          16575,
          11,
          286,
          727,
          1029,
          264,
          1168,
          11,
          307,
          341,
          11677,
          7599,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.24942827224731445,
        "compression_ratio": 1.6115702479338843,
        "end": 1296.6,
        "id": 298,
        "no_speech_prob": 0.36647847294807434,
        "seek": 126960,
        "start": 1294.6,
        "temperature": 0,
        "text": " Wait.",
        "tokens": [
          51614,
          3802,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24942827224731445,
        "compression_ratio": 1.6115702479338843,
        "end": 1298.6,
        "id": 299,
        "no_speech_prob": 0.36647847294807434,
        "seek": 126960,
        "start": 1296.6,
        "temperature": 0,
        "text": " Nobody can answer this question.",
        "tokens": [
          51714,
          9297,
          393,
          1867,
          341,
          1168,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22433392506725383,
        "compression_ratio": 1.348148148148148,
        "end": 1300.6,
        "id": 300,
        "no_speech_prob": 0.018832296133041382,
        "seek": 129860,
        "start": 1298.6,
        "temperature": 0,
        "text": " So I'm asking this question.",
        "tokens": [
          50364,
          407,
          286,
          478,
          3365,
          341,
          1168,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22433392506725383,
        "compression_ratio": 1.348148148148148,
        "end": 1307.6,
        "id": 301,
        "no_speech_prob": 0.018832296133041382,
        "seek": 129860,
        "start": 1300.6,
        "temperature": 0,
        "text": " But what's interesting, whether or not you want to say yes or no, I'm going to go back to here for a second.",
        "tokens": [
          50464,
          583,
          437,
          311,
          1880,
          11,
          1968,
          420,
          406,
          291,
          528,
          281,
          584,
          2086,
          420,
          572,
          11,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          510,
          337,
          257,
          1150,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22433392506725383,
        "compression_ratio": 1.348148148148148,
        "end": 1309.6,
        "id": 302,
        "no_speech_prob": 0.018832296133041382,
        "seek": 129860,
        "start": 1307.6,
        "temperature": 0,
        "text": " Models for thinking, perception, and action.",
        "tokens": [
          50814,
          6583,
          1625,
          337,
          1953,
          11,
          12860,
          11,
          293,
          3069,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2168192598554823,
        "compression_ratio": 1.5895953757225434,
        "end": 1321.6,
        "id": 303,
        "no_speech_prob": 0.11919455230236053,
        "seek": 130960,
        "start": 1310.6,
        "temperature": 0,
        "text": " So one thing, if you remember, if you look at steering behaviors and steering behaviors pioneered by Craig Reynolds, what is it?",
        "tokens": [
          50414,
          407,
          472,
          551,
          11,
          498,
          291,
          1604,
          11,
          498,
          291,
          574,
          412,
          14823,
          15501,
          293,
          14823,
          15501,
          19761,
          4073,
          538,
          19732,
          29516,
          11,
          437,
          307,
          309,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.2168192598554823,
        "compression_ratio": 1.5895953757225434,
        "end": 1329.6,
        "id": 304,
        "no_speech_prob": 0.11919455230236053,
        "seek": 130960,
        "start": 1321.6,
        "temperature": 0,
        "text": " Action, steering, locomotion.",
        "tokens": [
          50964,
          16261,
          11,
          14823,
          11,
          36369,
          19228,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2168192598554823,
        "compression_ratio": 1.5895953757225434,
        "end": 1333.6,
        "id": 305,
        "no_speech_prob": 0.11919455230236053,
        "seek": 130960,
        "start": 1329.6,
        "temperature": 0,
        "text": " So I've really been focusing on steering.",
        "tokens": [
          51364,
          407,
          286,
          600,
          534,
          668,
          8416,
          322,
          14823,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2168192598554823,
        "compression_ratio": 1.5895953757225434,
        "end": 1335.6,
        "id": 306,
        "no_speech_prob": 0.11919455230236053,
        "seek": 130960,
        "start": 1333.6,
        "temperature": 0,
        "text": " How do you calculate a steering force?",
        "tokens": [
          51564,
          1012,
          360,
          291,
          8873,
          257,
          14823,
          3464,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2168192598554823,
        "compression_ratio": 1.5895953757225434,
        "end": 1337.6,
        "id": 307,
        "no_speech_prob": 0.11919455230236053,
        "seek": 130960,
        "start": 1335.6,
        "temperature": 0,
        "text": " How do you do the physics for that?",
        "tokens": [
          51664,
          1012,
          360,
          291,
          360,
          264,
          10649,
          337,
          300,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2519995851336785,
        "compression_ratio": 1.8982300884955752,
        "end": 1339.6,
        "id": 308,
        "no_speech_prob": 0.21467651426792145,
        "seek": 133760,
        "start": 1337.6,
        "temperature": 0,
        "text": " How do you do the physics for one pixel to another?",
        "tokens": [
          50364,
          1012,
          360,
          291,
          360,
          264,
          10649,
          337,
          472,
          19261,
          281,
          1071,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.2519995851336785,
        "compression_ratio": 1.8982300884955752,
        "end": 1343.6,
        "id": 309,
        "no_speech_prob": 0.21467651426792145,
        "seek": 133760,
        "start": 1339.6,
        "temperature": 0,
        "text": " And steering and locomotion kind of cover all of those pieces.",
        "tokens": [
          50464,
          400,
          14823,
          293,
          36369,
          19228,
          733,
          295,
          2060,
          439,
          295,
          729,
          3755,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2519995851336785,
        "compression_ratio": 1.8982300884955752,
        "end": 1347.6,
        "id": 310,
        "no_speech_prob": 0.21467651426792145,
        "seek": 133760,
        "start": 1343.6,
        "temperature": 0,
        "text": " Action, this is a place where, well, what is the action?",
        "tokens": [
          50664,
          16261,
          11,
          341,
          307,
          257,
          1081,
          689,
          11,
          731,
          11,
          437,
          307,
          264,
          3069,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2519995851336785,
        "compression_ratio": 1.8982300884955752,
        "end": 1349.6,
        "id": 311,
        "no_speech_prob": 0.21467651426792145,
        "seek": 133760,
        "start": 1347.6,
        "temperature": 0,
        "text": " What are the goals?",
        "tokens": [
          50864,
          708,
          366,
          264,
          5493,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.2519995851336785,
        "compression_ratio": 1.8982300884955752,
        "end": 1359.6,
        "id": 312,
        "no_speech_prob": 0.21467651426792145,
        "seek": 133760,
        "start": 1349.6,
        "temperature": 0,
        "text": " In the flocking system, the goals are stay with your neighbors, but don't crash into your neighbors, and also stay in proximity to your neighbors and also move in the same direction as your neighbors, but don't crash into your neighbors.",
        "tokens": [
          50964,
          682,
          264,
          2591,
          25723,
          1185,
          11,
          264,
          5493,
          366,
          1754,
          365,
          428,
          12512,
          11,
          457,
          500,
          380,
          8252,
          666,
          428,
          12512,
          11,
          293,
          611,
          1754,
          294,
          27632,
          281,
          428,
          12512,
          293,
          611,
          1286,
          294,
          264,
          912,
          3513,
          382,
          428,
          12512,
          11,
          457,
          500,
          380,
          8252,
          666,
          428,
          12512,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21764024455895584,
        "compression_ratio": 1.8272727272727274,
        "end": 1368.6,
        "id": 313,
        "no_speech_prob": 0.15813305974006653,
        "seek": 135960,
        "start": 1359.6,
        "temperature": 0,
        "text": " And the other kind of action things that you might select is follow this thing or chase this thing or run away from this thing or try to get through this doorway the fastest that you can.",
        "tokens": [
          50364,
          400,
          264,
          661,
          733,
          295,
          3069,
          721,
          300,
          291,
          1062,
          3048,
          307,
          1524,
          341,
          551,
          420,
          15359,
          341,
          551,
          420,
          1190,
          1314,
          490,
          341,
          551,
          420,
          853,
          281,
          483,
          807,
          341,
          41992,
          264,
          14573,
          300,
          291,
          393,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21764024455895584,
        "compression_ratio": 1.8272727272727274,
        "end": 1379.6,
        "id": 314,
        "no_speech_prob": 0.15813305974006653,
        "seek": 135960,
        "start": 1368.6,
        "temperature": 0,
        "text": " So what's interesting here is seeing this link is what are models for thinking and perception that might lead to action to govern the types of animated systems that you might create?",
        "tokens": [
          50814,
          407,
          437,
          311,
          1880,
          510,
          307,
          2577,
          341,
          2113,
          307,
          437,
          366,
          5245,
          337,
          1953,
          293,
          12860,
          300,
          1062,
          1477,
          281,
          3069,
          281,
          1980,
          264,
          3467,
          295,
          18947,
          3652,
          300,
          291,
          1062,
          1884,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.21764024455895584,
        "compression_ratio": 1.8272727272727274,
        "end": 1381.6,
        "id": 315,
        "no_speech_prob": 0.15813305974006653,
        "seek": 135960,
        "start": 1379.6,
        "temperature": 0,
        "text": " So this to me is the link here.",
        "tokens": [
          51364,
          407,
          341,
          281,
          385,
          307,
          264,
          2113,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21212755400558997,
        "compression_ratio": 1.6930232558139535,
        "end": 1390.6,
        "id": 316,
        "no_speech_prob": 0.07368605583906174,
        "seek": 138160,
        "start": 1381.6,
        "temperature": 0,
        "text": " Whether it's enough to say I am going to kind of define the rules, almost known as like a rule-based system, feature engineering, so to speak.",
        "tokens": [
          50364,
          8503,
          309,
          311,
          1547,
          281,
          584,
          286,
          669,
          516,
          281,
          733,
          295,
          6964,
          264,
          4474,
          11,
          1920,
          2570,
          382,
          411,
          257,
          4978,
          12,
          6032,
          1185,
          11,
          4111,
          7043,
          11,
          370,
          281,
          1710,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21212755400558997,
        "compression_ratio": 1.6930232558139535,
        "end": 1392.6,
        "id": 317,
        "no_speech_prob": 0.07368605583906174,
        "seek": 138160,
        "start": 1390.6,
        "temperature": 0,
        "text": " Like I don't need a learning-based system.",
        "tokens": [
          50814,
          1743,
          286,
          500,
          380,
          643,
          257,
          2539,
          12,
          6032,
          1185,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21212755400558997,
        "compression_ratio": 1.6930232558139535,
        "end": 1400.6,
        "id": 318,
        "no_speech_prob": 0.07368605583906174,
        "seek": 138160,
        "start": 1392.6,
        "temperature": 0,
        "text": " I'm going to define the rules of how all these things should behave, but they're going to appear intelligent versus something like a learning system which has to learn over time.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          6964,
          264,
          4474,
          295,
          577,
          439,
          613,
          721,
          820,
          15158,
          11,
          457,
          436,
          434,
          516,
          281,
          4204,
          13232,
          5717,
          746,
          411,
          257,
          2539,
          1185,
          597,
          575,
          281,
          1466,
          670,
          565,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23124160486109116,
        "compression_ratio": 1.7486338797814207,
        "end": 1413.6,
        "id": 319,
        "no_speech_prob": 0.13659846782684326,
        "seek": 140060,
        "start": 1400.6,
        "temperature": 0,
        "text": " So machine learning being something that crosses over with artificial intelligence, I think of machine learning as something that you have data and you make meaning from that data.",
        "tokens": [
          50364,
          407,
          3479,
          2539,
          885,
          746,
          300,
          28467,
          670,
          365,
          11677,
          7599,
          11,
          286,
          519,
          295,
          3479,
          2539,
          382,
          746,
          300,
          291,
          362,
          1412,
          293,
          291,
          652,
          3620,
          490,
          300,
          1412,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23124160486109116,
        "compression_ratio": 1.7486338797814207,
        "end": 1425.6,
        "id": 320,
        "no_speech_prob": 0.13659846782684326,
        "seek": 140060,
        "start": 1413.6,
        "temperature": 0,
        "text": " So how do you, and there's more to it than this, but one of the most classic applications of a machine learning system is classifying data.",
        "tokens": [
          51014,
          407,
          577,
          360,
          291,
          11,
          293,
          456,
          311,
          544,
          281,
          309,
          813,
          341,
          11,
          457,
          472,
          295,
          264,
          881,
          7230,
          5821,
          295,
          257,
          3479,
          2539,
          1185,
          307,
          1508,
          5489,
          1412,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23064179853959518,
        "compression_ratio": 1.6869565217391305,
        "end": 1427.6,
        "id": 321,
        "no_speech_prob": 0.004399322438985109,
        "seek": 142560,
        "start": 1426.6,
        "temperature": 0,
        "text": " Classification.",
        "tokens": [
          50414,
          9471,
          3774,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23064179853959518,
        "compression_ratio": 1.6869565217391305,
        "end": 1430.6,
        "id": 322,
        "no_speech_prob": 0.004399322438985109,
        "seek": 142560,
        "start": 1427.6,
        "temperature": 0,
        "text": " So here's a bunch of pictures.",
        "tokens": [
          50464,
          407,
          510,
          311,
          257,
          3840,
          295,
          5242,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23064179853959518,
        "compression_ratio": 1.6869565217391305,
        "end": 1432.6,
        "id": 323,
        "no_speech_prob": 0.004399322438985109,
        "seek": 142560,
        "start": 1430.6,
        "temperature": 0,
        "text": " Which ones are cats and which ones are dogs?",
        "tokens": [
          50614,
          3013,
          2306,
          366,
          11111,
          293,
          597,
          2306,
          366,
          7197,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.23064179853959518,
        "compression_ratio": 1.6869565217391305,
        "end": 1448.6,
        "id": 324,
        "no_speech_prob": 0.004399322438985109,
        "seek": 142560,
        "start": 1432.6,
        "temperature": 0,
        "text": " And there's more, you know, the other type of system that you, classic application of machine learning is regression, which instead of categorizing into a discrete set of labels, you know, cats or dogs, you might say, you know, here's all of these.",
        "tokens": [
          50714,
          400,
          456,
          311,
          544,
          11,
          291,
          458,
          11,
          264,
          661,
          2010,
          295,
          1185,
          300,
          291,
          11,
          7230,
          3861,
          295,
          3479,
          2539,
          307,
          24590,
          11,
          597,
          2602,
          295,
          19250,
          3319,
          666,
          257,
          27706,
          992,
          295,
          16949,
          11,
          291,
          458,
          11,
          11111,
          420,
          7197,
          11,
          291,
          1062,
          584,
          11,
          291,
          458,
          11,
          510,
          311,
          439,
          295,
          613,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23064179853959518,
        "compression_ratio": 1.6869565217391305,
        "end": 1452.6,
        "id": 325,
        "no_speech_prob": 0.004399322438985109,
        "seek": 142560,
        "start": 1448.6,
        "temperature": 0,
        "text": " You want to arrive at a more continuous result.",
        "tokens": [
          51514,
          509,
          528,
          281,
          8881,
          412,
          257,
          544,
          10957,
          1874,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1454.6,
        "id": 326,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1452.6,
        "temperature": 0,
        "text": " So here's all these properties of a house.",
        "tokens": [
          50364,
          407,
          510,
          311,
          439,
          613,
          7221,
          295,
          257,
          1782,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1455.6,
        "id": 327,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1454.6,
        "temperature": 0,
        "text": " How many bedrooms?",
        "tokens": [
          50464,
          1012,
          867,
          39955,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1456.6,
        "id": 328,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1455.6,
        "temperature": 0,
        "text": " Where is it located?",
        "tokens": [
          50514,
          2305,
          307,
          309,
          6870,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1457.6,
        "id": 329,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1456.6,
        "temperature": 0,
        "text": " How many bathrooms?",
        "tokens": [
          50564,
          1012,
          867,
          39537,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1463.6,
        "id": 330,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1457.6,
        "temperature": 0,
        "text": " And can the system take that data and determine predictive price?",
        "tokens": [
          50614,
          400,
          393,
          264,
          1185,
          747,
          300,
          1412,
          293,
          6997,
          35521,
          3218,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1467.6,
        "id": 331,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1463.6,
        "temperature": 0,
        "text": " So these are two classic tasks in machine learning.",
        "tokens": [
          50914,
          407,
          613,
          366,
          732,
          7230,
          9608,
          294,
          3479,
          2539,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1471.6,
        "id": 332,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1467.6,
        "temperature": 0,
        "text": " Now, what's in the news and what's all the rage?",
        "tokens": [
          51114,
          823,
          11,
          437,
          311,
          294,
          264,
          2583,
          293,
          437,
          311,
          439,
          264,
          20133,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.21564073996110397,
        "compression_ratio": 1.5761904761904761,
        "end": 1475.6,
        "id": 333,
        "no_speech_prob": 0.04534906893968582,
        "seek": 145260,
        "start": 1471.6,
        "temperature": 0,
        "text": " What's everybody working with these days are neural networks.",
        "tokens": [
          51314,
          708,
          311,
          2201,
          1364,
          365,
          613,
          1708,
          366,
          18161,
          9590,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20412983894348144,
        "compression_ratio": 1.6621004566210045,
        "end": 1485.6,
        "id": 334,
        "no_speech_prob": 0.129395991563797,
        "seek": 147560,
        "start": 1475.6,
        "temperature": 0,
        "text": " So, you know, a popular and powerful and exciting, so much new research in this right now, recently, of creating machine learning systems to do these tasks with neural networks.",
        "tokens": [
          50364,
          407,
          11,
          291,
          458,
          11,
          257,
          3743,
          293,
          4005,
          293,
          4670,
          11,
          370,
          709,
          777,
          2132,
          294,
          341,
          558,
          586,
          11,
          3938,
          11,
          295,
          4084,
          3479,
          2539,
          3652,
          281,
          360,
          613,
          9608,
          365,
          18161,
          9590,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20412983894348144,
        "compression_ratio": 1.6621004566210045,
        "end": 1495.6,
        "id": 335,
        "no_speech_prob": 0.129395991563797,
        "seek": 147560,
        "start": 1485.6,
        "temperature": 0,
        "text": " However, in this course, I want to look at other systems that do the same thing, that are simpler, that might not be as powerful, but might have opportunities for creative possibilities.",
        "tokens": [
          50864,
          2908,
          11,
          294,
          341,
          1164,
          11,
          286,
          528,
          281,
          574,
          412,
          661,
          3652,
          300,
          360,
          264,
          912,
          551,
          11,
          300,
          366,
          18587,
          11,
          300,
          1062,
          406,
          312,
          382,
          4005,
          11,
          457,
          1062,
          362,
          4786,
          337,
          5880,
          12178,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20697823277226202,
        "compression_ratio": 1.5627376425855513,
        "end": 1505.6,
        "id": 336,
        "no_speech_prob": 0.21466775238513947,
        "seek": 149560,
        "start": 1496.6,
        "temperature": 0,
        "text": " But also, if you can use the simpler system for the same result, it's going to make it a little easier to perhaps dive into what in my mind might be the most difficult.",
        "tokens": [
          50414,
          583,
          611,
          11,
          498,
          291,
          393,
          764,
          264,
          18587,
          1185,
          337,
          264,
          912,
          1874,
          11,
          309,
          311,
          516,
          281,
          652,
          309,
          257,
          707,
          3571,
          281,
          4317,
          9192,
          666,
          437,
          294,
          452,
          1575,
          1062,
          312,
          264,
          881,
          2252,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20697823277226202,
        "compression_ratio": 1.5627376425855513,
        "end": 1507.6,
        "id": 337,
        "no_speech_prob": 0.21466775238513947,
        "seek": 149560,
        "start": 1505.6,
        "temperature": 0,
        "text": " I might cancel this part.",
        "tokens": [
          50864,
          286,
          1062,
          10373,
          341,
          644,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20697823277226202,
        "compression_ratio": 1.5627376425855513,
        "end": 1510.6,
        "id": 338,
        "no_speech_prob": 0.21466775238513947,
        "seek": 149560,
        "start": 1507.6,
        "temperature": 0,
        "text": " Actually, last time I mentioned machine learning, a fire alarm went off, which saved me.",
        "tokens": [
          50964,
          5135,
          11,
          1036,
          565,
          286,
          2835,
          3479,
          2539,
          11,
          257,
          2610,
          14183,
          1437,
          766,
          11,
          597,
          6624,
          385,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20697823277226202,
        "compression_ratio": 1.5627376425855513,
        "end": 1512.6,
        "id": 339,
        "no_speech_prob": 0.21466775238513947,
        "seek": 149560,
        "start": 1510.6,
        "temperature": 0,
        "text": " Nothing happened this time.",
        "tokens": [
          51114,
          6693,
          2011,
          341,
          565,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20697823277226202,
        "compression_ratio": 1.5627376425855513,
        "end": 1514.6,
        "id": 340,
        "no_speech_prob": 0.21466775238513947,
        "seek": 149560,
        "start": 1512.6,
        "temperature": 0,
        "text": " But so we'll see.",
        "tokens": [
          51214,
          583,
          370,
          321,
          603,
          536,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20697823277226202,
        "compression_ratio": 1.5627376425855513,
        "end": 1522.6,
        "id": 341,
        "no_speech_prob": 0.21466775238513947,
        "seek": 149560,
        "start": 1514.6,
        "temperature": 0,
        "text": " So now, so these are areas where I want to just look at and cover in this course.",
        "tokens": [
          51314,
          407,
          586,
          11,
          370,
          613,
          366,
          3179,
          689,
          286,
          528,
          281,
          445,
          574,
          412,
          293,
          2060,
          294,
          341,
          1164,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18642929301542394,
        "compression_ratio": 1.6394230769230769,
        "end": 1525.6,
        "id": 342,
        "no_speech_prob": 0.004331468604505062,
        "seek": 152260,
        "start": 1522.6,
        "temperature": 0,
        "text": " Now, what's this thing down here under DL?",
        "tokens": [
          50364,
          823,
          11,
          437,
          311,
          341,
          551,
          760,
          510,
          833,
          413,
          43,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.18642929301542394,
        "compression_ratio": 1.6394230769230769,
        "end": 1526.6,
        "id": 343,
        "no_speech_prob": 0.004331468604505062,
        "seek": 152260,
        "start": 1525.6,
        "temperature": 0,
        "text": " This is deep learning.",
        "tokens": [
          50514,
          639,
          307,
          2452,
          2539,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18642929301542394,
        "compression_ratio": 1.6394230769230769,
        "end": 1527.6,
        "id": 344,
        "no_speech_prob": 0.004331468604505062,
        "seek": 152260,
        "start": 1526.6,
        "temperature": 0,
        "text": " And you know what?",
        "tokens": [
          50564,
          400,
          291,
          458,
          437,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.18642929301542394,
        "compression_ratio": 1.6394230769230769,
        "end": 1529.6,
        "id": 345,
        "no_speech_prob": 0.004331468604505062,
        "seek": 152260,
        "start": 1527.6,
        "temperature": 0,
        "text": " I'm going to put deep learning in here.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          829,
          2452,
          2539,
          294,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18642929301542394,
        "compression_ratio": 1.6394230769230769,
        "end": 1540.6,
        "id": 346,
        "no_speech_prob": 0.004331468604505062,
        "seek": 152260,
        "start": 1529.6,
        "temperature": 0,
        "text": " So as I just mentioned, one technique for performing these machine learning tasks is using something called an artificial neural network.",
        "tokens": [
          50714,
          407,
          382,
          286,
          445,
          2835,
          11,
          472,
          6532,
          337,
          10205,
          613,
          3479,
          2539,
          9608,
          307,
          1228,
          746,
          1219,
          364,
          11677,
          18161,
          3209,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18642929301542394,
        "compression_ratio": 1.6394230769230769,
        "end": 1550.6,
        "id": 347,
        "no_speech_prob": 0.004331468604505062,
        "seek": 152260,
        "start": 1540.6,
        "temperature": 0,
        "text": " So an artificial neural network is a system where the data flows in as inputs.",
        "tokens": [
          51264,
          407,
          364,
          11677,
          18161,
          3209,
          307,
          257,
          1185,
          689,
          264,
          1412,
          12867,
          294,
          382,
          15743,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1556.6,
        "id": 348,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1550.6,
        "temperature": 0,
        "text": " And there are some set of connected neurons that we...",
        "tokens": [
          50364,
          400,
          456,
          366,
          512,
          992,
          295,
          4582,
          22027,
          300,
          321,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1558.6,
        "id": 349,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1556.6,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50664,
          407,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1562.6,
        "id": 350,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1558.6,
        "temperature": 0,
        "text": " How am I doing on time, everybody?",
        "tokens": [
          50764,
          1012,
          669,
          286,
          884,
          322,
          565,
          11,
          2201,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1565.6,
        "id": 351,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1562.6,
        "temperature": 0,
        "text": " The birds have no feelings looking at the chat.",
        "tokens": [
          50964,
          440,
          9009,
          362,
          572,
          6640,
          1237,
          412,
          264,
          5081,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1567.6,
        "id": 352,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1565.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1568.6,
        "id": 353,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1567.6,
        "temperature": 0,
        "text": " Let me come back.",
        "tokens": [
          51214,
          961,
          385,
          808,
          646,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1569.6,
        "id": 354,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1568.6,
        "temperature": 0,
        "text": " Let me erase this for a second.",
        "tokens": [
          51264,
          961,
          385,
          23525,
          341,
          337,
          257,
          1150,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3033865213394165,
        "compression_ratio": 1.4861878453038675,
        "end": 1577.6,
        "id": 355,
        "no_speech_prob": 0.028869278728961945,
        "seek": 155060,
        "start": 1574.6,
        "temperature": 0,
        "text": " Let me do that again for a second because I lost my train of thought.",
        "tokens": [
          51564,
          961,
          385,
          360,
          300,
          797,
          337,
          257,
          1150,
          570,
          286,
          2731,
          452,
          3847,
          295,
          1194,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18696625416095441,
        "compression_ratio": 1.303030303030303,
        "end": 1582.6,
        "id": 356,
        "no_speech_prob": 0.000060141406720504165,
        "seek": 158060,
        "start": 1581.6,
        "temperature": 0,
        "text": " 4.30.",
        "tokens": [
          50414,
          1017,
          13,
          3446,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18696625416095441,
        "compression_ratio": 1.303030303030303,
        "end": 1583.6,
        "id": 357,
        "no_speech_prob": 0.000060141406720504165,
        "seek": 158060,
        "start": 1582.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18696625416095441,
        "compression_ratio": 1.303030303030303,
        "end": 1584.6,
        "id": 358,
        "no_speech_prob": 0.000060141406720504165,
        "seek": 158060,
        "start": 1583.6,
        "temperature": 0,
        "text": " Got to keep moving.",
        "tokens": [
          50514,
          5803,
          281,
          1066,
          2684,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18696625416095441,
        "compression_ratio": 1.303030303030303,
        "end": 1587.6,
        "id": 359,
        "no_speech_prob": 0.000060141406720504165,
        "seek": 158060,
        "start": 1584.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50564,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18696625416095441,
        "compression_ratio": 1.303030303030303,
        "end": 1604.6,
        "id": 360,
        "no_speech_prob": 0.000060141406720504165,
        "seek": 158060,
        "start": 1587.6,
        "temperature": 0,
        "text": " So in the case of an artificial neural network, that data that you're trying to classify enters as input to something called a neuron.",
        "tokens": [
          50714,
          407,
          294,
          264,
          1389,
          295,
          364,
          11677,
          18161,
          3209,
          11,
          300,
          1412,
          300,
          291,
          434,
          1382,
          281,
          33872,
          18780,
          382,
          4846,
          281,
          746,
          1219,
          257,
          34090,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16160480046676376,
        "compression_ratio": 1.6569343065693432,
        "end": 1611.6,
        "id": 361,
        "no_speech_prob": 0.0014779308112338185,
        "seek": 160460,
        "start": 1604.6,
        "temperature": 0,
        "text": " And then passes through a network of neurons to have some sort of output.",
        "tokens": [
          50364,
          400,
          550,
          11335,
          807,
          257,
          3209,
          295,
          22027,
          281,
          362,
          512,
          1333,
          295,
          5598,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16160480046676376,
        "compression_ratio": 1.6569343065693432,
        "end": 1613.6,
        "id": 362,
        "no_speech_prob": 0.0014779308112338185,
        "seek": 160460,
        "start": 1611.6,
        "temperature": 0,
        "text": " And I spelled that wrong, but close enough.",
        "tokens": [
          50714,
          400,
          286,
          34388,
          300,
          2085,
          11,
          457,
          1998,
          1547,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16160480046676376,
        "compression_ratio": 1.6569343065693432,
        "end": 1617.6,
        "id": 363,
        "no_speech_prob": 0.0014779308112338185,
        "seek": 160460,
        "start": 1613.6,
        "temperature": 0,
        "text": " Cat, dog, price of a house, that sort of thing.",
        "tokens": [
          50814,
          9565,
          11,
          3000,
          11,
          3218,
          295,
          257,
          1782,
          11,
          300,
          1333,
          295,
          551,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16160480046676376,
        "compression_ratio": 1.6569343065693432,
        "end": 1621.6,
        "id": 364,
        "no_speech_prob": 0.0014779308112338185,
        "seek": 160460,
        "start": 1617.6,
        "temperature": 0,
        "text": " Now, an artificial neural network is a system...",
        "tokens": [
          51014,
          823,
          11,
          364,
          11677,
          18161,
          3209,
          307,
          257,
          1185,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.16160480046676376,
        "compression_ratio": 1.6569343065693432,
        "end": 1624.6,
        "id": 365,
        "no_speech_prob": 0.0014779308112338185,
        "seek": 160460,
        "start": 1621.6,
        "temperature": 0,
        "text": " And I'm going to get more into this in another video that's specifically just about this.",
        "tokens": [
          51214,
          400,
          286,
          478,
          516,
          281,
          483,
          544,
          666,
          341,
          294,
          1071,
          960,
          300,
          311,
          4682,
          445,
          466,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16160480046676376,
        "compression_ratio": 1.6569343065693432,
        "end": 1627.6,
        "id": 366,
        "no_speech_prob": 0.0014779308112338185,
        "seek": 160460,
        "start": 1624.6,
        "temperature": 0,
        "text": " So I kind of want to just actually kind of move ahead and skip over this.",
        "tokens": [
          51364,
          407,
          286,
          733,
          295,
          528,
          281,
          445,
          767,
          733,
          295,
          1286,
          2286,
          293,
          10023,
          670,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16160480046676376,
        "compression_ratio": 1.6569343065693432,
        "end": 1632.6,
        "id": 367,
        "no_speech_prob": 0.0014779308112338185,
        "seek": 160460,
        "start": 1627.6,
        "temperature": 0,
        "text": " But the reason why I was mentioning this is there's a long history of this.",
        "tokens": [
          51514,
          583,
          264,
          1778,
          983,
          286,
          390,
          18315,
          341,
          307,
          456,
          311,
          257,
          938,
          2503,
          295,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16961521572536892,
        "compression_ratio": 1.8868778280542986,
        "end": 1639.6,
        "id": 368,
        "no_speech_prob": 0.007011726498603821,
        "seek": 163260,
        "start": 1632.6,
        "temperature": 0,
        "text": " And the very first discovery of an artificial neural network, and I'm going to build one of these in a future coding challenge, is called a perceptron.",
        "tokens": [
          50364,
          400,
          264,
          588,
          700,
          12114,
          295,
          364,
          11677,
          18161,
          3209,
          11,
          293,
          286,
          478,
          516,
          281,
          1322,
          472,
          295,
          613,
          294,
          257,
          2027,
          17720,
          3430,
          11,
          307,
          1219,
          257,
          43276,
          2044,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16961521572536892,
        "compression_ratio": 1.8868778280542986,
        "end": 1644.6,
        "id": 369,
        "no_speech_prob": 0.007011726498603821,
        "seek": 163260,
        "start": 1639.6,
        "temperature": 0,
        "text": " Which is almost wrong to call it a network because it's a single neuron.",
        "tokens": [
          50714,
          3013,
          307,
          1920,
          2085,
          281,
          818,
          309,
          257,
          3209,
          570,
          309,
          311,
          257,
          2167,
          34090,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16961521572536892,
        "compression_ratio": 1.8868778280542986,
        "end": 1646.6,
        "id": 370,
        "no_speech_prob": 0.007011726498603821,
        "seek": 163260,
        "start": 1644.6,
        "temperature": 0,
        "text": " So a model for a single neuron.",
        "tokens": [
          50964,
          407,
          257,
          2316,
          337,
          257,
          2167,
          34090,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16961521572536892,
        "compression_ratio": 1.8868778280542986,
        "end": 1650.6,
        "id": 371,
        "no_speech_prob": 0.007011726498603821,
        "seek": 163260,
        "start": 1646.6,
        "temperature": 0,
        "text": " An artificial neural network being a model for many interconnected neurons.",
        "tokens": [
          51064,
          1107,
          11677,
          18161,
          3209,
          885,
          257,
          2316,
          337,
          867,
          36611,
          22027,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16961521572536892,
        "compression_ratio": 1.8868778280542986,
        "end": 1652.6,
        "id": 372,
        "no_speech_prob": 0.007011726498603821,
        "seek": 163260,
        "start": 1650.6,
        "temperature": 0,
        "text": " Maybe it's a fully connected network.",
        "tokens": [
          51264,
          2704,
          309,
          311,
          257,
          4498,
          4582,
          3209,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16961521572536892,
        "compression_ratio": 1.8868778280542986,
        "end": 1655.6,
        "id": 373,
        "no_speech_prob": 0.007011726498603821,
        "seek": 163260,
        "start": 1652.6,
        "temperature": 0,
        "text": " Maybe it's like a partially connected network.",
        "tokens": [
          51364,
          2704,
          309,
          311,
          411,
          257,
          18886,
          4582,
          3209,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22611637438757945,
        "compression_ratio": 1.599290780141844,
        "end": 1663.6,
        "id": 374,
        "no_speech_prob": 0.32762372493743896,
        "seek": 165560,
        "start": 1655.6,
        "temperature": 0,
        "text": " But the reason why so much... that there has been a revolution in research and applications.",
        "tokens": [
          50364,
          583,
          264,
          1778,
          983,
          370,
          709,
          485,
          300,
          456,
          575,
          668,
          257,
          8894,
          294,
          2132,
          293,
          5821,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22611637438757945,
        "compression_ratio": 1.599290780141844,
        "end": 1670.6,
        "id": 375,
        "no_speech_prob": 0.32762372493743896,
        "seek": 165560,
        "start": 1663.6,
        "temperature": 0,
        "text": " Neural networks, when they were first discovered, this idea of a perceptron, couldn't solve very simple problems.",
        "tokens": [
          50764,
          1734,
          1807,
          9590,
          11,
          562,
          436,
          645,
          700,
          6941,
          11,
          341,
          1558,
          295,
          257,
          43276,
          2044,
          11,
          2809,
          380,
          5039,
          588,
          2199,
          2740,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22611637438757945,
        "compression_ratio": 1.599290780141844,
        "end": 1673.6,
        "id": 376,
        "no_speech_prob": 0.32762372493743896,
        "seek": 165560,
        "start": 1670.6,
        "temperature": 0,
        "text": " So there's a famous paper, the perceptron paper, McCullough-Pitts.",
        "tokens": [
          51114,
          407,
          456,
          311,
          257,
          4618,
          3035,
          11,
          264,
          43276,
          2044,
          3035,
          11,
          12061,
          858,
          581,
          12,
          47,
          593,
          82,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22611637438757945,
        "compression_ratio": 1.599290780141844,
        "end": 1675.6,
        "id": 377,
        "no_speech_prob": 0.32762372493743896,
        "seek": 165560,
        "start": 1673.6,
        "temperature": 0,
        "text": " I believe I'm getting that right.",
        "tokens": [
          51264,
          286,
          1697,
          286,
          478,
          1242,
          300,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22611637438757945,
        "compression_ratio": 1.599290780141844,
        "end": 1677.6,
        "id": 378,
        "no_speech_prob": 0.32762372493743896,
        "seek": 165560,
        "start": 1675.6,
        "temperature": 0,
        "text": " So I mean, the chat will confirm.",
        "tokens": [
          51364,
          407,
          286,
          914,
          11,
          264,
          5081,
          486,
          9064,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22611637438757945,
        "compression_ratio": 1.599290780141844,
        "end": 1680.6,
        "id": 379,
        "no_speech_prob": 0.32762372493743896,
        "seek": 165560,
        "start": 1677.6,
        "temperature": 0,
        "text": " I'll try to link to that information in this video's description.",
        "tokens": [
          51464,
          286,
          603,
          853,
          281,
          2113,
          281,
          300,
          1589,
          294,
          341,
          960,
          311,
          3855,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22611637438757945,
        "compression_ratio": 1.599290780141844,
        "end": 1682.6,
        "id": 380,
        "no_speech_prob": 0.32762372493743896,
        "seek": 165560,
        "start": 1680.6,
        "temperature": 0,
        "text": " And there were various steps along the way.",
        "tokens": [
          51614,
          400,
          456,
          645,
          3683,
          4439,
          2051,
          264,
          636,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1945535269650546,
        "compression_ratio": 1.6798029556650247,
        "end": 1688.6,
        "id": 381,
        "no_speech_prob": 0.04208569601178169,
        "seek": 168260,
        "start": 1682.6,
        "temperature": 0,
        "text": " But there was a long time before anyone was really able to do a lot of work with neural networks.",
        "tokens": [
          50364,
          583,
          456,
          390,
          257,
          938,
          565,
          949,
          2878,
          390,
          534,
          1075,
          281,
          360,
          257,
          688,
          295,
          589,
          365,
          18161,
          9590,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1945535269650546,
        "compression_ratio": 1.6798029556650247,
        "end": 1695.6,
        "id": 382,
        "no_speech_prob": 0.04208569601178169,
        "seek": 168260,
        "start": 1688.6,
        "temperature": 0,
        "text": " And so deep learning refers to the idea of a neural network which has a lot of depth to it.",
        "tokens": [
          50664,
          400,
          370,
          2452,
          2539,
          14942,
          281,
          264,
          1558,
          295,
          257,
          18161,
          3209,
          597,
          575,
          257,
          688,
          295,
          7161,
          281,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1945535269650546,
        "compression_ratio": 1.6798029556650247,
        "end": 1704.6,
        "id": 383,
        "no_speech_prob": 0.04208569601178169,
        "seek": 168260,
        "start": 1695.6,
        "temperature": 0,
        "text": " So in between the inputs and the outputs, output, and these could both be plural or singular, there are many, many, many layers.",
        "tokens": [
          51014,
          407,
          294,
          1296,
          264,
          15743,
          293,
          264,
          23930,
          11,
          5598,
          11,
          293,
          613,
          727,
          1293,
          312,
          25377,
          420,
          20010,
          11,
          456,
          366,
          867,
          11,
          867,
          11,
          867,
          7914,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1945535269650546,
        "compression_ratio": 1.6798029556650247,
        "end": 1707.6,
        "id": 384,
        "no_speech_prob": 0.04208569601178169,
        "seek": 168260,
        "start": 1704.6,
        "temperature": 0,
        "text": " It is deep. Very deep.",
        "tokens": [
          51464,
          467,
          307,
          2452,
          13,
          4372,
          2452,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23357782865825452,
        "compression_ratio": 1.6929133858267718,
        "end": 1711.6,
        "id": 385,
        "no_speech_prob": 0.0004044741508550942,
        "seek": 170760,
        "start": 1708.6,
        "temperature": 0,
        "text": " So you could imagine all of these connections.",
        "tokens": [
          50414,
          407,
          291,
          727,
          3811,
          439,
          295,
          613,
          9271,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23357782865825452,
        "compression_ratio": 1.6929133858267718,
        "end": 1716.6,
        "id": 386,
        "no_speech_prob": 0.0004044741508550942,
        "seek": 170760,
        "start": 1711.6,
        "temperature": 0,
        "text": " And so the idea here... and the training systems and how it works and how the learning system...",
        "tokens": [
          50564,
          400,
          370,
          264,
          1558,
          510,
          485,
          293,
          264,
          3097,
          3652,
          293,
          577,
          309,
          1985,
          293,
          577,
          264,
          2539,
          1185,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.23357782865825452,
        "compression_ratio": 1.6929133858267718,
        "end": 1719.6,
        "id": 387,
        "no_speech_prob": 0.0004044741508550942,
        "seek": 170760,
        "start": 1716.6,
        "temperature": 0,
        "text": " Ah, we've got to get into all that. But that's not for this video right here.",
        "tokens": [
          50814,
          2438,
          11,
          321,
          600,
          658,
          281,
          483,
          666,
          439,
          300,
          13,
          583,
          300,
          311,
          406,
          337,
          341,
          960,
          558,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23357782865825452,
        "compression_ratio": 1.6929133858267718,
        "end": 1723.6,
        "id": 388,
        "no_speech_prob": 0.0004044741508550942,
        "seek": 170760,
        "start": 1719.6,
        "temperature": 0,
        "text": " I got off on this tangent about neural networks.",
        "tokens": [
          50964,
          286,
          658,
          766,
          322,
          341,
          27747,
          466,
          18161,
          9590,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23357782865825452,
        "compression_ratio": 1.6929133858267718,
        "end": 1728.6,
        "id": 389,
        "no_speech_prob": 0.0004044741508550942,
        "seek": 170760,
        "start": 1723.6,
        "temperature": 0,
        "text": " So these are the different aspects of the pieces of this course that I would like to look at.",
        "tokens": [
          51164,
          407,
          613,
          366,
          264,
          819,
          7270,
          295,
          264,
          3755,
          295,
          341,
          1164,
          300,
          286,
          576,
          411,
          281,
          574,
          412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23357782865825452,
        "compression_ratio": 1.6929133858267718,
        "end": 1730.6,
        "id": 390,
        "no_speech_prob": 0.0004044741508550942,
        "seek": 170760,
        "start": 1728.6,
        "temperature": 0,
        "text": " Now, let me come back over here.",
        "tokens": [
          51414,
          823,
          11,
          718,
          385,
          808,
          646,
          670,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23357782865825452,
        "compression_ratio": 1.6929133858267718,
        "end": 1735.6,
        "id": 391,
        "no_speech_prob": 0.0004044741508550942,
        "seek": 170760,
        "start": 1733.6,
        "temperature": 0,
        "text": " Okay, I'm coming back over here.",
        "tokens": [
          51664,
          1033,
          11,
          286,
          478,
          1348,
          646,
          670,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1737.6,
        "id": 392,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1736.6,
        "temperature": 0,
        "text": " Anybody...",
        "tokens": [
          50414,
          19082,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1745.6,
        "id": 393,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1741.6,
        "temperature": 0,
        "text": " Oh, someone sent me an amount of time so far.",
        "tokens": [
          50664,
          876,
          11,
          1580,
          2279,
          385,
          364,
          2372,
          295,
          565,
          370,
          1400,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1748.6,
        "id": 394,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1745.6,
        "temperature": 0,
        "text": " About 10 minutes. A few minutes ago. Great.",
        "tokens": [
          50864,
          7769,
          1266,
          2077,
          13,
          316,
          1326,
          2077,
          2057,
          13,
          3769,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1750.6,
        "id": 395,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1748.6,
        "temperature": 0,
        "text": " Okay, that's good.",
        "tokens": [
          51014,
          1033,
          11,
          300,
          311,
          665,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1753.6,
        "id": 396,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1752.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1754.6,
        "id": 397,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1753.6,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          51264,
          407,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1758.6,
        "id": 398,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1754.6,
        "temperature": 0,
        "text": " Anybody want to fact check my McCullough-Pitts reference?",
        "tokens": [
          51314,
          19082,
          528,
          281,
          1186,
          1520,
          452,
          12061,
          858,
          581,
          12,
          47,
          593,
          82,
          6408,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2497814608291841,
        "compression_ratio": 1.3051948051948052,
        "end": 1764.6,
        "id": 399,
        "no_speech_prob": 0.006796813104301691,
        "seek": 173560,
        "start": 1763.6,
        "temperature": 0,
        "text": " Perceptron.",
        "tokens": [
          51764,
          3026,
          1336,
          2044,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1769.6,
        "id": 400,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1766.6,
        "temperature": 0,
        "text": " McCullough-Pitts and perceptron models.",
        "tokens": [
          50414,
          12061,
          858,
          581,
          12,
          47,
          593,
          82,
          293,
          43276,
          2044,
          5245,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1770.6,
        "id": 401,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1769.6,
        "temperature": 0,
        "text": " McCullough-Pitts model.",
        "tokens": [
          50564,
          12061,
          858,
          581,
          12,
          47,
          593,
          82,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1772.6,
        "id": 402,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1770.6,
        "temperature": 0,
        "text": " So I must be right.",
        "tokens": [
          50614,
          407,
          286,
          1633,
          312,
          558,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1773.6,
        "id": 403,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1772.6,
        "temperature": 0,
        "text": " Okay, good.",
        "tokens": [
          50714,
          1033,
          11,
          665,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1775.6,
        "id": 404,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1774.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1778.6,
        "id": 405,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1777.6,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50964,
          2798,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1780.6,
        "id": 406,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1779.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1782.6,
        "id": 407,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1780.6,
        "temperature": 0,
        "text": " So, history of the perceptron.",
        "tokens": [
          51114,
          407,
          11,
          2503,
          295,
          264,
          43276,
          2044,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1787.6,
        "id": 408,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1782.6,
        "temperature": 0,
        "text": " I'm going to do stuff about the history and all that when I actually do neural networks, I think.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          360,
          1507,
          466,
          264,
          2503,
          293,
          439,
          300,
          562,
          286,
          767,
          360,
          18161,
          9590,
          11,
          286,
          519,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1789.6,
        "id": 409,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1787.6,
        "temperature": 0,
        "text": " So I'm coming back over here.",
        "tokens": [
          51464,
          407,
          286,
          478,
          1348,
          646,
          670,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1791.6,
        "id": 410,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1789.6,
        "temperature": 0,
        "text": " What was... oh, this would be open.",
        "tokens": [
          51564,
          708,
          390,
          485,
          1954,
          11,
          341,
          576,
          312,
          1269,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1793.6,
        "id": 411,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1791.6,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51664,
          400,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.18629011057190975,
        "compression_ratio": 1.5781990521327014,
        "end": 1794.6,
        "id": 412,
        "no_speech_prob": 0.0000453966531495098,
        "seek": 176560,
        "start": 1793.6,
        "temperature": 0,
        "text": " This was open.",
        "tokens": [
          51764,
          639,
          390,
          1269,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1796.6,
        "id": 413,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1795.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1798.6,
        "id": 414,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1796.6,
        "temperature": 0,
        "text": " And I probably zoomed in on this.",
        "tokens": [
          50414,
          400,
          286,
          1391,
          8863,
          292,
          294,
          322,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1799.6,
        "id": 415,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1798.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1801.6,
        "id": 416,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1799.6,
        "temperature": 0,
        "text": " So let me come back.",
        "tokens": [
          50564,
          407,
          718,
          385,
          808,
          646,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1805.6,
        "id": 417,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1802.6,
        "temperature": 0,
        "text": " Okay, so let me take a look at the list of topics.",
        "tokens": [
          50714,
          1033,
          11,
          370,
          718,
          385,
          747,
          257,
          574,
          412,
          264,
          1329,
          295,
          8378,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1808.6,
        "id": 418,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1805.6,
        "temperature": 0,
        "text": " I'm going to skip week one for a second.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          10023,
          1243,
          472,
          337,
          257,
          1150,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1809.6,
        "id": 419,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1808.6,
        "temperature": 0,
        "text": " So this is the course.",
        "tokens": [
          51014,
          407,
          341,
          307,
          264,
          1164,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1812.6,
        "id": 420,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1809.6,
        "temperature": 0,
        "text": " If you want, this URL will be in the video's description.",
        "tokens": [
          51064,
          759,
          291,
          528,
          11,
          341,
          12905,
          486,
          312,
          294,
          264,
          960,
          311,
          3855,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1816.6,
        "id": 421,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1812.6,
        "temperature": 0,
        "text": " This is the syllabus for the course.",
        "tokens": [
          51214,
          639,
          307,
          264,
          48077,
          337,
          264,
          1164,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1817.6,
        "id": 422,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1816.6,
        "temperature": 0,
        "text": " It's kind of my working document.",
        "tokens": [
          51414,
          467,
          311,
          733,
          295,
          452,
          1364,
          4166,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15584419513570852,
        "compression_ratio": 1.5512820512820513,
        "end": 1820.6,
        "id": 423,
        "no_speech_prob": 0.0005792785668745637,
        "seek": 179560,
        "start": 1817.6,
        "temperature": 0,
        "text": " Boy, do I accept any and all contributions and help.",
        "tokens": [
          51464,
          9486,
          11,
          360,
          286,
          3241,
          604,
          293,
          439,
          15725,
          293,
          854,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1825.6,
        "id": 424,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1820.6,
        "temperature": 0,
        "text": " So feel free to file GitHub issues and pull requests and things.",
        "tokens": [
          50364,
          407,
          841,
          1737,
          281,
          3991,
          23331,
          2663,
          293,
          2235,
          12475,
          293,
          721,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1827.6,
        "id": 425,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1825.6,
        "temperature": 0,
        "text": " And if I come down here to the...",
        "tokens": [
          50614,
          400,
          498,
          286,
          808,
          760,
          510,
          281,
          264,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1830.6,
        "id": 426,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1827.6,
        "temperature": 0,
        "text": " Oh, and I'm kind of in a place where you can't really see it.",
        "tokens": [
          50714,
          876,
          11,
          293,
          286,
          478,
          733,
          295,
          294,
          257,
          1081,
          689,
          291,
          393,
          380,
          534,
          536,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1832.6,
        "id": 427,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1830.6,
        "temperature": 0,
        "text": " I'm going to skip over week one.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          10023,
          670,
          1243,
          472,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1834.6,
        "id": 428,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1832.6,
        "temperature": 0,
        "text": " And so here are my topics.",
        "tokens": [
          50964,
          400,
          370,
          510,
          366,
          452,
          8378,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1836.6,
        "id": 429,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1834.6,
        "temperature": 0,
        "text": " So I'm going to go through these kind of quickly.",
        "tokens": [
          51064,
          407,
          286,
          478,
          516,
          281,
          352,
          807,
          613,
          733,
          295,
          2661,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1838.6,
        "id": 430,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1836.6,
        "temperature": 0,
        "text": " Again, this is very survey-oriented.",
        "tokens": [
          51164,
          3764,
          11,
          341,
          307,
          588,
          8984,
          12,
          27414,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1840.6,
        "id": 431,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1838.6,
        "temperature": 0,
        "text": " And I'm missing a ton of stuff.",
        "tokens": [
          51264,
          400,
          286,
          478,
          5361,
          257,
          2952,
          295,
          1507,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1844.6,
        "id": 432,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1840.6,
        "temperature": 0,
        "text": " So this is just a selection, but I'm also still figuring this out.",
        "tokens": [
          51364,
          407,
          341,
          307,
          445,
          257,
          9450,
          11,
          457,
          286,
          478,
          611,
          920,
          15213,
          341,
          484,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17459433618253165,
        "compression_ratio": 1.669064748201439,
        "end": 1847.6,
        "id": 433,
        "no_speech_prob": 0.05664797127246857,
        "seek": 182060,
        "start": 1844.6,
        "temperature": 0,
        "text": " So next week, I'm going to talk about genetic algorithms,",
        "tokens": [
          51564,
          407,
          958,
          1243,
          11,
          286,
          478,
          516,
          281,
          751,
          466,
          12462,
          14642,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1851.6,
        "id": 434,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1847.6,
        "temperature": 0,
        "text": " which is an evolutionary-based approach to solving problems with...",
        "tokens": [
          50364,
          597,
          307,
          364,
          27567,
          12,
          6032,
          3109,
          281,
          12606,
          2740,
          365,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1853.6,
        "id": 435,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1851.6,
        "temperature": 0,
        "text": " which is a way of solving problems in software,",
        "tokens": [
          50564,
          597,
          307,
          257,
          636,
          295,
          12606,
          2740,
          294,
          4722,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1856.6,
        "id": 436,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1853.6,
        "temperature": 0,
        "text": " taking inspiration from evolutionary processes in nature.",
        "tokens": [
          50664,
          1940,
          10249,
          490,
          27567,
          7555,
          294,
          3687,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1858.6,
        "id": 437,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1856.6,
        "temperature": 0,
        "text": " So I already have a bunch of videos on that,",
        "tokens": [
          50814,
          407,
          286,
          1217,
          362,
          257,
          3840,
          295,
          2145,
          322,
          300,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1860.6,
        "id": 438,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1858.6,
        "temperature": 0,
        "text": " and I'll do some more content about that as well.",
        "tokens": [
          50914,
          293,
          286,
          603,
          360,
          512,
          544,
          2701,
          466,
          300,
          382,
          731,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1862.6,
        "id": 439,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1860.6,
        "temperature": 0,
        "text": " And that will be in next week.",
        "tokens": [
          51014,
          400,
          300,
          486,
          312,
          294,
          958,
          1243,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1865.6,
        "id": 440,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1862.6,
        "temperature": 0,
        "text": " This should say classification and regression.",
        "tokens": [
          51114,
          639,
          820,
          584,
          21538,
          293,
          24590,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1870.6,
        "id": 441,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1865.6,
        "temperature": 0,
        "text": " And recently I learned that the term regression comes from regression to the mean.",
        "tokens": [
          51264,
          400,
          3938,
          286,
          3264,
          300,
          264,
          1433,
          24590,
          1487,
          490,
          24590,
          281,
          264,
          914,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1873.6,
        "id": 442,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1870.6,
        "temperature": 0,
        "text": " And this is like a 19th century concept.",
        "tokens": [
          51514,
          400,
          341,
          307,
          411,
          257,
          1294,
          392,
          4901,
          3410,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18243264059984046,
        "compression_ratio": 1.706451612903226,
        "end": 1875.6,
        "id": 443,
        "no_speech_prob": 0.10374100506305695,
        "seek": 184760,
        "start": 1873.6,
        "temperature": 0,
        "text": " But anyway, I'll talk about where I'm getting all my info.",
        "tokens": [
          51664,
          583,
          4033,
          11,
          286,
          603,
          751,
          466,
          689,
          286,
          478,
          1242,
          439,
          452,
          294,
          16931,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1877.6,
        "id": 444,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1875.6,
        "temperature": 0,
        "text": " I just read a bunch of books in the last week.",
        "tokens": [
          50364,
          286,
          445,
          1401,
          257,
          3840,
          295,
          3642,
          294,
          264,
          1036,
          1243,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1882.6,
        "id": 445,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1877.6,
        "temperature": 0,
        "text": " I have to thank all these people that I'm probably messing up all the stuff that I read.",
        "tokens": [
          50464,
          286,
          362,
          281,
          1309,
          439,
          613,
          561,
          300,
          286,
          478,
          1391,
          23258,
          493,
          439,
          264,
          1507,
          300,
          286,
          1401,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1885.6,
        "id": 446,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1882.6,
        "temperature": 0,
        "text": " But I want to get interested in those...",
        "tokens": [
          50714,
          583,
          286,
          528,
          281,
          483,
          3102,
          294,
          729,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1890.6,
        "id": 447,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1885.6,
        "temperature": 0,
        "text": " I want to get started with those tasks without using neural network-based models.",
        "tokens": [
          50864,
          286,
          528,
          281,
          483,
          1409,
          365,
          729,
          9608,
          1553,
          1228,
          18161,
          3209,
          12,
          6032,
          5245,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1892.6,
        "id": 448,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1890.6,
        "temperature": 0,
        "text": " So something called k-nearest neighbor.",
        "tokens": [
          51114,
          407,
          746,
          1219,
          350,
          12,
          716,
          17363,
          5987,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1896.6,
        "id": 449,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1892.6,
        "temperature": 0,
        "text": " One of the things I would like to do is build a simple movie recommendation system",
        "tokens": [
          51214,
          1485,
          295,
          264,
          721,
          286,
          576,
          411,
          281,
          360,
          307,
          1322,
          257,
          2199,
          3169,
          11879,
          1185,
          51414
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1897.6,
        "id": 450,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1896.6,
        "temperature": 0,
        "text": " with k-nearest neighbor as an idea.",
        "tokens": [
          51414,
          365,
          350,
          12,
          716,
          17363,
          5987,
          382,
          364,
          1558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1901.6,
        "id": 451,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1897.6,
        "temperature": 0,
        "text": " If you have an idea for a data set or an interesting creative application for k-nearest neighbor",
        "tokens": [
          51464,
          759,
          291,
          362,
          364,
          1558,
          337,
          257,
          1412,
          992,
          420,
          364,
          1880,
          5880,
          3861,
          337,
          350,
          12,
          716,
          17363,
          5987,
          51664
        ]
      },
      {
        "avg_logprob": -0.18163987244067548,
        "compression_ratio": 1.864516129032258,
        "end": 1904.6,
        "id": 452,
        "no_speech_prob": 0.1540364772081375,
        "seek": 187560,
        "start": 1901.6,
        "temperature": 0,
        "text": " that's very simple with a simple data set that I can work with,",
        "tokens": [
          51664,
          300,
          311,
          588,
          2199,
          365,
          257,
          2199,
          1412,
          992,
          300,
          286,
          393,
          589,
          365,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.2131564594874872,
        "compression_ratio": 1.722943722943723,
        "end": 1906.6,
        "id": 453,
        "no_speech_prob": 0.0017273962730541825,
        "seek": 190460,
        "start": 1904.6,
        "temperature": 0,
        "text": " I would love that suggestion.",
        "tokens": [
          50364,
          286,
          576,
          959,
          300,
          16541,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2131564594874872,
        "compression_ratio": 1.722943722943723,
        "end": 1908.6,
        "id": 454,
        "no_speech_prob": 0.0017273962730541825,
        "seek": 190460,
        "start": 1906.6,
        "temperature": 0,
        "text": " And also linear regression.",
        "tokens": [
          50464,
          400,
          611,
          8213,
          24590,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2131564594874872,
        "compression_ratio": 1.722943722943723,
        "end": 1913.6,
        "id": 455,
        "no_speech_prob": 0.0017273962730541825,
        "seek": 190460,
        "start": 1908.6,
        "temperature": 0,
        "text": " So I want to do an example of the simplest form of regression.",
        "tokens": [
          50564,
          407,
          286,
          528,
          281,
          360,
          364,
          1365,
          295,
          264,
          22811,
          1254,
          295,
          24590,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2131564594874872,
        "compression_ratio": 1.722943722943723,
        "end": 1921.6,
        "id": 456,
        "no_speech_prob": 0.0017273962730541825,
        "seek": 190460,
        "start": 1913.6,
        "temperature": 0,
        "text": " And we can think of that with an input and having an output that's a continuous floating point value.",
        "tokens": [
          50814,
          400,
          321,
          393,
          519,
          295,
          300,
          365,
          364,
          4846,
          293,
          1419,
          364,
          5598,
          300,
          311,
          257,
          10957,
          12607,
          935,
          2158,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2131564594874872,
        "compression_ratio": 1.722943722943723,
        "end": 1922.6,
        "id": 457,
        "no_speech_prob": 0.0017273962730541825,
        "seek": 190460,
        "start": 1921.6,
        "temperature": 0,
        "text": " So I want to look at that.",
        "tokens": [
          51214,
          407,
          286,
          528,
          281,
          574,
          412,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2131564594874872,
        "compression_ratio": 1.722943722943723,
        "end": 1925.6,
        "id": 458,
        "no_speech_prob": 0.0017273962730541825,
        "seek": 190460,
        "start": 1922.6,
        "temperature": 0,
        "text": " And when we'll do that, we're going to get all this stuff like,",
        "tokens": [
          51264,
          400,
          562,
          321,
          603,
          360,
          300,
          11,
          321,
          434,
          516,
          281,
          483,
          439,
          341,
          1507,
          411,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2131564594874872,
        "compression_ratio": 1.722943722943723,
        "end": 1929.6,
        "id": 459,
        "no_speech_prob": 0.0017273962730541825,
        "seek": 190460,
        "start": 1925.6,
        "temperature": 0,
        "text": " oh, there's a learning rate, what's this gradient descent thing, and all this stuff.",
        "tokens": [
          51414,
          1954,
          11,
          456,
          311,
          257,
          2539,
          3314,
          11,
          437,
          311,
          341,
          16235,
          23475,
          551,
          11,
          293,
          439,
          341,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19235367071433146,
        "compression_ratio": 1.6710963455149501,
        "end": 1933.6,
        "id": 460,
        "no_speech_prob": 0.06371112167835236,
        "seek": 192960,
        "start": 1929.6,
        "temperature": 0,
        "text": " So hopefully, kind of defining some of those terminology and understanding those pieces",
        "tokens": [
          50364,
          407,
          4696,
          11,
          733,
          295,
          17827,
          512,
          295,
          729,
          27575,
          293,
          3701,
          729,
          3755,
          50564
        ]
      },
      {
        "avg_logprob": -0.19235367071433146,
        "compression_ratio": 1.6710963455149501,
        "end": 1936.6,
        "id": 461,
        "no_speech_prob": 0.06371112167835236,
        "seek": 192960,
        "start": 1933.6,
        "temperature": 0,
        "text": " as we look at k-nearest neighbor and linear regression",
        "tokens": [
          50564,
          382,
          321,
          574,
          412,
          350,
          12,
          716,
          17363,
          5987,
          293,
          8213,
          24590,
          50714
        ]
      },
      {
        "avg_logprob": -0.19235367071433146,
        "compression_ratio": 1.6710963455149501,
        "end": 1941.6,
        "id": 462,
        "no_speech_prob": 0.06371112167835236,
        "seek": 192960,
        "start": 1936.6,
        "temperature": 0,
        "text": " will give us a leg up for the next week when we look at neural networks.",
        "tokens": [
          50714,
          486,
          976,
          505,
          257,
          1676,
          493,
          337,
          264,
          958,
          1243,
          562,
          321,
          574,
          412,
          18161,
          9590,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19235367071433146,
        "compression_ratio": 1.6710963455149501,
        "end": 1947.6,
        "id": 463,
        "no_speech_prob": 0.06371112167835236,
        "seek": 192960,
        "start": 1941.6,
        "temperature": 0,
        "text": " So I would like to build some simple neural network examples from scratch.",
        "tokens": [
          50964,
          407,
          286,
          576,
          411,
          281,
          1322,
          512,
          2199,
          18161,
          3209,
          5110,
          490,
          8459,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19235367071433146,
        "compression_ratio": 1.6710963455149501,
        "end": 1952.6,
        "id": 464,
        "no_speech_prob": 0.06371112167835236,
        "seek": 192960,
        "start": 1947.6,
        "temperature": 0,
        "text": " And all of this stuff I'm going to do so far probably in processing or JavaScript",
        "tokens": [
          51264,
          400,
          439,
          295,
          341,
          1507,
          286,
          478,
          516,
          281,
          360,
          370,
          1400,
          1391,
          294,
          9007,
          420,
          15778,
          51514
        ]
      },
      {
        "avg_logprob": -0.19235367071433146,
        "compression_ratio": 1.6710963455149501,
        "end": 1955.6,
        "id": 465,
        "no_speech_prob": 0.06371112167835236,
        "seek": 192960,
        "start": 1952.6,
        "temperature": 0,
        "text": " using the p5.js library, some combination of those things.",
        "tokens": [
          51514,
          1228,
          264,
          280,
          20,
          13,
          25530,
          6405,
          11,
          512,
          6562,
          295,
          729,
          721,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19235367071433146,
        "compression_ratio": 1.6710963455149501,
        "end": 1958.6,
        "id": 466,
        "no_speech_prob": 0.06371112167835236,
        "seek": 192960,
        "start": 1955.6,
        "temperature": 0,
        "text": " So if we want to build a perceptron, you know, if I'm feeling ambitious",
        "tokens": [
          51664,
          407,
          498,
          321,
          528,
          281,
          1322,
          257,
          43276,
          2044,
          11,
          291,
          458,
          11,
          498,
          286,
          478,
          2633,
          20239,
          51814
        ]
      },
      {
        "avg_logprob": -0.17523216532769603,
        "compression_ratio": 1.7509727626459144,
        "end": 1962.6,
        "id": 467,
        "no_speech_prob": 0.00023782109201420099,
        "seek": 195860,
        "start": 1958.6,
        "temperature": 0,
        "text": " we might look at what happens if instead of a perceptron we have a multi-layered network.",
        "tokens": [
          50364,
          321,
          1062,
          574,
          412,
          437,
          2314,
          498,
          2602,
          295,
          257,
          43276,
          2044,
          321,
          362,
          257,
          4825,
          12,
          8376,
          4073,
          3209,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17523216532769603,
        "compression_ratio": 1.7509727626459144,
        "end": 1967.6,
        "id": 468,
        "no_speech_prob": 0.00023782109201420099,
        "seek": 195860,
        "start": 1962.6,
        "temperature": 0,
        "text": " And all of this, you can think of the neural network as like you're tuning all of these knobs",
        "tokens": [
          50564,
          400,
          439,
          295,
          341,
          11,
          291,
          393,
          519,
          295,
          264,
          18161,
          3209,
          382,
          411,
          291,
          434,
          15164,
          439,
          295,
          613,
          46999,
          50814
        ]
      },
      {
        "avg_logprob": -0.17523216532769603,
        "compression_ratio": 1.7509727626459144,
        "end": 1971.6,
        "id": 469,
        "no_speech_prob": 0.00023782109201420099,
        "seek": 195860,
        "start": 1967.6,
        "temperature": 0,
        "text": " so that the output gives you something that's correct.",
        "tokens": [
          50814,
          370,
          300,
          264,
          5598,
          2709,
          291,
          746,
          300,
          311,
          3006,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17523216532769603,
        "compression_ratio": 1.7509727626459144,
        "end": 1975.6,
        "id": 470,
        "no_speech_prob": 0.00023782109201420099,
        "seek": 195860,
        "start": 1971.6,
        "temperature": 0,
        "text": " There's a whole training process that we're going to have to discuss called supervised learning.",
        "tokens": [
          51014,
          821,
          311,
          257,
          1379,
          3097,
          1399,
          300,
          321,
          434,
          516,
          281,
          362,
          281,
          2248,
          1219,
          46533,
          2539,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17523216532769603,
        "compression_ratio": 1.7509727626459144,
        "end": 1978.6,
        "id": 471,
        "no_speech_prob": 0.00023782109201420099,
        "seek": 195860,
        "start": 1975.6,
        "temperature": 0,
        "text": " Supervised learning, unsupervised learning, reinforcement learning.",
        "tokens": [
          51214,
          4548,
          24420,
          2539,
          11,
          2693,
          12879,
          24420,
          2539,
          11,
          29280,
          2539,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17523216532769603,
        "compression_ratio": 1.7509727626459144,
        "end": 1981.6,
        "id": 472,
        "no_speech_prob": 0.00023782109201420099,
        "seek": 195860,
        "start": 1978.6,
        "temperature": 0,
        "text": " Interesting topics that I'm going to get into.",
        "tokens": [
          51364,
          14711,
          8378,
          300,
          286,
          478,
          516,
          281,
          483,
          666,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24815789089407972,
        "compression_ratio": 1.5701357466063348,
        "end": 1989.6,
        "id": 473,
        "no_speech_prob": 0.02758389338850975,
        "seek": 198160,
        "start": 1982.6,
        "temperature": 0,
        "text": " But one of the most complex aspects of neural networks is what do you do,",
        "tokens": [
          50414,
          583,
          472,
          295,
          264,
          881,
          3997,
          7270,
          295,
          18161,
          9590,
          307,
          437,
          360,
          291,
          360,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.24815789089407972,
        "compression_ratio": 1.5701357466063348,
        "end": 1991.6,
        "id": 474,
        "no_speech_prob": 0.02758389338850975,
        "seek": 198160,
        "start": 1989.6,
        "temperature": 0,
        "text": " how do you train all that stuff that's in the middle?",
        "tokens": [
          50764,
          577,
          360,
          291,
          3847,
          439,
          300,
          1507,
          300,
          311,
          294,
          264,
          2808,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.24815789089407972,
        "compression_ratio": 1.5701357466063348,
        "end": 1995.6,
        "id": 475,
        "no_speech_prob": 0.02758389338850975,
        "seek": 198160,
        "start": 1991.6,
        "temperature": 0,
        "text": " And so there's a concept known as back propagation that I...",
        "tokens": [
          50864,
          400,
          370,
          456,
          311,
          257,
          3410,
          2570,
          382,
          646,
          38377,
          300,
          286,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.24815789089407972,
        "compression_ratio": 1.5701357466063348,
        "end": 2001.6,
        "id": 476,
        "no_speech_prob": 0.02758389338850975,
        "seek": 198160,
        "start": 1995.6,
        "temperature": 0,
        "text": " That's like almost like quaternions for me, but I'm not running out of the room just yet.",
        "tokens": [
          51064,
          663,
          311,
          411,
          1920,
          411,
          421,
          771,
          77,
          626,
          337,
          385,
          11,
          457,
          286,
          478,
          406,
          2614,
          484,
          295,
          264,
          1808,
          445,
          1939,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24815789089407972,
        "compression_ratio": 1.5701357466063348,
        "end": 2005.6,
        "id": 477,
        "no_speech_prob": 0.02758389338850975,
        "seek": 198160,
        "start": 2001.6,
        "temperature": 0,
        "text": " And once I get to there, I want to investigate some other platforms.",
        "tokens": [
          51364,
          400,
          1564,
          286,
          483,
          281,
          456,
          11,
          286,
          528,
          281,
          15013,
          512,
          661,
          9473,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24277069545028232,
        "compression_ratio": 1.672,
        "end": 2008.6,
        "id": 478,
        "no_speech_prob": 0.3241727650165558,
        "seek": 200560,
        "start": 2005.6,
        "temperature": 0,
        "text": " I might, I might, all this is, I might.",
        "tokens": [
          50364,
          286,
          1062,
          11,
          286,
          1062,
          11,
          439,
          341,
          307,
          11,
          286,
          1062,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24277069545028232,
        "compression_ratio": 1.672,
        "end": 2014.6,
        "id": 479,
        "no_speech_prob": 0.3241727650165558,
        "seek": 200560,
        "start": 2008.6,
        "temperature": 0,
        "text": " But my plan and hope is to look a bit at, once we've built some simple examples from scratch,",
        "tokens": [
          50514,
          583,
          452,
          1393,
          293,
          1454,
          307,
          281,
          574,
          257,
          857,
          412,
          11,
          1564,
          321,
          600,
          3094,
          512,
          2199,
          5110,
          490,
          8459,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.24277069545028232,
        "compression_ratio": 1.672,
        "end": 2020.6,
        "id": 480,
        "no_speech_prob": 0.3241727650165558,
        "seek": 200560,
        "start": 2014.6,
        "temperature": 0,
        "text": " to look at other tools for some more sophisticated applications like TensorFlow",
        "tokens": [
          50814,
          281,
          574,
          412,
          661,
          3873,
          337,
          512,
          544,
          16950,
          5821,
          411,
          37624,
          51114
        ]
      },
      {
        "avg_logprob": -0.24277069545028232,
        "compression_ratio": 1.672,
        "end": 2024.6,
        "id": 481,
        "no_speech_prob": 0.3241727650165558,
        "seek": 200560,
        "start": 2020.6,
        "temperature": 0,
        "text": " and then be able to get into certain specific kinds of neural networks",
        "tokens": [
          51114,
          293,
          550,
          312,
          1075,
          281,
          483,
          666,
          1629,
          2685,
          3685,
          295,
          18161,
          9590,
          51314
        ]
      },
      {
        "avg_logprob": -0.24277069545028232,
        "compression_ratio": 1.672,
        "end": 2026.6,
        "id": 482,
        "no_speech_prob": 0.3241727650165558,
        "seek": 200560,
        "start": 2024.6,
        "temperature": 0,
        "text": " that can do different kinds of tasks.",
        "tokens": [
          51314,
          300,
          393,
          360,
          819,
          3685,
          295,
          9608,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24277069545028232,
        "compression_ratio": 1.672,
        "end": 2031.6,
        "id": 483,
        "no_speech_prob": 0.3241727650165558,
        "seek": 200560,
        "start": 2026.6,
        "temperature": 0,
        "text": " What is a convolution network, what is a recurrent network, and what is reinforcement learning?",
        "tokens": [
          51414,
          708,
          307,
          257,
          45216,
          3209,
          11,
          437,
          307,
          257,
          18680,
          1753,
          3209,
          11,
          293,
          437,
          307,
          29280,
          2539,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2034.6,
        "id": 484,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2031.6,
        "temperature": 0,
        "text": " So those are some aspects of things and, you know,",
        "tokens": [
          50364,
          407,
          729,
          366,
          512,
          7270,
          295,
          721,
          293,
          11,
          291,
          458,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2039.6,
        "id": 485,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2034.6,
        "temperature": 0,
        "text": " I don't plan on building those larger, more sophisticated systems from scratch.",
        "tokens": [
          50514,
          286,
          500,
          380,
          1393,
          322,
          2390,
          729,
          4833,
          11,
          544,
          16950,
          3652,
          490,
          8459,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2042.6,
        "id": 486,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2039.6,
        "temperature": 0,
        "text": " But if we can build some basic ones, understand how everything works,",
        "tokens": [
          50764,
          583,
          498,
          321,
          393,
          1322,
          512,
          3875,
          2306,
          11,
          1223,
          577,
          1203,
          1985,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2048.6,
        "id": 487,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2042.6,
        "temperature": 0,
        "text": " then my thinking is then we will have a leg up to using frameworks and tools to do some of the other stuff.",
        "tokens": [
          50914,
          550,
          452,
          1953,
          307,
          550,
          321,
          486,
          362,
          257,
          1676,
          493,
          281,
          1228,
          29834,
          293,
          3873,
          281,
          360,
          512,
          295,
          264,
          661,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2050.6,
        "id": 488,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2048.6,
        "temperature": 0,
        "text": " Again, all this is subject to change.",
        "tokens": [
          51214,
          3764,
          11,
          439,
          341,
          307,
          3983,
          281,
          1319,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2053.6,
        "id": 489,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2050.6,
        "temperature": 0,
        "text": " One of the things I mentioned this last week that I'm hoping to do,",
        "tokens": [
          51314,
          1485,
          295,
          264,
          721,
          286,
          2835,
          341,
          1036,
          1243,
          300,
          286,
          478,
          7159,
          281,
          360,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2057.6,
        "id": 490,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2053.6,
        "temperature": 0,
        "text": " because even though I might move to something like TensorFlow and Python",
        "tokens": [
          51464,
          570,
          754,
          1673,
          286,
          1062,
          1286,
          281,
          746,
          411,
          37624,
          293,
          15329,
          51664
        ]
      },
      {
        "avg_logprob": -0.1943726284813335,
        "compression_ratio": 1.6595744680851063,
        "end": 2060.6,
        "id": 491,
        "no_speech_prob": 0.12083081156015396,
        "seek": 203160,
        "start": 2057.6,
        "temperature": 0,
        "text": " to demonstrate some examples in some of these other areas,",
        "tokens": [
          51664,
          281,
          11698,
          512,
          5110,
          294,
          512,
          295,
          613,
          661,
          3179,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.24941102732782777,
        "compression_ratio": 1.4907749077490775,
        "end": 2065.6,
        "id": 492,
        "no_speech_prob": 0.05339862033724785,
        "seek": 206060,
        "start": 2060.6,
        "temperature": 0,
        "text": " I would love to work on a simple web server that runs TensorFlow in the background",
        "tokens": [
          50364,
          286,
          576,
          959,
          281,
          589,
          322,
          257,
          2199,
          3670,
          7154,
          300,
          6676,
          37624,
          294,
          264,
          3678,
          50614
        ]
      },
      {
        "avg_logprob": -0.24941102732782777,
        "compression_ratio": 1.4907749077490775,
        "end": 2067.6,
        "id": 493,
        "no_speech_prob": 0.05339862033724785,
        "seek": 206060,
        "start": 2065.6,
        "temperature": 0,
        "text": " that ProcessingerP5 could talk to.",
        "tokens": [
          50614,
          300,
          31093,
          278,
          260,
          47,
          20,
          727,
          751,
          281,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24941102732782777,
        "compression_ratio": 1.4907749077490775,
        "end": 2070.6,
        "id": 494,
        "no_speech_prob": 0.05339862033724785,
        "seek": 206060,
        "start": 2067.6,
        "temperature": 0,
        "text": " There are also examples of some of these written in JavaScript,",
        "tokens": [
          50714,
          821,
          366,
          611,
          5110,
          295,
          512,
          295,
          613,
          3720,
          294,
          15778,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.24941102732782777,
        "compression_ratio": 1.4907749077490775,
        "end": 2079.6,
        "id": 495,
        "no_speech_prob": 0.05339862033724785,
        "seek": 206060,
        "start": 2070.6,
        "temperature": 0,
        "text": " well-known examples by Andrej Karpathy, the recurrent RNN.js and ConvNet.js.",
        "tokens": [
          50864,
          731,
          12,
          6861,
          5110,
          538,
          20667,
          73,
          591,
          6529,
          9527,
          11,
          264,
          18680,
          1753,
          45702,
          45,
          13,
          25530,
          293,
          2656,
          85,
          31890,
          13,
          25530,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24941102732782777,
        "compression_ratio": 1.4907749077490775,
        "end": 2082.6,
        "id": 496,
        "no_speech_prob": 0.05339862033724785,
        "seek": 206060,
        "start": 2079.6,
        "temperature": 0,
        "text": " So, people are telling me time's up.",
        "tokens": [
          51314,
          407,
          11,
          561,
          366,
          3585,
          385,
          565,
          311,
          493,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24941102732782777,
        "compression_ratio": 1.4907749077490775,
        "end": 2085.6,
        "id": 497,
        "no_speech_prob": 0.05339862033724785,
        "seek": 206060,
        "start": 2082.6,
        "temperature": 0,
        "text": " I'm doing this live, but you might be watching this in an archive,",
        "tokens": [
          51464,
          286,
          478,
          884,
          341,
          1621,
          11,
          457,
          291,
          1062,
          312,
          1976,
          341,
          294,
          364,
          23507,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.24941102732782777,
        "compression_ratio": 1.4907749077490775,
        "end": 2087.6,
        "id": 498,
        "no_speech_prob": 0.05339862033724785,
        "seek": 206060,
        "start": 2085.6,
        "temperature": 0,
        "text": " that I wanted to keep this to 20 minutes.",
        "tokens": [
          51614,
          300,
          286,
          1415,
          281,
          1066,
          341,
          281,
          945,
          2077,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18908537650594906,
        "compression_ratio": 1.569377990430622,
        "end": 2090.6,
        "id": 499,
        "no_speech_prob": 0.0008969267946667969,
        "seek": 208760,
        "start": 2087.6,
        "temperature": 0,
        "text": " Sound is low. Okay. Hold on. Time out.",
        "tokens": [
          50364,
          14673,
          307,
          2295,
          13,
          1033,
          13,
          6962,
          322,
          13,
          6161,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18908537650594906,
        "compression_ratio": 1.569377990430622,
        "end": 2096.6,
        "id": 500,
        "no_speech_prob": 0.0008969267946667969,
        "seek": 208760,
        "start": 2093.6,
        "temperature": 0,
        "text": " Okay. Hold on. A lot of people are complaining about the sound.",
        "tokens": [
          50664,
          1033,
          13,
          6962,
          322,
          13,
          316,
          688,
          295,
          561,
          366,
          20740,
          466,
          264,
          1626,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18908537650594906,
        "compression_ratio": 1.569377990430622,
        "end": 2100.6,
        "id": 501,
        "no_speech_prob": 0.0008969267946667969,
        "seek": 208760,
        "start": 2096.6,
        "temperature": 0,
        "text": " Fortunately for everybody, I have a dial here that I can just turn it up.",
        "tokens": [
          50814,
          20652,
          337,
          2201,
          11,
          286,
          362,
          257,
          5502,
          510,
          300,
          286,
          393,
          445,
          1261,
          309,
          493,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18908537650594906,
        "compression_ratio": 1.569377990430622,
        "end": 2104.6,
        "id": 502,
        "no_speech_prob": 0.0008969267946667969,
        "seek": 208760,
        "start": 2102.6,
        "temperature": 0,
        "text": " Is that better? Is that better for everybody?",
        "tokens": [
          51114,
          1119,
          300,
          1101,
          30,
          1119,
          300,
          1101,
          337,
          2201,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.18908537650594906,
        "compression_ratio": 1.569377990430622,
        "end": 2106.6,
        "id": 503,
        "no_speech_prob": 0.0008969267946667969,
        "seek": 208760,
        "start": 2104.6,
        "temperature": 0,
        "text": " And is there any peaking or distortion?",
        "tokens": [
          51214,
          400,
          307,
          456,
          604,
          520,
          2456,
          420,
          28426,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.18908537650594906,
        "compression_ratio": 1.569377990430622,
        "end": 2109.6,
        "id": 504,
        "no_speech_prob": 0.0008969267946667969,
        "seek": 208760,
        "start": 2108.6,
        "temperature": 0,
        "text": " Let me know.",
        "tokens": [
          51414,
          961,
          385,
          458,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18908537650594906,
        "compression_ratio": 1.569377990430622,
        "end": 2116.6,
        "id": 505,
        "no_speech_prob": 0.0008969267946667969,
        "seek": 208760,
        "start": 2113.6,
        "temperature": 0,
        "text": " Sound is fine. Okay. Well, now it's up a little bit.",
        "tokens": [
          51664,
          14673,
          307,
          2489,
          13,
          1033,
          13,
          1042,
          11,
          586,
          309,
          311,
          493,
          257,
          707,
          857,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2121.6,
        "id": 506,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2118.6,
        "temperature": 0,
        "text": " I guess maybe I shouldn't have changed it for the...",
        "tokens": [
          50414,
          286,
          2041,
          1310,
          286,
          4659,
          380,
          362,
          3105,
          309,
          337,
          264,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2125.6,
        "id": 507,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2122.6,
        "temperature": 0,
        "text": " Okay. Everyone's saying sound is fine. I turned it up a little bit.",
        "tokens": [
          50614,
          1033,
          13,
          5198,
          311,
          1566,
          1626,
          307,
          2489,
          13,
          286,
          3574,
          309,
          493,
          257,
          707,
          857,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2127.6,
        "id": 508,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2125.6,
        "temperature": 0,
        "text": " Okay. I forgot what I was saying.",
        "tokens": [
          50764,
          1033,
          13,
          286,
          5298,
          437,
          286,
          390,
          1566,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2132.6,
        "id": 509,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2129.6,
        "temperature": 0,
        "text": " Okay. So...",
        "tokens": [
          50964,
          1033,
          13,
          407,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2135.6,
        "id": 510,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2133.6,
        "temperature": 0,
        "text": " I think I'm wrapping up then.",
        "tokens": [
          51164,
          286,
          519,
          286,
          478,
          21993,
          493,
          550,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2137.6,
        "id": 511,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2135.6,
        "temperature": 0,
        "text": " Okay. So, that's my introduction.",
        "tokens": [
          51264,
          1033,
          13,
          407,
          11,
          300,
          311,
          452,
          9339,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2140.6,
        "id": 512,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2138.6,
        "temperature": 0,
        "text": " You know, here's the thing. I'm learning this stuff.",
        "tokens": [
          51414,
          509,
          458,
          11,
          510,
          311,
          264,
          551,
          13,
          286,
          478,
          2539,
          341,
          1507,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.182162468586493,
        "compression_ratio": 1.5851528384279476,
        "end": 2144.6,
        "id": 513,
        "no_speech_prob": 0.0000468387188448105,
        "seek": 211760,
        "start": 2140.6,
        "temperature": 0,
        "text": " So, if you want to go watch a course from somebody who really knows this stuff,",
        "tokens": [
          51514,
          407,
          11,
          498,
          291,
          528,
          281,
          352,
          1159,
          257,
          1164,
          490,
          2618,
          567,
          534,
          3255,
          341,
          1507,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2146.6,
        "id": 514,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2144.6,
        "temperature": 0,
        "text": " I will link to lots of resources.",
        "tokens": [
          50364,
          286,
          486,
          2113,
          281,
          3195,
          295,
          3593,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2148.6,
        "id": 515,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2146.6,
        "temperature": 0,
        "text": " And that's what I meant to...",
        "tokens": [
          50464,
          400,
          300,
          311,
          437,
          286,
          4140,
          281,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2151.6,
        "id": 516,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2148.6,
        "temperature": 0,
        "text": " I wanted to mention some resources that I'm using.",
        "tokens": [
          50564,
          286,
          1415,
          281,
          2152,
          512,
          3593,
          300,
          286,
          478,
          1228,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2154.6,
        "id": 517,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2151.6,
        "temperature": 0,
        "text": " Very important that I will include in this video's description.",
        "tokens": [
          50714,
          4372,
          1021,
          300,
          286,
          486,
          4090,
          294,
          341,
          960,
          311,
          3855,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2158.6,
        "id": 518,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2154.6,
        "temperature": 0,
        "text": " And I think here under the wiki, under related projects and resources,",
        "tokens": [
          50864,
          400,
          286,
          519,
          510,
          833,
          264,
          261,
          9850,
          11,
          833,
          4077,
          4455,
          293,
          3593,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2164.6,
        "id": 519,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2159.6,
        "temperature": 0,
        "text": " here are some resources that I want to specifically mention.",
        "tokens": [
          51114,
          510,
          366,
          512,
          3593,
          300,
          286,
          528,
          281,
          4682,
          2152,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2167.6,
        "id": 520,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2165.6,
        "temperature": 0,
        "text": " So, one is a website called Machine Learning for Artists.",
        "tokens": [
          51414,
          407,
          11,
          472,
          307,
          257,
          3144,
          1219,
          22155,
          15205,
          337,
          5735,
          1751,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19423210286648473,
        "compression_ratio": 1.6951219512195121,
        "end": 2171.6,
        "id": 521,
        "no_speech_prob": 0.001115924445912242,
        "seek": 214460,
        "start": 2167.6,
        "temperature": 0,
        "text": " It's got videos, video tutorial, video lectures,",
        "tokens": [
          51514,
          467,
          311,
          658,
          2145,
          11,
          960,
          7073,
          11,
          960,
          16564,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2173.6,
        "id": 522,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2171.6,
        "temperature": 0,
        "text": " examples, written descriptions,",
        "tokens": [
          50364,
          5110,
          11,
          3720,
          24406,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2176.6,
        "id": 523,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2173.6,
        "temperature": 0,
        "text": " lots of wonderful things by an artist and researcher named Gene Kogan.",
        "tokens": [
          50464,
          3195,
          295,
          3715,
          721,
          538,
          364,
          5748,
          293,
          21751,
          4926,
          18083,
          591,
          21576,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2178.6,
        "id": 524,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2176.6,
        "temperature": 0,
        "text": " Absolute expert, wonderful in this field.",
        "tokens": [
          50614,
          43965,
          1169,
          5844,
          11,
          3715,
          294,
          341,
          2519,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2183.6,
        "id": 525,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2179.6,
        "temperature": 0,
        "text": " I watched a lot of Rebecca Fiebrink's Machine Learning for Musicians and Artists videos.",
        "tokens": [
          50764,
          286,
          6337,
          257,
          688,
          295,
          19381,
          479,
          414,
          1443,
          475,
          311,
          22155,
          15205,
          337,
          7609,
          2567,
          293,
          5735,
          1751,
          2145,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2187.6,
        "id": 526,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2183.6,
        "temperature": 0,
        "text": " Rebecca Fiebrink has made something absolutely wonderful called Wekinator,",
        "tokens": [
          50964,
          19381,
          479,
          414,
          1443,
          475,
          575,
          1027,
          746,
          3122,
          3715,
          1219,
          492,
          5843,
          1639,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2189.6,
        "id": 527,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2187.6,
        "temperature": 0,
        "text": " which is a tool that allows you to send data.",
        "tokens": [
          51164,
          597,
          307,
          257,
          2290,
          300,
          4045,
          291,
          281,
          2845,
          1412,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2191.6,
        "id": 528,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2189.6,
        "temperature": 0,
        "text": " It does machine learning stuff and it sends it back out",
        "tokens": [
          51264,
          467,
          775,
          3479,
          2539,
          1507,
          293,
          309,
          14790,
          309,
          646,
          484,
          51364
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2193.6,
        "id": 529,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2191.6,
        "temperature": 0,
        "text": " all with something called OSC, Open Sound Control.",
        "tokens": [
          51364,
          439,
          365,
          746,
          1219,
          12731,
          34,
          11,
          7238,
          14673,
          12912,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2195.6,
        "id": 530,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2193.6,
        "temperature": 0,
        "text": " I would love to do some video tutorials on that",
        "tokens": [
          51464,
          286,
          576,
          959,
          281,
          360,
          512,
          960,
          17616,
          322,
          300,
          51564
        ]
      },
      {
        "avg_logprob": -0.20210431146283522,
        "compression_ratio": 1.7314814814814814,
        "end": 2198.6,
        "id": 531,
        "no_speech_prob": 0.008312494494020939,
        "seek": 217160,
        "start": 2195.6,
        "temperature": 0,
        "text": " or have some guest tutorials from Rebecca Fiebrink.",
        "tokens": [
          51564,
          420,
          362,
          512,
          8341,
          17616,
          490,
          19381,
          479,
          414,
          1443,
          475,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24487343575190573,
        "compression_ratio": 1.56640625,
        "end": 2203.6,
        "id": 532,
        "no_speech_prob": 0.023325037211179733,
        "seek": 219860,
        "start": 2199.6,
        "temperature": 0,
        "text": " There's also a cadenza course on creative applications with TensorFlow",
        "tokens": [
          50414,
          821,
          311,
          611,
          257,
          12209,
          23691,
          1164,
          322,
          5880,
          5821,
          365,
          37624,
          50614
        ]
      },
      {
        "avg_logprob": -0.24487343575190573,
        "compression_ratio": 1.56640625,
        "end": 2206.6,
        "id": 533,
        "no_speech_prob": 0.023325037211179733,
        "seek": 219860,
        "start": 2203.6,
        "temperature": 0,
        "text": " that I intend to look at and get some resources from.",
        "tokens": [
          50614,
          300,
          286,
          19759,
          281,
          574,
          412,
          293,
          483,
          512,
          3593,
          490,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24487343575190573,
        "compression_ratio": 1.56640625,
        "end": 2211.6,
        "id": 534,
        "no_speech_prob": 0.023325037211179733,
        "seek": 219860,
        "start": 2207.6,
        "temperature": 0,
        "text": " I also want to mention the... let's see, what else?",
        "tokens": [
          50814,
          286,
          611,
          528,
          281,
          2152,
          264,
          485,
          718,
          311,
          536,
          11,
          437,
          1646,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.24487343575190573,
        "compression_ratio": 1.56640625,
        "end": 2216.6,
        "id": 535,
        "no_speech_prob": 0.023325037211179733,
        "seek": 219860,
        "start": 2211.6,
        "temperature": 0,
        "text": " Ah! Andrew Glasner is writing a book about machine learning and deep learning.",
        "tokens": [
          51014,
          2438,
          0,
          10110,
          29078,
          1193,
          307,
          3579,
          257,
          1446,
          466,
          3479,
          2539,
          293,
          2452,
          2539,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24487343575190573,
        "compression_ratio": 1.56640625,
        "end": 2220.6,
        "id": 536,
        "no_speech_prob": 0.023325037211179733,
        "seek": 219860,
        "start": 2216.6,
        "temperature": 0,
        "text": " It is not out yet, but he was generous enough to let me look at some preview drafts.",
        "tokens": [
          51264,
          467,
          307,
          406,
          484,
          1939,
          11,
          457,
          415,
          390,
          14537,
          1547,
          281,
          718,
          385,
          574,
          412,
          512,
          14281,
          11206,
          82,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24487343575190573,
        "compression_ratio": 1.56640625,
        "end": 2224.6,
        "id": 537,
        "no_speech_prob": 0.023325037211179733,
        "seek": 219860,
        "start": 2220.6,
        "temperature": 0,
        "text": " So, thank you very much. Follow at Andrew Glasner on Twitter",
        "tokens": [
          51464,
          407,
          11,
          1309,
          291,
          588,
          709,
          13,
          9876,
          412,
          10110,
          29078,
          1193,
          322,
          5794,
          51664
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2229.6,
        "id": 538,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2225.6,
        "temperature": 0,
        "text": " if you want to find out about his upcoming book that's coming out.",
        "tokens": [
          50414,
          498,
          291,
          528,
          281,
          915,
          484,
          466,
          702,
          11500,
          1446,
          300,
          311,
          1348,
          484,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2231.6,
        "id": 539,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2229.6,
        "temperature": 0,
        "text": " It's been really helpful to read.",
        "tokens": [
          50614,
          467,
          311,
          668,
          534,
          4961,
          281,
          1401,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2233.6,
        "id": 540,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2231.6,
        "temperature": 0,
        "text": " And I'm sure there are...",
        "tokens": [
          50714,
          400,
          286,
          478,
          988,
          456,
          366,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2235.6,
        "id": 541,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2233.6,
        "temperature": 0,
        "text": " Ah, yeah, also...",
        "tokens": [
          50814,
          2438,
          11,
          1338,
          11,
          611,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2238.6,
        "id": 542,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2235.6,
        "temperature": 0,
        "text": " Grokking Deep Learning is a book from Manning and Grokking Algorithms.",
        "tokens": [
          50914,
          12981,
          74,
          5092,
          14895,
          15205,
          307,
          257,
          1446,
          490,
          2458,
          773,
          293,
          12981,
          74,
          5092,
          35014,
          6819,
          2592,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2241.6,
        "id": 543,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2238.6,
        "temperature": 0,
        "text": " These are books that I've mentioned that I have been looking,",
        "tokens": [
          51064,
          1981,
          366,
          3642,
          300,
          286,
          600,
          2835,
          300,
          286,
          362,
          668,
          1237,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2243.6,
        "id": 544,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2241.6,
        "temperature": 0,
        "text": " as well as Make Your Own Neural Network,",
        "tokens": [
          51214,
          382,
          731,
          382,
          4387,
          2260,
          25964,
          1734,
          1807,
          12640,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2247.6,
        "id": 545,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2243.6,
        "temperature": 0,
        "text": " which is a book that walks you through programming your own neural network in Python.",
        "tokens": [
          51314,
          597,
          307,
          257,
          1446,
          300,
          12896,
          291,
          807,
          9410,
          428,
          1065,
          18161,
          3209,
          294,
          15329,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2250.6,
        "id": 546,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2247.6,
        "temperature": 0,
        "text": " Now, people in the chat are giving me lots of suggestions",
        "tokens": [
          51514,
          823,
          11,
          561,
          294,
          264,
          5081,
          366,
          2902,
          385,
          3195,
          295,
          13396,
          51664
        ]
      },
      {
        "avg_logprob": -0.21731752628902737,
        "compression_ratio": 1.686084142394822,
        "end": 2253.6,
        "id": 547,
        "no_speech_prob": 0.12418286502361298,
        "seek": 222460,
        "start": 2250.6,
        "temperature": 0,
        "text": " for other deep learning and machine learning and AI books.",
        "tokens": [
          51664,
          337,
          661,
          2452,
          2539,
          293,
          3479,
          2539,
          293,
          7318,
          3642,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2256.6,
        "id": 548,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2253.6,
        "temperature": 0,
        "text": " Oh, I don't have my props. I have these old textbooks.",
        "tokens": [
          50364,
          876,
          11,
          286,
          500,
          380,
          362,
          452,
          26173,
          13,
          286,
          362,
          613,
          1331,
          33587,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2260.6,
        "id": 549,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2256.6,
        "temperature": 0,
        "text": " I'll bring those another time on artificial intelligence, which are great.",
        "tokens": [
          50514,
          286,
          603,
          1565,
          729,
          1071,
          565,
          322,
          11677,
          7599,
          11,
          597,
          366,
          869,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2263.6,
        "id": 550,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2260.6,
        "temperature": 0,
        "text": " But the other thing I would recommend is...",
        "tokens": [
          50714,
          583,
          264,
          661,
          551,
          286,
          576,
          2748,
          307,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2267.6,
        "id": 551,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2263.6,
        "temperature": 0,
        "text": " These are three compilations of resources.",
        "tokens": [
          50864,
          1981,
          366,
          1045,
          715,
          388,
          763,
          295,
          3593,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2269.6,
        "id": 552,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2267.6,
        "temperature": 0,
        "text": " So, this is one that's put together by this community.",
        "tokens": [
          51064,
          407,
          11,
          341,
          307,
          472,
          300,
          311,
          829,
          1214,
          538,
          341,
          1768,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2271.6,
        "id": 553,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2269.6,
        "temperature": 0,
        "text": " This is awesome machine learning.",
        "tokens": [
          51164,
          639,
          307,
          3476,
          3479,
          2539,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2275.6,
        "id": 554,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2271.6,
        "temperature": 0,
        "text": " There's a lot of awesome blank lists that are put together.",
        "tokens": [
          51264,
          821,
          311,
          257,
          688,
          295,
          3476,
          8247,
          14511,
          300,
          366,
          829,
          1214,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2278.6,
        "id": 555,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2275.6,
        "temperature": 0,
        "text": " Let me see who puts this together, just because I forgot.",
        "tokens": [
          51464,
          961,
          385,
          536,
          567,
          8137,
          341,
          1214,
          11,
          445,
          570,
          286,
          5298,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22150616645812987,
        "compression_ratio": 1.6214285714285714,
        "end": 2282.6,
        "id": 556,
        "no_speech_prob": 0.0316130593419075,
        "seek": 225360,
        "start": 2278.6,
        "temperature": 0,
        "text": " From Joseph Misciti on GitHub.",
        "tokens": [
          51614,
          3358,
          11170,
          376,
          5606,
          8707,
          322,
          23331,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24623651420120643,
        "compression_ratio": 1.5225563909774436,
        "end": 2287.6,
        "id": 557,
        "no_speech_prob": 0.007695217616856098,
        "seek": 228260,
        "start": 2282.6,
        "temperature": 0,
        "text": " And also, this is a list of resources from Memo Atkin.",
        "tokens": [
          50364,
          400,
          611,
          11,
          341,
          307,
          257,
          1329,
          295,
          3593,
          490,
          8731,
          78,
          1711,
          5843,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24623651420120643,
        "compression_ratio": 1.5225563909774436,
        "end": 2293.6,
        "id": 558,
        "no_speech_prob": 0.007695217616856098,
        "seek": 228260,
        "start": 2287.6,
        "temperature": 0,
        "text": " Okay, so, please, I'm accepting all suggestions and help and examples and ideas.",
        "tokens": [
          50614,
          1033,
          11,
          370,
          11,
          1767,
          11,
          286,
          478,
          17391,
          439,
          13396,
          293,
          854,
          293,
          5110,
          293,
          3487,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24623651420120643,
        "compression_ratio": 1.5225563909774436,
        "end": 2297.6,
        "id": 559,
        "no_speech_prob": 0.007695217616856098,
        "seek": 228260,
        "start": 2293.6,
        "temperature": 0,
        "text": " I look forward to all of the, hopefully not so angry letters I will receive",
        "tokens": [
          50914,
          286,
          574,
          2128,
          281,
          439,
          295,
          264,
          11,
          4696,
          406,
          370,
          6884,
          7825,
          286,
          486,
          4774,
          51114
        ]
      },
      {
        "avg_logprob": -0.24623651420120643,
        "compression_ratio": 1.5225563909774436,
        "end": 2300.6,
        "id": 560,
        "no_speech_prob": 0.007695217616856098,
        "seek": 228260,
        "start": 2297.6,
        "temperature": 0,
        "text": " as I screw everything up over the next six or seven weeks.",
        "tokens": [
          51114,
          382,
          286,
          5630,
          1203,
          493,
          670,
          264,
          958,
          2309,
          420,
          3407,
          3259,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24623651420120643,
        "compression_ratio": 1.5225563909774436,
        "end": 2302.6,
        "id": 561,
        "no_speech_prob": 0.007695217616856098,
        "seek": 228260,
        "start": 2300.6,
        "temperature": 0,
        "text": " We're going to...",
        "tokens": [
          51264,
          492,
          434,
          516,
          281,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.24623651420120643,
        "compression_ratio": 1.5225563909774436,
        "end": 2305.6,
        "id": 562,
        "no_speech_prob": 0.007695217616856098,
        "seek": 228260,
        "start": 2302.6,
        "temperature": 0,
        "text": " I guess what I didn't really say is, I have...",
        "tokens": [
          51364,
          286,
          2041,
          437,
          286,
          994,
          380,
          534,
          584,
          307,
          11,
          286,
          362,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.24623651420120643,
        "compression_ratio": 1.5225563909774436,
        "end": 2310.6,
        "id": 563,
        "no_speech_prob": 0.007695217616856098,
        "seek": 228260,
        "start": 2305.6,
        "temperature": 0,
        "text": " To wrap up here, what I have is these two chapters in Nature of Code,",
        "tokens": [
          51514,
          1407,
          7019,
          493,
          510,
          11,
          437,
          286,
          362,
          307,
          613,
          732,
          20013,
          294,
          20159,
          295,
          15549,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2313.6,
        "id": 564,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2310.6,
        "temperature": 0,
        "text": " which deal with genetic algorithms and the basics of neural networks.",
        "tokens": [
          50364,
          597,
          2028,
          365,
          12462,
          14642,
          293,
          264,
          14688,
          295,
          18161,
          9590,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2315.6,
        "id": 565,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2313.6,
        "temperature": 0,
        "text": " That's where I've kind of left my knowledge behind.",
        "tokens": [
          50514,
          663,
          311,
          689,
          286,
          600,
          733,
          295,
          1411,
          452,
          3601,
          2261,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2318.6,
        "id": 566,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2315.6,
        "temperature": 0,
        "text": " And I'm embarking on this journey here on YouTube",
        "tokens": [
          50614,
          400,
          286,
          478,
          29832,
          278,
          322,
          341,
          4671,
          510,
          322,
          3088,
          50764
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2320.6,
        "id": 567,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2318.6,
        "temperature": 0,
        "text": " to try to expand past what's in there.",
        "tokens": [
          50764,
          281,
          853,
          281,
          5268,
          1791,
          437,
          311,
          294,
          456,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2322.6,
        "id": 568,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2320.6,
        "temperature": 0,
        "text": " And we will see how it goes.",
        "tokens": [
          50864,
          400,
          321,
          486,
          536,
          577,
          309,
          1709,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2324.6,
        "id": 569,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2322.6,
        "temperature": 0,
        "text": " So, thanks for joining me.",
        "tokens": [
          50964,
          407,
          11,
          3231,
          337,
          5549,
          385,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2326.6,
        "id": 570,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2324.6,
        "temperature": 0,
        "text": " And I look forward to seeing you in some future videos.",
        "tokens": [
          51064,
          400,
          286,
          574,
          2128,
          281,
          2577,
          291,
          294,
          512,
          2027,
          2145,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2328.6,
        "id": 571,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2326.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2330.6,
        "id": 572,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2328.6,
        "temperature": 0,
        "text": " Great. Stay hydrated.",
        "tokens": [
          51264,
          3769,
          13,
          8691,
          44960,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2332.6,
        "id": 573,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2330.6,
        "temperature": 0,
        "text": " Alright, so that was my introduction.",
        "tokens": [
          51364,
          2798,
          11,
          370,
          300,
          390,
          452,
          9339,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2335.6,
        "id": 574,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2332.6,
        "temperature": 0,
        "text": " There were so many things that I wanted to talk about and cover,",
        "tokens": [
          51464,
          821,
          645,
          370,
          867,
          721,
          300,
          286,
          1415,
          281,
          751,
          466,
          293,
          2060,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.18422913205796393,
        "compression_ratio": 1.5974025974025974,
        "end": 2337.6,
        "id": 575,
        "no_speech_prob": 0.0038243881426751614,
        "seek": 231060,
        "start": 2335.6,
        "temperature": 0,
        "text": " but I think it was good that I didn't.",
        "tokens": [
          51614,
          457,
          286,
          519,
          309,
          390,
          665,
          300,
          286,
          994,
          380,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19669661109830128,
        "compression_ratio": 1.4848484848484849,
        "end": 2339.6,
        "id": 576,
        "no_speech_prob": 0.003649825928732753,
        "seek": 233760,
        "start": 2337.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19669661109830128,
        "compression_ratio": 1.4848484848484849,
        "end": 2345.6,
        "id": 577,
        "no_speech_prob": 0.003649825928732753,
        "seek": 233760,
        "start": 2342.6,
        "temperature": 0,
        "text": " I'm okay on time. It's 4.40.",
        "tokens": [
          50614,
          286,
          478,
          1392,
          322,
          565,
          13,
          467,
          311,
          1017,
          13,
          5254,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19669661109830128,
        "compression_ratio": 1.4848484848484849,
        "end": 2351.6,
        "id": 578,
        "no_speech_prob": 0.003649825928732753,
        "seek": 233760,
        "start": 2345.6,
        "temperature": 0,
        "text": " So now what I want to do is introduce the first week.",
        "tokens": [
          50764,
          407,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          5366,
          264,
          700,
          1243,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19669661109830128,
        "compression_ratio": 1.4848484848484849,
        "end": 2355.6,
        "id": 579,
        "no_speech_prob": 0.003649825928732753,
        "seek": 233760,
        "start": 2353.6,
        "temperature": 0,
        "text": " Oh, I'm there already. Okay.",
        "tokens": [
          51164,
          876,
          11,
          286,
          478,
          456,
          1217,
          13,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19669661109830128,
        "compression_ratio": 1.4848484848484849,
        "end": 2360.6,
        "id": 580,
        "no_speech_prob": 0.003649825928732753,
        "seek": 233760,
        "start": 2359.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19669661109830128,
        "compression_ratio": 1.4848484848484849,
        "end": 2363.6,
        "id": 581,
        "no_speech_prob": 0.003649825928732753,
        "seek": 233760,
        "start": 2360.6,
        "temperature": 0,
        "text": " Yeah, see, I had all these other notes about...",
        "tokens": [
          51514,
          865,
          11,
          536,
          11,
          286,
          632,
          439,
          613,
          661,
          5570,
          466,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.19669661109830128,
        "compression_ratio": 1.4848484848484849,
        "end": 2366.6,
        "id": 582,
        "no_speech_prob": 0.003649825928732753,
        "seek": 233760,
        "start": 2363.6,
        "temperature": 0,
        "text": " These are my notes of things that I want to talk about in my introduction",
        "tokens": [
          51664,
          1981,
          366,
          452,
          5570,
          295,
          721,
          300,
          286,
          528,
          281,
          751,
          466,
          294,
          452,
          9339,
          51814
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2368.6,
        "id": 583,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2366.6,
        "temperature": 0,
        "text": " that I didn't really remember.",
        "tokens": [
          50364,
          300,
          286,
          994,
          380,
          534,
          1604,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2370.6,
        "id": 584,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2368.6,
        "temperature": 0,
        "text": " Oh, I wanted to talk... This is so important.",
        "tokens": [
          50464,
          876,
          11,
          286,
          1415,
          281,
          751,
          485,
          639,
          307,
          370,
          1021,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2372.6,
        "id": 585,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2370.6,
        "temperature": 0,
        "text": " Well, what are we going to do?",
        "tokens": [
          50564,
          1042,
          11,
          437,
          366,
          321,
          516,
          281,
          360,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2374.6,
        "id": 586,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2372.6,
        "temperature": 0,
        "text": " Another time, I will...",
        "tokens": [
          50664,
          3996,
          565,
          11,
          286,
          486,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2377.6,
        "id": 587,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2374.6,
        "temperature": 0,
        "text": " Maybe I'll do a separate video about this.",
        "tokens": [
          50764,
          2704,
          286,
          603,
          360,
          257,
          4994,
          960,
          466,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2380.6,
        "id": 588,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2377.6,
        "temperature": 0,
        "text": " And we'll come back to it as we get further along.",
        "tokens": [
          50914,
          400,
          321,
          603,
          808,
          646,
          281,
          309,
          382,
          321,
          483,
          3052,
          2051,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2382.6,
        "id": 589,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2380.6,
        "temperature": 0,
        "text": " Somebody remind me about this.",
        "tokens": [
          51064,
          13463,
          4160,
          385,
          466,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2385.6,
        "id": 590,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2382.6,
        "temperature": 0,
        "text": " I don't think I need to reinsert this into that introduction,",
        "tokens": [
          51164,
          286,
          500,
          380,
          519,
          286,
          643,
          281,
          47200,
          911,
          341,
          666,
          300,
          9339,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2388.6,
        "id": 591,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2385.6,
        "temperature": 0,
        "text": " but I think it's incredibly important",
        "tokens": [
          51314,
          457,
          286,
          519,
          309,
          311,
          6252,
          1021,
          51464
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2390.6,
        "id": 592,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2388.6,
        "temperature": 0,
        "text": " when studying and working with these topics",
        "tokens": [
          51464,
          562,
          7601,
          293,
          1364,
          365,
          613,
          8378,
          51564
        ]
      },
      {
        "avg_logprob": -0.16083883066646387,
        "compression_ratio": 1.6088560885608856,
        "end": 2393.6,
        "id": 593,
        "no_speech_prob": 0.00021653690782841295,
        "seek": 236660,
        "start": 2390.6,
        "temperature": 0,
        "text": " to be critical and to ask questions",
        "tokens": [
          51564,
          281,
          312,
          4924,
          293,
          281,
          1029,
          1651,
          51714
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2396.6,
        "id": 594,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2393.6,
        "temperature": 0,
        "text": " if anything we're doing is actually a good idea.",
        "tokens": [
          50364,
          498,
          1340,
          321,
          434,
          884,
          307,
          767,
          257,
          665,
          1558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2398.6,
        "id": 595,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2396.6,
        "temperature": 0,
        "text": " David Ha, who's a researcher at Google,",
        "tokens": [
          50514,
          4389,
          4064,
          11,
          567,
          311,
          257,
          21751,
          412,
          3329,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2400.6,
        "id": 596,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2398.6,
        "temperature": 0,
        "text": " I believe, or Google Creative Lab,",
        "tokens": [
          50614,
          286,
          1697,
          11,
          420,
          3329,
          26598,
          10137,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2402.6,
        "id": 597,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2400.6,
        "temperature": 0,
        "text": " who makes lots of great machine learning projects,",
        "tokens": [
          50714,
          567,
          1669,
          3195,
          295,
          869,
          3479,
          2539,
          4455,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2404.6,
        "id": 598,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2402.6,
        "temperature": 0,
        "text": " tweeted at one point, I thought,",
        "tokens": [
          50814,
          25646,
          412,
          472,
          935,
          11,
          286,
          1194,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2406.6,
        "id": 599,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2404.6,
        "temperature": 0,
        "text": " what happened to making the world a better place?",
        "tokens": [
          50914,
          437,
          2011,
          281,
          1455,
          264,
          1002,
          257,
          1101,
          1081,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2409.6,
        "id": 600,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2406.6,
        "temperature": 0,
        "text": " See, I'm doing this now. It'll just be in...",
        "tokens": [
          51014,
          3008,
          11,
          286,
          478,
          884,
          341,
          586,
          13,
          467,
          603,
          445,
          312,
          294,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2413.6,
        "id": 601,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2409.6,
        "temperature": 0,
        "text": " You know what? Let's do an addendum.",
        "tokens": [
          51164,
          509,
          458,
          437,
          30,
          961,
          311,
          360,
          364,
          909,
          27574,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2415.6,
        "id": 602,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2413.6,
        "temperature": 0,
        "text": " What do you think, Mathieu?",
        "tokens": [
          51364,
          708,
          360,
          291,
          519,
          11,
          15776,
          19347,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2417.6,
        "id": 603,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2415.6,
        "temperature": 0,
        "text": " You said it was under 20 minutes.",
        "tokens": [
          51464,
          509,
          848,
          309,
          390,
          833,
          945,
          2077,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2419.6,
        "id": 604,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2417.6,
        "temperature": 0,
        "text": " I'm going to do a quick addendum.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          360,
          257,
          1702,
          909,
          27574,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1624462821266868,
        "compression_ratio": 1.6398601398601398,
        "end": 2421.6,
        "id": 605,
        "no_speech_prob": 0.07692226022481918,
        "seek": 239360,
        "start": 2419.6,
        "temperature": 0,
        "text": " I'm going to do a quick addendum.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          360,
          257,
          1702,
          909,
          27574,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2425.6,
        "id": 606,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2422.6,
        "temperature": 0,
        "text": " Oh, I'm back. I do this a lot.",
        "tokens": [
          50414,
          876,
          11,
          286,
          478,
          646,
          13,
          286,
          360,
          341,
          257,
          688,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2428.6,
        "id": 607,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2425.6,
        "temperature": 0,
        "text": " I'm back because I forgot that I had this page of notes,",
        "tokens": [
          50564,
          286,
          478,
          646,
          570,
          286,
          5298,
          300,
          286,
          632,
          341,
          3028,
          295,
          5570,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2430.6,
        "id": 608,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2428.6,
        "temperature": 0,
        "text": " and instead I just rambled.",
        "tokens": [
          50714,
          293,
          2602,
          286,
          445,
          367,
          43390,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2432.6,
        "id": 609,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2430.6,
        "temperature": 0,
        "text": " It's got a few more links about thinking about",
        "tokens": [
          50814,
          467,
          311,
          658,
          257,
          1326,
          544,
          6123,
          466,
          1953,
          466,
          50914
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2434.6,
        "id": 610,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2432.6,
        "temperature": 0,
        "text": " the definition of artificial intelligence and machine learning.",
        "tokens": [
          50914,
          264,
          7123,
          295,
          11677,
          7599,
          293,
          3479,
          2539,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2436.6,
        "id": 611,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2434.6,
        "temperature": 0,
        "text": " I'm still working on stuff. You'll find this also linked.",
        "tokens": [
          51014,
          286,
          478,
          920,
          1364,
          322,
          1507,
          13,
          509,
          603,
          915,
          341,
          611,
          9408,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2438.6,
        "id": 612,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2436.6,
        "temperature": 0,
        "text": " But something really important here",
        "tokens": [
          51114,
          583,
          746,
          534,
          1021,
          510,
          51214
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2441.6,
        "id": 613,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2438.6,
        "temperature": 0,
        "text": " that I wanted to just mention was...",
        "tokens": [
          51214,
          300,
          286,
          1415,
          281,
          445,
          2152,
          390,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2444.6,
        "id": 614,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2441.6,
        "temperature": 0,
        "text": " It's very important when studying...",
        "tokens": [
          51364,
          467,
          311,
          588,
          1021,
          562,
          7601,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2446.6,
        "id": 615,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2444.6,
        "temperature": 0,
        "text": " I'm literally just going to be looking at the algorithms",
        "tokens": [
          51514,
          286,
          478,
          3736,
          445,
          516,
          281,
          312,
          1237,
          412,
          264,
          14642,
          51614
        ]
      },
      {
        "avg_logprob": -0.22599745166394136,
        "compression_ratio": 1.7706093189964158,
        "end": 2448.6,
        "id": 616,
        "no_speech_prob": 0.0031701717525720596,
        "seek": 242160,
        "start": 2446.6,
        "temperature": 0,
        "text": " and making stuff and trying to be creative",
        "tokens": [
          51614,
          293,
          1455,
          1507,
          293,
          1382,
          281,
          312,
          5880,
          51714
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2451.6,
        "id": 617,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2448.6,
        "temperature": 0,
        "text": " and whackadoodling my way through this, if that's a verb.",
        "tokens": [
          50364,
          293,
          42877,
          1573,
          378,
          1688,
          452,
          636,
          807,
          341,
          11,
          498,
          300,
          311,
          257,
          9595,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2454.6,
        "id": 618,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2451.6,
        "temperature": 0,
        "text": " But it is really important for you,",
        "tokens": [
          50514,
          583,
          309,
          307,
          534,
          1021,
          337,
          291,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2457.6,
        "id": 619,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2454.6,
        "temperature": 0,
        "text": " the world of people who are going to be using these tools,",
        "tokens": [
          50664,
          264,
          1002,
          295,
          561,
          567,
          366,
          516,
          281,
          312,
          1228,
          613,
          3873,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2459.6,
        "id": 620,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2457.6,
        "temperature": 0,
        "text": " using these algorithms, making projects,",
        "tokens": [
          50814,
          1228,
          613,
          14642,
          11,
          1455,
          4455,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2461.6,
        "id": 621,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2459.6,
        "temperature": 0,
        "text": " working for companies, to be critical",
        "tokens": [
          50914,
          1364,
          337,
          3431,
          11,
          281,
          312,
          4924,
          51014
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2463.6,
        "id": 622,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2461.6,
        "temperature": 0,
        "text": " and think about what you're doing,",
        "tokens": [
          51014,
          293,
          519,
          466,
          437,
          291,
          434,
          884,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2465.6,
        "id": 623,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2463.6,
        "temperature": 0,
        "text": " and whether it's even a good idea,",
        "tokens": [
          51114,
          293,
          1968,
          309,
          311,
          754,
          257,
          665,
          1558,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2467.6,
        "id": 624,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2465.6,
        "temperature": 0,
        "text": " and is it hurting anybody, is it helping anybody?",
        "tokens": [
          51214,
          293,
          307,
          309,
          17744,
          4472,
          11,
          307,
          309,
          4315,
          4472,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2469.6,
        "id": 625,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2467.6,
        "temperature": 0,
        "text": " And so there's some...",
        "tokens": [
          51314,
          400,
          370,
          456,
          311,
          512,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2471.6,
        "id": 626,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2469.6,
        "temperature": 0,
        "text": " One thing I'll just mention here is",
        "tokens": [
          51414,
          1485,
          551,
          286,
          603,
          445,
          2152,
          510,
          307,
          51514
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2473.6,
        "id": 627,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2471.6,
        "temperature": 0,
        "text": " there's an organization called AI Now,",
        "tokens": [
          51514,
          456,
          311,
          364,
          4475,
          1219,
          7318,
          823,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2475.6,
        "id": 628,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2473.6,
        "temperature": 0,
        "text": " which I just learned about recently.",
        "tokens": [
          51614,
          597,
          286,
          445,
          3264,
          466,
          3938,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19565660423702663,
        "compression_ratio": 1.6720257234726688,
        "end": 2477.6,
        "id": 629,
        "no_speech_prob": 0.0518297478556633,
        "seek": 244860,
        "start": 2475.6,
        "temperature": 0,
        "text": " I thought I just clicked on them.",
        "tokens": [
          51714,
          286,
          1194,
          286,
          445,
          23370,
          322,
          552,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2479.6,
        "id": 630,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2477.6,
        "temperature": 0,
        "text": " It's over here.",
        "tokens": [
          50364,
          467,
          311,
          670,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2481.6,
        "id": 631,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2479.6,
        "temperature": 0,
        "text": " It's an initiative to research the social impacts",
        "tokens": [
          50464,
          467,
          311,
          364,
          11552,
          281,
          2132,
          264,
          2093,
          11606,
          50564
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2484.6,
        "id": 632,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2481.6,
        "temperature": 0,
        "text": " of artificial intelligence to ensure a more equitable future.",
        "tokens": [
          50564,
          295,
          11677,
          7599,
          281,
          5586,
          257,
          544,
          33730,
          2027,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2486.6,
        "id": 633,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2484.6,
        "temperature": 0,
        "text": " So I encourage you to check out.",
        "tokens": [
          50714,
          407,
          286,
          5373,
          291,
          281,
          1520,
          484,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2488.6,
        "id": 634,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2486.6,
        "temperature": 0,
        "text": " There's going to be a symposium in July.",
        "tokens": [
          50814,
          821,
          311,
          516,
          281,
          312,
          257,
          13240,
          42161,
          294,
          7370,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2490.6,
        "id": 635,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2488.6,
        "temperature": 0,
        "text": " Check out about this.",
        "tokens": [
          50914,
          6881,
          484,
          466,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2493.6,
        "id": 636,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2490.6,
        "temperature": 0,
        "text": " I also just love this quote from Hard Maru on Twitter,",
        "tokens": [
          51014,
          286,
          611,
          445,
          959,
          341,
          6513,
          490,
          11817,
          2039,
          84,
          322,
          5794,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2495.6,
        "id": 637,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2493.6,
        "temperature": 0,
        "text": " which is...",
        "tokens": [
          51164,
          597,
          307,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2498.6,
        "id": 638,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2495.6,
        "temperature": 0,
        "text": " David Ha from Google makes a lot of wonderful...",
        "tokens": [
          51264,
          4389,
          4064,
          490,
          3329,
          1669,
          257,
          688,
          295,
          3715,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2501.6,
        "id": 639,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2498.6,
        "temperature": 0,
        "text": " There's a wonderful recurrent neural network",
        "tokens": [
          51414,
          821,
          311,
          257,
          3715,
          18680,
          1753,
          18161,
          3209,
          51564
        ]
      },
      {
        "avg_logprob": -0.24478709803218335,
        "compression_ratio": 1.537037037037037,
        "end": 2504.6,
        "id": 640,
        "no_speech_prob": 0.1777224838733673,
        "seek": 247760,
        "start": 2501.6,
        "temperature": 0,
        "text": " handwriting with p5.js example",
        "tokens": [
          51564,
          39179,
          365,
          280,
          20,
          13,
          25530,
          1365,
          51714
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2507.6,
        "id": 641,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2505.6,
        "temperature": 0,
        "text": " that you can find.",
        "tokens": [
          50414,
          300,
          291,
          393,
          915,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2509.6,
        "id": 642,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2507.6,
        "temperature": 0,
        "text": " I'll try to link to that as well.",
        "tokens": [
          50514,
          286,
          603,
          853,
          281,
          2113,
          281,
          300,
          382,
          731,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2512.6,
        "id": 643,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2509.6,
        "temperature": 0,
        "text": " But whatever happened to making the world a better place?",
        "tokens": [
          50614,
          583,
          2035,
          2011,
          281,
          1455,
          264,
          1002,
          257,
          1101,
          1081,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2514.6,
        "id": 644,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2512.6,
        "temperature": 0,
        "text": " So when you talk about what is your goal",
        "tokens": [
          50764,
          407,
          562,
          291,
          751,
          466,
          437,
          307,
          428,
          3387,
          50864
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2516.6,
        "id": 645,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2514.6,
        "temperature": 0,
        "text": " with building an AI system,",
        "tokens": [
          50864,
          365,
          2390,
          364,
          7318,
          1185,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2518.6,
        "id": 646,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2516.6,
        "temperature": 0,
        "text": " with using machine learning,",
        "tokens": [
          50964,
          365,
          1228,
          3479,
          2539,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2520.6,
        "id": 647,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2518.6,
        "temperature": 0,
        "text": " why are you doing it?",
        "tokens": [
          51064,
          983,
          366,
          291,
          884,
          309,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2522.6,
        "id": 648,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2520.6,
        "temperature": 0,
        "text": " And so I'll leave you with that.",
        "tokens": [
          51164,
          400,
          370,
          286,
          603,
          1856,
          291,
          365,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2524.6,
        "id": 649,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2522.6,
        "temperature": 0,
        "text": " Are you making the world a better place?",
        "tokens": [
          51264,
          2014,
          291,
          1455,
          264,
          1002,
          257,
          1101,
          1081,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2526.6,
        "id": 650,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2524.6,
        "temperature": 0,
        "text": " I hope that you are.",
        "tokens": [
          51364,
          286,
          1454,
          300,
          291,
          366,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2528.6,
        "id": 651,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2526.6,
        "temperature": 0,
        "text": " And come along.",
        "tokens": [
          51464,
          400,
          808,
          2051,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2530.6,
        "id": 652,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2528.6,
        "temperature": 0,
        "text": " I'll see you in the next video.",
        "tokens": [
          51564,
          286,
          603,
          536,
          291,
          294,
          264,
          958,
          960,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.163200762844825,
        "compression_ratio": 1.7530864197530864,
        "end": 2532.6,
        "id": 653,
        "no_speech_prob": 0.00941204372793436,
        "seek": 250460,
        "start": 2530.6,
        "temperature": 0,
        "text": " Okay, you can decide whether to include that or not.",
        "tokens": [
          51664,
          1033,
          11,
          291,
          393,
          4536,
          1968,
          281,
          4090,
          300,
          420,
          406,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2534.6,
        "id": 654,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2532.6,
        "temperature": 0,
        "text": " That was something that I wanted to say.",
        "tokens": [
          50364,
          663,
          390,
          746,
          300,
          286,
          1415,
          281,
          584,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2536.6,
        "id": 655,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2534.6,
        "temperature": 0,
        "text": " Here at least in this longer live stream,",
        "tokens": [
          50464,
          1692,
          412,
          1935,
          294,
          341,
          2854,
          1621,
          4309,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2538.6,
        "id": 656,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2536.6,
        "temperature": 0,
        "text": " it will be here in this video.",
        "tokens": [
          50564,
          309,
          486,
          312,
          510,
          294,
          341,
          960,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2541.6,
        "id": 657,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2538.6,
        "temperature": 0,
        "text": " Okay, so now what I want to do is...",
        "tokens": [
          50664,
          1033,
          11,
          370,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2543.6,
        "id": 658,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2541.6,
        "temperature": 0,
        "text": " Yeah, I talked about this.",
        "tokens": [
          50814,
          865,
          11,
          286,
          2825,
          466,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2545.6,
        "id": 659,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2543.6,
        "temperature": 0,
        "text": " I didn't go over my sort of glossary of terms.",
        "tokens": [
          50914,
          286,
          994,
          380,
          352,
          670,
          452,
          1333,
          295,
          19574,
          822,
          295,
          2115,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2547.6,
        "id": 660,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2545.6,
        "temperature": 0,
        "text": " But that's okay.",
        "tokens": [
          51014,
          583,
          300,
          311,
          1392,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2549.6,
        "id": 661,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2547.6,
        "temperature": 0,
        "text": " We'll come back to those.",
        "tokens": [
          51114,
          492,
          603,
          808,
          646,
          281,
          729,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2551.6,
        "id": 662,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2549.6,
        "temperature": 0,
        "text": " And now here we go.",
        "tokens": [
          51214,
          400,
          586,
          510,
          321,
          352,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2553.6,
        "id": 663,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2551.6,
        "temperature": 0,
        "text": " So I'm going to do...",
        "tokens": [
          51314,
          407,
          286,
          478,
          516,
          281,
          360,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2555.6,
        "id": 664,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2553.6,
        "temperature": 0,
        "text": " I'm going to now...",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          586,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2557.6,
        "id": 665,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2555.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2559.6,
        "id": 666,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2557.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1643283163854318,
        "compression_ratio": 1.6306306306306306,
        "end": 2561.6,
        "id": 667,
        "no_speech_prob": 0.6293594241142273,
        "seek": 253260,
        "start": 2559.6,
        "temperature": 0,
        "text": " Okay, so here we go.",
        "tokens": [
          51714,
          1033,
          11,
          370,
          510,
          321,
          352,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2563.6,
        "id": 668,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2561.6,
        "temperature": 0,
        "text": " So I'm going to do that.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2565.6,
        "id": 669,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2563.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2567.6,
        "id": 670,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2565.6,
        "temperature": 0,
        "text": " So now this video...",
        "tokens": [
          50564,
          407,
          586,
          341,
          960,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2569.6,
        "id": 671,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2567.6,
        "temperature": 0,
        "text": " So that was an introduction to the whole course.",
        "tokens": [
          50664,
          407,
          300,
          390,
          364,
          9339,
          281,
          264,
          1379,
          1164,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2571.6,
        "id": 672,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2569.6,
        "temperature": 0,
        "text": " This video, which I hope will just be 5 to 10 minutes,",
        "tokens": [
          50764,
          639,
          960,
          11,
          597,
          286,
          1454,
          486,
          445,
          312,
          1025,
          281,
          1266,
          2077,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2573.6,
        "id": 673,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2571.6,
        "temperature": 0,
        "text": " if not even shorter than that,",
        "tokens": [
          50864,
          498,
          406,
          754,
          11639,
          813,
          300,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2577.6,
        "id": 674,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2573.6,
        "temperature": 0,
        "text": " will be just an introduction to the topics for week 1.",
        "tokens": [
          50964,
          486,
          312,
          445,
          364,
          9339,
          281,
          264,
          8378,
          337,
          1243,
          502,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2579.6,
        "id": 675,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2577.6,
        "temperature": 0,
        "text": " And one of the things...",
        "tokens": [
          51164,
          400,
          472,
          295,
          264,
          721,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2581.6,
        "id": 676,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2579.6,
        "temperature": 0,
        "text": " My dream has always been...",
        "tokens": [
          51264,
          1222,
          3055,
          575,
          1009,
          668,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2583.6,
        "id": 677,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2581.6,
        "temperature": 0,
        "text": " And I just make all these coding challenges and random videos,",
        "tokens": [
          51364,
          400,
          286,
          445,
          652,
          439,
          613,
          17720,
          4759,
          293,
          4974,
          2145,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2586.6,
        "id": 678,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2583.6,
        "temperature": 0,
        "text": " but they're modular pieces that could be assembled into a course.",
        "tokens": [
          51464,
          457,
          436,
          434,
          31111,
          3755,
          300,
          727,
          312,
          24204,
          666,
          257,
          1164,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24150577121310765,
        "compression_ratio": 1.685512367491166,
        "end": 2589.6,
        "id": 679,
        "no_speech_prob": 0.06655926257371902,
        "seek": 256160,
        "start": 2586.6,
        "temperature": 0,
        "text": " So I'm kind of trying to do that to some extent here.",
        "tokens": [
          51614,
          407,
          286,
          478,
          733,
          295,
          1382,
          281,
          360,
          300,
          281,
          512,
          8396,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2591.6,
        "id": 680,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2589.6,
        "temperature": 0,
        "text": " And most of the stuff that's in this week 1",
        "tokens": [
          50364,
          400,
          881,
          295,
          264,
          1507,
          300,
          311,
          294,
          341,
          1243,
          502,
          50464
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2593.6,
        "id": 681,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2591.6,
        "temperature": 0,
        "text": " are topics I've already made videos about.",
        "tokens": [
          50464,
          366,
          8378,
          286,
          600,
          1217,
          1027,
          2145,
          466,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2598.6,
        "id": 682,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2593.6,
        "temperature": 0,
        "text": " Traveling salesperson, A-star, binary search tree.",
        "tokens": [
          50564,
          20610,
          278,
          5763,
          10813,
          11,
          316,
          12,
          9710,
          11,
          17434,
          3164,
          4230,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2602.6,
        "id": 683,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2598.6,
        "temperature": 0,
        "text": " So the only thing that I'm going to have time for today, really, is...",
        "tokens": [
          50814,
          407,
          264,
          787,
          551,
          300,
          286,
          478,
          516,
          281,
          362,
          565,
          337,
          965,
          11,
          534,
          11,
          307,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2604.6,
        "id": 684,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2602.6,
        "temperature": 0,
        "text": " Oh, the camera went off.",
        "tokens": [
          51014,
          876,
          11,
          264,
          2799,
          1437,
          766,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2606.6,
        "id": 685,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2604.6,
        "temperature": 0,
        "text": " Is breadth-first search.",
        "tokens": [
          51114,
          1119,
          35862,
          12,
          29581,
          3164,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2610.6,
        "id": 686,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2606.6,
        "temperature": 0,
        "text": " But as I go on and make more videos...",
        "tokens": [
          51214,
          583,
          382,
          286,
          352,
          322,
          293,
          652,
          544,
          2145,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2612.6,
        "id": 687,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2610.6,
        "temperature": 0,
        "text": " Someday I'll do a video on big O notation.",
        "tokens": [
          51414,
          12297,
          16826,
          286,
          603,
          360,
          257,
          960,
          322,
          955,
          422,
          24657,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2614.6,
        "id": 688,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2612.6,
        "temperature": 0,
        "text": " I don't think I'll get to it today.",
        "tokens": [
          51514,
          286,
          500,
          380,
          519,
          286,
          603,
          483,
          281,
          309,
          965,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22136346995830536,
        "compression_ratio": 1.5801526717557253,
        "end": 2616.6,
        "id": 689,
        "no_speech_prob": 0.0966968759894371,
        "seek": 258960,
        "start": 2614.6,
        "temperature": 0,
        "text": " I'll insert it back into this course.",
        "tokens": [
          51614,
          286,
          603,
          8969,
          309,
          646,
          666,
          341,
          1164,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2618.6,
        "id": 690,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2616.6,
        "temperature": 0,
        "text": " So I'm going to do a little introduction.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          360,
          257,
          707,
          9339,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2620.6,
        "id": 691,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2618.6,
        "temperature": 0,
        "text": " I want to first lay out what the topic is,",
        "tokens": [
          50464,
          286,
          528,
          281,
          700,
          2360,
          484,
          437,
          264,
          4829,
          307,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2623.6,
        "id": 692,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2620.6,
        "temperature": 0,
        "text": " but also explain to people that these aren't necessarily sequenced,",
        "tokens": [
          50564,
          457,
          611,
          2903,
          281,
          561,
          300,
          613,
          3212,
          380,
          4725,
          5123,
          14672,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2625.6,
        "id": 693,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2623.6,
        "temperature": 0,
        "text": " but if you're watching in this playlist, they are.",
        "tokens": [
          50714,
          457,
          498,
          291,
          434,
          1976,
          294,
          341,
          16788,
          11,
          436,
          366,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2627.6,
        "id": 694,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2625.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2629.6,
        "id": 695,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2627.6,
        "temperature": 0,
        "text": " So sorry I'm going to say everything twice,",
        "tokens": [
          50914,
          407,
          2597,
          286,
          478,
          516,
          281,
          584,
          1203,
          6091,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2631.6,
        "id": 696,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2629.6,
        "temperature": 0,
        "text": " but I have to sort of figure it out.",
        "tokens": [
          51014,
          457,
          286,
          362,
          281,
          1333,
          295,
          2573,
          309,
          484,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2633.6,
        "id": 697,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2631.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2637.6,
        "id": 698,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2633.6,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51214,
          1692,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2640.6,
        "id": 699,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2637.6,
        "temperature": 0,
        "text": " Let's begin.",
        "tokens": [
          51414,
          961,
          311,
          1841,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.31799902482466263,
        "compression_ratio": 1.5954545454545455,
        "end": 2643.6,
        "id": 700,
        "no_speech_prob": 0.6546354293823242,
        "seek": 261660,
        "start": 2640.6,
        "temperature": 0,
        "text": " I'm going to leave this here.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          1856,
          341,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2645.6,
        "id": 701,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2643.6,
        "temperature": 0,
        "text": " Let me actually...",
        "tokens": [
          50364,
          961,
          385,
          767,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2647.6,
        "id": 702,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2645.6,
        "temperature": 0,
        "text": " So I will...",
        "tokens": [
          50464,
          407,
          286,
          486,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2649.6,
        "id": 703,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2647.6,
        "temperature": 0,
        "text": " Oh, yeah. Okay.",
        "tokens": [
          50564,
          876,
          11,
          1338,
          13,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2651.6,
        "id": 704,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2649.6,
        "temperature": 0,
        "text": " Ooh, this is a mistake.",
        "tokens": [
          50664,
          7951,
          11,
          341,
          307,
          257,
          6146,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2653.6,
        "id": 705,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2651.6,
        "temperature": 0,
        "text": " Mmm.",
        "tokens": [
          50764,
          12146,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2655.6,
        "id": 706,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2653.6,
        "temperature": 0,
        "text": " I'm not logged... I always forget that I'm not logged in at GitHub.",
        "tokens": [
          50864,
          286,
          478,
          406,
          27231,
          485,
          286,
          1009,
          2870,
          300,
          286,
          478,
          406,
          27231,
          294,
          412,
          23331,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2657.6,
        "id": 707,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2655.6,
        "temperature": 0,
        "text": " I need to fix this bottom link.",
        "tokens": [
          50964,
          286,
          643,
          281,
          3191,
          341,
          2767,
          2113,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2659.6,
        "id": 708,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2657.6,
        "temperature": 0,
        "text": " Wait, I can do... Ah, never mind. It's fine.",
        "tokens": [
          51064,
          3802,
          11,
          286,
          393,
          360,
          485,
          2438,
          11,
          1128,
          1575,
          13,
          467,
          311,
          2489,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2661.6,
        "id": 709,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2659.6,
        "temperature": 0,
        "text": " I got it.",
        "tokens": [
          51164,
          286,
          658,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2663.6,
        "id": 710,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2661.6,
        "temperature": 0,
        "text": " Time is of the essence. Okay.",
        "tokens": [
          51264,
          6161,
          307,
          295,
          264,
          12801,
          13,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2665.6,
        "id": 711,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2663.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2667.6,
        "id": 712,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2665.6,
        "temperature": 0,
        "text": " So maybe you watched the first...",
        "tokens": [
          51464,
          407,
          1310,
          291,
          6337,
          264,
          700,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.2415210018638803,
        "compression_ratio": 1.497816593886463,
        "end": 2670.6,
        "id": 713,
        "no_speech_prob": 0.009267620742321014,
        "seek": 264360,
        "start": 2667.6,
        "temperature": 0,
        "text": " The introduction to this larger playlist,",
        "tokens": [
          51564,
          440,
          9339,
          281,
          341,
          4833,
          16788,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2673.6,
        "id": 714,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2670.6,
        "temperature": 0,
        "text": " the intelligence and learning set of videos,",
        "tokens": [
          50364,
          264,
          7599,
          293,
          2539,
          992,
          295,
          2145,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2677.6,
        "id": 715,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2673.6,
        "temperature": 0,
        "text": " but now this video is an introduction to just the first session.",
        "tokens": [
          50514,
          457,
          586,
          341,
          960,
          307,
          364,
          9339,
          281,
          445,
          264,
          700,
          5481,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2681.6,
        "id": 716,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2677.6,
        "temperature": 0,
        "text": " And the first session is about search and graph systems.",
        "tokens": [
          50714,
          400,
          264,
          700,
          5481,
          307,
          466,
          3164,
          293,
          4295,
          3652,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2683.6,
        "id": 717,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2681.6,
        "temperature": 0,
        "text": " Now, why? Why?",
        "tokens": [
          50914,
          823,
          11,
          983,
          30,
          1545,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2685.6,
        "id": 718,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2683.6,
        "temperature": 0,
        "text": " Why should that be the first session?",
        "tokens": [
          51014,
          1545,
          820,
          300,
          312,
          264,
          700,
          5481,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2687.6,
        "id": 719,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2685.6,
        "temperature": 0,
        "text": " I don't know. It might be a bad idea.",
        "tokens": [
          51114,
          286,
          500,
          380,
          458,
          13,
          467,
          1062,
          312,
          257,
          1578,
          1558,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2689.6,
        "id": 720,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2687.6,
        "temperature": 0,
        "text": " First of all, I wanted a warm-up.",
        "tokens": [
          51214,
          2386,
          295,
          439,
          11,
          286,
          1415,
          257,
          4561,
          12,
          1010,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2692.6,
        "id": 721,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2689.6,
        "temperature": 0,
        "text": " So I wanted something to kind of get us thinking about algorithms and data",
        "tokens": [
          51314,
          407,
          286,
          1415,
          746,
          281,
          733,
          295,
          483,
          505,
          1953,
          466,
          14642,
          293,
          1412,
          51464
        ]
      },
      {
        "avg_logprob": -0.20392587449815539,
        "compression_ratio": 1.7248062015503876,
        "end": 2696.6,
        "id": 722,
        "no_speech_prob": 0.04958589747548103,
        "seek": 267060,
        "start": 2692.6,
        "temperature": 0,
        "text": " and things that seem intelligent or that solve problems in an intelligent way.",
        "tokens": [
          51464,
          293,
          721,
          300,
          1643,
          13232,
          420,
          300,
          5039,
          2740,
          294,
          364,
          13232,
          636,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2702.6,
        "id": 723,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2697.6,
        "temperature": 0,
        "text": " And also, there are some very, in some ways, common unsolved problems of computer science,",
        "tokens": [
          50414,
          400,
          611,
          11,
          456,
          366,
          512,
          588,
          11,
          294,
          512,
          2098,
          11,
          2689,
          2693,
          29110,
          2740,
          295,
          3820,
          3497,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2706.6,
        "id": 724,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2702.6,
        "temperature": 0,
        "text": " like the traveling salesperson problem, which is one of the topics of this week,",
        "tokens": [
          50664,
          411,
          264,
          9712,
          5763,
          10813,
          1154,
          11,
          597,
          307,
          472,
          295,
          264,
          8378,
          295,
          341,
          1243,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2712.6,
        "id": 725,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2706.6,
        "temperature": 0,
        "text": " that could use a newly invented machine learning system to solve it.",
        "tokens": [
          50864,
          300,
          727,
          764,
          257,
          15109,
          14479,
          3479,
          2539,
          1185,
          281,
          5039,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2714.6,
        "id": 726,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2712.6,
        "temperature": 0,
        "text": " So anyway, I'm off track.",
        "tokens": [
          51164,
          407,
          4033,
          11,
          286,
          478,
          766,
          2837,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2716.6,
        "id": 727,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2714.6,
        "temperature": 0,
        "text": " So where does this fit in?",
        "tokens": [
          51264,
          407,
          689,
          775,
          341,
          3318,
          294,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2719.6,
        "id": 728,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2716.6,
        "temperature": 0,
        "text": " So if you go and grab... I wish I had my props.",
        "tokens": [
          51364,
          407,
          498,
          291,
          352,
          293,
          4444,
          485,
          286,
          3172,
          286,
          632,
          452,
          26173,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2721.6,
        "id": 729,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2719.6,
        "temperature": 0,
        "text": " Can we get some post-production here?",
        "tokens": [
          51514,
          1664,
          321,
          483,
          512,
          2183,
          12,
          40827,
          510,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2723.6,
        "id": 730,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2721.6,
        "temperature": 0,
        "text": " I'm going to hold up the...",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          1797,
          493,
          264,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.2268052520751953,
        "compression_ratio": 1.595667870036101,
        "end": 2725.6,
        "id": 731,
        "no_speech_prob": 0.0792015790939331,
        "seek": 269660,
        "start": 2723.6,
        "temperature": 0,
        "text": " What's the book that I always use?",
        "tokens": [
          51714,
          708,
          311,
          264,
          1446,
          300,
          286,
          1009,
          764,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.23317898930730047,
        "compression_ratio": 1.4390243902439024,
        "end": 2727.6,
        "id": 732,
        "no_speech_prob": 0.0010162367252632976,
        "seek": 272560,
        "start": 2725.6,
        "temperature": 0,
        "text": " Hold on. Time out.",
        "tokens": [
          50364,
          6962,
          322,
          13,
          6161,
          484,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23317898930730047,
        "compression_ratio": 1.4390243902439024,
        "end": 2733.6,
        "id": 733,
        "no_speech_prob": 0.0010162367252632976,
        "seek": 272560,
        "start": 2729.6,
        "temperature": 0,
        "text": " It's the Norvig Artificial Intelligence...",
        "tokens": [
          50564,
          467,
          311,
          264,
          6966,
          85,
          328,
          5735,
          10371,
          27274,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.23317898930730047,
        "compression_ratio": 1.4390243902439024,
        "end": 2738.6,
        "id": 734,
        "no_speech_prob": 0.0010162367252632976,
        "seek": 272560,
        "start": 2736.6,
        "temperature": 0,
        "text": " I just want to get the name of it correct.",
        "tokens": [
          50914,
          286,
          445,
          528,
          281,
          483,
          264,
          1315,
          295,
          309,
          3006,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23317898930730047,
        "compression_ratio": 1.4390243902439024,
        "end": 2742.6,
        "id": 735,
        "no_speech_prob": 0.0010162367252632976,
        "seek": 272560,
        "start": 2738.6,
        "temperature": 0,
        "text": " Artificial Intelligence, a Modern Approach by Russell and Norvig.",
        "tokens": [
          51014,
          5735,
          10371,
          27274,
          11,
          257,
          19814,
          29551,
          608,
          538,
          20937,
          293,
          6966,
          85,
          328,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23317898930730047,
        "compression_ratio": 1.4390243902439024,
        "end": 2744.6,
        "id": 736,
        "no_speech_prob": 0.0010162367252632976,
        "seek": 272560,
        "start": 2742.6,
        "temperature": 0,
        "text": " Okay, that's what I was going to...",
        "tokens": [
          51214,
          1033,
          11,
          300,
          311,
          437,
          286,
          390,
          516,
          281,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.23317898930730047,
        "compression_ratio": 1.4390243902439024,
        "end": 2747.6,
        "id": 737,
        "no_speech_prob": 0.0010162367252632976,
        "seek": 272560,
        "start": 2745.6,
        "temperature": 0,
        "text": " Good luck editing this.",
        "tokens": [
          51364,
          2205,
          3668,
          10000,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23317898930730047,
        "compression_ratio": 1.4390243902439024,
        "end": 2749.6,
        "id": 738,
        "no_speech_prob": 0.0010162367252632976,
        "seek": 272560,
        "start": 2747.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2758.6,
        "id": 739,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2756.6,
        "temperature": 0,
        "text": " I'm going to pretend.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          11865,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2761.6,
        "id": 740,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2758.6,
        "temperature": 0,
        "text": " I'm just going to pretend I'm doing that again, which is so ridiculous.",
        "tokens": [
          50514,
          286,
          478,
          445,
          516,
          281,
          11865,
          286,
          478,
          884,
          300,
          797,
          11,
          597,
          307,
          370,
          11083,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2764.6,
        "id": 741,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2761.6,
        "temperature": 0,
        "text": " I'm going to do it anyway. Oh, God. I can't believe I do these live.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          360,
          309,
          4033,
          13,
          876,
          11,
          1265,
          13,
          286,
          393,
          380,
          1697,
          286,
          360,
          613,
          1621,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2767.6,
        "id": 742,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2765.6,
        "temperature": 0,
        "text": " Oh, I don't have my props.",
        "tokens": [
          50864,
          876,
          11,
          286,
          500,
          380,
          362,
          452,
          26173,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2774.6,
        "id": 743,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2767.6,
        "temperature": 0,
        "text": " If I had my book, Artificial Intelligence, a Modern Approach, the Norvig-Russell book...",
        "tokens": [
          50964,
          759,
          286,
          632,
          452,
          1446,
          11,
          5735,
          10371,
          27274,
          11,
          257,
          19814,
          29551,
          608,
          11,
          264,
          6966,
          85,
          328,
          12,
          49,
          301,
          14555,
          1446,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2776.6,
        "id": 744,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2774.6,
        "temperature": 0,
        "text": " Yes? I don't know. Hopefully I got that right.",
        "tokens": [
          51314,
          1079,
          30,
          286,
          500,
          380,
          458,
          13,
          10429,
          286,
          658,
          300,
          558,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2779.6,
        "id": 745,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2776.6,
        "temperature": 0,
        "text": " You would see a lot of... I don't have my pen anymore.",
        "tokens": [
          51414,
          509,
          576,
          536,
          257,
          688,
          295,
          485,
          286,
          500,
          380,
          362,
          452,
          3435,
          3602,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22471675872802735,
        "compression_ratio": 1.6015936254980079,
        "end": 2781.6,
        "id": 746,
        "no_speech_prob": 0.006903548259288073,
        "seek": 275560,
        "start": 2779.6,
        "temperature": 0,
        "text": " Ah! Continuity error.",
        "tokens": [
          51564,
          2438,
          0,
          14674,
          21757,
          6713,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2369131391698664,
        "compression_ratio": 1.7079646017699115,
        "end": 2787.6,
        "id": 747,
        "no_speech_prob": 0.004681732971221209,
        "seek": 278160,
        "start": 2782.6,
        "temperature": 0,
        "text": " You would notice that there's a lot of algorithms in these books about search.",
        "tokens": [
          50414,
          509,
          576,
          3449,
          300,
          456,
          311,
          257,
          688,
          295,
          14642,
          294,
          613,
          3642,
          466,
          3164,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2369131391698664,
        "compression_ratio": 1.7079646017699115,
        "end": 2792.6,
        "id": 748,
        "no_speech_prob": 0.004681732971221209,
        "seek": 278160,
        "start": 2787.6,
        "temperature": 0,
        "text": " Because one of the kinds of problems that artificial intelligence algorithms,",
        "tokens": [
          50664,
          1436,
          472,
          295,
          264,
          3685,
          295,
          2740,
          300,
          11677,
          7599,
          14642,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2369131391698664,
        "compression_ratio": 1.7079646017699115,
        "end": 2797.6,
        "id": 749,
        "no_speech_prob": 0.004681732971221209,
        "seek": 278160,
        "start": 2792.6,
        "temperature": 0,
        "text": " that intelligent algorithms often need to solve in computer science,",
        "tokens": [
          50914,
          300,
          13232,
          14642,
          2049,
          643,
          281,
          5039,
          294,
          3820,
          3497,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2369131391698664,
        "compression_ratio": 1.7079646017699115,
        "end": 2802.6,
        "id": 750,
        "no_speech_prob": 0.004681732971221209,
        "seek": 278160,
        "start": 2797.6,
        "temperature": 0,
        "text": " in applications, interactivity, all the sort of projects you might be thinking of making,",
        "tokens": [
          51164,
          294,
          5821,
          11,
          4648,
          4253,
          11,
          439,
          264,
          1333,
          295,
          4455,
          291,
          1062,
          312,
          1953,
          295,
          1455,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2369131391698664,
        "compression_ratio": 1.7079646017699115,
        "end": 2805.6,
        "id": 751,
        "no_speech_prob": 0.004681732971221209,
        "seek": 278160,
        "start": 2802.6,
        "temperature": 0,
        "text": " is there's a problem.",
        "tokens": [
          51414,
          307,
          456,
          311,
          257,
          1154,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2369131391698664,
        "compression_ratio": 1.7079646017699115,
        "end": 2808.6,
        "id": 752,
        "no_speech_prob": 0.004681732971221209,
        "seek": 278160,
        "start": 2805.6,
        "temperature": 0,
        "text": " I need to figure out the answer to this problem.",
        "tokens": [
          51564,
          286,
          643,
          281,
          2573,
          484,
          264,
          1867,
          281,
          341,
          1154,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17654441197713217,
        "compression_ratio": 1.6422018348623852,
        "end": 2813.6,
        "id": 753,
        "no_speech_prob": 0.0007793601253069937,
        "seek": 280860,
        "start": 2808.6,
        "temperature": 0,
        "text": " But there are so many possible answers, I couldn't possibly check every single one.",
        "tokens": [
          50364,
          583,
          456,
          366,
          370,
          867,
          1944,
          6338,
          11,
          286,
          2809,
          380,
          6264,
          1520,
          633,
          2167,
          472,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17654441197713217,
        "compression_ratio": 1.6422018348623852,
        "end": 2821.6,
        "id": 754,
        "no_speech_prob": 0.0007793601253069937,
        "seek": 280860,
        "start": 2813.6,
        "temperature": 0,
        "text": " And so, search refers to the idea of searching for the answer in a sea of possibilities.",
        "tokens": [
          50614,
          400,
          370,
          11,
          3164,
          14942,
          281,
          264,
          1558,
          295,
          10808,
          337,
          264,
          1867,
          294,
          257,
          4158,
          295,
          12178,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17654441197713217,
        "compression_ratio": 1.6422018348623852,
        "end": 2824.6,
        "id": 755,
        "no_speech_prob": 0.0007793601253069937,
        "seek": 280860,
        "start": 2821.6,
        "temperature": 0,
        "text": " Now, one way is to search every single possibility.",
        "tokens": [
          51014,
          823,
          11,
          472,
          636,
          307,
          281,
          3164,
          633,
          2167,
          7959,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17654441197713217,
        "compression_ratio": 1.6422018348623852,
        "end": 2826.6,
        "id": 756,
        "no_speech_prob": 0.0007793601253069937,
        "seek": 280860,
        "start": 2824.6,
        "temperature": 0,
        "text": " I mentioned the traveling salesperson problem.",
        "tokens": [
          51164,
          286,
          2835,
          264,
          9712,
          5763,
          10813,
          1154,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17654441197713217,
        "compression_ratio": 1.6422018348623852,
        "end": 2828.6,
        "id": 757,
        "no_speech_prob": 0.0007793601253069937,
        "seek": 280860,
        "start": 2826.6,
        "temperature": 0,
        "text": " Let's talk about that for a second.",
        "tokens": [
          51264,
          961,
          311,
          751,
          466,
          300,
          337,
          257,
          1150,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17654441197713217,
        "compression_ratio": 1.6422018348623852,
        "end": 2837.6,
        "id": 758,
        "no_speech_prob": 0.0007793601253069937,
        "seek": 280860,
        "start": 2830.6,
        "temperature": 0,
        "text": " So, I want to talk about search and graph systems.",
        "tokens": [
          51464,
          407,
          11,
          286,
          528,
          281,
          751,
          466,
          3164,
          293,
          4295,
          3652,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2840.6,
        "id": 759,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2837.6,
        "temperature": 0,
        "text": " This is kind of loosely the topic for right now.",
        "tokens": [
          50364,
          639,
          307,
          733,
          295,
          37966,
          264,
          4829,
          337,
          558,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2845.6,
        "id": 760,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2841.6,
        "temperature": 0,
        "text": " There goes that eraser. Oh my god! Sorry everybody!",
        "tokens": [
          50564,
          821,
          1709,
          300,
          46018,
          13,
          876,
          452,
          3044,
          0,
          4919,
          2201,
          0,
          50764
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2847.6,
        "id": 761,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2845.6,
        "temperature": 0,
        "text": " The eraser's okay. Everything's fine.",
        "tokens": [
          50764,
          440,
          46018,
          311,
          1392,
          13,
          5471,
          311,
          2489,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2851.6,
        "id": 762,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2847.6,
        "temperature": 0,
        "text": " So, the traveling salesperson problem says...",
        "tokens": [
          50864,
          407,
          11,
          264,
          9712,
          5763,
          10813,
          1154,
          1619,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2854.6,
        "id": 763,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2851.6,
        "temperature": 0,
        "text": " Oh, I have videos on this already. So, you can go watch those.",
        "tokens": [
          51064,
          876,
          11,
          286,
          362,
          2145,
          322,
          341,
          1217,
          13,
          407,
          11,
          291,
          393,
          352,
          1159,
          729,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2856.6,
        "id": 764,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2854.6,
        "temperature": 0,
        "text": " There are some number of cities.",
        "tokens": [
          51214,
          821,
          366,
          512,
          1230,
          295,
          6486,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2860.6,
        "id": 765,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2858.6,
        "temperature": 0,
        "text": " Let's say there are five.",
        "tokens": [
          51414,
          961,
          311,
          584,
          456,
          366,
          1732,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25450218425077553,
        "compression_ratio": 1.5603448275862069,
        "end": 2865.6,
        "id": 766,
        "no_speech_prob": 0.00012931103992741555,
        "seek": 283760,
        "start": 2860.6,
        "temperature": 0,
        "text": " And that a salesperson needs to visit all of the cities",
        "tokens": [
          51514,
          400,
          300,
          257,
          5763,
          10813,
          2203,
          281,
          3441,
          439,
          295,
          264,
          6486,
          51764
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2868.6,
        "id": 767,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2865.6,
        "temperature": 0,
        "text": " in the shortest amount of time or with the shortest distance.",
        "tokens": [
          50364,
          294,
          264,
          31875,
          2372,
          295,
          565,
          420,
          365,
          264,
          31875,
          4560,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2871.6,
        "id": 768,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2868.6,
        "temperature": 0,
        "text": " In any order. Starting with any one, ending with any one.",
        "tokens": [
          50514,
          682,
          604,
          1668,
          13,
          16217,
          365,
          604,
          472,
          11,
          8121,
          365,
          604,
          472,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2874.6,
        "id": 769,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2871.6,
        "temperature": 0,
        "text": " So, I might be able to eyeball this and say,",
        "tokens": [
          50664,
          407,
          11,
          286,
          1062,
          312,
          1075,
          281,
          38868,
          341,
          293,
          584,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2876.6,
        "id": 770,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2874.6,
        "temperature": 0,
        "text": " okay, well, maybe that's the path.",
        "tokens": [
          50814,
          1392,
          11,
          731,
          11,
          1310,
          300,
          311,
          264,
          3100,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2878.6,
        "id": 771,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2876.6,
        "temperature": 0,
        "text": " It's probably not the path. It's probably more like this.",
        "tokens": [
          50914,
          467,
          311,
          1391,
          406,
          264,
          3100,
          13,
          467,
          311,
          1391,
          544,
          411,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2881.6,
        "id": 772,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2878.6,
        "temperature": 0,
        "text": " Whatever. The point is, we could have a computer algorithm figure this out.",
        "tokens": [
          51014,
          8541,
          13,
          440,
          935,
          307,
          11,
          321,
          727,
          362,
          257,
          3820,
          9284,
          2573,
          341,
          484,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2883.6,
        "id": 773,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2881.6,
        "temperature": 0,
        "text": " Let's just check every single possibility.",
        "tokens": [
          51164,
          961,
          311,
          445,
          1520,
          633,
          2167,
          7959,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2885.6,
        "id": 774,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2883.6,
        "temperature": 0,
        "text": " So, first, let's pick a city.",
        "tokens": [
          51264,
          407,
          11,
          700,
          11,
          718,
          311,
          1888,
          257,
          2307,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2888.6,
        "id": 775,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2885.6,
        "temperature": 0,
        "text": " How many cities should I pick? How many cities could I pick?",
        "tokens": [
          51364,
          1012,
          867,
          6486,
          820,
          286,
          1888,
          30,
          1012,
          867,
          6486,
          727,
          286,
          1888,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2890.6,
        "id": 776,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2888.6,
        "temperature": 0,
        "text": " Oh, there's five of them. Okay.",
        "tokens": [
          51514,
          876,
          11,
          456,
          311,
          1732,
          295,
          552,
          13,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2892.6,
        "id": 777,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2890.6,
        "temperature": 0,
        "text": " Now, if I pick... If there's five possibilities.",
        "tokens": [
          51614,
          823,
          11,
          498,
          286,
          1888,
          485,
          759,
          456,
          311,
          1732,
          12178,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21665573120117188,
        "compression_ratio": 1.8871951219512195,
        "end": 2894.6,
        "id": 778,
        "no_speech_prob": 0.01665549911558628,
        "seek": 286560,
        "start": 2892.6,
        "temperature": 0,
        "text": " Now, once I've picked one city, how many possibilities are there left?",
        "tokens": [
          51714,
          823,
          11,
          1564,
          286,
          600,
          6183,
          472,
          2307,
          11,
          577,
          867,
          12178,
          366,
          456,
          1411,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2896.6,
        "id": 779,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2894.6,
        "temperature": 0,
        "text": " Four.",
        "tokens": [
          50364,
          7451,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2898.6,
        "id": 780,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2896.6,
        "temperature": 0,
        "text": " And how many are left? Three.",
        "tokens": [
          50464,
          400,
          577,
          867,
          366,
          1411,
          30,
          6244,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2900.6,
        "id": 781,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2898.6,
        "temperature": 0,
        "text": " And how many are left? Two. And how many are left? One.",
        "tokens": [
          50564,
          400,
          577,
          867,
          366,
          1411,
          30,
          4453,
          13,
          400,
          577,
          867,
          366,
          1411,
          30,
          1485,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2902.6,
        "id": 782,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2900.6,
        "temperature": 0,
        "text": " So, five factorial. 20, 60, 120.",
        "tokens": [
          50664,
          407,
          11,
          1732,
          36916,
          13,
          945,
          11,
          4060,
          11,
          10411,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2905.6,
        "id": 783,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2902.6,
        "temperature": 0,
        "text": " 120 possibilities for five cities.",
        "tokens": [
          50764,
          10411,
          12178,
          337,
          1732,
          6486,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2907.6,
        "id": 784,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2905.6,
        "temperature": 0,
        "text": " And this is five factorial.",
        "tokens": [
          50914,
          400,
          341,
          307,
          1732,
          36916,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2910.6,
        "id": 785,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2907.6,
        "temperature": 0,
        "text": " So, this is the kind of problem that doesn't seem like such a big deal.",
        "tokens": [
          51014,
          407,
          11,
          341,
          307,
          264,
          733,
          295,
          1154,
          300,
          1177,
          380,
          1643,
          411,
          1270,
          257,
          955,
          2028,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2912.6,
        "id": 786,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2910.6,
        "temperature": 0,
        "text": " But if I just have 10 cities...",
        "tokens": [
          51164,
          583,
          498,
          286,
          445,
          362,
          1266,
          6486,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2918.6,
        "id": 787,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2915.6,
        "temperature": 0,
        "text": " What's 10 factorial? Eh, I don't know.",
        "tokens": [
          51414,
          708,
          311,
          1266,
          36916,
          30,
          9663,
          11,
          286,
          500,
          380,
          458,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2921.6,
        "id": 788,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2918.6,
        "temperature": 0,
        "text": " A computer could probably crunch through that number.",
        "tokens": [
          51564,
          316,
          3820,
          727,
          1391,
          13386,
          807,
          300,
          1230,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19972568942654517,
        "compression_ratio": 1.7130801687763713,
        "end": 2923.6,
        "id": 789,
        "no_speech_prob": 0.00044421726488508284,
        "seek": 289460,
        "start": 2921.6,
        "temperature": 0,
        "text": " What about 50 cities?",
        "tokens": [
          51714,
          708,
          466,
          2625,
          6486,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2930.6,
        "id": 790,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2925.6,
        "temperature": 0,
        "text": " Okay. That's a three with 64 zeros after it.",
        "tokens": [
          50414,
          1033,
          13,
          663,
          311,
          257,
          1045,
          365,
          12145,
          35193,
          934,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2933.6,
        "id": 791,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2930.6,
        "temperature": 0,
        "text": " It's like a really, really, really big number.",
        "tokens": [
          50664,
          467,
          311,
          411,
          257,
          534,
          11,
          534,
          11,
          534,
          955,
          1230,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2938.6,
        "id": 792,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2933.6,
        "temperature": 0,
        "text": " I mean, what's the age of the known universe?",
        "tokens": [
          50814,
          286,
          914,
          11,
          437,
          311,
          264,
          3205,
          295,
          264,
          2570,
          6445,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2943.6,
        "id": 793,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2941.6,
        "temperature": 0,
        "text": " It's just 13.772 billion years.",
        "tokens": [
          51214,
          467,
          311,
          445,
          3705,
          13,
          17512,
          17,
          5218,
          924,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2945.6,
        "id": 794,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2943.6,
        "temperature": 0,
        "text": " That other number's a lot more than that.",
        "tokens": [
          51314,
          663,
          661,
          1230,
          311,
          257,
          688,
          544,
          813,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2949.6,
        "id": 795,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2945.6,
        "temperature": 0,
        "text": " So, and, you know, even if we could do like a million per second or something,",
        "tokens": [
          51414,
          407,
          11,
          293,
          11,
          291,
          458,
          11,
          754,
          498,
          321,
          727,
          360,
          411,
          257,
          2459,
          680,
          1150,
          420,
          746,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2951.6,
        "id": 796,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2949.6,
        "temperature": 0,
        "text": " trust me, we're going to have some issues.",
        "tokens": [
          51614,
          3361,
          385,
          11,
          321,
          434,
          516,
          281,
          362,
          512,
          2663,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2303123644420079,
        "compression_ratio": 1.5450643776824033,
        "end": 2952.6,
        "id": 797,
        "no_speech_prob": 0.000041335239075124264,
        "seek": 292460,
        "start": 2951.6,
        "temperature": 0,
        "text": " And we'll talk about that.",
        "tokens": [
          51714,
          400,
          321,
          603,
          751,
          466,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2953.6,
        "id": 798,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2952.6,
        "temperature": 0,
        "text": " So, what are some solutions to this?",
        "tokens": [
          50364,
          407,
          11,
          437,
          366,
          512,
          6547,
          281,
          341,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2955.6,
        "id": 799,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2953.6,
        "temperature": 0,
        "text": " Next week, we're going to look at genetic algorithms,",
        "tokens": [
          50414,
          3087,
          1243,
          11,
          321,
          434,
          516,
          281,
          574,
          412,
          12462,
          14642,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2959.6,
        "id": 800,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2955.6,
        "temperature": 0,
        "text": " which is a technique for trying to optimally find a solution.",
        "tokens": [
          50514,
          597,
          307,
          257,
          6532,
          337,
          1382,
          281,
          5028,
          379,
          915,
          257,
          3827,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2963.6,
        "id": 801,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2959.6,
        "temperature": 0,
        "text": " And there are ways we might say something known as a greedy algorithm.",
        "tokens": [
          50714,
          400,
          456,
          366,
          2098,
          321,
          1062,
          584,
          746,
          2570,
          382,
          257,
          28228,
          9284,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2966.6,
        "id": 802,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2963.6,
        "temperature": 0,
        "text": " I went off on a tangent here.",
        "tokens": [
          50914,
          286,
          1437,
          766,
          322,
          257,
          27747,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2968.6,
        "id": 803,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2966.6,
        "temperature": 0,
        "text": " We'll see if this is a problem. We'll edit this part out.",
        "tokens": [
          51064,
          492,
          603,
          536,
          498,
          341,
          307,
          257,
          1154,
          13,
          492,
          603,
          8129,
          341,
          644,
          484,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2970.6,
        "id": 804,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2968.6,
        "temperature": 0,
        "text": " But a greedy algorithm, which might say, like, I don't know,",
        "tokens": [
          51164,
          583,
          257,
          28228,
          9284,
          11,
          597,
          1062,
          584,
          11,
          411,
          11,
          286,
          500,
          380,
          458,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2972.6,
        "id": 805,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2970.6,
        "temperature": 0,
        "text": " let's just pick a city and then pick the closest one,",
        "tokens": [
          51264,
          718,
          311,
          445,
          1888,
          257,
          2307,
          293,
          550,
          1888,
          264,
          13699,
          472,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2974.6,
        "id": 806,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2972.6,
        "temperature": 0,
        "text": " then pick the closest one to that.",
        "tokens": [
          51364,
          550,
          1888,
          264,
          13699,
          472,
          281,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2976.6,
        "id": 807,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2974.6,
        "temperature": 0,
        "text": " It's probably going to get us a pretty good answer,",
        "tokens": [
          51464,
          467,
          311,
          1391,
          516,
          281,
          483,
          505,
          257,
          1238,
          665,
          1867,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2978.6,
        "id": 808,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2976.6,
        "temperature": 0,
        "text": " even if it's not the exact optimal answer.",
        "tokens": [
          51564,
          754,
          498,
          309,
          311,
          406,
          264,
          1900,
          16252,
          1867,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17768595592085137,
        "compression_ratio": 1.8348909657320873,
        "end": 2979.6,
        "id": 809,
        "no_speech_prob": 0.2941538095474243,
        "seek": 295260,
        "start": 2978.6,
        "temperature": 0,
        "text": " The point of what I'm saying is,",
        "tokens": [
          51664,
          440,
          935,
          295,
          437,
          286,
          478,
          1566,
          307,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.21287575250939478,
        "compression_ratio": 1.513089005235602,
        "end": 2983.6,
        "id": 810,
        "no_speech_prob": 0.052616510540246964,
        "seek": 297960,
        "start": 2979.6,
        "temperature": 0,
        "text": " this is the application that I want to look at in this first week.",
        "tokens": [
          50364,
          341,
          307,
          264,
          3861,
          300,
          286,
          528,
          281,
          574,
          412,
          294,
          341,
          700,
          1243,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21287575250939478,
        "compression_ratio": 1.513089005235602,
        "end": 2987.6,
        "id": 811,
        "no_speech_prob": 0.052616510540246964,
        "seek": 297960,
        "start": 2983.6,
        "temperature": 0,
        "text": " So, the things that we need to learn about to be able to do things",
        "tokens": [
          50564,
          407,
          11,
          264,
          721,
          300,
          321,
          643,
          281,
          1466,
          466,
          281,
          312,
          1075,
          281,
          360,
          721,
          50764
        ]
      },
      {
        "avg_logprob": -0.21287575250939478,
        "compression_ratio": 1.513089005235602,
        "end": 2990.6,
        "id": 812,
        "no_speech_prob": 0.052616510540246964,
        "seek": 297960,
        "start": 2987.6,
        "temperature": 0,
        "text": " and work with problems like the traveling salesperson are,",
        "tokens": [
          50764,
          293,
          589,
          365,
          2740,
          411,
          264,
          9712,
          5763,
          10813,
          366,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.21287575250939478,
        "compression_ratio": 1.513089005235602,
        "end": 2994.6,
        "id": 813,
        "no_speech_prob": 0.052616510540246964,
        "seek": 297960,
        "start": 2990.6,
        "temperature": 0,
        "text": " number one, graph systems.",
        "tokens": [
          50914,
          1230,
          472,
          11,
          4295,
          3652,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21287575250939478,
        "compression_ratio": 1.513089005235602,
        "end": 3000.6,
        "id": 814,
        "no_speech_prob": 0.052616510540246964,
        "seek": 297960,
        "start": 2994.6,
        "temperature": 0,
        "text": " And number two, search algorithms.",
        "tokens": [
          51114,
          400,
          1230,
          732,
          11,
          3164,
          14642,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21287575250939478,
        "compression_ratio": 1.513089005235602,
        "end": 3005.6,
        "id": 815,
        "no_speech_prob": 0.052616510540246964,
        "seek": 297960,
        "start": 3000.6,
        "temperature": 0,
        "text": " Okay. Now, what is a graph system?",
        "tokens": [
          51414,
          1033,
          13,
          823,
          11,
          437,
          307,
          257,
          4295,
          1185,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3010.6,
        "id": 816,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3005.6,
        "temperature": 0,
        "text": " A graph system is something,",
        "tokens": [
          50364,
          316,
          4295,
          1185,
          307,
          746,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3013.6,
        "id": 817,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3010.6,
        "temperature": 0,
        "text": " a system that is made up of two elements,",
        "tokens": [
          50614,
          257,
          1185,
          300,
          307,
          1027,
          493,
          295,
          732,
          4959,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3016.6,
        "id": 818,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3013.6,
        "temperature": 0,
        "text": " node and an edge.",
        "tokens": [
          50764,
          9984,
          293,
          364,
          4691,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3017.6,
        "id": 819,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3016.6,
        "temperature": 0,
        "text": " We could name these other things,",
        "tokens": [
          50914,
          492,
          727,
          1315,
          613,
          661,
          721,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3020.6,
        "id": 820,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3017.6,
        "temperature": 0,
        "text": " but I'm going to call them nodes and edges.",
        "tokens": [
          50964,
          457,
          286,
          478,
          516,
          281,
          818,
          552,
          13891,
          293,
          8819,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3022.6,
        "id": 821,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3020.6,
        "temperature": 0,
        "text": " One of the next videos that you'll watch,",
        "tokens": [
          51114,
          1485,
          295,
          264,
          958,
          2145,
          300,
          291,
          603,
          1159,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3023.6,
        "id": 822,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3022.6,
        "temperature": 0,
        "text": " if you follow this playlist,",
        "tokens": [
          51214,
          498,
          291,
          1524,
          341,
          16788,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3026.6,
        "id": 823,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3023.6,
        "temperature": 0,
        "text": " will be on something called a binary search tree.",
        "tokens": [
          51264,
          486,
          312,
          322,
          746,
          1219,
          257,
          17434,
          3164,
          4230,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3030.6,
        "id": 824,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3026.6,
        "temperature": 0,
        "text": " A binary tree is a graph system where every node",
        "tokens": [
          51414,
          316,
          17434,
          4230,
          307,
          257,
          4295,
          1185,
          689,
          633,
          9984,
          51614
        ]
      },
      {
        "avg_logprob": -0.17460076625530535,
        "compression_ratio": 1.631578947368421,
        "end": 3033.6,
        "id": 825,
        "no_speech_prob": 0.00014883828407619148,
        "seek": 300560,
        "start": 3030.6,
        "temperature": 0,
        "text": " is connected to two children nodes,",
        "tokens": [
          51614,
          307,
          4582,
          281,
          732,
          2227,
          13891,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3034.6,
        "id": 826,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3033.6,
        "temperature": 0,
        "text": " a left and a right,",
        "tokens": [
          50364,
          257,
          1411,
          293,
          257,
          558,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3036.6,
        "id": 827,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3034.6,
        "temperature": 0,
        "text": " and those are connected to two,",
        "tokens": [
          50414,
          293,
          729,
          366,
          4582,
          281,
          732,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3039.6,
        "id": 828,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3036.6,
        "temperature": 0,
        "text": " and those are connected to two,",
        "tokens": [
          50514,
          293,
          729,
          366,
          4582,
          281,
          732,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3042.6,
        "id": 829,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3039.6,
        "temperature": 0,
        "text": " et cetera, et cetera, et cetera.",
        "tokens": [
          50664,
          1030,
          11458,
          11,
          1030,
          11458,
          11,
          1030,
          11458,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3045.6,
        "id": 830,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3042.6,
        "temperature": 0,
        "text": " So, this is one example of a graph system.",
        "tokens": [
          50814,
          407,
          11,
          341,
          307,
          472,
          1365,
          295,
          257,
          4295,
          1185,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3046.6,
        "id": 831,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3045.6,
        "temperature": 0,
        "text": " So, what you'll notice is,",
        "tokens": [
          50964,
          407,
          11,
          437,
          291,
          603,
          3449,
          307,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3050.6,
        "id": 832,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3046.6,
        "temperature": 0,
        "text": " we need some sort of data structure to store",
        "tokens": [
          51014,
          321,
          643,
          512,
          1333,
          295,
          1412,
          3877,
          281,
          3531,
          51214
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3052.6,
        "id": 833,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3050.6,
        "temperature": 0,
        "text": " what are all the nodes and what are all the edges.",
        "tokens": [
          51214,
          437,
          366,
          439,
          264,
          13891,
          293,
          437,
          366,
          439,
          264,
          8819,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3053.6,
        "id": 834,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3052.6,
        "temperature": 0,
        "text": " And this depends on the problem.",
        "tokens": [
          51314,
          400,
          341,
          5946,
          322,
          264,
          1154,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3056.6,
        "id": 835,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3053.6,
        "temperature": 0,
        "text": " A common example, also, of a graph system",
        "tokens": [
          51364,
          316,
          2689,
          1365,
          11,
          611,
          11,
          295,
          257,
          4295,
          1185,
          51514
        ]
      },
      {
        "avg_logprob": -0.18890022840656218,
        "compression_ratio": 1.8789237668161436,
        "end": 3060.6,
        "id": 836,
        "no_speech_prob": 0.004399375524371862,
        "seek": 303360,
        "start": 3056.6,
        "temperature": 0,
        "text": " similar to the traveling salesperson problem is a subway map.",
        "tokens": [
          51514,
          2531,
          281,
          264,
          9712,
          5763,
          10813,
          1154,
          307,
          257,
          24953,
          4471,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3063.6,
        "id": 837,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3060.6,
        "temperature": 0,
        "text": " So, let's say I need to get from this station to this station.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          584,
          286,
          643,
          281,
          483,
          490,
          341,
          5214,
          281,
          341,
          5214,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3066.6,
        "id": 838,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3063.6,
        "temperature": 0,
        "text": " Well, there are all these other stations and routes,",
        "tokens": [
          50514,
          1042,
          11,
          456,
          366,
          439,
          613,
          661,
          13390,
          293,
          18242,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3068.6,
        "id": 839,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3066.6,
        "temperature": 0,
        "text": " and maybe they all are interconnected,",
        "tokens": [
          50664,
          293,
          1310,
          436,
          439,
          366,
          36611,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3070.6,
        "id": 840,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3068.6,
        "temperature": 0,
        "text": " and there's many ways to get,",
        "tokens": [
          50764,
          293,
          456,
          311,
          867,
          2098,
          281,
          483,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3072.6,
        "id": 841,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3070.6,
        "temperature": 0,
        "text": " and the subway map makes no sense,",
        "tokens": [
          50864,
          293,
          264,
          24953,
          4471,
          1669,
          572,
          2020,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3073.6,
        "id": 842,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3072.6,
        "temperature": 0,
        "text": " there's many ways to get there,",
        "tokens": [
          50964,
          456,
          311,
          867,
          2098,
          281,
          483,
          456,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3076.6,
        "id": 843,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3073.6,
        "temperature": 0,
        "text": " but they all take different amounts of time.",
        "tokens": [
          51014,
          457,
          436,
          439,
          747,
          819,
          11663,
          295,
          565,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3079.6,
        "id": 844,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3076.6,
        "temperature": 0,
        "text": " Like, maybe I could go from here to here",
        "tokens": [
          51164,
          1743,
          11,
          1310,
          286,
          727,
          352,
          490,
          510,
          281,
          510,
          51314
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3080.6,
        "id": 845,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3079.6,
        "temperature": 0,
        "text": " to here to here to here,",
        "tokens": [
          51314,
          281,
          510,
          281,
          510,
          281,
          510,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3084.6,
        "id": 846,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3080.6,
        "temperature": 0,
        "text": " which is, hold on, let me redraw this.",
        "tokens": [
          51364,
          597,
          307,
          11,
          1797,
          322,
          11,
          718,
          385,
          2182,
          5131,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19968470764160157,
        "compression_ratio": 1.8622222222222222,
        "end": 3086.6,
        "id": 847,
        "no_speech_prob": 0.00016346413758583367,
        "seek": 306060,
        "start": 3084.6,
        "temperature": 0,
        "text": " Time out, editor!",
        "tokens": [
          51564,
          6161,
          484,
          11,
          9839,
          0,
          51664
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3090.6,
        "id": 848,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3086.6,
        "temperature": 0,
        "text": " Okay, I'm back, I'm going to redraw that to make more sense.",
        "tokens": [
          50364,
          1033,
          11,
          286,
          478,
          646,
          11,
          286,
          478,
          516,
          281,
          2182,
          5131,
          300,
          281,
          652,
          544,
          2020,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3095.6,
        "id": 849,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3093.6,
        "temperature": 0,
        "text": " Let me just draw it like this.",
        "tokens": [
          50714,
          961,
          385,
          445,
          2642,
          309,
          411,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3098.6,
        "id": 850,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3095.6,
        "temperature": 0,
        "text": " So, let's say we wanted to get from here to here.",
        "tokens": [
          50814,
          407,
          11,
          718,
          311,
          584,
          321,
          1415,
          281,
          483,
          490,
          510,
          281,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3100.6,
        "id": 851,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3098.6,
        "temperature": 0,
        "text": " We could see, like, oh, I'm going to get from,",
        "tokens": [
          50964,
          492,
          727,
          536,
          11,
          411,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          483,
          490,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3102.6,
        "id": 852,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3100.6,
        "temperature": 0,
        "text": " in one step to here, and it's going to,",
        "tokens": [
          51064,
          294,
          472,
          1823,
          281,
          510,
          11,
          293,
          309,
          311,
          516,
          281,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3105.6,
        "id": 853,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3102.6,
        "temperature": 0,
        "text": " two steps, I want to take two trains to get to here.",
        "tokens": [
          51164,
          732,
          4439,
          11,
          286,
          528,
          281,
          747,
          732,
          16329,
          281,
          483,
          281,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3108.6,
        "id": 854,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3105.6,
        "temperature": 0,
        "text": " But what if this train takes 60 minutes,",
        "tokens": [
          51314,
          583,
          437,
          498,
          341,
          3847,
          2516,
          4060,
          2077,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3110.6,
        "id": 855,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3108.6,
        "temperature": 0,
        "text": " this train takes 30 minutes,",
        "tokens": [
          51464,
          341,
          3847,
          2516,
          2217,
          2077,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3112.6,
        "id": 856,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3110.6,
        "temperature": 0,
        "text": " and each one of these, this takes five,",
        "tokens": [
          51564,
          293,
          1184,
          472,
          295,
          613,
          11,
          341,
          2516,
          1732,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3113.6,
        "id": 857,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3112.6,
        "temperature": 0,
        "text": " and this one takes five,",
        "tokens": [
          51664,
          293,
          341,
          472,
          2516,
          1732,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.2816613425671215,
        "compression_ratio": 1.9173913043478261,
        "end": 3114.6,
        "id": 858,
        "no_speech_prob": 0.0018969003576785326,
        "seek": 308660,
        "start": 3113.6,
        "temperature": 0,
        "text": " and this one takes five,",
        "tokens": [
          51714,
          293,
          341,
          472,
          2516,
          1732,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3115.6,
        "id": 859,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3114.6,
        "temperature": 0,
        "text": " and this one takes 30 minutes,",
        "tokens": [
          50364,
          293,
          341,
          472,
          2516,
          2217,
          2077,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3116.6,
        "id": 860,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3115.6,
        "temperature": 0,
        "text": " and each one of these, this takes five,",
        "tokens": [
          50414,
          293,
          1184,
          472,
          295,
          613,
          11,
          341,
          2516,
          1732,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3117.6,
        "id": 861,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3116.6,
        "temperature": 0,
        "text": " this takes two, this takes one,",
        "tokens": [
          50464,
          341,
          2516,
          732,
          11,
          341,
          2516,
          472,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3118.6,
        "id": 862,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3117.6,
        "temperature": 0,
        "text": " and this takes six.",
        "tokens": [
          50514,
          293,
          341,
          2516,
          2309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3122.6,
        "id": 863,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3118.6,
        "temperature": 0,
        "text": " So even though I have to go on one, two, three, four trains,",
        "tokens": [
          50564,
          407,
          754,
          1673,
          286,
          362,
          281,
          352,
          322,
          472,
          11,
          732,
          11,
          1045,
          11,
          1451,
          16329,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3125.6,
        "id": 864,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3122.6,
        "temperature": 0,
        "text": " this is optimal, this will get me there faster.",
        "tokens": [
          50764,
          341,
          307,
          16252,
          11,
          341,
          486,
          483,
          385,
          456,
          4663,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3128.6,
        "id": 865,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3125.6,
        "temperature": 0,
        "text": " This is known as a weighted graph system.",
        "tokens": [
          50914,
          639,
          307,
          2570,
          382,
          257,
          32807,
          4295,
          1185,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3133.6,
        "id": 866,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3130.6,
        "temperature": 0,
        "text": " So the graph system is a bunch of nodes,",
        "tokens": [
          51164,
          407,
          264,
          4295,
          1185,
          307,
          257,
          3840,
          295,
          13891,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3134.6,
        "id": 867,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3133.6,
        "temperature": 0,
        "text": " those nodes might have values,",
        "tokens": [
          51314,
          729,
          13891,
          1062,
          362,
          4190,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3136.6,
        "id": 868,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3134.6,
        "temperature": 0,
        "text": " so a binary search tree you can use",
        "tokens": [
          51364,
          370,
          257,
          17434,
          3164,
          4230,
          291,
          393,
          764,
          51464
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3139.6,
        "id": 869,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3136.6,
        "temperature": 0,
        "text": " to organize in alphabetical order a lot of words,",
        "tokens": [
          51464,
          281,
          13859,
          294,
          23339,
          804,
          1668,
          257,
          688,
          295,
          2283,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3141.6,
        "id": 870,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3139.6,
        "temperature": 0,
        "text": " or numbers, and other variety of things.",
        "tokens": [
          51614,
          420,
          3547,
          11,
          293,
          661,
          5673,
          295,
          721,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19742661837873787,
        "compression_ratio": 1.8205128205128205,
        "end": 3142.6,
        "id": 871,
        "no_speech_prob": 0.0011160090798512101,
        "seek": 311460,
        "start": 3141.6,
        "temperature": 0,
        "text": " You could think of this,",
        "tokens": [
          51714,
          509,
          727,
          519,
          295,
          341,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3144.6,
        "id": 872,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3142.6,
        "temperature": 0,
        "text": " but the edges here don't necessarily have weights,",
        "tokens": [
          50364,
          457,
          264,
          8819,
          510,
          500,
          380,
          4725,
          362,
          17443,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3147.6,
        "id": 873,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3144.6,
        "temperature": 0,
        "text": " at least in a standard binary tree,",
        "tokens": [
          50464,
          412,
          1935,
          294,
          257,
          3832,
          17434,
          4230,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3148.6,
        "id": 874,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3147.6,
        "temperature": 0,
        "text": " but here they do.",
        "tokens": [
          50614,
          457,
          510,
          436,
          360,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3151.6,
        "id": 875,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3148.6,
        "temperature": 0,
        "text": " Now, there's an algorithm for searching",
        "tokens": [
          50664,
          823,
          11,
          456,
          311,
          364,
          9284,
          337,
          10808,
          50814
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3152.6,
        "id": 876,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3151.6,
        "temperature": 0,
        "text": " for that optimal path in this scenario,",
        "tokens": [
          50814,
          337,
          300,
          16252,
          3100,
          294,
          341,
          9005,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3153.6,
        "id": 877,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3152.6,
        "temperature": 0,
        "text": " in a weighted graph,",
        "tokens": [
          50864,
          294,
          257,
          32807,
          4295,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3156.6,
        "id": 878,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3153.6,
        "temperature": 0,
        "text": " and it's called Dijkstra's algorithm.",
        "tokens": [
          50914,
          293,
          309,
          311,
          1219,
          413,
          6940,
          19639,
          311,
          9284,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3161.6,
        "id": 879,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3158.6,
        "temperature": 0,
        "text": " There's also another algorithm called A-star,",
        "tokens": [
          51164,
          821,
          311,
          611,
          1071,
          9284,
          1219,
          316,
          12,
          9710,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3164.6,
        "id": 880,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3161.6,
        "temperature": 0,
        "text": " and et cetera, et cetera.",
        "tokens": [
          51314,
          293,
          1030,
          11458,
          11,
          1030,
          11458,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3166.6,
        "id": 881,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3164.6,
        "temperature": 0,
        "text": " So these are different examples,",
        "tokens": [
          51464,
          407,
          613,
          366,
          819,
          5110,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3169.6,
        "id": 882,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3166.6,
        "temperature": 0,
        "text": " binary search algorithm, Dijkstra's algorithm, A-star,",
        "tokens": [
          51564,
          17434,
          3164,
          9284,
          11,
          413,
          6940,
          19639,
          311,
          9284,
          11,
          316,
          12,
          9710,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.17824203010619155,
        "compression_ratio": 1.7490196078431373,
        "end": 3171.6,
        "id": 883,
        "no_speech_prob": 0.00010554666368989274,
        "seek": 314260,
        "start": 3169.6,
        "temperature": 0,
        "text": " and the one that I'm actually doing today,",
        "tokens": [
          51714,
          293,
          264,
          472,
          300,
          286,
          478,
          767,
          884,
          965,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3173.6,
        "id": 884,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3171.6,
        "temperature": 0,
        "text": " but that doesn't really matter to you,",
        "tokens": [
          50364,
          457,
          300,
          1177,
          380,
          534,
          1871,
          281,
          291,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3175.6,
        "id": 885,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3173.6,
        "temperature": 0,
        "text": " because you're going to watch these videos in sequence,",
        "tokens": [
          50464,
          570,
          291,
          434,
          516,
          281,
          1159,
          613,
          2145,
          294,
          8310,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3176.6,
        "id": 886,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3175.6,
        "temperature": 0,
        "text": " which I'll talk about in a second,",
        "tokens": [
          50564,
          597,
          286,
          603,
          751,
          466,
          294,
          257,
          1150,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3178.6,
        "id": 887,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3176.6,
        "temperature": 0,
        "text": " is something called breadth-first search.",
        "tokens": [
          50614,
          307,
          746,
          1219,
          35862,
          12,
          29581,
          3164,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3180.6,
        "id": 888,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3178.6,
        "temperature": 0,
        "text": " So breadth-first search is a good algorithm",
        "tokens": [
          50714,
          407,
          35862,
          12,
          29581,
          3164,
          307,
          257,
          665,
          9284,
          50814
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3184.6,
        "id": 889,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3180.6,
        "temperature": 0,
        "text": " for finding the shortest path between two nodes in a graph",
        "tokens": [
          50814,
          337,
          5006,
          264,
          31875,
          3100,
          1296,
          732,
          13891,
          294,
          257,
          4295,
          51014
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3185.6,
        "id": 890,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3184.6,
        "temperature": 0,
        "text": " that aren't weighted,",
        "tokens": [
          51014,
          300,
          3212,
          380,
          32807,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3187.6,
        "id": 891,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3185.6,
        "temperature": 0,
        "text": " so the shortest number of steps,",
        "tokens": [
          51064,
          370,
          264,
          31875,
          1230,
          295,
          4439,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3188.6,
        "id": 892,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3187.6,
        "temperature": 0,
        "text": " and I'll talk about the example",
        "tokens": [
          51164,
          293,
          286,
          603,
          751,
          466,
          264,
          1365,
          51214
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3190.6,
        "id": 893,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3188.6,
        "temperature": 0,
        "text": " that I'm going to use for that in a bit.",
        "tokens": [
          51214,
          300,
          286,
          478,
          516,
          281,
          764,
          337,
          300,
          294,
          257,
          857,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3192.6,
        "id": 894,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3190.6,
        "temperature": 0,
        "text": " So this week is all about learning",
        "tokens": [
          51314,
          407,
          341,
          1243,
          307,
          439,
          466,
          2539,
          51414
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3194.6,
        "id": 895,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3192.6,
        "temperature": 0,
        "text": " how to program a graph system,",
        "tokens": [
          51414,
          577,
          281,
          1461,
          257,
          4295,
          1185,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3196.6,
        "id": 896,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3194.6,
        "temperature": 0,
        "text": " and learning about different algorithms",
        "tokens": [
          51514,
          293,
          2539,
          466,
          819,
          14642,
          51614
        ]
      },
      {
        "avg_logprob": -0.15150956312815347,
        "compression_ratio": 1.8211920529801324,
        "end": 3200.6,
        "id": 897,
        "no_speech_prob": 0.000755401561036706,
        "seek": 317160,
        "start": 3196.6,
        "temperature": 0,
        "text": " to efficiently solve some type of problem",
        "tokens": [
          51614,
          281,
          19621,
          5039,
          512,
          2010,
          295,
          1154,
          51814
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3201.6,
        "id": 898,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3200.6,
        "temperature": 0,
        "text": " associated with a graph system,",
        "tokens": [
          50364,
          6615,
          365,
          257,
          4295,
          1185,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3203.6,
        "id": 899,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3201.6,
        "temperature": 0,
        "text": " like the shortest path,",
        "tokens": [
          50414,
          411,
          264,
          31875,
          3100,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3206.6,
        "id": 900,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3203.6,
        "temperature": 0,
        "text": " and so now, once you stop watching this video,",
        "tokens": [
          50514,
          293,
          370,
          586,
          11,
          1564,
          291,
          1590,
          1976,
          341,
          960,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3208.6,
        "id": 901,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3206.6,
        "temperature": 0,
        "text": " there's going to be a bunch of others in this playlist",
        "tokens": [
          50664,
          456,
          311,
          516,
          281,
          312,
          257,
          3840,
          295,
          2357,
          294,
          341,
          16788,
          50764
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3210.6,
        "id": 902,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3208.6,
        "temperature": 0,
        "text": " that I've made at all different times",
        "tokens": [
          50764,
          300,
          286,
          600,
          1027,
          412,
          439,
          819,
          1413,
          50864
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3211.6,
        "id": 903,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3210.6,
        "temperature": 0,
        "text": " under different circumstances.",
        "tokens": [
          50864,
          833,
          819,
          9121,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3213.6,
        "id": 904,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3211.6,
        "temperature": 0,
        "text": " So this is an experiment that I'm trying,",
        "tokens": [
          50914,
          407,
          341,
          307,
          364,
          5120,
          300,
          286,
          478,
          1382,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3214.6,
        "id": 905,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3213.6,
        "temperature": 0,
        "text": " trying to put together a sequence course",
        "tokens": [
          51014,
          1382,
          281,
          829,
          1214,
          257,
          8310,
          1164,
          51064
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3216.6,
        "id": 906,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3214.6,
        "temperature": 0,
        "text": " with all different coding challenges.",
        "tokens": [
          51064,
          365,
          439,
          819,
          17720,
          4759,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3219.6,
        "id": 907,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3216.6,
        "temperature": 0,
        "text": " So you'll see there's a binary search tree example,",
        "tokens": [
          51164,
          407,
          291,
          603,
          536,
          456,
          311,
          257,
          17434,
          3164,
          4230,
          1365,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3222.6,
        "id": 908,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3219.6,
        "temperature": 0,
        "text": " there will be a breadth-first search example,",
        "tokens": [
          51314,
          456,
          486,
          312,
          257,
          35862,
          12,
          29581,
          3164,
          1365,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3224.6,
        "id": 909,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3222.6,
        "temperature": 0,
        "text": " there is no at the time of this recording,",
        "tokens": [
          51464,
          456,
          307,
          572,
          412,
          264,
          565,
          295,
          341,
          6613,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3226.6,
        "id": 910,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3224.6,
        "temperature": 0,
        "text": " but there might be at the time of your watching,",
        "tokens": [
          51564,
          457,
          456,
          1062,
          312,
          412,
          264,
          565,
          295,
          428,
          1976,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.17288082097870072,
        "compression_ratio": 1.7893081761006289,
        "end": 3228.6,
        "id": 911,
        "no_speech_prob": 0.0023229997605085373,
        "seek": 320060,
        "start": 3226.6,
        "temperature": 0,
        "text": " a Dijkstra's algorithm, A-star,",
        "tokens": [
          51664,
          257,
          413,
          6940,
          19639,
          311,
          9284,
          11,
          316,
          12,
          9710,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3229.6,
        "id": 912,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3228.6,
        "temperature": 0,
        "text": " so you'll see, and I'm going to be",
        "tokens": [
          50364,
          370,
          291,
          603,
          536,
          11,
          293,
          286,
          478,
          516,
          281,
          312,
          50414
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3231.6,
        "id": 913,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3229.6,
        "temperature": 0,
        "text": " filling stuff in as time goes on.",
        "tokens": [
          50414,
          10623,
          1507,
          294,
          382,
          565,
          1709,
          322,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3233.6,
        "id": 914,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3231.6,
        "temperature": 0,
        "text": " Once you get to the end of all of those,",
        "tokens": [
          50514,
          3443,
          291,
          483,
          281,
          264,
          917,
          295,
          439,
          295,
          729,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3235.6,
        "id": 915,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3233.6,
        "temperature": 0,
        "text": " if you choose to watch them all,",
        "tokens": [
          50614,
          498,
          291,
          2826,
          281,
          1159,
          552,
          439,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3237.6,
        "id": 916,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3235.6,
        "temperature": 0,
        "text": " I'll make another video that kind of wraps up",
        "tokens": [
          50714,
          286,
          603,
          652,
          1071,
          960,
          300,
          733,
          295,
          25831,
          493,
          50814
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3239.6,
        "id": 917,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3237.6,
        "temperature": 0,
        "text": " and shows you a bunch of examples all together,",
        "tokens": [
          50814,
          293,
          3110,
          291,
          257,
          3840,
          295,
          5110,
          439,
          1214,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3243.6,
        "id": 918,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3239.6,
        "temperature": 0,
        "text": " and gives you some ideas for some homework exercises",
        "tokens": [
          50914,
          293,
          2709,
          291,
          512,
          3487,
          337,
          512,
          14578,
          11900,
          51114
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3244.6,
        "id": 919,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3243.6,
        "temperature": 0,
        "text": " that you might do,",
        "tokens": [
          51114,
          300,
          291,
          1062,
          360,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3245.6,
        "id": 920,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3244.6,
        "temperature": 0,
        "text": " that you could share with me in the comments,",
        "tokens": [
          51164,
          300,
          291,
          727,
          2073,
          365,
          385,
          294,
          264,
          3053,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3246.6,
        "id": 921,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3245.6,
        "temperature": 0,
        "text": " and that sort of thing.",
        "tokens": [
          51214,
          293,
          300,
          1333,
          295,
          551,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3249.6,
        "id": 922,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3246.6,
        "temperature": 0,
        "text": " If you want to participate in a Slack channel",
        "tokens": [
          51264,
          759,
          291,
          528,
          281,
          8197,
          294,
          257,
          37211,
          2269,
          51414
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3250.6,
        "id": 923,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3249.6,
        "temperature": 0,
        "text": " that I have that's going on for this course,",
        "tokens": [
          51414,
          300,
          286,
          362,
          300,
          311,
          516,
          322,
          337,
          341,
          1164,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3253.6,
        "id": 924,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3250.6,
        "temperature": 0,
        "text": " you can sign up at patreon.com,",
        "tokens": [
          51464,
          291,
          393,
          1465,
          493,
          412,
          33161,
          13,
          1112,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3255.6,
        "id": 925,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3253.6,
        "temperature": 0,
        "text": " Coding Train, it's a crowdfunding thing",
        "tokens": [
          51614,
          383,
          8616,
          28029,
          11,
          309,
          311,
          257,
          6919,
          45033,
          551,
          51714
        ]
      },
      {
        "avg_logprob": -0.18001429992314627,
        "compression_ratio": 1.8240740740740742,
        "end": 3256.6,
        "id": 926,
        "no_speech_prob": 0.09265253692865372,
        "seek": 322860,
        "start": 3255.6,
        "temperature": 0,
        "text": " if you want to participate in that Slack channel,",
        "tokens": [
          51714,
          498,
          291,
          528,
          281,
          8197,
          294,
          300,
          37211,
          2269,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3258.6,
        "id": 927,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3256.6,
        "temperature": 0,
        "text": " but you can also always hit me up on Twitter at Schiffman,",
        "tokens": [
          50364,
          457,
          291,
          393,
          611,
          1009,
          2045,
          385,
          493,
          322,
          5794,
          412,
          2065,
          3661,
          1601,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3262.6,
        "id": 928,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3258.6,
        "temperature": 0,
        "text": " and in the comments here, which I do read.",
        "tokens": [
          50464,
          293,
          294,
          264,
          3053,
          510,
          11,
          597,
          286,
          360,
          1401,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3265.6,
        "id": 929,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3262.6,
        "temperature": 0,
        "text": " Okay, so that's what's going to happen next,",
        "tokens": [
          50664,
          1033,
          11,
          370,
          300,
          311,
          437,
          311,
          516,
          281,
          1051,
          958,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3268.6,
        "id": 930,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3265.6,
        "temperature": 0,
        "text": " and I will see you if you decide to come back",
        "tokens": [
          50814,
          293,
          286,
          486,
          536,
          291,
          498,
          291,
          4536,
          281,
          808,
          646,
          50964
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3272.6,
        "id": 931,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3268.6,
        "temperature": 0,
        "text": " in a wrap-up video where I kind of summarize",
        "tokens": [
          50964,
          294,
          257,
          7019,
          12,
          1010,
          960,
          689,
          286,
          733,
          295,
          20858,
          51164
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3275.6,
        "id": 932,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3272.6,
        "temperature": 0,
        "text": " a bunch of this stuff and give you some exercise ideas.",
        "tokens": [
          51164,
          257,
          3840,
          295,
          341,
          1507,
          293,
          976,
          291,
          512,
          5380,
          3487,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3277.6,
        "id": 933,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3275.6,
        "temperature": 0,
        "text": " Great, so I'm going to go and actually record a video",
        "tokens": [
          51314,
          3769,
          11,
          370,
          286,
          478,
          516,
          281,
          352,
          293,
          767,
          2136,
          257,
          960,
          51414
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3279.6,
        "id": 934,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3277.6,
        "temperature": 0,
        "text": " right now on breadth-first search,",
        "tokens": [
          51414,
          558,
          586,
          322,
          35862,
          12,
          29581,
          3164,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3281.6,
        "id": 935,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3279.6,
        "temperature": 0,
        "text": " but you might watch some of these other ones first.",
        "tokens": [
          51514,
          457,
          291,
          1062,
          1159,
          512,
          295,
          613,
          661,
          2306,
          700,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19332480797400842,
        "compression_ratio": 1.5971731448763251,
        "end": 3282.6,
        "id": 936,
        "no_speech_prob": 0.01001287717372179,
        "seek": 325660,
        "start": 3281.6,
        "temperature": 0,
        "text": " Thanks very much.",
        "tokens": [
          51614,
          2561,
          588,
          709,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3020721435546875,
        "compression_ratio": 1.4050632911392404,
        "end": 3287.6,
        "id": 937,
        "no_speech_prob": 0.005384892225265503,
        "seek": 328260,
        "start": 3282.6,
        "temperature": 0,
        "text": " Let me see, oops, how was that?",
        "tokens": [
          50364,
          961,
          385,
          536,
          11,
          34166,
          11,
          577,
          390,
          300,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.3020721435546875,
        "compression_ratio": 1.4050632911392404,
        "end": 3294.6,
        "id": 938,
        "no_speech_prob": 0.005384892225265503,
        "seek": 328260,
        "start": 3291.6,
        "temperature": 0,
        "text": " People are talking about quality, okay.",
        "tokens": [
          50814,
          3432,
          366,
          1417,
          466,
          3125,
          11,
          1392,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3020721435546875,
        "compression_ratio": 1.4050632911392404,
        "end": 3295.6,
        "id": 939,
        "no_speech_prob": 0.005384892225265503,
        "seek": 328260,
        "start": 3294.6,
        "temperature": 0,
        "text": " So how are we doing here?",
        "tokens": [
          50964,
          407,
          577,
          366,
          321,
          884,
          510,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.3020721435546875,
        "compression_ratio": 1.4050632911392404,
        "end": 3297.6,
        "id": 940,
        "no_speech_prob": 0.005384892225265503,
        "seek": 328260,
        "start": 3295.6,
        "temperature": 0,
        "text": " How long was that, would you say?",
        "tokens": [
          51014,
          1012,
          938,
          390,
          300,
          11,
          576,
          291,
          584,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.3020721435546875,
        "compression_ratio": 1.4050632911392404,
        "end": 3299.6,
        "id": 941,
        "no_speech_prob": 0.005384892225265503,
        "seek": 328260,
        "start": 3297.6,
        "temperature": 0,
        "text": " That was probably way too long, okay.",
        "tokens": [
          51114,
          663,
          390,
          1391,
          636,
          886,
          938,
          11,
          1392,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3020721435546875,
        "compression_ratio": 1.4050632911392404,
        "end": 3311.6,
        "id": 942,
        "no_speech_prob": 0.005384892225265503,
        "seek": 328260,
        "start": 3308.6,
        "temperature": 0,
        "text": " Oh, big O notation is something I didn't know about.",
        "tokens": [
          51664,
          876,
          11,
          955,
          422,
          24657,
          307,
          746,
          286,
          994,
          380,
          458,
          466,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1891868189761513,
        "compression_ratio": 1.5454545454545454,
        "end": 3315.6,
        "id": 943,
        "no_speech_prob": 0.021614979952573776,
        "seek": 331160,
        "start": 3311.6,
        "temperature": 0,
        "text": " Something I didn't mention, that's fine, that's fine.",
        "tokens": [
          50364,
          6595,
          286,
          994,
          380,
          2152,
          11,
          300,
          311,
          2489,
          11,
          300,
          311,
          2489,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1891868189761513,
        "compression_ratio": 1.5454545454545454,
        "end": 3320.6,
        "id": 944,
        "no_speech_prob": 0.021614979952573776,
        "seek": 331160,
        "start": 3318.6,
        "temperature": 0,
        "text": " Nine to 10 minutes, wow, all right.",
        "tokens": [
          50714,
          18939,
          281,
          1266,
          2077,
          11,
          6076,
          11,
          439,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1891868189761513,
        "compression_ratio": 1.5454545454545454,
        "end": 3327.6,
        "id": 945,
        "no_speech_prob": 0.021614979952573776,
        "seek": 331160,
        "start": 3323.6,
        "temperature": 0,
        "text": " I don't have my soundboard today, I forgot it, sad.",
        "tokens": [
          50964,
          286,
          500,
          380,
          362,
          452,
          1626,
          3787,
          965,
          11,
          286,
          5298,
          309,
          11,
          4227,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1891868189761513,
        "compression_ratio": 1.5454545454545454,
        "end": 3330.6,
        "id": 946,
        "no_speech_prob": 0.021614979952573776,
        "seek": 331160,
        "start": 3327.6,
        "temperature": 0,
        "text": " Okay, so I got to get set up for this coding challenge.",
        "tokens": [
          51164,
          1033,
          11,
          370,
          286,
          658,
          281,
          483,
          992,
          493,
          337,
          341,
          17720,
          3430,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1891868189761513,
        "compression_ratio": 1.5454545454545454,
        "end": 3334.6,
        "id": 947,
        "no_speech_prob": 0.021614979952573776,
        "seek": 331160,
        "start": 3331.6,
        "temperature": 0,
        "text": " Oh, I knew something I forgot to mention.",
        "tokens": [
          51364,
          876,
          11,
          286,
          2586,
          746,
          286,
          5298,
          281,
          2152,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1891868189761513,
        "compression_ratio": 1.5454545454545454,
        "end": 3336.6,
        "id": 948,
        "no_speech_prob": 0.021614979952573776,
        "seek": 331160,
        "start": 3334.6,
        "temperature": 0,
        "text": " Does anybody have any questions?",
        "tokens": [
          51514,
          4402,
          4472,
          362,
          604,
          1651,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1891868189761513,
        "compression_ratio": 1.5454545454545454,
        "end": 3339.6,
        "id": 949,
        "no_speech_prob": 0.021614979952573776,
        "seek": 331160,
        "start": 3336.6,
        "temperature": 0,
        "text": " Because one thing I should do is answer questions.",
        "tokens": [
          51614,
          1436,
          472,
          551,
          286,
          820,
          360,
          307,
          1867,
          1651,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2119129313979038,
        "compression_ratio": 1.5714285714285714,
        "end": 3342.6,
        "id": 950,
        "no_speech_prob": 0.000020145684175076894,
        "seek": 333960,
        "start": 3339.6,
        "temperature": 0,
        "text": " I totally forgot to mention something important, that's fine.",
        "tokens": [
          50364,
          286,
          3879,
          5298,
          281,
          2152,
          746,
          1021,
          11,
          300,
          311,
          2489,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2119129313979038,
        "compression_ratio": 1.5714285714285714,
        "end": 3346.6,
        "id": 951,
        "no_speech_prob": 0.000020145684175076894,
        "seek": 333960,
        "start": 3344.6,
        "temperature": 0,
        "text": " That's fine, because the thing that I want to mention,",
        "tokens": [
          50614,
          663,
          311,
          2489,
          11,
          570,
          264,
          551,
          300,
          286,
          528,
          281,
          2152,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.2119129313979038,
        "compression_ratio": 1.5714285714285714,
        "end": 3350.6,
        "id": 952,
        "no_speech_prob": 0.000020145684175076894,
        "seek": 333960,
        "start": 3346.6,
        "temperature": 0,
        "text": " ah, shoot, I'm going to mention it.",
        "tokens": [
          50714,
          3716,
          11,
          3076,
          11,
          286,
          478,
          516,
          281,
          2152,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2119129313979038,
        "compression_ratio": 1.5714285714285714,
        "end": 3353.6,
        "id": 953,
        "no_speech_prob": 0.000020145684175076894,
        "seek": 333960,
        "start": 3351.6,
        "temperature": 0,
        "text": " I'm going to do my addendum.",
        "tokens": [
          50964,
          286,
          478,
          516,
          281,
          360,
          452,
          909,
          27574,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2119129313979038,
        "compression_ratio": 1.5714285714285714,
        "end": 3358.6,
        "id": 954,
        "no_speech_prob": 0.000020145684175076894,
        "seek": 333960,
        "start": 3353.6,
        "temperature": 0,
        "text": " We can, if it makes no sense, it's just what I always do.",
        "tokens": [
          51064,
          492,
          393,
          11,
          498,
          309,
          1669,
          572,
          2020,
          11,
          309,
          311,
          445,
          437,
          286,
          1009,
          360,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2119129313979038,
        "compression_ratio": 1.5714285714285714,
        "end": 3363.6,
        "id": 955,
        "no_speech_prob": 0.000020145684175076894,
        "seek": 333960,
        "start": 3360.6,
        "temperature": 0,
        "text": " Week one, read me.",
        "tokens": [
          51414,
          12615,
          472,
          11,
          1401,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2119129313979038,
        "compression_ratio": 1.5714285714285714,
        "end": 3366.6,
        "id": 956,
        "no_speech_prob": 0.000020145684175076894,
        "seek": 333960,
        "start": 3365.6,
        "temperature": 0,
        "text": " Here.",
        "tokens": [
          51664,
          1692,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3369.6,
        "id": 957,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3367.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3374.6,
        "id": 958,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3370.6,
        "temperature": 0,
        "text": " I didn't really talk about prerequisites.",
        "tokens": [
          50564,
          286,
          994,
          380,
          534,
          751,
          466,
          38333,
          15398,
          3324,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3376.6,
        "id": 959,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3374.6,
        "temperature": 0,
        "text": " It's a very hard word to say.",
        "tokens": [
          50764,
          467,
          311,
          257,
          588,
          1152,
          1349,
          281,
          584,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3378.6,
        "id": 960,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3376.6,
        "temperature": 0,
        "text": " Prerequisites.",
        "tokens": [
          50864,
          2114,
          323,
          15398,
          3324,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3380.6,
        "id": 961,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3378.6,
        "temperature": 0,
        "text": " Pre-requisites.",
        "tokens": [
          50964,
          6001,
          12,
          265,
          15398,
          3324,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3382.6,
        "id": 962,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3380.6,
        "temperature": 0,
        "text": " Okay, I didn't really talk about prerequisites.",
        "tokens": [
          51064,
          1033,
          11,
          286,
          994,
          380,
          534,
          751,
          466,
          38333,
          15398,
          3324,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3384.6,
        "id": 963,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3382.6,
        "temperature": 0,
        "text": " Pre-requisites.",
        "tokens": [
          51164,
          6001,
          12,
          265,
          15398,
          3324,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3386.6,
        "id": 964,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3384.6,
        "temperature": 0,
        "text": " Marriage.",
        "tokens": [
          51264,
          49593,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3387.6,
        "id": 965,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3386.6,
        "temperature": 0,
        "text": " Anyway.",
        "tokens": [
          51364,
          5684,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3390.6,
        "id": 966,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3388.6,
        "temperature": 0,
        "text": " How many of you get that reference?",
        "tokens": [
          51464,
          1012,
          867,
          295,
          291,
          483,
          300,
          6408,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3391.6,
        "id": 967,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3390.6,
        "temperature": 0,
        "text": " Okay, you want to see the mug?",
        "tokens": [
          51564,
          1033,
          11,
          291,
          528,
          281,
          536,
          264,
          23610,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.23464964132393357,
        "compression_ratio": 1.7909604519774012,
        "end": 3394.6,
        "id": 968,
        "no_speech_prob": 0.0017821816727519035,
        "seek": 336660,
        "start": 3391.6,
        "temperature": 0,
        "text": " Oh, I didn't bring the mug, because I have my water bottle.",
        "tokens": [
          51614,
          876,
          11,
          286,
          994,
          380,
          1565,
          264,
          23610,
          11,
          570,
          286,
          362,
          452,
          1281,
          7817,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3396.6,
        "id": 969,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3394.6,
        "temperature": 0,
        "text": " My purple, clean canteen.",
        "tokens": [
          50364,
          1222,
          9656,
          11,
          2541,
          393,
          9791,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3400.6,
        "id": 970,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3396.6,
        "temperature": 0,
        "text": " Sponsored by, wouldn't that be great if they would sponsor me?",
        "tokens": [
          50464,
          1738,
          892,
          2769,
          538,
          11,
          2759,
          380,
          300,
          312,
          869,
          498,
          436,
          576,
          16198,
          385,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3402.6,
        "id": 971,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3400.6,
        "temperature": 0,
        "text": " I can get a water, I actually make that joke,",
        "tokens": [
          50664,
          286,
          393,
          483,
          257,
          1281,
          11,
          286,
          767,
          652,
          300,
          7647,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3407.6,
        "id": 972,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3402.6,
        "temperature": 0,
        "text": " but I really should get a water company or something to sponsor me.",
        "tokens": [
          50764,
          457,
          286,
          534,
          820,
          483,
          257,
          1281,
          2237,
          420,
          746,
          281,
          16198,
          385,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3410.6,
        "id": 973,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3408.6,
        "temperature": 0,
        "text": " Product placement, oh my god.",
        "tokens": [
          51064,
          22005,
          17257,
          11,
          1954,
          452,
          3044,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3415.6,
        "id": 974,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3412.6,
        "temperature": 0,
        "text": " You know what, I think maybe I should just leave things as they are.",
        "tokens": [
          51264,
          509,
          458,
          437,
          11,
          286,
          519,
          1310,
          286,
          820,
          445,
          1856,
          721,
          382,
          436,
          366,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3419.6,
        "id": 975,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3415.6,
        "temperature": 0,
        "text": " Let me do a little, maybe this will get added on, maybe it won't,",
        "tokens": [
          51414,
          961,
          385,
          360,
          257,
          707,
          11,
          1310,
          341,
          486,
          483,
          3869,
          322,
          11,
          1310,
          309,
          1582,
          380,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21152169587182218,
        "compression_ratio": 1.6588235294117648,
        "end": 3422.6,
        "id": 976,
        "no_speech_prob": 0.0033243943471461535,
        "seek": 339460,
        "start": 3419.6,
        "temperature": 0,
        "text": " but this is important, so I'm going to mention it here.",
        "tokens": [
          51614,
          457,
          341,
          307,
          1021,
          11,
          370,
          286,
          478,
          516,
          281,
          2152,
          309,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3423.6,
        "id": 977,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3422.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3424.6,
        "id": 978,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3423.6,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50414,
          21726,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3427.6,
        "id": 979,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3424.6,
        "temperature": 0,
        "text": " I'm always back at the end of my videos when you think they're over.",
        "tokens": [
          50464,
          286,
          478,
          1009,
          646,
          412,
          264,
          917,
          295,
          452,
          2145,
          562,
          291,
          519,
          436,
          434,
          670,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3430.6,
        "id": 980,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3427.6,
        "temperature": 0,
        "text": " So one thing I want to mention, that if you're about to watch",
        "tokens": [
          50614,
          407,
          472,
          551,
          286,
          528,
          281,
          2152,
          11,
          300,
          498,
          291,
          434,
          466,
          281,
          1159,
          50764
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3433.6,
        "id": 981,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3430.6,
        "temperature": 0,
        "text": " some of these, the rest of the videos in this sequence,",
        "tokens": [
          50764,
          512,
          295,
          613,
          11,
          264,
          1472,
          295,
          264,
          2145,
          294,
          341,
          8310,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3438.6,
        "id": 982,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3433.6,
        "temperature": 0,
        "text": " first of all, if you don't know JavaScript programming in p5.js,",
        "tokens": [
          50914,
          700,
          295,
          439,
          11,
          498,
          291,
          500,
          380,
          458,
          15778,
          9410,
          294,
          280,
          20,
          13,
          25530,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3441.6,
        "id": 983,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3438.6,
        "temperature": 0,
        "text": " you might want to take a look at some of my intro to p5.js videos,",
        "tokens": [
          51164,
          291,
          1062,
          528,
          281,
          747,
          257,
          574,
          412,
          512,
          295,
          452,
          12897,
          281,
          280,
          20,
          13,
          25530,
          2145,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3444.6,
        "id": 984,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3441.6,
        "temperature": 0,
        "text": " but more importantly than that, if you have experience with,",
        "tokens": [
          51314,
          457,
          544,
          8906,
          813,
          300,
          11,
          498,
          291,
          362,
          1752,
          365,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3446.6,
        "id": 985,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3444.6,
        "temperature": 0,
        "text": " two things that I'm using in these videos is,",
        "tokens": [
          51464,
          732,
          721,
          300,
          286,
          478,
          1228,
          294,
          613,
          2145,
          307,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.20447224248064697,
        "compression_ratio": 1.7127272727272727,
        "end": 3449.6,
        "id": 986,
        "no_speech_prob": 0.006797152571380138,
        "seek": 342260,
        "start": 3446.6,
        "temperature": 0,
        "text": " one is this concept of prototype,",
        "tokens": [
          51564,
          472,
          307,
          341,
          3410,
          295,
          19475,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3453.6,
        "id": 987,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3449.6,
        "temperature": 0,
        "text": " as a way of attaching methods to an object in JavaScript,",
        "tokens": [
          50364,
          382,
          257,
          636,
          295,
          39074,
          7150,
          281,
          364,
          2657,
          294,
          15778,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3456.6,
        "id": 988,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3453.6,
        "temperature": 0,
        "text": " as well as this idea of an associative array or hash table,",
        "tokens": [
          50564,
          382,
          731,
          382,
          341,
          1558,
          295,
          364,
          4180,
          1166,
          10225,
          420,
          22019,
          3199,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3458.6,
        "id": 989,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3456.6,
        "temperature": 0,
        "text": " and how that works in JavaScript.",
        "tokens": [
          50714,
          293,
          577,
          300,
          1985,
          294,
          15778,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3461.6,
        "id": 990,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3458.6,
        "temperature": 0,
        "text": " So those two things might be videos that you might want to go and watch first",
        "tokens": [
          50814,
          407,
          729,
          732,
          721,
          1062,
          312,
          2145,
          300,
          291,
          1062,
          528,
          281,
          352,
          293,
          1159,
          700,
          50964
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3463.6,
        "id": 991,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3461.6,
        "temperature": 0,
        "text": " before you start looking at some of the graph systems",
        "tokens": [
          50964,
          949,
          291,
          722,
          1237,
          412,
          512,
          295,
          264,
          4295,
          3652,
          51064
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3465.6,
        "id": 992,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3463.6,
        "temperature": 0,
        "text": " and different search algorithms.",
        "tokens": [
          51064,
          293,
          819,
          3164,
          14642,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3467.6,
        "id": 993,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3465.6,
        "temperature": 0,
        "text": " Just in case that matters to you.",
        "tokens": [
          51164,
          1449,
          294,
          1389,
          300,
          7001,
          281,
          291,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3470.6,
        "id": 994,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3467.6,
        "temperature": 0,
        "text": " But you don't really have to know very much to follow this stuff along.",
        "tokens": [
          51264,
          583,
          291,
          500,
          380,
          534,
          362,
          281,
          458,
          588,
          709,
          281,
          1524,
          341,
          1507,
          2051,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3472.6,
        "id": 995,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3470.6,
        "temperature": 0,
        "text": " If you know a bit about programming, you've tried,",
        "tokens": [
          51414,
          759,
          291,
          458,
          257,
          857,
          466,
          9410,
          11,
          291,
          600,
          3031,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3474.6,
        "id": 996,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3472.6,
        "temperature": 0,
        "text": " you've watched some of my other videos, hopefully you'll be okay.",
        "tokens": [
          51514,
          291,
          600,
          6337,
          512,
          295,
          452,
          661,
          2145,
          11,
          4696,
          291,
          603,
          312,
          1392,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17965833242837484,
        "compression_ratio": 1.7113702623906706,
        "end": 3477.6,
        "id": 997,
        "no_speech_prob": 0.016656402498483658,
        "seek": 344960,
        "start": 3474.6,
        "temperature": 0,
        "text": " If not, let me know and I'll see what I can do.",
        "tokens": [
          51614,
          759,
          406,
          11,
          718,
          385,
          458,
          293,
          286,
          603,
          536,
          437,
          286,
          393,
          360,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3478.6,
        "id": 998,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3477.6,
        "temperature": 0,
        "text": " Okay, see you soon.",
        "tokens": [
          50364,
          1033,
          11,
          536,
          291,
          2321,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3479.6,
        "id": 999,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3478.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3484.6,
        "id": 1000,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3482.6,
        "temperature": 0,
        "text": " So, oh, I ignore questions.",
        "tokens": [
          50614,
          407,
          11,
          1954,
          11,
          286,
          11200,
          1651,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3486.6,
        "id": 1001,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3484.6,
        "temperature": 0,
        "text": " I'm trying to not ignore questions.",
        "tokens": [
          50714,
          286,
          478,
          1382,
          281,
          406,
          11200,
          1651,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3488.6,
        "id": 1002,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3486.6,
        "temperature": 0,
        "text": " Oh, Unikitty!",
        "tokens": [
          50814,
          876,
          11,
          1156,
          1035,
          10016,
          0,
          50914
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3490.6,
        "id": 1003,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3488.6,
        "temperature": 0,
        "text": " Unikitty is in the chat!",
        "tokens": [
          50914,
          1156,
          1035,
          10016,
          307,
          294,
          264,
          5081,
          0,
          51014
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3496.6,
        "id": 1004,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3492.6,
        "temperature": 0,
        "text": " What sometimes might, the YouTube chat scrolls pretty fast,",
        "tokens": [
          51114,
          708,
          2171,
          1062,
          11,
          264,
          3088,
          5081,
          11369,
          82,
          1238,
          2370,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.26376292705535886,
        "compression_ratio": 1.437125748502994,
        "end": 3504.6,
        "id": 1005,
        "no_speech_prob": 0.0019266814924776554,
        "seek": 347760,
        "start": 3496.6,
        "temperature": 0,
        "text": " and it's very hard for me to watch it continuously.",
        "tokens": [
          51314,
          293,
          309,
          311,
          588,
          1152,
          337,
          385,
          281,
          1159,
          309,
          15684,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3508.6,
        "id": 1006,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3505.6,
        "temperature": 0,
        "text": " So sometimes if there's a really important salient question,",
        "tokens": [
          50414,
          407,
          2171,
          498,
          456,
          311,
          257,
          534,
          1021,
          1845,
          1196,
          1168,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3512.6,
        "id": 1007,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3508.6,
        "temperature": 0,
        "text": " and somebody who's in both YouTube and Slack wants to paste it over,",
        "tokens": [
          50564,
          293,
          2618,
          567,
          311,
          294,
          1293,
          3088,
          293,
          37211,
          2738,
          281,
          9163,
          309,
          670,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3514.6,
        "id": 1008,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3512.6,
        "temperature": 0,
        "text": " that could be a way.",
        "tokens": [
          50764,
          300,
          727,
          312,
          257,
          636,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3515.6,
        "id": 1009,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3514.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3518.6,
        "id": 1010,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3517.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3520.6,
        "id": 1011,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3518.6,
        "temperature": 0,
        "text": " So how are we on time?",
        "tokens": [
          51064,
          407,
          577,
          366,
          321,
          322,
          565,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3521.6,
        "id": 1012,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3520.6,
        "temperature": 0,
        "text": " Five o'clock.",
        "tokens": [
          51164,
          9436,
          277,
          6,
          9023,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3524.6,
        "id": 1013,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3521.6,
        "temperature": 0,
        "text": " So this is the thing that I'm now hoping to do in a half an hour.",
        "tokens": [
          51214,
          407,
          341,
          307,
          264,
          551,
          300,
          286,
          478,
          586,
          7159,
          281,
          360,
          294,
          257,
          1922,
          364,
          1773,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3526.6,
        "id": 1014,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3524.6,
        "temperature": 0,
        "text": " It'll take longer, but we'll see.",
        "tokens": [
          51364,
          467,
          603,
          747,
          2854,
          11,
          457,
          321,
          603,
          536,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3527.6,
        "id": 1015,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3526.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3530.6,
        "id": 1016,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3527.6,
        "temperature": 0,
        "text": " I've got to get myself ready for this now.",
        "tokens": [
          51514,
          286,
          600,
          658,
          281,
          483,
          2059,
          1919,
          337,
          341,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17051719665527343,
        "compression_ratio": 1.563265306122449,
        "end": 3533.6,
        "id": 1017,
        "no_speech_prob": 0.001345834694802761,
        "seek": 350460,
        "start": 3530.6,
        "temperature": 0,
        "text": " So what I need is a couple things.",
        "tokens": [
          51664,
          407,
          437,
          286,
          643,
          307,
          257,
          1916,
          721,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18131363182737117,
        "compression_ratio": 1.3055555555555556,
        "end": 3536.6,
        "id": 1018,
        "no_speech_prob": 0.00061662687221542,
        "seek": 353360,
        "start": 3533.6,
        "temperature": 0,
        "text": " I need to get a data set.",
        "tokens": [
          50364,
          286,
          643,
          281,
          483,
          257,
          1412,
          992,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18131363182737117,
        "compression_ratio": 1.3055555555555556,
        "end": 3543.6,
        "id": 1019,
        "no_speech_prob": 0.00061662687221542,
        "seek": 353360,
        "start": 3542.6,
        "temperature": 0,
        "text": " Okay, so first, okay, hold on.",
        "tokens": [
          50814,
          1033,
          11,
          370,
          700,
          11,
          1392,
          11,
          1797,
          322,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18131363182737117,
        "compression_ratio": 1.3055555555555556,
        "end": 3544.6,
        "id": 1020,
        "no_speech_prob": 0.00061662687221542,
        "seek": 353360,
        "start": 3543.6,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50864,
          2438,
          0,
          50914
        ]
      },
      {
        "avg_logprob": -0.18131363182737117,
        "compression_ratio": 1.3055555555555556,
        "end": 3546.6,
        "id": 1021,
        "no_speech_prob": 0.00061662687221542,
        "seek": 353360,
        "start": 3544.6,
        "temperature": 0,
        "text": " I need to go here.",
        "tokens": [
          50914,
          286,
          643,
          281,
          352,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18131363182737117,
        "compression_ratio": 1.3055555555555556,
        "end": 3551.6,
        "id": 1022,
        "no_speech_prob": 0.00061662687221542,
        "seek": 353360,
        "start": 3549.6,
        "temperature": 0,
        "text": " So I'm going to clone my repo.",
        "tokens": [
          51164,
          407,
          286,
          478,
          516,
          281,
          26506,
          452,
          49040,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18131363182737117,
        "compression_ratio": 1.3055555555555556,
        "end": 3560.6,
        "id": 1023,
        "no_speech_prob": 0.00061662687221542,
        "seek": 353360,
        "start": 3558.6,
        "temperature": 0,
        "text": " And I'm going to run a server.",
        "tokens": [
          51614,
          400,
          286,
          478,
          516,
          281,
          1190,
          257,
          7154,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3566.6,
        "id": 1024,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3564.6,
        "temperature": 0,
        "text": " And now I'm going to get the browser back open.",
        "tokens": [
          50414,
          400,
          586,
          286,
          478,
          516,
          281,
          483,
          264,
          11185,
          646,
          1269,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3568.6,
        "id": 1025,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3566.6,
        "temperature": 0,
        "text": " Oops, wrong thing.",
        "tokens": [
          50514,
          21726,
          11,
          2085,
          551,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3575.6,
        "id": 1026,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3570.6,
        "temperature": 0,
        "text": " And, oops, I really don't want to run the server from the desktop.",
        "tokens": [
          50714,
          400,
          11,
          34166,
          11,
          286,
          534,
          500,
          380,
          528,
          281,
          1190,
          264,
          7154,
          490,
          264,
          14502,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3577.6,
        "id": 1027,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3575.6,
        "temperature": 0,
        "text": " That's a little bit silly.",
        "tokens": [
          50964,
          663,
          311,
          257,
          707,
          857,
          11774,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3579.6,
        "id": 1028,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3578.6,
        "temperature": 0,
        "text": " Oh, shoot.",
        "tokens": [
          51114,
          876,
          11,
          3076,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3582.6,
        "id": 1029,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3581.6,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51264,
          2438,
          0,
          51314
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3585.6,
        "id": 1030,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3584.6,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51414,
          4919,
          11,
          2201,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20277327219645183,
        "compression_ratio": 1.3885350318471337,
        "end": 3591.6,
        "id": 1031,
        "no_speech_prob": 0.0013249345356598496,
        "seek": 356360,
        "start": 3589.6,
        "temperature": 0,
        "text": " I will run it from here.",
        "tokens": [
          51664,
          286,
          486,
          1190,
          309,
          490,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3595.6,
        "id": 1032,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3593.6,
        "temperature": 0,
        "text": " Sorry that I'm standing in front of what I'm doing.",
        "tokens": [
          50364,
          4919,
          300,
          286,
          478,
          4877,
          294,
          1868,
          295,
          437,
          286,
          478,
          884,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3599.6,
        "id": 1033,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3595.6,
        "temperature": 0,
        "text": " I'm just kind of getting some examples ready to go.",
        "tokens": [
          50464,
          286,
          478,
          445,
          733,
          295,
          1242,
          512,
          5110,
          1919,
          281,
          352,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3600.6,
        "id": 1034,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3599.6,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50664,
          21726,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3605.6,
        "id": 1035,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3603.6,
        "temperature": 0,
        "text": " Okay, so this one we're going to need.",
        "tokens": [
          50864,
          1033,
          11,
          370,
          341,
          472,
          321,
          434,
          516,
          281,
          643,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3607.6,
        "id": 1036,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3606.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3611.6,
        "id": 1037,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3609.6,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51164,
          1044,
          291,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3614.6,
        "id": 1038,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3611.6,
        "temperature": 0,
        "text": " Somebody contributed the force-directed physics of this.",
        "tokens": [
          51264,
          13463,
          18434,
          264,
          3464,
          12,
          44868,
          292,
          10649,
          295,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3617.6,
        "id": 1039,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3614.6,
        "temperature": 0,
        "text": " I want to make sure I thank this person.",
        "tokens": [
          51414,
          286,
          528,
          281,
          652,
          988,
          286,
          1309,
          341,
          954,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3619.6,
        "id": 1040,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3617.6,
        "temperature": 0,
        "text": " Let me look at pull requests.",
        "tokens": [
          51564,
          961,
          385,
          574,
          412,
          2235,
          12475,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1352869669596354,
        "compression_ratio": 1.481818181818182,
        "end": 3620.6,
        "id": 1041,
        "no_speech_prob": 0.0010986870620399714,
        "seek": 359360,
        "start": 3619.6,
        "temperature": 0,
        "text": " I made a bunch of changes to it,",
        "tokens": [
          51664,
          286,
          1027,
          257,
          3840,
          295,
          2962,
          281,
          309,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3623.6,
        "id": 1042,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3620.6,
        "temperature": 0,
        "text": " but the original implementation was done by,",
        "tokens": [
          50364,
          457,
          264,
          3380,
          11420,
          390,
          1096,
          538,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3625.6,
        "id": 1043,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3623.6,
        "temperature": 0,
        "text": " so first of all, thank you to, there's a bunch,",
        "tokens": [
          50514,
          370,
          700,
          295,
          439,
          11,
          1309,
          291,
          281,
          11,
          456,
          311,
          257,
          3840,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3627.6,
        "id": 1044,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3625.6,
        "temperature": 0,
        "text": " let me thank all of these people.",
        "tokens": [
          50614,
          718,
          385,
          1309,
          439,
          295,
          613,
          561,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3631.6,
        "id": 1045,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3627.6,
        "temperature": 0,
        "text": " Kate Wieckmann, who has added a lot of links to references",
        "tokens": [
          50714,
          16251,
          9233,
          547,
          14912,
          11,
          567,
          575,
          3869,
          257,
          688,
          295,
          6123,
          281,
          15400,
          50914
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3632.6,
        "id": 1046,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3631.6,
        "temperature": 0,
        "text": " and other information.",
        "tokens": [
          50914,
          293,
          661,
          1589,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3634.6,
        "id": 1047,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3632.6,
        "temperature": 0,
        "text": " That's been really super helpful.",
        "tokens": [
          50964,
          663,
          311,
          668,
          534,
          1687,
          4961,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3642.6,
        "id": 1048,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3634.6,
        "temperature": 0,
        "text": " Somebody contributed a better way of laying out the binary tree example",
        "tokens": [
          51064,
          13463,
          18434,
          257,
          1101,
          636,
          295,
          14903,
          484,
          264,
          17434,
          4230,
          1365,
          51464
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3645.6,
        "id": 1049,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3642.6,
        "temperature": 0,
        "text": " that I made, which was in my videos, as well,",
        "tokens": [
          51464,
          300,
          286,
          1027,
          11,
          597,
          390,
          294,
          452,
          2145,
          11,
          382,
          731,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.27015192574317304,
        "compression_ratio": 1.5378486055776892,
        "end": 3648.6,
        "id": 1050,
        "no_speech_prob": 0.012624259106814861,
        "seek": 362060,
        "start": 3645.6,
        "temperature": 0,
        "text": " which is D-Raw on GitHub.",
        "tokens": [
          51614,
          597,
          307,
          413,
          12,
          49,
          1607,
          322,
          23331,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18178252684764373,
        "compression_ratio": 1.4270833333333333,
        "end": 3651.6,
        "id": 1051,
        "no_speech_prob": 0.00010229901090497151,
        "seek": 364860,
        "start": 3648.6,
        "temperature": 0,
        "text": " And then R-Hacking contributed the force-directed aspect",
        "tokens": [
          50364,
          400,
          550,
          497,
          12,
          39,
          14134,
          18434,
          264,
          3464,
          12,
          44868,
          292,
          4171,
          50514
        ]
      },
      {
        "avg_logprob": -0.18178252684764373,
        "compression_ratio": 1.4270833333333333,
        "end": 3655.6,
        "id": 1052,
        "no_speech_prob": 0.00010229901090497151,
        "seek": 364860,
        "start": 3651.6,
        "temperature": 0,
        "text": " of this particular breadth-first search example.",
        "tokens": [
          50514,
          295,
          341,
          1729,
          35862,
          12,
          29581,
          3164,
          1365,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18178252684764373,
        "compression_ratio": 1.4270833333333333,
        "end": 3660.6,
        "id": 1053,
        "no_speech_prob": 0.00010229901090497151,
        "seek": 364860,
        "start": 3657.6,
        "temperature": 0,
        "text": " I want to also go to the Wikipedia page",
        "tokens": [
          50814,
          286,
          528,
          281,
          611,
          352,
          281,
          264,
          28999,
          3028,
          50964
        ]
      },
      {
        "avg_logprob": -0.18178252684764373,
        "compression_ratio": 1.4270833333333333,
        "end": 3668.6,
        "id": 1054,
        "no_speech_prob": 0.00010229901090497151,
        "seek": 364860,
        "start": 3663.6,
        "temperature": 0,
        "text": " because we can follow along with the algorithm here.",
        "tokens": [
          51114,
          570,
          321,
          393,
          1524,
          2051,
          365,
          264,
          9284,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18178252684764373,
        "compression_ratio": 1.4270833333333333,
        "end": 3671.6,
        "id": 1055,
        "no_speech_prob": 0.00010229901090497151,
        "seek": 364860,
        "start": 3670.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18178252684764373,
        "compression_ratio": 1.4270833333333333,
        "end": 3674.6,
        "id": 1056,
        "no_speech_prob": 0.00010229901090497151,
        "seek": 364860,
        "start": 3671.6,
        "temperature": 0,
        "text": " And then what I also need is,",
        "tokens": [
          51514,
          400,
          550,
          437,
          286,
          611,
          643,
          307,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.18178252684764373,
        "compression_ratio": 1.4270833333333333,
        "end": 3677.6,
        "id": 1057,
        "no_speech_prob": 0.00010229901090497151,
        "seek": 364860,
        "start": 3674.6,
        "temperature": 0,
        "text": " oh, so now I need to make my own thing.",
        "tokens": [
          51664,
          1954,
          11,
          370,
          586,
          286,
          643,
          281,
          652,
          452,
          1065,
          551,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15830007819242256,
        "compression_ratio": 1.6603773584905661,
        "end": 3683.6,
        "id": 1058,
        "no_speech_prob": 0.00002668848719622474,
        "seek": 367860,
        "start": 3678.6,
        "temperature": 0,
        "text": " What I'm going to do, let me just get any random example.",
        "tokens": [
          50364,
          708,
          286,
          478,
          516,
          281,
          360,
          11,
          718,
          385,
          445,
          483,
          604,
          4974,
          1365,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15830007819242256,
        "compression_ratio": 1.6603773584905661,
        "end": 3686.6,
        "id": 1059,
        "no_speech_prob": 0.00002668848719622474,
        "seek": 367860,
        "start": 3684.6,
        "temperature": 0,
        "text": " Let me just grab this one.",
        "tokens": [
          50664,
          961,
          385,
          445,
          4444,
          341,
          472,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15830007819242256,
        "compression_ratio": 1.6603773584905661,
        "end": 3689.6,
        "id": 1060,
        "no_speech_prob": 0.00002668848719622474,
        "seek": 367860,
        "start": 3686.6,
        "temperature": 0,
        "text": " I'm going to do this from scratch,",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          360,
          341,
          490,
          8459,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.15830007819242256,
        "compression_ratio": 1.6603773584905661,
        "end": 3691.6,
        "id": 1061,
        "no_speech_prob": 0.00002668848719622474,
        "seek": 367860,
        "start": 3689.6,
        "temperature": 0,
        "text": " so I don't need any of this code.",
        "tokens": [
          50914,
          370,
          286,
          500,
          380,
          643,
          604,
          295,
          341,
          3089,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15830007819242256,
        "compression_ratio": 1.6603773584905661,
        "end": 3698.6,
        "id": 1062,
        "no_speech_prob": 0.00002668848719622474,
        "seek": 367860,
        "start": 3691.6,
        "temperature": 0,
        "text": " I'm going to call this six degrees of bacon.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          818,
          341,
          2309,
          5310,
          295,
          16400,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15830007819242256,
        "compression_ratio": 1.6603773584905661,
        "end": 3701.6,
        "id": 1063,
        "no_speech_prob": 0.00002668848719622474,
        "seek": 367860,
        "start": 3699.6,
        "temperature": 0,
        "text": " By bacon, I mean Kevin Bacon.",
        "tokens": [
          51414,
          3146,
          16400,
          11,
          286,
          914,
          9954,
          42460,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15830007819242256,
        "compression_ratio": 1.6603773584905661,
        "end": 3706.6,
        "id": 1064,
        "no_speech_prob": 0.00002668848719622474,
        "seek": 367860,
        "start": 3701.6,
        "temperature": 0,
        "text": " And I'm going to open that in Atom.",
        "tokens": [
          51514,
          400,
          286,
          478,
          516,
          281,
          1269,
          300,
          294,
          1711,
          298,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3712.6,
        "id": 1065,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3709.6,
        "temperature": 0,
        "text": " I'm going to delete all of the code.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          12097,
          439,
          295,
          264,
          3089,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3719.6,
        "id": 1066,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3712.6,
        "temperature": 0,
        "text": " I am going to make a new file, call it Kevin Bacon.json.",
        "tokens": [
          50564,
          286,
          669,
          516,
          281,
          652,
          257,
          777,
          3991,
          11,
          818,
          309,
          9954,
          42460,
          13,
          73,
          3015,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3721.6,
        "id": 1067,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3719.6,
        "temperature": 0,
        "text": " And then somewhere I made,",
        "tokens": [
          50914,
          400,
          550,
          4079,
          286,
          1027,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3724.6,
        "id": 1068,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3721.6,
        "temperature": 0,
        "text": " what I already did is I made a little data set.",
        "tokens": [
          51014,
          437,
          286,
          1217,
          630,
          307,
          286,
          1027,
          257,
          707,
          1412,
          992,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3728.6,
        "id": 1069,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3726.6,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          51264,
          1692,
          309,
          307,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3732.6,
        "id": 1070,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3730.6,
        "temperature": 0,
        "text": " Whoops, let's do this.",
        "tokens": [
          51464,
          45263,
          11,
          718,
          311,
          360,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3735.6,
        "id": 1071,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3732.6,
        "temperature": 0,
        "text": " I can put in here, and there we go.",
        "tokens": [
          51564,
          286,
          393,
          829,
          294,
          510,
          11,
          293,
          456,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20023183713014098,
        "compression_ratio": 1.4244186046511629,
        "end": 3736.6,
        "id": 1072,
        "no_speech_prob": 0.00023413395683746785,
        "seek": 370860,
        "start": 3735.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51714,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2258026631673177,
        "compression_ratio": 1.4201183431952662,
        "end": 3740.6,
        "id": 1073,
        "no_speech_prob": 0.000006240929906198289,
        "seek": 373660,
        "start": 3736.6,
        "temperature": 0,
        "text": " So now, yeah.",
        "tokens": [
          50364,
          407,
          586,
          11,
          1338,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2258026631673177,
        "compression_ratio": 1.4201183431952662,
        "end": 3745.6,
        "id": 1074,
        "no_speech_prob": 0.000006240929906198289,
        "seek": 373660,
        "start": 3740.6,
        "temperature": 0,
        "text": " Okay, so I'm just about ready to talk about,",
        "tokens": [
          50564,
          1033,
          11,
          370,
          286,
          478,
          445,
          466,
          1919,
          281,
          751,
          466,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2258026631673177,
        "compression_ratio": 1.4201183431952662,
        "end": 3749.6,
        "id": 1075,
        "no_speech_prob": 0.000006240929906198289,
        "seek": 373660,
        "start": 3747.6,
        "temperature": 0,
        "text": " can you code it in Java?",
        "tokens": [
          50914,
          393,
          291,
          3089,
          309,
          294,
          10745,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2258026631673177,
        "compression_ratio": 1.4201183431952662,
        "end": 3755.6,
        "id": 1076,
        "no_speech_prob": 0.000006240929906198289,
        "seek": 373660,
        "start": 3749.6,
        "temperature": 0,
        "text": " You know, I'm going to do this one in JavaScript in P5",
        "tokens": [
          51014,
          509,
          458,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          472,
          294,
          15778,
          294,
          430,
          20,
          51314
        ]
      },
      {
        "avg_logprob": -0.2258026631673177,
        "compression_ratio": 1.4201183431952662,
        "end": 3760.6,
        "id": 1077,
        "no_speech_prob": 0.000006240929906198289,
        "seek": 373660,
        "start": 3755.6,
        "temperature": 0,
        "text": " because I wanted to just make it quickly interactive in the browser.",
        "tokens": [
          51314,
          570,
          286,
          1415,
          281,
          445,
          652,
          309,
          2661,
          15141,
          294,
          264,
          11185,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2258026631673177,
        "compression_ratio": 1.4201183431952662,
        "end": 3763.6,
        "id": 1078,
        "no_speech_prob": 0.000006240929906198289,
        "seek": 373660,
        "start": 3760.6,
        "temperature": 0,
        "text": " But I'm not opposed to making a,",
        "tokens": [
          51564,
          583,
          286,
          478,
          406,
          8851,
          281,
          1455,
          257,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3766.6,
        "id": 1079,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3764.6,
        "temperature": 0,
        "text": " oh, the Chrome extension, by the way, that I use,",
        "tokens": [
          50414,
          1954,
          11,
          264,
          15327,
          10320,
          11,
          538,
          264,
          636,
          11,
          300,
          286,
          764,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3768.6,
        "id": 1080,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3766.6,
        "temperature": 0,
        "text": " it's really, really good for the, I love this,",
        "tokens": [
          50514,
          309,
          311,
          534,
          11,
          534,
          665,
          337,
          264,
          11,
          286,
          959,
          341,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3771.6,
        "id": 1081,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3768.6,
        "temperature": 0,
        "text": " JSON formatter, Chrome extension.",
        "tokens": [
          50614,
          31828,
          1254,
          1161,
          11,
          15327,
          10320,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3774.6,
        "id": 1082,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3771.6,
        "temperature": 0,
        "text": " Got to get this Chrome extension.",
        "tokens": [
          50764,
          5803,
          281,
          483,
          341,
          15327,
          10320,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3778.6,
        "id": 1083,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3774.6,
        "temperature": 0,
        "text": " You got to get this Chrome extension, let me tell you.",
        "tokens": [
          50914,
          509,
          658,
          281,
          483,
          341,
          15327,
          10320,
          11,
          718,
          385,
          980,
          291,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3780.6,
        "id": 1084,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3778.6,
        "temperature": 0,
        "text": " JSON formatter, I believe it's this one,",
        "tokens": [
          51114,
          31828,
          1254,
          1161,
          11,
          286,
          1697,
          309,
          311,
          341,
          472,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3782.6,
        "id": 1085,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3780.6,
        "temperature": 0,
        "text": " first one that comes up in Google.",
        "tokens": [
          51214,
          700,
          472,
          300,
          1487,
          493,
          294,
          3329,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3784.6,
        "id": 1086,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3782.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3787.6,
        "id": 1087,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3784.6,
        "temperature": 0,
        "text": " But I'm happy to make processing versions",
        "tokens": [
          51414,
          583,
          286,
          478,
          2055,
          281,
          652,
          9007,
          9606,
          51564
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3788.6,
        "id": 1088,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3787.6,
        "temperature": 0,
        "text": " or come back and do it again,",
        "tokens": [
          51564,
          420,
          808,
          646,
          293,
          360,
          309,
          797,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.1968486754874873,
        "compression_ratio": 1.7743362831858407,
        "end": 3792.6,
        "id": 1089,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 376360,
        "start": 3788.6,
        "temperature": 0,
        "text": " but today it's going to be,",
        "tokens": [
          51614,
          457,
          965,
          309,
          311,
          516,
          281,
          312,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.22386663877047025,
        "compression_ratio": 1.3082706766917294,
        "end": 3794.6,
        "id": 1090,
        "no_speech_prob": 0.00026529619935899973,
        "seek": 379260,
        "start": 3792.6,
        "temperature": 0,
        "text": " okay.",
        "tokens": [
          50364,
          1392,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22386663877047025,
        "compression_ratio": 1.3082706766917294,
        "end": 3797.6,
        "id": 1091,
        "no_speech_prob": 0.00026529619935899973,
        "seek": 379260,
        "start": 3794.6,
        "temperature": 0,
        "text": " Okay, all right, so this is,",
        "tokens": [
          50464,
          1033,
          11,
          439,
          558,
          11,
          370,
          341,
          307,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.22386663877047025,
        "compression_ratio": 1.3082706766917294,
        "end": 3803.6,
        "id": 1092,
        "no_speech_prob": 0.00026529619935899973,
        "seek": 379260,
        "start": 3797.6,
        "temperature": 0,
        "text": " okay, so that I wanted to demonstrate just as a diagram.",
        "tokens": [
          50614,
          1392,
          11,
          370,
          300,
          286,
          1415,
          281,
          11698,
          445,
          382,
          257,
          10686,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22386663877047025,
        "compression_ratio": 1.3082706766917294,
        "end": 3806.6,
        "id": 1093,
        "no_speech_prob": 0.00026529619935899973,
        "seek": 379260,
        "start": 3803.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50914,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22386663877047025,
        "compression_ratio": 1.3082706766917294,
        "end": 3809.6,
        "id": 1094,
        "no_speech_prob": 0.00026529619935899973,
        "seek": 379260,
        "start": 3806.6,
        "temperature": 0,
        "text": " So I don't know,",
        "tokens": [
          51064,
          407,
          286,
          500,
          380,
          458,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.22386663877047025,
        "compression_ratio": 1.3082706766917294,
        "end": 3817.6,
        "id": 1095,
        "no_speech_prob": 0.00026529619935899973,
        "seek": 379260,
        "start": 3814.6,
        "temperature": 0,
        "text": " wait, no, what am I doing?",
        "tokens": [
          51464,
          1699,
          11,
          572,
          11,
          437,
          669,
          286,
          884,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.22386663877047025,
        "compression_ratio": 1.3082706766917294,
        "end": 3820.6,
        "id": 1096,
        "no_speech_prob": 0.00026529619935899973,
        "seek": 379260,
        "start": 3817.6,
        "temperature": 0,
        "text": " Hold on, everybody, six degrees.",
        "tokens": [
          51614,
          6962,
          322,
          11,
          2201,
          11,
          2309,
          5310,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3824.6,
        "id": 1097,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3820.6,
        "temperature": 0,
        "text": " I'm going to just run this on a different port.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          445,
          1190,
          341,
          322,
          257,
          819,
          2436,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3827.6,
        "id": 1098,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3824.6,
        "temperature": 0,
        "text": " That'll do.",
        "tokens": [
          50564,
          663,
          603,
          360,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3831.6,
        "id": 1099,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3829.6,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50814,
          821,
          321,
          352,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3834.6,
        "id": 1100,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3831.6,
        "temperature": 0,
        "text": " And let me actually just change the title.",
        "tokens": [
          50914,
          400,
          718,
          385,
          767,
          445,
          1319,
          264,
          4876,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3838.6,
        "id": 1101,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3834.6,
        "temperature": 0,
        "text": " Six degrees of Kevin Bacon.",
        "tokens": [
          51064,
          11678,
          5310,
          295,
          9954,
          42460,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3841.6,
        "id": 1102,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3838.6,
        "temperature": 0,
        "text": " So I can see that that's different.",
        "tokens": [
          51264,
          407,
          286,
          393,
          536,
          300,
          300,
          311,
          819,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3843.6,
        "id": 1103,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3841.6,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51414,
          400,
          456,
          321,
          352,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3847.6,
        "id": 1104,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3843.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20665858704366802,
        "compression_ratio": 1.475609756097561,
        "end": 3849.6,
        "id": 1105,
        "no_speech_prob": 0.0003353442589286715,
        "seek": 382060,
        "start": 3847.6,
        "temperature": 0,
        "text": " Okay, so I want to reference this book,",
        "tokens": [
          51714,
          1033,
          11,
          370,
          286,
          528,
          281,
          6408,
          341,
          1446,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.23973888158798218,
        "compression_ratio": 1.4055944055944056,
        "end": 3856.6,
        "id": 1106,
        "no_speech_prob": 0.0006165913655422628,
        "seek": 384960,
        "start": 3849.6,
        "temperature": 0,
        "text": " which this particular example comes from.",
        "tokens": [
          50364,
          597,
          341,
          1729,
          1365,
          1487,
          490,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23973888158798218,
        "compression_ratio": 1.4055944055944056,
        "end": 3862.6,
        "id": 1107,
        "no_speech_prob": 0.0006165913655422628,
        "seek": 384960,
        "start": 3856.6,
        "temperature": 0,
        "text": " Make this bigger.",
        "tokens": [
          50714,
          4387,
          341,
          3801,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23973888158798218,
        "compression_ratio": 1.4055944055944056,
        "end": 3866.6,
        "id": 1108,
        "no_speech_prob": 0.0006165913655422628,
        "seek": 384960,
        "start": 3862.6,
        "temperature": 0,
        "text": " And then, oops.",
        "tokens": [
          51014,
          400,
          550,
          11,
          34166,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23973888158798218,
        "compression_ratio": 1.4055944055944056,
        "end": 3867.6,
        "id": 1109,
        "no_speech_prob": 0.0006165913655422628,
        "seek": 384960,
        "start": 3866.6,
        "temperature": 0,
        "text": " And I have this,",
        "tokens": [
          51214,
          400,
          286,
          362,
          341,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.23973888158798218,
        "compression_ratio": 1.4055944055944056,
        "end": 3869.6,
        "id": 1110,
        "no_speech_prob": 0.0006165913655422628,
        "seek": 384960,
        "start": 3867.6,
        "temperature": 0,
        "text": " and then I have the breadth-first search page.",
        "tokens": [
          51264,
          293,
          550,
          286,
          362,
          264,
          35862,
          12,
          29581,
          3164,
          3028,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23973888158798218,
        "compression_ratio": 1.4055944055944056,
        "end": 3871.6,
        "id": 1111,
        "no_speech_prob": 0.0006165913655422628,
        "seek": 384960,
        "start": 3869.6,
        "temperature": 0,
        "text": " So I think we are good.",
        "tokens": [
          51364,
          407,
          286,
          519,
          321,
          366,
          665,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23973888158798218,
        "compression_ratio": 1.4055944055944056,
        "end": 3876.6,
        "id": 1112,
        "no_speech_prob": 0.0006165913655422628,
        "seek": 384960,
        "start": 3871.6,
        "temperature": 0,
        "text": " I'm going to go erase the whiteboard.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          352,
          23525,
          264,
          2418,
          3787,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2503660519917806,
        "compression_ratio": 1.5548387096774194,
        "end": 3893.6,
        "id": 1113,
        "no_speech_prob": 0.00012533699919003993,
        "seek": 387960,
        "start": 3880.6,
        "temperature": 0,
        "text": " And so I think,",
        "tokens": [
          50414,
          400,
          370,
          286,
          519,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2503660519917806,
        "compression_ratio": 1.5548387096774194,
        "end": 3896.6,
        "id": 1114,
        "no_speech_prob": 0.00012533699919003993,
        "seek": 387960,
        "start": 3893.6,
        "temperature": 0,
        "text": " in terms of editing this,",
        "tokens": [
          51064,
          294,
          2115,
          295,
          10000,
          341,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2503660519917806,
        "compression_ratio": 1.5548387096774194,
        "end": 3897.6,
        "id": 1115,
        "no_speech_prob": 0.00012533699919003993,
        "seek": 387960,
        "start": 3896.6,
        "temperature": 0,
        "text": " I think this,",
        "tokens": [
          51214,
          286,
          519,
          341,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.2503660519917806,
        "compression_ratio": 1.5548387096774194,
        "end": 3899.6,
        "id": 1116,
        "no_speech_prob": 0.00012533699919003993,
        "seek": 387960,
        "start": 3897.6,
        "temperature": 0,
        "text": " well, it doesn't really have to decide this right now,",
        "tokens": [
          51264,
          731,
          11,
          309,
          1177,
          380,
          534,
          362,
          281,
          4536,
          341,
          558,
          586,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2503660519917806,
        "compression_ratio": 1.5548387096774194,
        "end": 3901.6,
        "id": 1117,
        "no_speech_prob": 0.00012533699919003993,
        "seek": 387960,
        "start": 3899.6,
        "temperature": 0,
        "text": " but I think this is a coding challenge.",
        "tokens": [
          51364,
          457,
          286,
          519,
          341,
          307,
          257,
          17720,
          3430,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2503660519917806,
        "compression_ratio": 1.5548387096774194,
        "end": 3904.6,
        "id": 1118,
        "no_speech_prob": 0.00012533699919003993,
        "seek": 387960,
        "start": 3901.6,
        "temperature": 0,
        "text": " I could make it one video where I explain the algorithm",
        "tokens": [
          51464,
          286,
          727,
          652,
          309,
          472,
          960,
          689,
          286,
          2903,
          264,
          9284,
          51614
        ]
      },
      {
        "avg_logprob": -0.2503660519917806,
        "compression_ratio": 1.5548387096774194,
        "end": 3906.6,
        "id": 1119,
        "no_speech_prob": 0.00012533699919003993,
        "seek": 387960,
        "start": 3904.6,
        "temperature": 0,
        "text": " and another video where I code it,",
        "tokens": [
          51614,
          293,
          1071,
          960,
          689,
          286,
          3089,
          309,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3908.6,
        "id": 1120,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3906.6,
        "temperature": 0,
        "text": " but I kind of prefer to just do them both together.",
        "tokens": [
          50364,
          457,
          286,
          733,
          295,
          4382,
          281,
          445,
          360,
          552,
          1293,
          1214,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3911.6,
        "id": 1121,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3908.6,
        "temperature": 0,
        "text": " So I think what I'll try to do is,",
        "tokens": [
          50464,
          407,
          286,
          519,
          437,
          286,
          603,
          853,
          281,
          360,
          307,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3918.6,
        "id": 1122,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3911.6,
        "temperature": 0,
        "text": " there's a poll now going on.",
        "tokens": [
          50614,
          456,
          311,
          257,
          6418,
          586,
          516,
          322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3919.6,
        "id": 1123,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3918.6,
        "temperature": 0,
        "text": " By the way,",
        "tokens": [
          50964,
          3146,
          264,
          636,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3921.6,
        "id": 1124,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3919.6,
        "temperature": 0,
        "text": " somebody pointed out that I can use straw poll for polls.",
        "tokens": [
          51014,
          2618,
          10932,
          484,
          300,
          286,
          393,
          764,
          10099,
          6418,
          337,
          24264,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3923.6,
        "id": 1125,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3921.6,
        "temperature": 0,
        "text": " And Nadim in the chat asked,",
        "tokens": [
          51114,
          400,
          23269,
          332,
          294,
          264,
          5081,
          2351,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3925.6,
        "id": 1126,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3923.6,
        "temperature": 0,
        "text": " will this video be available after the stream ends?",
        "tokens": [
          51214,
          486,
          341,
          960,
          312,
          2435,
          934,
          264,
          4309,
          5314,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3926.6,
        "id": 1127,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3925.6,
        "temperature": 0,
        "text": " Yes, it will be.",
        "tokens": [
          51314,
          1079,
          11,
          309,
          486,
          312,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3931.6,
        "id": 1128,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3926.6,
        "temperature": 0,
        "text": " I think what I want to do is try to do this all at once,",
        "tokens": [
          51364,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          307,
          853,
          281,
          360,
          341,
          439,
          412,
          1564,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3933.6,
        "id": 1129,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3931.6,
        "temperature": 0,
        "text": " like describe the problem and the algorithm",
        "tokens": [
          51614,
          411,
          6786,
          264,
          1154,
          293,
          264,
          9284,
          51714
        ]
      },
      {
        "avg_logprob": -0.20468878746032715,
        "compression_ratio": 1.66015625,
        "end": 3935.6,
        "id": 1130,
        "no_speech_prob": 0.018546205013990402,
        "seek": 390660,
        "start": 3933.6,
        "temperature": 0,
        "text": " and write the code all at the same time.",
        "tokens": [
          51714,
          293,
          2464,
          264,
          3089,
          439,
          412,
          264,
          912,
          565,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3938.6,
        "id": 1131,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3935.6,
        "temperature": 0,
        "text": " And if it is taking a while,",
        "tokens": [
          50364,
          400,
          498,
          309,
          307,
          1940,
          257,
          1339,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3940.6,
        "id": 1132,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3938.6,
        "temperature": 0,
        "text": " I might break it into two parts.",
        "tokens": [
          50514,
          286,
          1062,
          1821,
          309,
          666,
          732,
          3166,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3942.6,
        "id": 1133,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3940.6,
        "temperature": 0,
        "text": " This is probably,",
        "tokens": [
          50614,
          639,
          307,
          1391,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3943.6,
        "id": 1134,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3942.6,
        "temperature": 0,
        "text": " I mean,",
        "tokens": [
          50714,
          286,
          914,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3946.6,
        "id": 1135,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3943.6,
        "temperature": 0,
        "text": " this is in theory much more complex than my pong example,",
        "tokens": [
          50764,
          341,
          307,
          294,
          5261,
          709,
          544,
          3997,
          813,
          452,
          36164,
          1365,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3951.6,
        "id": 1136,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3946.6,
        "temperature": 0,
        "text": " but I don't know why I think in my head this is like not going to take very long to program,",
        "tokens": [
          50914,
          457,
          286,
          500,
          380,
          458,
          983,
          286,
          519,
          294,
          452,
          1378,
          341,
          307,
          411,
          406,
          516,
          281,
          747,
          588,
          938,
          281,
          1461,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3953.6,
        "id": 1137,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3951.6,
        "temperature": 0,
        "text": " but we'll sort of see.",
        "tokens": [
          51164,
          457,
          321,
          603,
          1333,
          295,
          536,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3954.6,
        "id": 1138,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3953.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3956.6,
        "id": 1139,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3954.6,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          51314,
          407,
          510,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20659808937562715,
        "compression_ratio": 1.5178571428571428,
        "end": 3960.6,
        "id": 1140,
        "no_speech_prob": 0.003649880178272724,
        "seek": 393560,
        "start": 3956.6,
        "temperature": 0,
        "text": " Let me see if I can get these cameras to not go to sleep.",
        "tokens": [
          51414,
          961,
          385,
          536,
          498,
          286,
          393,
          483,
          613,
          8622,
          281,
          406,
          352,
          281,
          2817,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3963.6,
        "id": 1141,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3961.6,
        "temperature": 0,
        "text": " And where am I?",
        "tokens": [
          50414,
          400,
          689,
          669,
          286,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3965.6,
        "id": 1142,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3963.6,
        "temperature": 0,
        "text": " Oh, this other camera.",
        "tokens": [
          50514,
          876,
          11,
          341,
          661,
          2799,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3967.6,
        "id": 1143,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3965.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3969.6,
        "id": 1144,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3967.6,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50714,
          1692,
          321,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3971.6,
        "id": 1145,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3969.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3973.6,
        "id": 1146,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3971.6,
        "temperature": 0,
        "text": " Here we go, everybody.",
        "tokens": [
          50914,
          1692,
          321,
          352,
          11,
          2201,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3975.6,
        "id": 1147,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3973.6,
        "temperature": 0,
        "text": " This is the last thing that I'm going to do today,",
        "tokens": [
          51014,
          639,
          307,
          264,
          1036,
          551,
          300,
          286,
          478,
          516,
          281,
          360,
          965,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3976.6,
        "id": 1148,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3975.6,
        "temperature": 0,
        "text": " just so you guys know,",
        "tokens": [
          51114,
          445,
          370,
          291,
          1074,
          458,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3977.6,
        "id": 1149,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3976.6,
        "temperature": 0,
        "text": " although I'm happy to,",
        "tokens": [
          51164,
          4878,
          286,
          478,
          2055,
          281,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3979.6,
        "id": 1150,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3977.6,
        "temperature": 0,
        "text": " assuming this goes okay,",
        "tokens": [
          51214,
          11926,
          341,
          1709,
          1392,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3981.6,
        "id": 1151,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3979.6,
        "temperature": 0,
        "text": " it's not going to go terribly wrong,",
        "tokens": [
          51314,
          309,
          311,
          406,
          516,
          281,
          352,
          22903,
          2085,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3983.6,
        "id": 1152,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3981.6,
        "temperature": 0,
        "text": " but I'm going to try to do this all at once.",
        "tokens": [
          51414,
          457,
          286,
          478,
          516,
          281,
          853,
          281,
          360,
          341,
          439,
          412,
          1564,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.4892661508205718,
        "compression_ratio": 1.6526315789473685,
        "end": 3985.6,
        "id": 1153,
        "no_speech_prob": 0.012817822396755219,
        "seek": 396060,
        "start": 3983.6,
        "temperature": 0,
        "text": " So I'm going to do this.",
        "tokens": [
          51514,
          407,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3987.6,
        "id": 1154,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3985.6,
        "temperature": 0,
        "text": " This is the last thing that I'm going to do today,",
        "tokens": [
          50364,
          639,
          307,
          264,
          1036,
          551,
          300,
          286,
          478,
          516,
          281,
          360,
          965,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3988.6,
        "id": 1155,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3987.6,
        "temperature": 0,
        "text": " just so you guys know,",
        "tokens": [
          50464,
          445,
          370,
          291,
          1074,
          458,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3989.6,
        "id": 1156,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3988.6,
        "temperature": 0,
        "text": " although I'm happy to,",
        "tokens": [
          50514,
          4878,
          286,
          478,
          2055,
          281,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3990.6,
        "id": 1157,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3989.6,
        "temperature": 0,
        "text": " assuming this goes okay,",
        "tokens": [
          50564,
          11926,
          341,
          1709,
          1392,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3991.6,
        "id": 1158,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3990.6,
        "temperature": 0,
        "text": " it's not total,",
        "tokens": [
          50614,
          309,
          311,
          406,
          3217,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3994.6,
        "id": 1159,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3991.6,
        "temperature": 0,
        "text": " and I don't go running out of here with my hair on fire or something,",
        "tokens": [
          50664,
          293,
          286,
          500,
          380,
          352,
          2614,
          484,
          295,
          510,
          365,
          452,
          2578,
          322,
          2610,
          420,
          746,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3997.6,
        "id": 1160,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3994.6,
        "temperature": 0,
        "text": " I will maybe try to answer a few questions.",
        "tokens": [
          50814,
          286,
          486,
          1310,
          853,
          281,
          1867,
          257,
          1326,
          1651,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 3999.6,
        "id": 1161,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3997.6,
        "temperature": 0,
        "text": " Boy, I'm really exhausted,",
        "tokens": [
          50964,
          9486,
          11,
          286,
          478,
          534,
          17992,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 4001.6,
        "id": 1162,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 3999.6,
        "temperature": 0,
        "text": " but we're going to go through this anyway.",
        "tokens": [
          51064,
          457,
          321,
          434,
          516,
          281,
          352,
          807,
          341,
          4033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 4002.6,
        "id": 1163,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 4001.6,
        "temperature": 0,
        "text": " Yeah, no tea, no coffee,",
        "tokens": [
          51164,
          865,
          11,
          572,
          5817,
          11,
          572,
          4982,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 4008.6,
        "id": 1164,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 4002.6,
        "temperature": 0,
        "text": " but I do have my clean canteen of water.",
        "tokens": [
          51214,
          457,
          286,
          360,
          362,
          452,
          2541,
          393,
          9791,
          295,
          1281,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 4010.6,
        "id": 1165,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 4008.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1864720546838009,
        "compression_ratio": 1.5637065637065637,
        "end": 4014.6,
        "id": 1166,
        "no_speech_prob": 0.4919646680355072,
        "seek": 398560,
        "start": 4010.6,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51614,
          1692,
          321,
          352,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4016.6,
        "id": 1167,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4014.6,
        "temperature": 0,
        "text": " Welcome to a coding challenge.",
        "tokens": [
          50364,
          4027,
          281,
          257,
          17720,
          3430,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4017.6,
        "id": 1168,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4016.6,
        "temperature": 0,
        "text": " In this coding challenge,",
        "tokens": [
          50464,
          682,
          341,
          17720,
          3430,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4019.6,
        "id": 1169,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4017.6,
        "temperature": 0,
        "text": " I am going to,",
        "tokens": [
          50514,
          286,
          669,
          516,
          281,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4020.6,
        "id": 1170,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4019.6,
        "temperature": 0,
        "text": " what am I going to do?",
        "tokens": [
          50614,
          437,
          669,
          286,
          516,
          281,
          360,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4022.6,
        "id": 1171,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4020.6,
        "temperature": 0,
        "text": " Ah, breadth-first search.",
        "tokens": [
          50664,
          2438,
          11,
          35862,
          12,
          29581,
          3164,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4023.6,
        "id": 1172,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4022.6,
        "temperature": 0,
        "text": " What's breadth-first search?",
        "tokens": [
          50764,
          708,
          311,
          35862,
          12,
          29581,
          3164,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4024.6,
        "id": 1173,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4023.6,
        "temperature": 0,
        "text": " Why should you care first?",
        "tokens": [
          50814,
          1545,
          820,
          291,
          1127,
          700,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4025.6,
        "id": 1174,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4024.6,
        "temperature": 0,
        "text": " Before I even get into it,",
        "tokens": [
          50864,
          4546,
          286,
          754,
          483,
          666,
          309,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4028.6,
        "id": 1175,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4025.6,
        "temperature": 0,
        "text": " I would like to thank the author of this book,",
        "tokens": [
          50914,
          286,
          576,
          411,
          281,
          1309,
          264,
          3793,
          295,
          341,
          1446,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4029.6,
        "id": 1176,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4028.6,
        "temperature": 0,
        "text": " Grokking Algorithms,",
        "tokens": [
          51064,
          12981,
          74,
          5092,
          35014,
          6819,
          2592,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4032.6,
        "id": 1177,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4029.6,
        "temperature": 0,
        "text": " because this particular example,",
        "tokens": [
          51114,
          570,
          341,
          1729,
          1365,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4034.6,
        "id": 1178,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4032.6,
        "temperature": 0,
        "text": " that's not exactly the thing that I'm going to build,",
        "tokens": [
          51264,
          300,
          311,
          406,
          2293,
          264,
          551,
          300,
          286,
          478,
          516,
          281,
          1322,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4037.6,
        "id": 1179,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4034.6,
        "temperature": 0,
        "text": " but it's something that I did recently after reading this book.",
        "tokens": [
          51364,
          457,
          309,
          311,
          746,
          300,
          286,
          630,
          3938,
          934,
          3760,
          341,
          1446,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16448846524649294,
        "compression_ratio": 1.7366412213740459,
        "end": 4042.6,
        "id": 1180,
        "no_speech_prob": 0.09807028621435165,
        "seek": 401460,
        "start": 4037.6,
        "temperature": 0,
        "text": " This is a version, this example,",
        "tokens": [
          51514,
          639,
          307,
          257,
          3037,
          11,
          341,
          1365,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4048.6,
        "id": 1181,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4042.6,
        "temperature": 0,
        "text": " Do I get my do-over?",
        "tokens": [
          50364,
          1144,
          286,
          483,
          452,
          360,
          12,
          3570,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4050.6,
        "id": 1182,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4048.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4051.6,
        "id": 1183,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4050.6,
        "temperature": 0,
        "text": " Maybe I should use the whistle.",
        "tokens": [
          50764,
          2704,
          286,
          820,
          764,
          264,
          23470,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4053.6,
        "id": 1184,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4051.6,
        "temperature": 0,
        "text": " Whistle is good luck.",
        "tokens": [
          50814,
          506,
          16088,
          307,
          665,
          3668,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4055.6,
        "id": 1185,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4053.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50914,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4057.6,
        "id": 1186,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4055.6,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51014,
          2425,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4059.6,
        "id": 1187,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4057.6,
        "temperature": 0,
        "text": " Welcome to a coding challenge.",
        "tokens": [
          51114,
          4027,
          281,
          257,
          17720,
          3430,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4060.6,
        "id": 1188,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4059.6,
        "temperature": 0,
        "text": " In this coding challenge,",
        "tokens": [
          51214,
          682,
          341,
          17720,
          3430,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4063.6,
        "id": 1189,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4060.6,
        "temperature": 0,
        "text": " I am going to attempt something called breadth-first search.",
        "tokens": [
          51264,
          286,
          669,
          516,
          281,
          5217,
          746,
          1219,
          35862,
          12,
          29581,
          3164,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4065.6,
        "id": 1190,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4063.6,
        "temperature": 0,
        "text": " Now, this is an example,",
        "tokens": [
          51414,
          823,
          11,
          341,
          307,
          364,
          1365,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.158608781530502,
        "compression_ratio": 1.5483870967741935,
        "end": 4069.6,
        "id": 1191,
        "no_speech_prob": 0.006388039793819189,
        "seek": 404260,
        "start": 4065.6,
        "temperature": 0,
        "text": " an implementation in p5.js of breadth-first search.",
        "tokens": [
          51514,
          364,
          11420,
          294,
          280,
          20,
          13,
          25530,
          295,
          35862,
          12,
          29581,
          3164,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4071.6,
        "id": 1192,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4069.6,
        "temperature": 0,
        "text": " It comes directly from this book,",
        "tokens": [
          50364,
          467,
          1487,
          3838,
          490,
          341,
          1446,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4072.6,
        "id": 1193,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4071.6,
        "temperature": 0,
        "text": " Grokking Algorithms,",
        "tokens": [
          50464,
          12981,
          74,
          5092,
          35014,
          6819,
          2592,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4075.6,
        "id": 1194,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4072.6,
        "temperature": 0,
        "text": " by Aditya Y. Bhargava.",
        "tokens": [
          50514,
          538,
          1999,
          507,
          64,
          398,
          13,
          49104,
          70,
          4061,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4076.6,
        "id": 1195,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4075.6,
        "temperature": 0,
        "text": " It's a wonderful book.",
        "tokens": [
          50664,
          467,
          311,
          257,
          3715,
          1446,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4077.6,
        "id": 1196,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4076.6,
        "temperature": 0,
        "text": " I highly recommend it.",
        "tokens": [
          50714,
          286,
          5405,
          2748,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4081.6,
        "id": 1197,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4077.6,
        "temperature": 0,
        "text": " Buzz marketing books here on my YouTube thing.",
        "tokens": [
          50764,
          29209,
          6370,
          3642,
          510,
          322,
          452,
          3088,
          551,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4082.6,
        "id": 1198,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4081.6,
        "temperature": 0,
        "text": " But I do want to thank,",
        "tokens": [
          50964,
          583,
          286,
          360,
          528,
          281,
          1309,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4085.6,
        "id": 1199,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4082.6,
        "temperature": 0,
        "text": " that's where I learned more recently about this algorithm",
        "tokens": [
          51014,
          300,
          311,
          689,
          286,
          3264,
          544,
          3938,
          466,
          341,
          9284,
          51164
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4086.6,
        "id": 1200,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4085.6,
        "temperature": 0,
        "text": " and in practicing it,",
        "tokens": [
          51164,
          293,
          294,
          11350,
          309,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4087.6,
        "id": 1201,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4086.6,
        "temperature": 0,
        "text": " implemented the example.",
        "tokens": [
          51214,
          12270,
          264,
          1365,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4088.6,
        "id": 1202,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4087.6,
        "temperature": 0,
        "text": " So what is breadth-first search?",
        "tokens": [
          51264,
          407,
          437,
          307,
          35862,
          12,
          29581,
          3164,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4090.6,
        "id": 1203,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4088.6,
        "temperature": 0,
        "text": " So this video, first of all,",
        "tokens": [
          51314,
          407,
          341,
          960,
          11,
          700,
          295,
          439,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4092.6,
        "id": 1204,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4090.6,
        "temperature": 0,
        "text": " is also placed in a series of videos",
        "tokens": [
          51414,
          307,
          611,
          7074,
          294,
          257,
          2638,
          295,
          2145,
          51514
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4095.6,
        "id": 1205,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4092.6,
        "temperature": 0,
        "text": " about graph systems and search algorithms.",
        "tokens": [
          51514,
          466,
          4295,
          3652,
          293,
          3164,
          14642,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16035458758160784,
        "compression_ratio": 1.6283783783783783,
        "end": 4097.6,
        "id": 1206,
        "no_speech_prob": 0.02886955626308918,
        "seek": 406960,
        "start": 4095.6,
        "temperature": 0,
        "text": " So you can, in this video's description,",
        "tokens": [
          51664,
          407,
          291,
          393,
          11,
          294,
          341,
          960,
          311,
          3855,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4099.6,
        "id": 1207,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4097.6,
        "temperature": 0,
        "text": " go back to some of the introduction videos",
        "tokens": [
          50364,
          352,
          646,
          281,
          512,
          295,
          264,
          9339,
          2145,
          50464
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4100.6,
        "id": 1208,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4099.6,
        "temperature": 0,
        "text": " that will lead you up to here.",
        "tokens": [
          50464,
          300,
          486,
          1477,
          291,
          493,
          281,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4101.6,
        "id": 1209,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4100.6,
        "temperature": 0,
        "text": " But you can also just be here right now",
        "tokens": [
          50514,
          583,
          291,
          393,
          611,
          445,
          312,
          510,
          558,
          586,
          50564
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4103.6,
        "id": 1210,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4101.6,
        "temperature": 0,
        "text": " because I'm going to do everything from scratch",
        "tokens": [
          50564,
          570,
          286,
          478,
          516,
          281,
          360,
          1203,
          490,
          8459,
          50664
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4104.6,
        "id": 1211,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4103.6,
        "temperature": 0,
        "text": " with no knowledge.",
        "tokens": [
          50664,
          365,
          572,
          3601,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4107.6,
        "id": 1212,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4104.6,
        "temperature": 0,
        "text": " But a graph system is a system of nodes and edges.",
        "tokens": [
          50714,
          583,
          257,
          4295,
          1185,
          307,
          257,
          1185,
          295,
          13891,
          293,
          8819,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4109.6,
        "id": 1213,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4107.6,
        "temperature": 0,
        "text": " And you can see, here are the nodes.",
        "tokens": [
          50864,
          400,
          291,
          393,
          536,
          11,
          510,
          366,
          264,
          13891,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4110.6,
        "id": 1214,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4109.6,
        "temperature": 0,
        "text": " Now, the nodes all have a name.",
        "tokens": [
          50964,
          823,
          11,
          264,
          13891,
          439,
          362,
          257,
          1315,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4112.6,
        "id": 1215,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4110.6,
        "temperature": 0,
        "text": " These names are exactly the names",
        "tokens": [
          51014,
          1981,
          5288,
          366,
          2293,
          264,
          5288,
          51114
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4114.6,
        "id": 1216,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4112.6,
        "temperature": 0,
        "text": " in the Grokking Algorithms book.",
        "tokens": [
          51114,
          294,
          264,
          12981,
          74,
          5092,
          35014,
          6819,
          2592,
          1446,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4115.6,
        "id": 1217,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4114.6,
        "temperature": 0,
        "text": " And they have edges,",
        "tokens": [
          51214,
          400,
          436,
          362,
          8819,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4116.6,
        "id": 1218,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4115.6,
        "temperature": 0,
        "text": " so they have connections.",
        "tokens": [
          51264,
          370,
          436,
          362,
          9271,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4120.6,
        "id": 1219,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4116.6,
        "temperature": 0,
        "text": " You can think of this as maybe a map of friends",
        "tokens": [
          51314,
          509,
          393,
          519,
          295,
          341,
          382,
          1310,
          257,
          4471,
          295,
          1855,
          51514
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4122.6,
        "id": 1220,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4120.6,
        "temperature": 0,
        "text": " and their relationships.",
        "tokens": [
          51514,
          293,
          641,
          6159,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16313453182097404,
        "compression_ratio": 1.744408945686901,
        "end": 4126.6,
        "id": 1221,
        "no_speech_prob": 0.061867501586675644,
        "seek": 409760,
        "start": 4122.6,
        "temperature": 0,
        "text": " You could also turn this into more like a maze type thing.",
        "tokens": [
          51614,
          509,
          727,
          611,
          1261,
          341,
          666,
          544,
          411,
          257,
          33032,
          2010,
          551,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4127.6,
        "id": 1222,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4126.6,
        "temperature": 0,
        "text": " There's so many different ways",
        "tokens": [
          50364,
          821,
          311,
          370,
          867,
          819,
          2098,
          50414
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4130.6,
        "id": 1223,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4127.6,
        "temperature": 0,
        "text": " you could sort of visualize this idea of a graph system.",
        "tokens": [
          50414,
          291,
          727,
          1333,
          295,
          23273,
          341,
          1558,
          295,
          257,
          4295,
          1185,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4131.6,
        "id": 1224,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4130.6,
        "temperature": 0,
        "text": " And you'll see in some future videos",
        "tokens": [
          50564,
          400,
          291,
          603,
          536,
          294,
          512,
          2027,
          2145,
          50614
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4133.6,
        "id": 1225,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4131.6,
        "temperature": 0,
        "text": " that I actually made previously,",
        "tokens": [
          50614,
          300,
          286,
          767,
          1027,
          8046,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4135.6,
        "id": 1226,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4133.6,
        "temperature": 0,
        "text": " I do have some implementations of graph systems",
        "tokens": [
          50714,
          286,
          360,
          362,
          512,
          4445,
          763,
          295,
          4295,
          3652,
          50814
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4137.6,
        "id": 1227,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4135.6,
        "temperature": 0,
        "text": " to create mazes.",
        "tokens": [
          50814,
          281,
          1884,
          463,
          12214,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4138.6,
        "id": 1228,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4137.6,
        "temperature": 0,
        "text": " But that aside,",
        "tokens": [
          50914,
          583,
          300,
          7359,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4141.6,
        "id": 1229,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4138.6,
        "temperature": 0,
        "text": " what breadth-first search is designed to do",
        "tokens": [
          50964,
          437,
          35862,
          12,
          29581,
          3164,
          307,
          4761,
          281,
          360,
          51114
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4145.6,
        "id": 1230,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4141.6,
        "temperature": 0,
        "text": " is find the shortest path between two nodes.",
        "tokens": [
          51114,
          307,
          915,
          264,
          31875,
          3100,
          1296,
          732,
          13891,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4146.6,
        "id": 1231,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4145.6,
        "temperature": 0,
        "text": " And in something like this,",
        "tokens": [
          51314,
          400,
          294,
          746,
          411,
          341,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4151.6,
        "id": 1232,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4146.6,
        "temperature": 0,
        "text": " it's quite a simple problem to eyeball it.",
        "tokens": [
          51364,
          309,
          311,
          1596,
          257,
          2199,
          1154,
          281,
          38868,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4152.6,
        "id": 1233,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4151.6,
        "temperature": 0,
        "text": " We can see, like,",
        "tokens": [
          51614,
          492,
          393,
          536,
          11,
          411,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4154.6,
        "id": 1234,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4152.6,
        "temperature": 0,
        "text": " if I want to get from you or me",
        "tokens": [
          51664,
          498,
          286,
          528,
          281,
          483,
          490,
          291,
          420,
          385,
          51764
        ]
      },
      {
        "avg_logprob": -0.17217910201461226,
        "compression_ratio": 1.6047297297297298,
        "end": 4155.6,
        "id": 1235,
        "no_speech_prob": 0.00011061147961299866,
        "seek": 412660,
        "start": 4154.6,
        "temperature": 0,
        "text": " or whoever this person is,",
        "tokens": [
          51764,
          420,
          11387,
          341,
          954,
          307,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4156.6,
        "id": 1236,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4155.6,
        "temperature": 0,
        "text": " to Tom,",
        "tokens": [
          50364,
          281,
          5041,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4159.6,
        "id": 1237,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4156.6,
        "temperature": 0,
        "text": " I can see through Claire there are just two steps.",
        "tokens": [
          50414,
          286,
          393,
          536,
          807,
          22605,
          456,
          366,
          445,
          732,
          4439,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4161.6,
        "id": 1238,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4159.6,
        "temperature": 0,
        "text": " If I want to get to Anuj,",
        "tokens": [
          50564,
          759,
          286,
          528,
          281,
          483,
          281,
          1107,
          4579,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4162.6,
        "id": 1239,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4161.6,
        "temperature": 0,
        "text": " this through Bob",
        "tokens": [
          50664,
          341,
          807,
          6085,
          50714
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4165.6,
        "id": 1240,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4162.6,
        "temperature": 0,
        "text": " is faster than going through Alice, Peggy, Bob, Anuj.",
        "tokens": [
          50714,
          307,
          4663,
          813,
          516,
          807,
          16004,
          11,
          28007,
          1480,
          11,
          6085,
          11,
          1107,
          4579,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4167.6,
        "id": 1241,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4165.6,
        "temperature": 0,
        "text": " So how do you figure this out?",
        "tokens": [
          50864,
          407,
          577,
          360,
          291,
          2573,
          341,
          484,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4171.6,
        "id": 1242,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4167.6,
        "temperature": 0,
        "text": " One algorithm for doing this is called breadth-first search.",
        "tokens": [
          50964,
          1485,
          9284,
          337,
          884,
          341,
          307,
          1219,
          35862,
          12,
          29581,
          3164,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4173.6,
        "id": 1243,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4171.6,
        "temperature": 0,
        "text": " And the reason why it's called breadth-first search",
        "tokens": [
          51164,
          400,
          264,
          1778,
          983,
          309,
          311,
          1219,
          35862,
          12,
          29581,
          3164,
          51264
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4176.6,
        "id": 1244,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4173.6,
        "temperature": 0,
        "text": " rather than something else that you might have learned about",
        "tokens": [
          51264,
          2831,
          813,
          746,
          1646,
          300,
          291,
          1062,
          362,
          3264,
          466,
          51414
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4179.6,
        "id": 1245,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4176.6,
        "temperature": 0,
        "text": " or see in a future video called depth-first search",
        "tokens": [
          51414,
          420,
          536,
          294,
          257,
          2027,
          960,
          1219,
          7161,
          12,
          29581,
          3164,
          51564
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4181.6,
        "id": 1246,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4179.6,
        "temperature": 0,
        "text": " is breadth-first search, by definition,",
        "tokens": [
          51564,
          307,
          35862,
          12,
          29581,
          3164,
          11,
          538,
          7123,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.16174948916715734,
        "compression_ratio": 1.7653429602888087,
        "end": 4184.6,
        "id": 1247,
        "no_speech_prob": 0.0005976649117656052,
        "seek": 415560,
        "start": 4181.6,
        "temperature": 0,
        "text": " looks at all the nearest nodes first,",
        "tokens": [
          51664,
          1542,
          412,
          439,
          264,
          23831,
          13891,
          700,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4186.6,
        "id": 1248,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4184.6,
        "temperature": 0,
        "text": " sees if it finds what it's looking for,",
        "tokens": [
          50364,
          8194,
          498,
          309,
          10704,
          437,
          309,
          311,
          1237,
          337,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4188.6,
        "id": 1249,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4186.6,
        "temperature": 0,
        "text": " then looks at all the nearest ones to those first",
        "tokens": [
          50464,
          550,
          1542,
          412,
          439,
          264,
          23831,
          2306,
          281,
          729,
          700,
          50564
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4190.6,
        "id": 1250,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4188.6,
        "temperature": 0,
        "text": " and sees what it looks to find first,",
        "tokens": [
          50564,
          293,
          8194,
          437,
          309,
          1542,
          281,
          915,
          700,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4192.6,
        "id": 1251,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4190.6,
        "temperature": 0,
        "text": " as opposed to going all the way through.",
        "tokens": [
          50664,
          382,
          8851,
          281,
          516,
          439,
          264,
          636,
          807,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4195.6,
        "id": 1252,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4192.6,
        "temperature": 0,
        "text": " I recently made a video about binary trees and search trees.",
        "tokens": [
          50764,
          286,
          3938,
          1027,
          257,
          960,
          466,
          17434,
          5852,
          293,
          3164,
          5852,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4197.6,
        "id": 1253,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4195.6,
        "temperature": 0,
        "text": " That's more like depth-first search",
        "tokens": [
          50914,
          663,
          311,
          544,
          411,
          7161,
          12,
          29581,
          3164,
          51014
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4198.6,
        "id": 1254,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4197.6,
        "temperature": 0,
        "text": " because in the binary tree,",
        "tokens": [
          51014,
          570,
          294,
          264,
          17434,
          4230,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4201.6,
        "id": 1255,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4198.6,
        "temperature": 0,
        "text": " you just keep going to the left all the way to the bottom.",
        "tokens": [
          51064,
          291,
          445,
          1066,
          516,
          281,
          264,
          1411,
          439,
          264,
          636,
          281,
          264,
          2767,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4202.6,
        "id": 1256,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4201.6,
        "temperature": 0,
        "text": " But here, breadth-first,",
        "tokens": [
          51214,
          583,
          510,
          11,
          35862,
          12,
          29581,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4205.6,
        "id": 1257,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4202.6,
        "temperature": 0,
        "text": " we're looking at the nearest neighbors to start.",
        "tokens": [
          51264,
          321,
          434,
          1237,
          412,
          264,
          23831,
          12512,
          281,
          722,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4208.6,
        "id": 1258,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4205.6,
        "temperature": 0,
        "text": " Okay, so what's the problem that I'm going to work with today?",
        "tokens": [
          51414,
          1033,
          11,
          370,
          437,
          311,
          264,
          1154,
          300,
          286,
          478,
          516,
          281,
          589,
          365,
          965,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4211.6,
        "id": 1259,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4208.6,
        "temperature": 0,
        "text": " You may or may not be familiar with...",
        "tokens": [
          51564,
          509,
          815,
          420,
          815,
          406,
          312,
          4963,
          365,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.1827174663543701,
        "compression_ratio": 1.7753846153846153,
        "end": 4213.6,
        "id": 1260,
        "no_speech_prob": 0.00019716793030966073,
        "seek": 418460,
        "start": 4211.6,
        "temperature": 0,
        "text": " I don't know what this is, a thought experiment,",
        "tokens": [
          51714,
          286,
          500,
          380,
          458,
          437,
          341,
          307,
          11,
          257,
          1194,
          5120,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4216.6,
        "id": 1261,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4213.6,
        "temperature": 0,
        "text": " a weird idea, six degrees of Kevin Bacon.",
        "tokens": [
          50364,
          257,
          3657,
          1558,
          11,
          2309,
          5310,
          295,
          9954,
          42460,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4217.6,
        "id": 1262,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4216.6,
        "temperature": 0,
        "text": " There's actually a website.",
        "tokens": [
          50514,
          821,
          311,
          767,
          257,
          3144,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4220.6,
        "id": 1263,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4217.6,
        "temperature": 0,
        "text": " It's called Oracle of Bacon.",
        "tokens": [
          50564,
          467,
          311,
          1219,
          25654,
          295,
          42460,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4222.6,
        "id": 1264,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4220.6,
        "temperature": 0,
        "text": " And I'm going to go to it right now.",
        "tokens": [
          50714,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          309,
          558,
          586,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4227.6,
        "id": 1265,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4222.6,
        "temperature": 0,
        "text": " And I don't know, I need an actor.",
        "tokens": [
          50814,
          400,
          286,
          500,
          380,
          458,
          11,
          286,
          643,
          364,
          8747,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4231.6,
        "id": 1266,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4227.6,
        "temperature": 0,
        "text": " Let's pick Amy Schumer.",
        "tokens": [
          51064,
          961,
          311,
          1888,
          12651,
          2065,
          15583,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4234.6,
        "id": 1267,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4231.6,
        "temperature": 0,
        "text": " And I'm going to pick Find Link.",
        "tokens": [
          51264,
          400,
          286,
          478,
          516,
          281,
          1888,
          11809,
          8466,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4237.6,
        "id": 1268,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4234.6,
        "temperature": 0,
        "text": " Okay, Amy Schumer has a Bacon number of two.",
        "tokens": [
          51414,
          1033,
          11,
          12651,
          2065,
          15583,
          575,
          257,
          42460,
          1230,
          295,
          732,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19117204959575945,
        "compression_ratio": 1.587378640776699,
        "end": 4241.6,
        "id": 1269,
        "no_speech_prob": 0.00008220170275308192,
        "seek": 421360,
        "start": 4237.6,
        "temperature": 0,
        "text": " The shortest path between Amy Schumer and Kevin Bacon,",
        "tokens": [
          51564,
          440,
          31875,
          3100,
          1296,
          12651,
          2065,
          15583,
          293,
          9954,
          42460,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4244.6,
        "id": 1270,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4241.6,
        "temperature": 0,
        "text": " Amy Schumer was in the movie Trainwreck with Marissa Tomei,",
        "tokens": [
          50364,
          12651,
          2065,
          15583,
          390,
          294,
          264,
          3169,
          28029,
          86,
          14954,
          365,
          2039,
          10138,
          314,
          423,
          72,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4248.6,
        "id": 1271,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4244.6,
        "temperature": 0,
        "text": " who's in the movie Crazy Stupid Love with Kevin Bacon.",
        "tokens": [
          50514,
          567,
          311,
          294,
          264,
          3169,
          22509,
          37659,
          5956,
          365,
          9954,
          42460,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4252.6,
        "id": 1272,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4248.6,
        "temperature": 0,
        "text": " So this particular website has a massive database of movies,",
        "tokens": [
          50714,
          407,
          341,
          1729,
          3144,
          575,
          257,
          5994,
          8149,
          295,
          6233,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4255.6,
        "id": 1273,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4252.6,
        "temperature": 0,
        "text": " casts, and uses breadth-first search",
        "tokens": [
          50914,
          41921,
          11,
          293,
          4960,
          35862,
          12,
          29581,
          3164,
          51064
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4258.6,
        "id": 1274,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4255.6,
        "temperature": 0,
        "text": " to find the shortest path between two actors.",
        "tokens": [
          51064,
          281,
          915,
          264,
          31875,
          3100,
          1296,
          732,
          10037,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4260.6,
        "id": 1275,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4258.6,
        "temperature": 0,
        "text": " And the thought experiment here is that Kevin Bacon",
        "tokens": [
          51214,
          400,
          264,
          1194,
          5120,
          510,
          307,
          300,
          9954,
          42460,
          51314
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4261.6,
        "id": 1276,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4260.6,
        "temperature": 0,
        "text": " has just been in so many movies",
        "tokens": [
          51314,
          575,
          445,
          668,
          294,
          370,
          867,
          6233,
          51364
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4265.6,
        "id": 1277,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4261.6,
        "temperature": 0,
        "text": " that anyone could be within six degrees of Kevin Bacon.",
        "tokens": [
          51364,
          300,
          2878,
          727,
          312,
          1951,
          2309,
          5310,
          295,
          9954,
          42460,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1741621787087959,
        "compression_ratio": 1.6029962546816479,
        "end": 4267.6,
        "id": 1278,
        "no_speech_prob": 0.04272110015153885,
        "seek": 424160,
        "start": 4265.6,
        "temperature": 0,
        "text": " I don't think I have an IMDB.",
        "tokens": [
          51564,
          286,
          500,
          380,
          519,
          286,
          362,
          364,
          21463,
          27735,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4271.6,
        "id": 1279,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4267.6,
        "temperature": 0,
        "text": " What's the chance that Kevin Bacon to Daniel Shiffman?",
        "tokens": [
          50364,
          708,
          311,
          264,
          2931,
          300,
          9954,
          42460,
          281,
          8033,
          1160,
          3661,
          1601,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4273.6,
        "id": 1280,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4271.6,
        "temperature": 0,
        "text": " Nah, infinity.",
        "tokens": [
          50564,
          13933,
          11,
          13202,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4274.6,
        "id": 1281,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4273.6,
        "temperature": 0,
        "text": " Infinity, we got to work on that.",
        "tokens": [
          50664,
          34762,
          11,
          321,
          658,
          281,
          589,
          322,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4276.6,
        "id": 1282,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4274.6,
        "temperature": 0,
        "text": " Come on, help me out with this here.",
        "tokens": [
          50714,
          2492,
          322,
          11,
          854,
          385,
          484,
          365,
          341,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4278.6,
        "id": 1283,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4276.6,
        "temperature": 0,
        "text": " I want my Kevin Bacon number to come on down.",
        "tokens": [
          50814,
          286,
          528,
          452,
          9954,
          42460,
          1230,
          281,
          808,
          322,
          760,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4280.6,
        "id": 1284,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4278.6,
        "temperature": 0,
        "text": " Okay, so how are we going to do this?",
        "tokens": [
          50914,
          1033,
          11,
          370,
          577,
          366,
          321,
          516,
          281,
          360,
          341,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4283.6,
        "id": 1285,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4280.6,
        "temperature": 0,
        "text": " Now, I would love if anybody...",
        "tokens": [
          51014,
          823,
          11,
          286,
          576,
          959,
          498,
          4472,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4285.6,
        "id": 1286,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4283.6,
        "temperature": 0,
        "text": " So this is an experiment.",
        "tokens": [
          51164,
          407,
          341,
          307,
          364,
          5120,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4286.6,
        "id": 1287,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4285.6,
        "temperature": 0,
        "text": " I'm going to do this for you",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          360,
          341,
          337,
          291,
          51314
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4289.6,
        "id": 1288,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4286.6,
        "temperature": 0,
        "text": " and hopefully teach you something about this.",
        "tokens": [
          51314,
          293,
          4696,
          2924,
          291,
          746,
          466,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4290.6,
        "id": 1289,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4289.6,
        "temperature": 0,
        "text": " And then maybe you could do something similar",
        "tokens": [
          51464,
          400,
          550,
          1310,
          291,
          727,
          360,
          746,
          2531,
          51514
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4292.6,
        "id": 1290,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4290.6,
        "temperature": 0,
        "text": " but with a different data set.",
        "tokens": [
          51514,
          457,
          365,
          257,
          819,
          1412,
          992,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1883068742423222,
        "compression_ratio": 1.686206896551724,
        "end": 4295.6,
        "id": 1291,
        "no_speech_prob": 0.05920650437474251,
        "seek": 426760,
        "start": 4292.6,
        "temperature": 0,
        "text": " But I'm going to use just a toy data set, essentially.",
        "tokens": [
          51614,
          583,
          286,
          478,
          516,
          281,
          764,
          445,
          257,
          12058,
          1412,
          992,
          11,
          4476,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4298.6,
        "id": 1292,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4295.6,
        "temperature": 0,
        "text": " This is what I manually created before coming here.",
        "tokens": [
          50364,
          639,
          307,
          437,
          286,
          16945,
          2942,
          949,
          1348,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4299.6,
        "id": 1293,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4298.6,
        "temperature": 0,
        "text": " Right now, this data set.",
        "tokens": [
          50514,
          1779,
          586,
          11,
          341,
          1412,
          992,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4303.6,
        "id": 1294,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4299.6,
        "temperature": 0,
        "text": " So this data set has a few movies in it,",
        "tokens": [
          50564,
          407,
          341,
          1412,
          992,
          575,
          257,
          1326,
          6233,
          294,
          309,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4305.6,
        "id": 1295,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4303.6,
        "temperature": 0,
        "text": " some of which have Kevin Bacon in it,",
        "tokens": [
          50764,
          512,
          295,
          597,
          362,
          9954,
          42460,
          294,
          309,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4307.6,
        "id": 1296,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4305.6,
        "temperature": 0,
        "text": " and some of which don't have Kevin Bacon in it.",
        "tokens": [
          50864,
          293,
          512,
          295,
          597,
          500,
          380,
          362,
          9954,
          42460,
          294,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4310.6,
        "id": 1297,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4307.6,
        "temperature": 0,
        "text": " It's organized in JSON format,",
        "tokens": [
          50964,
          467,
          311,
          9983,
          294,
          31828,
          7877,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4312.6,
        "id": 1298,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4310.6,
        "temperature": 0,
        "text": " which is JavaScript Object Notation.",
        "tokens": [
          51114,
          597,
          307,
          15778,
          24753,
          1726,
          399,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4313.6,
        "id": 1299,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4312.6,
        "temperature": 0,
        "text": " I do have some video tutorials about that",
        "tokens": [
          51214,
          286,
          360,
          362,
          512,
          960,
          17616,
          466,
          300,
          51264
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4315.6,
        "id": 1300,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4313.6,
        "temperature": 0,
        "text": " if that's unfamiliar to you,",
        "tokens": [
          51264,
          498,
          300,
          311,
          29415,
          281,
          291,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4317.6,
        "id": 1301,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4315.6,
        "temperature": 0,
        "text": " but I'll try to talk about that a little bit as I go through.",
        "tokens": [
          51364,
          457,
          286,
          603,
          853,
          281,
          751,
          466,
          300,
          257,
          707,
          857,
          382,
          286,
          352,
          807,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4319.6,
        "id": 1302,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4317.6,
        "temperature": 0,
        "text": " So let me move over to the whiteboard",
        "tokens": [
          51464,
          407,
          718,
          385,
          1286,
          670,
          281,
          264,
          2418,
          3787,
          51564
        ]
      },
      {
        "avg_logprob": -0.16265098084794713,
        "compression_ratio": 1.6815068493150684,
        "end": 4322.6,
        "id": 1303,
        "no_speech_prob": 0.029311681166291237,
        "seek": 429560,
        "start": 4319.6,
        "temperature": 0,
        "text": " to figure out how we're going to work this out.",
        "tokens": [
          51564,
          281,
          2573,
          484,
          577,
          321,
          434,
          516,
          281,
          589,
          341,
          484,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4325.6,
        "id": 1304,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4322.6,
        "temperature": 0,
        "text": " So what I need to do in my program...",
        "tokens": [
          50364,
          407,
          437,
          286,
          643,
          281,
          360,
          294,
          452,
          1461,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4327.6,
        "id": 1305,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4325.6,
        "temperature": 0,
        "text": " We're going to look at the algorithm itself on Wikipedia",
        "tokens": [
          50514,
          492,
          434,
          516,
          281,
          574,
          412,
          264,
          9284,
          2564,
          322,
          28999,
          50614
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4329.6,
        "id": 1306,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4327.6,
        "temperature": 0,
        "text": " and start translating it into code.",
        "tokens": [
          50614,
          293,
          722,
          35030,
          309,
          666,
          3089,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4330.6,
        "id": 1307,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4329.6,
        "temperature": 0,
        "text": " But before we even do that,",
        "tokens": [
          50714,
          583,
          949,
          321,
          754,
          360,
          300,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4336.6,
        "id": 1308,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4330.6,
        "temperature": 0,
        "text": " what I need is I need a node object.",
        "tokens": [
          50764,
          437,
          286,
          643,
          307,
          286,
          643,
          257,
          9984,
          2657,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4339.6,
        "id": 1309,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4336.6,
        "temperature": 0,
        "text": " So in the end, there's going to be Kevin Bacon,",
        "tokens": [
          51064,
          407,
          294,
          264,
          917,
          11,
          456,
          311,
          516,
          281,
          312,
          9954,
          42460,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4341.6,
        "id": 1310,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4339.6,
        "temperature": 0,
        "text": " there's going to be some movie,",
        "tokens": [
          51214,
          456,
          311,
          516,
          281,
          312,
          512,
          3169,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4344.6,
        "id": 1311,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4341.6,
        "temperature": 0,
        "text": " and there's going to be some other actor.",
        "tokens": [
          51314,
          293,
          456,
          311,
          516,
          281,
          312,
          512,
          661,
          8747,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4348.6,
        "id": 1312,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4346.6,
        "temperature": 0,
        "text": " And then there's lots of other stuff.",
        "tokens": [
          51564,
          400,
          550,
          456,
          311,
          3195,
          295,
          661,
          1507,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17008322682873955,
        "compression_ratio": 1.7692307692307692,
        "end": 4350.6,
        "id": 1313,
        "no_speech_prob": 0.000054759504564572126,
        "seek": 432260,
        "start": 4348.6,
        "temperature": 0,
        "text": " So in order to keep track of these,",
        "tokens": [
          51664,
          407,
          294,
          1668,
          281,
          1066,
          2837,
          295,
          613,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4353.6,
        "id": 1314,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4350.6,
        "temperature": 0,
        "text": " what I need is I need some sort of object.",
        "tokens": [
          50364,
          437,
          286,
          643,
          307,
          286,
          643,
          512,
          1333,
          295,
          2657,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4355.6,
        "id": 1315,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4353.6,
        "temperature": 0,
        "text": " I'm going to call it a node.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          818,
          309,
          257,
          9984,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4358.6,
        "id": 1316,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4355.6,
        "temperature": 0,
        "text": " And that object needs to have what you call a value or a label.",
        "tokens": [
          50614,
          400,
          300,
          2657,
          2203,
          281,
          362,
          437,
          291,
          818,
          257,
          2158,
          420,
          257,
          7645,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4360.6,
        "id": 1317,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4358.6,
        "temperature": 0,
        "text": " We're going to say a value.",
        "tokens": [
          50764,
          492,
          434,
          516,
          281,
          584,
          257,
          2158,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4361.6,
        "id": 1318,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4360.6,
        "temperature": 0,
        "text": " It also needs...",
        "tokens": [
          50864,
          467,
          611,
          2203,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4364.6,
        "id": 1319,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4361.6,
        "temperature": 0,
        "text": " Each object needs to keep track of its edges.",
        "tokens": [
          50914,
          6947,
          2657,
          2203,
          281,
          1066,
          2837,
          295,
          1080,
          8819,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4368.6,
        "id": 1320,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4364.6,
        "temperature": 0,
        "text": " Which other nodes is it connected to?",
        "tokens": [
          51064,
          3013,
          661,
          13891,
          307,
          309,
          4582,
          281,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4371.6,
        "id": 1321,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4368.6,
        "temperature": 0,
        "text": " So we need edges, and this will be an array.",
        "tokens": [
          51264,
          407,
          321,
          643,
          8819,
          11,
          293,
          341,
          486,
          312,
          364,
          10225,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4373.6,
        "id": 1322,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4371.6,
        "temperature": 0,
        "text": " I don't like these dashes here.",
        "tokens": [
          51414,
          286,
          500,
          380,
          411,
          613,
          8240,
          279,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4374.6,
        "id": 1323,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4373.6,
        "temperature": 0,
        "text": " They look like minus signs.",
        "tokens": [
          51514,
          814,
          574,
          411,
          3175,
          7880,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4375.6,
        "id": 1324,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4374.6,
        "temperature": 0,
        "text": " So I don't know.",
        "tokens": [
          51564,
          407,
          286,
          500,
          380,
          458,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4376.6,
        "id": 1325,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4375.6,
        "temperature": 0,
        "text": " Dot.",
        "tokens": [
          51614,
          38753,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4378.6,
        "id": 1326,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4376.6,
        "temperature": 0,
        "text": " That looks like something else, but anyway.",
        "tokens": [
          51664,
          663,
          1542,
          411,
          746,
          1646,
          11,
          457,
          4033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19605300161573622,
        "compression_ratio": 1.6902985074626866,
        "end": 4379.6,
        "id": 1327,
        "no_speech_prob": 0.00038596519152633846,
        "seek": 435060,
        "start": 4378.6,
        "temperature": 0,
        "text": " This is the data.",
        "tokens": [
          51764,
          639,
          307,
          264,
          1412,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4380.6,
        "id": 1328,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4379.6,
        "temperature": 0,
        "text": " Now, at its core,",
        "tokens": [
          50364,
          823,
          11,
          412,
          1080,
          4965,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4383.6,
        "id": 1329,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4380.6,
        "temperature": 0,
        "text": " this is very similar to my binary search tree that I mentioned,",
        "tokens": [
          50414,
          341,
          307,
          588,
          2531,
          281,
          452,
          17434,
          3164,
          4230,
          300,
          286,
          2835,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4386.6,
        "id": 1330,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4383.6,
        "temperature": 0,
        "text": " which each node just has a left and a right.",
        "tokens": [
          50564,
          597,
          1184,
          9984,
          445,
          575,
          257,
          1411,
          293,
          257,
          558,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4389.6,
        "id": 1331,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4386.6,
        "temperature": 0,
        "text": " But here, each node could have just one connection,",
        "tokens": [
          50714,
          583,
          510,
          11,
          1184,
          9984,
          727,
          362,
          445,
          472,
          4984,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4391.6,
        "id": 1332,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4389.6,
        "temperature": 0,
        "text": " zero connections, ten connections.",
        "tokens": [
          50864,
          4018,
          9271,
          11,
          2064,
          9271,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4394.6,
        "id": 1333,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4391.6,
        "temperature": 0,
        "text": " Now, there's other pieces of data that the node is going to need.",
        "tokens": [
          50964,
          823,
          11,
          456,
          311,
          661,
          3755,
          295,
          1412,
          300,
          264,
          9984,
          307,
          516,
          281,
          643,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4396.6,
        "id": 1334,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4394.6,
        "temperature": 0,
        "text": " And these are part of the breadth-first search algorithm.",
        "tokens": [
          51114,
          400,
          613,
          366,
          644,
          295,
          264,
          35862,
          12,
          29581,
          3164,
          9284,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4398.6,
        "id": 1335,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4396.6,
        "temperature": 0,
        "text": " I'm just going to mention them right now",
        "tokens": [
          51214,
          286,
          478,
          445,
          516,
          281,
          2152,
          552,
          558,
          586,
          51314
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4400.6,
        "id": 1336,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4398.6,
        "temperature": 0,
        "text": " because that's why they're in my mind.",
        "tokens": [
          51314,
          570,
          300,
          311,
          983,
          436,
          434,
          294,
          452,
          1575,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4402.6,
        "id": 1337,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4400.6,
        "temperature": 0,
        "text": " One is we need to know a Boolean.",
        "tokens": [
          51414,
          1485,
          307,
          321,
          643,
          281,
          458,
          257,
          23351,
          28499,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4405.6,
        "id": 1338,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4402.6,
        "temperature": 0,
        "text": " Has it been checked, searched or not?",
        "tokens": [
          51514,
          8646,
          309,
          668,
          10033,
          11,
          22961,
          420,
          406,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1947747975179594,
        "compression_ratio": 1.7049180327868851,
        "end": 4406.6,
        "id": 1339,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 437960,
        "start": 4405.6,
        "temperature": 0,
        "text": " We're looking for Kevin Bacon.",
        "tokens": [
          51664,
          492,
          434,
          1237,
          337,
          9954,
          42460,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4409.6,
        "id": 1340,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4406.6,
        "temperature": 0,
        "text": " Is this node been checked already to see whether it's Kevin Bacon or not?",
        "tokens": [
          50364,
          1119,
          341,
          9984,
          668,
          10033,
          1217,
          281,
          536,
          1968,
          309,
          311,
          9954,
          42460,
          420,
          406,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4411.6,
        "id": 1341,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4409.6,
        "temperature": 0,
        "text": " So this is going to be true or false.",
        "tokens": [
          50514,
          407,
          341,
          307,
          516,
          281,
          312,
          2074,
          420,
          7908,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4413.6,
        "id": 1342,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4411.6,
        "temperature": 0,
        "text": " This is going to be a Boolean.",
        "tokens": [
          50614,
          639,
          307,
          516,
          281,
          312,
          257,
          23351,
          28499,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4414.6,
        "id": 1343,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4413.6,
        "temperature": 0,
        "text": " And we're also going to want...",
        "tokens": [
          50714,
          400,
          321,
          434,
          611,
          516,
          281,
          528,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4417.6,
        "id": 1344,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4414.6,
        "temperature": 0,
        "text": " Eventually, we're trying to solve for that path.",
        "tokens": [
          50764,
          17586,
          11,
          321,
          434,
          1382,
          281,
          5039,
          337,
          300,
          3100,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4420.6,
        "id": 1345,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4417.6,
        "temperature": 0,
        "text": " So we're going to have nodes keep track of their parent,",
        "tokens": [
          50914,
          407,
          321,
          434,
          516,
          281,
          362,
          13891,
          1066,
          2837,
          295,
          641,
          2596,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4424.6,
        "id": 1346,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4420.6,
        "temperature": 0,
        "text": " meaning as I'm checking and moving about through this graph system,",
        "tokens": [
          51064,
          3620,
          382,
          286,
          478,
          8568,
          293,
          2684,
          466,
          807,
          341,
          4295,
          1185,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4426.6,
        "id": 1347,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4424.6,
        "temperature": 0,
        "text": " I want to keep track of where I came from.",
        "tokens": [
          51264,
          286,
          528,
          281,
          1066,
          2837,
          295,
          689,
          286,
          1361,
          490,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4428.6,
        "id": 1348,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4426.6,
        "temperature": 0,
        "text": " What was the previous node?",
        "tokens": [
          51364,
          708,
          390,
          264,
          3894,
          9984,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4432.6,
        "id": 1349,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4428.6,
        "temperature": 0,
        "text": " So that when I find Kevin Bacon, I can back up and find that full path.",
        "tokens": [
          51464,
          407,
          300,
          562,
          286,
          915,
          9954,
          42460,
          11,
          286,
          393,
          646,
          493,
          293,
          915,
          300,
          1577,
          3100,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1754737879266802,
        "compression_ratio": 1.8361774744027304,
        "end": 4434.6,
        "id": 1350,
        "no_speech_prob": 0.16235701739788055,
        "seek": 440660,
        "start": 4432.6,
        "temperature": 0,
        "text": " So I want to keep track of the parent as well.",
        "tokens": [
          51664,
          407,
          286,
          528,
          281,
          1066,
          2837,
          295,
          264,
          2596,
          382,
          731,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4438.6,
        "id": 1351,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4434.6,
        "temperature": 0,
        "text": " So we know we need an object that stores all of this stuff.",
        "tokens": [
          50364,
          407,
          321,
          458,
          321,
          643,
          364,
          2657,
          300,
          9512,
          439,
          295,
          341,
          1507,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4441.6,
        "id": 1352,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4438.6,
        "temperature": 0,
        "text": " So let me come back and start building that.",
        "tokens": [
          50564,
          407,
          718,
          385,
          808,
          646,
          293,
          722,
          2390,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4443.6,
        "id": 1353,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4441.6,
        "temperature": 0,
        "text": " And I'm just going to put that...",
        "tokens": [
          50714,
          400,
          286,
          478,
          445,
          516,
          281,
          829,
          300,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4446.6,
        "id": 1354,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4443.6,
        "temperature": 0,
        "text": " So I have a JavaScript project set up.",
        "tokens": [
          50814,
          407,
          286,
          362,
          257,
          15778,
          1716,
          992,
          493,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4449.6,
        "id": 1355,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4446.6,
        "temperature": 0,
        "text": " If I go to the browser and refresh the page,",
        "tokens": [
          50964,
          759,
          286,
          352,
          281,
          264,
          11185,
          293,
          15134,
          264,
          3028,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4452.6,
        "id": 1356,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4449.6,
        "temperature": 0,
        "text": " there's nothing on the page, but I'm going to start adding some code.",
        "tokens": [
          51114,
          456,
          311,
          1825,
          322,
          264,
          3028,
          11,
          457,
          286,
          478,
          516,
          281,
          722,
          5127,
          512,
          3089,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4457.6,
        "id": 1357,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4452.6,
        "temperature": 0,
        "text": " So first thing I'm going to do is I'm going to write a constructor function",
        "tokens": [
          51264,
          407,
          700,
          551,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          2464,
          257,
          47479,
          2445,
          51514
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4459.6,
        "id": 1358,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4457.6,
        "temperature": 0,
        "text": " for a node object.",
        "tokens": [
          51514,
          337,
          257,
          9984,
          2657,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18355704892066219,
        "compression_ratio": 1.7550200803212852,
        "end": 4462.6,
        "id": 1359,
        "no_speech_prob": 0.0004044792440254241,
        "seek": 443460,
        "start": 4459.6,
        "temperature": 0,
        "text": " And I'm going to say this.value equals something.",
        "tokens": [
          51614,
          400,
          286,
          478,
          516,
          281,
          584,
          341,
          13,
          29155,
          6915,
          746,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4464.6,
        "id": 1360,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4462.6,
        "temperature": 0,
        "text": " We needed that.",
        "tokens": [
          50364,
          492,
          2978,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4467.6,
        "id": 1361,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4465.6,
        "temperature": 0,
        "text": " This.edges is an array.",
        "tokens": [
          50514,
          639,
          13,
          292,
          2880,
          307,
          364,
          10225,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4471.6,
        "id": 1362,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4467.6,
        "temperature": 0,
        "text": " This.searched is false. It hasn't been searched.",
        "tokens": [
          50614,
          639,
          13,
          405,
          1178,
          292,
          307,
          7908,
          13,
          467,
          6132,
          380,
          668,
          22961,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4473.6,
        "id": 1363,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4471.6,
        "temperature": 0,
        "text": " And this.parent...",
        "tokens": [
          50814,
          400,
          341,
          13,
          38321,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4475.6,
        "id": 1364,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4473.6,
        "temperature": 0,
        "text": " I'm going to just set it equal to null.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          445,
          992,
          309,
          2681,
          281,
          18184,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4481.6,
        "id": 1365,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4475.6,
        "temperature": 0,
        "text": " So I want to be able to, whenever I make a node with this constructor function,",
        "tokens": [
          51014,
          407,
          286,
          528,
          281,
          312,
          1075,
          281,
          11,
          5699,
          286,
          652,
          257,
          9984,
          365,
          341,
          47479,
          2445,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4486.6,
        "id": 1366,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4481.6,
        "temperature": 0,
        "text": " even though this, by definition, its parent would be undefined,",
        "tokens": [
          51314,
          754,
          1673,
          341,
          11,
          538,
          7123,
          11,
          1080,
          2596,
          576,
          312,
          674,
          5666,
          2001,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4489.6,
        "id": 1367,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4486.6,
        "temperature": 0,
        "text": " I'm going to explicitly set it to null just so I'm keeping track of that.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          20803,
          992,
          309,
          281,
          18184,
          445,
          370,
          286,
          478,
          5145,
          2837,
          295,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19275037907371836,
        "compression_ratio": 1.6322314049586777,
        "end": 4491.6,
        "id": 1368,
        "no_speech_prob": 0.0006771907792426646,
        "seek": 446260,
        "start": 4489.6,
        "temperature": 0,
        "text": " Okay. So this is pretty good.",
        "tokens": [
          51714,
          1033,
          13,
          407,
          341,
          307,
          1238,
          665,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4492.6,
        "id": 1369,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4491.6,
        "temperature": 0,
        "text": " This is pretty good.",
        "tokens": [
          50364,
          639,
          307,
          1238,
          665,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4494.6,
        "id": 1370,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4492.6,
        "temperature": 0,
        "text": " Okay. First of all, this shouldn't be blank.",
        "tokens": [
          50414,
          1033,
          13,
          2386,
          295,
          439,
          11,
          341,
          4659,
          380,
          312,
          8247,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4498.6,
        "id": 1371,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4494.6,
        "temperature": 0,
        "text": " So maybe when I say new node, I'm going to give it a value.",
        "tokens": [
          50514,
          407,
          1310,
          562,
          286,
          584,
          777,
          9984,
          11,
          286,
          478,
          516,
          281,
          976,
          309,
          257,
          2158,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4501.6,
        "id": 1372,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4500.6,
        "temperature": 0,
        "text": " Okay. So this is good.",
        "tokens": [
          50814,
          1033,
          13,
          407,
          341,
          307,
          665,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4502.6,
        "id": 1373,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4501.6,
        "temperature": 0,
        "text": " You know what I want to do?",
        "tokens": [
          50864,
          509,
          458,
          437,
          286,
          528,
          281,
          360,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4506.6,
        "id": 1374,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4502.6,
        "temperature": 0,
        "text": " I want to take this code and I want to put this in a file called...",
        "tokens": [
          50914,
          286,
          528,
          281,
          747,
          341,
          3089,
          293,
          286,
          528,
          281,
          829,
          341,
          294,
          257,
          3991,
          1219,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4508.6,
        "id": 1375,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4506.6,
        "temperature": 0,
        "text": " I probably shouldn't call it node.js.",
        "tokens": [
          51114,
          286,
          1391,
          4659,
          380,
          818,
          309,
          9984,
          13,
          25530,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4509.6,
        "id": 1376,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4508.6,
        "temperature": 0,
        "text": " Should I?",
        "tokens": [
          51214,
          6454,
          286,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4511.6,
        "id": 1377,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4509.6,
        "temperature": 0,
        "text": " Fine. I'm going to call it node.js.",
        "tokens": [
          51264,
          12024,
          13,
          286,
          478,
          516,
          281,
          818,
          309,
          9984,
          13,
          25530,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4512.6,
        "id": 1378,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4511.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4515.6,
        "id": 1379,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4514.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1769382121951081,
        "compression_ratio": 1.6940639269406392,
        "end": 4518.6,
        "id": 1380,
        "no_speech_prob": 0.0008426362765021622,
        "seek": 449160,
        "start": 4516.6,
        "temperature": 0,
        "text": " So now Sketch doesn't need it.",
        "tokens": [
          51614,
          407,
          586,
          49245,
          1177,
          380,
          643,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4521.6,
        "id": 1381,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4518.6,
        "temperature": 0,
        "text": " So in p5, p5 has a setup function.",
        "tokens": [
          50364,
          407,
          294,
          280,
          20,
          11,
          280,
          20,
          575,
          257,
          8657,
          2445,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4524.6,
        "id": 1382,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4521.6,
        "temperature": 0,
        "text": " Setup function is kind of like window page loaded type thing.",
        "tokens": [
          50514,
          8928,
          1010,
          2445,
          307,
          733,
          295,
          411,
          4910,
          3028,
          13210,
          2010,
          551,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4525.6,
        "id": 1383,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4524.6,
        "temperature": 0,
        "text": " So that's going to be in Sketch.",
        "tokens": [
          50664,
          407,
          300,
          311,
          516,
          281,
          312,
          294,
          49245,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4527.6,
        "id": 1384,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4525.6,
        "temperature": 0,
        "text": " I'm also going to make... Here's the thing.",
        "tokens": [
          50714,
          286,
          478,
          611,
          516,
          281,
          652,
          485,
          1692,
          311,
          264,
          551,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4531.6,
        "id": 1385,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4528.6,
        "temperature": 0,
        "text": " I'm going to make a graph object.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          652,
          257,
          4295,
          2657,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4537.6,
        "id": 1386,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4534.6,
        "temperature": 0,
        "text": " So I might have some redundancy or some things in my code.",
        "tokens": [
          51164,
          407,
          286,
          1062,
          362,
          512,
          27830,
          6717,
          420,
          512,
          721,
          294,
          452,
          3089,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4539.6,
        "id": 1387,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4537.6,
        "temperature": 0,
        "text": " I'm sort of out of the picture here.",
        "tokens": [
          51314,
          286,
          478,
          1333,
          295,
          484,
          295,
          264,
          3036,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4541.6,
        "id": 1388,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4539.6,
        "temperature": 0,
        "text": " That are a little bit unnecessary.",
        "tokens": [
          51414,
          663,
          366,
          257,
          707,
          857,
          19350,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17705115293845153,
        "compression_ratio": 1.6581196581196582,
        "end": 4543.6,
        "id": 1389,
        "no_speech_prob": 0.0023596365936100483,
        "seek": 451860,
        "start": 4541.6,
        "temperature": 0,
        "text": " But what I would like to do with the graph object",
        "tokens": [
          51514,
          583,
          437,
          286,
          576,
          411,
          281,
          360,
          365,
          264,
          4295,
          2657,
          51614
        ]
      },
      {
        "avg_logprob": -0.25972422549599095,
        "compression_ratio": 1.7227722772277227,
        "end": 4549.6,
        "id": 1390,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 454360,
        "start": 4543.6,
        "temperature": 0,
        "text": " is I would like to store an array of all the nodes.",
        "tokens": [
          50364,
          307,
          286,
          576,
          411,
          281,
          3531,
          364,
          10225,
          295,
          439,
          264,
          13891,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.25972422549599095,
        "compression_ratio": 1.7227722772277227,
        "end": 4552.6,
        "id": 1391,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 454360,
        "start": 4551.6,
        "temperature": 0,
        "text": " And then I would like...",
        "tokens": [
          50764,
          400,
          550,
          286,
          576,
          411,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.25972422549599095,
        "compression_ratio": 1.7227722772277227,
        "end": 4554.6,
        "id": 1392,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 454360,
        "start": 4552.6,
        "temperature": 0,
        "text": " Of all the nodes and I probably need...",
        "tokens": [
          50814,
          2720,
          439,
          264,
          13891,
          293,
          286,
          1391,
          643,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.25972422549599095,
        "compression_ratio": 1.7227722772277227,
        "end": 4557.6,
        "id": 1393,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 454360,
        "start": 4554.6,
        "temperature": 0,
        "text": " You know what the graph really should be as a data structure?",
        "tokens": [
          50914,
          509,
          458,
          437,
          264,
          4295,
          534,
          820,
          312,
          382,
          257,
          1412,
          3877,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.25972422549599095,
        "compression_ratio": 1.7227722772277227,
        "end": 4562.6,
        "id": 1394,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 454360,
        "start": 4557.6,
        "temperature": 0,
        "text": " It would be something like I could look up each node by its...",
        "tokens": [
          51064,
          467,
          576,
          312,
          746,
          411,
          286,
          727,
          574,
          493,
          1184,
          9984,
          538,
          1080,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.25972422549599095,
        "compression_ratio": 1.7227722772277227,
        "end": 4567.6,
        "id": 1395,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 454360,
        "start": 4564.6,
        "temperature": 0,
        "text": " I'll call this a graph by its label, by its value.",
        "tokens": [
          51414,
          286,
          603,
          818,
          341,
          257,
          4295,
          538,
          1080,
          7645,
          11,
          538,
          1080,
          2158,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.25972422549599095,
        "compression_ratio": 1.7227722772277227,
        "end": 4572.6,
        "id": 1396,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 454360,
        "start": 4567.6,
        "temperature": 0,
        "text": " So this would typically be something like a hash table.",
        "tokens": [
          51564,
          407,
          341,
          576,
          5850,
          312,
          746,
          411,
          257,
          22019,
          3199,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4577.6,
        "id": 1397,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4573.6,
        "temperature": 0,
        "text": " Where the key might be Kevin Bacon.",
        "tokens": [
          50364,
          2305,
          264,
          2141,
          1062,
          312,
          9954,
          42460,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4580.6,
        "id": 1398,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4578.6,
        "temperature": 0,
        "text": " And then I could...",
        "tokens": [
          50614,
          400,
          550,
          286,
          727,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4585.6,
        "id": 1399,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4580.6,
        "temperature": 0,
        "text": " With that key I would find out all of its edges, its parent, all that other stuff.",
        "tokens": [
          50714,
          2022,
          300,
          2141,
          286,
          576,
          915,
          484,
          439,
          295,
          1080,
          8819,
          11,
          1080,
          2596,
          11,
          439,
          300,
          661,
          1507,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4586.6,
        "id": 1400,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4585.6,
        "temperature": 0,
        "text": " So I want to be able to have...",
        "tokens": [
          50964,
          407,
          286,
          528,
          281,
          312,
          1075,
          281,
          362,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4588.6,
        "id": 1401,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4586.6,
        "temperature": 0,
        "text": " I might not need this array because I could always...",
        "tokens": [
          51014,
          286,
          1062,
          406,
          643,
          341,
          10225,
          570,
          286,
          727,
          1009,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4592.6,
        "id": 1402,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4588.6,
        "temperature": 0,
        "text": " The whole point of the algorithm is to traverse the graph to find what I'm looking for.",
        "tokens": [
          51114,
          440,
          1379,
          935,
          295,
          264,
          9284,
          307,
          281,
          45674,
          264,
          4295,
          281,
          915,
          437,
          286,
          478,
          1237,
          337,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4595.6,
        "id": 1403,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4592.6,
        "temperature": 0,
        "text": " But it might be useful to have this array if I want to visualize it.",
        "tokens": [
          51314,
          583,
          309,
          1062,
          312,
          4420,
          281,
          362,
          341,
          10225,
          498,
          286,
          528,
          281,
          23273,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4598.6,
        "id": 1404,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4595.6,
        "temperature": 0,
        "text": " Or do something that I could just iterate over all the nodes really quickly.",
        "tokens": [
          51464,
          1610,
          360,
          746,
          300,
          286,
          727,
          445,
          44497,
          670,
          439,
          264,
          13891,
          534,
          2661,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4599.6,
        "id": 1405,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4598.6,
        "temperature": 0,
        "text": " There's going to be some redundancy here.",
        "tokens": [
          51614,
          821,
          311,
          516,
          281,
          312,
          512,
          27830,
          6717,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19602261247306035,
        "compression_ratio": 1.7508196721311475,
        "end": 4600.6,
        "id": 1406,
        "no_speech_prob": 0.0000033405324302293593,
        "seek": 457360,
        "start": 4599.6,
        "temperature": 0,
        "text": " But this is what I'm going to do.",
        "tokens": [
          51664,
          583,
          341,
          307,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4603.6,
        "id": 1407,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4600.6,
        "temperature": 0,
        "text": " So let's go and do that.",
        "tokens": [
          50364,
          407,
          718,
          311,
          352,
          293,
          360,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4609.6,
        "id": 1408,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4606.6,
        "temperature": 0,
        "text": " I look forward to hearing from everybody later about how I'm not doing this correctly.",
        "tokens": [
          50664,
          286,
          574,
          2128,
          281,
          4763,
          490,
          2201,
          1780,
          466,
          577,
          286,
          478,
          406,
          884,
          341,
          8944,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4613.6,
        "id": 1409,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4610.6,
        "temperature": 0,
        "text": " I'm going to say function graph.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          584,
          2445,
          4295,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4618.6,
        "id": 1410,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4613.6,
        "temperature": 0,
        "text": " This.nodes is an array and this.graph is an object.",
        "tokens": [
          51014,
          639,
          13,
          77,
          4789,
          307,
          364,
          10225,
          293,
          341,
          13,
          34091,
          307,
          364,
          2657,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4619.6,
        "id": 1411,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4618.6,
        "temperature": 0,
        "text": " An empty object.",
        "tokens": [
          51264,
          1107,
          6707,
          2657,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4620.6,
        "id": 1412,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4619.6,
        "temperature": 0,
        "text": " So if you're...",
        "tokens": [
          51314,
          407,
          498,
          291,
          434,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4623.6,
        "id": 1413,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4620.6,
        "temperature": 0,
        "text": " I'm going to use this object essentially as an associative array or a hash table.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          764,
          341,
          2657,
          4476,
          382,
          364,
          4180,
          1166,
          10225,
          420,
          257,
          22019,
          3199,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4624.6,
        "id": 1414,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4623.6,
        "temperature": 0,
        "text": " And I have a video about that if you're interested.",
        "tokens": [
          51514,
          400,
          286,
          362,
          257,
          960,
          466,
          300,
          498,
          291,
          434,
          3102,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4625.6,
        "id": 1415,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4624.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4627.6,
        "id": 1416,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4625.6,
        "temperature": 0,
        "text": " Now I need to read the data.",
        "tokens": [
          51614,
          823,
          286,
          643,
          281,
          1401,
          264,
          1412,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18244326664851263,
        "compression_ratio": 1.7058823529411764,
        "end": 4628.6,
        "id": 1417,
        "no_speech_prob": 0.005819815210998058,
        "seek": 460060,
        "start": 4627.6,
        "temperature": 0,
        "text": " That's the first thing I need to do.",
        "tokens": [
          51714,
          663,
          311,
          264,
          700,
          551,
          286,
          643,
          281,
          360,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4633.6,
        "id": 1418,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4630.6,
        "temperature": 0,
        "text": " So I'm going to use p5 as a function called preload.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          764,
          280,
          20,
          382,
          257,
          2445,
          1219,
          659,
          2907,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4635.6,
        "id": 1419,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4633.6,
        "temperature": 0,
        "text": " Which I can use to...",
        "tokens": [
          50514,
          3013,
          286,
          393,
          764,
          281,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4637.6,
        "id": 1420,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4635.6,
        "temperature": 0,
        "text": " I'm just going to say var data.",
        "tokens": [
          50614,
          286,
          478,
          445,
          516,
          281,
          584,
          1374,
          1412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4640.6,
        "id": 1421,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4638.6,
        "temperature": 0,
        "text": " And then I'm going to say data equals...",
        "tokens": [
          50764,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          1412,
          6915,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4642.6,
        "id": 1422,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4640.6,
        "temperature": 0,
        "text": " And this is a p5 function called loadJSON.",
        "tokens": [
          50864,
          400,
          341,
          307,
          257,
          280,
          20,
          2445,
          1219,
          3677,
          41,
          10388,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4647.6,
        "id": 1423,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4642.6,
        "temperature": 0,
        "text": " Where I can just pass in the name of my JSON file which is kevinbacon.json.",
        "tokens": [
          50964,
          2305,
          286,
          393,
          445,
          1320,
          294,
          264,
          1315,
          295,
          452,
          31828,
          3991,
          597,
          307,
          803,
          4796,
          65,
          18181,
          13,
          73,
          3015,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4651.6,
        "id": 1424,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4649.6,
        "temperature": 0,
        "text": " Kevinbacon.json.",
        "tokens": [
          51314,
          9954,
          65,
          18181,
          13,
          73,
          3015,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4652.6,
        "id": 1425,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4651.6,
        "temperature": 0,
        "text": " JSON.",
        "tokens": [
          51414,
          31828,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4653.6,
        "id": 1426,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4652.6,
        "temperature": 0,
        "text": " JSON.",
        "tokens": [
          51464,
          31828,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4654.6,
        "id": 1427,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4653.6,
        "temperature": 0,
        "text": " Ah! What is it?",
        "tokens": [
          51514,
          2438,
          0,
          708,
          307,
          309,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4655.6,
        "id": 1428,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4654.6,
        "temperature": 0,
        "text": " Somebody will tell me.",
        "tokens": [
          51564,
          13463,
          486,
          980,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20217139380318777,
        "compression_ratio": 1.675,
        "end": 4658.6,
        "id": 1429,
        "no_speech_prob": 0.0005614717374555767,
        "seek": 463060,
        "start": 4655.6,
        "temperature": 0,
        "text": " I'm pretty sure from the comments that it's gif though and not jif.",
        "tokens": [
          51614,
          286,
          478,
          1238,
          988,
          490,
          264,
          3053,
          300,
          309,
          311,
          290,
          351,
          1673,
          293,
          406,
          361,
          351,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4660.6,
        "id": 1430,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4658.6,
        "temperature": 0,
        "text": " I've been told that many a time.",
        "tokens": [
          50364,
          286,
          600,
          668,
          1907,
          300,
          867,
          257,
          565,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4661.6,
        "id": 1431,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4660.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4662.6,
        "id": 1432,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4661.6,
        "temperature": 0,
        "text": " So now I'm just going to...",
        "tokens": [
          50514,
          407,
          586,
          286,
          478,
          445,
          516,
          281,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4663.6,
        "id": 1433,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4662.6,
        "temperature": 0,
        "text": " In setup I'm going to say no canvas.",
        "tokens": [
          50564,
          682,
          8657,
          286,
          478,
          516,
          281,
          584,
          572,
          16267,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4665.6,
        "id": 1434,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4663.6,
        "temperature": 0,
        "text": " p5 makes a canvas by default but I don't need it.",
        "tokens": [
          50614,
          280,
          20,
          1669,
          257,
          16267,
          538,
          7576,
          457,
          286,
          500,
          380,
          643,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4667.6,
        "id": 1435,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4665.6,
        "temperature": 0,
        "text": " And then I'm going to console.log the data.",
        "tokens": [
          50714,
          400,
          550,
          286,
          478,
          516,
          281,
          11076,
          13,
          4987,
          264,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4669.6,
        "id": 1436,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4667.6,
        "temperature": 0,
        "text": " So let's just make sure the data is there.",
        "tokens": [
          50814,
          407,
          718,
          311,
          445,
          652,
          988,
          264,
          1412,
          307,
          456,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4671.6,
        "id": 1437,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4670.6,
        "temperature": 0,
        "text": " And we can see there it is.",
        "tokens": [
          50964,
          400,
          321,
          393,
          536,
          456,
          309,
          307,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4672.6,
        "id": 1438,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4671.6,
        "temperature": 0,
        "text": " So the data came in.",
        "tokens": [
          51014,
          407,
          264,
          1412,
          1361,
          294,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4675.6,
        "id": 1439,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4672.6,
        "temperature": 0,
        "text": " I have an object which has an array called movies.",
        "tokens": [
          51064,
          286,
          362,
          364,
          2657,
          597,
          575,
          364,
          10225,
          1219,
          6233,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4679.6,
        "id": 1440,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4675.6,
        "temperature": 0,
        "text": " And each movie has a property called cast which is an array of all the actors.",
        "tokens": [
          51214,
          400,
          1184,
          3169,
          575,
          257,
          4707,
          1219,
          4193,
          597,
          307,
          364,
          10225,
          295,
          439,
          264,
          10037,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4681.6,
        "id": 1441,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4679.6,
        "temperature": 0,
        "text": " So that's great.",
        "tokens": [
          51414,
          407,
          300,
          311,
          869,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15903317706185097,
        "compression_ratio": 1.8469750889679715,
        "end": 4687.6,
        "id": 1442,
        "no_speech_prob": 0.00012931473611388355,
        "seek": 465860,
        "start": 4681.6,
        "temperature": 0,
        "text": " So now what I need to do is I need to make a node for every movie and every actor.",
        "tokens": [
          51514,
          407,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          652,
          257,
          9984,
          337,
          633,
          3169,
          293,
          633,
          8747,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4689.6,
        "id": 1443,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4688.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4692.6,
        "id": 1444,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4689.6,
        "temperature": 0,
        "text": " So I want to be able to parse through and read this list.",
        "tokens": [
          50414,
          407,
          286,
          528,
          281,
          312,
          1075,
          281,
          48377,
          807,
          293,
          1401,
          341,
          1329,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4695.6,
        "id": 1445,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4692.6,
        "temperature": 0,
        "text": " So the object has movies.",
        "tokens": [
          50564,
          407,
          264,
          2657,
          575,
          6233,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4699.6,
        "id": 1446,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4695.6,
        "temperature": 0,
        "text": " So I'm going to say var movies equals data.movies.",
        "tokens": [
          50714,
          407,
          286,
          478,
          516,
          281,
          584,
          1374,
          6233,
          6915,
          1412,
          13,
          3280,
          85,
          530,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4703.6,
        "id": 1447,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4699.6,
        "temperature": 0,
        "text": " Then I'm going to loop over all the movies in that JSON file.",
        "tokens": [
          50914,
          1396,
          286,
          478,
          516,
          281,
          6367,
          670,
          439,
          264,
          6233,
          294,
          300,
          31828,
          3991,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4707.6,
        "id": 1448,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4705.6,
        "temperature": 0,
        "text": " I'm really not on to breadth-first search yet.",
        "tokens": [
          51214,
          286,
          478,
          534,
          406,
          322,
          281,
          35862,
          12,
          29581,
          3164,
          1939,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4709.6,
        "id": 1449,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4707.6,
        "temperature": 0,
        "text": " I'm just kind of gathering the data.",
        "tokens": [
          51314,
          286,
          478,
          445,
          733,
          295,
          13519,
          264,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4711.6,
        "id": 1450,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4709.6,
        "temperature": 0,
        "text": " And I'm going to get...",
        "tokens": [
          51414,
          400,
          286,
          478,
          516,
          281,
          483,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4714.6,
        "id": 1451,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4711.6,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going to get the movie equals...",
        "tokens": [
          51514,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          483,
          264,
          3169,
          6915,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4715.6,
        "id": 1452,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4714.6,
        "temperature": 0,
        "text": " And what was the movie?",
        "tokens": [
          51664,
          400,
          437,
          390,
          264,
          3169,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.1448814728680779,
        "compression_ratio": 1.8504273504273505,
        "end": 4717.6,
        "id": 1453,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 468860,
        "start": 4715.6,
        "temperature": 0,
        "text": " The movie has a cast and a title.",
        "tokens": [
          51714,
          440,
          3169,
          575,
          257,
          4193,
          293,
          257,
          4876,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4719.6,
        "id": 1454,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4717.6,
        "temperature": 0,
        "text": " So the title is also a node.",
        "tokens": [
          50364,
          407,
          264,
          4876,
          307,
          611,
          257,
          9984,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4720.6,
        "id": 1455,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4719.6,
        "temperature": 0,
        "text": " So I want the movie...",
        "tokens": [
          50464,
          407,
          286,
          528,
          264,
          3169,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4722.6,
        "id": 1456,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4720.6,
        "temperature": 0,
        "text": " Movies index i.title.",
        "tokens": [
          50514,
          43756,
          530,
          8186,
          741,
          13,
          27689,
          306,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4726.6,
        "id": 1457,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4722.6,
        "temperature": 0,
        "text": " And cast equals movies index i.cast.",
        "tokens": [
          50614,
          400,
          4193,
          6915,
          6233,
          8186,
          741,
          13,
          3734,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4728.6,
        "id": 1458,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4726.6,
        "temperature": 0,
        "text": " So first I need to make a node.",
        "tokens": [
          50814,
          407,
          700,
          286,
          643,
          281,
          652,
          257,
          9984,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4738.6,
        "id": 1459,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4730.6,
        "temperature": 0,
        "text": " var n equals a new node movies index i.title.",
        "tokens": [
          51014,
          1374,
          297,
          6915,
          257,
          777,
          9984,
          6233,
          8186,
          741,
          13,
          27689,
          306,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4739.6,
        "id": 1460,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4738.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4740.6,
        "id": 1461,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4739.6,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          51464,
          407,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4741.6,
        "id": 1462,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4740.6,
        "temperature": 0,
        "text": " Oh, actually I don't need to say that again.",
        "tokens": [
          51514,
          876,
          11,
          767,
          286,
          500,
          380,
          643,
          281,
          584,
          300,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4742.6,
        "id": 1463,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4741.6,
        "temperature": 0,
        "text": " Movie.",
        "tokens": [
          51564,
          28766,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1939974197974572,
        "compression_ratio": 1.7530864197530864,
        "end": 4744.6,
        "id": 1464,
        "no_speech_prob": 0.0001293154782615602,
        "seek": 471760,
        "start": 4742.6,
        "temperature": 0,
        "text": " So I need to make a movie node.",
        "tokens": [
          51614,
          407,
          286,
          643,
          281,
          652,
          257,
          3169,
          9984,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4748.6,
        "id": 1465,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4744.6,
        "temperature": 0,
        "text": " And then what I want to do in the graph is I want to say...",
        "tokens": [
          50364,
          400,
          550,
          437,
          286,
          528,
          281,
          360,
          294,
          264,
          4295,
          307,
          286,
          528,
          281,
          584,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4751.6,
        "id": 1466,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4748.6,
        "temperature": 0,
        "text": " Oh, I want to say I'm going to make a graph object.",
        "tokens": [
          50564,
          876,
          11,
          286,
          528,
          281,
          584,
          286,
          478,
          516,
          281,
          652,
          257,
          4295,
          2657,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4752.6,
        "id": 1467,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4751.6,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          50714,
          400,
          550,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4755.6,
        "id": 1468,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4752.6,
        "temperature": 0,
        "text": " Right, the graph object is the thing that's going to keep track of all the nodes.",
        "tokens": [
          50764,
          1779,
          11,
          264,
          4295,
          2657,
          307,
          264,
          551,
          300,
          311,
          516,
          281,
          1066,
          2837,
          295,
          439,
          264,
          13891,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4757.6,
        "id": 1469,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4755.6,
        "temperature": 0,
        "text": " So I need to say at the beginning...",
        "tokens": [
          50914,
          407,
          286,
          643,
          281,
          584,
          412,
          264,
          2863,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4760.6,
        "id": 1470,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4758.6,
        "temperature": 0,
        "text": " Graph equals new graph.",
        "tokens": [
          51064,
          21884,
          6915,
          777,
          4295,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4764.6,
        "id": 1471,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4760.6,
        "temperature": 0,
        "text": " And then what I would like to do is add this node to the graph.",
        "tokens": [
          51164,
          400,
          550,
          437,
          286,
          576,
          411,
          281,
          360,
          307,
          909,
          341,
          9984,
          281,
          264,
          4295,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2109495593655494,
        "compression_ratio": 1.8849557522123894,
        "end": 4770.6,
        "id": 1472,
        "no_speech_prob": 0.00009314590715803206,
        "seek": 474460,
        "start": 4764.6,
        "temperature": 0,
        "text": " So I want to take this node object, whose value is a particular movie, and add it to the graph.",
        "tokens": [
          51364,
          407,
          286,
          528,
          281,
          747,
          341,
          9984,
          2657,
          11,
          6104,
          2158,
          307,
          257,
          1729,
          3169,
          11,
          293,
          909,
          309,
          281,
          264,
          4295,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4775.6,
        "id": 1473,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4771.6,
        "temperature": 0,
        "text": " graph.addNodeN.",
        "tokens": [
          50414,
          4295,
          13,
          25224,
          45,
          1429,
          45,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4778.6,
        "id": 1474,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4775.6,
        "temperature": 0,
        "text": " Now, can I just do this and get this to run?",
        "tokens": [
          50614,
          823,
          11,
          393,
          286,
          445,
          360,
          341,
          293,
          483,
          341,
          281,
          1190,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4779.6,
        "id": 1475,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4778.6,
        "temperature": 0,
        "text": " Ta-da!",
        "tokens": [
          50764,
          6551,
          12,
          2675,
          0,
          50814
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4780.6,
        "id": 1476,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4779.6,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50814,
          883,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4781.6,
        "id": 1477,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4780.6,
        "temperature": 0,
        "text": " Graph is not defined.",
        "tokens": [
          50864,
          21884,
          307,
          406,
          7642,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4783.6,
        "id": 1478,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4781.6,
        "temperature": 0,
        "text": " Okay, so first of all I forgot a bunch of things.",
        "tokens": [
          50914,
          1033,
          11,
          370,
          700,
          295,
          439,
          286,
          5298,
          257,
          3840,
          295,
          721,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4791.6,
        "id": 1479,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4783.6,
        "temperature": 0,
        "text": " One is I forgot I need to add a reference to my node object JavaScript file and the graph object JavaScript file.",
        "tokens": [
          51014,
          1485,
          307,
          286,
          5298,
          286,
          643,
          281,
          909,
          257,
          6408,
          281,
          452,
          9984,
          2657,
          15778,
          3991,
          293,
          264,
          4295,
          2657,
          15778,
          3991,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4793.6,
        "id": 1480,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4791.6,
        "temperature": 0,
        "text": " So that's one problem.",
        "tokens": [
          51414,
          407,
          300,
          311,
          472,
          1154,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4795.6,
        "id": 1481,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4793.6,
        "temperature": 0,
        "text": " Number two, addNode is not a function.",
        "tokens": [
          51514,
          5118,
          732,
          11,
          909,
          45,
          1429,
          307,
          406,
          257,
          2445,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4796.6,
        "id": 1482,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4795.6,
        "temperature": 0,
        "text": " This doesn't just exist.",
        "tokens": [
          51614,
          639,
          1177,
          380,
          445,
          2514,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1667960689913842,
        "compression_ratio": 1.646551724137931,
        "end": 4798.6,
        "id": 1483,
        "no_speech_prob": 0.00022693346545565873,
        "seek": 477060,
        "start": 4796.6,
        "temperature": 0,
        "text": " It's a function that I need to write.",
        "tokens": [
          51664,
          467,
          311,
          257,
          2445,
          300,
          286,
          643,
          281,
          2464,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19063695889074825,
        "compression_ratio": 1.5922330097087378,
        "end": 4803.6,
        "id": 1484,
        "no_speech_prob": 0.0007321800803765655,
        "seek": 479860,
        "start": 4798.6,
        "temperature": 0,
        "text": " So I'm going to attach a method to the graph object using the prototype.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          5085,
          257,
          3170,
          281,
          264,
          4295,
          2657,
          1228,
          264,
          19475,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19063695889074825,
        "compression_ratio": 1.5922330097087378,
        "end": 4806.6,
        "id": 1485,
        "no_speech_prob": 0.0007321800803765655,
        "seek": 479860,
        "start": 4803.6,
        "temperature": 0,
        "text": " I have a video about what prototype is, if that's not familiar to you.",
        "tokens": [
          50614,
          286,
          362,
          257,
          960,
          466,
          437,
          19475,
          307,
          11,
          498,
          300,
          311,
          406,
          4963,
          281,
          291,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19063695889074825,
        "compression_ratio": 1.5922330097087378,
        "end": 4812.6,
        "id": 1486,
        "no_speech_prob": 0.0007321800803765655,
        "seek": 479860,
        "start": 4806.6,
        "temperature": 0,
        "text": " graph.prototype.addNode equals function.",
        "tokens": [
          50764,
          4295,
          13,
          33629,
          13108,
          13,
          25224,
          45,
          1429,
          6915,
          2445,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19063695889074825,
        "compression_ratio": 1.5922330097087378,
        "end": 4815.6,
        "id": 1487,
        "no_speech_prob": 0.0007321800803765655,
        "seek": 479860,
        "start": 4812.6,
        "temperature": 0,
        "text": " Okay, now what comes in a node?",
        "tokens": [
          51064,
          1033,
          11,
          586,
          437,
          1487,
          294,
          257,
          9984,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.19063695889074825,
        "compression_ratio": 1.5922330097087378,
        "end": 4817.6,
        "id": 1488,
        "no_speech_prob": 0.0007321800803765655,
        "seek": 479860,
        "start": 4815.6,
        "temperature": 0,
        "text": " So what do I want to do?",
        "tokens": [
          51214,
          407,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.19063695889074825,
        "compression_ratio": 1.5922330097087378,
        "end": 4820.6,
        "id": 1489,
        "no_speech_prob": 0.0007321800803765655,
        "seek": 479860,
        "start": 4817.6,
        "temperature": 0,
        "text": " Okay, so I need first a couple things.",
        "tokens": [
          51314,
          1033,
          11,
          370,
          286,
          643,
          700,
          257,
          1916,
          721,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19063695889074825,
        "compression_ratio": 1.5922330097087378,
        "end": 4824.6,
        "id": 1490,
        "no_speech_prob": 0.0007321800803765655,
        "seek": 479860,
        "start": 4820.6,
        "temperature": 0,
        "text": " One is I want to say this.nodes.push that node.",
        "tokens": [
          51464,
          1485,
          307,
          286,
          528,
          281,
          584,
          341,
          13,
          77,
          4789,
          13,
          79,
          1498,
          300,
          9984,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1807796574440323,
        "compression_ratio": 1.7842323651452283,
        "end": 4828.6,
        "id": 1491,
        "no_speech_prob": 0.0015011756913736463,
        "seek": 482460,
        "start": 4824.6,
        "temperature": 0,
        "text": " So any node that comes in I want to put it in the array because I want to store all the nodes in an array.",
        "tokens": [
          50364,
          407,
          604,
          9984,
          300,
          1487,
          294,
          286,
          528,
          281,
          829,
          309,
          294,
          264,
          10225,
          570,
          286,
          528,
          281,
          3531,
          439,
          264,
          13891,
          294,
          364,
          10225,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1807796574440323,
        "compression_ratio": 1.7842323651452283,
        "end": 4831.6,
        "id": 1492,
        "no_speech_prob": 0.0015011756913736463,
        "seek": 482460,
        "start": 4828.6,
        "temperature": 0,
        "text": " Which might be unnecessary, but I'm doing that as a safety mechanism.",
        "tokens": [
          50564,
          3013,
          1062,
          312,
          19350,
          11,
          457,
          286,
          478,
          884,
          300,
          382,
          257,
          4514,
          7513,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1807796574440323,
        "compression_ratio": 1.7842323651452283,
        "end": 4837.6,
        "id": 1493,
        "no_speech_prob": 0.0015011756913736463,
        "seek": 482460,
        "start": 4831.6,
        "temperature": 0,
        "text": " Then I also want to have a lookup of the node based on the name.",
        "tokens": [
          50714,
          1396,
          286,
          611,
          528,
          281,
          362,
          257,
          574,
          1010,
          295,
          264,
          9984,
          2361,
          322,
          264,
          1315,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1807796574440323,
        "compression_ratio": 1.7842323651452283,
        "end": 4841.6,
        "id": 1494,
        "no_speech_prob": 0.0015011756913736463,
        "seek": 482460,
        "start": 4837.6,
        "temperature": 0,
        "text": " So the movie name needs to be the key for that node object.",
        "tokens": [
          51014,
          407,
          264,
          3169,
          1315,
          2203,
          281,
          312,
          264,
          2141,
          337,
          300,
          9984,
          2657,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1807796574440323,
        "compression_ratio": 1.7842323651452283,
        "end": 4848.6,
        "id": 1495,
        "no_speech_prob": 0.0015011756913736463,
        "seek": 482460,
        "start": 4841.6,
        "temperature": 0,
        "text": " So this is going to look a little bit weird, but I'm going to say title equals n.value.",
        "tokens": [
          51214,
          407,
          341,
          307,
          516,
          281,
          574,
          257,
          707,
          857,
          3657,
          11,
          457,
          286,
          478,
          516,
          281,
          584,
          4876,
          6915,
          297,
          13,
          29155,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1807796574440323,
        "compression_ratio": 1.7842323651452283,
        "end": 4851.6,
        "id": 1496,
        "no_speech_prob": 0.0015011756913736463,
        "seek": 482460,
        "start": 4848.6,
        "temperature": 0,
        "text": " The title is stored in the node's value.",
        "tokens": [
          51564,
          440,
          4876,
          307,
          12187,
          294,
          264,
          9984,
          311,
          2158,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2385949655012651,
        "compression_ratio": 1.547872340425532,
        "end": 4858.6,
        "id": 1497,
        "no_speech_prob": 0.0066927834413945675,
        "seek": 485160,
        "start": 4851.6,
        "temperature": 0,
        "text": " Then I'm going to say this.graph index that title equals that node.",
        "tokens": [
          50364,
          1396,
          286,
          478,
          516,
          281,
          584,
          341,
          13,
          34091,
          8186,
          300,
          4876,
          6915,
          300,
          9984,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2385949655012651,
        "compression_ratio": 1.547872340425532,
        "end": 4867.6,
        "id": 1498,
        "no_speech_prob": 0.0066927834413945675,
        "seek": 485160,
        "start": 4858.6,
        "temperature": 0,
        "text": " So this is me putting node into array and node into...",
        "tokens": [
          50714,
          407,
          341,
          307,
          385,
          3372,
          9984,
          666,
          10225,
          293,
          9984,
          666,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2385949655012651,
        "compression_ratio": 1.547872340425532,
        "end": 4871.6,
        "id": 1499,
        "no_speech_prob": 0.0066927834413945675,
        "seek": 485160,
        "start": 4867.6,
        "temperature": 0,
        "text": " It's not really a hash table because it's JavaScript, but I'm thinking of it as like a hash table.",
        "tokens": [
          51164,
          467,
          311,
          406,
          534,
          257,
          22019,
          3199,
          570,
          309,
          311,
          15778,
          11,
          457,
          286,
          478,
          1953,
          295,
          309,
          382,
          411,
          257,
          22019,
          3199,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2385949655012651,
        "compression_ratio": 1.547872340425532,
        "end": 4873.6,
        "id": 1500,
        "no_speech_prob": 0.0066927834413945675,
        "seek": 485160,
        "start": 4871.6,
        "temperature": 0,
        "text": " Okay, so that's good.",
        "tokens": [
          51364,
          1033,
          11,
          370,
          300,
          311,
          665,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2385949655012651,
        "compression_ratio": 1.547872340425532,
        "end": 4878.6,
        "id": 1501,
        "no_speech_prob": 0.0066927834413945675,
        "seek": 485160,
        "start": 4873.6,
        "temperature": 0,
        "text": " I've got the...",
        "tokens": [
          51464,
          286,
          600,
          658,
          264,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.2385949655012651,
        "compression_ratio": 1.547872340425532,
        "end": 4880.6,
        "id": 1502,
        "no_speech_prob": 0.0066927834413945675,
        "seek": 485160,
        "start": 4878.6,
        "temperature": 0,
        "text": " I've got the... what do I have?",
        "tokens": [
          51714,
          286,
          600,
          658,
          264,
          485,
          437,
          360,
          286,
          362,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.20991863638667738,
        "compression_ratio": 1.6798245614035088,
        "end": 4883.6,
        "id": 1503,
        "no_speech_prob": 0.008061855100095272,
        "seek": 488060,
        "start": 4880.6,
        "temperature": 0,
        "text": " The movies. Okay, let's now add the actors.",
        "tokens": [
          50364,
          440,
          6233,
          13,
          1033,
          11,
          718,
          311,
          586,
          909,
          264,
          10037,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20991863638667738,
        "compression_ratio": 1.6798245614035088,
        "end": 4887.6,
        "id": 1504,
        "no_speech_prob": 0.008061855100095272,
        "seek": 488060,
        "start": 4883.6,
        "temperature": 0,
        "text": " What I'm going to do in this first part is I'm going to add all the data and get the graph set up.",
        "tokens": [
          50514,
          708,
          286,
          478,
          516,
          281,
          360,
          294,
          341,
          700,
          644,
          307,
          286,
          478,
          516,
          281,
          909,
          439,
          264,
          1412,
          293,
          483,
          264,
          4295,
          992,
          493,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20991863638667738,
        "compression_ratio": 1.6798245614035088,
        "end": 4892.6,
        "id": 1505,
        "no_speech_prob": 0.008061855100095272,
        "seek": 488060,
        "start": 4887.6,
        "temperature": 0,
        "text": " Then I'll take a break and there'll be a second part to this video which will be the actual implement the algorithm.",
        "tokens": [
          50714,
          1396,
          286,
          603,
          747,
          257,
          1821,
          293,
          456,
          603,
          312,
          257,
          1150,
          644,
          281,
          341,
          960,
          597,
          486,
          312,
          264,
          3539,
          4445,
          264,
          9284,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20991863638667738,
        "compression_ratio": 1.6798245614035088,
        "end": 4894.6,
        "id": 1506,
        "no_speech_prob": 0.008061855100095272,
        "seek": 488060,
        "start": 4892.6,
        "temperature": 0,
        "text": " So now the cast.",
        "tokens": [
          50964,
          407,
          586,
          264,
          4193,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20991863638667738,
        "compression_ratio": 1.6798245614035088,
        "end": 4898.6,
        "id": 1507,
        "no_speech_prob": 0.008061855100095272,
        "seek": 488060,
        "start": 4894.6,
        "temperature": 0,
        "text": " I need another loop. I can't use i, so I'm going to use j.",
        "tokens": [
          51064,
          286,
          643,
          1071,
          6367,
          13,
          286,
          393,
          380,
          764,
          741,
          11,
          370,
          286,
          478,
          516,
          281,
          764,
          361,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20991863638667738,
        "compression_ratio": 1.6798245614035088,
        "end": 4902.6,
        "id": 1508,
        "no_speech_prob": 0.008061855100095272,
        "seek": 488060,
        "start": 4898.6,
        "temperature": 0,
        "text": " The cast.length j++.",
        "tokens": [
          51264,
          440,
          4193,
          13,
          45390,
          361,
          25472,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20991863638667738,
        "compression_ratio": 1.6798245614035088,
        "end": 4904.6,
        "id": 1509,
        "no_speech_prob": 0.008061855100095272,
        "seek": 488060,
        "start": 4902.6,
        "temperature": 0,
        "text": " Now I need to make a node.",
        "tokens": [
          51464,
          823,
          286,
          643,
          281,
          652,
          257,
          9984,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4909.6,
        "id": 1510,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4904.6,
        "temperature": 0,
        "text": " I'll call this actor equals cast...",
        "tokens": [
          50364,
          286,
          603,
          818,
          341,
          8747,
          6915,
          4193,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4910.6,
        "id": 1511,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4909.6,
        "temperature": 0,
        "text": " I'm not calling... sorry.",
        "tokens": [
          50614,
          286,
          478,
          406,
          5141,
          485,
          2597,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4912.6,
        "id": 1512,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4910.6,
        "temperature": 0,
        "text": " Cast index i...",
        "tokens": [
          50664,
          11019,
          8186,
          741,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4914.6,
        "id": 1513,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4912.6,
        "temperature": 0,
        "text": " Yeah, the strings are just there in the array.",
        "tokens": [
          50764,
          865,
          11,
          264,
          13985,
          366,
          445,
          456,
          294,
          264,
          10225,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4920.6,
        "id": 1514,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4914.6,
        "temperature": 0,
        "text": " Let me just console.log everything to make sure I'm getting all the...",
        "tokens": [
          50864,
          961,
          385,
          445,
          11076,
          13,
          4987,
          1203,
          281,
          652,
          988,
          286,
          478,
          1242,
          439,
          264,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4922.6,
        "id": 1515,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4920.6,
        "temperature": 0,
        "text": " That's correct what I'm thinking here.",
        "tokens": [
          51164,
          663,
          311,
          3006,
          437,
          286,
          478,
          1953,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4924.6,
        "id": 1516,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4922.6,
        "temperature": 0,
        "text": " Okay, so we can see that...",
        "tokens": [
          51264,
          1033,
          11,
          370,
          321,
          393,
          536,
          300,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4926.6,
        "id": 1517,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4924.6,
        "temperature": 0,
        "text": " Oops, I used index i.",
        "tokens": [
          51364,
          21726,
          11,
          286,
          1143,
          8186,
          741,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4930.6,
        "id": 1518,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4926.6,
        "temperature": 0,
        "text": " I'm like, why is it Steve Guttenberg 14 times?",
        "tokens": [
          51464,
          286,
          478,
          411,
          11,
          983,
          307,
          309,
          7466,
          24481,
          1147,
          6873,
          3499,
          1413,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2198045950020309,
        "compression_ratio": 1.5084033613445378,
        "end": 4932.6,
        "id": 1519,
        "no_speech_prob": 0.1602533757686615,
        "seek": 490460,
        "start": 4930.6,
        "temperature": 0,
        "text": " Because this needs to be j.",
        "tokens": [
          51664,
          1436,
          341,
          2203,
          281,
          312,
          361,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.255026047488293,
        "compression_ratio": 1.6571428571428573,
        "end": 4938.6,
        "id": 1520,
        "no_speech_prob": 0.01542435958981514,
        "seek": 493260,
        "start": 4933.6,
        "temperature": 0,
        "text": " Okay, so now you can see that's me iterating over all the movies and the actors.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          586,
          291,
          393,
          536,
          300,
          311,
          385,
          17138,
          990,
          670,
          439,
          264,
          6233,
          293,
          264,
          10037,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.255026047488293,
        "compression_ratio": 1.6571428571428573,
        "end": 4952.6,
        "id": 1521,
        "no_speech_prob": 0.01542435958981514,
        "seek": 493260,
        "start": 4938.6,
        "temperature": 0,
        "text": " So now what I need to do is I need to say var actorNode equals a new node with that actor name and then graph addNode actorNode.",
        "tokens": [
          50664,
          407,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          584,
          1374,
          8747,
          45,
          1429,
          6915,
          257,
          777,
          9984,
          365,
          300,
          8747,
          1315,
          293,
          550,
          4295,
          909,
          45,
          1429,
          8747,
          45,
          1429,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.255026047488293,
        "compression_ratio": 1.6571428571428573,
        "end": 4956.6,
        "id": 1522,
        "no_speech_prob": 0.01542435958981514,
        "seek": 493260,
        "start": 4952.6,
        "temperature": 0,
        "text": " So just like for every movie, add the movie, then add all the actors.",
        "tokens": [
          51364,
          407,
          445,
          411,
          337,
          633,
          3169,
          11,
          909,
          264,
          3169,
          11,
          550,
          909,
          439,
          264,
          10037,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.255026047488293,
        "compression_ratio": 1.6571428571428573,
        "end": 4957.6,
        "id": 1523,
        "no_speech_prob": 0.01542435958981514,
        "seek": 493260,
        "start": 4956.6,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          51564,
          22768,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4965.6,
        "id": 1524,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4957.6,
        "temperature": 0,
        "text": " Okay, so now let's also at the end of setup now, let's say console.log graph.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          586,
          718,
          311,
          611,
          412,
          264,
          917,
          295,
          8657,
          586,
          11,
          718,
          311,
          584,
          11076,
          13,
          4987,
          4295,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4967.6,
        "id": 1525,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4965.6,
        "temperature": 0,
        "text": " Just so we can look at what's in there.",
        "tokens": [
          50764,
          1449,
          370,
          321,
          393,
          574,
          412,
          437,
          311,
          294,
          456,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4970.6,
        "id": 1526,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4967.6,
        "temperature": 0,
        "text": " And I don't need to console.log the data anymore.",
        "tokens": [
          50864,
          400,
          286,
          500,
          380,
          643,
          281,
          11076,
          13,
          4987,
          264,
          1412,
          3602,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4972.6,
        "id": 1527,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4970.6,
        "temperature": 0,
        "text": " I feel confident about that.",
        "tokens": [
          51014,
          286,
          841,
          6679,
          466,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4976.6,
        "id": 1528,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4972.6,
        "temperature": 0,
        "text": " So, oops, and I don't need to console.log the actors anymore.",
        "tokens": [
          51114,
          407,
          11,
          34166,
          11,
          293,
          286,
          500,
          380,
          643,
          281,
          11076,
          13,
          4987,
          264,
          10037,
          3602,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4978.6,
        "id": 1529,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4976.6,
        "temperature": 0,
        "text": " So let me go here.",
        "tokens": [
          51314,
          407,
          718,
          385,
          352,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4979.6,
        "id": 1530,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4978.6,
        "temperature": 0,
        "text": " So this is the graph.",
        "tokens": [
          51414,
          407,
          341,
          307,
          264,
          4295,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4980.6,
        "id": 1531,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4979.6,
        "temperature": 0,
        "text": " You can see it's an array.",
        "tokens": [
          51464,
          509,
          393,
          536,
          309,
          311,
          364,
          10225,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18600880897651284,
        "compression_ratio": 1.7163461538461537,
        "end": 4982.6,
        "id": 1532,
        "no_speech_prob": 0.1384572982788086,
        "seek": 495760,
        "start": 4980.6,
        "temperature": 0,
        "text": " It's got an array of 74 nodes.",
        "tokens": [
          51514,
          467,
          311,
          658,
          364,
          10225,
          295,
          28868,
          13891,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 4988.6,
        "id": 1533,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 4982.6,
        "temperature": 0,
        "text": " It's also got a whole bunch of objects, which all have the actor name or the movie name as the lookup.",
        "tokens": [
          50364,
          467,
          311,
          611,
          658,
          257,
          1379,
          3840,
          295,
          6565,
          11,
          597,
          439,
          362,
          264,
          8747,
          1315,
          420,
          264,
          3169,
          1315,
          382,
          264,
          574,
          1010,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 4989.6,
        "id": 1534,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 4988.6,
        "temperature": 0,
        "text": " So this is good.",
        "tokens": [
          50664,
          407,
          341,
          307,
          665,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 4990.6,
        "id": 1535,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 4989.6,
        "temperature": 0,
        "text": " I'm kind of almost there.",
        "tokens": [
          50714,
          286,
          478,
          733,
          295,
          1920,
          456,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 4992.6,
        "id": 1536,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 4990.6,
        "temperature": 0,
        "text": " Like, what do I have so far?",
        "tokens": [
          50764,
          1743,
          11,
          437,
          360,
          286,
          362,
          370,
          1400,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 4996.6,
        "id": 1537,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 4992.6,
        "temperature": 0,
        "text": " I have a graph object, which stores all of these nodes.",
        "tokens": [
          50864,
          286,
          362,
          257,
          4295,
          2657,
          11,
          597,
          9512,
          439,
          295,
          613,
          13891,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 4998.6,
        "id": 1538,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 4996.6,
        "temperature": 0,
        "text": " Only it looks like this.",
        "tokens": [
          51064,
          5686,
          309,
          1542,
          411,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 5000.6,
        "id": 1539,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 4998.6,
        "temperature": 0,
        "text": " I haven't done any of the edges.",
        "tokens": [
          51164,
          286,
          2378,
          380,
          1096,
          604,
          295,
          264,
          8819,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 5002.6,
        "id": 1540,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 5000.6,
        "temperature": 0,
        "text": " So what do I need to do?",
        "tokens": [
          51264,
          407,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 5007.6,
        "id": 1541,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 5002.6,
        "temperature": 0,
        "text": " Every movie needs to be connected to every actor that's in that movie.",
        "tokens": [
          51364,
          2048,
          3169,
          2203,
          281,
          312,
          4582,
          281,
          633,
          8747,
          300,
          311,
          294,
          300,
          3169,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15000878274440765,
        "compression_ratio": 1.7254098360655739,
        "end": 5010.6,
        "id": 1542,
        "no_speech_prob": 0.14033132791519165,
        "seek": 498260,
        "start": 5007.6,
        "temperature": 0,
        "text": " So I need some way of setting edges.",
        "tokens": [
          51614,
          407,
          286,
          643,
          512,
          636,
          295,
          3287,
          8819,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19035933880095787,
        "compression_ratio": 1.7659574468085106,
        "end": 5015.6,
        "id": 1543,
        "no_speech_prob": 0.0006563721690326929,
        "seek": 501060,
        "start": 5010.6,
        "temperature": 0,
        "text": " So the edges for each node should be a list of other nodes that it's connected to.",
        "tokens": [
          50364,
          407,
          264,
          8819,
          337,
          1184,
          9984,
          820,
          312,
          257,
          1329,
          295,
          661,
          13891,
          300,
          309,
          311,
          4582,
          281,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19035933880095787,
        "compression_ratio": 1.7659574468085106,
        "end": 5017.6,
        "id": 1544,
        "no_speech_prob": 0.0006563721690326929,
        "seek": 501060,
        "start": 5015.6,
        "temperature": 0,
        "text": " So let me see if I can do this.",
        "tokens": [
          50614,
          407,
          718,
          385,
          536,
          498,
          286,
          393,
          360,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19035933880095787,
        "compression_ratio": 1.7659574468085106,
        "end": 5024.6,
        "id": 1545,
        "no_speech_prob": 0.0006563721690326929,
        "seek": 501060,
        "start": 5017.6,
        "temperature": 0,
        "text": " So if I'm thinking about this code-wise, what I want to do here is for every actor, let me call this movie node.",
        "tokens": [
          50714,
          407,
          498,
          286,
          478,
          1953,
          466,
          341,
          3089,
          12,
          3711,
          11,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          337,
          633,
          8747,
          11,
          718,
          385,
          818,
          341,
          3169,
          9984,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19035933880095787,
        "compression_ratio": 1.7659574468085106,
        "end": 5033.6,
        "id": 1546,
        "no_speech_prob": 0.0006563721690326929,
        "seek": 501060,
        "start": 5024.6,
        "temperature": 0,
        "text": " I want to say something like movie node.connect actor node.",
        "tokens": [
          51064,
          286,
          528,
          281,
          584,
          746,
          411,
          3169,
          9984,
          13,
          9826,
          8747,
          9984,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19035933880095787,
        "compression_ratio": 1.7659574468085106,
        "end": 5036.6,
        "id": 1547,
        "no_speech_prob": 0.0006563721690326929,
        "seek": 501060,
        "start": 5033.6,
        "temperature": 0,
        "text": " So I want to connect the movie to the actor.",
        "tokens": [
          51514,
          407,
          286,
          528,
          281,
          1745,
          264,
          3169,
          281,
          264,
          8747,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5040.6,
        "id": 1548,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5036.6,
        "temperature": 0,
        "text": " And the other thing I want to do, though this is a question that comes up with these kind of algorithms,",
        "tokens": [
          50364,
          400,
          264,
          661,
          551,
          286,
          528,
          281,
          360,
          11,
          1673,
          341,
          307,
          257,
          1168,
          300,
          1487,
          493,
          365,
          613,
          733,
          295,
          14642,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5045.6,
        "id": 1549,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5040.6,
        "temperature": 0,
        "text": " is the graph, does the graph only go in one direction or do things go in two directions?",
        "tokens": [
          50564,
          307,
          264,
          4295,
          11,
          775,
          264,
          4295,
          787,
          352,
          294,
          472,
          3513,
          420,
          360,
          721,
          352,
          294,
          732,
          11095,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5047.6,
        "id": 1550,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5045.6,
        "temperature": 0,
        "text": " So in this case, I want to be able to go in either direction.",
        "tokens": [
          50814,
          407,
          294,
          341,
          1389,
          11,
          286,
          528,
          281,
          312,
          1075,
          281,
          352,
          294,
          2139,
          3513,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5051.6,
        "id": 1551,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5047.6,
        "temperature": 0,
        "text": " So let's, we need to add this connect function or add edge.",
        "tokens": [
          50914,
          407,
          718,
          311,
          11,
          321,
          643,
          281,
          909,
          341,
          1745,
          2445,
          420,
          909,
          4691,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5053.6,
        "id": 1552,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5051.6,
        "temperature": 0,
        "text": " Maybe I should just call this add edge.",
        "tokens": [
          51114,
          2704,
          286,
          820,
          445,
          818,
          341,
          909,
          4691,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5055.6,
        "id": 1553,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5053.6,
        "temperature": 0,
        "text": " So I have add node, now I have an add edge function.",
        "tokens": [
          51214,
          407,
          286,
          362,
          909,
          9984,
          11,
          586,
          286,
          362,
          364,
          909,
          4691,
          2445,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5056.6,
        "id": 1554,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5055.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2138798010610316,
        "compression_ratio": 1.9003831417624522,
        "end": 5064.6,
        "id": 1555,
        "no_speech_prob": 0.18475593626499176,
        "seek": 503660,
        "start": 5056.6,
        "temperature": 0,
        "text": " Here in node, so now I want to add to the node object a function called add edge.",
        "tokens": [
          51364,
          1692,
          294,
          9984,
          11,
          370,
          586,
          286,
          528,
          281,
          909,
          281,
          264,
          9984,
          2657,
          257,
          2445,
          1219,
          909,
          4691,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5067.6,
        "id": 1556,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5064.6,
        "temperature": 0,
        "text": " And it gets another, I'll call it a neighbor.",
        "tokens": [
          50364,
          400,
          309,
          2170,
          1071,
          11,
          286,
          603,
          818,
          309,
          257,
          5987,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5071.6,
        "id": 1557,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5067.6,
        "temperature": 0,
        "text": " And then I just want to say this.edges.push neighbor.",
        "tokens": [
          50514,
          400,
          550,
          286,
          445,
          528,
          281,
          584,
          341,
          13,
          292,
          2880,
          13,
          79,
          1498,
          5987,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5073.6,
        "id": 1558,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5071.6,
        "temperature": 0,
        "text": " Simple as that.",
        "tokens": [
          50714,
          21532,
          382,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5076.6,
        "id": 1559,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5073.6,
        "temperature": 0,
        "text": " All I need to do, push the neighbor.",
        "tokens": [
          50814,
          1057,
          286,
          643,
          281,
          360,
          11,
          2944,
          264,
          5987,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5078.6,
        "id": 1560,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5076.6,
        "temperature": 0,
        "text": " Now hold on a second.",
        "tokens": [
          50964,
          823,
          1797,
          322,
          257,
          1150,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5080.6,
        "id": 1561,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5078.6,
        "temperature": 0,
        "text": " We've got a problem.",
        "tokens": [
          51064,
          492,
          600,
          658,
          257,
          1154,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5082.6,
        "id": 1562,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5080.6,
        "temperature": 0,
        "text": " I just realized we have a problem.",
        "tokens": [
          51164,
          286,
          445,
          5334,
          321,
          362,
          257,
          1154,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5086.6,
        "id": 1563,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5082.6,
        "temperature": 0,
        "text": " The whole point of this is that actors can be in multiple movies.",
        "tokens": [
          51264,
          440,
          1379,
          935,
          295,
          341,
          307,
          300,
          10037,
          393,
          312,
          294,
          3866,
          6233,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5088.6,
        "id": 1564,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5086.6,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51464,
          1779,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.16229128015452418,
        "compression_ratio": 1.6008771929824561,
        "end": 5093.6,
        "id": 1565,
        "no_speech_prob": 0.0007672908250242472,
        "seek": 506460,
        "start": 5088.6,
        "temperature": 0,
        "text": " So here I am, always, always, always making a new actor node.",
        "tokens": [
          51564,
          407,
          510,
          286,
          669,
          11,
          1009,
          11,
          1009,
          11,
          1009,
          1455,
          257,
          777,
          8747,
          9984,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16775356398688424,
        "compression_ratio": 1.6815286624203822,
        "end": 5099.6,
        "id": 1566,
        "no_speech_prob": 0.0015247848350554705,
        "seek": 509360,
        "start": 5093.6,
        "temperature": 0,
        "text": " Now I know I can't have two instances of the same movie in this data set.",
        "tokens": [
          50364,
          823,
          286,
          458,
          286,
          393,
          380,
          362,
          732,
          14519,
          295,
          264,
          912,
          3169,
          294,
          341,
          1412,
          992,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16775356398688424,
        "compression_ratio": 1.6815286624203822,
        "end": 5101.6,
        "id": 1567,
        "no_speech_prob": 0.0015247848350554705,
        "seek": 509360,
        "start": 5099.6,
        "temperature": 0,
        "text": " But I could have two instances of the same actor.",
        "tokens": [
          50664,
          583,
          286,
          727,
          362,
          732,
          14519,
          295,
          264,
          912,
          8747,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16775356398688424,
        "compression_ratio": 1.6815286624203822,
        "end": 5107.6,
        "id": 1568,
        "no_speech_prob": 0.0015247848350554705,
        "seek": 509360,
        "start": 5101.6,
        "temperature": 0,
        "text": " So whenever I go through the cast, I need to figure out if the node already exists.",
        "tokens": [
          50764,
          407,
          5699,
          286,
          352,
          807,
          264,
          4193,
          11,
          286,
          643,
          281,
          2573,
          484,
          498,
          264,
          9984,
          1217,
          8198,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16775356398688424,
        "compression_ratio": 1.6815286624203822,
        "end": 5110.6,
        "id": 1569,
        "no_speech_prob": 0.0015247848350554705,
        "seek": 509360,
        "start": 5107.6,
        "temperature": 0,
        "text": " If the node already exists, I shouldn't make a new node.",
        "tokens": [
          51064,
          759,
          264,
          9984,
          1217,
          8198,
          11,
          286,
          4659,
          380,
          652,
          257,
          777,
          9984,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19461990892887115,
        "compression_ratio": 1.832,
        "end": 5125.6,
        "id": 1570,
        "no_speech_prob": 0.6583470106124878,
        "seek": 511060,
        "start": 5111.6,
        "temperature": 0,
        "text": " So I want to say if graph contains actor, then actor node, I want to say var actor node.",
        "tokens": [
          50414,
          407,
          286,
          528,
          281,
          584,
          498,
          4295,
          8306,
          8747,
          11,
          550,
          8747,
          9984,
          11,
          286,
          528,
          281,
          584,
          1374,
          8747,
          9984,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19461990892887115,
        "compression_ratio": 1.832,
        "end": 5129.6,
        "id": 1571,
        "no_speech_prob": 0.6583470106124878,
        "seek": 511060,
        "start": 5125.6,
        "temperature": 0,
        "text": " I'm just going to set an actor node to null for a second.",
        "tokens": [
          51114,
          286,
          478,
          445,
          516,
          281,
          992,
          364,
          8747,
          9984,
          281,
          18184,
          337,
          257,
          1150,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19461990892887115,
        "compression_ratio": 1.832,
        "end": 5137.6,
        "id": 1572,
        "no_speech_prob": 0.6583470106124878,
        "seek": 511060,
        "start": 5129.6,
        "temperature": 0,
        "text": " If graph contains the actor, then I want to say graph.get node actor or something.",
        "tokens": [
          51314,
          759,
          4295,
          8306,
          264,
          8747,
          11,
          550,
          286,
          528,
          281,
          584,
          4295,
          13,
          847,
          9984,
          8747,
          420,
          746,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19128301066737022,
        "compression_ratio": 1.7796610169491525,
        "end": 5139.6,
        "id": 1573,
        "no_speech_prob": 0.00806193146854639,
        "seek": 513760,
        "start": 5137.6,
        "temperature": 0,
        "text": " You know what I could do?",
        "tokens": [
          50364,
          509,
          458,
          437,
          286,
          727,
          360,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.19128301066737022,
        "compression_ratio": 1.7796610169491525,
        "end": 5144.6,
        "id": 1574,
        "no_speech_prob": 0.00806193146854639,
        "seek": 513760,
        "start": 5139.6,
        "temperature": 0,
        "text": " I could say var actor node equals graph.get the actor.",
        "tokens": [
          50464,
          286,
          727,
          584,
          1374,
          8747,
          9984,
          6915,
          4295,
          13,
          847,
          264,
          8747,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19128301066737022,
        "compression_ratio": 1.7796610169491525,
        "end": 5145.6,
        "id": 1575,
        "no_speech_prob": 0.00806193146854639,
        "seek": 513760,
        "start": 5144.6,
        "temperature": 0,
        "text": " Get node.",
        "tokens": [
          50714,
          3240,
          9984,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19128301066737022,
        "compression_ratio": 1.7796610169491525,
        "end": 5148.6,
        "id": 1576,
        "no_speech_prob": 0.00806193146854639,
        "seek": 513760,
        "start": 5145.6,
        "temperature": 0,
        "text": " So I could just have a function that says get node.",
        "tokens": [
          50764,
          407,
          286,
          727,
          445,
          362,
          257,
          2445,
          300,
          1619,
          483,
          9984,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19128301066737022,
        "compression_ratio": 1.7796610169491525,
        "end": 5152.6,
        "id": 1577,
        "no_speech_prob": 0.00806193146854639,
        "seek": 513760,
        "start": 5148.6,
        "temperature": 0,
        "text": " And that function will return null if the actor is not in there.",
        "tokens": [
          50914,
          400,
          300,
          2445,
          486,
          2736,
          18184,
          498,
          264,
          8747,
          307,
          406,
          294,
          456,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19128301066737022,
        "compression_ratio": 1.7796610169491525,
        "end": 5164.6,
        "id": 1578,
        "no_speech_prob": 0.00806193146854639,
        "seek": 513760,
        "start": 5152.6,
        "temperature": 0,
        "text": " So then I could say if actor node equals null, then I make a new actor node.",
        "tokens": [
          51114,
          407,
          550,
          286,
          727,
          584,
          498,
          8747,
          9984,
          6915,
          18184,
          11,
          550,
          286,
          652,
          257,
          777,
          8747,
          9984,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19128301066737022,
        "compression_ratio": 1.7796610169491525,
        "end": 5166.6,
        "id": 1579,
        "no_speech_prob": 0.00806193146854639,
        "seek": 513760,
        "start": 5164.6,
        "temperature": 0,
        "text": " So what do I need to add here?",
        "tokens": [
          51714,
          407,
          437,
          360,
          286,
          643,
          281,
          909,
          510,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.18415074176098928,
        "compression_ratio": 1.702127659574468,
        "end": 5169.6,
        "id": 1580,
        "no_speech_prob": 0.004133942537009716,
        "seek": 516660,
        "start": 5166.6,
        "temperature": 0,
        "text": " I need to add a get node function into the graph.",
        "tokens": [
          50364,
          286,
          643,
          281,
          909,
          257,
          483,
          9984,
          2445,
          666,
          264,
          4295,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18415074176098928,
        "compression_ratio": 1.702127659574468,
        "end": 5171.6,
        "id": 1581,
        "no_speech_prob": 0.004133942537009716,
        "seek": 516660,
        "start": 5169.6,
        "temperature": 0,
        "text": " So let me add that.",
        "tokens": [
          50514,
          407,
          718,
          385,
          909,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18415074176098928,
        "compression_ratio": 1.702127659574468,
        "end": 5177.6,
        "id": 1582,
        "no_speech_prob": 0.004133942537009716,
        "seek": 516660,
        "start": 5171.6,
        "temperature": 0,
        "text": " So I want to say graph.prototype.get node equals function.",
        "tokens": [
          50614,
          407,
          286,
          528,
          281,
          584,
          4295,
          13,
          33629,
          13108,
          13,
          847,
          9984,
          6915,
          2445,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18415074176098928,
        "compression_ratio": 1.702127659574468,
        "end": 5179.6,
        "id": 1583,
        "no_speech_prob": 0.004133942537009716,
        "seek": 516660,
        "start": 5177.6,
        "temperature": 0,
        "text": " And what do I want to do?",
        "tokens": [
          50914,
          400,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18415074176098928,
        "compression_ratio": 1.702127659574468,
        "end": 5180.6,
        "id": 1584,
        "no_speech_prob": 0.004133942537009716,
        "seek": 516660,
        "start": 5179.6,
        "temperature": 0,
        "text": " I want to look up.",
        "tokens": [
          51014,
          286,
          528,
          281,
          574,
          493,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18415074176098928,
        "compression_ratio": 1.702127659574468,
        "end": 5183.6,
        "id": 1585,
        "no_speech_prob": 0.004133942537009716,
        "seek": 516660,
        "start": 5180.6,
        "temperature": 0,
        "text": " So this is like an actor.",
        "tokens": [
          51064,
          407,
          341,
          307,
          411,
          364,
          8747,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18415074176098928,
        "compression_ratio": 1.702127659574468,
        "end": 5187.6,
        "id": 1586,
        "no_speech_prob": 0.004133942537009716,
        "seek": 516660,
        "start": 5183.6,
        "temperature": 0,
        "text": " So I want to say, what do I want to say?",
        "tokens": [
          51214,
          407,
          286,
          528,
          281,
          584,
          11,
          437,
          360,
          286,
          528,
          281,
          584,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5197.6,
        "id": 1587,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5187.6,
        "temperature": 0,
        "text": " var n equals this.graph lookup by the actor.",
        "tokens": [
          50364,
          1374,
          297,
          6915,
          341,
          13,
          34091,
          574,
          1010,
          538,
          264,
          8747,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5200.6,
        "id": 1588,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5197.6,
        "temperature": 0,
        "text": " And then return n.",
        "tokens": [
          50864,
          400,
          550,
          2736,
          297,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5203.6,
        "id": 1589,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5200.6,
        "temperature": 0,
        "text": " So this is going to get undefined, right?",
        "tokens": [
          51014,
          407,
          341,
          307,
          516,
          281,
          483,
          674,
          5666,
          2001,
          11,
          558,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5205.6,
        "id": 1590,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5203.6,
        "temperature": 0,
        "text": " It's not going to actually return null.",
        "tokens": [
          51164,
          467,
          311,
          406,
          516,
          281,
          767,
          2736,
          18184,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5210.6,
        "id": 1591,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5205.6,
        "temperature": 0,
        "text": " So I should actually say in the main program if actor node equals undefined.",
        "tokens": [
          51264,
          407,
          286,
          820,
          767,
          584,
          294,
          264,
          2135,
          1461,
          498,
          8747,
          9984,
          6915,
          674,
          5666,
          2001,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5211.6,
        "id": 1592,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5210.6,
        "temperature": 0,
        "text": " So exhausted.",
        "tokens": [
          51514,
          407,
          17992,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5213.6,
        "id": 1593,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5211.6,
        "temperature": 0,
        "text": " This is exhausting.",
        "tokens": [
          51564,
          639,
          307,
          34076,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20713308487815418,
        "compression_ratio": 1.6077348066298343,
        "end": 5215.6,
        "id": 1594,
        "no_speech_prob": 0.0826941430568695,
        "seek": 518760,
        "start": 5213.6,
        "temperature": 0,
        "text": " Are you still watching this video?",
        "tokens": [
          51664,
          2014,
          291,
          920,
          1976,
          341,
          960,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5217.6,
        "id": 1595,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5215.6,
        "temperature": 0,
        "text": " I need to take a nap, but I've got to finish this.",
        "tokens": [
          50364,
          286,
          643,
          281,
          747,
          257,
          9296,
          11,
          457,
          286,
          600,
          658,
          281,
          2413,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5218.6,
        "id": 1596,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5217.6,
        "temperature": 0,
        "text": " It's getting late.",
        "tokens": [
          50464,
          467,
          311,
          1242,
          3469,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5219.6,
        "id": 1597,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5218.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5222.6,
        "id": 1598,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5219.6,
        "temperature": 0,
        "text": " Maybe you just woke up and are having a nice little sip of tea and watching this video.",
        "tokens": [
          50564,
          2704,
          291,
          445,
          12852,
          493,
          293,
          366,
          1419,
          257,
          1481,
          707,
          29668,
          295,
          5817,
          293,
          1976,
          341,
          960,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5224.6,
        "id": 1599,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5222.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5226.6,
        "id": 1600,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5224.6,
        "temperature": 0,
        "text": " So I think this is going to work.",
        "tokens": [
          50814,
          407,
          286,
          519,
          341,
          307,
          516,
          281,
          589,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5228.6,
        "id": 1601,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5226.6,
        "temperature": 0,
        "text": " I might have made a mistake.",
        "tokens": [
          50914,
          286,
          1062,
          362,
          1027,
          257,
          6146,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5230.6,
        "id": 1602,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5228.6,
        "temperature": 0,
        "text": " But let's take a look.",
        "tokens": [
          51014,
          583,
          718,
          311,
          747,
          257,
          574,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5231.6,
        "id": 1603,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5230.6,
        "temperature": 0,
        "text": " Refresh.",
        "tokens": [
          51114,
          16957,
          3644,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5232.6,
        "id": 1604,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5231.6,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          51164,
          2438,
          11,
          1392,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5236.6,
        "id": 1605,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5232.6,
        "temperature": 0,
        "text": " Node.js line 8, there is an error.",
        "tokens": [
          51214,
          38640,
          13,
          25530,
          1622,
          1649,
          11,
          456,
          307,
          364,
          6713,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5238.6,
        "id": 1606,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5236.6,
        "temperature": 0,
        "text": " Oh, this should say equals function.",
        "tokens": [
          51414,
          876,
          11,
          341,
          820,
          584,
          6915,
          2445,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5241.6,
        "id": 1607,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5238.6,
        "temperature": 0,
        "text": " I just had the wrong syntax.",
        "tokens": [
          51514,
          286,
          445,
          632,
          264,
          2085,
          28431,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15165115969024434,
        "compression_ratio": 1.5642023346303502,
        "end": 5243.6,
        "id": 1608,
        "no_speech_prob": 0.28773772716522217,
        "seek": 521560,
        "start": 5241.6,
        "temperature": 0,
        "text": " So now let's look at this.",
        "tokens": [
          51664,
          407,
          586,
          718,
          311,
          574,
          412,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5244.6,
        "id": 1609,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5243.6,
        "temperature": 0,
        "text": " The node.",
        "tokens": [
          50364,
          440,
          9984,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5246.6,
        "id": 1610,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5244.6,
        "temperature": 0,
        "text": " So let's look at any given node.",
        "tokens": [
          50414,
          407,
          718,
          311,
          574,
          412,
          604,
          2212,
          9984,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5248.6,
        "id": 1611,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5246.6,
        "temperature": 0,
        "text": " This is Mickey Rourke.",
        "tokens": [
          50514,
          639,
          307,
          24714,
          497,
          396,
          330,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5249.6,
        "id": 1612,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5248.6,
        "temperature": 0,
        "text": " Edges.",
        "tokens": [
          50614,
          3977,
          2880,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5250.6,
        "id": 1613,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5249.6,
        "temperature": 0,
        "text": " It doesn't have any edges.",
        "tokens": [
          50664,
          467,
          1177,
          380,
          362,
          604,
          8819,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5251.6,
        "id": 1614,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5250.6,
        "temperature": 0,
        "text": " So what did I forget?",
        "tokens": [
          50714,
          407,
          437,
          630,
          286,
          2870,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5253.6,
        "id": 1615,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5251.6,
        "temperature": 0,
        "text": " The edges have to go both ways.",
        "tokens": [
          50764,
          440,
          8819,
          362,
          281,
          352,
          1293,
          2098,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5263.6,
        "id": 1616,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5253.6,
        "temperature": 0,
        "text": " So this.edges.push neighbor and neighbor.edges.push this.",
        "tokens": [
          50864,
          407,
          341,
          13,
          292,
          2880,
          13,
          79,
          1498,
          5987,
          293,
          5987,
          13,
          292,
          2880,
          13,
          79,
          1498,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5266.6,
        "id": 1617,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5263.6,
        "temperature": 0,
        "text": " Both directions.",
        "tokens": [
          51364,
          6767,
          11095,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5268.6,
        "id": 1618,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5266.6,
        "temperature": 0,
        "text": " So let's try that again.",
        "tokens": [
          51514,
          407,
          718,
          311,
          853,
          300,
          797,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5269.6,
        "id": 1619,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5268.6,
        "temperature": 0,
        "text": " Refresh.",
        "tokens": [
          51614,
          16957,
          3644,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1644486418557823,
        "compression_ratio": 1.620879120879121,
        "end": 5271.6,
        "id": 1620,
        "no_speech_prob": 0.0009253842290490866,
        "seek": 524360,
        "start": 5269.6,
        "temperature": 0,
        "text": " Let's look at an arbitrary node.",
        "tokens": [
          51664,
          961,
          311,
          574,
          412,
          364,
          23211,
          9984,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19699104972507642,
        "compression_ratio": 1.7589285714285714,
        "end": 5277.6,
        "id": 1621,
        "no_speech_prob": 0.18950633704662323,
        "seek": 527160,
        "start": 5271.6,
        "temperature": 0,
        "text": " Kevin Bacon, which is connected to ah, what did I just do?",
        "tokens": [
          50364,
          9954,
          42460,
          11,
          597,
          307,
          4582,
          281,
          220,
          545,
          11,
          437,
          630,
          286,
          445,
          360,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.19699104972507642,
        "compression_ratio": 1.7589285714285714,
        "end": 5283.6,
        "id": 1622,
        "no_speech_prob": 0.18950633704662323,
        "seek": 527160,
        "start": 5277.6,
        "temperature": 0,
        "text": " Kevin Bacon, which is connected to flat liners, footloose, and diner.",
        "tokens": [
          50664,
          9954,
          42460,
          11,
          597,
          307,
          4582,
          281,
          4962,
          22896,
          433,
          11,
          2671,
          752,
          541,
          11,
          293,
          3791,
          260,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19699104972507642,
        "compression_ratio": 1.7589285714285714,
        "end": 5289.6,
        "id": 1623,
        "no_speech_prob": 0.18950633704662323,
        "seek": 527160,
        "start": 5283.6,
        "temperature": 0,
        "text": " And if I look at zero, which is diner, it's connected to all these other actors, which are also connected to other things.",
        "tokens": [
          50964,
          400,
          498,
          286,
          574,
          412,
          4018,
          11,
          597,
          307,
          3791,
          260,
          11,
          309,
          311,
          4582,
          281,
          439,
          613,
          661,
          10037,
          11,
          597,
          366,
          611,
          4582,
          281,
          661,
          721,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19699104972507642,
        "compression_ratio": 1.7589285714285714,
        "end": 5291.6,
        "id": 1624,
        "no_speech_prob": 0.18950633704662323,
        "seek": 527160,
        "start": 5289.6,
        "temperature": 0,
        "text": " So I think this is right.",
        "tokens": [
          51264,
          407,
          286,
          519,
          341,
          307,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19699104972507642,
        "compression_ratio": 1.7589285714285714,
        "end": 5295.6,
        "id": 1625,
        "no_speech_prob": 0.18950633704662323,
        "seek": 527160,
        "start": 5291.6,
        "temperature": 0,
        "text": " I'm pretty sure I have the data correct.",
        "tokens": [
          51364,
          286,
          478,
          1238,
          988,
          286,
          362,
          264,
          1412,
          3006,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19699104972507642,
        "compression_ratio": 1.7589285714285714,
        "end": 5297.6,
        "id": 1626,
        "no_speech_prob": 0.18950633704662323,
        "seek": 527160,
        "start": 5295.6,
        "temperature": 0,
        "text": " Anybody want to say otherwise?",
        "tokens": [
          51564,
          19082,
          528,
          281,
          584,
          5911,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.19699104972507642,
        "compression_ratio": 1.7589285714285714,
        "end": 5300.6,
        "id": 1627,
        "no_speech_prob": 0.18950633704662323,
        "seek": 527160,
        "start": 5297.6,
        "temperature": 0,
        "text": " Because then I'm going to move on to part 2.",
        "tokens": [
          51664,
          1436,
          550,
          286,
          478,
          516,
          281,
          1286,
          322,
          281,
          644,
          568,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1922793080729823,
        "compression_ratio": 1.6836363636363636,
        "end": 5302.6,
        "id": 1628,
        "no_speech_prob": 0.7878575921058655,
        "seek": 530060,
        "start": 5300.6,
        "temperature": 0,
        "text": " So now we can actually do the algorithm.",
        "tokens": [
          50364,
          407,
          586,
          321,
          393,
          767,
          360,
          264,
          9284,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1922793080729823,
        "compression_ratio": 1.6836363636363636,
        "end": 5305.6,
        "id": 1629,
        "no_speech_prob": 0.7878575921058655,
        "seek": 530060,
        "start": 5302.6,
        "temperature": 0,
        "text": " So this would be really nice if I had a visual example.",
        "tokens": [
          50464,
          407,
          341,
          576,
          312,
          534,
          1481,
          498,
          286,
          632,
          257,
          5056,
          1365,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1922793080729823,
        "compression_ratio": 1.6836363636363636,
        "end": 5312.6,
        "id": 1630,
        "no_speech_prob": 0.7878575921058655,
        "seek": 530060,
        "start": 5305.6,
        "temperature": 0,
        "text": " So I will link to this code example as well, which is using a force-directed graph to arrange it.",
        "tokens": [
          50614,
          407,
          286,
          486,
          2113,
          281,
          341,
          3089,
          1365,
          382,
          731,
          11,
          597,
          307,
          1228,
          257,
          3464,
          12,
          44868,
          292,
          4295,
          281,
          9424,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1922793080729823,
        "compression_ratio": 1.6836363636363636,
        "end": 5317.6,
        "id": 1631,
        "no_speech_prob": 0.7878575921058655,
        "seek": 530060,
        "start": 5312.6,
        "temperature": 0,
        "text": " And as an exercise, you can even stop here and just try to visualize this graph.",
        "tokens": [
          50964,
          400,
          382,
          364,
          5380,
          11,
          291,
          393,
          754,
          1590,
          510,
          293,
          445,
          853,
          281,
          23273,
          341,
          4295,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1922793080729823,
        "compression_ratio": 1.6836363636363636,
        "end": 5318.6,
        "id": 1632,
        "no_speech_prob": 0.7878575921058655,
        "seek": 530060,
        "start": 5317.6,
        "temperature": 0,
        "text": " Not the easiest problem.",
        "tokens": [
          51214,
          1726,
          264,
          12889,
          1154,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1922793080729823,
        "compression_ratio": 1.6836363636363636,
        "end": 5320.6,
        "id": 1633,
        "no_speech_prob": 0.7878575921058655,
        "seek": 530060,
        "start": 5318.6,
        "temperature": 0,
        "text": " I would love to see your solution.",
        "tokens": [
          51264,
          286,
          576,
          959,
          281,
          536,
          428,
          3827,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1922793080729823,
        "compression_ratio": 1.6836363636363636,
        "end": 5327.6,
        "id": 1634,
        "no_speech_prob": 0.7878575921058655,
        "seek": 530060,
        "start": 5320.6,
        "temperature": 0,
        "text": " But I'm going to stop, and what I'm going to do in the next video is I'm going to implement the breadth-first search algorithm.",
        "tokens": [
          51364,
          583,
          286,
          478,
          516,
          281,
          1590,
          11,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          264,
          958,
          960,
          307,
          286,
          478,
          516,
          281,
          4445,
          264,
          35862,
          12,
          29581,
          3164,
          9284,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2702839249058774,
        "compression_ratio": 1.3591160220994476,
        "end": 5331.6,
        "id": 1635,
        "no_speech_prob": 0.022977055981755257,
        "seek": 532760,
        "start": 5327.6,
        "temperature": 0,
        "text": " And when I come back at the beginning of it, if I found any mistakes, I'll let you know.",
        "tokens": [
          50364,
          400,
          562,
          286,
          808,
          646,
          412,
          264,
          2863,
          295,
          309,
          11,
          498,
          286,
          1352,
          604,
          8038,
          11,
          286,
          603,
          718,
          291,
          458,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2702839249058774,
        "compression_ratio": 1.3591160220994476,
        "end": 5335.6,
        "id": 1636,
        "no_speech_prob": 0.022977055981755257,
        "seek": 532760,
        "start": 5331.6,
        "temperature": 0,
        "text": " Okay. 530.",
        "tokens": [
          50564,
          1033,
          13,
          1025,
          3446,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2702839249058774,
        "compression_ratio": 1.3591160220994476,
        "end": 5344.6,
        "id": 1637,
        "no_speech_prob": 0.022977055981755257,
        "seek": 532760,
        "start": 5339.6,
        "temperature": 0,
        "text": " Yeah, Mark in the chat writes, can you visualize this? I'm having a hard time understanding this setup.",
        "tokens": [
          50964,
          865,
          11,
          3934,
          294,
          264,
          5081,
          13657,
          11,
          393,
          291,
          23273,
          341,
          30,
          286,
          478,
          1419,
          257,
          1152,
          565,
          3701,
          341,
          8657,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2702839249058774,
        "compression_ratio": 1.3591160220994476,
        "end": 5346.6,
        "id": 1638,
        "no_speech_prob": 0.022977055981755257,
        "seek": 532760,
        "start": 5344.6,
        "temperature": 0,
        "text": " It's a very good point.",
        "tokens": [
          51214,
          467,
          311,
          257,
          588,
          665,
          935,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2702839249058774,
        "compression_ratio": 1.3591160220994476,
        "end": 5352.6,
        "id": 1639,
        "no_speech_prob": 0.022977055981755257,
        "seek": 532760,
        "start": 5350.6,
        "temperature": 0,
        "text": " It's not the best.",
        "tokens": [
          51514,
          467,
          311,
          406,
          264,
          1151,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2857388366352428,
        "compression_ratio": 1.4864864864864864,
        "end": 5355.6,
        "id": 1640,
        "no_speech_prob": 0.00009314576163887978,
        "seek": 535260,
        "start": 5353.6,
        "temperature": 0,
        "text": " So what I'm going to do...",
        "tokens": [
          50414,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2857388366352428,
        "compression_ratio": 1.4864864864864864,
        "end": 5362.6,
        "id": 1641,
        "no_speech_prob": 0.00009314576163887978,
        "seek": 535260,
        "start": 5357.6,
        "temperature": 0,
        "text": " K. Weekmon asks, there's no inherent set data structure, is there?",
        "tokens": [
          50614,
          591,
          13,
          492,
          68,
          74,
          3317,
          8962,
          11,
          456,
          311,
          572,
          26387,
          992,
          1412,
          3877,
          11,
          307,
          456,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2857388366352428,
        "compression_ratio": 1.4864864864864864,
        "end": 5369.6,
        "id": 1642,
        "no_speech_prob": 0.00009314576163887978,
        "seek": 535260,
        "start": 5365.6,
        "temperature": 0,
        "text": " Set node type. You know what? I don't actually need to set the node type to movie or actor.",
        "tokens": [
          51014,
          8928,
          9984,
          2010,
          13,
          509,
          458,
          437,
          30,
          286,
          500,
          380,
          767,
          643,
          281,
          992,
          264,
          9984,
          2010,
          281,
          3169,
          420,
          8747,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2857388366352428,
        "compression_ratio": 1.4864864864864864,
        "end": 5375.6,
        "id": 1643,
        "no_speech_prob": 0.00009314576163887978,
        "seek": 535260,
        "start": 5372.6,
        "temperature": 0,
        "text": " Yeah, no, I'm kind of just...",
        "tokens": [
          51364,
          865,
          11,
          572,
          11,
          286,
          478,
          733,
          295,
          445,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.2857388366352428,
        "compression_ratio": 1.4864864864864864,
        "end": 5380.6,
        "id": 1644,
        "no_speech_prob": 0.00009314576163887978,
        "seek": 535260,
        "start": 5375.6,
        "temperature": 0,
        "text": " If we look when I get to this, it's going to say empty set.",
        "tokens": [
          51514,
          759,
          321,
          574,
          562,
          286,
          483,
          281,
          341,
          11,
          309,
          311,
          516,
          281,
          584,
          6707,
          992,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5385.6,
        "id": 1645,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5383.6,
        "temperature": 0,
        "text": " Wait, what's the empty set?",
        "tokens": [
          50414,
          3802,
          11,
          437,
          311,
          264,
          6707,
          992,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5388.6,
        "id": 1646,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5386.6,
        "temperature": 0,
        "text": " Oh, that's for searched.",
        "tokens": [
          50564,
          876,
          11,
          300,
          311,
          337,
          22961,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5391.6,
        "id": 1647,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5389.6,
        "temperature": 0,
        "text": " So I'm doing it differently.",
        "tokens": [
          50714,
          407,
          286,
          478,
          884,
          309,
          7614,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5395.6,
        "id": 1648,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5391.6,
        "temperature": 0,
        "text": " So I just need to create a queue and the root. Okay.",
        "tokens": [
          50814,
          407,
          286,
          445,
          643,
          281,
          1884,
          257,
          18639,
          293,
          264,
          5593,
          13,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5401.6,
        "id": 1649,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5398.6,
        "temperature": 0,
        "text": " So I'm doing it a little bit differently, but...",
        "tokens": [
          51164,
          407,
          286,
          478,
          884,
          309,
          257,
          707,
          857,
          7614,
          11,
          457,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5403.6,
        "id": 1650,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5401.6,
        "temperature": 0,
        "text": " Yeah, these are the data structures I'm using.",
        "tokens": [
          51314,
          865,
          11,
          613,
          366,
          264,
          1412,
          9227,
          286,
          478,
          1228,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5407.6,
        "id": 1651,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5403.6,
        "temperature": 0,
        "text": " Okay, sorry, I'm fading here, but I'm going to push through and finish this.",
        "tokens": [
          51414,
          1033,
          11,
          2597,
          11,
          286,
          478,
          38644,
          510,
          11,
          457,
          286,
          478,
          516,
          281,
          2944,
          807,
          293,
          2413,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18607853140149797,
        "compression_ratio": 1.6331877729257642,
        "end": 5410.6,
        "id": 1652,
        "no_speech_prob": 0.00021654354350175709,
        "seek": 538260,
        "start": 5407.6,
        "temperature": 0,
        "text": " But it was a really good point in the chat about visualizing this.",
        "tokens": [
          51614,
          583,
          309,
          390,
          257,
          534,
          665,
          935,
          294,
          264,
          5081,
          466,
          5056,
          3319,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.24433841990001165,
        "compression_ratio": 1.3801169590643274,
        "end": 5414.6,
        "id": 1653,
        "no_speech_prob": 0.00005920866169617511,
        "seek": 541060,
        "start": 5410.6,
        "temperature": 0,
        "text": " Maybe I'll start by drawing this out a bit more.",
        "tokens": [
          50364,
          2704,
          286,
          603,
          722,
          538,
          6316,
          341,
          484,
          257,
          857,
          544,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24433841990001165,
        "compression_ratio": 1.3801169590643274,
        "end": 5423.6,
        "id": 1654,
        "no_speech_prob": 0.00005920866169617511,
        "seek": 541060,
        "start": 5419.6,
        "temperature": 0,
        "text": " Nobody sees any mistakes here? Let's just double check this.",
        "tokens": [
          50814,
          9297,
          8194,
          604,
          8038,
          510,
          30,
          961,
          311,
          445,
          3834,
          1520,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24433841990001165,
        "compression_ratio": 1.3801169590643274,
        "end": 5429.6,
        "id": 1655,
        "no_speech_prob": 0.00005920866169617511,
        "seek": 541060,
        "start": 5424.6,
        "temperature": 0,
        "text": " This is a terrible way of looking at it, but I'm pretty sure it's right.",
        "tokens": [
          51064,
          639,
          307,
          257,
          6237,
          636,
          295,
          1237,
          412,
          309,
          11,
          457,
          286,
          478,
          1238,
          988,
          309,
          311,
          558,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24433841990001165,
        "compression_ratio": 1.3801169590643274,
        "end": 5436.6,
        "id": 1656,
        "no_speech_prob": 0.00005920866169617511,
        "seek": 541060,
        "start": 5432.6,
        "temperature": 0,
        "text": " If I look at this particular actor, it's these edges.",
        "tokens": [
          51464,
          759,
          286,
          574,
          412,
          341,
          1729,
          8747,
          11,
          309,
          311,
          613,
          8819,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21259452819824218,
        "compression_ratio": 1.5467980295566504,
        "end": 5440.6,
        "id": 1657,
        "no_speech_prob": 0.00016346304619219154,
        "seek": 543660,
        "start": 5436.6,
        "temperature": 0,
        "text": " Which is Eat, Pray, Love, which is connected to all these other actors.",
        "tokens": [
          50364,
          3013,
          307,
          14429,
          11,
          36365,
          11,
          5956,
          11,
          597,
          307,
          4582,
          281,
          439,
          613,
          661,
          10037,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21259452819824218,
        "compression_ratio": 1.5467980295566504,
        "end": 5444.6,
        "id": 1658,
        "no_speech_prob": 0.00016346304619219154,
        "seek": 543660,
        "start": 5441.6,
        "temperature": 0,
        "text": " And I don't see any... There's no duplicate.",
        "tokens": [
          50614,
          400,
          286,
          500,
          380,
          536,
          604,
          485,
          821,
          311,
          572,
          23976,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21259452819824218,
        "compression_ratio": 1.5467980295566504,
        "end": 5450.6,
        "id": 1659,
        "no_speech_prob": 0.00016346304619219154,
        "seek": 543660,
        "start": 5446.6,
        "temperature": 0,
        "text": " There shouldn't be any duplicates, so I think this is good.",
        "tokens": [
          50864,
          821,
          4659,
          380,
          312,
          604,
          17154,
          1024,
          11,
          370,
          286,
          519,
          341,
          307,
          665,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21259452819824218,
        "compression_ratio": 1.5467980295566504,
        "end": 5452.6,
        "id": 1660,
        "no_speech_prob": 0.00016346304619219154,
        "seek": 543660,
        "start": 5451.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21259452819824218,
        "compression_ratio": 1.5467980295566504,
        "end": 5457.6,
        "id": 1661,
        "no_speech_prob": 0.00016346304619219154,
        "seek": 543660,
        "start": 5453.6,
        "temperature": 0,
        "text": " S is a tab with visited nodes. Yeah, yeah, yeah, yeah.",
        "tokens": [
          51214,
          318,
          307,
          257,
          4421,
          365,
          11220,
          13891,
          13,
          865,
          11,
          1338,
          11,
          1338,
          11,
          1338,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21259452819824218,
        "compression_ratio": 1.5467980295566504,
        "end": 5461.6,
        "id": 1662,
        "no_speech_prob": 0.00016346304619219154,
        "seek": 543660,
        "start": 5458.6,
        "temperature": 0,
        "text": " Okay. Why don't I make games anymore?",
        "tokens": [
          51464,
          1033,
          13,
          1545,
          500,
          380,
          286,
          652,
          2813,
          3602,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.21259452819824218,
        "compression_ratio": 1.5467980295566504,
        "end": 5464.6,
        "id": 1663,
        "no_speech_prob": 0.00016346304619219154,
        "seek": 543660,
        "start": 5461.6,
        "temperature": 0,
        "text": " I don't know. I wish I was doing that.",
        "tokens": [
          51614,
          286,
          500,
          380,
          458,
          13,
          286,
          3172,
          286,
          390,
          884,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22406852408631206,
        "compression_ratio": 1.452127659574468,
        "end": 5469.6,
        "id": 1664,
        "no_speech_prob": 0.0004373312694951892,
        "seek": 546460,
        "start": 5465.6,
        "temperature": 0,
        "text": " I agreed to teach this class on artificial intelligence and machine learning.",
        "tokens": [
          50414,
          286,
          9166,
          281,
          2924,
          341,
          1508,
          322,
          11677,
          7599,
          293,
          3479,
          2539,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22406852408631206,
        "compression_ratio": 1.452127659574468,
        "end": 5471.6,
        "id": 1665,
        "no_speech_prob": 0.0004373312694951892,
        "seek": 546460,
        "start": 5469.6,
        "temperature": 0,
        "text": " I thought that search algorithms would work.",
        "tokens": [
          50614,
          286,
          1194,
          300,
          3164,
          14642,
          576,
          589,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22406852408631206,
        "compression_ratio": 1.452127659574468,
        "end": 5476.6,
        "id": 1666,
        "no_speech_prob": 0.0004373312694951892,
        "seek": 546460,
        "start": 5472.6,
        "temperature": 0,
        "text": " Really, I just want to take a nap and read some nice fiction.",
        "tokens": [
          50764,
          4083,
          11,
          286,
          445,
          528,
          281,
          747,
          257,
          9296,
          293,
          1401,
          512,
          1481,
          13266,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22406852408631206,
        "compression_ratio": 1.452127659574468,
        "end": 5478.6,
        "id": 1667,
        "no_speech_prob": 0.0004373312694951892,
        "seek": 546460,
        "start": 5476.6,
        "temperature": 0,
        "text": " But this is what I'm doing.",
        "tokens": [
          50964,
          583,
          341,
          307,
          437,
          286,
          478,
          884,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22406852408631206,
        "compression_ratio": 1.452127659574468,
        "end": 5481.6,
        "id": 1668,
        "no_speech_prob": 0.0004373312694951892,
        "seek": 546460,
        "start": 5479.6,
        "temperature": 0,
        "text": " I'm definitely with you there, though.",
        "tokens": [
          51114,
          286,
          478,
          2138,
          365,
          291,
          456,
          11,
          1673,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22406852408631206,
        "compression_ratio": 1.452127659574468,
        "end": 5485.6,
        "id": 1669,
        "no_speech_prob": 0.0004373312694951892,
        "seek": 546460,
        "start": 5483.6,
        "temperature": 0,
        "text": " Let's come back here.",
        "tokens": [
          51314,
          961,
          311,
          808,
          646,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21834386189778646,
        "compression_ratio": 1.3076923076923077,
        "end": 5486.6,
        "id": 1670,
        "no_speech_prob": 0.00225181900896132,
        "seek": 548560,
        "start": 5485.6,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          50364,
          400,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.21834386189778646,
        "compression_ratio": 1.3076923076923077,
        "end": 5494.6,
        "id": 1671,
        "no_speech_prob": 0.00225181900896132,
        "seek": 548560,
        "start": 5492.6,
        "temperature": 0,
        "text": " Okay. So, grass.",
        "tokens": [
          50714,
          1033,
          13,
          407,
          11,
          8054,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21834386189778646,
        "compression_ratio": 1.3076923076923077,
        "end": 5499.6,
        "id": 1672,
        "no_speech_prob": 0.00225181900896132,
        "seek": 548560,
        "start": 5495.6,
        "temperature": 0,
        "text": " Okay. I'm going to try to finish this now.",
        "tokens": [
          50864,
          1033,
          13,
          286,
          478,
          516,
          281,
          853,
          281,
          2413,
          341,
          586,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21834386189778646,
        "compression_ratio": 1.3076923076923077,
        "end": 5507.6,
        "id": 1673,
        "no_speech_prob": 0.00225181900896132,
        "seek": 548560,
        "start": 5505.6,
        "temperature": 0,
        "text": " Okay. Here we go.",
        "tokens": [
          51364,
          1033,
          13,
          1692,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21834386189778646,
        "compression_ratio": 1.3076923076923077,
        "end": 5514.6,
        "id": 1674,
        "no_speech_prob": 0.00225181900896132,
        "seek": 548560,
        "start": 5510.6,
        "temperature": 0,
        "text": " I know that wasn't a half an hour, because the cameras didn't go off, so that's good.",
        "tokens": [
          51614,
          286,
          458,
          300,
          2067,
          380,
          257,
          1922,
          364,
          1773,
          11,
          570,
          264,
          8622,
          994,
          380,
          352,
          766,
          11,
          370,
          300,
          311,
          665,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.26654922260957603,
        "compression_ratio": 1.3582089552238805,
        "end": 5517.6,
        "id": 1675,
        "no_speech_prob": 0.000543997623026371,
        "seek": 551560,
        "start": 5516.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26654922260957603,
        "compression_ratio": 1.3582089552238805,
        "end": 5528.6,
        "id": 1676,
        "no_speech_prob": 0.000543997623026371,
        "seek": 551560,
        "start": 5524.6,
        "temperature": 0,
        "text": " Okay. Take a nap. Poor Dan. I don't mean for all your sympathy here.",
        "tokens": [
          50814,
          1033,
          13,
          3664,
          257,
          9296,
          13,
          23591,
          3394,
          13,
          286,
          500,
          380,
          914,
          337,
          439,
          428,
          33240,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.26654922260957603,
        "compression_ratio": 1.3582089552238805,
        "end": 5531.6,
        "id": 1677,
        "no_speech_prob": 0.000543997623026371,
        "seek": 551560,
        "start": 5529.6,
        "temperature": 0,
        "text": " Thank you, though. That's nice of you.",
        "tokens": [
          51064,
          1044,
          291,
          11,
          1673,
          13,
          663,
          311,
          1481,
          295,
          291,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26654922260957603,
        "compression_ratio": 1.3582089552238805,
        "end": 5533.6,
        "id": 1678,
        "no_speech_prob": 0.000543997623026371,
        "seek": 551560,
        "start": 5532.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26654922260957603,
        "compression_ratio": 1.3582089552238805,
        "end": 5536.6,
        "id": 1679,
        "no_speech_prob": 0.000543997623026371,
        "seek": 551560,
        "start": 5534.6,
        "temperature": 0,
        "text": " Alright. Let's go here.",
        "tokens": [
          51314,
          2798,
          13,
          961,
          311,
          352,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.26654922260957603,
        "compression_ratio": 1.3582089552238805,
        "end": 5539.6,
        "id": 1680,
        "no_speech_prob": 0.000543997623026371,
        "seek": 551560,
        "start": 5537.6,
        "temperature": 0,
        "text": " I don't know what to start with.",
        "tokens": [
          51464,
          286,
          500,
          380,
          458,
          437,
          281,
          722,
          365,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26654922260957603,
        "compression_ratio": 1.3582089552238805,
        "end": 5541.6,
        "id": 1681,
        "no_speech_prob": 0.000543997623026371,
        "seek": 551560,
        "start": 5540.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25888659954071047,
        "compression_ratio": 1.3908629441624365,
        "end": 5543.6,
        "id": 1682,
        "no_speech_prob": 0.0005033295601606369,
        "seek": 554160,
        "start": 5542.6,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50414,
          876,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.25888659954071047,
        "compression_ratio": 1.3908629441624365,
        "end": 5558.6,
        "id": 1683,
        "no_speech_prob": 0.0005033295601606369,
        "seek": 554160,
        "start": 5551.6,
        "temperature": 0,
        "text": " Okay. So, I'm back here for part two of this breath-first search algorithm thingy.",
        "tokens": [
          50864,
          1033,
          13,
          407,
          11,
          286,
          478,
          646,
          510,
          337,
          644,
          732,
          295,
          341,
          6045,
          12,
          29581,
          3164,
          9284,
          551,
          88,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25888659954071047,
        "compression_ratio": 1.3908629441624365,
        "end": 5561.6,
        "id": 1684,
        "no_speech_prob": 0.0005033295601606369,
        "seek": 554160,
        "start": 5558.6,
        "temperature": 0,
        "text": " So, somebody in the chat had asked,",
        "tokens": [
          51214,
          407,
          11,
          2618,
          294,
          264,
          5081,
          632,
          2351,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.25888659954071047,
        "compression_ratio": 1.3908629441624365,
        "end": 5564.6,
        "id": 1685,
        "no_speech_prob": 0.0005033295601606369,
        "seek": 554160,
        "start": 5561.6,
        "temperature": 0,
        "text": " this is really hard to follow. Could you visualize this?",
        "tokens": [
          51364,
          341,
          307,
          534,
          1152,
          281,
          1524,
          13,
          7497,
          291,
          23273,
          341,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.25888659954071047,
        "compression_ratio": 1.3908629441624365,
        "end": 5566.6,
        "id": 1686,
        "no_speech_prob": 0.0005033295601606369,
        "seek": 554160,
        "start": 5564.6,
        "temperature": 0,
        "text": " It's a very, very good point.",
        "tokens": [
          51514,
          467,
          311,
          257,
          588,
          11,
          588,
          665,
          935,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.25888659954071047,
        "compression_ratio": 1.3908629441624365,
        "end": 5569.6,
        "id": 1687,
        "no_speech_prob": 0.0005033295601606369,
        "seek": 554160,
        "start": 5566.6,
        "temperature": 0,
        "text": " Unfortunately, the way that I'm building this example right now,",
        "tokens": [
          51614,
          8590,
          11,
          264,
          636,
          300,
          286,
          478,
          2390,
          341,
          1365,
          558,
          586,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.20972261843474016,
        "compression_ratio": 1.6736401673640167,
        "end": 5572.6,
        "id": 1688,
        "no_speech_prob": 0.0007321603479795158,
        "seek": 556960,
        "start": 5569.6,
        "temperature": 0,
        "text": " I'm not going to build in a lot of graphics features.",
        "tokens": [
          50364,
          286,
          478,
          406,
          516,
          281,
          1322,
          294,
          257,
          688,
          295,
          11837,
          4122,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20972261843474016,
        "compression_ratio": 1.6736401673640167,
        "end": 5574.6,
        "id": 1689,
        "no_speech_prob": 0.0007321603479795158,
        "seek": 556960,
        "start": 5572.6,
        "temperature": 0,
        "text": " That's a great exercise for you to do.",
        "tokens": [
          50514,
          663,
          311,
          257,
          869,
          5380,
          337,
          291,
          281,
          360,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20972261843474016,
        "compression_ratio": 1.6736401673640167,
        "end": 5578.6,
        "id": 1690,
        "no_speech_prob": 0.0007321603479795158,
        "seek": 556960,
        "start": 5574.6,
        "temperature": 0,
        "text": " And I do have other examples that do have those features that I'll link to, you can look at.",
        "tokens": [
          50614,
          400,
          286,
          360,
          362,
          661,
          5110,
          300,
          360,
          362,
          729,
          4122,
          300,
          286,
          603,
          2113,
          281,
          11,
          291,
          393,
          574,
          412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20972261843474016,
        "compression_ratio": 1.6736401673640167,
        "end": 5581.6,
        "id": 1691,
        "no_speech_prob": 0.0007321603479795158,
        "seek": 556960,
        "start": 5578.6,
        "temperature": 0,
        "text": " But I think that we could, at the very least,",
        "tokens": [
          50814,
          583,
          286,
          519,
          300,
          321,
          727,
          11,
          412,
          264,
          588,
          1935,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20972261843474016,
        "compression_ratio": 1.6736401673640167,
        "end": 5585.6,
        "id": 1692,
        "no_speech_prob": 0.0007321603479795158,
        "seek": 556960,
        "start": 5582.6,
        "temperature": 0,
        "text": " I could draw it for you, what this is looking like.",
        "tokens": [
          51014,
          286,
          727,
          2642,
          309,
          337,
          291,
          11,
          437,
          341,
          307,
          1237,
          411,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20972261843474016,
        "compression_ratio": 1.6736401673640167,
        "end": 5589.6,
        "id": 1693,
        "no_speech_prob": 0.0007321603479795158,
        "seek": 556960,
        "start": 5585.6,
        "temperature": 0,
        "text": " So, without using actual movie names or actor names,",
        "tokens": [
          51164,
          407,
          11,
          1553,
          1228,
          3539,
          3169,
          5288,
          420,
          8747,
          5288,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.20972261843474016,
        "compression_ratio": 1.6736401673640167,
        "end": 5595.6,
        "id": 1694,
        "no_speech_prob": 0.0007321603479795158,
        "seek": 556960,
        "start": 5589.6,
        "temperature": 0,
        "text": " I'm just going to say, like, movie one, movie two, movie three.",
        "tokens": [
          51364,
          286,
          478,
          445,
          516,
          281,
          584,
          11,
          411,
          11,
          3169,
          472,
          11,
          3169,
          732,
          11,
          3169,
          1045,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5599.6,
        "id": 1695,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5596.6,
        "temperature": 0,
        "text": " I'm going to have actor one, actor two.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          362,
          8747,
          472,
          11,
          8747,
          732,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5602.6,
        "id": 1696,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5599.6,
        "temperature": 0,
        "text": " I should probably use real names to make this make more sense.",
        "tokens": [
          50564,
          286,
          820,
          1391,
          764,
          957,
          5288,
          281,
          652,
          341,
          652,
          544,
          2020,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5604.6,
        "id": 1697,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5602.6,
        "temperature": 0,
        "text": " Actor three, actor four, actor five.",
        "tokens": [
          50714,
          45457,
          1045,
          11,
          8747,
          1451,
          11,
          8747,
          1732,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5607.6,
        "id": 1698,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5604.6,
        "temperature": 0,
        "text": " So, maybe these actors were in this movie.",
        "tokens": [
          50814,
          407,
          11,
          1310,
          613,
          10037,
          645,
          294,
          341,
          3169,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5611.6,
        "id": 1699,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5609.6,
        "temperature": 0,
        "text": " These actors were in this movie.",
        "tokens": [
          51064,
          1981,
          10037,
          645,
          294,
          341,
          3169,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5614.6,
        "id": 1700,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5611.6,
        "temperature": 0,
        "text": " Oops. The actors don't have connections to each other.",
        "tokens": [
          51164,
          21726,
          13,
          440,
          10037,
          500,
          380,
          362,
          9271,
          281,
          1184,
          661,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5615.6,
        "id": 1701,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5614.6,
        "temperature": 0,
        "text": " And this, right?",
        "tokens": [
          51314,
          400,
          341,
          11,
          558,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5618.6,
        "id": 1702,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5615.6,
        "temperature": 0,
        "text": " So, the actors, it's only in this particular example,",
        "tokens": [
          51364,
          407,
          11,
          264,
          10037,
          11,
          309,
          311,
          787,
          294,
          341,
          1729,
          1365,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17725662712578302,
        "compression_ratio": 1.914691943127962,
        "end": 5621.6,
        "id": 1703,
        "no_speech_prob": 0.00003763641507248394,
        "seek": 559560,
        "start": 5618.6,
        "temperature": 0,
        "text": " the actors only have connections to each other through movies.",
        "tokens": [
          51514,
          264,
          10037,
          787,
          362,
          9271,
          281,
          1184,
          661,
          807,
          6233,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19389951551282728,
        "compression_ratio": 1.6716981132075472,
        "end": 5625.6,
        "id": 1704,
        "no_speech_prob": 0.013848376460373402,
        "seek": 562160,
        "start": 5621.6,
        "temperature": 0,
        "text": " And somebody else in the chat mentioned you should distinguish between movie and actor nodes.",
        "tokens": [
          50364,
          400,
          2618,
          1646,
          294,
          264,
          5081,
          2835,
          291,
          820,
          20206,
          1296,
          3169,
          293,
          8747,
          13891,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19389951551282728,
        "compression_ratio": 1.6716981132075472,
        "end": 5627.6,
        "id": 1705,
        "no_speech_prob": 0.013848376460373402,
        "seek": 562160,
        "start": 5625.6,
        "temperature": 0,
        "text": " And that could be an interesting thing to work with.",
        "tokens": [
          50564,
          400,
          300,
          727,
          312,
          364,
          1880,
          551,
          281,
          589,
          365,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19389951551282728,
        "compression_ratio": 1.6716981132075472,
        "end": 5630.6,
        "id": 1706,
        "no_speech_prob": 0.013848376460373402,
        "seek": 562160,
        "start": 5627.6,
        "temperature": 0,
        "text": " And, you know, depending on how you're visualizing it, you probably would want to do that.",
        "tokens": [
          50664,
          400,
          11,
          291,
          458,
          11,
          5413,
          322,
          577,
          291,
          434,
          5056,
          3319,
          309,
          11,
          291,
          1391,
          576,
          528,
          281,
          360,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19389951551282728,
        "compression_ratio": 1.6716981132075472,
        "end": 5633.6,
        "id": 1707,
        "no_speech_prob": 0.013848376460373402,
        "seek": 562160,
        "start": 5630.6,
        "temperature": 0,
        "text": " But for just finding the shortest path, I don't actually need to do that.",
        "tokens": [
          50814,
          583,
          337,
          445,
          5006,
          264,
          31875,
          3100,
          11,
          286,
          500,
          380,
          767,
          643,
          281,
          360,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19389951551282728,
        "compression_ratio": 1.6716981132075472,
        "end": 5638.6,
        "id": 1708,
        "no_speech_prob": 0.013848376460373402,
        "seek": 562160,
        "start": 5633.6,
        "temperature": 0,
        "text": " So, let's say that actor one, let's say actor four is actually Kevin Bacon.",
        "tokens": [
          50964,
          407,
          11,
          718,
          311,
          584,
          300,
          8747,
          472,
          11,
          718,
          311,
          584,
          8747,
          1451,
          307,
          767,
          9954,
          42460,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19389951551282728,
        "compression_ratio": 1.6716981132075472,
        "end": 5646.6,
        "id": 1709,
        "no_speech_prob": 0.013848376460373402,
        "seek": 562160,
        "start": 5640.6,
        "temperature": 0,
        "text": " So, what the breadth-first search algorithm looks to do",
        "tokens": [
          51314,
          407,
          11,
          437,
          264,
          35862,
          12,
          29581,
          3164,
          9284,
          1542,
          281,
          360,
          51614
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5651.6,
        "id": 1710,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5646.6,
        "temperature": 0,
        "text": " is I want to pick any actor and find the shortest route to get to Kevin Bacon.",
        "tokens": [
          50364,
          307,
          286,
          528,
          281,
          1888,
          604,
          8747,
          293,
          915,
          264,
          31875,
          7955,
          281,
          483,
          281,
          9954,
          42460,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5656.6,
        "id": 1711,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5651.6,
        "temperature": 0,
        "text": " And this, we can see here is actor two was in movie two with Kevin Bacon.",
        "tokens": [
          50614,
          400,
          341,
          11,
          321,
          393,
          536,
          510,
          307,
          8747,
          732,
          390,
          294,
          3169,
          732,
          365,
          9954,
          42460,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5659.6,
        "id": 1712,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5656.6,
        "temperature": 0,
        "text": " Actor three was in movie two with Kevin Bacon.",
        "tokens": [
          50864,
          45457,
          1045,
          390,
          294,
          3169,
          732,
          365,
          9954,
          42460,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5660.6,
        "id": 1713,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5659.6,
        "temperature": 0,
        "text": " Or, this is the same distance.",
        "tokens": [
          51014,
          1610,
          11,
          341,
          307,
          264,
          912,
          4560,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5662.6,
        "id": 1714,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5660.6,
        "temperature": 0,
        "text": " Actor five was in movie three with Kevin Bacon.",
        "tokens": [
          51064,
          45457,
          1732,
          390,
          294,
          3169,
          1045,
          365,
          9954,
          42460,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5669.6,
        "id": 1715,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5662.6,
        "temperature": 0,
        "text": " And actor one was in movie one with actor three, who was in movie two with Kevin Bacon.",
        "tokens": [
          51164,
          400,
          8747,
          472,
          390,
          294,
          3169,
          472,
          365,
          8747,
          1045,
          11,
          567,
          390,
          294,
          3169,
          732,
          365,
          9954,
          42460,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5671.6,
        "id": 1716,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5669.6,
        "temperature": 0,
        "text": " So, there's not a lot of possibilities here.",
        "tokens": [
          51514,
          407,
          11,
          456,
          311,
          406,
          257,
          688,
          295,
          12178,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19124529438634072,
        "compression_ratio": 2.0472103004291844,
        "end": 5675.6,
        "id": 1717,
        "no_speech_prob": 0.0013670206535607576,
        "seek": 564660,
        "start": 5671.6,
        "temperature": 0,
        "text": " But you could imagine a much more complex interconnected network.",
        "tokens": [
          51614,
          583,
          291,
          727,
          3811,
          257,
          709,
          544,
          3997,
          36611,
          3209,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21164110544565562,
        "compression_ratio": 1.6371308016877637,
        "end": 5679.6,
        "id": 1718,
        "no_speech_prob": 0.000030241950298659503,
        "seek": 567560,
        "start": 5675.6,
        "temperature": 0,
        "text": " And if you think about actors in all the movies they've been in, in full cast lists, it's massive.",
        "tokens": [
          50364,
          400,
          498,
          291,
          519,
          466,
          10037,
          294,
          439,
          264,
          6233,
          436,
          600,
          668,
          294,
          11,
          294,
          1577,
          4193,
          14511,
          11,
          309,
          311,
          5994,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21164110544565562,
        "compression_ratio": 1.6371308016877637,
        "end": 5686.6,
        "id": 1719,
        "no_speech_prob": 0.000030241950298659503,
        "seek": 567560,
        "start": 5679.6,
        "temperature": 0,
        "text": " Okay. So, now, let's come back here.",
        "tokens": [
          50564,
          1033,
          13,
          407,
          11,
          586,
          11,
          718,
          311,
          808,
          646,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21164110544565562,
        "compression_ratio": 1.6371308016877637,
        "end": 5690.6,
        "id": 1720,
        "no_speech_prob": 0.000030241950298659503,
        "seek": 567560,
        "start": 5686.6,
        "temperature": 0,
        "text": " Okay. So, now what I need to do is actually implement the breadth-first search algorithm.",
        "tokens": [
          50914,
          1033,
          13,
          407,
          11,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          767,
          4445,
          264,
          35862,
          12,
          29581,
          3164,
          9284,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21164110544565562,
        "compression_ratio": 1.6371308016877637,
        "end": 5697.6,
        "id": 1721,
        "no_speech_prob": 0.000030241950298659503,
        "seek": 567560,
        "start": 5690.6,
        "temperature": 0,
        "text": " Now, before I do that, I need to add a beginning and end.",
        "tokens": [
          51114,
          823,
          11,
          949,
          286,
          360,
          300,
          11,
          286,
          643,
          281,
          909,
          257,
          2863,
          293,
          917,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21164110544565562,
        "compression_ratio": 1.6371308016877637,
        "end": 5699.6,
        "id": 1722,
        "no_speech_prob": 0.000030241950298659503,
        "seek": 567560,
        "start": 5697.6,
        "temperature": 0,
        "text": " So, I need somewhere to start and somewhere I want to finish.",
        "tokens": [
          51464,
          407,
          11,
          286,
          643,
          4079,
          281,
          722,
          293,
          4079,
          286,
          528,
          281,
          2413,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21164110544565562,
        "compression_ratio": 1.6371308016877637,
        "end": 5702.6,
        "id": 1723,
        "no_speech_prob": 0.000030241950298659503,
        "seek": 567560,
        "start": 5699.6,
        "temperature": 0,
        "text": " So, always, the graph always wants to end.",
        "tokens": [
          51564,
          407,
          11,
          1009,
          11,
          264,
          4295,
          1009,
          2738,
          281,
          917,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19707234700520834,
        "compression_ratio": 1.6623376623376624,
        "end": 5710.6,
        "id": 1724,
        "no_speech_prob": 0.030675508081912994,
        "seek": 570260,
        "start": 5702.6,
        "temperature": 0,
        "text": " And I'm going to have a graph have this.end and this.start.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          362,
          257,
          4295,
          362,
          341,
          13,
          521,
          293,
          341,
          13,
          24419,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19707234700520834,
        "compression_ratio": 1.6623376623376624,
        "end": 5714.6,
        "id": 1725,
        "no_speech_prob": 0.030675508081912994,
        "seek": 570260,
        "start": 5710.6,
        "temperature": 0,
        "text": " So, I'm going to give the graph object an end and a start node.",
        "tokens": [
          50764,
          407,
          11,
          286,
          478,
          516,
          281,
          976,
          264,
          4295,
          2657,
          364,
          917,
          293,
          257,
          722,
          9984,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19707234700520834,
        "compression_ratio": 1.6623376623376624,
        "end": 5727.6,
        "id": 1726,
        "no_speech_prob": 0.030675508081912994,
        "seek": 570260,
        "start": 5714.6,
        "temperature": 0,
        "text": " And what I'm going to do is after I've added all the data, I mean, I'm just going to hard code this in, which is a little bit silly.",
        "tokens": [
          50964,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          934,
          286,
          600,
          3869,
          439,
          264,
          1412,
          11,
          286,
          914,
          11,
          286,
          478,
          445,
          516,
          281,
          1152,
          3089,
          341,
          294,
          11,
          597,
          307,
          257,
          707,
          857,
          11774,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1977947483892026,
        "compression_ratio": 1.625,
        "end": 5734.6,
        "id": 1727,
        "no_speech_prob": 0.00806185882538557,
        "seek": 572760,
        "start": 5727.6,
        "temperature": 0,
        "text": " And I'm going to say graph.set and I'll just do it this way.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          584,
          4295,
          13,
          3854,
          293,
          286,
          603,
          445,
          360,
          309,
          341,
          636,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1977947483892026,
        "compression_ratio": 1.625,
        "end": 5739.6,
        "id": 1728,
        "no_speech_prob": 0.00806185882538557,
        "seek": 572760,
        "start": 5734.6,
        "temperature": 0,
        "text": " Set and Kevin Bacon and graph.set.start.",
        "tokens": [
          50714,
          8928,
          293,
          9954,
          42460,
          293,
          4295,
          13,
          3854,
          13,
          24419,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1977947483892026,
        "compression_ratio": 1.625,
        "end": 5746.6,
        "id": 1729,
        "no_speech_prob": 0.00806185882538557,
        "seek": 572760,
        "start": 5739.6,
        "temperature": 0,
        "text": " Let's just pick some actor from, whoops, let's pick some actor from that list.",
        "tokens": [
          50964,
          961,
          311,
          445,
          1888,
          512,
          8747,
          490,
          11,
          567,
          3370,
          11,
          718,
          311,
          1888,
          512,
          8747,
          490,
          300,
          1329,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1977947483892026,
        "compression_ratio": 1.625,
        "end": 5749.6,
        "id": 1730,
        "no_speech_prob": 0.00806185882538557,
        "seek": 572760,
        "start": 5746.6,
        "temperature": 0,
        "text": " Wasn't Mickey Rourke in that list? Let's see if I get this right.",
        "tokens": [
          51314,
          28782,
          380,
          24714,
          497,
          396,
          330,
          294,
          300,
          1329,
          30,
          961,
          311,
          536,
          498,
          286,
          483,
          341,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1977947483892026,
        "compression_ratio": 1.625,
        "end": 5753.6,
        "id": 1731,
        "no_speech_prob": 0.00806185882538557,
        "seek": 572760,
        "start": 5749.6,
        "temperature": 0,
        "text": " So, Mickey Rourke to Kevin Bacon. Okay.",
        "tokens": [
          51464,
          407,
          11,
          24714,
          497,
          396,
          330,
          281,
          9954,
          42460,
          13,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2481659279494989,
        "compression_ratio": 1.648,
        "end": 5760.6,
        "id": 1732,
        "no_speech_prob": 0.013020324520766735,
        "seek": 575360,
        "start": 5754.6,
        "temperature": 0,
        "text": " So, now I'm going to go and in graph, I need to add those functions, set start.",
        "tokens": [
          50414,
          407,
          11,
          586,
          286,
          478,
          516,
          281,
          352,
          293,
          294,
          4295,
          11,
          286,
          643,
          281,
          909,
          729,
          6828,
          11,
          992,
          722,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2481659279494989,
        "compression_ratio": 1.648,
        "end": 5775.6,
        "id": 1733,
        "no_speech_prob": 0.013020324520766735,
        "seek": 575360,
        "start": 5760.6,
        "temperature": 0,
        "text": " Set start equals function and I'm going to say actor and then I'm going to say set end.",
        "tokens": [
          50714,
          8928,
          722,
          6915,
          2445,
          293,
          286,
          478,
          516,
          281,
          584,
          8747,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          992,
          917,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2481659279494989,
        "compression_ratio": 1.648,
        "end": 5780.6,
        "id": 1734,
        "no_speech_prob": 0.013020324520766735,
        "seek": 575360,
        "start": 5775.6,
        "temperature": 0,
        "text": " And then this.start equals this.graph.",
        "tokens": [
          51464,
          400,
          550,
          341,
          13,
          24419,
          6915,
          341,
          13,
          34091,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19125650910770192,
        "compression_ratio": 1.9299610894941635,
        "end": 5786.6,
        "id": 1735,
        "no_speech_prob": 0.07263483107089996,
        "seek": 578060,
        "start": 5780.6,
        "temperature": 0,
        "text": " Now, if the actor doesn't exist, we're going to have a problem, but I'm just going to assume that actor does exist.",
        "tokens": [
          50364,
          823,
          11,
          498,
          264,
          8747,
          1177,
          380,
          2514,
          11,
          321,
          434,
          516,
          281,
          362,
          257,
          1154,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          6552,
          300,
          8747,
          775,
          2514,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19125650910770192,
        "compression_ratio": 1.9299610894941635,
        "end": 5789.6,
        "id": 1736,
        "no_speech_prob": 0.07263483107089996,
        "seek": 578060,
        "start": 5786.6,
        "temperature": 0,
        "text": " So, I want to pull, I need to get the node.",
        "tokens": [
          50664,
          407,
          11,
          286,
          528,
          281,
          2235,
          11,
          286,
          643,
          281,
          483,
          264,
          9984,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19125650910770192,
        "compression_ratio": 1.9299610894941635,
        "end": 5797.6,
        "id": 1737,
        "no_speech_prob": 0.07263483107089996,
        "seek": 578060,
        "start": 5789.6,
        "temperature": 0,
        "text": " I mean, maybe I could just keep it as a string, but I want to get the node, the particular node that is the start associated with that actor and the particular node that is the end associated with that actor.",
        "tokens": [
          50814,
          286,
          914,
          11,
          1310,
          286,
          727,
          445,
          1066,
          309,
          382,
          257,
          6798,
          11,
          457,
          286,
          528,
          281,
          483,
          264,
          9984,
          11,
          264,
          1729,
          9984,
          300,
          307,
          264,
          722,
          6615,
          365,
          300,
          8747,
          293,
          264,
          1729,
          9984,
          300,
          307,
          264,
          917,
          6615,
          365,
          300,
          8747,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19125650910770192,
        "compression_ratio": 1.9299610894941635,
        "end": 5799.6,
        "id": 1738,
        "no_speech_prob": 0.07263483107089996,
        "seek": 578060,
        "start": 5797.6,
        "temperature": 0,
        "text": " Okay. We've got that.",
        "tokens": [
          51214,
          1033,
          13,
          492,
          600,
          658,
          300,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19125650910770192,
        "compression_ratio": 1.9299610894941635,
        "end": 5801.6,
        "id": 1739,
        "no_speech_prob": 0.07263483107089996,
        "seek": 578060,
        "start": 5799.6,
        "temperature": 0,
        "text": " I should have put that in the last video, but we've got that.",
        "tokens": [
          51314,
          286,
          820,
          362,
          829,
          300,
          294,
          264,
          1036,
          960,
          11,
          457,
          321,
          600,
          658,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19125650910770192,
        "compression_ratio": 1.9299610894941635,
        "end": 5805.6,
        "id": 1740,
        "no_speech_prob": 0.07263483107089996,
        "seek": 578060,
        "start": 5801.6,
        "temperature": 0,
        "text": " Now, we are ready for breadth-first search.",
        "tokens": [
          51414,
          823,
          11,
          321,
          366,
          1919,
          337,
          35862,
          12,
          29581,
          3164,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16175658411259275,
        "compression_ratio": 1.8512110726643598,
        "end": 5820.6,
        "id": 1741,
        "no_speech_prob": 0.4454796314239502,
        "seek": 580560,
        "start": 5805.6,
        "temperature": 0,
        "text": " So, I'm going to use, I'm just going to pull, I referenced before this book, which is a really great visual explanation, grokking algorithms of this particular algorithm, but I'm just going to try to write the algorithm from the Wikipedia page.",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          516,
          281,
          764,
          11,
          286,
          478,
          445,
          516,
          281,
          2235,
          11,
          286,
          32734,
          949,
          341,
          1446,
          11,
          597,
          307,
          257,
          534,
          869,
          5056,
          10835,
          11,
          4634,
          74,
          5092,
          14642,
          295,
          341,
          1729,
          9284,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          853,
          281,
          2464,
          264,
          9284,
          490,
          264,
          28999,
          3028,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16175658411259275,
        "compression_ratio": 1.8512110726643598,
        "end": 5823.6,
        "id": 1742,
        "no_speech_prob": 0.4454796314239502,
        "seek": 580560,
        "start": 5820.6,
        "temperature": 0,
        "text": " But, you know, I could also just explain it to you.",
        "tokens": [
          51114,
          583,
          11,
          291,
          458,
          11,
          286,
          727,
          611,
          445,
          2903,
          309,
          281,
          291,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16175658411259275,
        "compression_ratio": 1.8512110726643598,
        "end": 5831.6,
        "id": 1743,
        "no_speech_prob": 0.4454796314239502,
        "seek": 580560,
        "start": 5823.6,
        "temperature": 0,
        "text": " So, what we're going to do if we're starting with an actor is we're just going to say breadth-first search means check every single edge connected to this actor.",
        "tokens": [
          51264,
          407,
          11,
          437,
          321,
          434,
          516,
          281,
          360,
          498,
          321,
          434,
          2891,
          365,
          364,
          8747,
          307,
          321,
          434,
          445,
          516,
          281,
          584,
          35862,
          12,
          29581,
          3164,
          1355,
          1520,
          633,
          2167,
          4691,
          4582,
          281,
          341,
          8747,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16175658411259275,
        "compression_ratio": 1.8512110726643598,
        "end": 5832.6,
        "id": 1744,
        "no_speech_prob": 0.4454796314239502,
        "seek": 580560,
        "start": 5831.6,
        "temperature": 0,
        "text": " Is that Kevin Bacon? No.",
        "tokens": [
          51664,
          1119,
          300,
          9954,
          42460,
          30,
          883,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16175658411259275,
        "compression_ratio": 1.8512110726643598,
        "end": 5833.6,
        "id": 1745,
        "no_speech_prob": 0.4454796314239502,
        "seek": 580560,
        "start": 5832.6,
        "temperature": 0,
        "text": " Is that Kevin Bacon? No.",
        "tokens": [
          51714,
          1119,
          300,
          9954,
          42460,
          30,
          883,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16175658411259275,
        "compression_ratio": 1.8512110726643598,
        "end": 5834.6,
        "id": 1746,
        "no_speech_prob": 0.4454796314239502,
        "seek": 580560,
        "start": 5833.6,
        "temperature": 0,
        "text": " Is that Kevin Bacon? Nope.",
        "tokens": [
          51764,
          1119,
          300,
          9954,
          42460,
          30,
          12172,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17871714083947868,
        "compression_ratio": 1.845,
        "end": 5840.6,
        "id": 1747,
        "no_speech_prob": 0.00793795008212328,
        "seek": 583460,
        "start": 5834.6,
        "temperature": 0,
        "text": " So, all of these that aren't Kevin Bacon should get added to something called a queue.",
        "tokens": [
          50364,
          407,
          11,
          439,
          295,
          613,
          300,
          3212,
          380,
          9954,
          42460,
          820,
          483,
          3869,
          281,
          746,
          1219,
          257,
          18639,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17871714083947868,
        "compression_ratio": 1.845,
        "end": 5848.6,
        "id": 1748,
        "no_speech_prob": 0.00793795008212328,
        "seek": 583460,
        "start": 5840.6,
        "temperature": 0,
        "text": " A queue is a kind of data structure that's first in, first out.",
        "tokens": [
          50664,
          316,
          18639,
          307,
          257,
          733,
          295,
          1412,
          3877,
          300,
          311,
          700,
          294,
          11,
          700,
          484,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17871714083947868,
        "compression_ratio": 1.845,
        "end": 5851.6,
        "id": 1749,
        "no_speech_prob": 0.00793795008212328,
        "seek": 583460,
        "start": 5848.6,
        "temperature": 0,
        "text": " So, it's like lining up to buy tickets.",
        "tokens": [
          51064,
          407,
          11,
          309,
          311,
          411,
          19628,
          493,
          281,
          2256,
          12628,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17871714083947868,
        "compression_ratio": 1.845,
        "end": 5853.6,
        "id": 1750,
        "no_speech_prob": 0.00793795008212328,
        "seek": 583460,
        "start": 5851.6,
        "temperature": 0,
        "text": " If you've gotten line first, you get to buy the first ticket.",
        "tokens": [
          51214,
          759,
          291,
          600,
          5768,
          1622,
          700,
          11,
          291,
          483,
          281,
          2256,
          264,
          700,
          10550,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17871714083947868,
        "compression_ratio": 1.845,
        "end": 5857.6,
        "id": 1751,
        "no_speech_prob": 0.00793795008212328,
        "seek": 583460,
        "start": 5853.6,
        "temperature": 0,
        "text": " So, if this is not Kevin Bacon, it gets added to the queue.",
        "tokens": [
          51314,
          407,
          11,
          498,
          341,
          307,
          406,
          9954,
          42460,
          11,
          309,
          2170,
          3869,
          281,
          264,
          18639,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17871714083947868,
        "compression_ratio": 1.845,
        "end": 5861.6,
        "id": 1752,
        "no_speech_prob": 0.00793795008212328,
        "seek": 583460,
        "start": 5857.6,
        "temperature": 0,
        "text": " Then, M2 is not Kevin Bacon, it gets added to the queue.",
        "tokens": [
          51514,
          1396,
          11,
          376,
          17,
          307,
          406,
          9954,
          42460,
          11,
          309,
          2170,
          3869,
          281,
          264,
          18639,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5869.6,
        "id": 1753,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5861.6,
        "temperature": 0,
        "text": " Now, when I'm done checking all those edges, I go to the queue and take the first thing off, which is M1, and check all its edges.",
        "tokens": [
          50364,
          823,
          11,
          562,
          286,
          478,
          1096,
          8568,
          439,
          729,
          8819,
          11,
          286,
          352,
          281,
          264,
          18639,
          293,
          747,
          264,
          700,
          551,
          766,
          11,
          597,
          307,
          376,
          16,
          11,
          293,
          1520,
          439,
          1080,
          8819,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5872.6,
        "id": 1754,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5869.6,
        "temperature": 0,
        "text": " Well, I don't have to check that anymore because it's been checked.",
        "tokens": [
          50764,
          1042,
          11,
          286,
          500,
          380,
          362,
          281,
          1520,
          300,
          3602,
          570,
          309,
          311,
          668,
          10033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5876.6,
        "id": 1755,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5872.6,
        "temperature": 0,
        "text": " So, I've got to mark things checked when I check them, and then I've got to check its edges.",
        "tokens": [
          50914,
          407,
          11,
          286,
          600,
          658,
          281,
          1491,
          721,
          10033,
          562,
          286,
          1520,
          552,
          11,
          293,
          550,
          286,
          600,
          658,
          281,
          1520,
          1080,
          8819,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5878.6,
        "id": 1756,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5876.6,
        "temperature": 0,
        "text": " Nope. So, that's not it.",
        "tokens": [
          51114,
          12172,
          13,
          407,
          11,
          300,
          311,
          406,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5879.6,
        "id": 1757,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5878.6,
        "temperature": 0,
        "text": " So, this goes off the queue.",
        "tokens": [
          51214,
          407,
          11,
          341,
          1709,
          766,
          264,
          18639,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5880.6,
        "id": 1758,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5879.6,
        "temperature": 0,
        "text": " Now, this is next.",
        "tokens": [
          51264,
          823,
          11,
          341,
          307,
          958,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5884.6,
        "id": 1759,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5880.6,
        "temperature": 0,
        "text": " A1 actually then gets added to the queue as well.",
        "tokens": [
          51314,
          316,
          16,
          767,
          550,
          2170,
          3869,
          281,
          264,
          18639,
          382,
          731,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5887.6,
        "id": 1760,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5884.6,
        "temperature": 0,
        "text": " Then, M2 I've got to check all its edges.",
        "tokens": [
          51514,
          1396,
          11,
          376,
          17,
          286,
          600,
          658,
          281,
          1520,
          439,
          1080,
          8819,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19650108749802048,
        "compression_ratio": 1.867704280155642,
        "end": 5888.6,
        "id": 1761,
        "no_speech_prob": 0.30072444677352905,
        "seek": 586160,
        "start": 5887.6,
        "temperature": 0,
        "text": " That's not Kevin Bacon.",
        "tokens": [
          51664,
          663,
          311,
          406,
          9954,
          42460,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5889.6,
        "id": 1762,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5888.6,
        "temperature": 0,
        "text": " It's been checked. It's been checked.",
        "tokens": [
          50364,
          467,
          311,
          668,
          10033,
          13,
          467,
          311,
          668,
          10033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5891.6,
        "id": 1763,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5889.6,
        "temperature": 0,
        "text": " Oh, that's Kevin Bacon.",
        "tokens": [
          50414,
          876,
          11,
          300,
          311,
          9954,
          42460,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5892.6,
        "id": 1764,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5891.6,
        "temperature": 0,
        "text": " I'm done.",
        "tokens": [
          50514,
          286,
          478,
          1096,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5893.6,
        "id": 1765,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5892.6,
        "temperature": 0,
        "text": " So, now I'm done.",
        "tokens": [
          50564,
          407,
          11,
          586,
          286,
          478,
          1096,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5902.6,
        "id": 1766,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5893.6,
        "temperature": 0,
        "text": " And, all the while I was doing this, by the way, I was keeping track that M2 came from actor 3, and then Kevin Bacon came from actor 4,",
        "tokens": [
          50614,
          400,
          11,
          439,
          264,
          1339,
          286,
          390,
          884,
          341,
          11,
          538,
          264,
          636,
          11,
          286,
          390,
          5145,
          2837,
          300,
          376,
          17,
          1361,
          490,
          8747,
          805,
          11,
          293,
          550,
          9954,
          42460,
          1361,
          490,
          8747,
          1017,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5906.6,
        "id": 1767,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5902.6,
        "temperature": 0,
        "text": " so that I will then be able to back up and create a list, a path of those nodes.",
        "tokens": [
          51064,
          370,
          300,
          286,
          486,
          550,
          312,
          1075,
          281,
          646,
          493,
          293,
          1884,
          257,
          1329,
          11,
          257,
          3100,
          295,
          729,
          13891,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5910.6,
        "id": 1768,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5906.6,
        "temperature": 0,
        "text": " So, the idea is check everything nearest and add that to a queue.",
        "tokens": [
          51264,
          407,
          11,
          264,
          1558,
          307,
          1520,
          1203,
          23831,
          293,
          909,
          300,
          281,
          257,
          18639,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5914.6,
        "id": 1769,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5910.6,
        "temperature": 0,
        "text": " And, when you're done checking everything nearest, just keep pulling from the queue to check what's nearest to that,",
        "tokens": [
          51464,
          400,
          11,
          562,
          291,
          434,
          1096,
          8568,
          1203,
          23831,
          11,
          445,
          1066,
          8407,
          490,
          264,
          18639,
          281,
          1520,
          437,
          311,
          23831,
          281,
          300,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.23049545288085938,
        "compression_ratio": 1.917857142857143,
        "end": 5916.6,
        "id": 1770,
        "no_speech_prob": 0.06371081620454788,
        "seek": 588860,
        "start": 5914.6,
        "temperature": 0,
        "text": " and keep going until you find the nearest node.",
        "tokens": [
          51664,
          293,
          1066,
          516,
          1826,
          291,
          915,
          264,
          23831,
          9984,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5919.6,
        "id": 1771,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5916.6,
        "temperature": 0,
        "text": " Check what's nearest to that, and keep going until you find Kevin Bacon.",
        "tokens": [
          50364,
          6881,
          437,
          311,
          23831,
          281,
          300,
          11,
          293,
          1066,
          516,
          1826,
          291,
          915,
          9954,
          42460,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5920.6,
        "id": 1772,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5919.6,
        "temperature": 0,
        "text": " Okay?",
        "tokens": [
          50514,
          1033,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5923.6,
        "id": 1773,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5920.6,
        "temperature": 0,
        "text": " So, hopefully that helps you understand it a little bit.",
        "tokens": [
          50564,
          407,
          11,
          4696,
          300,
          3665,
          291,
          1223,
          309,
          257,
          707,
          857,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5924.6,
        "id": 1774,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5923.6,
        "temperature": 0,
        "text": " And, now we're going to...",
        "tokens": [
          50714,
          400,
          11,
          586,
          321,
          434,
          516,
          281,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5925.6,
        "id": 1775,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5924.6,
        "temperature": 0,
        "text": " Now, okay.",
        "tokens": [
          50764,
          823,
          11,
          1392,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5927.6,
        "id": 1776,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5925.6,
        "temperature": 0,
        "text": " So, empty set S.",
        "tokens": [
          50814,
          407,
          11,
          6707,
          992,
          318,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5934.6,
        "id": 1777,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5927.6,
        "temperature": 0,
        "text": " The way that this is described on Wikipedia is to keep a separate list or set of things that have already been searched.",
        "tokens": [
          50914,
          440,
          636,
          300,
          341,
          307,
          7619,
          322,
          28999,
          307,
          281,
          1066,
          257,
          4994,
          1329,
          420,
          992,
          295,
          721,
          300,
          362,
          1217,
          668,
          22961,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5936.6,
        "id": 1778,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5934.6,
        "temperature": 0,
        "text": " But, I'm going to do this a little bit differently.",
        "tokens": [
          51264,
          583,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          257,
          707,
          857,
          7614,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5941.6,
        "id": 1779,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5936.6,
        "temperature": 0,
        "text": " In my node object, I have a Boolean to keep track of whether it's been searched or not.",
        "tokens": [
          51364,
          682,
          452,
          9984,
          2657,
          11,
          286,
          362,
          257,
          23351,
          28499,
          281,
          1066,
          2837,
          295,
          1968,
          309,
          311,
          668,
          22961,
          420,
          406,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5943.6,
        "id": 1780,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5941.6,
        "temperature": 0,
        "text": " So, I can just flag it when it's been searched.",
        "tokens": [
          51614,
          407,
          11,
          286,
          393,
          445,
          7166,
          309,
          562,
          309,
          311,
          668,
          22961,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17536482041881932,
        "compression_ratio": 1.691358024691358,
        "end": 5945.6,
        "id": 1781,
        "no_speech_prob": 0.24506108462810516,
        "seek": 591660,
        "start": 5943.6,
        "temperature": 0,
        "text": " I don't need a separate data structure for that.",
        "tokens": [
          51714,
          286,
          500,
          380,
          643,
          257,
          4994,
          1412,
          3877,
          337,
          300,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5947.6,
        "id": 1782,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5945.6,
        "temperature": 0,
        "text": " But, I do need a queue.",
        "tokens": [
          50364,
          583,
          11,
          286,
          360,
          643,
          257,
          18639,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5948.6,
        "id": 1783,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5947.6,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          50464,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5951.6,
        "id": 1784,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5948.6,
        "temperature": 0,
        "text": " I could actually implement a queue and have like...",
        "tokens": [
          50514,
          286,
          727,
          767,
          4445,
          257,
          18639,
          293,
          362,
          411,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5954.6,
        "id": 1785,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5951.6,
        "temperature": 0,
        "text": " In a fancy way, but I'm in JavaScript.",
        "tokens": [
          50664,
          682,
          257,
          10247,
          636,
          11,
          457,
          286,
          478,
          294,
          15778,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5956.6,
        "id": 1786,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5954.6,
        "temperature": 0,
        "text": " It's late. I'm tired.",
        "tokens": [
          50814,
          467,
          311,
          3469,
          13,
          286,
          478,
          5868,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5957.6,
        "id": 1787,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5956.6,
        "temperature": 0,
        "text": " I'm just going to use an array.",
        "tokens": [
          50914,
          286,
          478,
          445,
          516,
          281,
          764,
          364,
          10225,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5960.6,
        "id": 1788,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5957.6,
        "temperature": 0,
        "text": " Because, an array is something I can add to and I can pull off from the beginning.",
        "tokens": [
          50964,
          1436,
          11,
          364,
          10225,
          307,
          746,
          286,
          393,
          909,
          281,
          293,
          286,
          393,
          2235,
          766,
          490,
          264,
          2863,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5963.6,
        "id": 1789,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5960.6,
        "temperature": 0,
        "text": " So, what I'm going to do is I'm going to call it a queue.",
        "tokens": [
          51114,
          407,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          818,
          309,
          257,
          18639,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5968.6,
        "id": 1790,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5963.6,
        "temperature": 0,
        "text": " I'm going to say right down here, var q equals an array.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          584,
          558,
          760,
          510,
          11,
          1374,
          9505,
          6915,
          364,
          10225,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5969.6,
        "id": 1791,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5968.6,
        "temperature": 0,
        "text": " Okay?",
        "tokens": [
          51514,
          1033,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19922089402693033,
        "compression_ratio": 1.7131147540983607,
        "end": 5971.6,
        "id": 1792,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 594560,
        "start": 5969.6,
        "temperature": 0,
        "text": " Var q equals an array.",
        "tokens": [
          51564,
          14662,
          9505,
          6915,
          364,
          10225,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5973.6,
        "id": 1793,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5972.6,
        "temperature": 0,
        "text": " And then, what I'm going to do is...",
        "tokens": [
          50414,
          400,
          550,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5975.6,
        "id": 1794,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5973.6,
        "temperature": 0,
        "text": " Let's just keep following this algorithm.",
        "tokens": [
          50464,
          961,
          311,
          445,
          1066,
          3480,
          341,
          9284,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5977.6,
        "id": 1795,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5975.6,
        "temperature": 0,
        "text": " Okay. So, the root.",
        "tokens": [
          50564,
          1033,
          13,
          407,
          11,
          264,
          5593,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5978.6,
        "id": 1796,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5977.6,
        "temperature": 0,
        "text": " We got to start with the root.",
        "tokens": [
          50664,
          492,
          658,
          281,
          722,
          365,
          264,
          5593,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5979.6,
        "id": 1797,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5978.6,
        "temperature": 0,
        "text": " So, the root is the start.",
        "tokens": [
          50714,
          407,
          11,
          264,
          5593,
          307,
          264,
          722,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5982.6,
        "id": 1798,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5979.6,
        "temperature": 0,
        "text": " So, var start.",
        "tokens": [
          50764,
          407,
          11,
          1374,
          722,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5983.6,
        "id": 1799,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5982.6,
        "temperature": 0,
        "text": " This is a little silly.",
        "tokens": [
          50914,
          639,
          307,
          257,
          707,
          11774,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5984.6,
        "id": 1800,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5983.6,
        "temperature": 0,
        "text": " This is kind of redundant.",
        "tokens": [
          50964,
          639,
          307,
          733,
          295,
          40997,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5986.6,
        "id": 1801,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5984.6,
        "temperature": 0,
        "text": " But, graph.get.",
        "tokens": [
          51014,
          583,
          11,
          4295,
          13,
          847,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5990.6,
        "id": 1802,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5986.6,
        "temperature": 0,
        "text": " So, I should have this return the value.",
        "tokens": [
          51114,
          407,
          11,
          286,
          820,
          362,
          341,
          2736,
          264,
          2158,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5991.6,
        "id": 1803,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5990.6,
        "temperature": 0,
        "text": " Var start.",
        "tokens": [
          51314,
          14662,
          722,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5993.6,
        "id": 1804,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5991.6,
        "temperature": 0,
        "text": " Var end.",
        "tokens": [
          51364,
          14662,
          917,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 5995.6,
        "id": 1805,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5993.6,
        "temperature": 0,
        "text": " So, that way I can have a reference to it out here.",
        "tokens": [
          51464,
          407,
          11,
          300,
          636,
          286,
          393,
          362,
          257,
          6408,
          281,
          309,
          484,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20065470536549887,
        "compression_ratio": 1.7647058823529411,
        "end": 6000.6,
        "id": 1806,
        "no_speech_prob": 0.0003982127527706325,
        "seek": 597160,
        "start": 5995.6,
        "temperature": 0,
        "text": " So, I'm going to go to the graph and have it also return this.start.",
        "tokens": [
          51564,
          407,
          11,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          4295,
          293,
          362,
          309,
          611,
          2736,
          341,
          13,
          24419,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6003.6,
        "id": 1807,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6000.6,
        "temperature": 0,
        "text": " So, I can have the node return this.end.",
        "tokens": [
          50364,
          407,
          11,
          286,
          393,
          362,
          264,
          9984,
          2736,
          341,
          13,
          521,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6007.6,
        "id": 1808,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6003.6,
        "temperature": 0,
        "text": " And now, what I'm going to do is...",
        "tokens": [
          50514,
          400,
          586,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6009.6,
        "id": 1809,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6007.6,
        "temperature": 0,
        "text": " Now, I've got the start.",
        "tokens": [
          50714,
          823,
          11,
          286,
          600,
          658,
          264,
          722,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6011.6,
        "id": 1810,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6009.6,
        "temperature": 0,
        "text": " Let's look back at the algorithm.",
        "tokens": [
          50814,
          961,
          311,
          574,
          646,
          412,
          264,
          9284,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6013.6,
        "id": 1811,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6011.6,
        "temperature": 0,
        "text": " The start's parent is already null.",
        "tokens": [
          50914,
          440,
          722,
          311,
          2596,
          307,
          1217,
          18184,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6015.6,
        "id": 1812,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6013.6,
        "temperature": 0,
        "text": " Add root to s.",
        "tokens": [
          51014,
          5349,
          5593,
          281,
          262,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6017.6,
        "id": 1813,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6015.6,
        "temperature": 0,
        "text": " So, root's now going to be searched.",
        "tokens": [
          51114,
          407,
          11,
          5593,
          311,
          586,
          516,
          281,
          312,
          22961,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6020.6,
        "id": 1814,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6017.6,
        "temperature": 0,
        "text": " Start.searched equals true.",
        "tokens": [
          51214,
          6481,
          13,
          405,
          1178,
          292,
          6915,
          2074,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6021.6,
        "id": 1815,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6020.6,
        "temperature": 0,
        "text": " That's the first thing.",
        "tokens": [
          51364,
          663,
          311,
          264,
          700,
          551,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6022.6,
        "id": 1816,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6021.6,
        "temperature": 0,
        "text": " So, I don't need to add it to the set.",
        "tokens": [
          51414,
          407,
          11,
          286,
          500,
          380,
          643,
          281,
          909,
          309,
          281,
          264,
          992,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6024.6,
        "id": 1817,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6022.6,
        "temperature": 0,
        "text": " I'm just going to flag it as searched.",
        "tokens": [
          51464,
          286,
          478,
          445,
          516,
          281,
          7166,
          309,
          382,
          22961,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.14428115065080405,
        "compression_ratio": 1.6939655172413792,
        "end": 6027.6,
        "id": 1818,
        "no_speech_prob": 0.00024156607105396688,
        "seek": 600060,
        "start": 6024.6,
        "temperature": 0,
        "text": " Oh, then I need to add it to the queue.",
        "tokens": [
          51564,
          876,
          11,
          550,
          286,
          643,
          281,
          909,
          309,
          281,
          264,
          18639,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6031.6,
        "id": 1819,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6028.6,
        "temperature": 0,
        "text": " Queue.push the start.",
        "tokens": [
          50414,
          4493,
          622,
          13,
          79,
          1498,
          264,
          722,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6034.6,
        "id": 1820,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6031.6,
        "temperature": 0,
        "text": " So, now I'm adding it to the queue.",
        "tokens": [
          50564,
          407,
          11,
          586,
          286,
          478,
          5127,
          309,
          281,
          264,
          18639,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6036.6,
        "id": 1821,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6034.6,
        "temperature": 0,
        "text": " Okay, what else do I need to do?",
        "tokens": [
          50714,
          1033,
          11,
          437,
          1646,
          360,
          286,
          643,
          281,
          360,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6040.6,
        "id": 1822,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6036.6,
        "temperature": 0,
        "text": " Now, I'm going to keep going as long as the queue has stuff to look at.",
        "tokens": [
          50814,
          823,
          11,
          286,
          478,
          516,
          281,
          1066,
          516,
          382,
          938,
          382,
          264,
          18639,
          575,
          1507,
          281,
          574,
          412,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6043.6,
        "id": 1823,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6040.6,
        "temperature": 0,
        "text": " Now, it is possible that there is no connection.",
        "tokens": [
          51014,
          823,
          11,
          309,
          307,
          1944,
          300,
          456,
          307,
          572,
          4984,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6047.6,
        "id": 1824,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6043.6,
        "temperature": 0,
        "text": " So, you saw that in the quick demonstration in the previous video.",
        "tokens": [
          51164,
          407,
          11,
          291,
          1866,
          300,
          294,
          264,
          1702,
          16520,
          294,
          264,
          3894,
          960,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6048.6,
        "id": 1825,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6047.6,
        "temperature": 0,
        "text": " There could be infinity.",
        "tokens": [
          51364,
          821,
          727,
          312,
          13202,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6049.6,
        "id": 1826,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6048.6,
        "temperature": 0,
        "text": " There's no connection.",
        "tokens": [
          51414,
          821,
          311,
          572,
          4984,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1762563450129952,
        "compression_ratio": 1.7096774193548387,
        "end": 6055.6,
        "id": 1827,
        "no_speech_prob": 0.0006070740637369454,
        "seek": 602760,
        "start": 6049.6,
        "temperature": 0,
        "text": " But, as long as queue is not empty, which I could say is while queue.length is greater than zero.",
        "tokens": [
          51464,
          583,
          11,
          382,
          938,
          382,
          18639,
          307,
          406,
          6707,
          11,
          597,
          286,
          727,
          584,
          307,
          1339,
          18639,
          13,
          45390,
          307,
          5044,
          813,
          4018,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6057.6,
        "id": 1828,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6055.6,
        "temperature": 0,
        "text": " I'm sure there's a more elegant way to say that.",
        "tokens": [
          50364,
          286,
          478,
          988,
          456,
          311,
          257,
          544,
          21117,
          636,
          281,
          584,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6061.6,
        "id": 1829,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6057.6,
        "temperature": 0,
        "text": " Dequeue, which means get the first thing off the queue.",
        "tokens": [
          50464,
          1346,
          1077,
          622,
          11,
          597,
          1355,
          483,
          264,
          700,
          551,
          766,
          264,
          18639,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6065.6,
        "id": 1830,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6061.6,
        "temperature": 0,
        "text": " I think in JavaScript that is...",
        "tokens": [
          50664,
          286,
          519,
          294,
          15778,
          300,
          307,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6071.6,
        "id": 1831,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6065.6,
        "temperature": 0,
        "text": " I'm going to just call this current equals a queue.shift.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          445,
          818,
          341,
          2190,
          6915,
          257,
          18639,
          13,
          47445,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6073.6,
        "id": 1832,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6071.6,
        "temperature": 0,
        "text": " I think it's shift.",
        "tokens": [
          51164,
          286,
          519,
          309,
          311,
          5513,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6074.6,
        "id": 1833,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6073.6,
        "temperature": 0,
        "text": " Is that right?",
        "tokens": [
          51264,
          1119,
          300,
          558,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6075.6,
        "id": 1834,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6074.6,
        "temperature": 0,
        "text": " Hopefully, that's right.",
        "tokens": [
          51314,
          10429,
          11,
          300,
          311,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6077.6,
        "id": 1835,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6075.6,
        "temperature": 0,
        "text": " Somebody correct me if that's wrong.",
        "tokens": [
          51364,
          13463,
          3006,
          385,
          498,
          300,
          311,
          2085,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20950864396005306,
        "compression_ratio": 1.5622119815668203,
        "end": 6082.6,
        "id": 1836,
        "no_speech_prob": 0.0005976686952635646,
        "seek": 605560,
        "start": 6077.6,
        "temperature": 0,
        "text": " Okay, now, if current is the goal, we're done.",
        "tokens": [
          51464,
          1033,
          11,
          586,
          11,
          498,
          2190,
          307,
          264,
          3387,
          11,
          321,
          434,
          1096,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2734878613398625,
        "compression_ratio": 1.304,
        "end": 6084.6,
        "id": 1837,
        "no_speech_prob": 0.00029136970988474786,
        "seek": 608260,
        "start": 6082.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2734878613398625,
        "compression_ratio": 1.304,
        "end": 6097.6,
        "id": 1838,
        "no_speech_prob": 0.00029136970988474786,
        "seek": 608260,
        "start": 6084.6,
        "temperature": 0,
        "text": " If current equals end, console.log found.",
        "tokens": [
          50464,
          759,
          2190,
          6915,
          917,
          11,
          11076,
          13,
          4987,
          1352,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2734878613398625,
        "compression_ratio": 1.304,
        "end": 6103.6,
        "id": 1839,
        "no_speech_prob": 0.00029136970988474786,
        "seek": 608260,
        "start": 6097.6,
        "temperature": 0,
        "text": " And then, I'm going to say current.value.",
        "tokens": [
          51114,
          400,
          550,
          11,
          286,
          478,
          516,
          281,
          584,
          2190,
          13,
          29155,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2734878613398625,
        "compression_ratio": 1.304,
        "end": 6110.6,
        "id": 1840,
        "no_speech_prob": 0.00029136970988474786,
        "seek": 608260,
        "start": 6103.6,
        "temperature": 0,
        "text": " So, just to make sure this works, I'm going to set temporarily the start.",
        "tokens": [
          51414,
          407,
          11,
          445,
          281,
          652,
          988,
          341,
          1985,
          11,
          286,
          478,
          516,
          281,
          992,
          23750,
          264,
          722,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6112.6,
        "id": 1841,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6110.6,
        "temperature": 0,
        "text": " Also, to Kevin Bacon.",
        "tokens": [
          50364,
          2743,
          11,
          281,
          9954,
          42460,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6124.6,
        "id": 1842,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6112.6,
        "temperature": 0,
        "text": " Because now, when I run it, it should set it to searched, put it in the queue, get the first thing off the queue, and check to see if it's the end.",
        "tokens": [
          50464,
          1436,
          586,
          11,
          562,
          286,
          1190,
          309,
          11,
          309,
          820,
          992,
          309,
          281,
          22961,
          11,
          829,
          309,
          294,
          264,
          18639,
          11,
          483,
          264,
          700,
          551,
          766,
          264,
          18639,
          11,
          293,
          1520,
          281,
          536,
          498,
          309,
          311,
          264,
          917,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6126.6,
        "id": 1843,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6124.6,
        "temperature": 0,
        "text": " I don't know what this is here.",
        "tokens": [
          51064,
          286,
          500,
          380,
          458,
          437,
          341,
          307,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6128.6,
        "id": 1844,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6126.6,
        "temperature": 0,
        "text": " Okay, so let's run that.",
        "tokens": [
          51164,
          1033,
          11,
          370,
          718,
          311,
          1190,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6131.6,
        "id": 1845,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6128.6,
        "temperature": 0,
        "text": " Found Kevin Bacon.",
        "tokens": [
          51264,
          8207,
          9954,
          42460,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6132.6,
        "id": 1846,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6131.6,
        "temperature": 0,
        "text": " So, things are working.",
        "tokens": [
          51414,
          407,
          11,
          721,
          366,
          1364,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6134.6,
        "id": 1847,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6132.6,
        "temperature": 0,
        "text": " If the start and the end are equal, we're good.",
        "tokens": [
          51464,
          759,
          264,
          722,
          293,
          264,
          917,
          366,
          2681,
          11,
          321,
          434,
          665,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18342731154967692,
        "compression_ratio": 1.5492957746478873,
        "end": 6136.6,
        "id": 1848,
        "no_speech_prob": 0.0018675565952435136,
        "seek": 611060,
        "start": 6134.6,
        "temperature": 0,
        "text": " What's next?",
        "tokens": [
          51564,
          708,
          311,
          958,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6139.6,
        "id": 1849,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6137.6,
        "temperature": 0,
        "text": " I want to check.",
        "tokens": [
          50414,
          286,
          528,
          281,
          1520,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6142.6,
        "id": 1850,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6139.6,
        "temperature": 0,
        "text": " If it's not, I want to check all of the edges.",
        "tokens": [
          50514,
          759,
          309,
          311,
          406,
          11,
          286,
          528,
          281,
          1520,
          439,
          295,
          264,
          8819,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6145.6,
        "id": 1851,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6142.6,
        "temperature": 0,
        "text": " So, let's go through and say...",
        "tokens": [
          50664,
          407,
          11,
          718,
          311,
          352,
          807,
          293,
          584,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6148.6,
        "id": 1852,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6145.6,
        "temperature": 0,
        "text": " I probably want to say break here, too.",
        "tokens": [
          50814,
          286,
          1391,
          528,
          281,
          584,
          1821,
          510,
          11,
          886,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6151.6,
        "id": 1853,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6148.6,
        "temperature": 0,
        "text": " Break is a way of getting out of the loop once you're done.",
        "tokens": [
          50964,
          16925,
          307,
          257,
          636,
          295,
          1242,
          484,
          295,
          264,
          6367,
          1564,
          291,
          434,
          1096,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6156.6,
        "id": 1854,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6151.6,
        "temperature": 0,
        "text": " So, I want to say var edges equals current.edges.",
        "tokens": [
          51114,
          407,
          11,
          286,
          528,
          281,
          584,
          1374,
          8819,
          6915,
          2190,
          13,
          292,
          2880,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6159.6,
        "id": 1855,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6156.6,
        "temperature": 0,
        "text": " Then, I want to loop through all of the edges.",
        "tokens": [
          51364,
          1396,
          11,
          286,
          528,
          281,
          6367,
          807,
          439,
          295,
          264,
          8819,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.178680236522968,
        "compression_ratio": 1.8275862068965518,
        "end": 6164.6,
        "id": 1856,
        "no_speech_prob": 0.07263416051864624,
        "seek": 613660,
        "start": 6159.6,
        "temperature": 0,
        "text": " I want to check them all.",
        "tokens": [
          51514,
          286,
          528,
          281,
          1520,
          552,
          439,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2240471456242704,
        "compression_ratio": 1.5502958579881656,
        "end": 6167.6,
        "id": 1857,
        "no_speech_prob": 0.0038844558876007795,
        "seek": 616460,
        "start": 6164.6,
        "temperature": 0,
        "text": " First of all, I need to check.",
        "tokens": [
          50364,
          2386,
          295,
          439,
          11,
          286,
          643,
          281,
          1520,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2240471456242704,
        "compression_ratio": 1.5502958579881656,
        "end": 6175.6,
        "id": 1858,
        "no_speech_prob": 0.0038844558876007795,
        "seek": 616460,
        "start": 6167.6,
        "temperature": 0,
        "text": " Let's call this neighbor equals edges index i.",
        "tokens": [
          50514,
          961,
          311,
          818,
          341,
          5987,
          6915,
          8819,
          8186,
          741,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2240471456242704,
        "compression_ratio": 1.5502958579881656,
        "end": 6180.6,
        "id": 1859,
        "no_speech_prob": 0.0038844558876007795,
        "seek": 616460,
        "start": 6175.6,
        "temperature": 0,
        "text": " So, if neighbor.searched already, skip it.",
        "tokens": [
          50914,
          407,
          11,
          498,
          5987,
          13,
          405,
          1178,
          292,
          1217,
          11,
          10023,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2240471456242704,
        "compression_ratio": 1.5502958579881656,
        "end": 6183.6,
        "id": 1860,
        "no_speech_prob": 0.0038844558876007795,
        "seek": 616460,
        "start": 6180.6,
        "temperature": 0,
        "text": " Maybe I want to say if it's not been searched.",
        "tokens": [
          51164,
          2704,
          286,
          528,
          281,
          584,
          498,
          309,
          311,
          406,
          668,
          22961,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2240471456242704,
        "compression_ratio": 1.5502958579881656,
        "end": 6185.6,
        "id": 1861,
        "no_speech_prob": 0.0038844558876007795,
        "seek": 616460,
        "start": 6183.6,
        "temperature": 0,
        "text": " What does it say here?",
        "tokens": [
          51314,
          708,
          775,
          309,
          584,
          510,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.2240471456242704,
        "compression_ratio": 1.5502958579881656,
        "end": 6188.6,
        "id": 1862,
        "no_speech_prob": 0.0038844558876007795,
        "seek": 616460,
        "start": 6185.6,
        "temperature": 0,
        "text": " If it's not in S, it means it's not searched.",
        "tokens": [
          51414,
          759,
          309,
          311,
          406,
          294,
          318,
          11,
          309,
          1355,
          309,
          311,
          406,
          22961,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2240471456242704,
        "compression_ratio": 1.5502958579881656,
        "end": 6190.6,
        "id": 1863,
        "no_speech_prob": 0.0038844558876007795,
        "seek": 616460,
        "start": 6188.6,
        "temperature": 0,
        "text": " Now, it's being searched.",
        "tokens": [
          51564,
          823,
          11,
          309,
          311,
          885,
          22961,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6195.6,
        "id": 1864,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6190.6,
        "temperature": 0,
        "text": " So, I'm going to say neighbor.searched equals true.",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          516,
          281,
          584,
          5987,
          13,
          405,
          1178,
          292,
          6915,
          2074,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6197.6,
        "id": 1865,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6195.6,
        "temperature": 0,
        "text": " I'm checking it.",
        "tokens": [
          50614,
          286,
          478,
          8568,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6199.6,
        "id": 1866,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6197.6,
        "temperature": 0,
        "text": " Then, I also want to set its parent.",
        "tokens": [
          50714,
          1396,
          11,
          286,
          611,
          528,
          281,
          992,
          1080,
          2596,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6201.6,
        "id": 1867,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6199.6,
        "temperature": 0,
        "text": " Where did I just come from?",
        "tokens": [
          50814,
          2305,
          630,
          286,
          445,
          808,
          490,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6204.6,
        "id": 1868,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6201.6,
        "temperature": 0,
        "text": " Neighbor.parent equals current.",
        "tokens": [
          50914,
          47729,
          13,
          38321,
          6915,
          2190,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6206.6,
        "id": 1869,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6204.6,
        "temperature": 0,
        "text": " So, where did it just come from?",
        "tokens": [
          51064,
          407,
          11,
          689,
          630,
          309,
          445,
          808,
          490,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6209.6,
        "id": 1870,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6206.6,
        "temperature": 0,
        "text": " Then, I want to add it to the queue.",
        "tokens": [
          51164,
          1396,
          11,
          286,
          528,
          281,
          909,
          309,
          281,
          264,
          18639,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6211.6,
        "id": 1871,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6209.6,
        "temperature": 0,
        "text": " So, what's that?",
        "tokens": [
          51314,
          407,
          11,
          437,
          311,
          300,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6212.6,
        "id": 1872,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6211.6,
        "temperature": 0,
        "text": " Queue.push.",
        "tokens": [
          51414,
          4493,
          622,
          13,
          79,
          1498,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6214.6,
        "id": 1873,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6212.6,
        "temperature": 0,
        "text": " Push adds it to the end.",
        "tokens": [
          51464,
          18229,
          10860,
          309,
          281,
          264,
          917,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6216.6,
        "id": 1874,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6214.6,
        "temperature": 0,
        "text": " Neighbor.",
        "tokens": [
          51564,
          47729,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1855201248295051,
        "compression_ratio": 1.6829268292682926,
        "end": 6218.6,
        "id": 1875,
        "no_speech_prob": 0.020963070914149284,
        "seek": 619060,
        "start": 6216.6,
        "temperature": 0,
        "text": " So, we can see how this algorithm is working.",
        "tokens": [
          51664,
          407,
          11,
          321,
          393,
          536,
          577,
          341,
          9284,
          307,
          1364,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6220.6,
        "id": 1876,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6218.6,
        "temperature": 0,
        "text": " It's really very simple.",
        "tokens": [
          50364,
          467,
          311,
          534,
          588,
          2199,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6221.6,
        "id": 1877,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6220.6,
        "temperature": 0,
        "text": " It seems so complex.",
        "tokens": [
          50464,
          467,
          2544,
          370,
          3997,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6222.6,
        "id": 1878,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6221.6,
        "temperature": 0,
        "text": " It's such a fancy name.",
        "tokens": [
          50514,
          467,
          311,
          1270,
          257,
          10247,
          1315,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6225.6,
        "id": 1879,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6222.6,
        "temperature": 0,
        "text": " But, we're just saying start with the beginning.",
        "tokens": [
          50564,
          583,
          11,
          321,
          434,
          445,
          1566,
          722,
          365,
          264,
          2863,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6227.6,
        "id": 1880,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6225.6,
        "temperature": 0,
        "text": " Look at everything next to it.",
        "tokens": [
          50714,
          2053,
          412,
          1203,
          958,
          281,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6228.6,
        "id": 1881,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6227.6,
        "temperature": 0,
        "text": " Did you find it? Nope.",
        "tokens": [
          50814,
          2589,
          291,
          915,
          309,
          30,
          12172,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6229.6,
        "id": 1882,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6228.6,
        "temperature": 0,
        "text": " Look at everything next to that.",
        "tokens": [
          50864,
          2053,
          412,
          1203,
          958,
          281,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6231.6,
        "id": 1883,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6229.6,
        "temperature": 0,
        "text": " Did you find it? Nope.",
        "tokens": [
          50914,
          2589,
          291,
          915,
          309,
          30,
          12172,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6232.6,
        "id": 1884,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6231.6,
        "temperature": 0,
        "text": " Look at everything next to that.",
        "tokens": [
          51014,
          2053,
          412,
          1203,
          958,
          281,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6233.6,
        "id": 1885,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6232.6,
        "temperature": 0,
        "text": " Did you find it? Nope.",
        "tokens": [
          51064,
          2589,
          291,
          915,
          309,
          30,
          12172,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6236.6,
        "id": 1886,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6233.6,
        "temperature": 0,
        "text": " And, all the while, make sure you don't double check anything you've already checked before.",
        "tokens": [
          51114,
          400,
          11,
          439,
          264,
          1339,
          11,
          652,
          988,
          291,
          500,
          380,
          3834,
          1520,
          1340,
          291,
          600,
          1217,
          10033,
          949,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6239.6,
        "id": 1887,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6236.6,
        "temperature": 0,
        "text": " That's really all that's going on here.",
        "tokens": [
          51264,
          663,
          311,
          534,
          439,
          300,
          311,
          516,
          322,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6241.6,
        "id": 1888,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6239.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6244.6,
        "id": 1889,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6241.6,
        "temperature": 0,
        "text": " Now, let's see.",
        "tokens": [
          51514,
          823,
          11,
          718,
          311,
          536,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6246.6,
        "id": 1890,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6244.6,
        "temperature": 0,
        "text": " What am I missing?",
        "tokens": [
          51664,
          708,
          669,
          286,
          5361,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.17396035099661114,
        "compression_ratio": 1.9142857142857144,
        "end": 6247.6,
        "id": 1891,
        "no_speech_prob": 0.05749055743217468,
        "seek": 621860,
        "start": 6246.6,
        "temperature": 0,
        "text": " What else?",
        "tokens": [
          51764,
          708,
          1646,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6248.6,
        "id": 1892,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6247.6,
        "temperature": 0,
        "text": " Nothing.",
        "tokens": [
          50364,
          6693,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6249.6,
        "id": 1893,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6248.6,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50414,
          8239,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6251.6,
        "id": 1894,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6249.6,
        "temperature": 0,
        "text": " Let's run this.",
        "tokens": [
          50464,
          961,
          311,
          1190,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6255.6,
        "id": 1895,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6251.6,
        "temperature": 0,
        "text": " So, let's run this.",
        "tokens": [
          50564,
          407,
          11,
          718,
          311,
          1190,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6256.6,
        "id": 1896,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6255.6,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50764,
          1692,
          321,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6259.6,
        "id": 1897,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6256.6,
        "temperature": 0,
        "text": " Hey, found Kevin Bacon.",
        "tokens": [
          50814,
          1911,
          11,
          1352,
          9954,
          42460,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6264.6,
        "id": 1898,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6259.6,
        "temperature": 0,
        "text": " Now, let's change the start to Mickey Rourke.",
        "tokens": [
          50964,
          823,
          11,
          718,
          311,
          1319,
          264,
          722,
          281,
          24714,
          497,
          396,
          330,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6268.6,
        "id": 1899,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6264.6,
        "temperature": 0,
        "text": " Now, whenever I do these kind of things, I often end up with an infinite loop and the browser crashes.",
        "tokens": [
          51214,
          823,
          11,
          5699,
          286,
          360,
          613,
          733,
          295,
          721,
          11,
          286,
          2049,
          917,
          493,
          365,
          364,
          13785,
          6367,
          293,
          264,
          11185,
          28642,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6271.6,
        "id": 1900,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6268.6,
        "temperature": 0,
        "text": " Let's see if I made a mistake somewhere.",
        "tokens": [
          51414,
          961,
          311,
          536,
          498,
          286,
          1027,
          257,
          6146,
          4079,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6272.6,
        "id": 1901,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6271.6,
        "temperature": 0,
        "text": " And, let's see.",
        "tokens": [
          51564,
          400,
          11,
          718,
          311,
          536,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6273.6,
        "id": 1902,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6272.6,
        "temperature": 0,
        "text": " Nope.",
        "tokens": [
          51614,
          12172,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6274.6,
        "id": 1903,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6273.6,
        "temperature": 0,
        "text": " Found Kevin Bacon.",
        "tokens": [
          51664,
          8207,
          9954,
          42460,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1518082338220933,
        "compression_ratio": 1.5825688073394495,
        "end": 6276.6,
        "id": 1904,
        "no_speech_prob": 0.009859740734100342,
        "seek": 624760,
        "start": 6274.6,
        "temperature": 0,
        "text": " Now, is this really working?",
        "tokens": [
          51714,
          823,
          11,
          307,
          341,
          534,
          1364,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6278.6,
        "id": 1905,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6276.6,
        "temperature": 0,
        "text": " Let's look at...",
        "tokens": [
          50364,
          961,
          311,
          574,
          412,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6285.6,
        "id": 1906,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6278.6,
        "temperature": 0,
        "text": " So, let's, every time we check a node, let's console log it.",
        "tokens": [
          50464,
          407,
          11,
          718,
          311,
          11,
          633,
          565,
          321,
          1520,
          257,
          9984,
          11,
          718,
          311,
          11076,
          3565,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6289.6,
        "id": 1907,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6285.6,
        "temperature": 0,
        "text": " And, let's say console log dot value.",
        "tokens": [
          50814,
          400,
          11,
          718,
          311,
          584,
          11076,
          3565,
          5893,
          2158,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6294.6,
        "id": 1908,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6289.6,
        "temperature": 0,
        "text": " So, we checked Mickey Rourke, who's in Diner, and then we checked a bunch of actors.",
        "tokens": [
          51014,
          407,
          11,
          321,
          10033,
          24714,
          497,
          396,
          330,
          11,
          567,
          311,
          294,
          413,
          4564,
          11,
          293,
          550,
          321,
          10033,
          257,
          3840,
          295,
          10037,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6295.6,
        "id": 1909,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6294.6,
        "temperature": 0,
        "text": " Oh, and found Kevin Bacon, and we're done.",
        "tokens": [
          51264,
          876,
          11,
          293,
          1352,
          9954,
          42460,
          11,
          293,
          321,
          434,
          1096,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6296.6,
        "id": 1910,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6295.6,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51314,
          3769,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6301.6,
        "id": 1911,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6296.6,
        "temperature": 0,
        "text": " Let's use a different actor that is kind of further down here.",
        "tokens": [
          51364,
          961,
          311,
          764,
          257,
          819,
          8747,
          300,
          307,
          733,
          295,
          3052,
          760,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20404986331337377,
        "compression_ratio": 1.6444444444444444,
        "end": 6304.6,
        "id": 1912,
        "no_speech_prob": 0.027168530970811844,
        "seek": 627660,
        "start": 6301.6,
        "temperature": 0,
        "text": " These are actors that are in movies without Kevin Bacon.",
        "tokens": [
          51614,
          1981,
          366,
          10037,
          300,
          366,
          294,
          6233,
          1553,
          9954,
          42460,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6308.6,
        "id": 1913,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6304.6,
        "temperature": 0,
        "text": " So, let's pick Rachel McAdams.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          1888,
          14246,
          4050,
          15830,
          4070,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6311.6,
        "id": 1914,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6308.6,
        "temperature": 0,
        "text": " Wow, I think we might be done.",
        "tokens": [
          50564,
          3153,
          11,
          286,
          519,
          321,
          1062,
          312,
          1096,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6313.6,
        "id": 1915,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6311.6,
        "temperature": 0,
        "text": " We're going to add some more stuff to this in a second.",
        "tokens": [
          50714,
          492,
          434,
          516,
          281,
          909,
          512,
          544,
          1507,
          281,
          341,
          294,
          257,
          1150,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6317.6,
        "id": 1916,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6313.6,
        "temperature": 0,
        "text": " But, let's add set start Rachel McAdams.",
        "tokens": [
          50814,
          583,
          11,
          718,
          311,
          909,
          992,
          722,
          14246,
          4050,
          15830,
          4070,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6318.6,
        "id": 1917,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6317.6,
        "temperature": 0,
        "text": " We're not actually done.",
        "tokens": [
          51014,
          492,
          434,
          406,
          767,
          1096,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6320.6,
        "id": 1918,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6318.6,
        "temperature": 0,
        "text": " Ah, I copy pasted the wrong thing.",
        "tokens": [
          51064,
          2438,
          11,
          286,
          5055,
          1791,
          292,
          264,
          2085,
          551,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6321.6,
        "id": 1919,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6320.6,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51164,
          4919,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6323.6,
        "id": 1920,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6321.6,
        "temperature": 0,
        "text": " Rachel McAdams, sketch, Rachel.",
        "tokens": [
          51214,
          14246,
          4050,
          15830,
          4070,
          11,
          12325,
          11,
          14246,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6325.6,
        "id": 1921,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6323.6,
        "temperature": 0,
        "text": " Ah, why is this not working?",
        "tokens": [
          51314,
          2438,
          11,
          983,
          307,
          341,
          406,
          1364,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6326.6,
        "id": 1922,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6325.6,
        "temperature": 0,
        "text": " Why can I not copy paste?",
        "tokens": [
          51414,
          1545,
          393,
          286,
          406,
          5055,
          9163,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6329.6,
        "id": 1923,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6326.6,
        "temperature": 0,
        "text": " Ah, oh my goodness, I copy pasted the file.",
        "tokens": [
          51464,
          2438,
          11,
          1954,
          452,
          8387,
          11,
          286,
          5055,
          1791,
          292,
          264,
          3991,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23223597208658855,
        "compression_ratio": 1.7136752136752136,
        "end": 6332.6,
        "id": 1924,
        "no_speech_prob": 0.11595384776592255,
        "seek": 630460,
        "start": 6329.6,
        "temperature": 0,
        "text": " This is falling, everything's falling apart.",
        "tokens": [
          51614,
          639,
          307,
          7440,
          11,
          1203,
          311,
          7440,
          4936,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6338.6,
        "id": 1925,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6332.6,
        "temperature": 0,
        "text": " Help me, Rachel McAdams and Mickey Rourke and Liev Schreiber.",
        "tokens": [
          50364,
          10773,
          385,
          11,
          14246,
          4050,
          15830,
          4070,
          293,
          24714,
          497,
          396,
          330,
          293,
          441,
          9037,
          2065,
          265,
          5331,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6339.6,
        "id": 1926,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6338.6,
        "temperature": 0,
        "text": " Okay, Rachel McAdams.",
        "tokens": [
          50664,
          1033,
          11,
          14246,
          4050,
          15830,
          4070,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6340.6,
        "id": 1927,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6339.6,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50714,
          821,
          321,
          352,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6341.6,
        "id": 1928,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6340.6,
        "temperature": 0,
        "text": " Okay, let's do this again.",
        "tokens": [
          50764,
          1033,
          11,
          718,
          311,
          360,
          341,
          797,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6343.6,
        "id": 1929,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6341.6,
        "temperature": 0,
        "text": " We can see what's going on.",
        "tokens": [
          50814,
          492,
          393,
          536,
          437,
          311,
          516,
          322,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6345.6,
        "id": 1930,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6343.6,
        "temperature": 0,
        "text": " Rachel McAdams in spotlight with all these actors.",
        "tokens": [
          50914,
          14246,
          4050,
          15830,
          4070,
          294,
          24656,
          365,
          439,
          613,
          10037,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6346.6,
        "id": 1931,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6345.6,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51014,
          876,
          452,
          8387,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6349.6,
        "id": 1932,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6346.6,
        "temperature": 0,
        "text": " Which was Ypres Love, all these actors, all these actors, all these actors.",
        "tokens": [
          51064,
          3013,
          390,
          398,
          14508,
          5956,
          11,
          439,
          613,
          10037,
          11,
          439,
          613,
          10037,
          11,
          439,
          613,
          10037,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6350.6,
        "id": 1933,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6349.6,
        "temperature": 0,
        "text": " Found Kevin Bacon.",
        "tokens": [
          51214,
          8207,
          9954,
          42460,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6351.6,
        "id": 1934,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6350.6,
        "temperature": 0,
        "text": " So, I can't really follow this.",
        "tokens": [
          51264,
          407,
          11,
          286,
          393,
          380,
          534,
          1524,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6354.6,
        "id": 1935,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6351.6,
        "temperature": 0,
        "text": " This is why I need to now go backwards through the parents.",
        "tokens": [
          51314,
          639,
          307,
          983,
          286,
          643,
          281,
          586,
          352,
          12204,
          807,
          264,
          3152,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6355.6,
        "id": 1936,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6354.6,
        "temperature": 0,
        "text": " So, when I'm done.",
        "tokens": [
          51464,
          407,
          11,
          562,
          286,
          478,
          1096,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19812961677452187,
        "compression_ratio": 1.7435897435897436,
        "end": 6358.6,
        "id": 1937,
        "no_speech_prob": 0.002182700904086232,
        "seek": 633260,
        "start": 6355.6,
        "temperature": 0,
        "text": " So, let's take, this is not helping us follow this.",
        "tokens": [
          51514,
          407,
          11,
          718,
          311,
          747,
          11,
          341,
          307,
          406,
          4315,
          505,
          1524,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21230745839548634,
        "compression_ratio": 1.4886363636363635,
        "end": 6362.6,
        "id": 1938,
        "no_speech_prob": 0.015424310229718685,
        "seek": 635860,
        "start": 6358.6,
        "temperature": 0,
        "text": " But when we're done here, we should be able to say,",
        "tokens": [
          50364,
          583,
          562,
          321,
          434,
          1096,
          510,
          11,
          321,
          820,
          312,
          1075,
          281,
          584,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.21230745839548634,
        "compression_ratio": 1.4886363636363635,
        "end": 6366.6,
        "id": 1939,
        "no_speech_prob": 0.015424310229718685,
        "seek": 635860,
        "start": 6362.6,
        "temperature": 0,
        "text": " I'm going to create a variable called path, which is an array.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          1884,
          257,
          7006,
          1219,
          3100,
          11,
          597,
          307,
          364,
          10225,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21230745839548634,
        "compression_ratio": 1.4886363636363635,
        "end": 6368.6,
        "id": 1940,
        "no_speech_prob": 0.015424310229718685,
        "seek": 635860,
        "start": 6366.6,
        "temperature": 0,
        "text": " And I want to put the full path in that array.",
        "tokens": [
          50764,
          400,
          286,
          528,
          281,
          829,
          264,
          1577,
          3100,
          294,
          300,
          10225,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21230745839548634,
        "compression_ratio": 1.4886363636363635,
        "end": 6379.6,
        "id": 1941,
        "no_speech_prob": 0.015424310229718685,
        "seek": 635860,
        "start": 6370.6,
        "temperature": 0,
        "text": " And I'm going to say, so, path.push, graph.end, right?",
        "tokens": [
          50964,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          370,
          11,
          3100,
          13,
          79,
          1498,
          11,
          4295,
          13,
          521,
          11,
          558,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.21230745839548634,
        "compression_ratio": 1.4886363636363635,
        "end": 6382.6,
        "id": 1942,
        "no_speech_prob": 0.015424310229718685,
        "seek": 635860,
        "start": 6381.6,
        "temperature": 0,
        "text": " Or no, end.",
        "tokens": [
          51514,
          1610,
          572,
          11,
          917,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21230745839548634,
        "compression_ratio": 1.4886363636363635,
        "end": 6383.6,
        "id": 1943,
        "no_speech_prob": 0.015424310229718685,
        "seek": 635860,
        "start": 6382.6,
        "temperature": 0,
        "text": " That's where we're starting.",
        "tokens": [
          51564,
          663,
          311,
          689,
          321,
          434,
          2891,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21230745839548634,
        "compression_ratio": 1.4886363636363635,
        "end": 6385.6,
        "id": 1944,
        "no_speech_prob": 0.015424310229718685,
        "seek": 635860,
        "start": 6384.6,
        "temperature": 0,
        "text": " End.",
        "tokens": [
          51664,
          6967,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18796654903527463,
        "compression_ratio": 1.8245614035087718,
        "end": 6388.6,
        "id": 1945,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 638560,
        "start": 6385.6,
        "temperature": 0,
        "text": " And then I want to say, next equals end.",
        "tokens": [
          50364,
          400,
          550,
          286,
          528,
          281,
          584,
          11,
          958,
          6915,
          917,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18796654903527463,
        "compression_ratio": 1.8245614035087718,
        "end": 6393.6,
        "id": 1946,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 638560,
        "start": 6388.6,
        "temperature": 0,
        "text": " So, I want to do a loop to just go from next equals end.parent.",
        "tokens": [
          50514,
          407,
          11,
          286,
          528,
          281,
          360,
          257,
          6367,
          281,
          445,
          352,
          490,
          958,
          6915,
          917,
          13,
          38321,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18796654903527463,
        "compression_ratio": 1.8245614035087718,
        "end": 6400.6,
        "id": 1947,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 638560,
        "start": 6394.6,
        "temperature": 0,
        "text": " And I want to say, while next is not equal to null.",
        "tokens": [
          50814,
          400,
          286,
          528,
          281,
          584,
          11,
          1339,
          958,
          307,
          406,
          2681,
          281,
          18184,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18796654903527463,
        "compression_ratio": 1.8245614035087718,
        "end": 6402.6,
        "id": 1948,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 638560,
        "start": 6400.6,
        "temperature": 0,
        "text": " I'll explain this again in a second.",
        "tokens": [
          51114,
          286,
          603,
          2903,
          341,
          797,
          294,
          257,
          1150,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18796654903527463,
        "compression_ratio": 1.8245614035087718,
        "end": 6411.6,
        "id": 1949,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 638560,
        "start": 6403.6,
        "temperature": 0,
        "text": " While next is not equal to null, path.push next, and then next equals next.parent.",
        "tokens": [
          51264,
          3987,
          958,
          307,
          406,
          2681,
          281,
          18184,
          11,
          3100,
          13,
          79,
          1498,
          958,
          11,
          293,
          550,
          958,
          6915,
          958,
          13,
          38321,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18796654903527463,
        "compression_ratio": 1.8245614035087718,
        "end": 6413.6,
        "id": 1950,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 638560,
        "start": 6411.6,
        "temperature": 0,
        "text": " Okay, let's, I think this is right.",
        "tokens": [
          51664,
          1033,
          11,
          718,
          311,
          11,
          286,
          519,
          341,
          307,
          558,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20035184130949132,
        "compression_ratio": 2.241545893719807,
        "end": 6421.6,
        "id": 1951,
        "no_speech_prob": 0.00010720867430791259,
        "seek": 641360,
        "start": 6413.6,
        "temperature": 0,
        "text": " Right, what I want to do is, I want to start with the end, and then go backwards.",
        "tokens": [
          50364,
          1779,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          286,
          528,
          281,
          722,
          365,
          264,
          917,
          11,
          293,
          550,
          352,
          12204,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20035184130949132,
        "compression_ratio": 2.241545893719807,
        "end": 6424.6,
        "id": 1952,
        "no_speech_prob": 0.00010720867430791259,
        "seek": 641360,
        "start": 6421.6,
        "temperature": 0,
        "text": " Go to the end's parent, then that one's parent, then that one's parent,",
        "tokens": [
          50764,
          1037,
          281,
          264,
          917,
          311,
          2596,
          11,
          550,
          300,
          472,
          311,
          2596,
          11,
          550,
          300,
          472,
          311,
          2596,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20035184130949132,
        "compression_ratio": 2.241545893719807,
        "end": 6427.6,
        "id": 1953,
        "no_speech_prob": 0.00010720867430791259,
        "seek": 641360,
        "start": 6424.6,
        "temperature": 0,
        "text": " and that's one's parent, to trace back to find that path that was found.",
        "tokens": [
          50914,
          293,
          300,
          311,
          472,
          311,
          2596,
          11,
          281,
          13508,
          646,
          281,
          915,
          300,
          3100,
          300,
          390,
          1352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20035184130949132,
        "compression_ratio": 2.241545893719807,
        "end": 6431.6,
        "id": 1954,
        "no_speech_prob": 0.00010720867430791259,
        "seek": 641360,
        "start": 6427.6,
        "temperature": 0,
        "text": " So, that's what this particular algorithm is doing.",
        "tokens": [
          51064,
          407,
          11,
          300,
          311,
          437,
          341,
          1729,
          9284,
          307,
          884,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20035184130949132,
        "compression_ratio": 2.241545893719807,
        "end": 6435.6,
        "id": 1955,
        "no_speech_prob": 0.00010720867430791259,
        "seek": 641360,
        "start": 6431.6,
        "temperature": 0,
        "text": " We start with the end, then we get the parent of the end,",
        "tokens": [
          51264,
          492,
          722,
          365,
          264,
          917,
          11,
          550,
          321,
          483,
          264,
          2596,
          295,
          264,
          917,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20035184130949132,
        "compression_ratio": 2.241545893719807,
        "end": 6437.6,
        "id": 1956,
        "no_speech_prob": 0.00010720867430791259,
        "seek": 641360,
        "start": 6435.6,
        "temperature": 0,
        "text": " and as long as it exists, put it in the path.",
        "tokens": [
          51464,
          293,
          382,
          938,
          382,
          309,
          8198,
          11,
          829,
          309,
          294,
          264,
          3100,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20035184130949132,
        "compression_ratio": 2.241545893719807,
        "end": 6441.6,
        "id": 1957,
        "no_speech_prob": 0.00010720867430791259,
        "seek": 641360,
        "start": 6437.6,
        "temperature": 0,
        "text": " And then we get the parent of that, and as long as it exists, put it in the path.",
        "tokens": [
          51564,
          400,
          550,
          321,
          483,
          264,
          2596,
          295,
          300,
          11,
          293,
          382,
          938,
          382,
          309,
          8198,
          11,
          829,
          309,
          294,
          264,
          3100,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1904482160295759,
        "compression_ratio": 1.7419354838709677,
        "end": 6445.6,
        "id": 1958,
        "no_speech_prob": 0.004198776092380285,
        "seek": 644160,
        "start": 6441.6,
        "temperature": 0,
        "text": " And keep doing it until eventually something has no parent anymore, because it's where we started.",
        "tokens": [
          50364,
          400,
          1066,
          884,
          309,
          1826,
          4728,
          746,
          575,
          572,
          2596,
          3602,
          11,
          570,
          309,
          311,
          689,
          321,
          1409,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1904482160295759,
        "compression_ratio": 1.7419354838709677,
        "end": 6447.6,
        "id": 1959,
        "no_speech_prob": 0.004198776092380285,
        "seek": 644160,
        "start": 6445.6,
        "temperature": 0,
        "text": " So, the start has no parent.",
        "tokens": [
          50564,
          407,
          11,
          264,
          722,
          575,
          572,
          2596,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1904482160295759,
        "compression_ratio": 1.7419354838709677,
        "end": 6453.6,
        "id": 1960,
        "no_speech_prob": 0.004198776092380285,
        "seek": 644160,
        "start": 6447.6,
        "temperature": 0,
        "text": " So, now I should be able to say, and I'm going to actually create a DOM element.",
        "tokens": [
          50664,
          407,
          11,
          586,
          286,
          820,
          312,
          1075,
          281,
          584,
          11,
          293,
          286,
          478,
          516,
          281,
          767,
          1884,
          257,
          35727,
          4478,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1904482160295759,
        "compression_ratio": 1.7419354838709677,
        "end": 6455.6,
        "id": 1961,
        "no_speech_prob": 0.004198776092380285,
        "seek": 644160,
        "start": 6453.6,
        "temperature": 0,
        "text": " I should be able to iterate over the path.",
        "tokens": [
          50964,
          286,
          820,
          312,
          1075,
          281,
          44497,
          670,
          264,
          3100,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1904482160295759,
        "compression_ratio": 1.7419354838709677,
        "end": 6459.6,
        "id": 1962,
        "no_speech_prob": 0.004198776092380285,
        "seek": 644160,
        "start": 6455.6,
        "temperature": 0,
        "text": " Do I have to iterate the path backwards?",
        "tokens": [
          51064,
          1144,
          286,
          362,
          281,
          44497,
          264,
          3100,
          12204,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1904482160295759,
        "compression_ratio": 1.7419354838709677,
        "end": 6462.6,
        "id": 1963,
        "no_speech_prob": 0.004198776092380285,
        "seek": 644160,
        "start": 6459.6,
        "temperature": 0,
        "text": " Because what's, yeah, the last thing is the beginning.",
        "tokens": [
          51264,
          1436,
          437,
          311,
          11,
          1338,
          11,
          264,
          1036,
          551,
          307,
          264,
          2863,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1904482160295759,
        "compression_ratio": 1.7419354838709677,
        "end": 6465.6,
        "id": 1964,
        "no_speech_prob": 0.004198776092380285,
        "seek": 644160,
        "start": 6462.6,
        "temperature": 0,
        "text": " So, I'm going to say path.length, I mean I could do this a number of different ways.",
        "tokens": [
          51414,
          407,
          11,
          286,
          478,
          516,
          281,
          584,
          3100,
          13,
          45390,
          11,
          286,
          914,
          286,
          727,
          360,
          341,
          257,
          1230,
          295,
          819,
          2098,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23686901728312174,
        "compression_ratio": 1.5661764705882353,
        "end": 6471.6,
        "id": 1965,
        "no_speech_prob": 0.11756377667188644,
        "seek": 646560,
        "start": 6465.6,
        "temperature": 0,
        "text": " Minus one, i goes all the way down to zero.",
        "tokens": [
          50364,
          2829,
          301,
          472,
          11,
          741,
          1709,
          439,
          264,
          636,
          760,
          281,
          4018,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23686901728312174,
        "compression_ratio": 1.5661764705882353,
        "end": 6476.6,
        "id": 1966,
        "no_speech_prob": 0.11756377667188644,
        "seek": 646560,
        "start": 6471.6,
        "temperature": 0,
        "text": " And I'm going to say node equals path index i.",
        "tokens": [
          50664,
          400,
          286,
          478,
          516,
          281,
          584,
          9984,
          6915,
          3100,
          8186,
          741,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23686901728312174,
        "compression_ratio": 1.5661764705882353,
        "end": 6482.6,
        "id": 1967,
        "no_speech_prob": 0.11756377667188644,
        "seek": 646560,
        "start": 6476.6,
        "temperature": 0,
        "text": " Then I'm going to say var text equals an empty string.",
        "tokens": [
          50914,
          1396,
          286,
          478,
          516,
          281,
          584,
          1374,
          2487,
          6915,
          364,
          6707,
          6798,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23686901728312174,
        "compression_ratio": 1.5661764705882353,
        "end": 6494.6,
        "id": 1968,
        "no_speech_prob": 0.11756377667188644,
        "seek": 646560,
        "start": 6482.6,
        "temperature": 0,
        "text": " Then I'm going to say text plus equals n.value plus, like an arrow.",
        "tokens": [
          51214,
          1396,
          286,
          478,
          516,
          281,
          584,
          2487,
          1804,
          6915,
          297,
          13,
          29155,
          1804,
          11,
          411,
          364,
          11610,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6496.6,
        "id": 1969,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6494.6,
        "temperature": 0,
        "text": " I should get the right arrow key.",
        "tokens": [
          50364,
          286,
          820,
          483,
          264,
          558,
          11610,
          2141,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6498.6,
        "id": 1970,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6496.6,
        "temperature": 0,
        "text": " And then I'm going to say create p text.",
        "tokens": [
          50464,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          1884,
          280,
          2487,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6503.6,
        "id": 1971,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6498.6,
        "temperature": 0,
        "text": " So, what I want to do here is just, the reason why I'm doing this is instead of console logging,",
        "tokens": [
          50564,
          407,
          11,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          445,
          11,
          264,
          1778,
          983,
          286,
          478,
          884,
          341,
          307,
          2602,
          295,
          11076,
          287,
          664,
          3249,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6506.6,
        "id": 1972,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6503.6,
        "temperature": 0,
        "text": " create p is a p5 function that will create a paragraph element in the browser,",
        "tokens": [
          50814,
          1884,
          280,
          307,
          257,
          280,
          20,
          2445,
          300,
          486,
          1884,
          257,
          18865,
          4478,
          294,
          264,
          11185,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6508.6,
        "id": 1973,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6506.6,
        "temperature": 0,
        "text": " so I can see it written out there.",
        "tokens": [
          50964,
          370,
          286,
          393,
          536,
          309,
          3720,
          484,
          456,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6510.6,
        "id": 1974,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6508.6,
        "temperature": 0,
        "text": " So, let's see if this helps.",
        "tokens": [
          51064,
          407,
          11,
          718,
          311,
          536,
          498,
          341,
          3665,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6512.6,
        "id": 1975,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6510.6,
        "temperature": 0,
        "text": " So, we can see, there we go.",
        "tokens": [
          51164,
          407,
          11,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6515.6,
        "id": 1976,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6512.6,
        "temperature": 0,
        "text": " Rachel McAdams was in Spotlight with Billy Crudup,",
        "tokens": [
          51264,
          14246,
          4050,
          15830,
          4070,
          390,
          294,
          19102,
          2764,
          365,
          18179,
          4779,
          532,
          1010,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6517.6,
        "id": 1977,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6515.6,
        "temperature": 0,
        "text": " who was in Eat, Pray, Love with Julia Roberts,",
        "tokens": [
          51414,
          567,
          390,
          294,
          14429,
          11,
          36365,
          11,
          5956,
          365,
          18551,
          20919,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6519.6,
        "id": 1978,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6517.6,
        "temperature": 0,
        "text": " who was in Flatliners with Kevin Bacon.",
        "tokens": [
          51514,
          567,
          390,
          294,
          36172,
          5045,
          433,
          365,
          9954,
          42460,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18718270627324451,
        "compression_ratio": 1.6798780487804879,
        "end": 6522.6,
        "id": 1979,
        "no_speech_prob": 0.015424140729010105,
        "seek": 649460,
        "start": 6519.6,
        "temperature": 0,
        "text": " Now, I should also have something that, I don't need that last arrow.",
        "tokens": [
          51614,
          823,
          11,
          286,
          820,
          611,
          362,
          746,
          300,
          11,
          286,
          500,
          380,
          643,
          300,
          1036,
          11610,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6531.6,
        "id": 1980,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6523.6,
        "temperature": 0,
        "text": " So, if i is not equal to zero, then also add the arrow.",
        "tokens": [
          50414,
          407,
          11,
          498,
          741,
          307,
          406,
          2681,
          281,
          4018,
          11,
          550,
          611,
          909,
          264,
          11610,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6533.6,
        "id": 1981,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6531.6,
        "temperature": 0,
        "text": " Let me just correct that.",
        "tokens": [
          50814,
          961,
          385,
          445,
          3006,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6539.6,
        "id": 1982,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6537.6,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51114,
          400,
          456,
          321,
          352,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6542.6,
        "id": 1983,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6539.6,
        "temperature": 0,
        "text": " Now, let's just quickly, while we're here, we're almost done.",
        "tokens": [
          51214,
          823,
          11,
          718,
          311,
          445,
          2661,
          11,
          1339,
          321,
          434,
          510,
          11,
          321,
          434,
          1920,
          1096,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6545.6,
        "id": 1984,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6542.6,
        "temperature": 0,
        "text": " People are asking in the chat,",
        "tokens": [
          51364,
          3432,
          366,
          3365,
          294,
          264,
          5081,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6547.6,
        "id": 1985,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6545.6,
        "temperature": 0,
        "text": " wouldn't this be a good time to talk about big O notation?",
        "tokens": [
          51514,
          2759,
          380,
          341,
          312,
          257,
          665,
          565,
          281,
          751,
          466,
          955,
          422,
          24657,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6548.6,
        "id": 1986,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6547.6,
        "temperature": 0,
        "text": " Definitely.",
        "tokens": [
          51614,
          12151,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20115258143498346,
        "compression_ratio": 1.4934497816593886,
        "end": 6551.6,
        "id": 1987,
        "no_speech_prob": 0.0035380551125854254,
        "seek": 652260,
        "start": 6548.6,
        "temperature": 0,
        "text": " I've got to make a video about that sometime, and it will come before this one.",
        "tokens": [
          51664,
          286,
          600,
          658,
          281,
          652,
          257,
          960,
          466,
          300,
          15053,
          11,
          293,
          309,
          486,
          808,
          949,
          341,
          472,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6553.6,
        "id": 1988,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6551.6,
        "temperature": 0,
        "text": " Maybe you already watched it because you're in the future.",
        "tokens": [
          50364,
          2704,
          291,
          1217,
          6337,
          309,
          570,
          291,
          434,
          294,
          264,
          2027,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6554.6,
        "id": 1989,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6553.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6557.6,
        "id": 1990,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6554.6,
        "temperature": 0,
        "text": " Very quickly, just to make this a little bit more interesting,",
        "tokens": [
          50514,
          4372,
          2661,
          11,
          445,
          281,
          652,
          341,
          257,
          707,
          857,
          544,
          1880,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6559.6,
        "id": 1991,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6557.6,
        "temperature": 0,
        "text": " let me do something.",
        "tokens": [
          50664,
          718,
          385,
          360,
          746,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6561.6,
        "id": 1992,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6559.6,
        "temperature": 0,
        "text": " I'm going to use a p5 function.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          764,
          257,
          280,
          20,
          2445,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6562.6,
        "id": 1993,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6561.6,
        "temperature": 0,
        "text": " Oh, this is going to make it harder, though.",
        "tokens": [
          50864,
          876,
          11,
          341,
          307,
          516,
          281,
          652,
          309,
          6081,
          11,
          1673,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6564.6,
        "id": 1994,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6562.6,
        "temperature": 0,
        "text": " I should really just stop.",
        "tokens": [
          50914,
          286,
          820,
          534,
          445,
          1590,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6566.6,
        "id": 1995,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6564.6,
        "temperature": 0,
        "text": " I'm going to do this anyway.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          360,
          341,
          4033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6570.6,
        "id": 1996,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6566.6,
        "temperature": 0,
        "text": " I'm going to say var drop down equals create select.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          584,
          1374,
          3270,
          760,
          6915,
          1884,
          3048,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6575.6,
        "id": 1997,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6570.6,
        "temperature": 0,
        "text": " So, what the create select function does",
        "tokens": [
          51314,
          407,
          11,
          437,
          264,
          1884,
          3048,
          2445,
          775,
          51564
        ]
      },
      {
        "avg_logprob": -0.178158042844662,
        "compression_ratio": 1.7024793388429753,
        "end": 6578.6,
        "id": 1998,
        "no_speech_prob": 0.00015597895253449678,
        "seek": 655160,
        "start": 6575.6,
        "temperature": 0,
        "text": " is it makes a little drop down menu,",
        "tokens": [
          51564,
          307,
          309,
          1669,
          257,
          707,
          3270,
          760,
          6510,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6581.6,
        "id": 1999,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6578.6,
        "temperature": 0,
        "text": " and there's some silly CSS styling here,",
        "tokens": [
          50364,
          293,
          456,
          311,
          512,
          11774,
          24387,
          27944,
          510,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6586.6,
        "id": 2000,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6581.6,
        "temperature": 0,
        "text": " which is causing it all to have no margins, which is unnecessary.",
        "tokens": [
          50514,
          597,
          307,
          9853,
          309,
          439,
          281,
          362,
          572,
          30317,
          11,
          597,
          307,
          19350,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6587.6,
        "id": 2001,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6586.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6590.6,
        "id": 2002,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6587.6,
        "temperature": 0,
        "text": " So, it makes a little drop down,",
        "tokens": [
          50814,
          407,
          11,
          309,
          1669,
          257,
          707,
          3270,
          760,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6593.6,
        "id": 2003,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6590.6,
        "temperature": 0,
        "text": " but I need to put stuff in the drop down.",
        "tokens": [
          50964,
          457,
          286,
          643,
          281,
          829,
          1507,
          294,
          264,
          3270,
          760,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6596.6,
        "id": 2004,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6593.6,
        "temperature": 0,
        "text": " I want to be able to select any actor and see the result.",
        "tokens": [
          51114,
          286,
          528,
          281,
          312,
          1075,
          281,
          3048,
          604,
          8747,
          293,
          536,
          264,
          1874,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6600.6,
        "id": 2005,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6596.6,
        "temperature": 0,
        "text": " So, now what I'm going to do is,",
        "tokens": [
          51264,
          407,
          11,
          586,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6602.6,
        "id": 2006,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6600.6,
        "temperature": 0,
        "text": " while I'm going through these actors,",
        "tokens": [
          51464,
          1339,
          286,
          478,
          516,
          807,
          613,
          10037,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6604.6,
        "id": 2007,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6602.6,
        "temperature": 0,
        "text": " this is where I get every actor name.",
        "tokens": [
          51564,
          341,
          307,
          689,
          286,
          483,
          633,
          8747,
          1315,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17512668997554456,
        "compression_ratio": 1.6160337552742616,
        "end": 6606.6,
        "id": 2008,
        "no_speech_prob": 0.001648466452024877,
        "seek": 657860,
        "start": 6604.6,
        "temperature": 0,
        "text": " As long as it's a new actor,",
        "tokens": [
          51664,
          1018,
          938,
          382,
          309,
          311,
          257,
          777,
          8747,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6611.6,
        "id": 2009,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6606.6,
        "temperature": 0,
        "text": " I'm going to say drop down dot option actor.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          3270,
          760,
          5893,
          3614,
          8747,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6612.6,
        "id": 2010,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6611.6,
        "temperature": 0,
        "text": " Watch this.",
        "tokens": [
          50614,
          7277,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6613.6,
        "id": 2011,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6612.6,
        "temperature": 0,
        "text": " Very simple in p5.",
        "tokens": [
          50664,
          4372,
          2199,
          294,
          280,
          20,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6615.6,
        "id": 2012,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6613.6,
        "temperature": 0,
        "text": " Create a DOM element and add some options to it.",
        "tokens": [
          50714,
          20248,
          257,
          35727,
          4478,
          293,
          909,
          512,
          3956,
          281,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6617.6,
        "id": 2013,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6615.6,
        "temperature": 0,
        "text": " A number of other ways you could do this.",
        "tokens": [
          50814,
          316,
          1230,
          295,
          661,
          2098,
          291,
          727,
          360,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6618.6,
        "id": 2014,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6617.6,
        "temperature": 0,
        "text": " I'm adding this part kind of quickly.",
        "tokens": [
          50914,
          286,
          478,
          5127,
          341,
          644,
          733,
          295,
          2661,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6622.6,
        "id": 2015,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6618.6,
        "temperature": 0,
        "text": " Now you can see I have a little menu where I can pick any actor.",
        "tokens": [
          50964,
          823,
          291,
          393,
          536,
          286,
          362,
          257,
          707,
          6510,
          689,
          286,
          393,
          1888,
          604,
          8747,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6625.6,
        "id": 2016,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6622.6,
        "temperature": 0,
        "text": " Now, I need to be able to know when do I pick a new actor.",
        "tokens": [
          51164,
          823,
          11,
          286,
          643,
          281,
          312,
          1075,
          281,
          458,
          562,
          360,
          286,
          1888,
          257,
          777,
          8747,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6628.6,
        "id": 2017,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6625.6,
        "temperature": 0,
        "text": " When I pick a new actor,",
        "tokens": [
          51314,
          1133,
          286,
          1888,
          257,
          777,
          8747,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6632.6,
        "id": 2018,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6628.6,
        "temperature": 0,
        "text": " when I pick a new actor,",
        "tokens": [
          51464,
          562,
          286,
          1888,
          257,
          777,
          8747,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.15816920353816105,
        "compression_ratio": 1.6926229508196722,
        "end": 6635.6,
        "id": 2019,
        "no_speech_prob": 0.0013670196058228612,
        "seek": 660660,
        "start": 6632.6,
        "temperature": 0,
        "text": " it's an event on this DOM element.",
        "tokens": [
          51664,
          309,
          311,
          364,
          2280,
          322,
          341,
          35727,
          4478,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6639.6,
        "id": 2020,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6635.6,
        "temperature": 0,
        "text": " So, the event, this is a p5 function I'm going to call changed.",
        "tokens": [
          50364,
          407,
          11,
          264,
          2280,
          11,
          341,
          307,
          257,
          280,
          20,
          2445,
          286,
          478,
          516,
          281,
          818,
          3105,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6643.6,
        "id": 2021,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6639.6,
        "temperature": 0,
        "text": " So, anytime, I'm going to say run,",
        "tokens": [
          50564,
          407,
          11,
          13038,
          11,
          286,
          478,
          516,
          281,
          584,
          1190,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6644.6,
        "id": 2022,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6643.6,
        "temperature": 0,
        "text": " I'm just going to say BFS.",
        "tokens": [
          50764,
          286,
          478,
          445,
          516,
          281,
          584,
          363,
          29318,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6647.6,
        "id": 2023,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6644.6,
        "temperature": 0,
        "text": " So, anytime the drop down change,",
        "tokens": [
          50814,
          407,
          11,
          13038,
          264,
          3270,
          760,
          1319,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6649.6,
        "id": 2024,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6647.6,
        "temperature": 0,
        "text": " just run breadth first search.",
        "tokens": [
          50964,
          445,
          1190,
          35862,
          700,
          3164,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6654.6,
        "id": 2025,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6649.6,
        "temperature": 0,
        "text": " And I'm going to now go down and take everything here.",
        "tokens": [
          51064,
          400,
          286,
          478,
          516,
          281,
          586,
          352,
          760,
          293,
          747,
          1203,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6658.6,
        "id": 2026,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6654.6,
        "temperature": 0,
        "text": " That's the entire breadth first search algorithm.",
        "tokens": [
          51314,
          663,
          311,
          264,
          2302,
          35862,
          700,
          3164,
          9284,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25288434982299807,
        "compression_ratio": 1.7407407407407407,
        "end": 6661.6,
        "id": 2027,
        "no_speech_prob": 0.00008092749339994043,
        "seek": 663560,
        "start": 6658.6,
        "temperature": 0,
        "text": " And put that in its own function.",
        "tokens": [
          51514,
          400,
          829,
          300,
          294,
          1080,
          1065,
          2445,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6664.6,
        "id": 2028,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6662.6,
        "temperature": 0,
        "text": " Function BFS.",
        "tokens": [
          50414,
          11166,
          882,
          363,
          29318,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6666.6,
        "id": 2029,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6664.6,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50514,
          821,
          321,
          352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6670.6,
        "id": 2030,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6666.6,
        "temperature": 0,
        "text": " So, now, just to see if this works,",
        "tokens": [
          50614,
          407,
          11,
          586,
          11,
          445,
          281,
          536,
          498,
          341,
          1985,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6672.6,
        "id": 2031,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6670.6,
        "temperature": 0,
        "text": " I'm going to,",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6675.6,
        "id": 2032,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6672.6,
        "temperature": 0,
        "text": " what we're going to do is we're going to run the page again.",
        "tokens": [
          50914,
          437,
          321,
          434,
          516,
          281,
          360,
          307,
          321,
          434,
          516,
          281,
          1190,
          264,
          3028,
          797,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6677.6,
        "id": 2033,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6675.6,
        "temperature": 0,
        "text": " I'm going to change the actor.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          1319,
          264,
          8747,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6679.6,
        "id": 2034,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6677.6,
        "temperature": 0,
        "text": " And it ran breadth first search.",
        "tokens": [
          51164,
          400,
          309,
          5872,
          35862,
          700,
          3164,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6681.6,
        "id": 2035,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6679.6,
        "temperature": 0,
        "text": " But it ran it with Rachel McAdams.",
        "tokens": [
          51264,
          583,
          309,
          5872,
          309,
          365,
          14246,
          4050,
          15830,
          4070,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6685.6,
        "id": 2036,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6681.6,
        "temperature": 0,
        "text": " So, the point is, what I want is to have it run with Paul Reiser.",
        "tokens": [
          51364,
          407,
          11,
          264,
          935,
          307,
          11,
          437,
          286,
          528,
          307,
          281,
          362,
          309,
          1190,
          365,
          4552,
          1300,
          6694,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16877257085479466,
        "compression_ratio": 1.5665024630541873,
        "end": 6687.6,
        "id": 2037,
        "no_speech_prob": 0.00012931556557305157,
        "seek": 666160,
        "start": 6685.6,
        "temperature": 0,
        "text": " So, where do I,",
        "tokens": [
          51564,
          407,
          11,
          689,
          360,
          286,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6691.6,
        "id": 2038,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6687.6,
        "temperature": 0,
        "text": " so, this drop down needs to be a global variable.",
        "tokens": [
          50364,
          370,
          11,
          341,
          3270,
          760,
          2203,
          281,
          312,
          257,
          4338,
          7006,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6698.6,
        "id": 2039,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6695.6,
        "temperature": 0,
        "text": " And the drop down needs to be a global variable.",
        "tokens": [
          50764,
          400,
          264,
          3270,
          760,
          2203,
          281,
          312,
          257,
          4338,
          7006,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6700.6,
        "id": 2040,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6698.6,
        "temperature": 0,
        "text": " I've got a lot of messy code here,",
        "tokens": [
          50914,
          286,
          600,
          658,
          257,
          688,
          295,
          16191,
          3089,
          510,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6703.6,
        "id": 2041,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6700.6,
        "temperature": 0,
        "text": " but someday we'll clean that up a little bit.",
        "tokens": [
          51014,
          457,
          19412,
          321,
          603,
          2541,
          300,
          493,
          257,
          707,
          857,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6706.6,
        "id": 2042,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6703.6,
        "temperature": 0,
        "text": " And I'm going to change the start,",
        "tokens": [
          51164,
          400,
          286,
          478,
          516,
          281,
          1319,
          264,
          722,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6710.6,
        "id": 2043,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6706.6,
        "temperature": 0,
        "text": " set start to drop down dot value.",
        "tokens": [
          51314,
          992,
          722,
          281,
          3270,
          760,
          5893,
          2158,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6713.6,
        "id": 2044,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6710.6,
        "temperature": 0,
        "text": " So, the actor's name for the start will actually come from there.",
        "tokens": [
          51514,
          407,
          11,
          264,
          8747,
          311,
          1315,
          337,
          264,
          722,
          486,
          767,
          808,
          490,
          456,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1873314614389457,
        "compression_ratio": 1.7085427135678393,
        "end": 6715.6,
        "id": 2045,
        "no_speech_prob": 0.002148944651708007,
        "seek": 668760,
        "start": 6713.6,
        "temperature": 0,
        "text": " Now, let's do this again.",
        "tokens": [
          51664,
          823,
          11,
          718,
          311,
          360,
          341,
          797,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6718.6,
        "id": 2046,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6716.6,
        "temperature": 0,
        "text": " I'm going to pick Paul Reiser again.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          1888,
          4552,
          1300,
          6694,
          797,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6720.6,
        "id": 2047,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6718.6,
        "temperature": 0,
        "text": " Paul Reiser was in the diner with Kevin Bacon.",
        "tokens": [
          50514,
          4552,
          1300,
          6694,
          390,
          294,
          264,
          3791,
          260,
          365,
          9954,
          42460,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6721.6,
        "id": 2048,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6720.6,
        "temperature": 0,
        "text": " Now, let's pick somebody else.",
        "tokens": [
          50614,
          823,
          11,
          718,
          311,
          1888,
          2618,
          1646,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6723.6,
        "id": 2049,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6721.6,
        "temperature": 0,
        "text": " Ah, this is not going to work.",
        "tokens": [
          50664,
          2438,
          11,
          341,
          307,
          406,
          516,
          281,
          589,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6725.6,
        "id": 2050,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6723.6,
        "temperature": 0,
        "text": " Paul Reiser. It didn't work.",
        "tokens": [
          50764,
          4552,
          1300,
          6694,
          13,
          467,
          994,
          380,
          589,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6728.6,
        "id": 2051,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6725.6,
        "temperature": 0,
        "text": " So, first of all, why didn't it work?",
        "tokens": [
          50864,
          407,
          11,
          700,
          295,
          439,
          11,
          983,
          994,
          380,
          309,
          589,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6730.6,
        "id": 2052,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6728.6,
        "temperature": 0,
        "text": " Well, a couple things.",
        "tokens": [
          51014,
          1042,
          11,
          257,
          1916,
          721,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6732.6,
        "id": 2053,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6730.6,
        "temperature": 0,
        "text": " Number one, it's weird that it's starting with Paul Reiser again.",
        "tokens": [
          51114,
          5118,
          472,
          11,
          309,
          311,
          3657,
          300,
          309,
          311,
          2891,
          365,
          4552,
          1300,
          6694,
          797,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6734.6,
        "id": 2054,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6732.6,
        "temperature": 0,
        "text": " I don't know what the bug is specifically,",
        "tokens": [
          51214,
          286,
          500,
          380,
          458,
          437,
          264,
          7426,
          307,
          4682,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6736.6,
        "id": 2055,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6734.6,
        "temperature": 0,
        "text": " but there's a major problem.",
        "tokens": [
          51314,
          457,
          456,
          311,
          257,
          2563,
          1154,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6738.6,
        "id": 2056,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6736.6,
        "temperature": 0,
        "text": " See this node object?",
        "tokens": [
          51414,
          3008,
          341,
          9984,
          2657,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6742.6,
        "id": 2057,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6739.6,
        "temperature": 0,
        "text": " Remember, I was setting parents and searched?",
        "tokens": [
          51564,
          5459,
          11,
          286,
          390,
          3287,
          3152,
          293,
          22961,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.16331363368678736,
        "compression_ratio": 1.6726618705035972,
        "end": 6743.6,
        "id": 2058,
        "no_speech_prob": 0.001432530116289854,
        "seek": 671560,
        "start": 6742.6,
        "temperature": 0,
        "text": " I've got to start over.",
        "tokens": [
          51714,
          286,
          600,
          658,
          281,
          722,
          670,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6745.6,
        "id": 2059,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6743.6,
        "temperature": 0,
        "text": " All the searched have to be set to false,",
        "tokens": [
          50364,
          1057,
          264,
          22961,
          362,
          281,
          312,
          992,
          281,
          7908,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6747.6,
        "id": 2060,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6745.6,
        "temperature": 0,
        "text": " and all the parents have to be set to null.",
        "tokens": [
          50464,
          293,
          439,
          264,
          3152,
          362,
          281,
          312,
          992,
          281,
          18184,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6749.6,
        "id": 2061,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6747.6,
        "temperature": 0,
        "text": " So, I need a function in graph,",
        "tokens": [
          50564,
          407,
          11,
          286,
          643,
          257,
          2445,
          294,
          4295,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6754.6,
        "id": 2062,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6751.6,
        "temperature": 0,
        "text": " which essentially is like a reset function.",
        "tokens": [
          50764,
          597,
          4476,
          307,
          411,
          257,
          14322,
          2445,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6756.6,
        "id": 2063,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6754.6,
        "temperature": 0,
        "text": " And what I'm going to do in this reset function,",
        "tokens": [
          50914,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          341,
          14322,
          2445,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6759.6,
        "id": 2064,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6756.6,
        "temperature": 0,
        "text": " I knew I needed that nodes array for some reason.",
        "tokens": [
          51014,
          286,
          2586,
          286,
          2978,
          300,
          13891,
          10225,
          337,
          512,
          1778,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6762.6,
        "id": 2065,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6759.6,
        "temperature": 0,
        "text": " I'm just going to go through all the nodes.",
        "tokens": [
          51164,
          286,
          478,
          445,
          516,
          281,
          352,
          807,
          439,
          264,
          13891,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6764.6,
        "id": 2066,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6762.6,
        "temperature": 0,
        "text": " Their edges all stay the same.",
        "tokens": [
          51314,
          6710,
          8819,
          439,
          1754,
          264,
          912,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2081715237777845,
        "compression_ratio": 1.7723214285714286,
        "end": 6770.6,
        "id": 2067,
        "no_speech_prob": 0.002359652193263173,
        "seek": 674360,
        "start": 6764.6,
        "temperature": 0,
        "text": " And I'm going to say nodes index i dot searched equals false.",
        "tokens": [
          51414,
          400,
          286,
          478,
          516,
          281,
          584,
          13891,
          8186,
          741,
          5893,
          22961,
          6915,
          7908,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6773.6,
        "id": 2068,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6771.6,
        "temperature": 0,
        "text": " And nodes index i dot searched,",
        "tokens": [
          50414,
          400,
          13891,
          8186,
          741,
          5893,
          22961,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6775.6,
        "id": 2069,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6773.6,
        "temperature": 0,
        "text": " oh no, no, no, parents,",
        "tokens": [
          50514,
          1954,
          572,
          11,
          572,
          11,
          572,
          11,
          3152,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6777.6,
        "id": 2070,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6775.6,
        "temperature": 0,
        "text": " equal, are you still with me?",
        "tokens": [
          50614,
          2681,
          11,
          366,
          291,
          920,
          365,
          385,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6779.6,
        "id": 2071,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6777.6,
        "temperature": 0,
        "text": " Are you with me? I'm barely with myself here.",
        "tokens": [
          50714,
          2014,
          291,
          365,
          385,
          30,
          286,
          478,
          10268,
          365,
          2059,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6781.6,
        "id": 2072,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6779.6,
        "temperature": 0,
        "text": " But, it's about to be the weekend for me.",
        "tokens": [
          50814,
          583,
          11,
          309,
          311,
          466,
          281,
          312,
          264,
          6711,
          337,
          385,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6783.6,
        "id": 2073,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6781.6,
        "temperature": 0,
        "text": " Okay, null. Okay, here we go.",
        "tokens": [
          50914,
          1033,
          11,
          18184,
          13,
          1033,
          11,
          510,
          321,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6785.6,
        "id": 2074,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6783.6,
        "temperature": 0,
        "text": " Steve Guttenberg, Mickey Rourke,",
        "tokens": [
          51014,
          7466,
          24481,
          1147,
          6873,
          11,
          24714,
          497,
          396,
          330,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6787.6,
        "id": 2075,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6785.6,
        "temperature": 0,
        "text": " was in diner with Kevin Bacon.",
        "tokens": [
          51114,
          390,
          294,
          3791,
          260,
          365,
          9954,
          42460,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6789.6,
        "id": 2076,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6787.6,
        "temperature": 0,
        "text": " Lynn Marta was in,",
        "tokens": [
          51214,
          27469,
          5807,
          64,
          390,
          294,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6793.6,
        "id": 2077,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6791.6,
        "temperature": 0,
        "text": " wah wah, sad trombone.",
        "tokens": [
          51414,
          31979,
          31979,
          11,
          4227,
          504,
          3548,
          546,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6795.6,
        "id": 2078,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6793.6,
        "temperature": 0,
        "text": " Okay, what did I miss?",
        "tokens": [
          51514,
          1033,
          11,
          437,
          630,
          286,
          1713,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6797.6,
        "id": 2079,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6795.6,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2594614895907315,
        "compression_ratio": 1.5638766519823788,
        "end": 6799.6,
        "id": 2080,
        "no_speech_prob": 0.0004728491767309606,
        "seek": 677060,
        "start": 6797.6,
        "temperature": 0,
        "text": " What did I miss?",
        "tokens": [
          51714,
          708,
          630,
          286,
          1713,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6803.6,
        "id": 2081,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6800.6,
        "temperature": 0.2,
        "text": " Path dot, oh, I could use join, that's right.",
        "tokens": [
          50414,
          21914,
          5893,
          11,
          1954,
          11,
          286,
          727,
          764,
          3917,
          11,
          300,
          311,
          558,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6805.6,
        "id": 2082,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6803.6,
        "temperature": 0.2,
        "text": " What did I miss?",
        "tokens": [
          50564,
          708,
          630,
          286,
          1713,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6808.6,
        "id": 2083,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6806.6,
        "temperature": 0.2,
        "text": " Oh, I didn't call reset!",
        "tokens": [
          50714,
          876,
          11,
          286,
          994,
          380,
          818,
          14322,
          0,
          50814
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6810.6,
        "id": 2084,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6808.6,
        "temperature": 0.2,
        "text": " I wrote the reset function, but I didn't call it.",
        "tokens": [
          50814,
          286,
          4114,
          264,
          14322,
          2445,
          11,
          457,
          286,
          994,
          380,
          818,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6813.6,
        "id": 2085,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6810.6,
        "temperature": 0.2,
        "text": " Oh, classic, horrible error here.",
        "tokens": [
          50914,
          876,
          11,
          7230,
          11,
          9263,
          6713,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6815.6,
        "id": 2086,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6813.6,
        "temperature": 0.2,
        "text": " Graph dot reset, oh my god.",
        "tokens": [
          51064,
          21884,
          5893,
          14322,
          11,
          1954,
          452,
          3044,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6819.6,
        "id": 2087,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6817.6,
        "temperature": 0.2,
        "text": " Blah blah blah, coding debugging,",
        "tokens": [
          51264,
          2177,
          545,
          12288,
          12288,
          11,
          17720,
          45592,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6821.6,
        "id": 2088,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6819.6,
        "temperature": 0.2,
        "text": " blah blah blah, okay, here we go.",
        "tokens": [
          51364,
          12288,
          12288,
          12288,
          11,
          1392,
          11,
          510,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6825.6,
        "id": 2089,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6822.6,
        "temperature": 0.2,
        "text": " Steve Guttenberg, oh, Ellen Barkin,",
        "tokens": [
          51514,
          7466,
          24481,
          1147,
          6873,
          11,
          1954,
          11,
          20306,
          36275,
          259,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.27787534814131887,
        "compression_ratio": 1.5231481481481481,
        "end": 6827.6,
        "id": 2090,
        "no_speech_prob": 0.00003822907092398964,
        "seek": 679960,
        "start": 6825.6,
        "temperature": 0.2,
        "text": " oh, nodes is not defined.",
        "tokens": [
          51664,
          1954,
          11,
          13891,
          307,
          406,
          7642,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6830.6,
        "id": 2091,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6827.6,
        "temperature": 0,
        "text": " Dot, this dot, this dot, this dot,",
        "tokens": [
          50364,
          38753,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6832.6,
        "id": 2092,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6830.6,
        "temperature": 0,
        "text": " it's gotta be that, right?",
        "tokens": [
          50514,
          309,
          311,
          3428,
          312,
          300,
          11,
          558,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6834.6,
        "id": 2093,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6832.6,
        "temperature": 0,
        "text": " The this dot song, never forget.",
        "tokens": [
          50614,
          440,
          341,
          5893,
          2153,
          11,
          1128,
          2870,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6838.6,
        "id": 2094,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6834.6,
        "temperature": 0,
        "text": " The this dot song,",
        "tokens": [
          50714,
          440,
          341,
          5893,
          2153,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6840.6,
        "id": 2095,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6838.6,
        "temperature": 0,
        "text": " never forget,",
        "tokens": [
          50914,
          1128,
          2870,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6842.6,
        "id": 2096,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6840.6,
        "temperature": 0,
        "text": " the this dot song.",
        "tokens": [
          51014,
          264,
          341,
          5893,
          2153,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6844.6,
        "id": 2097,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6842.6,
        "temperature": 0,
        "text": " Okay, Ellen Barkin,",
        "tokens": [
          51114,
          1033,
          11,
          20306,
          36275,
          259,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6846.6,
        "id": 2098,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6844.6,
        "temperature": 0,
        "text": " was in diner with Kevin Bacon,",
        "tokens": [
          51214,
          390,
          294,
          3791,
          260,
          365,
          9954,
          42460,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6848.6,
        "id": 2099,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6846.6,
        "temperature": 0,
        "text": " and Lynn Marta was in Footloose with Kevin Bacon,",
        "tokens": [
          51314,
          293,
          27469,
          5807,
          64,
          390,
          294,
          20989,
          752,
          541,
          365,
          9954,
          42460,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6850.6,
        "id": 2100,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6848.6,
        "temperature": 0,
        "text": " and Mark Ruffalo was in Spotlight",
        "tokens": [
          51414,
          293,
          3934,
          497,
          1245,
          10334,
          390,
          294,
          19102,
          2764,
          51514
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6852.6,
        "id": 2101,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6850.6,
        "temperature": 0,
        "text": " with Billy Cronop, was in Eat Pray Love",
        "tokens": [
          51514,
          365,
          18179,
          383,
          2044,
          404,
          11,
          390,
          294,
          14429,
          36365,
          5956,
          51614
        ]
      },
      {
        "avg_logprob": -0.2065643682712462,
        "compression_ratio": 1.8333333333333333,
        "end": 6854.6,
        "id": 2102,
        "no_speech_prob": 0.004198700189590454,
        "seek": 682760,
        "start": 6852.6,
        "temperature": 0,
        "text": " with Julia Roberts, who was in Flatliners",
        "tokens": [
          51614,
          365,
          18551,
          20919,
          11,
          567,
          390,
          294,
          36172,
          5045,
          433,
          51714
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6857.6,
        "id": 2103,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6854.6,
        "temperature": 0,
        "text": " with Kevin Bacon.",
        "tokens": [
          50364,
          365,
          9954,
          42460,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6861.6,
        "id": 2104,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6857.6,
        "temperature": 0,
        "text": " Okay, so this is breath first search",
        "tokens": [
          50514,
          1033,
          11,
          370,
          341,
          307,
          6045,
          700,
          3164,
          50714
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6862.6,
        "id": 2105,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6861.6,
        "temperature": 0,
        "text": " in two videos.",
        "tokens": [
          50714,
          294,
          732,
          2145,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6864.6,
        "id": 2106,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6862.6,
        "temperature": 0,
        "text": " If you watched this the whole way through,",
        "tokens": [
          50764,
          759,
          291,
          6337,
          341,
          264,
          1379,
          636,
          807,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6866.6,
        "id": 2107,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6864.6,
        "temperature": 0,
        "text": " that is amazing to me, thank you very much.",
        "tokens": [
          50864,
          300,
          307,
          2243,
          281,
          385,
          11,
          1309,
          291,
          588,
          709,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6869.6,
        "id": 2108,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6866.6,
        "temperature": 0,
        "text": " Hashtag, six degrees of Kevin Bacon,",
        "tokens": [
          50964,
          8646,
          357,
          559,
          11,
          2309,
          5310,
          295,
          9954,
          42460,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6871.6,
        "id": 2109,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6869.6,
        "temperature": 0,
        "text": " breath first search algorithm, whatever.",
        "tokens": [
          51114,
          6045,
          700,
          3164,
          9284,
          11,
          2035,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6873.6,
        "id": 2110,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6871.6,
        "temperature": 0,
        "text": " You know, there's a lot of details about algorithms,",
        "tokens": [
          51214,
          509,
          458,
          11,
          456,
          311,
          257,
          688,
          295,
          4365,
          466,
          14642,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6875.6,
        "id": 2111,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6873.6,
        "temperature": 0,
        "text": " things I'm sure I've missed here.",
        "tokens": [
          51314,
          721,
          286,
          478,
          988,
          286,
          600,
          6721,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6877.6,
        "id": 2112,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6875.6,
        "temperature": 0,
        "text": " Thinking about the interactivity,",
        "tokens": [
          51414,
          24460,
          466,
          264,
          4648,
          4253,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6878.6,
        "id": 2113,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6877.6,
        "temperature": 0,
        "text": " you could visualize this,",
        "tokens": [
          51514,
          291,
          727,
          23273,
          341,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6880.6,
        "id": 2114,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6878.6,
        "temperature": 0,
        "text": " so many wonderful possibilities.",
        "tokens": [
          51564,
          370,
          867,
          3715,
          12178,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21021285889640687,
        "compression_ratio": 1.6028880866425992,
        "end": 6882.6,
        "id": 2115,
        "no_speech_prob": 0.007345688994973898,
        "seek": 685460,
        "start": 6880.6,
        "temperature": 0,
        "text": " I am gonna be done for today,",
        "tokens": [
          51664,
          286,
          669,
          799,
          312,
          1096,
          337,
          965,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6886.6,
        "id": 2116,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6882.6,
        "temperature": 0,
        "text": " and I will see you in a future video sometime.",
        "tokens": [
          50364,
          293,
          286,
          486,
          536,
          291,
          294,
          257,
          2027,
          960,
          15053,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6890.6,
        "id": 2117,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6886.6,
        "temperature": 0,
        "text": " As always, the code for this particular challenge",
        "tokens": [
          50564,
          1018,
          1009,
          11,
          264,
          3089,
          337,
          341,
          1729,
          3430,
          50764
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6891.6,
        "id": 2118,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6890.6,
        "temperature": 0,
        "text": " is in the description,",
        "tokens": [
          50764,
          307,
          294,
          264,
          3855,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6892.6,
        "id": 2119,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6891.6,
        "temperature": 0,
        "text": " as well as links to other videos",
        "tokens": [
          50814,
          382,
          731,
          382,
          6123,
          281,
          661,
          2145,
          50864
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6893.6,
        "id": 2120,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6892.6,
        "temperature": 0,
        "text": " and things that I've referenced.",
        "tokens": [
          50864,
          293,
          721,
          300,
          286,
          600,
          32734,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6895.6,
        "id": 2121,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6893.6,
        "temperature": 0,
        "text": " If anything's missing, just let me know in the comments.",
        "tokens": [
          50914,
          759,
          1340,
          311,
          5361,
          11,
          445,
          718,
          385,
          458,
          294,
          264,
          3053,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6896.6,
        "id": 2122,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6895.6,
        "temperature": 0,
        "text": " Thanks for watching.",
        "tokens": [
          51014,
          2561,
          337,
          1976,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6899.6,
        "id": 2123,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6896.6,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          51064,
          1057,
          558,
          11,
          2201,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6902.6,
        "id": 2124,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6899.6,
        "temperature": 0,
        "text": " Oh my God.",
        "tokens": [
          51214,
          876,
          452,
          1265,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18703540490598095,
        "compression_ratio": 1.4808510638297872,
        "end": 6909.6,
        "id": 2125,
        "no_speech_prob": 0.04208148643374443,
        "seek": 688260,
        "start": 6906.6,
        "temperature": 0,
        "text": " Unfortunately, I don't think I can manage right now",
        "tokens": [
          51564,
          8590,
          11,
          286,
          500,
          380,
          519,
          286,
          393,
          3067,
          558,
          586,
          51714
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6912.6,
        "id": 2126,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6909.6,
        "temperature": 0,
        "text": " to do the homework assignment video,",
        "tokens": [
          50364,
          281,
          360,
          264,
          14578,
          15187,
          960,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6914.6,
        "id": 2127,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6912.6,
        "temperature": 0,
        "text": " but the good news is,",
        "tokens": [
          50514,
          457,
          264,
          665,
          2583,
          307,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6916.6,
        "id": 2128,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6914.6,
        "temperature": 0,
        "text": " any of you who are watching this live,",
        "tokens": [
          50614,
          604,
          295,
          291,
          567,
          366,
          1976,
          341,
          1621,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6917.6,
        "id": 2129,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6916.6,
        "temperature": 0,
        "text": " if you want the homework assignment",
        "tokens": [
          50714,
          498,
          291,
          528,
          264,
          14578,
          15187,
          50764
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6918.6,
        "id": 2130,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6917.6,
        "temperature": 0,
        "text": " to sort of think about it,",
        "tokens": [
          50764,
          281,
          1333,
          295,
          519,
          466,
          309,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6919.6,
        "id": 2131,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6918.6,
        "temperature": 0,
        "text": " it's just on the,",
        "tokens": [
          50814,
          309,
          311,
          445,
          322,
          264,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6921.6,
        "id": 2132,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6919.6,
        "temperature": 0,
        "text": " I mean, one thing I should say is",
        "tokens": [
          50864,
          286,
          914,
          11,
          472,
          551,
          286,
          820,
          584,
          307,
          50964
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6925.6,
        "id": 2133,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6921.6,
        "temperature": 0,
        "text": " this website is for the actual NYU course,",
        "tokens": [
          50964,
          341,
          3144,
          307,
          337,
          264,
          3539,
          42682,
          1164,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6927.6,
        "id": 2134,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6925.6,
        "temperature": 0,
        "text": " but you're all welcome to read",
        "tokens": [
          51164,
          457,
          291,
          434,
          439,
          2928,
          281,
          1401,
          51264
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6929.6,
        "id": 2135,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6927.6,
        "temperature": 0,
        "text": " and participate and make pull requests,",
        "tokens": [
          51264,
          293,
          8197,
          293,
          652,
          2235,
          12475,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6931.6,
        "id": 2136,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6929.6,
        "temperature": 0,
        "text": " but this wiki that has the homework assignment",
        "tokens": [
          51364,
          457,
          341,
          261,
          9850,
          300,
          575,
          264,
          14578,
          15187,
          51464
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6935.6,
        "id": 2137,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6931.6,
        "temperature": 0,
        "text": " with some ideas here,",
        "tokens": [
          51464,
          365,
          512,
          3487,
          510,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6936.6,
        "id": 2138,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6935.6,
        "temperature": 0,
        "text": " so let me,",
        "tokens": [
          51664,
          370,
          718,
          385,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.16993739788348858,
        "compression_ratio": 1.782258064516129,
        "end": 6938.6,
        "id": 2139,
        "no_speech_prob": 0.009267652407288551,
        "seek": 690960,
        "start": 6936.6,
        "temperature": 0,
        "text": " it's just for students here at NYU,",
        "tokens": [
          51714,
          309,
          311,
          445,
          337,
          1731,
          510,
          412,
          42682,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6939.6,
        "id": 2140,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6938.6,
        "temperature": 0,
        "text": " but you can share your stuff with me in the comments",
        "tokens": [
          50364,
          457,
          291,
          393,
          2073,
          428,
          1507,
          365,
          385,
          294,
          264,
          3053,
          50414
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6940.6,
        "id": 2141,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6939.6,
        "temperature": 0,
        "text": " and that sort of thing.",
        "tokens": [
          50414,
          293,
          300,
          1333,
          295,
          551,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6943.6,
        "id": 2142,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6940.6,
        "temperature": 0,
        "text": " So these are my exercise ideas,",
        "tokens": [
          50464,
          407,
          613,
          366,
          452,
          5380,
          3487,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6944.6,
        "id": 2143,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6943.6,
        "temperature": 0,
        "text": " which is really just,",
        "tokens": [
          50614,
          597,
          307,
          534,
          445,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6945.6,
        "id": 2144,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6944.6,
        "temperature": 0,
        "text": " you know,",
        "tokens": [
          50664,
          291,
          458,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6946.6,
        "id": 2145,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6945.6,
        "temperature": 0,
        "text": " if you look through a bunch of the things",
        "tokens": [
          50714,
          498,
          291,
          574,
          807,
          257,
          3840,
          295,
          264,
          721,
          50764
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6948.6,
        "id": 2146,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6946.6,
        "temperature": 0,
        "text": " that I've done already,",
        "tokens": [
          50764,
          300,
          286,
          600,
          1096,
          1217,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6949.6,
        "id": 2147,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6948.6,
        "temperature": 0,
        "text": " you can think about,",
        "tokens": [
          50864,
          291,
          393,
          519,
          466,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6950.6,
        "id": 2148,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6949.6,
        "temperature": 0,
        "text": " have this animal guessing game,",
        "tokens": [
          50914,
          362,
          341,
          5496,
          17939,
          1216,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6952.6,
        "id": 2149,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6950.6,
        "temperature": 0,
        "text": " which uses kind of like a binary tree-like thing",
        "tokens": [
          50964,
          597,
          4960,
          733,
          295,
          411,
          257,
          17434,
          4230,
          12,
          4092,
          551,
          51064
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6955.6,
        "id": 2150,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6952.6,
        "temperature": 0,
        "text": " to do a 20 questions-like thing.",
        "tokens": [
          51064,
          281,
          360,
          257,
          945,
          1651,
          12,
          4092,
          551,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6957.6,
        "id": 2151,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6955.6,
        "temperature": 0,
        "text": " Use a bigger data set with this",
        "tokens": [
          51214,
          8278,
          257,
          3801,
          1412,
          992,
          365,
          341,
          51314
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6960.6,
        "id": 2152,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6957.6,
        "temperature": 0,
        "text": " six degrees of Kevin Bacon.",
        "tokens": [
          51314,
          2309,
          5310,
          295,
          9954,
          42460,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6962.6,
        "id": 2153,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6960.6,
        "temperature": 0,
        "text": " Your own data set, visualize it.",
        "tokens": [
          51464,
          2260,
          1065,
          1412,
          992,
          11,
          23273,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6963.6,
        "id": 2154,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6962.6,
        "temperature": 0,
        "text": " These are the kind of things I'm looking for people",
        "tokens": [
          51564,
          1981,
          366,
          264,
          733,
          295,
          721,
          286,
          478,
          1237,
          337,
          561,
          51614
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6964.6,
        "id": 2155,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6963.6,
        "temperature": 0,
        "text": " to try to do.",
        "tokens": [
          51614,
          281,
          853,
          281,
          360,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6965.6,
        "id": 2156,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6964.6,
        "temperature": 0,
        "text": " What's your own,",
        "tokens": [
          51664,
          708,
          311,
          428,
          1065,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.20593586422148205,
        "compression_ratio": 1.7160493827160495,
        "end": 6966.6,
        "id": 2157,
        "no_speech_prob": 0.005301744677126408,
        "seek": 693860,
        "start": 6965.6,
        "temperature": 0,
        "text": " can you make a piece of art with this?",
        "tokens": [
          51714,
          393,
          291,
          652,
          257,
          2522,
          295,
          1523,
          365,
          341,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6968.6,
        "id": 2158,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6966.6,
        "temperature": 0,
        "text": " And then other examples that I have",
        "tokens": [
          50364,
          400,
          550,
          661,
          5110,
          300,
          286,
          362,
          50464
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6970.6,
        "id": 2159,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6968.6,
        "temperature": 0,
        "text": " that I want to just quickly show you",
        "tokens": [
          50464,
          300,
          286,
          528,
          281,
          445,
          2661,
          855,
          291,
          50564
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6972.6,
        "id": 2160,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6970.6,
        "temperature": 0,
        "text": " that are in the repository.",
        "tokens": [
          50564,
          300,
          366,
          294,
          264,
          25841,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6974.6,
        "id": 2161,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6972.6,
        "temperature": 0,
        "text": " So there's the binary tree stuff,",
        "tokens": [
          50664,
          407,
          456,
          311,
          264,
          17434,
          4230,
          1507,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6976.6,
        "id": 2162,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6974.6,
        "temperature": 0,
        "text": " which I have other videos about,",
        "tokens": [
          50764,
          597,
          286,
          362,
          661,
          2145,
          466,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6978.6,
        "id": 2163,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6976.6,
        "temperature": 0,
        "text": " which don't have as nice of a visualization in them,",
        "tokens": [
          50864,
          597,
          500,
          380,
          362,
          382,
          1481,
          295,
          257,
          25801,
          294,
          552,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6980.6,
        "id": 2164,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6978.6,
        "temperature": 0,
        "text": " but you can see this one.",
        "tokens": [
          50964,
          457,
          291,
          393,
          536,
          341,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6984.6,
        "id": 2165,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6980.6,
        "temperature": 0,
        "text": " This is the same exact breath-first search,",
        "tokens": [
          51064,
          639,
          307,
          264,
          912,
          1900,
          6045,
          12,
          29581,
          3164,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6987.6,
        "id": 2166,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6984.6,
        "temperature": 0,
        "text": " but using force-directed graph.",
        "tokens": [
          51264,
          457,
          1228,
          3464,
          12,
          44868,
          292,
          4295,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6989.6,
        "id": 2167,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6987.6,
        "temperature": 0,
        "text": " I have a Dijkstra's algorithm example",
        "tokens": [
          51414,
          286,
          362,
          257,
          413,
          6940,
          19639,
          311,
          9284,
          1365,
          51514
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6990.6,
        "id": 2168,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6989.6,
        "temperature": 0,
        "text": " that's just straight from the book,",
        "tokens": [
          51514,
          300,
          311,
          445,
          2997,
          490,
          264,
          1446,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6993.6,
        "id": 2169,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6990.6,
        "temperature": 0,
        "text": " but it just console logs the answer.",
        "tokens": [
          51564,
          457,
          309,
          445,
          11076,
          20820,
          264,
          1867,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.181906305040632,
        "compression_ratio": 1.7048611111111112,
        "end": 6995.6,
        "id": 2170,
        "no_speech_prob": 0.001244834391400218,
        "seek": 696660,
        "start": 6993.6,
        "temperature": 0,
        "text": " So I would love to make a video about that at some point.",
        "tokens": [
          51714,
          407,
          286,
          576,
          959,
          281,
          652,
          257,
          960,
          466,
          300,
          412,
          512,
          935,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 6998.6,
        "id": 2171,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 6996.6,
        "temperature": 0,
        "text": " This I have a whole separate set of videos about,",
        "tokens": [
          50414,
          639,
          286,
          362,
          257,
          1379,
          4994,
          992,
          295,
          2145,
          466,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7002.6,
        "id": 2172,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 6998.6,
        "temperature": 0,
        "text": " which is depth-first search to, whoops,",
        "tokens": [
          50514,
          597,
          307,
          7161,
          12,
          29581,
          3164,
          281,
          11,
          567,
          3370,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7004.6,
        "id": 2173,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7002.6,
        "temperature": 0,
        "text": " to make a maze.",
        "tokens": [
          50714,
          281,
          652,
          257,
          33032,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7006.6,
        "id": 2174,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7004.6,
        "temperature": 0,
        "text": " And then, as you guys might have seen,",
        "tokens": [
          50814,
          400,
          550,
          11,
          382,
          291,
          1074,
          1062,
          362,
          1612,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7008.6,
        "id": 2175,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7006.6,
        "temperature": 0,
        "text": " I have some videos on A-star",
        "tokens": [
          50914,
          286,
          362,
          512,
          2145,
          322,
          316,
          12,
          9710,
          51014
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7011.6,
        "id": 2176,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7008.6,
        "temperature": 0,
        "text": " to kind of like path-find within that.",
        "tokens": [
          51014,
          281,
          733,
          295,
          411,
          3100,
          12,
          35072,
          1951,
          300,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7015.6,
        "id": 2177,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7011.6,
        "temperature": 0,
        "text": " And then I made an example of,",
        "tokens": [
          51164,
          400,
          550,
          286,
          1027,
          364,
          1365,
          295,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7019.6,
        "id": 2178,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7017.6,
        "temperature": 0,
        "text": " I made an example of actually A-star",
        "tokens": [
          51464,
          286,
          1027,
          364,
          1365,
          295,
          767,
          316,
          12,
          9710,
          51564
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7020.6,
        "id": 2179,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7019.6,
        "temperature": 0,
        "text": " with the maze generation,",
        "tokens": [
          51564,
          365,
          264,
          33032,
          5125,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7021.6,
        "id": 2180,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7020.6,
        "temperature": 0,
        "text": " so solving for the path.",
        "tokens": [
          51614,
          370,
          12606,
          337,
          264,
          3100,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21719181028186765,
        "compression_ratio": 1.668141592920354,
        "end": 7023.6,
        "id": 2181,
        "no_speech_prob": 0.00015843540313653648,
        "seek": 699560,
        "start": 7021.6,
        "temperature": 0,
        "text": " So these are things you can play around with,",
        "tokens": [
          51664,
          407,
          613,
          366,
          721,
          291,
          393,
          862,
          926,
          365,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7025.6,
        "id": 2182,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7023.6,
        "temperature": 0,
        "text": " and I have other videos that connect to that.",
        "tokens": [
          50364,
          293,
          286,
          362,
          661,
          2145,
          300,
          1745,
          281,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7030.6,
        "id": 2183,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7025.6,
        "temperature": 0,
        "text": " And then, oh, I have the traveling salesperson problem.",
        "tokens": [
          50464,
          400,
          550,
          11,
          1954,
          11,
          286,
          362,
          264,
          9712,
          5763,
          10813,
          1154,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7033.6,
        "id": 2184,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7030.6,
        "temperature": 0,
        "text": " So this is just doing all possibilities with five nodes,",
        "tokens": [
          50714,
          407,
          341,
          307,
          445,
          884,
          439,
          12178,
          365,
          1732,
          13891,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7036.6,
        "id": 2185,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7033.6,
        "temperature": 0,
        "text": " and I'll come back to that next time that I'm around.",
        "tokens": [
          50864,
          293,
          286,
          603,
          808,
          646,
          281,
          300,
          958,
          565,
          300,
          286,
          478,
          926,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7038.6,
        "id": 2186,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7036.6,
        "temperature": 0,
        "text": " Okay, so that's my quick,",
        "tokens": [
          51014,
          1033,
          11,
          370,
          300,
          311,
          452,
          1702,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7040.6,
        "id": 2187,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7038.6,
        "temperature": 0,
        "text": " if people work with this stuff and make stuff,",
        "tokens": [
          51114,
          498,
          561,
          589,
          365,
          341,
          1507,
          293,
          652,
          1507,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7041.6,
        "id": 2188,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7040.6,
        "temperature": 0,
        "text": " share it with me on Twitter,",
        "tokens": [
          51214,
          2073,
          309,
          365,
          385,
          322,
          5794,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7044.6,
        "id": 2189,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7041.6,
        "temperature": 0,
        "text": " share it in the comments, that sort of thing.",
        "tokens": [
          51264,
          2073,
          309,
          294,
          264,
          3053,
          11,
          300,
          1333,
          295,
          551,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7049.6,
        "id": 2190,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7046.6,
        "temperature": 0,
        "text": " Okay, phone is ringing,",
        "tokens": [
          51514,
          1033,
          11,
          2593,
          307,
          18423,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.17447155811747567,
        "compression_ratio": 1.6342412451361867,
        "end": 7051.6,
        "id": 2191,
        "no_speech_prob": 0.009125439450144768,
        "seek": 702360,
        "start": 7049.6,
        "temperature": 0,
        "text": " which means it's time for me to go.",
        "tokens": [
          51664,
          597,
          1355,
          309,
          311,
          565,
          337,
          385,
          281,
          352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7053.6,
        "id": 2192,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7051.6,
        "temperature": 0,
        "text": " It's six o'clock, I'm a half an hour late,",
        "tokens": [
          50364,
          467,
          311,
          2309,
          277,
          6,
          9023,
          11,
          286,
          478,
          257,
          1922,
          364,
          1773,
          3469,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7055.6,
        "id": 2193,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7053.6,
        "temperature": 0,
        "text": " which I said I need to leave by 5.30,",
        "tokens": [
          50464,
          597,
          286,
          848,
          286,
          643,
          281,
          1856,
          538,
          1025,
          13,
          3446,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7057.6,
        "id": 2194,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7055.6,
        "temperature": 0,
        "text": " so I'm looking to see if there's any,",
        "tokens": [
          50564,
          370,
          286,
          478,
          1237,
          281,
          536,
          498,
          456,
          311,
          604,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7058.6,
        "id": 2195,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7057.6,
        "temperature": 0,
        "text": " am I ever going to code straight Java?",
        "tokens": [
          50664,
          669,
          286,
          1562,
          516,
          281,
          3089,
          2997,
          10745,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7060.6,
        "id": 2196,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7058.6,
        "temperature": 0,
        "text": " I do Java in processing,",
        "tokens": [
          50714,
          286,
          360,
          10745,
          294,
          9007,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7063.6,
        "id": 2197,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7060.6,
        "temperature": 0,
        "text": " and I will, I do have on my list",
        "tokens": [
          50814,
          293,
          286,
          486,
          11,
          286,
          360,
          362,
          322,
          452,
          1329,
          50964
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7066.6,
        "id": 2198,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7063.6,
        "temperature": 0,
        "text": " to do some Java in Eclipse videos",
        "tokens": [
          50964,
          281,
          360,
          512,
          10745,
          294,
          462,
          27197,
          2145,
          51114
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7067.6,
        "id": 2199,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7066.6,
        "temperature": 0,
        "text": " that use processing libraries,",
        "tokens": [
          51114,
          300,
          764,
          9007,
          15148,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7069.6,
        "id": 2200,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7067.6,
        "temperature": 0,
        "text": " but I just haven't had the time to get to it yet.",
        "tokens": [
          51164,
          457,
          286,
          445,
          2378,
          380,
          632,
          264,
          565,
          281,
          483,
          281,
          309,
          1939,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7074.6,
        "id": 2201,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7071.6,
        "temperature": 0,
        "text": " Okay, thank you everybody for sticking around",
        "tokens": [
          51364,
          1033,
          11,
          1309,
          291,
          2201,
          337,
          13465,
          926,
          51514
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7075.6,
        "id": 2202,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7074.6,
        "temperature": 0,
        "text": " for this session.",
        "tokens": [
          51514,
          337,
          341,
          5481,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1698414574206715,
        "compression_ratio": 1.5800711743772242,
        "end": 7078.6,
        "id": 2203,
        "no_speech_prob": 0.000626328110229224,
        "seek": 705160,
        "start": 7075.6,
        "temperature": 0,
        "text": " I'm done, I hope that I will be back next Friday.",
        "tokens": [
          51564,
          286,
          478,
          1096,
          11,
          286,
          1454,
          300,
          286,
          486,
          312,
          646,
          958,
          6984,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7083.6,
        "id": 2204,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7078.6,
        "temperature": 0,
        "text": " Like I said, the next month is going to be kind of rough,",
        "tokens": [
          50364,
          1743,
          286,
          848,
          11,
          264,
          958,
          1618,
          307,
          516,
          281,
          312,
          733,
          295,
          5903,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7086.6,
        "id": 2205,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7083.6,
        "temperature": 0,
        "text": " and so I expect to miss a couple weeks here and there,",
        "tokens": [
          50614,
          293,
          370,
          286,
          2066,
          281,
          1713,
          257,
          1916,
          3259,
          510,
          293,
          456,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7089.6,
        "id": 2206,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7086.6,
        "temperature": 0,
        "text": " but I am determined, you know, I would say,",
        "tokens": [
          50764,
          457,
          286,
          669,
          9540,
          11,
          291,
          458,
          11,
          286,
          576,
          584,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7091.6,
        "id": 2207,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7089.6,
        "temperature": 0,
        "text": " if I'm giving myself a personal deadline",
        "tokens": [
          50914,
          498,
          286,
          478,
          2902,
          2059,
          257,
          2973,
          20615,
          51014
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7092.6,
        "id": 2208,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7091.6,
        "temperature": 0,
        "text": " that I feel is realistic,",
        "tokens": [
          51014,
          300,
          286,
          841,
          307,
          12465,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7097.6,
        "id": 2209,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7092.6,
        "temperature": 0,
        "text": " I'm quite determined by the sort of middle of the summer",
        "tokens": [
          51064,
          286,
          478,
          1596,
          9540,
          538,
          264,
          1333,
          295,
          2808,
          295,
          264,
          4266,
          51314
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7099.6,
        "id": 2210,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7097.6,
        "temperature": 0,
        "text": " to have gotten through all this stuff,",
        "tokens": [
          51314,
          281,
          362,
          5768,
          807,
          439,
          341,
          1507,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7102.6,
        "id": 2211,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7099.6,
        "temperature": 0,
        "text": " and certainly I'm going to be preparing",
        "tokens": [
          51414,
          293,
          3297,
          286,
          478,
          516,
          281,
          312,
          10075,
          51564
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7104.6,
        "id": 2212,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7102.6,
        "temperature": 0,
        "text": " and working and researching all this stuff.",
        "tokens": [
          51564,
          293,
          1364,
          293,
          24176,
          439,
          341,
          1507,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1792861213368818,
        "compression_ratio": 1.6704545454545454,
        "end": 7106.6,
        "id": 2213,
        "no_speech_prob": 0.005554746836423874,
        "seek": 707860,
        "start": 7104.6,
        "temperature": 0,
        "text": " Whether the videos happen, we'll see.",
        "tokens": [
          51664,
          8503,
          264,
          2145,
          1051,
          11,
          321,
          603,
          536,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7108.6,
        "id": 2214,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7106.6,
        "temperature": 0,
        "text": " For those of you who are supporting me on Patreon,",
        "tokens": [
          50364,
          1171,
          729,
          295,
          291,
          567,
          366,
          7231,
          385,
          322,
          15692,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7109.6,
        "id": 2215,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7108.6,
        "temperature": 0,
        "text": " I thank you.",
        "tokens": [
          50464,
          286,
          1309,
          291,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7114.6,
        "id": 2216,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7109.6,
        "temperature": 0,
        "text": " If I miss weeks and you want to like turn off your Patreon,",
        "tokens": [
          50514,
          759,
          286,
          1713,
          3259,
          293,
          291,
          528,
          281,
          411,
          1261,
          766,
          428,
          15692,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7116.6,
        "id": 2217,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7114.6,
        "temperature": 0,
        "text": " that's completely understandable.",
        "tokens": [
          50764,
          300,
          311,
          2584,
          25648,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7118.6,
        "id": 2218,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7116.6,
        "temperature": 0,
        "text": " It's nice to have,",
        "tokens": [
          50864,
          467,
          311,
          1481,
          281,
          362,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7120.6,
        "id": 2219,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7118.6,
        "temperature": 0,
        "text": " but I don't want anyone to ever feel obligated to it,",
        "tokens": [
          50964,
          457,
          286,
          500,
          380,
          528,
          2878,
          281,
          1562,
          841,
          9270,
          770,
          281,
          309,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7121.6,
        "id": 2220,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7120.6,
        "temperature": 0,
        "text": " and that sort of thing.",
        "tokens": [
          51064,
          293,
          300,
          1333,
          295,
          551,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7124.6,
        "id": 2221,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7121.6,
        "temperature": 0,
        "text": " So okay, I will see you guys all later.",
        "tokens": [
          51114,
          407,
          1392,
          11,
          286,
          486,
          536,
          291,
          1074,
          439,
          1780,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7125.6,
        "id": 2222,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7124.6,
        "temperature": 0,
        "text": " I'm going to turn off this live stream.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          1261,
          766,
          341,
          1621,
          4309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7128.6,
        "id": 2223,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7125.6,
        "temperature": 0,
        "text": " Good night, good weekend, and keep in touch.",
        "tokens": [
          51314,
          2205,
          1818,
          11,
          665,
          6711,
          11,
          293,
          1066,
          294,
          2557,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7129.6,
        "id": 2224,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7128.6,
        "temperature": 0,
        "text": " Okay, goodbye.",
        "tokens": [
          51464,
          1033,
          11,
          12084,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18514762247415414,
        "compression_ratio": 1.6066176470588236,
        "end": 7134.6,
        "id": 2225,
        "no_speech_prob": 0.03513325750827789,
        "seek": 710660,
        "start": 7129.6,
        "temperature": 0,
        "text": " People are requesting the choo-choo sound.",
        "tokens": [
          51514,
          3432,
          366,
          31937,
          264,
          1586,
          78,
          12,
          339,
          1986,
          1626,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7135.6,
        "id": 2226,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7134.6,
        "temperature": 0,
        "text": " The choo-choo sound.",
        "tokens": [
          50364,
          440,
          1586,
          78,
          12,
          339,
          1986,
          1626,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7136.6,
        "id": 2227,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7135.6,
        "temperature": 0,
        "text": " I'm going to read you,",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          1401,
          291,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7138.6,
        "id": 2228,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7136.6,
        "temperature": 0,
        "text": " since I didn't do any random numbers.",
        "tokens": [
          50464,
          1670,
          286,
          994,
          380,
          360,
          604,
          4974,
          3547,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7141.6,
        "id": 2229,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7138.6,
        "temperature": 0,
        "text": " Like Sesame Street,",
        "tokens": [
          50564,
          1743,
          47686,
          7638,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7144.6,
        "id": 2230,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7141.6,
        "temperature": 0,
        "text": " this episode was brought to you by the letter or the number,",
        "tokens": [
          50714,
          341,
          3500,
          390,
          3038,
          281,
          291,
          538,
          264,
          5063,
          420,
          264,
          1230,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7147.6,
        "id": 2231,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7144.6,
        "temperature": 0,
        "text": " this Coding Train episode was brought to you by the number",
        "tokens": [
          50864,
          341,
          383,
          8616,
          28029,
          3500,
          390,
          3038,
          281,
          291,
          538,
          264,
          1230,
          51014
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7152.6,
        "id": 2232,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7147.6,
        "temperature": 0,
        "text": " 96,587.",
        "tokens": [
          51014,
          24124,
          11,
          20419,
          22,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7157.6,
        "id": 2233,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7152.6,
        "temperature": 0,
        "text": " Hashtag 96587 on Twitter, I don't know.",
        "tokens": [
          51264,
          8646,
          357,
          559,
          1722,
          16824,
          23853,
          322,
          5794,
          11,
          286,
          500,
          380,
          458,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20515793248226769,
        "compression_ratio": 1.5106382978723405,
        "end": 7159.6,
        "id": 2234,
        "no_speech_prob": 0.02886427752673626,
        "seek": 713460,
        "start": 7157.6,
        "temperature": 0,
        "text": " Okay, goodbye.",
        "tokens": [
          51514,
          1033,
          11,
          12084,
          13,
          51614
        ]
      }
    ],
    "transcription": " Can you hear me right? Let's try to pick the time of the week when I am most exhausted. And that's when I'll livestream on YouTube. That's what time it is right now. I have to say that, you know, if you will just bear with me and allow me to have a little therapy with you, few dozen people who happen to be watching this right now, I would say that this week and through the next six or seven or eight weeks, somewhere to the middle of May are probably the busiest weeks for me of the whole year. So I'm here and I'll probably be here next Friday. But I'm only going to be here the Friday after that. But you will see I might miss a Friday, but I'm looking forward to springtime end of May, June, and hopefully then you'll be seeing a lot more of me. So if I seem a little wobbly, a little tired, if you don't see me on a Friday, know that everything is fine, but I do have this like a job thing that I do and it's a busy time of year here at New York University. Okay. So first of all, I have a very important announcement to make. I have some new hydration technology that I have been working on all week, asking for recommendations, typing in credit card information onto Amazon. Actually, you don't have to type in the credit card information. It remembers it. But I present to you a purple water bottle. Okay. The nice thing about this is it's a little less dangerous. I don't know if you remember I had a pitcher one week. So this is good. I'm going to step off stage. I'm off stage right now. It's not really a stage. And drink some water. Okay. Now, I have to get moving here because I've got to leave in about an hour and a half. And you know, first of all, I think it's one hour is a pretty good amount of time for a weekly live stream. I would say. I like to do two hours if I can. Two and a half hours even sometimes. Been having a thing where like the last few weeks I did like five or six hours each Friday. So, audio up. Maybe turn your audio up because I see lots of green. I see people asking if the stream has crashed. Everything looks like it's working for me. So I don't have a lot of time today, but I have two. I'm going to try to over the next several weeks get started with content more quickly. I still would like to do something where I share work from the community, but I'm going to put that aside just for today. Hopefully next week I'll have more time to do that. And I'm going to try to pick essentially one project to do each week. I don't know what I mean by project, but one thing to focus on as opposed to trying to do four or five things. And then I will hopefully as things calm down and my schedule opens up a bit more in May and June, maybe I'll get some do some more other stuff and extra live streams and all sorts of that sort of stuff. Hopefully I'll have some more guests. If you didn't watch, Saran Yitbarek was on this week talking about how to give a good tech talk. Sum it up in one sentence like think about it as a story. I deal with this all the time here, I guess with listening to people present about their work here at NYU. And one thing that I think is a pitfall is you get up, you want to talk about your project and you say, okay, so I made this thing. I did it with Illustrator and then with pen and then purple and pink colors. This doesn't work for wallpaper. Here's my website. I made it with jQuery, but then I had to use a node server because I wanted web sockets because the thing about web sockets is they can talk real time in two directions. And instead of this is my story, this is who I am, this is why I care about this idea and this is the thing that I want to communicate to you today. So anyway, I'm off topic. Toot Toot is absolutely right. Okay, Dan in the chat asks, oh, hey, first of all, hi Dan. My name is also Dan. How long are you live tonight? Let's say 530 p.m. That is about one hour and 25 minutes from now. Okay, but as all of you know, there are always, after this is over, an archive is always uploaded and shorter edited versions of the stuff that I do in this one and a half hour time period are also put together and uploaded separately. Because why not just have redundant content? More views. So what did I want to say? In fact, last week I've been behind on so many things that I haven't even released two videos, two edited versions of, and one of them is not edited at all because it was my palm coding challenge which took me a little over one hour. I see people, everybody's having sort of issues, but book of random numbers, please. I don't have my, unfortunately I don't have my sound effects today. Actually, while I get set up here for a second, I'm going to let you guys in on something. I was noticing, I know that everyone is a big fan of the, I don't know that everyone is a big fan, some people enjoy the This.song. There's, little known to you, there is a second This.song. And actually, I don't know if this was actually the first This.song, but F Looper also made, the Perlinois song that I often play by F Looper, F Looper also made a version of the This.song, which I will now play for you while I, oh, sorry, it's not at the beginning. As always, I always forget the This.song. While I get set up here. This. This. This. This. The This.song. Never forget the This.song. Somebody compose that song for me. Okay. Okay. Okay. Alright, it's funny cause I can't really hear it. Is it too loud? I made it a little louder, but maybe I shouldn't have. Alright, I think I'm ready. So, it's too quiet if anything. Okay, so it's not too loud. Louder, a little quiet. Okay, so what am I going to do today in this short amount of time that I have? I would like to do two things. One is, as a lot of you have requested and know, I am teaching a course here at ITP at NYU called Intelligence and Learning. So, I'm going to do a, what I hope is just a 15, translated to three hours, a 15 to 20 minute introduction to that course, what topics I'm going to cover in that course, what are my goals and sort of themes behind that course, what are some of the references that I'm using for the course, and then, so I'm going to do that. And then after that, I am going to do a quick introduction to week one of the course, which involves search, graph systems and search algorithms. And then I've already made videos on, the next videos that would go in the sequence would be binary tree, maze generation, A-star, traveling salesperson, those videos. And then I want to do one new video, one new tutorial for this material on breadth-first search. And then if I have time, I'll do a quick five minute, like here's some ideas for an exercise that you could do for next week. So, that's my plan. Let me come over here. Okay. Got it. Sound is off on the whiteboard. Thank you guys for letting me know that. I'm going to fix that. Hold on a second. I have to switch to the whiteboard. It's going to take me 30 seconds to fix this. The funny thing is, I bet you, I'll keep playing. No, let me just fix this quickly. Test, test. Okay. So, you should have audio for me now in the whiteboard shot. Yes? Okay. And then, still have audio here. Okay. Okay. Okay. That should be good now. I'm afraid to take the top off of this because I'm going to knock it over. It'll be a little bit easier to drink if I did. Okay. Let's see. Okay, so I've got to get moving here. I'm sure the cameras are about to shut off. I'm not about to. Okay. So, this is the syllabus for the course. Let me give this a little bit. Do this, I think. Okay. I think what I want to do is have this example available. I want to discuss this. Okay. And then, I also want to have this. Nope, nope, nope, wrong thing. Sorry, everybody. Almost ready here. It's not really readable, is it? I wish, well, it will be what it will be. I will zoom in on things. So, that's going to have to do. And same for here. Okay. Okay. This is the real live stream experience. Okay. Everything, the audio is working fine now, correct? I'm seeing old messages, I think. Okay. So, what's going to do, what's going to cover big O notation? I don't think I'm going to get to that today. That's okay, though. Yeah, we're not doing all this today. But this is my schedule for the next seven weeks. I'll probably be slower to get to it on the YouTube channel. So, maybe you might consider this the schedule over the next ten weeks or so. But I'm going to do my best. But this is my schedule in preparing materials and information. So, if you want to follow along with this GitHub repository, there will be stuff each week. Okay. So, boy, one of these days. You know what I was going to do? I had this idea that I would prepare slides for this quick introduction. And then I'd be organized and I'd have, like, a plan for it. Oh, well, next time. You know those courses that are on Coursera? They're very organized. I highly recommend them. Okay. So, here we're going to do, I'm going to get started. Okay. I just pressed some buttons on the cameras to see if that happened. Okay. I don't know what the best thing ‑‑ I guess I'm going to leave this right here. Okay. Here we go. I'm going to get started. Hey, so those of you in the chat, if anybody wants to do me some help, oh, this is not going well. If anybody wants to help me out a little bit, one thing you could do is kind of just keep track of the time. It's something that I don't do a very good job of. I prefer for my videos to be between 20 and 30 minutes long. And then when I have a longer topic, to break them into parts. So, you know, it's a little hard to keep track because sometimes I'll pause and then I'll edit out the pause. But, you know, you might have a sense of that. If anybody wants to kind of send me a little nudge, hey, it's been 20 minutes, let me know. If only I had a JavaScript timer. Yeah. If only I had a timer or some sort of computing device that could keep track of the time. I'm just ‑‑ I'm not ‑‑ okay. Here we go. 4.15. I do not need to look at my phone. Too many random unnecessary alerts. Here we go. Hello, welcome to the first video in a new course, I don't know, series, set of videos that I am here, me, Dan Shiffman, presenting to you on my YouTube channel, The Coding Dream. Okay. So what is this? You might be aware, you might remember me from such videos as The Nature of Code. I have a playlist of videos. Most of these videos were recorded probably several years ago. They cover ‑‑ I'm going to zoom in here, all of these topics one through eight. And I have a book which covers all of these topics one through eight. I have been teaching a class about this stuff for a bunch of years, many years, almost like seven or eight years, in fact. And so this year I am trying something new with this course and therefore also on this YouTube channel. Now, what is this new thing that I'm trying? What always happens when I teach this course is if it's a full semester course at a kind of university‑like place, there are ‑‑ where am I? Over here. There are these ten topics. Oh, you can't see the bottom. Let's see. I'm not zoomed properly. Okay, there we go. There are these ten topics. And what happens is, you know, this here, the first half of it, is really about physics simulation, animation, moving things on the screen, and all the kind of stuff you can do with that. And by the time we get to this, people are on their way and they've been overloaded. They're trying to learn all this stuff that what's here in nine and ten, chapters nine and ten, gets lost. So what I'm doing this year and starting right now is I would like to take what's in this book here, nine and ten, chapters nine and ten, and expand the material out to something that would be several, you know, many sessions about seven, five or six or seven or eight, I have no idea, some amount of sessions of content where I take a closer look at topics related to, and here's the title of this course, intelligence and learning. So I'm going to come over here and I'm going to write that down. This is like what people who are teachers, I've been watching some like open courseware, you know, you have a big chalkboard and then you just like make a point and you write it down. So I'm going to do that. Intelligence and learning. Now, I am specific, first of all, I'm specifically not calling this a course, like artificial intelligence. Nor am I calling this a course, like introduction to machine learning. Nor am I saying it's a course called, say, introduction to deep learning. So what's one reason why I'm not calling it that? Well, first of all, I'm afraid of all these things. So I feel like if I call it, this is a course on artificial intelligence or machine learning, that's a little bit scary to me. You know, but also I want to make the point in this course and that about, let me ask you a question for a second. What's the difference between a computer that is intelligent or a computer that appears intelligent or has a piece of software? Let's say it's a piece of software. What's the difference between a piece of software that is intelligent versus a piece of software that emanates, that gives off, that has the illusion of intelligence? I don't know. And so what this course to me is about is creating systems, examples, interactivity, projects, strange useless experiments that relate to the concept of my computer program. Oh crap. The other computer does. I didn't like what I was saying. And I'm taking a break for a second. All right. I'm going to come back to that. Mateo is going to do some magic editing. I'm going to go from after I'm afraid of all this stuff. The other reason that I want to call this course just intelligence and learning is as I've always done with my materials, I'm not necessarily looking to create a perfect scientific simulation of the... Give me one more chance. You're not over here. Everybody bear with me. Give me one more chance. This is what happens Friday at 4 o'clock. I'm going to get through this. This is the kind of stuff I really struggle with. I'd much rather just be coding right now. But the thing is I'm going to move more quickly. The answer is to move more quickly. Thank you. Thank you for your patience, live audience. Okay. So the other reason why I want to call it intelligence and learning is I want to take the broadest approach possible. So you watching this course, whether it's you implement the latest and greatest perfect machine learning neural network, convolutional recurrent magical system thing that does something you read about in some academic paper or you make some crazy project where it seems like the computer is playing this goofy game with you and how could it possibly be doing that. So there's a lot of space in between. And for me I want to just really take a broad approach to this not just look at only neural networks and machine learning and not just look at only these topics in artificial intelligence. Okay. So first of all, I'm kind of blending all these terms. Let's try to at least define them. So let's ‑‑ I saw this chart in a book somewhere. So I'm going to recreate it. So artificial intelligence is a topic. So what is artificial intelligence? Well, I actually just recently watched a lecture by a professor at MIT, Patrick Winston. Patrick Winston I think says at the opening of the lecture, models ‑‑ someone will correct me if I'm wrong ‑‑ for thinking, perception, and action. So this is a very broad term. So let's think about this for a second. So I'm going to go back to some of my other examples. I'm going to come over here. And I'm going to open it where if we were following along with the sort of ‑‑ if we stopped here at week six or session six or chapter six, whatever you want to call it, and I ran this flocking simulation, I could ask the question, is this artificial intelligence? Wait. Nobody can answer this question. So I'm asking this question. But what's interesting, whether or not you want to say yes or no, I'm going to go back to here for a second. Models for thinking, perception, and action. So one thing, if you remember, if you look at steering behaviors and steering behaviors pioneered by Craig Reynolds, what is it? Action, steering, locomotion. So I've really been focusing on steering. How do you calculate a steering force? How do you do the physics for that? How do you do the physics for one pixel to another? And steering and locomotion kind of cover all of those pieces. Action, this is a place where, well, what is the action? What are the goals? In the flocking system, the goals are stay with your neighbors, but don't crash into your neighbors, and also stay in proximity to your neighbors and also move in the same direction as your neighbors, but don't crash into your neighbors. And the other kind of action things that you might select is follow this thing or chase this thing or run away from this thing or try to get through this doorway the fastest that you can. So what's interesting here is seeing this link is what are models for thinking and perception that might lead to action to govern the types of animated systems that you might create? So this to me is the link here. Whether it's enough to say I am going to kind of define the rules, almost known as like a rule-based system, feature engineering, so to speak. Like I don't need a learning-based system. I'm going to define the rules of how all these things should behave, but they're going to appear intelligent versus something like a learning system which has to learn over time. So machine learning being something that crosses over with artificial intelligence, I think of machine learning as something that you have data and you make meaning from that data. So how do you, and there's more to it than this, but one of the most classic applications of a machine learning system is classifying data. Classification. So here's a bunch of pictures. Which ones are cats and which ones are dogs? And there's more, you know, the other type of system that you, classic application of machine learning is regression, which instead of categorizing into a discrete set of labels, you know, cats or dogs, you might say, you know, here's all of these. You want to arrive at a more continuous result. So here's all these properties of a house. How many bedrooms? Where is it located? How many bathrooms? And can the system take that data and determine predictive price? So these are two classic tasks in machine learning. Now, what's in the news and what's all the rage? What's everybody working with these days are neural networks. So, you know, a popular and powerful and exciting, so much new research in this right now, recently, of creating machine learning systems to do these tasks with neural networks. However, in this course, I want to look at other systems that do the same thing, that are simpler, that might not be as powerful, but might have opportunities for creative possibilities. But also, if you can use the simpler system for the same result, it's going to make it a little easier to perhaps dive into what in my mind might be the most difficult. I might cancel this part. Actually, last time I mentioned machine learning, a fire alarm went off, which saved me. Nothing happened this time. But so we'll see. So now, so these are areas where I want to just look at and cover in this course. Now, what's this thing down here under DL? This is deep learning. And you know what? I'm going to put deep learning in here. So as I just mentioned, one technique for performing these machine learning tasks is using something called an artificial neural network. So an artificial neural network is a system where the data flows in as inputs. And there are some set of connected neurons that we... So... How am I doing on time, everybody? The birds have no feelings looking at the chat. Okay. Let me come back. Let me erase this for a second. Let me do that again for a second because I lost my train of thought. 4.30. Okay. Got to keep moving. Okay. So in the case of an artificial neural network, that data that you're trying to classify enters as input to something called a neuron. And then passes through a network of neurons to have some sort of output. And I spelled that wrong, but close enough. Cat, dog, price of a house, that sort of thing. Now, an artificial neural network is a system... And I'm going to get more into this in another video that's specifically just about this. So I kind of want to just actually kind of move ahead and skip over this. But the reason why I was mentioning this is there's a long history of this. And the very first discovery of an artificial neural network, and I'm going to build one of these in a future coding challenge, is called a perceptron. Which is almost wrong to call it a network because it's a single neuron. So a model for a single neuron. An artificial neural network being a model for many interconnected neurons. Maybe it's a fully connected network. Maybe it's like a partially connected network. But the reason why so much... that there has been a revolution in research and applications. Neural networks, when they were first discovered, this idea of a perceptron, couldn't solve very simple problems. So there's a famous paper, the perceptron paper, McCullough-Pitts. I believe I'm getting that right. So I mean, the chat will confirm. I'll try to link to that information in this video's description. And there were various steps along the way. But there was a long time before anyone was really able to do a lot of work with neural networks. And so deep learning refers to the idea of a neural network which has a lot of depth to it. So in between the inputs and the outputs, output, and these could both be plural or singular, there are many, many, many layers. It is deep. Very deep. So you could imagine all of these connections. And so the idea here... and the training systems and how it works and how the learning system... Ah, we've got to get into all that. But that's not for this video right here. I got off on this tangent about neural networks. So these are the different aspects of the pieces of this course that I would like to look at. Now, let me come back over here. Okay, I'm coming back over here. Anybody... Oh, someone sent me an amount of time so far. About 10 minutes. A few minutes ago. Great. Okay, that's good. Okay. So... Anybody want to fact check my McCullough-Pitts reference? Perceptron. McCullough-Pitts and perceptron models. McCullough-Pitts model. So I must be right. Okay, good. Okay. Alright. Okay. So, history of the perceptron. I'm going to do stuff about the history and all that when I actually do neural networks, I think. So I'm coming back over here. What was... oh, this would be open. And... This was open. Okay. And I probably zoomed in on this. Okay. So let me come back. Okay, so let me take a look at the list of topics. I'm going to skip week one for a second. So this is the course. If you want, this URL will be in the video's description. This is the syllabus for the course. It's kind of my working document. Boy, do I accept any and all contributions and help. So feel free to file GitHub issues and pull requests and things. And if I come down here to the... Oh, and I'm kind of in a place where you can't really see it. I'm going to skip over week one. And so here are my topics. So I'm going to go through these kind of quickly. Again, this is very survey-oriented. And I'm missing a ton of stuff. So this is just a selection, but I'm also still figuring this out. So next week, I'm going to talk about genetic algorithms, which is an evolutionary-based approach to solving problems with... which is a way of solving problems in software, taking inspiration from evolutionary processes in nature. So I already have a bunch of videos on that, and I'll do some more content about that as well. And that will be in next week. This should say classification and regression. And recently I learned that the term regression comes from regression to the mean. And this is like a 19th century concept. But anyway, I'll talk about where I'm getting all my info. I just read a bunch of books in the last week. I have to thank all these people that I'm probably messing up all the stuff that I read. But I want to get interested in those... I want to get started with those tasks without using neural network-based models. So something called k-nearest neighbor. One of the things I would like to do is build a simple movie recommendation system with k-nearest neighbor as an idea. If you have an idea for a data set or an interesting creative application for k-nearest neighbor that's very simple with a simple data set that I can work with, I would love that suggestion. And also linear regression. So I want to do an example of the simplest form of regression. And we can think of that with an input and having an output that's a continuous floating point value. So I want to look at that. And when we'll do that, we're going to get all this stuff like, oh, there's a learning rate, what's this gradient descent thing, and all this stuff. So hopefully, kind of defining some of those terminology and understanding those pieces as we look at k-nearest neighbor and linear regression will give us a leg up for the next week when we look at neural networks. So I would like to build some simple neural network examples from scratch. And all of this stuff I'm going to do so far probably in processing or JavaScript using the p5.js library, some combination of those things. So if we want to build a perceptron, you know, if I'm feeling ambitious we might look at what happens if instead of a perceptron we have a multi-layered network. And all of this, you can think of the neural network as like you're tuning all of these knobs so that the output gives you something that's correct. There's a whole training process that we're going to have to discuss called supervised learning. Supervised learning, unsupervised learning, reinforcement learning. Interesting topics that I'm going to get into. But one of the most complex aspects of neural networks is what do you do, how do you train all that stuff that's in the middle? And so there's a concept known as back propagation that I... That's like almost like quaternions for me, but I'm not running out of the room just yet. And once I get to there, I want to investigate some other platforms. I might, I might, all this is, I might. But my plan and hope is to look a bit at, once we've built some simple examples from scratch, to look at other tools for some more sophisticated applications like TensorFlow and then be able to get into certain specific kinds of neural networks that can do different kinds of tasks. What is a convolution network, what is a recurrent network, and what is reinforcement learning? So those are some aspects of things and, you know, I don't plan on building those larger, more sophisticated systems from scratch. But if we can build some basic ones, understand how everything works, then my thinking is then we will have a leg up to using frameworks and tools to do some of the other stuff. Again, all this is subject to change. One of the things I mentioned this last week that I'm hoping to do, because even though I might move to something like TensorFlow and Python to demonstrate some examples in some of these other areas, I would love to work on a simple web server that runs TensorFlow in the background that ProcessingerP5 could talk to. There are also examples of some of these written in JavaScript, well-known examples by Andrej Karpathy, the recurrent RNN.js and ConvNet.js. So, people are telling me time's up. I'm doing this live, but you might be watching this in an archive, that I wanted to keep this to 20 minutes. Sound is low. Okay. Hold on. Time out. Okay. Hold on. A lot of people are complaining about the sound. Fortunately for everybody, I have a dial here that I can just turn it up. Is that better? Is that better for everybody? And is there any peaking or distortion? Let me know. Sound is fine. Okay. Well, now it's up a little bit. I guess maybe I shouldn't have changed it for the... Okay. Everyone's saying sound is fine. I turned it up a little bit. Okay. I forgot what I was saying. Okay. So... I think I'm wrapping up then. Okay. So, that's my introduction. You know, here's the thing. I'm learning this stuff. So, if you want to go watch a course from somebody who really knows this stuff, I will link to lots of resources. And that's what I meant to... I wanted to mention some resources that I'm using. Very important that I will include in this video's description. And I think here under the wiki, under related projects and resources, here are some resources that I want to specifically mention. So, one is a website called Machine Learning for Artists. It's got videos, video tutorial, video lectures, examples, written descriptions, lots of wonderful things by an artist and researcher named Gene Kogan. Absolute expert, wonderful in this field. I watched a lot of Rebecca Fiebrink's Machine Learning for Musicians and Artists videos. Rebecca Fiebrink has made something absolutely wonderful called Wekinator, which is a tool that allows you to send data. It does machine learning stuff and it sends it back out all with something called OSC, Open Sound Control. I would love to do some video tutorials on that or have some guest tutorials from Rebecca Fiebrink. There's also a cadenza course on creative applications with TensorFlow that I intend to look at and get some resources from. I also want to mention the... let's see, what else? Ah! Andrew Glasner is writing a book about machine learning and deep learning. It is not out yet, but he was generous enough to let me look at some preview drafts. So, thank you very much. Follow at Andrew Glasner on Twitter if you want to find out about his upcoming book that's coming out. It's been really helpful to read. And I'm sure there are... Ah, yeah, also... Grokking Deep Learning is a book from Manning and Grokking Algorithms. These are books that I've mentioned that I have been looking, as well as Make Your Own Neural Network, which is a book that walks you through programming your own neural network in Python. Now, people in the chat are giving me lots of suggestions for other deep learning and machine learning and AI books. Oh, I don't have my props. I have these old textbooks. I'll bring those another time on artificial intelligence, which are great. But the other thing I would recommend is... These are three compilations of resources. So, this is one that's put together by this community. This is awesome machine learning. There's a lot of awesome blank lists that are put together. Let me see who puts this together, just because I forgot. From Joseph Misciti on GitHub. And also, this is a list of resources from Memo Atkin. Okay, so, please, I'm accepting all suggestions and help and examples and ideas. I look forward to all of the, hopefully not so angry letters I will receive as I screw everything up over the next six or seven weeks. We're going to... I guess what I didn't really say is, I have... To wrap up here, what I have is these two chapters in Nature of Code, which deal with genetic algorithms and the basics of neural networks. That's where I've kind of left my knowledge behind. And I'm embarking on this journey here on YouTube to try to expand past what's in there. And we will see how it goes. So, thanks for joining me. And I look forward to seeing you in some future videos. Okay. Great. Stay hydrated. Alright, so that was my introduction. There were so many things that I wanted to talk about and cover, but I think it was good that I didn't. Okay. I'm okay on time. It's 4.40. So now what I want to do is introduce the first week. Oh, I'm there already. Okay. Okay. Yeah, see, I had all these other notes about... These are my notes of things that I want to talk about in my introduction that I didn't really remember. Oh, I wanted to talk... This is so important. Well, what are we going to do? Another time, I will... Maybe I'll do a separate video about this. And we'll come back to it as we get further along. Somebody remind me about this. I don't think I need to reinsert this into that introduction, but I think it's incredibly important when studying and working with these topics to be critical and to ask questions if anything we're doing is actually a good idea. David Ha, who's a researcher at Google, I believe, or Google Creative Lab, who makes lots of great machine learning projects, tweeted at one point, I thought, what happened to making the world a better place? See, I'm doing this now. It'll just be in... You know what? Let's do an addendum. What do you think, Mathieu? You said it was under 20 minutes. I'm going to do a quick addendum. I'm going to do a quick addendum. Oh, I'm back. I do this a lot. I'm back because I forgot that I had this page of notes, and instead I just rambled. It's got a few more links about thinking about the definition of artificial intelligence and machine learning. I'm still working on stuff. You'll find this also linked. But something really important here that I wanted to just mention was... It's very important when studying... I'm literally just going to be looking at the algorithms and making stuff and trying to be creative and whackadoodling my way through this, if that's a verb. But it is really important for you, the world of people who are going to be using these tools, using these algorithms, making projects, working for companies, to be critical and think about what you're doing, and whether it's even a good idea, and is it hurting anybody, is it helping anybody? And so there's some... One thing I'll just mention here is there's an organization called AI Now, which I just learned about recently. I thought I just clicked on them. It's over here. It's an initiative to research the social impacts of artificial intelligence to ensure a more equitable future. So I encourage you to check out. There's going to be a symposium in July. Check out about this. I also just love this quote from Hard Maru on Twitter, which is... David Ha from Google makes a lot of wonderful... There's a wonderful recurrent neural network handwriting with p5.js example that you can find. I'll try to link to that as well. But whatever happened to making the world a better place? So when you talk about what is your goal with building an AI system, with using machine learning, why are you doing it? And so I'll leave you with that. Are you making the world a better place? I hope that you are. And come along. I'll see you in the next video. Okay, you can decide whether to include that or not. That was something that I wanted to say. Here at least in this longer live stream, it will be here in this video. Okay, so now what I want to do is... Yeah, I talked about this. I didn't go over my sort of glossary of terms. But that's okay. We'll come back to those. And now here we go. So I'm going to do... I'm going to now... Okay. Okay. Okay, so here we go. So I'm going to do that. Okay. So now this video... So that was an introduction to the whole course. This video, which I hope will just be 5 to 10 minutes, if not even shorter than that, will be just an introduction to the topics for week 1. And one of the things... My dream has always been... And I just make all these coding challenges and random videos, but they're modular pieces that could be assembled into a course. So I'm kind of trying to do that to some extent here. And most of the stuff that's in this week 1 are topics I've already made videos about. Traveling salesperson, A-star, binary search tree. So the only thing that I'm going to have time for today, really, is... Oh, the camera went off. Is breadth-first search. But as I go on and make more videos... Someday I'll do a video on big O notation. I don't think I'll get to it today. I'll insert it back into this course. So I'm going to do a little introduction. I want to first lay out what the topic is, but also explain to people that these aren't necessarily sequenced, but if you're watching in this playlist, they are. Okay. So sorry I'm going to say everything twice, but I have to sort of figure it out. Okay. Here we go. Let's begin. I'm going to leave this here. Let me actually... So I will... Oh, yeah. Okay. Ooh, this is a mistake. Mmm. I'm not logged... I always forget that I'm not logged in at GitHub. I need to fix this bottom link. Wait, I can do... Ah, never mind. It's fine. I got it. Time is of the essence. Okay. Okay. So maybe you watched the first... The introduction to this larger playlist, the intelligence and learning set of videos, but now this video is an introduction to just the first session. And the first session is about search and graph systems. Now, why? Why? Why should that be the first session? I don't know. It might be a bad idea. First of all, I wanted a warm-up. So I wanted something to kind of get us thinking about algorithms and data and things that seem intelligent or that solve problems in an intelligent way. And also, there are some very, in some ways, common unsolved problems of computer science, like the traveling salesperson problem, which is one of the topics of this week, that could use a newly invented machine learning system to solve it. So anyway, I'm off track. So where does this fit in? So if you go and grab... I wish I had my props. Can we get some post-production here? I'm going to hold up the... What's the book that I always use? Hold on. Time out. It's the Norvig Artificial Intelligence... I just want to get the name of it correct. Artificial Intelligence, a Modern Approach by Russell and Norvig. Okay, that's what I was going to... Good luck editing this. Okay. I'm going to pretend. I'm just going to pretend I'm doing that again, which is so ridiculous. I'm going to do it anyway. Oh, God. I can't believe I do these live. Oh, I don't have my props. If I had my book, Artificial Intelligence, a Modern Approach, the Norvig-Russell book... Yes? I don't know. Hopefully I got that right. You would see a lot of... I don't have my pen anymore. Ah! Continuity error. You would notice that there's a lot of algorithms in these books about search. Because one of the kinds of problems that artificial intelligence algorithms, that intelligent algorithms often need to solve in computer science, in applications, interactivity, all the sort of projects you might be thinking of making, is there's a problem. I need to figure out the answer to this problem. But there are so many possible answers, I couldn't possibly check every single one. And so, search refers to the idea of searching for the answer in a sea of possibilities. Now, one way is to search every single possibility. I mentioned the traveling salesperson problem. Let's talk about that for a second. So, I want to talk about search and graph systems. This is kind of loosely the topic for right now. There goes that eraser. Oh my god! Sorry everybody! The eraser's okay. Everything's fine. So, the traveling salesperson problem says... Oh, I have videos on this already. So, you can go watch those. There are some number of cities. Let's say there are five. And that a salesperson needs to visit all of the cities in the shortest amount of time or with the shortest distance. In any order. Starting with any one, ending with any one. So, I might be able to eyeball this and say, okay, well, maybe that's the path. It's probably not the path. It's probably more like this. Whatever. The point is, we could have a computer algorithm figure this out. Let's just check every single possibility. So, first, let's pick a city. How many cities should I pick? How many cities could I pick? Oh, there's five of them. Okay. Now, if I pick... If there's five possibilities. Now, once I've picked one city, how many possibilities are there left? Four. And how many are left? Three. And how many are left? Two. And how many are left? One. So, five factorial. 20, 60, 120. 120 possibilities for five cities. And this is five factorial. So, this is the kind of problem that doesn't seem like such a big deal. But if I just have 10 cities... What's 10 factorial? Eh, I don't know. A computer could probably crunch through that number. What about 50 cities? Okay. That's a three with 64 zeros after it. It's like a really, really, really big number. I mean, what's the age of the known universe? It's just 13.772 billion years. That other number's a lot more than that. So, and, you know, even if we could do like a million per second or something, trust me, we're going to have some issues. And we'll talk about that. So, what are some solutions to this? Next week, we're going to look at genetic algorithms, which is a technique for trying to optimally find a solution. And there are ways we might say something known as a greedy algorithm. I went off on a tangent here. We'll see if this is a problem. We'll edit this part out. But a greedy algorithm, which might say, like, I don't know, let's just pick a city and then pick the closest one, then pick the closest one to that. It's probably going to get us a pretty good answer, even if it's not the exact optimal answer. The point of what I'm saying is, this is the application that I want to look at in this first week. So, the things that we need to learn about to be able to do things and work with problems like the traveling salesperson are, number one, graph systems. And number two, search algorithms. Okay. Now, what is a graph system? A graph system is something, a system that is made up of two elements, node and an edge. We could name these other things, but I'm going to call them nodes and edges. One of the next videos that you'll watch, if you follow this playlist, will be on something called a binary search tree. A binary tree is a graph system where every node is connected to two children nodes, a left and a right, and those are connected to two, and those are connected to two, et cetera, et cetera, et cetera. So, this is one example of a graph system. So, what you'll notice is, we need some sort of data structure to store what are all the nodes and what are all the edges. And this depends on the problem. A common example, also, of a graph system similar to the traveling salesperson problem is a subway map. So, let's say I need to get from this station to this station. Well, there are all these other stations and routes, and maybe they all are interconnected, and there's many ways to get, and the subway map makes no sense, there's many ways to get there, but they all take different amounts of time. Like, maybe I could go from here to here to here to here to here, which is, hold on, let me redraw this. Time out, editor! Okay, I'm back, I'm going to redraw that to make more sense. Let me just draw it like this. So, let's say we wanted to get from here to here. We could see, like, oh, I'm going to get from, in one step to here, and it's going to, two steps, I want to take two trains to get to here. But what if this train takes 60 minutes, this train takes 30 minutes, and each one of these, this takes five, and this one takes five, and this one takes five, and this one takes 30 minutes, and each one of these, this takes five, this takes two, this takes one, and this takes six. So even though I have to go on one, two, three, four trains, this is optimal, this will get me there faster. This is known as a weighted graph system. So the graph system is a bunch of nodes, those nodes might have values, so a binary search tree you can use to organize in alphabetical order a lot of words, or numbers, and other variety of things. You could think of this, but the edges here don't necessarily have weights, at least in a standard binary tree, but here they do. Now, there's an algorithm for searching for that optimal path in this scenario, in a weighted graph, and it's called Dijkstra's algorithm. There's also another algorithm called A-star, and et cetera, et cetera. So these are different examples, binary search algorithm, Dijkstra's algorithm, A-star, and the one that I'm actually doing today, but that doesn't really matter to you, because you're going to watch these videos in sequence, which I'll talk about in a second, is something called breadth-first search. So breadth-first search is a good algorithm for finding the shortest path between two nodes in a graph that aren't weighted, so the shortest number of steps, and I'll talk about the example that I'm going to use for that in a bit. So this week is all about learning how to program a graph system, and learning about different algorithms to efficiently solve some type of problem associated with a graph system, like the shortest path, and so now, once you stop watching this video, there's going to be a bunch of others in this playlist that I've made at all different times under different circumstances. So this is an experiment that I'm trying, trying to put together a sequence course with all different coding challenges. So you'll see there's a binary search tree example, there will be a breadth-first search example, there is no at the time of this recording, but there might be at the time of your watching, a Dijkstra's algorithm, A-star, so you'll see, and I'm going to be filling stuff in as time goes on. Once you get to the end of all of those, if you choose to watch them all, I'll make another video that kind of wraps up and shows you a bunch of examples all together, and gives you some ideas for some homework exercises that you might do, that you could share with me in the comments, and that sort of thing. If you want to participate in a Slack channel that I have that's going on for this course, you can sign up at patreon.com, Coding Train, it's a crowdfunding thing if you want to participate in that Slack channel, but you can also always hit me up on Twitter at Schiffman, and in the comments here, which I do read. Okay, so that's what's going to happen next, and I will see you if you decide to come back in a wrap-up video where I kind of summarize a bunch of this stuff and give you some exercise ideas. Great, so I'm going to go and actually record a video right now on breadth-first search, but you might watch some of these other ones first. Thanks very much. Let me see, oops, how was that? People are talking about quality, okay. So how are we doing here? How long was that, would you say? That was probably way too long, okay. Oh, big O notation is something I didn't know about. Something I didn't mention, that's fine, that's fine. Nine to 10 minutes, wow, all right. I don't have my soundboard today, I forgot it, sad. Okay, so I got to get set up for this coding challenge. Oh, I knew something I forgot to mention. Does anybody have any questions? Because one thing I should do is answer questions. I totally forgot to mention something important, that's fine. That's fine, because the thing that I want to mention, ah, shoot, I'm going to mention it. I'm going to do my addendum. We can, if it makes no sense, it's just what I always do. Week one, read me. Here. Okay. I didn't really talk about prerequisites. It's a very hard word to say. Prerequisites. Pre-requisites. Okay, I didn't really talk about prerequisites. Pre-requisites. Marriage. Anyway. How many of you get that reference? Okay, you want to see the mug? Oh, I didn't bring the mug, because I have my water bottle. My purple, clean canteen. Sponsored by, wouldn't that be great if they would sponsor me? I can get a water, I actually make that joke, but I really should get a water company or something to sponsor me. Product placement, oh my god. You know what, I think maybe I should just leave things as they are. Let me do a little, maybe this will get added on, maybe it won't, but this is important, so I'm going to mention it here. Okay. Oops. I'm always back at the end of my videos when you think they're over. So one thing I want to mention, that if you're about to watch some of these, the rest of the videos in this sequence, first of all, if you don't know JavaScript programming in p5.js, you might want to take a look at some of my intro to p5.js videos, but more importantly than that, if you have experience with, two things that I'm using in these videos is, one is this concept of prototype, as a way of attaching methods to an object in JavaScript, as well as this idea of an associative array or hash table, and how that works in JavaScript. So those two things might be videos that you might want to go and watch first before you start looking at some of the graph systems and different search algorithms. Just in case that matters to you. But you don't really have to know very much to follow this stuff along. If you know a bit about programming, you've tried, you've watched some of my other videos, hopefully you'll be okay. If not, let me know and I'll see what I can do. Okay, see you soon. Okay. So, oh, I ignore questions. I'm trying to not ignore questions. Oh, Unikitty! Unikitty is in the chat! What sometimes might, the YouTube chat scrolls pretty fast, and it's very hard for me to watch it continuously. So sometimes if there's a really important salient question, and somebody who's in both YouTube and Slack wants to paste it over, that could be a way. Okay. Okay. So how are we on time? Five o'clock. So this is the thing that I'm now hoping to do in a half an hour. It'll take longer, but we'll see. Okay. I've got to get myself ready for this now. So what I need is a couple things. I need to get a data set. Okay, so first, okay, hold on. Ah! I need to go here. So I'm going to clone my repo. And I'm going to run a server. And now I'm going to get the browser back open. Oops, wrong thing. And, oops, I really don't want to run the server from the desktop. That's a little bit silly. Oh, shoot. Ah! Sorry, everybody. I will run it from here. Sorry that I'm standing in front of what I'm doing. I'm just kind of getting some examples ready to go. Oops. Okay, so this one we're going to need. Okay. Thank you. Somebody contributed the force-directed physics of this. I want to make sure I thank this person. Let me look at pull requests. I made a bunch of changes to it, but the original implementation was done by, so first of all, thank you to, there's a bunch, let me thank all of these people. Kate Wieckmann, who has added a lot of links to references and other information. That's been really super helpful. Somebody contributed a better way of laying out the binary tree example that I made, which was in my videos, as well, which is D-Raw on GitHub. And then R-Hacking contributed the force-directed aspect of this particular breadth-first search example. I want to also go to the Wikipedia page because we can follow along with the algorithm here. Okay. And then what I also need is, oh, so now I need to make my own thing. What I'm going to do, let me just get any random example. Let me just grab this one. I'm going to do this from scratch, so I don't need any of this code. I'm going to call this six degrees of bacon. By bacon, I mean Kevin Bacon. And I'm going to open that in Atom. I'm going to delete all of the code. I am going to make a new file, call it Kevin Bacon.json. And then somewhere I made, what I already did is I made a little data set. Here it is. Whoops, let's do this. I can put in here, and there we go. Okay. So now, yeah. Okay, so I'm just about ready to talk about, can you code it in Java? You know, I'm going to do this one in JavaScript in P5 because I wanted to just make it quickly interactive in the browser. But I'm not opposed to making a, oh, the Chrome extension, by the way, that I use, it's really, really good for the, I love this, JSON formatter, Chrome extension. Got to get this Chrome extension. You got to get this Chrome extension, let me tell you. JSON formatter, I believe it's this one, first one that comes up in Google. Okay. But I'm happy to make processing versions or come back and do it again, but today it's going to be, okay. Okay, all right, so this is, okay, so that I wanted to demonstrate just as a diagram. Okay. So I don't know, wait, no, what am I doing? Hold on, everybody, six degrees. I'm going to just run this on a different port. That'll do. There we go. And let me actually just change the title. Six degrees of Kevin Bacon. So I can see that that's different. And there we go. Okay. Okay, so I want to reference this book, which this particular example comes from. Make this bigger. And then, oops. And I have this, and then I have the breadth-first search page. So I think we are good. I'm going to go erase the whiteboard. And so I think, in terms of editing this, I think this, well, it doesn't really have to decide this right now, but I think this is a coding challenge. I could make it one video where I explain the algorithm and another video where I code it, but I kind of prefer to just do them both together. So I think what I'll try to do is, there's a poll now going on. By the way, somebody pointed out that I can use straw poll for polls. And Nadim in the chat asked, will this video be available after the stream ends? Yes, it will be. I think what I want to do is try to do this all at once, like describe the problem and the algorithm and write the code all at the same time. And if it is taking a while, I might break it into two parts. This is probably, I mean, this is in theory much more complex than my pong example, but I don't know why I think in my head this is like not going to take very long to program, but we'll sort of see. Okay. So here we go. Let me see if I can get these cameras to not go to sleep. And where am I? Oh, this other camera. Okay. Here we go. Okay. Here we go, everybody. This is the last thing that I'm going to do today, just so you guys know, although I'm happy to, assuming this goes okay, it's not going to go terribly wrong, but I'm going to try to do this all at once. So I'm going to do this. This is the last thing that I'm going to do today, just so you guys know, although I'm happy to, assuming this goes okay, it's not total, and I don't go running out of here with my hair on fire or something, I will maybe try to answer a few questions. Boy, I'm really exhausted, but we're going to go through this anyway. Yeah, no tea, no coffee, but I do have my clean canteen of water. Okay. Here we go. Welcome to a coding challenge. In this coding challenge, I am going to, what am I going to do? Ah, breadth-first search. What's breadth-first search? Why should you care first? Before I even get into it, I would like to thank the author of this book, Grokking Algorithms, because this particular example, that's not exactly the thing that I'm going to build, but it's something that I did recently after reading this book. This is a version, this example, Do I get my do-over? Okay. Maybe I should use the whistle. Whistle is good luck. Okay. Hello. Welcome to a coding challenge. In this coding challenge, I am going to attempt something called breadth-first search. Now, this is an example, an implementation in p5.js of breadth-first search. It comes directly from this book, Grokking Algorithms, by Aditya Y. Bhargava. It's a wonderful book. I highly recommend it. Buzz marketing books here on my YouTube thing. But I do want to thank, that's where I learned more recently about this algorithm and in practicing it, implemented the example. So what is breadth-first search? So this video, first of all, is also placed in a series of videos about graph systems and search algorithms. So you can, in this video's description, go back to some of the introduction videos that will lead you up to here. But you can also just be here right now because I'm going to do everything from scratch with no knowledge. But a graph system is a system of nodes and edges. And you can see, here are the nodes. Now, the nodes all have a name. These names are exactly the names in the Grokking Algorithms book. And they have edges, so they have connections. You can think of this as maybe a map of friends and their relationships. You could also turn this into more like a maze type thing. There's so many different ways you could sort of visualize this idea of a graph system. And you'll see in some future videos that I actually made previously, I do have some implementations of graph systems to create mazes. But that aside, what breadth-first search is designed to do is find the shortest path between two nodes. And in something like this, it's quite a simple problem to eyeball it. We can see, like, if I want to get from you or me or whoever this person is, to Tom, I can see through Claire there are just two steps. If I want to get to Anuj, this through Bob is faster than going through Alice, Peggy, Bob, Anuj. So how do you figure this out? One algorithm for doing this is called breadth-first search. And the reason why it's called breadth-first search rather than something else that you might have learned about or see in a future video called depth-first search is breadth-first search, by definition, looks at all the nearest nodes first, sees if it finds what it's looking for, then looks at all the nearest ones to those first and sees what it looks to find first, as opposed to going all the way through. I recently made a video about binary trees and search trees. That's more like depth-first search because in the binary tree, you just keep going to the left all the way to the bottom. But here, breadth-first, we're looking at the nearest neighbors to start. Okay, so what's the problem that I'm going to work with today? You may or may not be familiar with... I don't know what this is, a thought experiment, a weird idea, six degrees of Kevin Bacon. There's actually a website. It's called Oracle of Bacon. And I'm going to go to it right now. And I don't know, I need an actor. Let's pick Amy Schumer. And I'm going to pick Find Link. Okay, Amy Schumer has a Bacon number of two. The shortest path between Amy Schumer and Kevin Bacon, Amy Schumer was in the movie Trainwreck with Marissa Tomei, who's in the movie Crazy Stupid Love with Kevin Bacon. So this particular website has a massive database of movies, casts, and uses breadth-first search to find the shortest path between two actors. And the thought experiment here is that Kevin Bacon has just been in so many movies that anyone could be within six degrees of Kevin Bacon. I don't think I have an IMDB. What's the chance that Kevin Bacon to Daniel Shiffman? Nah, infinity. Infinity, we got to work on that. Come on, help me out with this here. I want my Kevin Bacon number to come on down. Okay, so how are we going to do this? Now, I would love if anybody... So this is an experiment. I'm going to do this for you and hopefully teach you something about this. And then maybe you could do something similar but with a different data set. But I'm going to use just a toy data set, essentially. This is what I manually created before coming here. Right now, this data set. So this data set has a few movies in it, some of which have Kevin Bacon in it, and some of which don't have Kevin Bacon in it. It's organized in JSON format, which is JavaScript Object Notation. I do have some video tutorials about that if that's unfamiliar to you, but I'll try to talk about that a little bit as I go through. So let me move over to the whiteboard to figure out how we're going to work this out. So what I need to do in my program... We're going to look at the algorithm itself on Wikipedia and start translating it into code. But before we even do that, what I need is I need a node object. So in the end, there's going to be Kevin Bacon, there's going to be some movie, and there's going to be some other actor. And then there's lots of other stuff. So in order to keep track of these, what I need is I need some sort of object. I'm going to call it a node. And that object needs to have what you call a value or a label. We're going to say a value. It also needs... Each object needs to keep track of its edges. Which other nodes is it connected to? So we need edges, and this will be an array. I don't like these dashes here. They look like minus signs. So I don't know. Dot. That looks like something else, but anyway. This is the data. Now, at its core, this is very similar to my binary search tree that I mentioned, which each node just has a left and a right. But here, each node could have just one connection, zero connections, ten connections. Now, there's other pieces of data that the node is going to need. And these are part of the breadth-first search algorithm. I'm just going to mention them right now because that's why they're in my mind. One is we need to know a Boolean. Has it been checked, searched or not? We're looking for Kevin Bacon. Is this node been checked already to see whether it's Kevin Bacon or not? So this is going to be true or false. This is going to be a Boolean. And we're also going to want... Eventually, we're trying to solve for that path. So we're going to have nodes keep track of their parent, meaning as I'm checking and moving about through this graph system, I want to keep track of where I came from. What was the previous node? So that when I find Kevin Bacon, I can back up and find that full path. So I want to keep track of the parent as well. So we know we need an object that stores all of this stuff. So let me come back and start building that. And I'm just going to put that... So I have a JavaScript project set up. If I go to the browser and refresh the page, there's nothing on the page, but I'm going to start adding some code. So first thing I'm going to do is I'm going to write a constructor function for a node object. And I'm going to say this.value equals something. We needed that. This.edges is an array. This.searched is false. It hasn't been searched. And this.parent... I'm going to just set it equal to null. So I want to be able to, whenever I make a node with this constructor function, even though this, by definition, its parent would be undefined, I'm going to explicitly set it to null just so I'm keeping track of that. Okay. So this is pretty good. This is pretty good. Okay. First of all, this shouldn't be blank. So maybe when I say new node, I'm going to give it a value. Okay. So this is good. You know what I want to do? I want to take this code and I want to put this in a file called... I probably shouldn't call it node.js. Should I? Fine. I'm going to call it node.js. Okay. Okay. So now Sketch doesn't need it. So in p5, p5 has a setup function. Setup function is kind of like window page loaded type thing. So that's going to be in Sketch. I'm also going to make... Here's the thing. I'm going to make a graph object. So I might have some redundancy or some things in my code. I'm sort of out of the picture here. That are a little bit unnecessary. But what I would like to do with the graph object is I would like to store an array of all the nodes. And then I would like... Of all the nodes and I probably need... You know what the graph really should be as a data structure? It would be something like I could look up each node by its... I'll call this a graph by its label, by its value. So this would typically be something like a hash table. Where the key might be Kevin Bacon. And then I could... With that key I would find out all of its edges, its parent, all that other stuff. So I want to be able to have... I might not need this array because I could always... The whole point of the algorithm is to traverse the graph to find what I'm looking for. But it might be useful to have this array if I want to visualize it. Or do something that I could just iterate over all the nodes really quickly. There's going to be some redundancy here. But this is what I'm going to do. So let's go and do that. I look forward to hearing from everybody later about how I'm not doing this correctly. I'm going to say function graph. This.nodes is an array and this.graph is an object. An empty object. So if you're... I'm going to use this object essentially as an associative array or a hash table. And I have a video about that if you're interested. Okay. Now I need to read the data. That's the first thing I need to do. So I'm going to use p5 as a function called preload. Which I can use to... I'm just going to say var data. And then I'm going to say data equals... And this is a p5 function called loadJSON. Where I can just pass in the name of my JSON file which is kevinbacon.json. Kevinbacon.json. JSON. JSON. Ah! What is it? Somebody will tell me. I'm pretty sure from the comments that it's gif though and not jif. I've been told that many a time. Okay. So now I'm just going to... In setup I'm going to say no canvas. p5 makes a canvas by default but I don't need it. And then I'm going to console.log the data. So let's just make sure the data is there. And we can see there it is. So the data came in. I have an object which has an array called movies. And each movie has a property called cast which is an array of all the actors. So that's great. So now what I need to do is I need to make a node for every movie and every actor. Okay. So I want to be able to parse through and read this list. So the object has movies. So I'm going to say var movies equals data.movies. Then I'm going to loop over all the movies in that JSON file. I'm really not on to breadth-first search yet. I'm just kind of gathering the data. And I'm going to get... And what I'm going to do is I'm going to get the movie equals... And what was the movie? The movie has a cast and a title. So the title is also a node. So I want the movie... Movies index i.title. And cast equals movies index i.cast. So first I need to make a node. var n equals a new node movies index i.title. Okay. So... Oh, actually I don't need to say that again. Movie. So I need to make a movie node. And then what I want to do in the graph is I want to say... Oh, I want to say I'm going to make a graph object. And then... Right, the graph object is the thing that's going to keep track of all the nodes. So I need to say at the beginning... Graph equals new graph. And then what I would like to do is add this node to the graph. So I want to take this node object, whose value is a particular movie, and add it to the graph. graph.addNodeN. Now, can I just do this and get this to run? Ta-da! No. Graph is not defined. Okay, so first of all I forgot a bunch of things. One is I forgot I need to add a reference to my node object JavaScript file and the graph object JavaScript file. So that's one problem. Number two, addNode is not a function. This doesn't just exist. It's a function that I need to write. So I'm going to attach a method to the graph object using the prototype. I have a video about what prototype is, if that's not familiar to you. graph.prototype.addNode equals function. Okay, now what comes in a node? So what do I want to do? Okay, so I need first a couple things. One is I want to say this.nodes.push that node. So any node that comes in I want to put it in the array because I want to store all the nodes in an array. Which might be unnecessary, but I'm doing that as a safety mechanism. Then I also want to have a lookup of the node based on the name. So the movie name needs to be the key for that node object. So this is going to look a little bit weird, but I'm going to say title equals n.value. The title is stored in the node's value. Then I'm going to say this.graph index that title equals that node. So this is me putting node into array and node into... It's not really a hash table because it's JavaScript, but I'm thinking of it as like a hash table. Okay, so that's good. I've got the... I've got the... what do I have? The movies. Okay, let's now add the actors. What I'm going to do in this first part is I'm going to add all the data and get the graph set up. Then I'll take a break and there'll be a second part to this video which will be the actual implement the algorithm. So now the cast. I need another loop. I can't use i, so I'm going to use j. The cast.length j++. Now I need to make a node. I'll call this actor equals cast... I'm not calling... sorry. Cast index i... Yeah, the strings are just there in the array. Let me just console.log everything to make sure I'm getting all the... That's correct what I'm thinking here. Okay, so we can see that... Oops, I used index i. I'm like, why is it Steve Guttenberg 14 times? Because this needs to be j. Okay, so now you can see that's me iterating over all the movies and the actors. So now what I need to do is I need to say var actorNode equals a new node with that actor name and then graph addNode actorNode. So just like for every movie, add the movie, then add all the actors. Wonderful. Okay, so now let's also at the end of setup now, let's say console.log graph. Just so we can look at what's in there. And I don't need to console.log the data anymore. I feel confident about that. So, oops, and I don't need to console.log the actors anymore. So let me go here. So this is the graph. You can see it's an array. It's got an array of 74 nodes. It's also got a whole bunch of objects, which all have the actor name or the movie name as the lookup. So this is good. I'm kind of almost there. Like, what do I have so far? I have a graph object, which stores all of these nodes. Only it looks like this. I haven't done any of the edges. So what do I need to do? Every movie needs to be connected to every actor that's in that movie. So I need some way of setting edges. So the edges for each node should be a list of other nodes that it's connected to. So let me see if I can do this. So if I'm thinking about this code-wise, what I want to do here is for every actor, let me call this movie node. I want to say something like movie node.connect actor node. So I want to connect the movie to the actor. And the other thing I want to do, though this is a question that comes up with these kind of algorithms, is the graph, does the graph only go in one direction or do things go in two directions? So in this case, I want to be able to go in either direction. So let's, we need to add this connect function or add edge. Maybe I should just call this add edge. So I have add node, now I have an add edge function. Okay. Here in node, so now I want to add to the node object a function called add edge. And it gets another, I'll call it a neighbor. And then I just want to say this.edges.push neighbor. Simple as that. All I need to do, push the neighbor. Now hold on a second. We've got a problem. I just realized we have a problem. The whole point of this is that actors can be in multiple movies. Right? So here I am, always, always, always making a new actor node. Now I know I can't have two instances of the same movie in this data set. But I could have two instances of the same actor. So whenever I go through the cast, I need to figure out if the node already exists. If the node already exists, I shouldn't make a new node. So I want to say if graph contains actor, then actor node, I want to say var actor node. I'm just going to set an actor node to null for a second. If graph contains the actor, then I want to say graph.get node actor or something. You know what I could do? I could say var actor node equals graph.get the actor. Get node. So I could just have a function that says get node. And that function will return null if the actor is not in there. So then I could say if actor node equals null, then I make a new actor node. So what do I need to add here? I need to add a get node function into the graph. So let me add that. So I want to say graph.prototype.get node equals function. And what do I want to do? I want to look up. So this is like an actor. So I want to say, what do I want to say? var n equals this.graph lookup by the actor. And then return n. So this is going to get undefined, right? It's not going to actually return null. So I should actually say in the main program if actor node equals undefined. So exhausted. This is exhausting. Are you still watching this video? I need to take a nap, but I've got to finish this. It's getting late. Okay. Maybe you just woke up and are having a nice little sip of tea and watching this video. Okay. So I think this is going to work. I might have made a mistake. But let's take a look. Refresh. Ah, okay. Node.js line 8, there is an error. Oh, this should say equals function. I just had the wrong syntax. So now let's look at this. The node. So let's look at any given node. This is Mickey Rourke. Edges. It doesn't have any edges. So what did I forget? The edges have to go both ways. So this.edges.push neighbor and neighbor.edges.push this. Both directions. So let's try that again. Refresh. Let's look at an arbitrary node. Kevin Bacon, which is connected to ah, what did I just do? Kevin Bacon, which is connected to flat liners, footloose, and diner. And if I look at zero, which is diner, it's connected to all these other actors, which are also connected to other things. So I think this is right. I'm pretty sure I have the data correct. Anybody want to say otherwise? Because then I'm going to move on to part 2. So now we can actually do the algorithm. So this would be really nice if I had a visual example. So I will link to this code example as well, which is using a force-directed graph to arrange it. And as an exercise, you can even stop here and just try to visualize this graph. Not the easiest problem. I would love to see your solution. But I'm going to stop, and what I'm going to do in the next video is I'm going to implement the breadth-first search algorithm. And when I come back at the beginning of it, if I found any mistakes, I'll let you know. Okay. 530. Yeah, Mark in the chat writes, can you visualize this? I'm having a hard time understanding this setup. It's a very good point. It's not the best. So what I'm going to do... K. Weekmon asks, there's no inherent set data structure, is there? Set node type. You know what? I don't actually need to set the node type to movie or actor. Yeah, no, I'm kind of just... If we look when I get to this, it's going to say empty set. Wait, what's the empty set? Oh, that's for searched. So I'm doing it differently. So I just need to create a queue and the root. Okay. So I'm doing it a little bit differently, but... Yeah, these are the data structures I'm using. Okay, sorry, I'm fading here, but I'm going to push through and finish this. But it was a really good point in the chat about visualizing this. Maybe I'll start by drawing this out a bit more. Nobody sees any mistakes here? Let's just double check this. This is a terrible way of looking at it, but I'm pretty sure it's right. If I look at this particular actor, it's these edges. Which is Eat, Pray, Love, which is connected to all these other actors. And I don't see any... There's no duplicate. There shouldn't be any duplicates, so I think this is good. Okay. S is a tab with visited nodes. Yeah, yeah, yeah, yeah. Okay. Why don't I make games anymore? I don't know. I wish I was doing that. I agreed to teach this class on artificial intelligence and machine learning. I thought that search algorithms would work. Really, I just want to take a nap and read some nice fiction. But this is what I'm doing. I'm definitely with you there, though. Let's come back here. And... Okay. So, grass. Okay. I'm going to try to finish this now. Okay. Here we go. I know that wasn't a half an hour, because the cameras didn't go off, so that's good. Okay. Okay. Take a nap. Poor Dan. I don't mean for all your sympathy here. Thank you, though. That's nice of you. Okay. Alright. Let's go here. I don't know what to start with. Okay. Oh. Okay. So, I'm back here for part two of this breath-first search algorithm thingy. So, somebody in the chat had asked, this is really hard to follow. Could you visualize this? It's a very, very good point. Unfortunately, the way that I'm building this example right now, I'm not going to build in a lot of graphics features. That's a great exercise for you to do. And I do have other examples that do have those features that I'll link to, you can look at. But I think that we could, at the very least, I could draw it for you, what this is looking like. So, without using actual movie names or actor names, I'm just going to say, like, movie one, movie two, movie three. I'm going to have actor one, actor two. I should probably use real names to make this make more sense. Actor three, actor four, actor five. So, maybe these actors were in this movie. These actors were in this movie. Oops. The actors don't have connections to each other. And this, right? So, the actors, it's only in this particular example, the actors only have connections to each other through movies. And somebody else in the chat mentioned you should distinguish between movie and actor nodes. And that could be an interesting thing to work with. And, you know, depending on how you're visualizing it, you probably would want to do that. But for just finding the shortest path, I don't actually need to do that. So, let's say that actor one, let's say actor four is actually Kevin Bacon. So, what the breadth-first search algorithm looks to do is I want to pick any actor and find the shortest route to get to Kevin Bacon. And this, we can see here is actor two was in movie two with Kevin Bacon. Actor three was in movie two with Kevin Bacon. Or, this is the same distance. Actor five was in movie three with Kevin Bacon. And actor one was in movie one with actor three, who was in movie two with Kevin Bacon. So, there's not a lot of possibilities here. But you could imagine a much more complex interconnected network. And if you think about actors in all the movies they've been in, in full cast lists, it's massive. Okay. So, now, let's come back here. Okay. So, now what I need to do is actually implement the breadth-first search algorithm. Now, before I do that, I need to add a beginning and end. So, I need somewhere to start and somewhere I want to finish. So, always, the graph always wants to end. And I'm going to have a graph have this.end and this.start. So, I'm going to give the graph object an end and a start node. And what I'm going to do is after I've added all the data, I mean, I'm just going to hard code this in, which is a little bit silly. And I'm going to say graph.set and I'll just do it this way. Set and Kevin Bacon and graph.set.start. Let's just pick some actor from, whoops, let's pick some actor from that list. Wasn't Mickey Rourke in that list? Let's see if I get this right. So, Mickey Rourke to Kevin Bacon. Okay. So, now I'm going to go and in graph, I need to add those functions, set start. Set start equals function and I'm going to say actor and then I'm going to say set end. And then this.start equals this.graph. Now, if the actor doesn't exist, we're going to have a problem, but I'm just going to assume that actor does exist. So, I want to pull, I need to get the node. I mean, maybe I could just keep it as a string, but I want to get the node, the particular node that is the start associated with that actor and the particular node that is the end associated with that actor. Okay. We've got that. I should have put that in the last video, but we've got that. Now, we are ready for breadth-first search. So, I'm going to use, I'm just going to pull, I referenced before this book, which is a really great visual explanation, grokking algorithms of this particular algorithm, but I'm just going to try to write the algorithm from the Wikipedia page. But, you know, I could also just explain it to you. So, what we're going to do if we're starting with an actor is we're just going to say breadth-first search means check every single edge connected to this actor. Is that Kevin Bacon? No. Is that Kevin Bacon? No. Is that Kevin Bacon? Nope. So, all of these that aren't Kevin Bacon should get added to something called a queue. A queue is a kind of data structure that's first in, first out. So, it's like lining up to buy tickets. If you've gotten line first, you get to buy the first ticket. So, if this is not Kevin Bacon, it gets added to the queue. Then, M2 is not Kevin Bacon, it gets added to the queue. Now, when I'm done checking all those edges, I go to the queue and take the first thing off, which is M1, and check all its edges. Well, I don't have to check that anymore because it's been checked. So, I've got to mark things checked when I check them, and then I've got to check its edges. Nope. So, that's not it. So, this goes off the queue. Now, this is next. A1 actually then gets added to the queue as well. Then, M2 I've got to check all its edges. That's not Kevin Bacon. It's been checked. It's been checked. Oh, that's Kevin Bacon. I'm done. So, now I'm done. And, all the while I was doing this, by the way, I was keeping track that M2 came from actor 3, and then Kevin Bacon came from actor 4, so that I will then be able to back up and create a list, a path of those nodes. So, the idea is check everything nearest and add that to a queue. And, when you're done checking everything nearest, just keep pulling from the queue to check what's nearest to that, and keep going until you find the nearest node. Check what's nearest to that, and keep going until you find Kevin Bacon. Okay? So, hopefully that helps you understand it a little bit. And, now we're going to... Now, okay. So, empty set S. The way that this is described on Wikipedia is to keep a separate list or set of things that have already been searched. But, I'm going to do this a little bit differently. In my node object, I have a Boolean to keep track of whether it's been searched or not. So, I can just flag it when it's been searched. I don't need a separate data structure for that. But, I do need a queue. Now, here's the thing. I could actually implement a queue and have like... In a fancy way, but I'm in JavaScript. It's late. I'm tired. I'm just going to use an array. Because, an array is something I can add to and I can pull off from the beginning. So, what I'm going to do is I'm going to call it a queue. I'm going to say right down here, var q equals an array. Okay? Var q equals an array. And then, what I'm going to do is... Let's just keep following this algorithm. Okay. So, the root. We got to start with the root. So, the root is the start. So, var start. This is a little silly. This is kind of redundant. But, graph.get. So, I should have this return the value. Var start. Var end. So, that way I can have a reference to it out here. So, I'm going to go to the graph and have it also return this.start. So, I can have the node return this.end. And now, what I'm going to do is... Now, I've got the start. Let's look back at the algorithm. The start's parent is already null. Add root to s. So, root's now going to be searched. Start.searched equals true. That's the first thing. So, I don't need to add it to the set. I'm just going to flag it as searched. Oh, then I need to add it to the queue. Queue.push the start. So, now I'm adding it to the queue. Okay, what else do I need to do? Now, I'm going to keep going as long as the queue has stuff to look at. Now, it is possible that there is no connection. So, you saw that in the quick demonstration in the previous video. There could be infinity. There's no connection. But, as long as queue is not empty, which I could say is while queue.length is greater than zero. I'm sure there's a more elegant way to say that. Dequeue, which means get the first thing off the queue. I think in JavaScript that is... I'm going to just call this current equals a queue.shift. I think it's shift. Is that right? Hopefully, that's right. Somebody correct me if that's wrong. Okay, now, if current is the goal, we're done. Okay. If current equals end, console.log found. And then, I'm going to say current.value. So, just to make sure this works, I'm going to set temporarily the start. Also, to Kevin Bacon. Because now, when I run it, it should set it to searched, put it in the queue, get the first thing off the queue, and check to see if it's the end. I don't know what this is here. Okay, so let's run that. Found Kevin Bacon. So, things are working. If the start and the end are equal, we're good. What's next? I want to check. If it's not, I want to check all of the edges. So, let's go through and say... I probably want to say break here, too. Break is a way of getting out of the loop once you're done. So, I want to say var edges equals current.edges. Then, I want to loop through all of the edges. I want to check them all. First of all, I need to check. Let's call this neighbor equals edges index i. So, if neighbor.searched already, skip it. Maybe I want to say if it's not been searched. What does it say here? If it's not in S, it means it's not searched. Now, it's being searched. So, I'm going to say neighbor.searched equals true. I'm checking it. Then, I also want to set its parent. Where did I just come from? Neighbor.parent equals current. So, where did it just come from? Then, I want to add it to the queue. So, what's that? Queue.push. Push adds it to the end. Neighbor. So, we can see how this algorithm is working. It's really very simple. It seems so complex. It's such a fancy name. But, we're just saying start with the beginning. Look at everything next to it. Did you find it? Nope. Look at everything next to that. Did you find it? Nope. Look at everything next to that. Did you find it? Nope. And, all the while, make sure you don't double check anything you've already checked before. That's really all that's going on here. Okay. Now, let's see. What am I missing? What else? Nothing. Hmm. Let's run this. So, let's run this. Here we go. Hey, found Kevin Bacon. Now, let's change the start to Mickey Rourke. Now, whenever I do these kind of things, I often end up with an infinite loop and the browser crashes. Let's see if I made a mistake somewhere. And, let's see. Nope. Found Kevin Bacon. Now, is this really working? Let's look at... So, let's, every time we check a node, let's console log it. And, let's say console log dot value. So, we checked Mickey Rourke, who's in Diner, and then we checked a bunch of actors. Oh, and found Kevin Bacon, and we're done. Great. Let's use a different actor that is kind of further down here. These are actors that are in movies without Kevin Bacon. So, let's pick Rachel McAdams. Wow, I think we might be done. We're going to add some more stuff to this in a second. But, let's add set start Rachel McAdams. We're not actually done. Ah, I copy pasted the wrong thing. Sorry. Rachel McAdams, sketch, Rachel. Ah, why is this not working? Why can I not copy paste? Ah, oh my goodness, I copy pasted the file. This is falling, everything's falling apart. Help me, Rachel McAdams and Mickey Rourke and Liev Schreiber. Okay, Rachel McAdams. There we go. Okay, let's do this again. We can see what's going on. Rachel McAdams in spotlight with all these actors. Oh my goodness. Which was Ypres Love, all these actors, all these actors, all these actors. Found Kevin Bacon. So, I can't really follow this. This is why I need to now go backwards through the parents. So, when I'm done. So, let's take, this is not helping us follow this. But when we're done here, we should be able to say, I'm going to create a variable called path, which is an array. And I want to put the full path in that array. And I'm going to say, so, path.push, graph.end, right? Or no, end. That's where we're starting. End. And then I want to say, next equals end. So, I want to do a loop to just go from next equals end.parent. And I want to say, while next is not equal to null. I'll explain this again in a second. While next is not equal to null, path.push next, and then next equals next.parent. Okay, let's, I think this is right. Right, what I want to do is, I want to start with the end, and then go backwards. Go to the end's parent, then that one's parent, then that one's parent, and that's one's parent, to trace back to find that path that was found. So, that's what this particular algorithm is doing. We start with the end, then we get the parent of the end, and as long as it exists, put it in the path. And then we get the parent of that, and as long as it exists, put it in the path. And keep doing it until eventually something has no parent anymore, because it's where we started. So, the start has no parent. So, now I should be able to say, and I'm going to actually create a DOM element. I should be able to iterate over the path. Do I have to iterate the path backwards? Because what's, yeah, the last thing is the beginning. So, I'm going to say path.length, I mean I could do this a number of different ways. Minus one, i goes all the way down to zero. And I'm going to say node equals path index i. Then I'm going to say var text equals an empty string. Then I'm going to say text plus equals n.value plus, like an arrow. I should get the right arrow key. And then I'm going to say create p text. So, what I want to do here is just, the reason why I'm doing this is instead of console logging, create p is a p5 function that will create a paragraph element in the browser, so I can see it written out there. So, let's see if this helps. So, we can see, there we go. Rachel McAdams was in Spotlight with Billy Crudup, who was in Eat, Pray, Love with Julia Roberts, who was in Flatliners with Kevin Bacon. Now, I should also have something that, I don't need that last arrow. So, if i is not equal to zero, then also add the arrow. Let me just correct that. And there we go. Now, let's just quickly, while we're here, we're almost done. People are asking in the chat, wouldn't this be a good time to talk about big O notation? Definitely. I've got to make a video about that sometime, and it will come before this one. Maybe you already watched it because you're in the future. Okay. Very quickly, just to make this a little bit more interesting, let me do something. I'm going to use a p5 function. Oh, this is going to make it harder, though. I should really just stop. I'm going to do this anyway. I'm going to say var drop down equals create select. So, what the create select function does is it makes a little drop down menu, and there's some silly CSS styling here, which is causing it all to have no margins, which is unnecessary. Okay. So, it makes a little drop down, but I need to put stuff in the drop down. I want to be able to select any actor and see the result. So, now what I'm going to do is, while I'm going through these actors, this is where I get every actor name. As long as it's a new actor, I'm going to say drop down dot option actor. Watch this. Very simple in p5. Create a DOM element and add some options to it. A number of other ways you could do this. I'm adding this part kind of quickly. Now you can see I have a little menu where I can pick any actor. Now, I need to be able to know when do I pick a new actor. When I pick a new actor, when I pick a new actor, it's an event on this DOM element. So, the event, this is a p5 function I'm going to call changed. So, anytime, I'm going to say run, I'm just going to say BFS. So, anytime the drop down change, just run breadth first search. And I'm going to now go down and take everything here. That's the entire breadth first search algorithm. And put that in its own function. Function BFS. There we go. So, now, just to see if this works, I'm going to, what we're going to do is we're going to run the page again. I'm going to change the actor. And it ran breadth first search. But it ran it with Rachel McAdams. So, the point is, what I want is to have it run with Paul Reiser. So, where do I, so, this drop down needs to be a global variable. And the drop down needs to be a global variable. I've got a lot of messy code here, but someday we'll clean that up a little bit. And I'm going to change the start, set start to drop down dot value. So, the actor's name for the start will actually come from there. Now, let's do this again. I'm going to pick Paul Reiser again. Paul Reiser was in the diner with Kevin Bacon. Now, let's pick somebody else. Ah, this is not going to work. Paul Reiser. It didn't work. So, first of all, why didn't it work? Well, a couple things. Number one, it's weird that it's starting with Paul Reiser again. I don't know what the bug is specifically, but there's a major problem. See this node object? Remember, I was setting parents and searched? I've got to start over. All the searched have to be set to false, and all the parents have to be set to null. So, I need a function in graph, which essentially is like a reset function. And what I'm going to do in this reset function, I knew I needed that nodes array for some reason. I'm just going to go through all the nodes. Their edges all stay the same. And I'm going to say nodes index i dot searched equals false. And nodes index i dot searched, oh no, no, no, parents, equal, are you still with me? Are you with me? I'm barely with myself here. But, it's about to be the weekend for me. Okay, null. Okay, here we go. Steve Guttenberg, Mickey Rourke, was in diner with Kevin Bacon. Lynn Marta was in, wah wah, sad trombone. Okay, what did I miss? Okay. What did I miss? Path dot, oh, I could use join, that's right. What did I miss? Oh, I didn't call reset! I wrote the reset function, but I didn't call it. Oh, classic, horrible error here. Graph dot reset, oh my god. Blah blah blah, coding debugging, blah blah blah, okay, here we go. Steve Guttenberg, oh, Ellen Barkin, oh, nodes is not defined. Dot, this dot, this dot, this dot, it's gotta be that, right? The this dot song, never forget. The this dot song, never forget, the this dot song. Okay, Ellen Barkin, was in diner with Kevin Bacon, and Lynn Marta was in Footloose with Kevin Bacon, and Mark Ruffalo was in Spotlight with Billy Cronop, was in Eat Pray Love with Julia Roberts, who was in Flatliners with Kevin Bacon. Okay, so this is breath first search in two videos. If you watched this the whole way through, that is amazing to me, thank you very much. Hashtag, six degrees of Kevin Bacon, breath first search algorithm, whatever. You know, there's a lot of details about algorithms, things I'm sure I've missed here. Thinking about the interactivity, you could visualize this, so many wonderful possibilities. I am gonna be done for today, and I will see you in a future video sometime. As always, the code for this particular challenge is in the description, as well as links to other videos and things that I've referenced. If anything's missing, just let me know in the comments. Thanks for watching. All right, everybody. Oh my God. Unfortunately, I don't think I can manage right now to do the homework assignment video, but the good news is, any of you who are watching this live, if you want the homework assignment to sort of think about it, it's just on the, I mean, one thing I should say is this website is for the actual NYU course, but you're all welcome to read and participate and make pull requests, but this wiki that has the homework assignment with some ideas here, so let me, it's just for students here at NYU, but you can share your stuff with me in the comments and that sort of thing. So these are my exercise ideas, which is really just, you know, if you look through a bunch of the things that I've done already, you can think about, have this animal guessing game, which uses kind of like a binary tree-like thing to do a 20 questions-like thing. Use a bigger data set with this six degrees of Kevin Bacon. Your own data set, visualize it. These are the kind of things I'm looking for people to try to do. What's your own, can you make a piece of art with this? And then other examples that I have that I want to just quickly show you that are in the repository. So there's the binary tree stuff, which I have other videos about, which don't have as nice of a visualization in them, but you can see this one. This is the same exact breath-first search, but using force-directed graph. I have a Dijkstra's algorithm example that's just straight from the book, but it just console logs the answer. So I would love to make a video about that at some point. This I have a whole separate set of videos about, which is depth-first search to, whoops, to make a maze. And then, as you guys might have seen, I have some videos on A-star to kind of like path-find within that. And then I made an example of, I made an example of actually A-star with the maze generation, so solving for the path. So these are things you can play around with, and I have other videos that connect to that. And then, oh, I have the traveling salesperson problem. So this is just doing all possibilities with five nodes, and I'll come back to that next time that I'm around. Okay, so that's my quick, if people work with this stuff and make stuff, share it with me on Twitter, share it in the comments, that sort of thing. Okay, phone is ringing, which means it's time for me to go. It's six o'clock, I'm a half an hour late, which I said I need to leave by 5.30, so I'm looking to see if there's any, am I ever going to code straight Java? I do Java in processing, and I will, I do have on my list to do some Java in Eclipse videos that use processing libraries, but I just haven't had the time to get to it yet. Okay, thank you everybody for sticking around for this session. I'm done, I hope that I will be back next Friday. Like I said, the next month is going to be kind of rough, and so I expect to miss a couple weeks here and there, but I am determined, you know, I would say, if I'm giving myself a personal deadline that I feel is realistic, I'm quite determined by the sort of middle of the summer to have gotten through all this stuff, and certainly I'm going to be preparing and working and researching all this stuff. Whether the videos happen, we'll see. For those of you who are supporting me on Patreon, I thank you. If I miss weeks and you want to like turn off your Patreon, that's completely understandable. It's nice to have, but I don't want anyone to ever feel obligated to it, and that sort of thing. So okay, I will see you guys all later. I'm going to turn off this live stream. Good night, good weekend, and keep in touch. Okay, goodbye. People are requesting the choo-choo sound. The choo-choo sound. I'm going to read you, since I didn't do any random numbers. Like Sesame Street, this episode was brought to you by the letter or the number, this Coding Train episode was brought to you by the number 96,587. Hashtag 96587 on Twitter, I don't know. Okay, goodbye.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:50:00.40243Z",
  "started_at": "2023-09-26T21:53:57.628605Z",
  "completed_at": "2023-09-26T22:17:51.305778Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=YUlJAu1j_UM",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1433.677173
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/nwlsombbxpfdbc7b3upogcp2pm/cancel",
    "get": "https://api.replicate.com/v1/predictions/nwlsombbxpfdbc7b3upogcp2pm"
  }
}