{
  "id": "zhifmajblkuk7oqyruyhnp4hhu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/jHnyFNMOffo.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/865551 [00:00<?, ?frames/s]\n  0%|          | 2636/865551 [00:04<23:56, 600.54frames/s]\n  1%|          | 5376/865551 [00:10<29:45, 481.64frames/s]\n  1%|          | 8096/865551 [00:17<32:27, 440.24frames/s]\n  1%|▏         | 11012/865551 [00:26<37:29, 379.95frames/s]\n  2%|▏         | 13328/865551 [00:34<41:05, 345.61frames/s]\n  2%|▏         | 13328/865551 [00:46<41:05, 345.61frames/s]\n  2%|▏         | 15072/865551 [01:34<2:33:37, 92.27frames/s]\n  2%|▏         | 17948/865551 [01:40<1:47:42, 131.15frames/s]\n  2%|▏         | 20948/865551 [01:48<1:22:10, 171.29frames/s]\n  3%|▎         | 23948/865551 [01:54<1:02:50, 223.23frames/s]\n  3%|▎         | 26848/865551 [01:57<48:32, 287.96frames/s]  \n  3%|▎         | 29848/865551 [02:04<42:00, 331.62frames/s]\n  4%|▍         | 32748/865551 [02:12<41:46, 332.32frames/s]\n  4%|▍         | 35548/865551 [02:19<39:07, 353.50frames/s]\n  4%|▍         | 38348/865551 [02:26<37:13, 370.34frames/s]\n  5%|▍         | 41148/865551 [02:32<35:00, 392.50frames/s]\n  5%|▌         | 44148/865551 [02:37<30:51, 443.69frames/s]\n  5%|▌         | 47048/865551 [02:43<30:43, 444.05frames/s]\n  6%|▌         | 49748/865551 [02:50<31:04, 437.63frames/s]\n  6%|▌         | 52348/865551 [02:53<27:05, 500.36frames/s]\n  6%|▋         | 55048/865551 [02:57<25:01, 539.91frames/s]\n  7%|▋         | 58048/865551 [03:02<23:43, 567.34frames/s]\n  7%|▋         | 60148/865551 [03:06<25:16, 531.21frames/s]\n  7%|▋         | 62848/865551 [03:14<29:45, 449.48frames/s]\n  8%|▊         | 65448/865551 [03:22<32:30, 410.28frames/s]\n  8%|▊         | 67348/865551 [03:26<31:36, 420.83frames/s]\n  8%|▊         | 69848/865551 [03:31<28:55, 458.43frames/s]\n  8%|▊         | 71848/865551 [03:34<27:11, 486.38frames/s]\n  8%|▊         | 73548/865551 [03:38<28:16, 466.90frames/s]\n  8%|▊         | 73548/865551 [03:56<28:16, 466.90frames/s]\n  9%|▉         | 76448/865551 [04:05<1:02:09, 211.58frames/s]\n  9%|▉         | 79348/865551 [04:12<52:11, 251.02frames/s]  \n  9%|▉         | 81948/865551 [04:18<44:52, 291.03frames/s]\n 10%|▉         | 84648/865551 [04:24<39:35, 328.71frames/s]\n 10%|█         | 87248/865551 [04:32<39:55, 324.95frames/s]\n 10%|█         | 88648/865551 [04:35<37:25, 346.00frames/s]\n 10%|█         | 90448/865551 [04:37<32:03, 402.87frames/s]\n 11%|█         | 92248/865551 [04:40<29:30, 436.75frames/s]\n 11%|█         | 94248/865551 [04:44<26:50, 478.98frames/s]\n 11%|█         | 96748/865551 [04:47<22:59, 557.25frames/s]\n 11%|█▏        | 98848/865551 [04:51<23:07, 552.59frames/s]\n 12%|█▏        | 101348/865551 [04:56<25:12, 505.33frames/s]\n 12%|█▏        | 103948/865551 [05:01<24:18, 522.03frames/s]\n 12%|█▏        | 106448/865551 [05:05<23:35, 536.32frames/s]\n 13%|█▎        | 109048/865551 [05:10<22:59, 548.22frames/s]\n 13%|█▎        | 111248/865551 [05:14<23:02, 545.79frames/s]\n 13%|█▎        | 111748/865551 [05:15<24:08, 520.24frames/s]\n 13%|█▎        | 114748/865551 [05:19<20:58, 596.52frames/s]\n 14%|█▎        | 117148/865551 [05:25<22:51, 545.69frames/s]\n 14%|█▍        | 119848/865551 [05:27<18:21, 677.22frames/s]\n 14%|█▍        | 122748/865551 [05:31<17:48, 695.39frames/s]\n 14%|█▍        | 125448/865551 [05:35<18:43, 658.73frames/s]\n 15%|█▍        | 127948/865551 [05:38<17:30, 702.44frames/s]\n 15%|█▌        | 130648/865551 [05:44<20:27, 598.65frames/s]\n 15%|█▌        | 133348/865551 [05:51<23:31, 518.82frames/s]\n 16%|█▌        | 136248/865551 [05:56<22:29, 540.43frames/s]\n 16%|█▌        | 138948/865551 [06:03<24:41, 490.58frames/s]\n 16%|█▋        | 141748/865551 [06:09<25:51, 466.65frames/s]\n 17%|█▋        | 144648/865551 [06:18<28:31, 421.32frames/s]\n 17%|█▋        | 147448/865551 [06:25<29:46, 402.04frames/s]\n 17%|█▋        | 150048/865551 [06:32<29:34, 403.25frames/s]\n 18%|█▊        | 152648/865551 [06:38<29:21, 404.79frames/s]\n 18%|█▊        | 155348/865551 [06:44<27:48, 425.70frames/s]\n 18%|█▊        | 157948/865551 [06:49<26:44, 441.12frames/s]\n 19%|█▊        | 160848/865551 [06:56<26:59, 435.23frames/s]\n 19%|█▉        | 162948/865551 [07:03<29:32, 396.49frames/s]\n 19%|█▉        | 165448/865551 [07:10<31:06, 375.16frames/s]\n 19%|█▉        | 168148/865551 [07:17<30:03, 386.67frames/s]\n 20%|█▉        | 170848/865551 [07:24<30:06, 384.57frames/s]\n 20%|█▉        | 173048/865551 [07:28<27:59, 412.31frames/s]\n 20%|██        | 175548/865551 [07:33<26:02, 441.66frames/s]\n 21%|██        | 178548/865551 [07:37<22:50, 501.43frames/s]\n 21%|██        | 181148/865551 [07:46<27:57, 407.89frames/s]\n 21%|██        | 181148/865551 [07:57<27:57, 407.89frames/s]\n 21%|██▏       | 183948/865551 [09:05<1:58:39, 95.73frames/s]\n 22%|██▏       | 186648/865551 [09:13<1:32:34, 122.22frames/s]\n 22%|██▏       | 189448/865551 [09:20<1:12:27, 155.52frames/s]\n 22%|██▏       | 192348/865551 [09:28<59:26, 188.73frames/s]  \n 23%|██▎       | 194948/865551 [09:34<50:28, 221.43frames/s]\n 23%|██▎       | 197848/865551 [09:43<44:11, 251.82frames/s]\n 23%|██▎       | 200748/865551 [09:48<37:09, 298.14frames/s]\n 24%|██▎       | 203448/865551 [09:53<31:24, 351.43frames/s]\n 24%|██▍       | 206348/865551 [10:00<30:09, 364.40frames/s]\n 24%|██▍       | 209048/865551 [10:06<28:28, 384.30frames/s]\n 24%|██▍       | 211748/865551 [10:12<27:08, 401.43frames/s]\n 25%|██▍       | 214548/865551 [10:20<28:23, 382.18frames/s]\n 25%|██▌       | 217248/865551 [10:25<25:57, 416.37frames/s]\n 25%|██▌       | 219948/865551 [10:32<25:44, 418.13frames/s]\n 26%|██▌       | 222048/865551 [10:38<27:21, 391.93frames/s]\n 26%|██▌       | 224848/865551 [10:44<25:55, 411.82frames/s]\n 26%|██▋       | 227648/865551 [10:48<22:56, 463.52frames/s]\n 27%|██▋       | 230448/865551 [10:52<20:00, 528.84frames/s]\n 27%|██▋       | 233048/865551 [10:58<20:39, 510.16frames/s]\n 27%|██▋       | 235648/865551 [11:03<21:13, 494.66frames/s]\n 28%|██▊       | 238348/865551 [11:09<21:11, 493.47frames/s]\n 28%|██▊       | 240848/865551 [11:13<20:03, 519.07frames/s]\n 28%|██▊       | 243748/865551 [11:19<20:35, 503.24frames/s]\n 28%|██▊       | 246648/865551 [11:22<17:03, 604.88frames/s]\n 29%|██▉       | 249248/865551 [11:29<19:56, 515.13frames/s]\n 29%|██▉       | 251648/865551 [11:34<20:41, 494.30frames/s]\n 29%|██▉       | 254448/865551 [11:38<18:59, 536.39frames/s]\n 30%|██▉       | 257048/865551 [11:43<18:34, 546.23frames/s]\n 30%|██▉       | 259648/865551 [11:50<21:38, 466.80frames/s]\n 30%|███       | 262048/865551 [11:53<19:01, 528.91frames/s]\n 31%|███       | 264548/865551 [11:58<19:05, 524.82frames/s]\n 31%|███       | 266348/865551 [12:01<17:55, 556.91frames/s]\n 31%|███       | 269248/865551 [12:06<17:25, 570.55frames/s]\n 31%|███▏      | 271648/865551 [12:10<17:32, 564.29frames/s]\n 32%|███▏      | 273848/865551 [12:14<17:17, 570.32frames/s]\n 32%|███▏      | 276448/865551 [12:17<15:55, 616.84frames/s]\n 32%|███▏      | 279248/865551 [12:22<15:57, 612.58frames/s]\n 33%|███▎      | 282148/865551 [12:27<16:38, 584.36frames/s]\n 33%|███▎      | 284848/865551 [12:36<20:51, 463.87frames/s]\n 33%|███▎      | 287748/865551 [12:41<19:38, 490.13frames/s]\n 33%|███▎      | 289848/865551 [12:43<16:59, 564.89frames/s]\n 34%|███▍      | 292748/865551 [12:49<17:30, 545.22frames/s]\n 34%|███▍      | 295648/865551 [13:00<23:19, 407.12frames/s]\n 34%|███▍      | 298548/865551 [13:04<19:58, 473.25frames/s]\n 35%|███▍      | 301448/865551 [13:13<22:50, 411.68frames/s]\n 35%|███▌      | 304148/865551 [13:20<23:20, 400.89frames/s]\n 35%|███▌      | 305748/865551 [13:24<23:11, 402.34frames/s]\n 36%|███▌      | 308548/865551 [13:32<24:14, 382.86frames/s]\n 36%|███▌      | 311448/865551 [13:38<22:38, 407.90frames/s]\n 36%|███▋      | 314248/865551 [13:44<21:14, 432.64frames/s]\n 37%|███▋      | 317148/865551 [13:52<22:40, 403.12frames/s]\n 37%|███▋      | 320148/865551 [13:58<20:55, 434.38frames/s]\n 37%|███▋      | 322948/865551 [14:04<20:20, 444.58frames/s]\n 38%|███▊      | 325848/865551 [14:11<21:04, 426.69frames/s]\n 38%|███▊      | 328748/865551 [14:20<22:51, 391.31frames/s]\n 38%|███▊      | 331748/865551 [14:29<23:39, 375.92frames/s]\n 39%|███▊      | 334748/865551 [14:34<21:40, 408.00frames/s]\n 39%|███▉      | 337548/865551 [14:42<21:58, 400.35frames/s]\n 39%|███▉      | 340348/865551 [14:50<22:38, 386.65frames/s]\n 40%|███▉      | 343048/865551 [14:56<21:42, 401.16frames/s]\n 40%|███▉      | 345848/865551 [15:03<22:03, 392.60frames/s]\n 40%|████      | 348448/865551 [15:11<22:43, 379.21frames/s]\n 41%|████      | 351348/865551 [15:16<20:43, 413.55frames/s]\n 41%|████      | 354248/865551 [15:25<22:10, 384.15frames/s]\n 41%|████▏     | 357048/865551 [15:30<20:11, 419.77frames/s]\n 42%|████▏     | 359948/865551 [15:39<21:48, 386.41frames/s]\n 42%|████▏     | 362848/865551 [15:47<22:21, 374.62frames/s]\n 42%|████▏     | 365148/865551 [15:53<21:22, 390.07frames/s]\n 42%|████▏     | 367848/865551 [15:57<19:25, 427.04frames/s]\n 43%|████▎     | 370548/865551 [16:04<19:34, 421.31frames/s]\n 43%|████▎     | 373448/865551 [16:13<21:32, 380.87frames/s]\n 43%|████▎     | 376048/865551 [16:20<20:54, 390.17frames/s]\n 44%|████▍     | 378948/865551 [16:23<17:34, 461.59frames/s]\n 44%|████▍     | 381748/865551 [16:33<20:12, 399.15frames/s]\n 44%|████▍     | 384348/865551 [16:36<17:34, 456.36frames/s]\n 45%|████▍     | 387048/865551 [16:40<15:49, 504.06frames/s]\n 45%|████▌     | 389848/865551 [16:44<14:18, 553.94frames/s]\n 45%|████▌     | 392748/865551 [16:50<15:02, 523.80frames/s]\n 46%|████▌     | 395648/865551 [16:59<17:43, 441.93frames/s]\n 46%|████▌     | 398548/865551 [17:03<15:28, 502.98frames/s]\n 46%|████▌     | 400148/865551 [17:08<16:56, 457.86frames/s]\n 47%|████▋     | 402748/865551 [17:12<15:29, 497.92frames/s]\n 47%|████▋     | 405548/865551 [17:17<14:36, 524.61frames/s]\n 47%|████▋     | 408248/865551 [17:21<13:37, 559.52frames/s]\n 47%|████▋     | 410648/865551 [17:25<13:24, 565.28frames/s]\n 48%|████▊     | 412848/865551 [17:29<13:12, 571.22frames/s]\n 48%|████▊     | 415548/865551 [17:32<12:01, 623.60frames/s]\n 48%|████▊     | 418248/865551 [17:38<13:13, 563.74frames/s]\n 49%|████▊     | 421148/865551 [17:47<16:20, 453.24frames/s]\n 49%|████▉     | 423848/865551 [17:56<18:33, 396.78frames/s]\n 49%|████▉     | 426348/865551 [17:59<15:43, 465.52frames/s]\n 50%|████▉     | 429048/865551 [18:02<13:12, 550.75frames/s]\n 50%|████▉     | 431648/865551 [18:08<14:18, 505.21frames/s]\n 50%|█████     | 434548/865551 [18:15<15:32, 462.40frames/s]\n 51%|█████     | 437248/865551 [18:22<16:09, 441.71frames/s]\n 51%|█████     | 439848/865551 [18:27<15:02, 471.44frames/s]\n 51%|█████     | 442848/865551 [18:29<11:59, 587.35frames/s]\n 51%|█████▏    | 444748/865551 [18:33<12:02, 582.33frames/s]\n 52%|█████▏    | 447748/865551 [18:35<09:46, 712.22frames/s]\n 52%|█████▏    | 450348/865551 [18:37<08:29, 814.79frames/s]\n 52%|█████▏    | 453348/865551 [18:38<06:26, 1066.75frames/s]\n 53%|█████▎    | 456148/865551 [18:44<09:03, 753.02frames/s] \n 53%|█████▎    | 458748/865551 [18:51<11:09, 607.61frames/s]\n 53%|█████▎    | 461548/865551 [18:57<12:02, 558.80frames/s]\n 54%|█████▎    | 464548/865551 [18:58<09:21, 713.61frames/s]\n 54%|█████▍    | 467548/865551 [19:03<09:22, 707.60frames/s]\n 54%|█████▍    | 469648/865551 [19:07<10:28, 630.31frames/s]\n 55%|█████▍    | 472348/865551 [19:11<09:54, 660.85frames/s]\n 55%|█████▍    | 475248/865551 [19:20<12:57, 502.29frames/s]\n 55%|█████▌    | 477848/865551 [19:27<14:31, 444.89frames/s]\n 56%|█████▌    | 480648/865551 [19:35<15:47, 406.12frames/s]\n 56%|█████▌    | 483548/865551 [19:43<15:51, 401.51frames/s]\n 56%|█████▌    | 486448/865551 [19:47<13:53, 454.75frames/s]\n 57%|█████▋    | 489248/865551 [19:55<15:13, 411.82frames/s]\n 57%|█████▋    | 492148/865551 [20:03<15:22, 404.58frames/s]\n 57%|█████▋    | 495048/865551 [20:11<15:46, 391.50frames/s]\n 58%|█████▊    | 497748/865551 [20:18<15:32, 394.51frames/s]\n 58%|█████▊    | 500648/865551 [20:24<14:51, 409.53frames/s]\n 58%|█████▊    | 503448/865551 [20:30<14:01, 430.41frames/s]\n 58%|█████▊    | 505848/865551 [20:33<12:19, 486.53frames/s]\n 59%|█████▉    | 508648/865551 [20:35<09:56, 597.92frames/s]\n 59%|█████▉    | 511548/865551 [20:41<10:19, 571.66frames/s]\n 59%|█████▉    | 512648/865551 [20:42<09:52, 595.95frames/s]\n 60%|█████▉    | 515448/865551 [20:43<07:07, 818.81frames/s]\n 60%|█████▉    | 518348/865551 [20:46<06:27, 895.07frames/s]\n 60%|██████    | 521148/865551 [20:47<05:25, 1058.54frames/s]\n 61%|██████    | 523948/865551 [20:51<05:45, 988.44frames/s] \n 61%|██████    | 526648/865551 [20:52<04:46, 1182.09frames/s]\n 61%|██████    | 528948/865551 [20:54<05:05, 1101.55frames/s]\n 61%|██████▏   | 531748/865551 [21:00<07:15, 765.97frames/s] \n 62%|██████▏   | 534548/865551 [21:03<06:41, 824.90frames/s]\n 62%|██████▏   | 537448/865551 [21:09<07:46, 703.71frames/s]\n 62%|██████▏   | 540348/865551 [21:14<08:32, 635.05frames/s]\n 63%|██████▎   | 542948/865551 [21:19<09:10, 585.89frames/s]\n 63%|██████▎   | 545748/865551 [21:25<09:18, 572.83frames/s]\n 63%|██████▎   | 548348/865551 [21:30<09:46, 540.80frames/s]\n 64%|██████▎   | 550948/865551 [21:34<08:57, 584.96frames/s]\n 64%|██████▍   | 553648/865551 [21:39<09:01, 575.62frames/s]\n 64%|██████▍   | 556348/865551 [21:44<09:23, 548.72frames/s]\n 65%|██████▍   | 558948/865551 [21:49<09:44, 524.21frames/s]\n 65%|██████▍   | 561548/865551 [21:54<09:20, 541.92frames/s]\n 65%|██████▌   | 564348/865551 [21:59<09:06, 550.86frames/s]\n 65%|██████▌   | 566348/865551 [22:03<09:13, 540.19frames/s]\n 65%|██████▌   | 566348/865551 [22:17<09:13, 540.19frames/s]\n 66%|██████▌   | 569048/865551 [22:36<25:44, 191.96frames/s]\n 66%|██████▌   | 571748/865551 [22:41<20:30, 238.86frames/s]\n 66%|██████▋   | 574748/865551 [22:45<15:28, 313.23frames/s]\n 67%|██████▋   | 577748/865551 [22:47<11:37, 412.75frames/s]\n 67%|██████▋   | 580648/865551 [22:51<09:36, 494.22frames/s]\n 67%|██████▋   | 582848/865551 [22:54<08:41, 542.36frames/s]\n 68%|██████▊   | 585748/865551 [22:59<08:50, 526.98frames/s]\n 68%|██████▊   | 588248/865551 [23:02<07:45, 595.34frames/s]\n 68%|██████▊   | 590748/865551 [23:07<07:58, 573.87frames/s]\n 69%|██████▊   | 593448/865551 [23:10<07:00, 646.51frames/s]\n 69%|██████▉   | 596248/865551 [23:15<07:16, 616.68frames/s]\n 69%|██████▉   | 598848/865551 [23:18<06:44, 659.42frames/s]\n 69%|██████▉   | 601448/865551 [23:23<07:13, 609.19frames/s]\n 70%|██████▉   | 604348/865551 [23:29<07:31, 578.35frames/s]\n 70%|███████   | 607348/865551 [23:33<06:53, 624.36frames/s]\n 70%|███████   | 610148/865551 [23:39<07:23, 575.69frames/s]\n 71%|███████   | 613148/865551 [23:43<06:45, 622.68frames/s]\n 71%|███████   | 615848/865551 [23:48<07:13, 576.61frames/s]\n 71%|███████▏  | 618548/865551 [23:54<07:46, 529.86frames/s]\n 72%|███████▏  | 621348/865551 [23:59<07:41, 528.93frames/s]\n 72%|███████▏  | 624148/865551 [24:10<09:49, 409.33frames/s]\n 72%|███████▏  | 627048/865551 [24:21<11:20, 350.61frames/s]\n 73%|███████▎  | 629948/865551 [24:28<10:55, 359.31frames/s]\n 73%|███████▎  | 632548/865551 [24:35<10:37, 365.56frames/s]\n 73%|███████▎  | 635548/865551 [24:40<09:04, 422.03frames/s]\n 74%|███████▍  | 638548/865551 [24:47<08:53, 425.17frames/s]\n 74%|███████▍  | 641348/865551 [24:53<08:33, 436.74frames/s]\n 74%|███████▍  | 644248/865551 [25:01<09:03, 407.11frames/s]\n 75%|███████▍  | 647148/865551 [25:07<08:24, 433.10frames/s]\n 75%|███████▌  | 649948/865551 [25:13<08:17, 433.00frames/s]\n 75%|███████▌  | 652648/865551 [25:21<08:38, 410.23frames/s]\n 76%|███████▌  | 655548/865551 [25:25<07:39, 456.56frames/s]\n 76%|███████▌  | 658448/865551 [25:33<07:55, 435.27frames/s]\n 76%|███████▋  | 660348/865551 [25:38<08:12, 416.96frames/s]\n 77%|███████▋  | 663148/865551 [25:42<06:53, 489.44frames/s]\n 77%|███████▋  | 665948/865551 [25:45<05:58, 556.77frames/s]\n 77%|███████▋  | 668648/865551 [25:50<05:47, 567.25frames/s]\n 78%|███████▊  | 671448/865551 [25:53<04:56, 655.09frames/s]\n 78%|███████▊  | 674148/865551 [25:58<05:28, 582.22frames/s]\n 78%|███████▊  | 676448/865551 [26:01<04:59, 631.85frames/s]\n 78%|███████▊  | 678948/865551 [26:07<05:30, 565.36frames/s]\n 79%|███████▊  | 681248/865551 [26:11<05:19, 576.00frames/s]\n 79%|███████▉  | 683948/865551 [26:16<05:28, 552.04frames/s]\n 79%|███████▉  | 686848/865551 [26:24<06:24, 465.22frames/s]\n 80%|███████▉  | 689648/865551 [26:32<06:54, 423.92frames/s]\n 80%|████████  | 692548/865551 [26:39<06:58, 413.43frames/s]\n 80%|████████  | 695448/865551 [26:46<06:45, 419.41frames/s]\n 81%|████████  | 697848/865551 [26:52<06:44, 414.95frames/s]\n 81%|████████  | 700748/865551 [26:58<06:19, 434.48frames/s]\n 81%|████████▏ | 703348/865551 [27:05<06:29, 416.80frames/s]\n 82%|████████▏ | 706248/865551 [27:10<05:47, 458.48frames/s]\n 82%|████████▏ | 708948/865551 [27:15<05:27, 478.63frames/s]\n 82%|████████▏ | 711548/865551 [27:23<06:05, 421.37frames/s]\n 83%|████████▎ | 714348/865551 [27:29<05:54, 427.03frames/s]\n 83%|████████▎ | 717148/865551 [27:36<05:54, 418.47frames/s]\n 83%|████████▎ | 719948/865551 [27:45<06:23, 379.99frames/s]\n 84%|████████▎ | 722848/865551 [27:53<06:15, 380.54frames/s]\n 84%|████████▍ | 725848/865551 [28:01<06:10, 377.34frames/s]\n 84%|████████▍ | 728648/865551 [28:08<05:57, 382.47frames/s]\n 84%|████████▍ | 731348/865551 [28:12<05:08, 435.39frames/s]\n 85%|████████▍ | 734348/865551 [28:18<04:50, 452.03frames/s]\n 85%|████████▌ | 736148/865551 [28:23<05:06, 422.53frames/s]\n 85%|████████▌ | 736148/865551 [28:37<05:06, 422.53frames/s]\n 85%|████████▌ | 738948/865551 [28:42<07:56, 265.80frames/s]\n 86%|████████▌ | 741848/865551 [28:50<07:06, 290.29frames/s]\n 86%|████████▌ | 744848/865551 [28:55<05:46, 348.20frames/s]\n 86%|████████▋ | 747848/865551 [29:00<04:48, 407.57frames/s]\n 87%|████████▋ | 750748/865551 [29:08<04:55, 388.38frames/s]\n 87%|████████▋ | 753248/865551 [29:12<04:17, 436.57frames/s]\n 87%|████████▋ | 755848/865551 [29:17<03:59, 458.47frames/s]\n 88%|████████▊ | 758548/865551 [29:26<04:29, 396.68frames/s]\n 88%|████████▊ | 761148/865551 [29:33<04:32, 383.27frames/s]\n 88%|████████▊ | 763948/865551 [29:38<03:54, 433.22frames/s]\n 89%|████████▊ | 766848/865551 [29:44<03:46, 436.49frames/s]\n 89%|████████▉ | 769648/865551 [29:50<03:29, 457.98frames/s]\n 89%|████████▉ | 772348/865551 [29:57<03:40, 422.09frames/s]\n 90%|████████▉ | 775048/865551 [30:04<03:33, 424.33frames/s]\n 90%|████████▉ | 777748/865551 [30:12<03:41, 396.49frames/s]\n 90%|█████████ | 780648/865551 [30:21<03:51, 367.31frames/s]\n 91%|█████████ | 783448/865551 [30:30<03:56, 347.55frames/s]\n 91%|█████████ | 786348/865551 [30:35<03:24, 388.18frames/s]\n 91%|█████████ | 789048/865551 [30:45<03:39, 348.56frames/s]\n 91%|█████████▏| 791848/865551 [30:52<03:20, 367.19frames/s]\n 92%|█████████▏| 793148/865551 [30:53<02:58, 404.53frames/s]\n 92%|█████████▏| 796148/865551 [30:55<02:02, 564.31frames/s]\n 92%|█████████▏| 798948/865551 [30:56<01:29, 743.17frames/s]\n 93%|█████████▎| 801548/865551 [31:03<01:51, 572.33frames/s]\n 93%|█████████▎| 804448/865551 [31:09<01:55, 528.05frames/s]\n 93%|█████████▎| 807448/865551 [31:13<01:39, 585.62frames/s]\n 94%|█████████▎| 810448/865551 [31:17<01:25, 647.79frames/s]\n 94%|█████████▍| 813148/865551 [31:21<01:22, 637.05frames/s]\n 94%|█████████▍| 815948/865551 [31:26<01:21, 609.14frames/s]\n 95%|█████████▍| 818348/865551 [31:32<01:24, 555.82frames/s]\n 95%|█████████▍| 821348/865551 [31:34<01:05, 670.84frames/s]\n 95%|█████████▌| 824348/865551 [31:40<01:07, 610.97frames/s]\n 96%|█████████▌| 827048/865551 [31:44<01:02, 612.08frames/s]\n 96%|█████████▌| 829948/865551 [31:50<01:01, 582.72frames/s]\n 96%|█████████▌| 832848/865551 [31:56<01:01, 535.69frames/s]\n 97%|█████████▋| 835648/865551 [32:01<00:54, 547.37frames/s]\n 97%|█████████▋| 838548/865551 [32:08<00:52, 512.55frames/s]\n 97%|█████████▋| 841348/865551 [32:13<00:48, 504.01frames/s]\n 98%|█████████▊| 844248/865551 [32:19<00:42, 498.15frames/s]\n 98%|█████████▊| 847048/865551 [32:25<00:37, 497.29frames/s]\n 98%|█████████▊| 849848/865551 [32:31<00:31, 497.22frames/s]\n 99%|█████████▊| 852648/865551 [32:37<00:26, 494.22frames/s]\n 99%|█████████▉| 855448/865551 [32:42<00:19, 509.17frames/s]\n 99%|█████████▉| 858148/865551 [32:47<00:14, 504.85frames/s]\n 99%|█████████▉| 860948/865551 [32:54<00:09, 481.16frames/s]\n100%|█████████▉| 863848/865551 [33:01<00:03, 448.98frames/s]\n100%|██████████| 865551/865551 [33:04<00:00, 467.16frames/s]\n100%|██████████| 865551/865551 [33:04<00:00, 436.15frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.37568179631637316,
        "compression_ratio": 1.3384615384615384,
        "end": 15.200000000000001,
        "id": 0,
        "no_speech_prob": 0.00925359781831503,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, I am here again, two days in a row!",
        "tokens": [
          50364,
          2425,
          11,
          286,
          669,
          510,
          797,
          11,
          732,
          1708,
          294,
          257,
          5386,
          0,
          51124
        ]
      },
      {
        "avg_logprob": -0.37568179631637316,
        "compression_ratio": 1.3384615384615384,
        "end": 16.2,
        "id": 1,
        "no_speech_prob": 0.00925359781831503,
        "seek": 0,
        "start": 15.200000000000001,
        "temperature": 0,
        "text": " Woohoo!",
        "tokens": [
          51124,
          10468,
          19069,
          0,
          51174
        ]
      },
      {
        "avg_logprob": -0.37568179631637316,
        "compression_ratio": 1.3384615384615384,
        "end": 22.88,
        "id": 2,
        "no_speech_prob": 0.00925359781831503,
        "seek": 0,
        "start": 16.2,
        "temperature": 0,
        "text": " Oh, I forgot to put my cloaking device here, which I will do on my extra laptop, which",
        "tokens": [
          51174,
          876,
          11,
          286,
          5298,
          281,
          829,
          452,
          20123,
          2456,
          4302,
          510,
          11,
          597,
          286,
          486,
          360,
          322,
          452,
          2857,
          10732,
          11,
          597,
          51508
        ]
      },
      {
        "avg_logprob": -0.37568179631637316,
        "compression_ratio": 1.3384615384615384,
        "end": 26.36,
        "id": 3,
        "no_speech_prob": 0.00925359781831503,
        "seek": 0,
        "start": 22.88,
        "temperature": 0,
        "text": " now has all my ukulele chords on it.",
        "tokens": [
          51508,
          586,
          575,
          439,
          452,
          26769,
          2271,
          306,
          21733,
          322,
          309,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.40735560591502856,
        "compression_ratio": 1.617801047120419,
        "end": 32.28,
        "id": 4,
        "no_speech_prob": 0.07338348031044006,
        "seek": 2636,
        "start": 27.36,
        "temperature": 0,
        "text": " I don't see anyone actually saying anything to me in the chat, so I'm not sure if I've",
        "tokens": [
          50414,
          286,
          500,
          380,
          536,
          2878,
          767,
          1566,
          1340,
          281,
          385,
          294,
          264,
          5081,
          11,
          370,
          286,
          478,
          406,
          988,
          498,
          286,
          600,
          50660
        ]
      },
      {
        "avg_logprob": -0.40735560591502856,
        "compression_ratio": 1.617801047120419,
        "end": 36.24,
        "id": 5,
        "no_speech_prob": 0.07338348031044006,
        "seek": 2636,
        "start": 32.28,
        "temperature": 0,
        "text": " actually started or if I'm just imagining it.",
        "tokens": [
          50660,
          767,
          1409,
          420,
          498,
          286,
          478,
          445,
          27798,
          309,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.40735560591502856,
        "compression_ratio": 1.617801047120419,
        "end": 43.36,
        "id": 6,
        "no_speech_prob": 0.07338348031044006,
        "seek": 2636,
        "start": 36.24,
        "temperature": 0,
        "text": " I'm going to check the patron group here.",
        "tokens": [
          50858,
          286,
          478,
          516,
          281,
          1520,
          264,
          21843,
          1594,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.40735560591502856,
        "compression_ratio": 1.617801047120419,
        "end": 50.519999999999996,
        "id": 7,
        "no_speech_prob": 0.07338348031044006,
        "seek": 2636,
        "start": 43.36,
        "temperature": 0,
        "text": " Uh, looking, oh, oh, oh, people are saying hello to me.",
        "tokens": [
          51214,
          4019,
          11,
          1237,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          561,
          366,
          1566,
          7751,
          281,
          385,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.40735560591502856,
        "compression_ratio": 1.617801047120419,
        "end": 51.519999999999996,
        "id": 8,
        "no_speech_prob": 0.07338348031044006,
        "seek": 2636,
        "start": 50.519999999999996,
        "temperature": 0,
        "text": " Okay, so, good morning.",
        "tokens": [
          51572,
          1033,
          11,
          370,
          11,
          665,
          2446,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.40735560591502856,
        "compression_ratio": 1.617801047120419,
        "end": 53.760000000000005,
        "id": 9,
        "no_speech_prob": 0.07338348031044006,
        "seek": 2636,
        "start": 51.519999999999996,
        "temperature": 0,
        "text": " It's not really the morning anymore, it's almost noon.",
        "tokens": [
          51622,
          467,
          311,
          406,
          534,
          264,
          2446,
          3602,
          11,
          309,
          311,
          1920,
          24040,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.3216691103848544,
        "compression_ratio": 1.6075949367088607,
        "end": 60.36,
        "id": 10,
        "no_speech_prob": 0.14999274909496307,
        "seek": 5376,
        "start": 53.76,
        "temperature": 0,
        "text": " I've got a couple hours here, and the project for today is a TensorFlow.js classification",
        "tokens": [
          50364,
          286,
          600,
          658,
          257,
          1916,
          2496,
          510,
          11,
          293,
          264,
          1716,
          337,
          965,
          307,
          257,
          37624,
          13,
          25530,
          21538,
          50694
        ]
      },
      {
        "avg_logprob": -0.3216691103848544,
        "compression_ratio": 1.6075949367088607,
        "end": 61.36,
        "id": 11,
        "no_speech_prob": 0.14999274909496307,
        "seek": 5376,
        "start": 60.36,
        "temperature": 0,
        "text": " project.",
        "tokens": [
          50694,
          1716,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.3216691103848544,
        "compression_ratio": 1.6075949367088607,
        "end": 66.64,
        "id": 12,
        "no_speech_prob": 0.14999274909496307,
        "seek": 5376,
        "start": 61.36,
        "temperature": 0,
        "text": " So, just to recap, I was here yesterday, and I did a couple coding challenges, if I recall",
        "tokens": [
          50744,
          407,
          11,
          445,
          281,
          20928,
          11,
          286,
          390,
          510,
          5186,
          11,
          293,
          286,
          630,
          257,
          1916,
          17720,
          4759,
          11,
          498,
          286,
          9901,
          51008
        ]
      },
      {
        "avg_logprob": -0.3216691103848544,
        "compression_ratio": 1.6075949367088607,
        "end": 67.64,
        "id": 13,
        "no_speech_prob": 0.14999274909496307,
        "seek": 5376,
        "start": 66.64,
        "temperature": 0,
        "text": " correctly.",
        "tokens": [
          51008,
          8944,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.3216691103848544,
        "compression_ratio": 1.6075949367088607,
        "end": 69.88,
        "id": 14,
        "no_speech_prob": 0.14999274909496307,
        "seek": 5376,
        "start": 67.64,
        "temperature": 0,
        "text": " There was the, oh, let's open them up.",
        "tokens": [
          51058,
          821,
          390,
          264,
          11,
          1954,
          11,
          718,
          311,
          1269,
          552,
          493,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.3216691103848544,
        "compression_ratio": 1.6075949367088607,
        "end": 74.28,
        "id": 15,
        "no_speech_prob": 0.14999274909496307,
        "seek": 5376,
        "start": 69.88,
        "temperature": 0,
        "text": " I haven't uploaded the code yet, actually, to, but let's just, they were so nice.",
        "tokens": [
          51170,
          286,
          2378,
          380,
          17135,
          264,
          3089,
          1939,
          11,
          767,
          11,
          281,
          11,
          457,
          718,
          311,
          445,
          11,
          436,
          645,
          370,
          1481,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.3216691103848544,
        "compression_ratio": 1.6075949367088607,
        "end": 80.96,
        "id": 16,
        "no_speech_prob": 0.14999274909496307,
        "seek": 5376,
        "start": 74.28,
        "temperature": 0,
        "text": " I really liked them, so let's take a minute to review them.",
        "tokens": [
          51390,
          286,
          534,
          4501,
          552,
          11,
          370,
          718,
          311,
          747,
          257,
          3456,
          281,
          3131,
          552,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 83.75999999999999,
        "id": 17,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 80.96,
        "temperature": 0,
        "text": " I have a feeling we're going to spend the entire two hours cleaning data.",
        "tokens": [
          50364,
          286,
          362,
          257,
          2633,
          321,
          434,
          516,
          281,
          3496,
          264,
          2302,
          732,
          2496,
          8924,
          1412,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 88.8,
        "id": 18,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 83.75999999999999,
        "temperature": 0,
        "text": " If that's what happens, that's going to be worth it, because that's kind of, I was going",
        "tokens": [
          50504,
          759,
          300,
          311,
          437,
          2314,
          11,
          300,
          311,
          516,
          281,
          312,
          3163,
          309,
          11,
          570,
          300,
          311,
          733,
          295,
          11,
          286,
          390,
          516,
          50756
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 92.6,
        "id": 19,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 88.8,
        "temperature": 0,
        "text": " to say half the battle, but I think it's all of the battle in machine learning is really",
        "tokens": [
          50756,
          281,
          584,
          1922,
          264,
          4635,
          11,
          457,
          286,
          519,
          309,
          311,
          439,
          295,
          264,
          4635,
          294,
          3479,
          2539,
          307,
          534,
          50946
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 95.28,
        "id": 20,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 92.6,
        "temperature": 0,
        "text": " thinking about your data.",
        "tokens": [
          50946,
          1953,
          466,
          428,
          1412,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 96.28,
        "id": 21,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 95.28,
        "temperature": 0,
        "text": " Open recent.",
        "tokens": [
          51080,
          7238,
          5162,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 98.52,
        "id": 22,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 96.28,
        "temperature": 0,
        "text": " Oh, you know, I moved everything.",
        "tokens": [
          51130,
          876,
          11,
          291,
          458,
          11,
          286,
          4259,
          1203,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 99.56,
        "id": 23,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 98.52,
        "temperature": 0,
        "text": " I don't know why I'm looking for this.",
        "tokens": [
          51242,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          1237,
          337,
          341,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 101.67999999999999,
        "id": 24,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 99.56,
        "temperature": 0,
        "text": " I just want to run, I want to run these.",
        "tokens": [
          51294,
          286,
          445,
          528,
          281,
          1190,
          11,
          286,
          528,
          281,
          1190,
          613,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 104.03999999999999,
        "id": 25,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 101.67999999999999,
        "temperature": 0,
        "text": " I enjoyed them so much yesterday.",
        "tokens": [
          51400,
          286,
          4626,
          552,
          370,
          709,
          5186,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 107.28,
        "id": 26,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 104.03999999999999,
        "temperature": 0,
        "text": " And I'm going to go here.",
        "tokens": [
          51518,
          400,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 109.11999999999999,
        "id": 27,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 107.28,
        "temperature": 0,
        "text": " I think I put them in here.",
        "tokens": [
          51680,
          286,
          519,
          286,
          829,
          552,
          294,
          510,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.2977559942948191,
        "compression_ratio": 1.7577854671280277,
        "end": 110.11999999999999,
        "id": 28,
        "no_speech_prob": 0.4377354085445404,
        "seek": 8096,
        "start": 109.11999999999999,
        "temperature": 0,
        "text": " What were they?",
        "tokens": [
          51772,
          708,
          645,
          436,
          30,
          51822
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 111.28,
        "id": 29,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 110.28,
        "temperature": 0,
        "text": " Sandpiles.",
        "tokens": [
          50372,
          7985,
          79,
          4680,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 112.28,
        "id": 30,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 111.28,
        "temperature": 0,
        "text": " What was the other one?",
        "tokens": [
          50422,
          708,
          390,
          264,
          661,
          472,
          30,
          50472
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 113.28,
        "id": 31,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 112.28,
        "temperature": 0,
        "text": " I don't remember.",
        "tokens": [
          50472,
          286,
          500,
          380,
          1604,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 114.28,
        "id": 32,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 113.28,
        "temperature": 0,
        "text": " Sandpiles.",
        "tokens": [
          50522,
          7985,
          79,
          4680,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 115.28,
        "id": 33,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 114.28,
        "temperature": 0,
        "text": " What was it?",
        "tokens": [
          50572,
          708,
          390,
          309,
          30,
          50622
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 120.28,
        "id": 34,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 115.28,
        "temperature": 0,
        "text": " Somebody's going to tell me before I remember, before I forget.",
        "tokens": [
          50622,
          13463,
          311,
          516,
          281,
          980,
          385,
          949,
          286,
          1604,
          11,
          949,
          286,
          2870,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 121.28,
        "id": 35,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 120.28,
        "temperature": 0,
        "text": " Before I forget.",
        "tokens": [
          50872,
          4546,
          286,
          2870,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 122.28,
        "id": 36,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 121.28,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50922,
          876,
          11,
          3237,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 125.28,
        "id": 37,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 122.28,
        "temperature": 0,
        "text": " I think my brain is turned off today.",
        "tokens": [
          50972,
          286,
          519,
          452,
          3567,
          307,
          3574,
          766,
          965,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 126.28,
        "id": 38,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 125.28,
        "temperature": 0,
        "text": " This is bad.",
        "tokens": [
          51122,
          639,
          307,
          1578,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 127.28,
        "id": 39,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 126.28,
        "temperature": 0,
        "text": " Oh, Barnsley Fern, that's right.",
        "tokens": [
          51172,
          876,
          11,
          21605,
          82,
          3420,
          16675,
          11,
          300,
          311,
          558,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 128.28,
        "id": 40,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 127.28,
        "temperature": 0,
        "text": " I couldn't remember that.",
        "tokens": [
          51222,
          286,
          2809,
          380,
          1604,
          300,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 129.28,
        "id": 41,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 128.28,
        "temperature": 0,
        "text": " Sandpiles.",
        "tokens": [
          51272,
          7985,
          79,
          4680,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 130.28,
        "id": 42,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 129.28,
        "temperature": 0,
        "text": " Where did the sandpiles go?",
        "tokens": [
          51322,
          2305,
          630,
          264,
          4932,
          79,
          4680,
          352,
          30,
          51372
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 131.28,
        "id": 43,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 130.28,
        "temperature": 0,
        "text": " Let's look at the sandpiles.",
        "tokens": [
          51372,
          961,
          311,
          574,
          412,
          264,
          4932,
          79,
          4680,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 132.28,
        "id": 44,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 131.28,
        "temperature": 0,
        "text": " All right, here we go, sandpiles.",
        "tokens": [
          51422,
          1057,
          558,
          11,
          510,
          321,
          352,
          11,
          4932,
          79,
          4680,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.33476702372233075,
        "compression_ratio": 1.7757847533632287,
        "end": 133.28,
        "id": 45,
        "no_speech_prob": 0.7930121421813965,
        "seek": 11012,
        "start": 132.28,
        "temperature": 0,
        "text": " Let's, let's see.",
        "tokens": [
          51472,
          961,
          311,
          11,
          718,
          311,
          536,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -1.5220712280273438,
        "compression_ratio": 1.208695652173913,
        "end": 134.68,
        "id": 46,
        "no_speech_prob": 0.14800837635993958,
        "seek": 13328,
        "start": 133.84,
        "temperature": 1,
        "text": " Beautiful sandpiles.",
        "tokens": [
          50392,
          14724,
          4932,
          79,
          4680,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -1.5220712280273438,
        "compression_ratio": 1.208695652173913,
        "end": 137.2,
        "id": 47,
        "no_speech_prob": 0.14800837635993958,
        "seek": 13328,
        "start": 134.68,
        "temperature": 1,
        "text": " Oh, let's do this.",
        "tokens": [
          50434,
          876,
          11,
          718,
          311,
          220,
          2595,
          341,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -1.5220712280273438,
        "compression_ratio": 1.208695652173913,
        "end": 140.72,
        "id": 48,
        "no_speech_prob": 0.14800837635993958,
        "seek": 13328,
        "start": 137.2,
        "temperature": 1,
        "text": " You know, while people are taking their time joining here.",
        "tokens": [
          50560,
          220,
          3223,
          458,
          11,
          315,
          72,
          306,
          561,
          594,
          68,
          20065,
          872,
          641,
          565,
          5549,
          510,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -1.5220712280273438,
        "compression_ratio": 1.208695652173913,
        "end": 150.72,
        "id": 49,
        "no_speech_prob": 0.14800837635993958,
        "seek": 13328,
        "start": 140.72,
        "temperature": 1,
        "text": " I'm going to switch the live stream off.",
        "tokens": [
          50736,
          286,
          478,
          516,
          281,
          3679,
          264,
          1621,
          4309,
          766,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -3.013623343573676,
        "compression_ratio": 0.9354838709677419,
        "end": 179.48,
        "id": 50,
        "no_speech_prob": 0.36088085174560547,
        "seek": 15072,
        "start": 150.72,
        "temperature": 1,
        "text": " That'll probably leave a bias in the rest of the audience.",
        "tokens": [
          50364,
          663,
          603,
          1391,
          1856,
          257,
          12577,
          294,
          264,
          725,
          83,
          295,
          264,
          4034,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -2.083645198656165,
        "compression_ratio": 0.8769230769230769,
        "end": 197.82,
        "id": 51,
        "no_speech_prob": 0.5686413645744324,
        "seek": 17948,
        "start": 179.82,
        "temperature": 1,
        "text": " I'm going to make that...",
        "tokens": [
          50381,
          286,
          478,
          290,
          78,
          278,
          281,
          652,
          300,
          485,
          51281
        ]
      },
      {
        "avg_logprob": -2.083645198656165,
        "compression_ratio": 0.8769230769230769,
        "end": 202.88,
        "id": 52,
        "no_speech_prob": 0.5686413645744324,
        "seek": 17948,
        "start": 198.38,
        "temperature": 1,
        "text": " Barnsley's Birds, Simon Thomas.",
        "tokens": [
          51309,
          21605,
          82,
          3420,
          311,
          41456,
          11,
          13193,
          8500,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 211.48,
        "id": 53,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 210.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 213.98,
        "id": 54,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 211.48,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50464,
          220,
          8373,
          311,
          536,
          13,
          50589
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 217.48,
        "id": 55,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 213.98,
        "temperature": 0,
        "text": " Somebody sent me, Kay Wichman sent me some chords",
        "tokens": [
          50589,
          13463,
          2279,
          385,
          11,
          14179,
          343,
          480,
          1601,
          2279,
          385,
          512,
          21733,
          50764
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 219.48,
        "id": 56,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 217.98,
        "temperature": 0,
        "text": " for Somewhere Over the Rainbow.",
        "tokens": [
          50789,
          337,
          34500,
          4886,
          264,
          29477,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 220.48,
        "id": 57,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 219.48,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50864,
          2438,
          0,
          50914
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 224.48,
        "id": 58,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 221.98,
        "temperature": 0,
        "text": " I have to provide my email to get a free trial.",
        "tokens": [
          50989,
          286,
          362,
          281,
          2893,
          452,
          3796,
          281,
          483,
          257,
          1737,
          7308,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 226.48,
        "id": 59,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 224.48,
        "temperature": 0,
        "text": " What if I refresh this page?",
        "tokens": [
          51114,
          708,
          498,
          286,
          15134,
          341,
          3028,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 227.98,
        "id": 60,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 226.98,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51239,
          1692,
          321,
          352,
          13,
          51289
        ]
      },
      {
        "avg_logprob": -0.4858383575043121,
        "compression_ratio": 1.3053892215568863,
        "end": 234.98,
        "id": 61,
        "no_speech_prob": 0.0187968946993351,
        "seek": 20948,
        "start": 232.98,
        "temperature": 0,
        "text": " What's E minor? This?",
        "tokens": [
          51539,
          708,
          311,
          462,
          6696,
          30,
          639,
          30,
          51639
        ]
      },
      {
        "avg_logprob": -0.3810033603590362,
        "compression_ratio": 1.0535714285714286,
        "end": 259.48,
        "id": 62,
        "no_speech_prob": 0.0028854559641331434,
        "seek": 23948,
        "start": 239.48,
        "temperature": 0,
        "text": " ♫",
        "tokens": [
          50364,
          220,
          158,
          247,
          104,
          51364
        ]
      },
      {
        "avg_logprob": -0.3810033603590362,
        "compression_ratio": 1.0535714285714286,
        "end": 260.48,
        "id": 63,
        "no_speech_prob": 0.0028854559641331434,
        "seek": 23948,
        "start": 259.48,
        "temperature": 0,
        "text": " Ooh, ooh, ooh.",
        "tokens": [
          51364,
          7951,
          11,
          17024,
          11,
          17024,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3810033603590362,
        "compression_ratio": 1.0535714285714286,
        "end": 261.48,
        "id": 64,
        "no_speech_prob": 0.0028854559641331434,
        "seek": 23948,
        "start": 260.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3810033603590362,
        "compression_ratio": 1.0535714285714286,
        "end": 263.48,
        "id": 65,
        "no_speech_prob": 0.0028854559641331434,
        "seek": 23948,
        "start": 262.98,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51539,
          1057,
          558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3810033603590362,
        "compression_ratio": 1.0535714285714286,
        "end": 267.48,
        "id": 66,
        "no_speech_prob": 0.0028854559641331434,
        "seek": 23948,
        "start": 263.48,
        "temperature": 0,
        "text": " So, I'm just getting myself kind of mentally into shape.",
        "tokens": [
          51564,
          407,
          11,
          286,
          478,
          445,
          1242,
          2059,
          733,
          295,
          17072,
          666,
          3909,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3810033603590362,
        "compression_ratio": 1.0535714285714286,
        "end": 268.48,
        "id": 67,
        "no_speech_prob": 0.0028854559641331434,
        "seek": 23948,
        "start": 267.48,
        "temperature": 0,
        "text": " We've got our sand piles.",
        "tokens": [
          51764,
          492,
          600,
          658,
          527,
          4932,
          34861,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 270.48,
        "id": 68,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 268.48,
        "temperature": 0,
        "text": " I meant to zoom in on these.",
        "tokens": [
          50364,
          286,
          4140,
          281,
          8863,
          294,
          322,
          613,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 273.48,
        "id": 69,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 271.98,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          50539,
          400,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 275.48,
        "id": 70,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 273.98,
        "temperature": 0,
        "text": " Good morning. Hello. Good day.",
        "tokens": [
          50639,
          2205,
          2446,
          13,
          2425,
          13,
          2205,
          786,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 277.48,
        "id": 71,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 275.48,
        "temperature": 0,
        "text": " Good day. I wish you good day.",
        "tokens": [
          50714,
          2205,
          786,
          13,
          286,
          3172,
          291,
          665,
          786,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 285.48,
        "id": 72,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 282.98,
        "temperature": 0,
        "text": " I'm not prepared. I'm not ready for this.",
        "tokens": [
          51089,
          286,
          478,
          406,
          4927,
          13,
          286,
          478,
          406,
          1919,
          337,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 290.48,
        "id": 73,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 289.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51414,
          1057,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 292.48,
        "id": 74,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 290.48,
        "temperature": 0,
        "text": " So, let's check out where we are.",
        "tokens": [
          51464,
          407,
          11,
          718,
          311,
          1520,
          484,
          689,
          321,
          366,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 294.48,
        "id": 75,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 292.48,
        "temperature": 0,
        "text": " Let's get ourselves centered",
        "tokens": [
          51564,
          961,
          311,
          483,
          4175,
          18988,
          51664
        ]
      },
      {
        "avg_logprob": -0.26689014215578977,
        "compression_ratio": 1.4855491329479769,
        "end": 297.48,
        "id": 76,
        "no_speech_prob": 0.00006920918531250209,
        "seek": 26848,
        "start": 294.48,
        "temperature": 0,
        "text": " and figure out what we're going to work on.",
        "tokens": [
          51664,
          293,
          2573,
          484,
          437,
          321,
          434,
          516,
          281,
          589,
          322,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 300.48,
        "id": 77,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 298.48,
        "temperature": 0,
        "text": " So, I'm going to go to...",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          516,
          281,
          352,
          281,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 304.48,
        "id": 78,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 302.48,
        "temperature": 0,
        "text": " github.com slash coding train.",
        "tokens": [
          50564,
          290,
          355,
          836,
          13,
          1112,
          17330,
          17720,
          3847,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 309.48,
        "id": 79,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 304.98,
        "temperature": 0,
        "text": " I am going to go to this crowdsource color data repository.",
        "tokens": [
          50689,
          286,
          669,
          516,
          281,
          352,
          281,
          341,
          26070,
          2948,
          2017,
          1412,
          25841,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 311.48,
        "id": 80,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 309.48,
        "temperature": 0,
        "text": " Ooh, there's some new pull requests.",
        "tokens": [
          50914,
          7951,
          11,
          456,
          311,
          512,
          777,
          2235,
          12475,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 313.48,
        "id": 81,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 311.48,
        "temperature": 0,
        "text": " Ooh! Ooh!",
        "tokens": [
          51014,
          7951,
          0,
          7951,
          0,
          51114
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 314.48,
        "id": 82,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 313.48,
        "temperature": 0,
        "text": " Uh, okay.",
        "tokens": [
          51114,
          4019,
          11,
          1392,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 315.48,
        "id": 83,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 314.48,
        "temperature": 0,
        "text": " Uh, and...",
        "tokens": [
          51164,
          4019,
          11,
          293,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 316.48,
        "id": 84,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 315.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51214,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 319.48,
        "id": 85,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 316.48,
        "temperature": 0,
        "text": " So, what I'm going to do here is I'm going to go to this page.",
        "tokens": [
          51264,
          407,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          307,
          286,
          478,
          516,
          281,
          352,
          281,
          341,
          3028,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 320.98,
        "id": 86,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 319.48,
        "temperature": 0,
        "text": " So, this is where we were yesterday.",
        "tokens": [
          51414,
          407,
          11,
          341,
          307,
          689,
          321,
          645,
          5186,
          13,
          51489
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 321.48,
        "id": 87,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 320.98,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51489,
          2438,
          0,
          51514
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 322.48,
        "id": 88,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 321.48,
        "temperature": 0,
        "text": " And, uh...",
        "tokens": [
          51514,
          400,
          11,
          2232,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 324.48,
        "id": 89,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 322.98,
        "temperature": 0,
        "text": " Many people from the community",
        "tokens": [
          51589,
          5126,
          561,
          490,
          264,
          1768,
          51664
        ]
      },
      {
        "avg_logprob": -0.25137157009956534,
        "compression_ratio": 1.6986899563318778,
        "end": 327.48,
        "id": 90,
        "no_speech_prob": 0.0004801992326974869,
        "seek": 29848,
        "start": 325.48,
        "temperature": 0,
        "text": " made some pull requests and changed the design.",
        "tokens": [
          51714,
          1027,
          512,
          2235,
          12475,
          293,
          3105,
          264,
          1715,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 329.48,
        "id": 91,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 327.48,
        "temperature": 0,
        "text": " I think that's brown.",
        "tokens": [
          50364,
          286,
          519,
          300,
          311,
          6292,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 331.48,
        "id": 92,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 329.48,
        "temperature": 0,
        "text": " Uh, I think that's, like, greenish.",
        "tokens": [
          50464,
          4019,
          11,
          286,
          519,
          300,
          311,
          11,
          411,
          11,
          3092,
          742,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 332.48,
        "id": 93,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 331.48,
        "temperature": 0,
        "text": " Greenish.",
        "tokens": [
          50564,
          6969,
          742,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 334.48,
        "id": 94,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 332.98,
        "temperature": 0,
        "text": " Greenish.",
        "tokens": [
          50639,
          6969,
          742,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 336.48,
        "id": 95,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 335.48,
        "temperature": 0,
        "text": " Pinkish.",
        "tokens": [
          50764,
          17118,
          742,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 337.48,
        "id": 96,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 336.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50814,
          1057,
          558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 340.48,
        "id": 97,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 337.48,
        "temperature": 0,
        "text": " So, this is my crowdsource color data example.",
        "tokens": [
          50864,
          407,
          11,
          341,
          307,
          452,
          26070,
          2948,
          2017,
          1412,
          1365,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 342.48,
        "id": 98,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 340.48,
        "temperature": 0,
        "text": " What's going on here?",
        "tokens": [
          51014,
          708,
          311,
          516,
          322,
          510,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 343.48,
        "id": 99,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 342.48,
        "temperature": 0,
        "text": " I need some tape.",
        "tokens": [
          51114,
          286,
          643,
          512,
          7314,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 345.48,
        "id": 100,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 344.48,
        "temperature": 0,
        "text": " Um...",
        "tokens": [
          51214,
          3301,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 351.48,
        "id": 101,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 350.48,
        "temperature": 0,
        "text": " Um...",
        "tokens": [
          51514,
          3301,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 353.48,
        "id": 102,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 351.98,
        "temperature": 0,
        "text": " And, so, this is what I need.",
        "tokens": [
          51589,
          400,
          11,
          370,
          11,
          341,
          307,
          437,
          286,
          643,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18377022604340487,
        "compression_ratio": 1.5454545454545454,
        "end": 355.48,
        "id": 103,
        "no_speech_prob": 0.0033237249590456486,
        "seek": 32748,
        "start": 353.48,
        "temperature": 0,
        "text": " Now, I also need to go to...",
        "tokens": [
          51664,
          823,
          11,
          286,
          611,
          643,
          281,
          352,
          281,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 362.48,
        "id": 104,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 355.48,
        "temperature": 0,
        "text": " So, the next video in this, uh, sequence, tutorial sequence,",
        "tokens": [
          50364,
          407,
          11,
          264,
          958,
          960,
          294,
          341,
          11,
          2232,
          11,
          8310,
          11,
          7073,
          8310,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 366.48,
        "id": 105,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 362.48,
        "temperature": 0,
        "text": " I am going to talk about cleaning the data.",
        "tokens": [
          50714,
          286,
          669,
          516,
          281,
          751,
          466,
          8924,
          264,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 369.48,
        "id": 106,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 366.48,
        "temperature": 0,
        "text": " And, so, what I'm going to do is actually...",
        "tokens": [
          50914,
          400,
          11,
          370,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          767,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 370.48,
        "id": 107,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 369.48,
        "temperature": 0,
        "text": " I think I'm going to write...",
        "tokens": [
          51064,
          286,
          519,
          286,
          478,
          516,
          281,
          2464,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 374.48,
        "id": 108,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 370.48,
        "temperature": 0,
        "text": " I was going to just download it directly from, um...",
        "tokens": [
          51114,
          286,
          390,
          516,
          281,
          445,
          5484,
          309,
          3838,
          490,
          11,
          1105,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 379.48,
        "id": 109,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 376.98,
        "temperature": 0,
        "text": " Firebase database.",
        "tokens": [
          51439,
          35173,
          8149,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 380.48,
        "id": 110,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 379.48,
        "temperature": 0,
        "text": " So, the, um...",
        "tokens": [
          51564,
          407,
          11,
          264,
          11,
          1105,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.22289801617057955,
        "compression_ratio": 1.6666666666666667,
        "end": 383.48,
        "id": 111,
        "no_speech_prob": 0.001810047891922295,
        "seek": 35548,
        "start": 380.48,
        "temperature": 0,
        "text": " So, I need to talk about the rules that were updated.",
        "tokens": [
          51614,
          407,
          11,
          286,
          643,
          281,
          751,
          466,
          264,
          4474,
          300,
          645,
          10588,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 385.48,
        "id": 112,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 384.48,
        "temperature": 0,
        "text": " Um...",
        "tokens": [
          50414,
          3301,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 387.48,
        "id": 113,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 385.48,
        "temperature": 0,
        "text": " And, I think what I'm going to also do",
        "tokens": [
          50464,
          400,
          11,
          286,
          519,
          437,
          286,
          478,
          516,
          281,
          611,
          360,
          50564
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 391.48,
        "id": 114,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 388.48,
        "temperature": 0,
        "text": " is I'm going to, uh, turn off writing.",
        "tokens": [
          50614,
          307,
          286,
          478,
          516,
          281,
          11,
          2232,
          11,
          1261,
          766,
          3579,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 395.48,
        "id": 115,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 393.48,
        "temperature": 0,
        "text": " So, can I put a comment in here?",
        "tokens": [
          50864,
          407,
          11,
          393,
          286,
          829,
          257,
          2871,
          294,
          510,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 396.48,
        "id": 116,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 395.48,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50964,
          883,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 401.48,
        "id": 117,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 398.48,
        "temperature": 0,
        "text": " Is there any way to put a comment in...",
        "tokens": [
          51114,
          1119,
          456,
          604,
          636,
          281,
          829,
          257,
          2871,
          294,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 402.48,
        "id": 118,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 401.48,
        "temperature": 0,
        "text": " I wonder if this will work.",
        "tokens": [
          51264,
          286,
          2441,
          498,
          341,
          486,
          589,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 405.48,
        "id": 119,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 402.48,
        "temperature": 0,
        "text": " If I change this to false...",
        "tokens": [
          51314,
          759,
          286,
          1319,
          341,
          281,
          7908,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 408.48,
        "id": 120,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 407.48,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          51564,
          400,
          550,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.23583134360935376,
        "compression_ratio": 1.5153374233128833,
        "end": 411.48,
        "id": 121,
        "no_speech_prob": 0.000677104399073869,
        "seek": 38348,
        "start": 409.48,
        "temperature": 0,
        "text": " temp, uh, like...",
        "tokens": [
          51664,
          18274,
          11,
          2232,
          11,
          411,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 413.48,
        "id": 122,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 411.48,
        "temperature": 0,
        "text": " For writing.",
        "tokens": [
          50364,
          1171,
          3579,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 414.48,
        "id": 123,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 413.48,
        "temperature": 0,
        "text": " Publish.",
        "tokens": [
          50464,
          21808,
          1933,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 415.48,
        "id": 124,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 414.48,
        "temperature": 0,
        "text": " Like, will it let me...",
        "tokens": [
          50514,
          1743,
          11,
          486,
          309,
          718,
          385,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 417.48,
        "id": 125,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 415.48,
        "temperature": 0,
        "text": " Error saving rules.",
        "tokens": [
          50564,
          3300,
          2874,
          6816,
          4474,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 419.48,
        "id": 126,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 418.48,
        "temperature": 0,
        "text": " Um, oh...",
        "tokens": [
          50714,
          3301,
          11,
          1954,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 422.48,
        "id": 127,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 419.48,
        "temperature": 0,
        "text": " So, it needs expect line eight.",
        "tokens": [
          50764,
          407,
          11,
          309,
          2203,
          2066,
          1622,
          3180,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 432.48,
        "id": 128,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 428.48,
        "temperature": 0,
        "text": " Expected curly bracket.",
        "tokens": [
          51214,
          2111,
          10729,
          32066,
          16904,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 433.48,
        "id": 129,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 432.48,
        "temperature": 0,
        "text": " Hmm...",
        "tokens": [
          51414,
          8239,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 435.48,
        "id": 130,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 433.48,
        "temperature": 0,
        "text": " I guess I just need to take this out.",
        "tokens": [
          51464,
          286,
          2041,
          286,
          445,
          643,
          281,
          747,
          341,
          484,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2517664138584921,
        "compression_ratio": 1.3175675675675675,
        "end": 439.48,
        "id": 131,
        "no_speech_prob": 0.0012642793590202928,
        "seek": 41148,
        "start": 437.48,
        "temperature": 0,
        "text": " Just do false and.",
        "tokens": [
          51664,
          1449,
          360,
          7908,
          293,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 445.48,
        "id": 132,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 442.48,
        "temperature": 0,
        "text": " How do you know all this, me I am so me?",
        "tokens": [
          50414,
          1012,
          360,
          291,
          458,
          439,
          341,
          11,
          385,
          286,
          669,
          370,
          385,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 449.48,
        "id": 133,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 447.48,
        "temperature": 0,
        "text": " How do you know all this?",
        "tokens": [
          50664,
          1012,
          360,
          291,
          458,
          439,
          341,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 450.48,
        "id": 134,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 449.48,
        "temperature": 0,
        "text": " Uh, okay.",
        "tokens": [
          50764,
          4019,
          11,
          1392,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 452.48,
        "id": 135,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 450.48,
        "temperature": 0,
        "text": " So, let's go back to...",
        "tokens": [
          50814,
          407,
          11,
          718,
          311,
          352,
          646,
          281,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 455.48,
        "id": 136,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 454.48,
        "temperature": 0,
        "text": " Write.",
        "tokens": [
          51014,
          23499,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 457.48,
        "id": 137,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 456.48,
        "temperature": 0,
        "text": " False.",
        "tokens": [
          51114,
          50040,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 459.48,
        "id": 138,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 458.48,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51214,
          400,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 461.48,
        "id": 139,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 460.48,
        "temperature": 0,
        "text": " So, now...",
        "tokens": [
          51314,
          407,
          11,
          586,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 464.48,
        "id": 140,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 461.48,
        "temperature": 0,
        "text": " I changed the rules of the database.",
        "tokens": [
          51364,
          286,
          3105,
          264,
          4474,
          295,
          264,
          8149,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 467.48,
        "id": 141,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 464.48,
        "temperature": 0,
        "text": " If I go here, hit refresh,",
        "tokens": [
          51514,
          759,
          286,
          352,
          510,
          11,
          2045,
          15134,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 469.48,
        "id": 142,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 467.48,
        "temperature": 0,
        "text": " and try to click greenish, great.",
        "tokens": [
          51664,
          293,
          853,
          281,
          2052,
          3092,
          742,
          11,
          869,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22850510508743757,
        "compression_ratio": 1.4615384615384615,
        "end": 470.48,
        "id": 143,
        "no_speech_prob": 0.003222058294340968,
        "seek": 44148,
        "start": 469.48,
        "temperature": 0,
        "text": " Permission denied.",
        "tokens": [
          51764,
          41006,
          3106,
          17774,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 472.48,
        "id": 144,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 470.48,
        "temperature": 0,
        "text": " Alright, so I just wanted to shut off.",
        "tokens": [
          50364,
          2798,
          11,
          370,
          286,
          445,
          1415,
          281,
          5309,
          766,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 475.48,
        "id": 145,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 473.48,
        "temperature": 0,
        "text": " Writing to the database.",
        "tokens": [
          50514,
          32774,
          281,
          264,
          8149,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 477.48,
        "id": 146,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 475.48,
        "temperature": 0,
        "text": " Temporarily, I guess.",
        "tokens": [
          50614,
          8095,
          2816,
          3289,
          11,
          286,
          2041,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 479.48,
        "id": 147,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 477.48,
        "temperature": 0,
        "text": " Eh, why not just leave it on?",
        "tokens": [
          50714,
          9663,
          11,
          983,
          406,
          445,
          1856,
          309,
          322,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 482.48,
        "id": 148,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 480.48,
        "temperature": 0,
        "text": " Let's leave it on.",
        "tokens": [
          50864,
          961,
          311,
          1856,
          309,
          322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 485.48,
        "id": 149,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 483.48,
        "temperature": 0,
        "text": " That's so unlike me.",
        "tokens": [
          51014,
          663,
          311,
          370,
          8343,
          385,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 490.48,
        "id": 150,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 489.48,
        "temperature": 0,
        "text": " Let's make sure it's back.",
        "tokens": [
          51314,
          961,
          311,
          652,
          988,
          309,
          311,
          646,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 491.48,
        "id": 151,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 490.48,
        "temperature": 0,
        "text": " That looks bluish to me.",
        "tokens": [
          51364,
          663,
          1542,
          888,
          33786,
          281,
          385,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 492.48,
        "id": 152,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 491.48,
        "temperature": 0,
        "text": " Great, alright.",
        "tokens": [
          51414,
          3769,
          11,
          5845,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 495.48,
        "id": 153,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 492.48,
        "temperature": 0,
        "text": " So, I need to talk about the data.",
        "tokens": [
          51464,
          407,
          11,
          286,
          643,
          281,
          751,
          466,
          264,
          1412,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2082887740362258,
        "compression_ratio": 1.5567567567567568,
        "end": 497.48,
        "id": 154,
        "no_speech_prob": 0.0021487160120159388,
        "seek": 47048,
        "start": 495.48,
        "temperature": 0,
        "text": " The data, the data, the data.",
        "tokens": [
          51614,
          440,
          1412,
          11,
          264,
          1412,
          11,
          264,
          1412,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2658441023393111,
        "compression_ratio": 1.256,
        "end": 501.48,
        "id": 155,
        "no_speech_prob": 0.0006361381965689361,
        "seek": 49748,
        "start": 498.48,
        "temperature": 0,
        "text": " So, what I'm going to do in this video,",
        "tokens": [
          50414,
          407,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          341,
          960,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.2658441023393111,
        "compression_ratio": 1.256,
        "end": 505.48,
        "id": 156,
        "no_speech_prob": 0.0006361381965689361,
        "seek": 49748,
        "start": 501.48,
        "temperature": 0,
        "text": " and let me get a sketch going that reads the data.",
        "tokens": [
          50564,
          293,
          718,
          385,
          483,
          257,
          12325,
          516,
          300,
          15700,
          264,
          1412,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2658441023393111,
        "compression_ratio": 1.256,
        "end": 515.48,
        "id": 157,
        "no_speech_prob": 0.0006361381965689361,
        "seek": 49748,
        "start": 511.48,
        "temperature": 0,
        "text": " So, if p5 TensorFlow crowdsource color.",
        "tokens": [
          51064,
          407,
          11,
          498,
          280,
          20,
          37624,
          26070,
          2948,
          2017,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2658441023393111,
        "compression_ratio": 1.256,
        "end": 521.48,
        "id": 158,
        "no_speech_prob": 0.0006361381965689361,
        "seek": 49748,
        "start": 519.48,
        "temperature": 0,
        "text": " Uh, let's see.",
        "tokens": [
          51464,
          4019,
          11,
          718,
          311,
          536,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2658441023393111,
        "compression_ratio": 1.256,
        "end": 523.48,
        "id": 159,
        "no_speech_prob": 0.0006361381965689361,
        "seek": 49748,
        "start": 521.48,
        "temperature": 0,
        "text": " Clean data.",
        "tokens": [
          51564,
          18463,
          1412,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18312959372997284,
        "compression_ratio": 1.4275862068965517,
        "end": 527.48,
        "id": 160,
        "no_speech_prob": 0.00020661712915170938,
        "seek": 52348,
        "start": 524.48,
        "temperature": 0,
        "text": " Let's open up a terminal.",
        "tokens": [
          50414,
          961,
          311,
          1269,
          493,
          257,
          14709,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18312959372997284,
        "compression_ratio": 1.4275862068965517,
        "end": 536.48,
        "id": 161,
        "no_speech_prob": 0.00020661712915170938,
        "seek": 52348,
        "start": 534.48,
        "temperature": 0,
        "text": " I did not sleep well last night.",
        "tokens": [
          50914,
          286,
          630,
          406,
          2817,
          731,
          1036,
          1818,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18312959372997284,
        "compression_ratio": 1.4275862068965517,
        "end": 537.48,
        "id": 162,
        "no_speech_prob": 0.00020661712915170938,
        "seek": 52348,
        "start": 536.48,
        "temperature": 0,
        "text": " No, no, no.",
        "tokens": [
          51014,
          883,
          11,
          572,
          11,
          572,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18312959372997284,
        "compression_ratio": 1.4275862068965517,
        "end": 539.48,
        "id": 163,
        "no_speech_prob": 0.00020661712915170938,
        "seek": 52348,
        "start": 537.48,
        "temperature": 0,
        "text": " Did not sleep well last night.",
        "tokens": [
          51064,
          2589,
          406,
          2817,
          731,
          1036,
          1818,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18312959372997284,
        "compression_ratio": 1.4275862068965517,
        "end": 549.48,
        "id": 164,
        "no_speech_prob": 0.00020661712915170938,
        "seek": 52348,
        "start": 543.48,
        "temperature": 0,
        "text": " This evening, I will be attending Harry Potter and the Cursed Child on Broadway.",
        "tokens": [
          51364,
          639,
          5634,
          11,
          286,
          486,
          312,
          15862,
          9378,
          18115,
          293,
          264,
          383,
          47267,
          9004,
          322,
          19414,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18312959372997284,
        "compression_ratio": 1.4275862068965517,
        "end": 550.48,
        "id": 165,
        "no_speech_prob": 0.00020661712915170938,
        "seek": 52348,
        "start": 549.48,
        "temperature": 0,
        "text": " Very excited about that.",
        "tokens": [
          51664,
          4372,
          2919,
          466,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 553.48,
        "id": 166,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 550.48,
        "temperature": 0,
        "text": " No spoilers, although I kind of know what's going to happen anyway.",
        "tokens": [
          50364,
          883,
          32237,
          11,
          4878,
          286,
          733,
          295,
          458,
          437,
          311,
          516,
          281,
          1051,
          4033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 555.48,
        "id": 167,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 553.48,
        "temperature": 0,
        "text": " Since I haven't read before.",
        "tokens": [
          50514,
          4162,
          286,
          2378,
          380,
          1401,
          949,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 559.48,
        "id": 168,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 558.48,
        "temperature": 0,
        "text": " What am I doing?",
        "tokens": [
          50764,
          708,
          669,
          286,
          884,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 561.48,
        "id": 169,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 559.48,
        "temperature": 0,
        "text": " Okay, desktop.",
        "tokens": [
          50814,
          1033,
          11,
          14502,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 565.48,
        "id": 170,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 563.48,
        "temperature": 0,
        "text": " P5 TensorFlow.",
        "tokens": [
          51014,
          430,
          20,
          37624,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 566.48,
        "id": 171,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 565.48,
        "temperature": 0,
        "text": " No?",
        "tokens": [
          51114,
          883,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 568.48,
        "id": 172,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 566.48,
        "temperature": 0,
        "text": " Oh, I want to be in desktop.",
        "tokens": [
          51164,
          876,
          11,
          286,
          528,
          281,
          312,
          294,
          14502,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 570.48,
        "id": 173,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 568.48,
        "temperature": 0,
        "text": " This is not boating well.",
        "tokens": [
          51264,
          639,
          307,
          406,
          748,
          990,
          731,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 576.48,
        "id": 174,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 575.48,
        "temperature": 0,
        "text": " Yeah, p5.",
        "tokens": [
          51614,
          865,
          11,
          280,
          20,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25372452333749057,
        "compression_ratio": 1.331360946745562,
        "end": 577.48,
        "id": 175,
        "no_speech_prob": 0.007937530055642128,
        "seek": 55048,
        "start": 576.48,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51664,
          821,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 585.48,
        "id": 176,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 581.48,
        "temperature": 0,
        "text": " All right, let's go to here.",
        "tokens": [
          50414,
          1057,
          558,
          11,
          718,
          311,
          352,
          281,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 588.48,
        "id": 177,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 585.48,
        "temperature": 0,
        "text": " So, I've got Firebase.",
        "tokens": [
          50614,
          407,
          11,
          286,
          600,
          658,
          35173,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 589.48,
        "id": 178,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 588.48,
        "temperature": 0,
        "text": " I've got this.",
        "tokens": [
          50764,
          286,
          600,
          658,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 591.48,
        "id": 179,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 589.48,
        "temperature": 0,
        "text": " I want to go to here.",
        "tokens": [
          50814,
          286,
          528,
          281,
          352,
          281,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 593.48,
        "id": 180,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 591.48,
        "temperature": 0,
        "text": " Closed.",
        "tokens": [
          50914,
          2033,
          1744,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 596.48,
        "id": 181,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 593.48,
        "temperature": 0,
        "text": " I want to reference this one.",
        "tokens": [
          51014,
          286,
          528,
          281,
          6408,
          341,
          472,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 599.48,
        "id": 182,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 596.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19451698575701032,
        "compression_ratio": 1.3875968992248062,
        "end": 601.48,
        "id": 183,
        "no_speech_prob": 0.002471937332302332,
        "seek": 58048,
        "start": 599.48,
        "temperature": 0,
        "text": " And, of course, the camera goes off right now.",
        "tokens": [
          51314,
          400,
          11,
          295,
          1164,
          11,
          264,
          2799,
          1709,
          766,
          558,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 604.48,
        "id": 184,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 602.48,
        "temperature": 0,
        "text": " I don't know why I don't see the YouTube chat.",
        "tokens": [
          50414,
          286,
          500,
          380,
          458,
          983,
          286,
          500,
          380,
          536,
          264,
          3088,
          5081,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 606.48,
        "id": 185,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 604.48,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50514,
          821,
          321,
          352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 610.48,
        "id": 186,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 606.48,
        "temperature": 0,
        "text": " So, Adam and a half in the chat asks, can we contribute to the crowdsourcing?",
        "tokens": [
          50614,
          407,
          11,
          7938,
          293,
          257,
          1922,
          294,
          264,
          5081,
          8962,
          11,
          393,
          321,
          10586,
          281,
          264,
          26070,
          41849,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 612.48,
        "id": 187,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 610.48,
        "temperature": 0,
        "text": " So, yes.",
        "tokens": [
          50814,
          407,
          11,
          2086,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 616.48,
        "id": 188,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 612.48,
        "temperature": 0,
        "text": " I kind of would say, like, hold off right now.",
        "tokens": [
          50914,
          286,
          733,
          295,
          576,
          584,
          11,
          411,
          11,
          1797,
          766,
          558,
          586,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 618.48,
        "id": 189,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 616.48,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          51114,
          286,
          500,
          380,
          458,
          983,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 620.48,
        "id": 190,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 618.48,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          51214,
          286,
          500,
          380,
          458,
          983,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 622.48,
        "id": 191,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 620.48,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          51314,
          286,
          500,
          380,
          458,
          983,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 624.48,
        "id": 192,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 622.48,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          51414,
          286,
          500,
          380,
          458,
          983,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 626.48,
        "id": 193,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 624.48,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          983,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.41413133334269564,
        "compression_ratio": 1.9419354838709677,
        "end": 628.48,
        "id": 194,
        "no_speech_prob": 0.011329778470098972,
        "seek": 60148,
        "start": 626.48,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          51614,
          286,
          500,
          380,
          458,
          983,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21652728587657483,
        "compression_ratio": 1.653386454183267,
        "end": 637.48,
        "id": 195,
        "no_speech_prob": 0.29726216197013855,
        "seek": 62848,
        "start": 628.48,
        "temperature": 0,
        "text": " I would say, like, hold off right now as I'm going to use what is currently there for the purpose of today's live stream.",
        "tokens": [
          50364,
          286,
          576,
          584,
          11,
          411,
          11,
          1797,
          766,
          558,
          586,
          382,
          286,
          478,
          516,
          281,
          764,
          437,
          307,
          4362,
          456,
          337,
          264,
          4334,
          295,
          965,
          311,
          1621,
          4309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21652728587657483,
        "compression_ratio": 1.653386454183267,
        "end": 644.48,
        "id": 196,
        "no_speech_prob": 0.29726216197013855,
        "seek": 62848,
        "start": 637.48,
        "temperature": 0,
        "text": " But, of course, I'm glad for it to continue to be improved, and then I will come back in future live streams potentially and reference it.",
        "tokens": [
          50814,
          583,
          11,
          295,
          1164,
          11,
          286,
          478,
          5404,
          337,
          309,
          281,
          2354,
          281,
          312,
          9689,
          11,
          293,
          550,
          286,
          486,
          808,
          646,
          294,
          2027,
          1621,
          15842,
          7263,
          293,
          6408,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21652728587657483,
        "compression_ratio": 1.653386454183267,
        "end": 648.48,
        "id": 197,
        "no_speech_prob": 0.29726216197013855,
        "seek": 62848,
        "start": 644.48,
        "temperature": 0,
        "text": " Is the sound okay today?",
        "tokens": [
          51164,
          1119,
          264,
          1626,
          1392,
          965,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.21652728587657483,
        "compression_ratio": 1.653386454183267,
        "end": 650.48,
        "id": 198,
        "no_speech_prob": 0.29726216197013855,
        "seek": 62848,
        "start": 648.48,
        "temperature": 0,
        "text": " I just want to make sure the microphone is not peaking.",
        "tokens": [
          51364,
          286,
          445,
          528,
          281,
          652,
          988,
          264,
          10952,
          307,
          406,
          520,
          2456,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21652728587657483,
        "compression_ratio": 1.653386454183267,
        "end": 652.48,
        "id": 199,
        "no_speech_prob": 0.29726216197013855,
        "seek": 62848,
        "start": 650.48,
        "temperature": 0,
        "text": " I suppose I could listen to my own sound.",
        "tokens": [
          51464,
          286,
          7297,
          286,
          727,
          2140,
          281,
          452,
          1065,
          1626,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21652728587657483,
        "compression_ratio": 1.653386454183267,
        "end": 654.48,
        "id": 200,
        "no_speech_prob": 0.29726216197013855,
        "seek": 62848,
        "start": 652.48,
        "temperature": 0,
        "text": " I could listen to my own voice.",
        "tokens": [
          51564,
          286,
          727,
          2140,
          281,
          452,
          1065,
          3177,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 657.48,
        "id": 201,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 655.48,
        "temperature": 0,
        "text": " Just to find out.",
        "tokens": [
          50414,
          1449,
          281,
          915,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 659.48,
        "id": 202,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 657.48,
        "temperature": 0,
        "text": " Test one two.",
        "tokens": [
          50514,
          9279,
          472,
          732,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 661.48,
        "id": 203,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 659.48,
        "temperature": 0,
        "text": " Test.",
        "tokens": [
          50614,
          9279,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 663.48,
        "id": 204,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 661.48,
        "temperature": 0,
        "text": " Test.",
        "tokens": [
          50714,
          9279,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 665.48,
        "id": 205,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 663.48,
        "temperature": 0,
        "text": " Test one two.",
        "tokens": [
          50814,
          9279,
          472,
          732,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 667.48,
        "id": 206,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 665.48,
        "temperature": 0,
        "text": " I think it sounds fine.",
        "tokens": [
          50914,
          286,
          519,
          309,
          3263,
          2489,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 669.48,
        "id": 207,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 667.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 671.48,
        "id": 208,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 669.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25974607467651367,
        "compression_ratio": 1.3205128205128205,
        "end": 673.48,
        "id": 209,
        "no_speech_prob": 0.07913106679916382,
        "seek": 65448,
        "start": 671.48,
        "temperature": 0,
        "text": " And so...",
        "tokens": [
          51214,
          400,
          370,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.26603180507443985,
        "compression_ratio": 1.280701754385965,
        "end": 676.48,
        "id": 210,
        "no_speech_prob": 0.02716159075498581,
        "seek": 67348,
        "start": 674.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.26603180507443985,
        "compression_ratio": 1.280701754385965,
        "end": 678.48,
        "id": 211,
        "no_speech_prob": 0.02716159075498581,
        "seek": 67348,
        "start": 676.48,
        "temperature": 0,
        "text": " And so...",
        "tokens": [
          50514,
          400,
          370,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.26603180507443985,
        "compression_ratio": 1.280701754385965,
        "end": 688.48,
        "id": 212,
        "no_speech_prob": 0.02716159075498581,
        "seek": 67348,
        "start": 683.48,
        "temperature": 0,
        "text": " So then what I need to do is I want to go to clean data here.",
        "tokens": [
          50864,
          407,
          550,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          528,
          281,
          352,
          281,
          2541,
          1412,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.26603180507443985,
        "compression_ratio": 1.280701754385965,
        "end": 694.48,
        "id": 213,
        "no_speech_prob": 0.02716159075498581,
        "seek": 67348,
        "start": 688.48,
        "temperature": 0,
        "text": " And I want to open up the Atom editor.",
        "tokens": [
          51114,
          400,
          286,
          528,
          281,
          1269,
          493,
          264,
          1711,
          298,
          9839,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.26603180507443985,
        "compression_ratio": 1.280701754385965,
        "end": 698.48,
        "id": 214,
        "no_speech_prob": 0.02716159075498581,
        "seek": 67348,
        "start": 694.48,
        "temperature": 0,
        "text": " I got to have a workflow day.",
        "tokens": [
          51414,
          286,
          658,
          281,
          362,
          257,
          20993,
          786,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2903318172547875,
        "compression_ratio": 1.1333333333333333,
        "end": 703.48,
        "id": 215,
        "no_speech_prob": 0.025560250505805016,
        "seek": 69848,
        "start": 698.48,
        "temperature": 0,
        "text": " A day just to, like, redo all my workflow stuff.",
        "tokens": [
          50364,
          316,
          786,
          445,
          281,
          11,
          411,
          11,
          29956,
          439,
          452,
          20993,
          1507,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2903318172547875,
        "compression_ratio": 1.1333333333333333,
        "end": 705.48,
        "id": 216,
        "no_speech_prob": 0.025560250505805016,
        "seek": 69848,
        "start": 703.48,
        "temperature": 0,
        "text": " Clean data.",
        "tokens": [
          50614,
          18463,
          1412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2903318172547875,
        "compression_ratio": 1.1333333333333333,
        "end": 707.48,
        "id": 217,
        "no_speech_prob": 0.025560250505805016,
        "seek": 69848,
        "start": 705.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2903318172547875,
        "compression_ratio": 1.1333333333333333,
        "end": 718.48,
        "id": 218,
        "no_speech_prob": 0.025560250505805016,
        "seek": 69848,
        "start": 707.48,
        "temperature": 0,
        "text": " I'm going to get to some actual content in a moment.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          483,
          281,
          512,
          3539,
          2701,
          294,
          257,
          1623,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 721.48,
        "id": 219,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 719.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 723.48,
        "id": 220,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 721.48,
        "temperature": 0,
        "text": " So, let's go to Firebase.",
        "tokens": [
          50514,
          407,
          11,
          718,
          311,
          352,
          281,
          35173,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 725.48,
        "id": 221,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 723.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 727.48,
        "id": 222,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 725.48,
        "temperature": 0,
        "text": " Firebase.",
        "tokens": [
          50714,
          35173,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 729.48,
        "id": 223,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 727.48,
        "temperature": 0,
        "text": " Let's go to shift.net.",
        "tokens": [
          50814,
          961,
          311,
          352,
          281,
          402,
          351,
          83,
          13,
          7129,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 731.48,
        "id": 224,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 729.48,
        "temperature": 0,
        "text": " A2Z.",
        "tokens": [
          50914,
          316,
          17,
          57,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 733.48,
        "id": 225,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 731.48,
        "temperature": 0,
        "text": " Firebase.",
        "tokens": [
          51014,
          35173,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.5063746452331543,
        "compression_ratio": 1.288659793814433,
        "end": 735.48,
        "id": 226,
        "no_speech_prob": 0.16227811574935913,
        "seek": 71848,
        "start": 733.48,
        "temperature": 0,
        "text": " So, I think I have all the URLs I need.",
        "tokens": [
          51114,
          407,
          11,
          286,
          519,
          286,
          362,
          439,
          264,
          43267,
          286,
          643,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 738.48,
        "id": 227,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 736.48,
        "temperature": 0.4,
        "text": " Push call back.",
        "tokens": [
          50414,
          18229,
          818,
          646,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 740.48,
        "id": 228,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 738.48,
        "temperature": 0.4,
        "text": " I'm just looking for retrieving data.",
        "tokens": [
          50514,
          286,
          478,
          445,
          1237,
          337,
          19817,
          798,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 742.48,
        "id": 229,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 740.48,
        "temperature": 0.4,
        "text": " If only somebody would make a tutorial.",
        "tokens": [
          50614,
          759,
          787,
          2618,
          576,
          652,
          257,
          7073,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 744.48,
        "id": 230,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 742.48,
        "temperature": 0.4,
        "text": " I mean, I'm not sure I would be able to do that.",
        "tokens": [
          50714,
          286,
          914,
          11,
          286,
          478,
          406,
          988,
          286,
          576,
          312,
          1075,
          281,
          360,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 746.48,
        "id": 231,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 744.48,
        "temperature": 0.4,
        "text": " I'm not sure I would be able to do that.",
        "tokens": [
          50814,
          286,
          478,
          406,
          988,
          286,
          576,
          312,
          1075,
          281,
          360,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 748.48,
        "id": 232,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 746.48,
        "temperature": 0.4,
        "text": " I'm not sure I would be able to do that.",
        "tokens": [
          50914,
          286,
          478,
          406,
          988,
          286,
          576,
          312,
          1075,
          281,
          360,
          300,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 750.48,
        "id": 233,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 748.48,
        "temperature": 0.4,
        "text": " Maybe I could.",
        "tokens": [
          51014,
          2704,
          286,
          727,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 752.48,
        "id": 234,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 750.48,
        "temperature": 0.4,
        "text": " I'm not sure.",
        "tokens": [
          51114,
          286,
          478,
          406,
          988,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 754.48,
        "id": 235,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 752.48,
        "temperature": 0.4,
        "text": " I don't know.",
        "tokens": [
          51214,
          286,
          500,
          380,
          458,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 756.48,
        "id": 236,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 754.48,
        "temperature": 0.4,
        "text": " I'm not sure.",
        "tokens": [
          51314,
          286,
          478,
          406,
          262,
          540,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 758.48,
        "id": 237,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 756.48,
        "temperature": 0.4,
        "text": " I'm not sure.",
        "tokens": [
          51414,
          286,
          478,
          406,
          988,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 760.48,
        "id": 238,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 758.48,
        "temperature": 0.4,
        "text": " I'm not sure.",
        "tokens": [
          51514,
          286,
          478,
          406,
          988,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 762.48,
        "id": 239,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 760.48,
        "temperature": 0.4,
        "text": " I'm not sure.",
        "tokens": [
          51614,
          286,
          478,
          406,
          988,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.6058185870830829,
        "compression_ratio": 2.3732394366197185,
        "end": 764.48,
        "id": 240,
        "no_speech_prob": 0.20420321822166443,
        "seek": 73548,
        "start": 762.48,
        "temperature": 0.4,
        "text": " I'm not sure.",
        "tokens": [
          51714,
          286,
          478,
          406,
          988,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 769.48,
        "id": 241,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 764.48,
        "temperature": 0,
        "text": " If somebody would make a tutorial on retrieving data from Firebase, then I would know how to do it.",
        "tokens": [
          50364,
          759,
          2618,
          576,
          652,
          257,
          7073,
          322,
          19817,
          798,
          1412,
          490,
          35173,
          11,
          550,
          286,
          576,
          458,
          577,
          281,
          360,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 771.48,
        "id": 242,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 769.48,
        "temperature": 0,
        "text": " Hello, Meijer.",
        "tokens": [
          50614,
          2425,
          11,
          1923,
          1718,
          260,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 773.48,
        "id": 243,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 771.48,
        "temperature": 0,
        "text": " Thank you, sponsor Meijer in the chat.",
        "tokens": [
          50714,
          1044,
          291,
          11,
          16198,
          1923,
          1718,
          260,
          294,
          264,
          5081,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 775.48,
        "id": 244,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 773.48,
        "temperature": 0,
        "text": " Uh-oh.",
        "tokens": [
          50814,
          4019,
          12,
          1445,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 777.48,
        "id": 245,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 775.48,
        "temperature": 0,
        "text": " I think coding garden with CJ is happening right now.",
        "tokens": [
          50914,
          286,
          519,
          17720,
          7431,
          365,
          42285,
          307,
          2737,
          558,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 779.48,
        "id": 246,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 777.48,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          51014,
          876,
          11,
          572,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 781.48,
        "id": 247,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 779.48,
        "temperature": 0,
        "text": " In 30 minutes.",
        "tokens": [
          51114,
          682,
          2217,
          2077,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 783.48,
        "id": 248,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 781.48,
        "temperature": 0,
        "text": " I'll be done by then.",
        "tokens": [
          51214,
          286,
          603,
          312,
          1096,
          538,
          550,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 785.48,
        "id": 249,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 783.48,
        "temperature": 0,
        "text": " I'll be done by then.",
        "tokens": [
          51314,
          286,
          603,
          312,
          1096,
          538,
          550,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 787.48,
        "id": 250,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 785.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51414,
          1779,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 789.48,
        "id": 251,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 787.48,
        "temperature": 0,
        "text": " Reference on.",
        "tokens": [
          51514,
          1300,
          5158,
          322,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 791.48,
        "id": 252,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 789.48,
        "temperature": 0,
        "text": " Got data.",
        "tokens": [
          51614,
          5803,
          1412,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2336041022991312,
        "compression_ratio": 1.4838709677419355,
        "end": 793.48,
        "id": 253,
        "no_speech_prob": 0.21460287272930145,
        "seek": 76448,
        "start": 791.48,
        "temperature": 0,
        "text": " Air data.",
        "tokens": [
          51714,
          5774,
          1412,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 796.48,
        "id": 254,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 794.48,
        "temperature": 0,
        "text": " I think I want once.",
        "tokens": [
          50414,
          286,
          519,
          286,
          528,
          1564,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 798.48,
        "id": 255,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 796.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50514,
          1779,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 800.48,
        "id": 256,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 798.48,
        "temperature": 0,
        "text": " I just want to use the once function.",
        "tokens": [
          50614,
          286,
          445,
          528,
          281,
          764,
          264,
          1564,
          2445,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 807.48,
        "id": 257,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 800.48,
        "temperature": 0,
        "text": " What did, what did Panzer on GitHub use to retrieve the data?",
        "tokens": [
          50714,
          708,
          630,
          11,
          437,
          630,
          45932,
          260,
          322,
          23331,
          764,
          281,
          30254,
          264,
          1412,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 809.48,
        "id": 258,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 807.48,
        "temperature": 0,
        "text": " Load data.",
        "tokens": [
          51064,
          48408,
          1412,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 811.48,
        "id": 259,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 809.48,
        "temperature": 0,
        "text": " Then show loading.",
        "tokens": [
          51164,
          1396,
          855,
          15114,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 813.48,
        "id": 260,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 811.48,
        "temperature": 0,
        "text": " Where's the load data function?",
        "tokens": [
          51264,
          2305,
          311,
          264,
          3677,
          1412,
          2445,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 815.48,
        "id": 261,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 813.48,
        "temperature": 0,
        "text": " Return database.",
        "tokens": [
          51364,
          24350,
          8149,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 817.48,
        "id": 262,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 815.48,
        "temperature": 0,
        "text": " Once.",
        "tokens": [
          51464,
          3443,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.36356858509342843,
        "compression_ratio": 1.4695121951219512,
        "end": 819.48,
        "id": 263,
        "no_speech_prob": 0.021942749619483948,
        "seek": 79348,
        "start": 817.48,
        "temperature": 0,
        "text": " That's what I'm going to do.",
        "tokens": [
          51564,
          663,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 822.48,
        "id": 264,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 820.48,
        "temperature": 0,
        "text": " Return database.",
        "tokens": [
          50414,
          24350,
          8149,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 824.48,
        "id": 265,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 822.48,
        "temperature": 0,
        "text": " Once.",
        "tokens": [
          50514,
          3443,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 826.48,
        "id": 266,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 824.48,
        "temperature": 0,
        "text": " That's what I want.",
        "tokens": [
          50614,
          663,
          311,
          437,
          286,
          528,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 828.48,
        "id": 267,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 826.48,
        "temperature": 0,
        "text": " Once.",
        "tokens": [
          50714,
          3443,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 830.48,
        "id": 268,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 828.48,
        "temperature": 0,
        "text": " I don't know why I have this on.",
        "tokens": [
          50814,
          286,
          500,
          380,
          458,
          983,
          286,
          362,
          341,
          322,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 832.48,
        "id": 269,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 830.48,
        "temperature": 0,
        "text": " I want once.",
        "tokens": [
          50914,
          286,
          528,
          1564,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 834.48,
        "id": 270,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 832.48,
        "temperature": 0,
        "text": " Close enough.",
        "tokens": [
          51014,
          16346,
          1547,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 836.48,
        "id": 271,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 834.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 838.48,
        "id": 272,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 836.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 840.48,
        "id": 273,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 838.48,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51314,
          21726,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 842.48,
        "id": 274,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 840.48,
        "temperature": 0,
        "text": " I've totally lost the chat and everything here.",
        "tokens": [
          51414,
          286,
          600,
          3879,
          2731,
          264,
          5081,
          293,
          1203,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 844.48,
        "id": 275,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 842.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51514,
          1057,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.14716056415012904,
        "compression_ratio": 1.4172185430463575,
        "end": 846.48,
        "id": 276,
        "no_speech_prob": 0.040230102837085724,
        "seek": 81948,
        "start": 844.48,
        "temperature": 0,
        "text": " Once value callback is good.",
        "tokens": [
          51614,
          3443,
          2158,
          818,
          3207,
          307,
          665,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25326842949038647,
        "compression_ratio": 1.7642585551330798,
        "end": 851.48,
        "id": 277,
        "no_speech_prob": 0.3379357159137726,
        "seek": 84648,
        "start": 846.48,
        "temperature": 0,
        "text": " Yeah, you know, so me I am so me is asking not just going to export it from the console.",
        "tokens": [
          50364,
          865,
          11,
          291,
          458,
          11,
          370,
          385,
          286,
          669,
          370,
          385,
          307,
          3365,
          406,
          445,
          516,
          281,
          10725,
          309,
          490,
          264,
          11076,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25326842949038647,
        "compression_ratio": 1.7642585551330798,
        "end": 857.48,
        "id": 278,
        "no_speech_prob": 0.3379357159137726,
        "seek": 84648,
        "start": 851.48,
        "temperature": 0,
        "text": " So that was my original plan was to export it from the console and then like bring it into a Google doc spreadsheet.",
        "tokens": [
          50614,
          407,
          300,
          390,
          452,
          3380,
          1393,
          390,
          281,
          10725,
          309,
          490,
          264,
          11076,
          293,
          550,
          411,
          1565,
          309,
          666,
          257,
          3329,
          3211,
          27733,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25326842949038647,
        "compression_ratio": 1.7642585551330798,
        "end": 859.48,
        "id": 279,
        "no_speech_prob": 0.3379357159137726,
        "seek": 84648,
        "start": 857.48,
        "temperature": 0,
        "text": " And then like, you know, clean it there.",
        "tokens": [
          50914,
          400,
          550,
          411,
          11,
          291,
          458,
          11,
          2541,
          309,
          456,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25326842949038647,
        "compression_ratio": 1.7642585551330798,
        "end": 865.48,
        "id": 280,
        "no_speech_prob": 0.3379357159137726,
        "seek": 84648,
        "start": 859.48,
        "temperature": 0,
        "text": " But then I realized I think I might actually be better at cleaning it from JavaScript itself.",
        "tokens": [
          51014,
          583,
          550,
          286,
          5334,
          286,
          519,
          286,
          1062,
          767,
          312,
          1101,
          412,
          8924,
          309,
          490,
          15778,
          2564,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25326842949038647,
        "compression_ratio": 1.7642585551330798,
        "end": 868.48,
        "id": 281,
        "no_speech_prob": 0.3379357159137726,
        "seek": 84648,
        "start": 865.48,
        "temperature": 0,
        "text": " Because what I could quickly do is just like do like a count.",
        "tokens": [
          51314,
          1436,
          437,
          286,
          727,
          2661,
          360,
          307,
          445,
          411,
          360,
          411,
          257,
          1207,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.25326842949038647,
        "compression_ratio": 1.7642585551330798,
        "end": 870.48,
        "id": 282,
        "no_speech_prob": 0.3379357159137726,
        "seek": 84648,
        "start": 868.48,
        "temperature": 0,
        "text": " I could visualize it.",
        "tokens": [
          51464,
          286,
          727,
          23273,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.25326842949038647,
        "compression_ratio": 1.7642585551330798,
        "end": 872.48,
        "id": 283,
        "no_speech_prob": 0.3379357159137726,
        "seek": 84648,
        "start": 870.48,
        "temperature": 0,
        "text": " So I think I want to do just the first.",
        "tokens": [
          51564,
          407,
          286,
          519,
          286,
          528,
          281,
          360,
          445,
          264,
          700,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21873850822448732,
        "compression_ratio": 1.2894736842105263,
        "end": 878.48,
        "id": 284,
        "no_speech_prob": 0.10229380428791046,
        "seek": 87248,
        "start": 872.48,
        "temperature": 0,
        "text": " So in this series, which is just to kind of remind myself where I am.",
        "tokens": [
          50364,
          407,
          294,
          341,
          2638,
          11,
          597,
          307,
          445,
          281,
          733,
          295,
          4160,
          2059,
          689,
          286,
          669,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21873850822448732,
        "compression_ratio": 1.2894736842105263,
        "end": 886.48,
        "id": 285,
        "no_speech_prob": 0.10229380428791046,
        "seek": 87248,
        "start": 878.48,
        "temperature": 0,
        "text": " If I go to the coding train and I go to neural networks and machine learning.",
        "tokens": [
          50664,
          759,
          286,
          352,
          281,
          264,
          17720,
          3847,
          293,
          286,
          352,
          281,
          18161,
          9590,
          293,
          3479,
          2539,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3043115985008978,
        "compression_ratio": 1.3409090909090908,
        "end": 904.48,
        "id": 286,
        "no_speech_prob": 0.5466324090957642,
        "seek": 88648,
        "start": 887.48,
        "temperature": 0,
        "text": " I think I am at this point in session 7, which is building a classifier with building a classifier with TensorFlow.js.",
        "tokens": [
          50414,
          286,
          519,
          286,
          669,
          412,
          341,
          935,
          294,
          5481,
          1614,
          11,
          597,
          307,
          2390,
          257,
          1508,
          9902,
          365,
          2390,
          257,
          1508,
          9902,
          365,
          37624,
          13,
          25530,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25622393868186255,
        "compression_ratio": 1.3461538461538463,
        "end": 915.48,
        "id": 287,
        "no_speech_prob": 0.13292060792446136,
        "seek": 90448,
        "start": 904.48,
        "temperature": 0,
        "text": " And so, so far what I have done is I just did I think one or two kind of short tutorials about crowdsourcing the data.",
        "tokens": [
          50364,
          400,
          370,
          11,
          370,
          1400,
          437,
          286,
          362,
          1096,
          307,
          286,
          445,
          630,
          286,
          519,
          472,
          420,
          732,
          733,
          295,
          2099,
          17616,
          466,
          26070,
          41849,
          264,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25622393868186255,
        "compression_ratio": 1.3461538461538463,
        "end": 919.48,
        "id": 288,
        "no_speech_prob": 0.13292060792446136,
        "seek": 90448,
        "start": 915.48,
        "temperature": 0,
        "text": " And I also wanted to reference somebody.",
        "tokens": [
          50914,
          400,
          286,
          611,
          1415,
          281,
          6408,
          2618,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.25622393868186255,
        "compression_ratio": 1.3461538461538463,
        "end": 922.48,
        "id": 289,
        "no_speech_prob": 0.13292060792446136,
        "seek": 90448,
        "start": 919.48,
        "temperature": 0,
        "text": " Maybe the Slack channel can help me out with this.",
        "tokens": [
          51114,
          2704,
          264,
          37211,
          2269,
          393,
          854,
          385,
          484,
          365,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2887153625488281,
        "compression_ratio": 1.4404761904761905,
        "end": 936.48,
        "id": 290,
        "no_speech_prob": 0.1823602020740509,
        "seek": 92248,
        "start": 923.48,
        "temperature": 0,
        "text": " Someone in the sent me a message, I believe in the patron Slack channel yesterday referencing a video about research into human perception and color that seemed kind of relevant.",
        "tokens": [
          50414,
          8734,
          294,
          264,
          2279,
          385,
          257,
          3636,
          11,
          286,
          1697,
          294,
          264,
          21843,
          37211,
          2269,
          5186,
          40582,
          257,
          960,
          466,
          2132,
          666,
          1952,
          12860,
          293,
          2017,
          300,
          6576,
          733,
          295,
          7340,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2887153625488281,
        "compression_ratio": 1.4404761904761905,
        "end": 938.48,
        "id": 291,
        "no_speech_prob": 0.1823602020740509,
        "seek": 92248,
        "start": 936.48,
        "temperature": 0,
        "text": " Somebody could share that with me again.",
        "tokens": [
          51064,
          13463,
          727,
          2073,
          300,
          365,
          385,
          797,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2887153625488281,
        "compression_ratio": 1.4404761904761905,
        "end": 942.48,
        "id": 292,
        "no_speech_prob": 0.1823602020740509,
        "seek": 92248,
        "start": 938.48,
        "temperature": 0,
        "text": " That would be helpful.",
        "tokens": [
          51164,
          663,
          576,
          312,
          4961,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.30319710572560626,
        "compression_ratio": 1.2592592592592593,
        "end": 952.48,
        "id": 293,
        "no_speech_prob": 0.05664614588022232,
        "seek": 94248,
        "start": 943.48,
        "temperature": 0,
        "text": " Okay, so I think other than that, I am ready to begin.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          286,
          519,
          661,
          813,
          300,
          11,
          286,
          669,
          1919,
          281,
          1841,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.30319710572560626,
        "compression_ratio": 1.2592592592592593,
        "end": 957.48,
        "id": 294,
        "no_speech_prob": 0.05664614588022232,
        "seek": 94248,
        "start": 952.48,
        "temperature": 0,
        "text": " I don't want this to be empty.",
        "tokens": [
          50864,
          286,
          500,
          380,
          528,
          341,
          281,
          312,
          6707,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.30319710572560626,
        "compression_ratio": 1.2592592592592593,
        "end": 965.48,
        "id": 295,
        "no_speech_prob": 0.05664614588022232,
        "seek": 94248,
        "start": 963.48,
        "temperature": 0,
        "text": " And so I'm starting with here.",
        "tokens": [
          51414,
          400,
          370,
          286,
          478,
          2891,
          365,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.30319710572560626,
        "compression_ratio": 1.2592592592592593,
        "end": 967.48,
        "id": 296,
        "no_speech_prob": 0.05664614588022232,
        "seek": 94248,
        "start": 965.48,
        "temperature": 0,
        "text": " I'm moving to here.",
        "tokens": [
          51514,
          286,
          478,
          2684,
          281,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3450061624700373,
        "compression_ratio": 1.4516129032258065,
        "end": 972.48,
        "id": 297,
        "no_speech_prob": 0.005384005140513182,
        "seek": 96748,
        "start": 967.48,
        "temperature": 0,
        "text": " And then I'm starting with here.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          2891,
          365,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3450061624700373,
        "compression_ratio": 1.4516129032258065,
        "end": 974.48,
        "id": 298,
        "no_speech_prob": 0.005384005140513182,
        "seek": 96748,
        "start": 972.48,
        "temperature": 0,
        "text": " Moving to here.",
        "tokens": [
          50614,
          14242,
          281,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3450061624700373,
        "compression_ratio": 1.4516129032258065,
        "end": 976.48,
        "id": 299,
        "no_speech_prob": 0.005384005140513182,
        "seek": 96748,
        "start": 974.48,
        "temperature": 0,
        "text": " Then to here.",
        "tokens": [
          50714,
          1396,
          281,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3450061624700373,
        "compression_ratio": 1.4516129032258065,
        "end": 982.48,
        "id": 300,
        "no_speech_prob": 0.005384005140513182,
        "seek": 96748,
        "start": 976.48,
        "temperature": 0,
        "text": " Then I'm going to, oh, then to here.",
        "tokens": [
          50814,
          1396,
          286,
          478,
          516,
          281,
          11,
          1954,
          11,
          550,
          281,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3450061624700373,
        "compression_ratio": 1.4516129032258065,
        "end": 984.48,
        "id": 301,
        "no_speech_prob": 0.005384005140513182,
        "seek": 96748,
        "start": 982.48,
        "temperature": 0,
        "text": " Here.",
        "tokens": [
          51114,
          1692,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3450061624700373,
        "compression_ratio": 1.4516129032258065,
        "end": 986.48,
        "id": 302,
        "no_speech_prob": 0.005384005140513182,
        "seek": 96748,
        "start": 984.48,
        "temperature": 0,
        "text": " And then I'll need this as a reference.",
        "tokens": [
          51214,
          400,
          550,
          286,
          603,
          643,
          341,
          382,
          257,
          6408,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3450061624700373,
        "compression_ratio": 1.4516129032258065,
        "end": 988.48,
        "id": 303,
        "no_speech_prob": 0.005384005140513182,
        "seek": 96748,
        "start": 986.48,
        "temperature": 0,
        "text": " Okay, I think I am ready to begin.",
        "tokens": [
          51314,
          1033,
          11,
          286,
          519,
          286,
          669,
          1919,
          281,
          1841,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 993.48,
        "id": 304,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 989.48,
        "temperature": 0,
        "text": " Nobody remembers this research that was somebody, I guess I could try to find it myself.",
        "tokens": [
          50414,
          9297,
          26228,
          341,
          2132,
          300,
          390,
          2618,
          11,
          286,
          2041,
          286,
          727,
          853,
          281,
          915,
          309,
          2059,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 995.48,
        "id": 305,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 993.48,
        "temperature": 0,
        "text": " Oh, the World Cup started.",
        "tokens": [
          50614,
          876,
          11,
          264,
          3937,
          13751,
          1409,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 997.48,
        "id": 306,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 995.48,
        "temperature": 0,
        "text": " I made my picks.",
        "tokens": [
          50714,
          286,
          1027,
          452,
          16137,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 999.48,
        "id": 307,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 997.48,
        "temperature": 0,
        "text": " Want to hear my picks?",
        "tokens": [
          50814,
          11773,
          281,
          1568,
          452,
          16137,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 1001.48,
        "id": 308,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 999.48,
        "temperature": 0,
        "text": " I don't want to embarrass myself.",
        "tokens": [
          50914,
          286,
          500,
          380,
          528,
          281,
          9187,
          2059,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 1005.48,
        "id": 309,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 1001.48,
        "temperature": 0,
        "text": " And I don't want to cause the chat to go off the rails.",
        "tokens": [
          51014,
          400,
          286,
          500,
          380,
          528,
          281,
          3082,
          264,
          5081,
          281,
          352,
          766,
          264,
          27649,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 1007.48,
        "id": 310,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 1005.48,
        "temperature": 0,
        "text": " So maybe I won't give you my picks.",
        "tokens": [
          51214,
          407,
          1310,
          286,
          1582,
          380,
          976,
          291,
          452,
          16137,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 1009.48,
        "id": 311,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 1007.48,
        "temperature": 0,
        "text": " I mean like what do you call those things?",
        "tokens": [
          51314,
          286,
          914,
          411,
          437,
          360,
          291,
          818,
          729,
          721,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 1011.48,
        "id": 312,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 1009.48,
        "temperature": 0,
        "text": " A pool?",
        "tokens": [
          51414,
          316,
          7005,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.30747076729747735,
        "compression_ratio": 1.6037735849056605,
        "end": 1013.48,
        "id": 313,
        "no_speech_prob": 0.09945544600486755,
        "seek": 98848,
        "start": 1011.48,
        "temperature": 0,
        "text": " A pool?",
        "tokens": [
          51514,
          316,
          7005,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1017.48,
        "id": 314,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1013.48,
        "temperature": 0,
        "text": " I mean like what do you call those things?",
        "tokens": [
          50364,
          286,
          914,
          411,
          437,
          360,
          291,
          818,
          729,
          721,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1019.48,
        "id": 315,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1017.48,
        "temperature": 0,
        "text": " A pool?",
        "tokens": [
          50564,
          316,
          7005,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1021.48,
        "id": 316,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1019.48,
        "temperature": 0,
        "text": " Friendly, $5.",
        "tokens": [
          50664,
          22812,
          356,
          11,
          1848,
          20,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1027.48,
        "id": 317,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1021.48,
        "temperature": 0,
        "text": " So I don't think I'm going to break the bank here, winning or losing.",
        "tokens": [
          50764,
          407,
          286,
          500,
          380,
          519,
          286,
          478,
          516,
          281,
          1821,
          264,
          3765,
          510,
          11,
          8224,
          420,
          7027,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1029.48,
        "id": 318,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1027.48,
        "temperature": 0,
        "text": " But I am kind of excited about the World Cup.",
        "tokens": [
          51064,
          583,
          286,
          669,
          733,
          295,
          2919,
          466,
          264,
          3937,
          13751,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1031.48,
        "id": 319,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1029.48,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          51164,
          2438,
          11,
          1392,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1036.48,
        "id": 320,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1031.48,
        "temperature": 0,
        "text": " It was from Bruno.",
        "tokens": [
          51264,
          467,
          390,
          490,
          23046,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2261379877726237,
        "compression_ratio": 1.3350253807106598,
        "end": 1039.48,
        "id": 321,
        "no_speech_prob": 0.20429162681102753,
        "seek": 101348,
        "start": 1036.48,
        "temperature": 0,
        "text": " Oh, first of all, I've got to show this to everybody.",
        "tokens": [
          51514,
          876,
          11,
          700,
          295,
          439,
          11,
          286,
          600,
          658,
          281,
          855,
          341,
          281,
          2201,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1046.48,
        "id": 322,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1040.48,
        "temperature": 0,
        "text": " Please, please humor me for just one moment.",
        "tokens": [
          50414,
          2555,
          11,
          1767,
          14318,
          385,
          337,
          445,
          472,
          1623,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1048.48,
        "id": 323,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1046.48,
        "temperature": 0,
        "text": " I'm going to go to Twitter.",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          352,
          281,
          5794,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1050.48,
        "id": 324,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1048.48,
        "temperature": 0,
        "text": " What am I logged in as?",
        "tokens": [
          50814,
          708,
          669,
          286,
          27231,
          294,
          382,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1052.48,
        "id": 325,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1050.48,
        "temperature": 0,
        "text": " Coding train?",
        "tokens": [
          50914,
          383,
          8616,
          3847,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1054.48,
        "id": 326,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1052.48,
        "temperature": 0,
        "text": " Notifications?",
        "tokens": [
          51014,
          1726,
          7833,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1056.48,
        "id": 327,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1054.48,
        "temperature": 0,
        "text": " Let's find mentions.",
        "tokens": [
          51114,
          961,
          311,
          915,
          23844,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1058.48,
        "id": 328,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1056.48,
        "temperature": 0,
        "text": " Oh, here it is already.",
        "tokens": [
          51214,
          876,
          11,
          510,
          309,
          307,
          1217,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1060.48,
        "id": 329,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1058.48,
        "temperature": 0,
        "text": " This is like my favorite.",
        "tokens": [
          51314,
          639,
          307,
          411,
          452,
          2954,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1062.48,
        "id": 330,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1060.48,
        "temperature": 0,
        "text": " So if you watched the stream yesterday.",
        "tokens": [
          51414,
          407,
          498,
          291,
          6337,
          264,
          4309,
          5186,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22381744384765626,
        "compression_ratio": 1.3641304347826086,
        "end": 1064.48,
        "id": 331,
        "no_speech_prob": 0.13471145927906036,
        "seek": 103948,
        "start": 1062.48,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          51514,
          1033,
          11,
          1797,
          322,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2226663633834484,
        "compression_ratio": 1.4378378378378378,
        "end": 1069.48,
        "id": 332,
        "no_speech_prob": 0.037316784262657166,
        "seek": 106448,
        "start": 1064.48,
        "temperature": 0,
        "text": " I need to, first of all, it's weird just that I'm here in front of it.",
        "tokens": [
          50364,
          286,
          643,
          281,
          11,
          700,
          295,
          439,
          11,
          309,
          311,
          3657,
          445,
          300,
          286,
          478,
          510,
          294,
          1868,
          295,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2226663633834484,
        "compression_ratio": 1.4378378378378378,
        "end": 1075.48,
        "id": 333,
        "no_speech_prob": 0.037316784262657166,
        "seek": 106448,
        "start": 1069.48,
        "temperature": 0,
        "text": " I need to give you the sound from the laptop.",
        "tokens": [
          50614,
          286,
          643,
          281,
          976,
          291,
          264,
          1626,
          490,
          264,
          10732,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2226663633834484,
        "compression_ratio": 1.4378378378378378,
        "end": 1080.48,
        "id": 334,
        "no_speech_prob": 0.037316784262657166,
        "seek": 106448,
        "start": 1075.48,
        "temperature": 0,
        "text": " Which is not going to come through unless I change.",
        "tokens": [
          50914,
          3013,
          307,
          406,
          516,
          281,
          808,
          807,
          5969,
          286,
          1319,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2226663633834484,
        "compression_ratio": 1.4378378378378378,
        "end": 1084.48,
        "id": 335,
        "no_speech_prob": 0.037316784262657166,
        "seek": 106448,
        "start": 1080.48,
        "temperature": 0,
        "text": " Oh, what a silly world we live in.",
        "tokens": [
          51164,
          876,
          11,
          437,
          257,
          11774,
          1002,
          321,
          1621,
          294,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2226663633834484,
        "compression_ratio": 1.4378378378378378,
        "end": 1089.48,
        "id": 336,
        "no_speech_prob": 0.037316784262657166,
        "seek": 106448,
        "start": 1084.48,
        "temperature": 0,
        "text": " If I do multi-output device, now you will get it.",
        "tokens": [
          51364,
          759,
          286,
          360,
          4825,
          12,
          346,
          2582,
          4302,
          11,
          586,
          291,
          486,
          483,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2226663633834484,
        "compression_ratio": 1.4378378378378378,
        "end": 1090.48,
        "id": 337,
        "no_speech_prob": 0.037316784262657166,
        "seek": 106448,
        "start": 1089.48,
        "temperature": 0,
        "text": " Okay, ready?",
        "tokens": [
          51614,
          1033,
          11,
          1919,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1101.48,
        "id": 338,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1090.48,
        "temperature": 0,
        "text": " I'm going to mute my microphone so I don't talk over this.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          24523,
          452,
          10952,
          370,
          286,
          500,
          380,
          751,
          670,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1103.48,
        "id": 339,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1101.48,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50914,
          21726,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1105.48,
        "id": 340,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1103.48,
        "temperature": 0,
        "text": " Color data should actually be colors.",
        "tokens": [
          51014,
          10458,
          1412,
          820,
          767,
          312,
          4577,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1106.48,
        "id": 341,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1105.48,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51114,
          21726,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1108.48,
        "id": 342,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1106.48,
        "temperature": 0,
        "text": " Color data based on the way I wrote the code.",
        "tokens": [
          51164,
          10458,
          1412,
          2361,
          322,
          264,
          636,
          286,
          4114,
          264,
          3089,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1109.48,
        "id": 343,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1108.48,
        "temperature": 0,
        "text": " Stop for a second.",
        "tokens": [
          51264,
          5535,
          337,
          257,
          1150,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1111.48,
        "id": 344,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1109.48,
        "temperature": 0,
        "text": " I need some errors here.",
        "tokens": [
          51314,
          286,
          643,
          512,
          13603,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3005528450012207,
        "compression_ratio": 1.4496644295302012,
        "end": 1112.48,
        "id": 345,
        "no_speech_prob": 0.13464289903640747,
        "seek": 109048,
        "start": 1111.48,
        "temperature": 0,
        "text": " Stop, stop, stop.",
        "tokens": [
          51414,
          5535,
          11,
          1590,
          11,
          1590,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.6937221050262451,
        "compression_ratio": 0.8596491228070176,
        "end": 1114.48,
        "id": 346,
        "no_speech_prob": 0.9335443377494812,
        "seek": 111248,
        "start": 1113.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.6937221050262451,
        "compression_ratio": 0.8596491228070176,
        "end": 1116.48,
        "id": 347,
        "no_speech_prob": 0.9335443377494812,
        "seek": 111248,
        "start": 1114.48,
        "temperature": 0,
        "text": " So apologies for that.",
        "tokens": [
          50464,
          407,
          34929,
          337,
          300,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.6937221050262451,
        "compression_ratio": 0.8596491228070176,
        "end": 1117.48,
        "id": 348,
        "no_speech_prob": 0.9335443377494812,
        "seek": 111248,
        "start": 1116.48,
        "temperature": 0,
        "text": " Now it's correcting.",
        "tokens": [
          50564,
          823,
          309,
          311,
          47032,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3133888813986707,
        "compression_ratio": 1.4475524475524475,
        "end": 1119.48,
        "id": 349,
        "no_speech_prob": 0.23852300643920898,
        "seek": 111748,
        "start": 1118.48,
        "temperature": 0,
        "text": " I made a bad mistake.",
        "tokens": [
          50414,
          286,
          1027,
          257,
          1578,
          6146,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3133888813986707,
        "compression_ratio": 1.4475524475524475,
        "end": 1122.48,
        "id": 350,
        "no_speech_prob": 0.23852300643920898,
        "seek": 111748,
        "start": 1119.48,
        "temperature": 0,
        "text": " I called the thing the wrong name.",
        "tokens": [
          50464,
          286,
          1219,
          264,
          551,
          264,
          2085,
          1315,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3133888813986707,
        "compression_ratio": 1.4475524475524475,
        "end": 1129.48,
        "id": 351,
        "no_speech_prob": 0.23852300643920898,
        "seek": 111748,
        "start": 1122.48,
        "temperature": 0,
        "text": " It's in my video that you're watching now.",
        "tokens": [
          50614,
          467,
          311,
          294,
          452,
          960,
          300,
          291,
          434,
          1976,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3133888813986707,
        "compression_ratio": 1.4475524475524475,
        "end": 1137.48,
        "id": 352,
        "no_speech_prob": 0.23852300643920898,
        "seek": 111748,
        "start": 1129.48,
        "temperature": 0,
        "text": " This time it's me just playing the ukulele in front of a green screen.",
        "tokens": [
          50964,
          639,
          565,
          309,
          311,
          385,
          445,
          2433,
          264,
          26769,
          2271,
          306,
          294,
          1868,
          295,
          257,
          3092,
          2568,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3133888813986707,
        "compression_ratio": 1.4475524475524475,
        "end": 1143.48,
        "id": 353,
        "no_speech_prob": 0.23852300643920898,
        "seek": 111748,
        "start": 1137.48,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51364,
          876,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3133888813986707,
        "compression_ratio": 1.4475524475524475,
        "end": 1144.48,
        "id": 354,
        "no_speech_prob": 0.23852300643920898,
        "seek": 111748,
        "start": 1143.48,
        "temperature": 0,
        "text": " Thank you, thank you, thank you.",
        "tokens": [
          51664,
          1044,
          291,
          11,
          1309,
          291,
          11,
          1309,
          291,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1152.48,
        "id": 355,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1148.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1153.48,
        "id": 356,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1152.48,
        "temperature": 0,
        "text": " So thank you for indulging me.",
        "tokens": [
          50614,
          407,
          1309,
          291,
          337,
          28626,
          3249,
          385,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1159.48,
        "id": 357,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1153.48,
        "temperature": 0,
        "text": " I really appreciated that Bruno took the time to remix all that insane footage from yesterday.",
        "tokens": [
          50664,
          286,
          534,
          17169,
          300,
          23046,
          1890,
          264,
          565,
          281,
          47788,
          439,
          300,
          10838,
          9556,
          490,
          5186,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1161.48,
        "id": 358,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1159.48,
        "temperature": 0,
        "text": " I was doing something more important, though.",
        "tokens": [
          50964,
          286,
          390,
          884,
          746,
          544,
          1021,
          11,
          1673,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1164.48,
        "id": 359,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1161.48,
        "temperature": 0,
        "text": " And I am going to go back here and just put the sound back here.",
        "tokens": [
          51064,
          400,
          286,
          669,
          516,
          281,
          352,
          646,
          510,
          293,
          445,
          829,
          264,
          1626,
          646,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1166.48,
        "id": 360,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1164.48,
        "temperature": 0,
        "text": " Then, ah, yes.",
        "tokens": [
          51214,
          1396,
          11,
          3716,
          11,
          2086,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1170.48,
        "id": 361,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1166.48,
        "temperature": 0,
        "text": " The surprising pattern behind color names around the world.",
        "tokens": [
          51314,
          440,
          8830,
          5102,
          2261,
          2017,
          5288,
          926,
          264,
          1002,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23000499476557193,
        "compression_ratio": 1.5294117647058822,
        "end": 1171.48,
        "id": 362,
        "no_speech_prob": 0.16875630617141724,
        "seek": 114748,
        "start": 1170.48,
        "temperature": 0,
        "text": " So let me find that.",
        "tokens": [
          51514,
          407,
          718,
          385,
          915,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3130270375145806,
        "compression_ratio": 1.1578947368421053,
        "end": 1178.48,
        "id": 363,
        "no_speech_prob": 0.1143055260181427,
        "seek": 117148,
        "start": 1172.48,
        "temperature": 0,
        "text": " The surprising pattern behind color names around the world.",
        "tokens": [
          50414,
          440,
          8830,
          5102,
          2261,
          2017,
          5288,
          926,
          264,
          1002,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3130270375145806,
        "compression_ratio": 1.1578947368421053,
        "end": 1183.48,
        "id": 364,
        "no_speech_prob": 0.1143055260181427,
        "seek": 117148,
        "start": 1178.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3130270375145806,
        "compression_ratio": 1.1578947368421053,
        "end": 1186.48,
        "id": 365,
        "no_speech_prob": 0.1143055260181427,
        "seek": 117148,
        "start": 1183.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50964,
          1057,
          558,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3130270375145806,
        "compression_ratio": 1.1578947368421053,
        "end": 1193.48,
        "id": 366,
        "no_speech_prob": 0.1143055260181427,
        "seek": 117148,
        "start": 1186.48,
        "temperature": 0,
        "text": " So coming back to the chat.",
        "tokens": [
          51114,
          407,
          1348,
          646,
          281,
          264,
          5081,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3130270375145806,
        "compression_ratio": 1.1578947368421053,
        "end": 1198.48,
        "id": 367,
        "no_speech_prob": 0.1143055260181427,
        "seek": 117148,
        "start": 1193.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1199.48,
        "id": 368,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1198.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1206.48,
        "id": 369,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1199.48,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50414,
          407,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1214.48,
        "id": 370,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1206.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50764,
          1057,
          558,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1215.48,
        "id": 371,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1214.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1217.48,
        "id": 372,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1215.48,
        "temperature": 0,
        "text": " I wore the same hoodie yesterday.",
        "tokens": [
          51214,
          286,
          13857,
          264,
          912,
          41191,
          5186,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1219.48,
        "id": 373,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1217.48,
        "temperature": 0,
        "text": " Have you not noticed that I just wear the same hoodie every day?",
        "tokens": [
          51314,
          3560,
          291,
          406,
          5694,
          300,
          286,
          445,
          3728,
          264,
          912,
          41191,
          633,
          786,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1221.48,
        "id": 374,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1219.48,
        "temperature": 0,
        "text": " I do have two of these, though.",
        "tokens": [
          51414,
          286,
          360,
          362,
          732,
          295,
          613,
          11,
          1673,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2492565663655599,
        "compression_ratio": 1.4606060606060607,
        "end": 1227.48,
        "id": 375,
        "no_speech_prob": 0.10816974937915802,
        "seek": 119848,
        "start": 1221.48,
        "temperature": 0,
        "text": " One says 2017 and this one says 2018 because this is the current ITP camp hoodie.",
        "tokens": [
          51514,
          1485,
          1619,
          6591,
          293,
          341,
          472,
          1619,
          6096,
          570,
          341,
          307,
          264,
          2190,
          6783,
          47,
          2255,
          41191,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1230.48,
        "id": 376,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1227.48,
        "temperature": 0,
        "text": " And I was wearing this one yesterday.",
        "tokens": [
          50364,
          400,
          286,
          390,
          4769,
          341,
          472,
          5186,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1234.48,
        "id": 377,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1230.48,
        "temperature": 0,
        "text": " I also have some emergency hoodies here.",
        "tokens": [
          50514,
          286,
          611,
          362,
          512,
          7473,
          1106,
          6087,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1235.48,
        "id": 378,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1234.48,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50714,
          2438,
          0,
          50764
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1240.48,
        "id": 379,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1235.48,
        "temperature": 0,
        "text": " Like a unicorn one.",
        "tokens": [
          50764,
          1743,
          257,
          28122,
          472,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1243.48,
        "id": 380,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1240.48,
        "temperature": 0,
        "text": " This is the old Coding Train branded hoodie.",
        "tokens": [
          51014,
          639,
          307,
          264,
          1331,
          383,
          8616,
          28029,
          38510,
          41191,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1245.48,
        "id": 381,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1243.48,
        "temperature": 0,
        "text": " There's a new one that's in the store now.",
        "tokens": [
          51164,
          821,
          311,
          257,
          777,
          472,
          300,
          311,
          294,
          264,
          3531,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1246.48,
        "id": 382,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1245.48,
        "temperature": 0,
        "text": " Anyway, I don't know.",
        "tokens": [
          51264,
          5684,
          11,
          286,
          500,
          380,
          458,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1247.48,
        "id": 383,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1246.48,
        "temperature": 0,
        "text": " Let's get started here.",
        "tokens": [
          51314,
          961,
          311,
          483,
          1409,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16854978449204389,
        "compression_ratio": 1.461111111111111,
        "end": 1254.48,
        "id": 384,
        "no_speech_prob": 0.011157283559441566,
        "seek": 122748,
        "start": 1247.48,
        "temperature": 0,
        "text": " Let's cycle these cameras.",
        "tokens": [
          51364,
          961,
          311,
          6586,
          613,
          8622,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2253110592181866,
        "compression_ratio": 1.314516129032258,
        "end": 1267.48,
        "id": 385,
        "no_speech_prob": 0.04083755984902382,
        "seek": 125448,
        "start": 1254.48,
        "temperature": 0,
        "text": " Definitely going to need to do some whiteboard erasing and using.",
        "tokens": [
          50364,
          12151,
          516,
          281,
          643,
          281,
          360,
          512,
          2418,
          3787,
          1189,
          3349,
          293,
          1228,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2253110592181866,
        "compression_ratio": 1.314516129032258,
        "end": 1274.48,
        "id": 386,
        "no_speech_prob": 0.04083755984902382,
        "seek": 125448,
        "start": 1267.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51014,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2253110592181866,
        "compression_ratio": 1.314516129032258,
        "end": 1277.48,
        "id": 387,
        "no_speech_prob": 0.04083755984902382,
        "seek": 125448,
        "start": 1274.48,
        "temperature": 0,
        "text": " Hello, I'm back again in my, I think it's the third.",
        "tokens": [
          51364,
          2425,
          11,
          286,
          478,
          646,
          797,
          294,
          452,
          11,
          286,
          519,
          309,
          311,
          264,
          2636,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2253110592181866,
        "compression_ratio": 1.314516129032258,
        "end": 1279.48,
        "id": 388,
        "no_speech_prob": 0.04083755984902382,
        "seek": 125448,
        "start": 1277.48,
        "temperature": 0,
        "text": " I can't keep track of this stuff.",
        "tokens": [
          51514,
          286,
          393,
          380,
          1066,
          2837,
          295,
          341,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.25100738030892833,
        "compression_ratio": 1.5985401459854014,
        "end": 1286.48,
        "id": 389,
        "no_speech_prob": 0.9517129063606262,
        "seek": 127948,
        "start": 1280.48,
        "temperature": 0,
        "text": " So building a classification example using a neural network and TensorFlow.js.",
        "tokens": [
          50414,
          407,
          2390,
          257,
          21538,
          1365,
          1228,
          257,
          18161,
          3209,
          293,
          37624,
          13,
          25530,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25100738030892833,
        "compression_ratio": 1.5985401459854014,
        "end": 1291.48,
        "id": 390,
        "no_speech_prob": 0.9517129063606262,
        "seek": 127948,
        "start": 1286.48,
        "temperature": 0,
        "text": " So where I last left off, which was actually in realtime yesterday, even though you might be watching these in sequence,",
        "tokens": [
          50714,
          407,
          689,
          286,
          1036,
          1411,
          766,
          11,
          597,
          390,
          767,
          294,
          957,
          3766,
          5186,
          11,
          754,
          1673,
          291,
          1062,
          312,
          1976,
          613,
          294,
          8310,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.25100738030892833,
        "compression_ratio": 1.5985401459854014,
        "end": 1296.48,
        "id": 391,
        "no_speech_prob": 0.9517129063606262,
        "seek": 127948,
        "start": 1291.48,
        "temperature": 0,
        "text": " I built this simple web app to crowdsource color classification.",
        "tokens": [
          50964,
          286,
          3094,
          341,
          2199,
          3670,
          724,
          281,
          26070,
          2948,
          2017,
          21538,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25100738030892833,
        "compression_ratio": 1.5985401459854014,
        "end": 1301.48,
        "id": 392,
        "no_speech_prob": 0.9517129063606262,
        "seek": 127948,
        "start": 1296.48,
        "temperature": 0,
        "text": " And the wonderful internet pull requested a bunch of nice features.",
        "tokens": [
          51214,
          400,
          264,
          3715,
          4705,
          2235,
          16436,
          257,
          3840,
          295,
          1481,
          4122,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.25100738030892833,
        "compression_ratio": 1.5985401459854014,
        "end": 1303.48,
        "id": 393,
        "no_speech_prob": 0.9517129063606262,
        "seek": 127948,
        "start": 1301.48,
        "temperature": 0,
        "text": " And so you can see this right here.",
        "tokens": [
          51464,
          400,
          370,
          291,
          393,
          536,
          341,
          558,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.25100738030892833,
        "compression_ratio": 1.5985401459854014,
        "end": 1305.48,
        "id": 394,
        "no_speech_prob": 0.9517129063606262,
        "seek": 127948,
        "start": 1303.48,
        "temperature": 0,
        "text": " I'm just going to say this one looks greenish.",
        "tokens": [
          51564,
          286,
          478,
          445,
          516,
          281,
          584,
          341,
          472,
          1542,
          3092,
          742,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25100738030892833,
        "compression_ratio": 1.5985401459854014,
        "end": 1306.48,
        "id": 395,
        "no_speech_prob": 0.9517129063606262,
        "seek": 127948,
        "start": 1305.48,
        "temperature": 0,
        "text": " And, oh, look at this.",
        "tokens": [
          51664,
          400,
          11,
          1954,
          11,
          574,
          412,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20181554363619897,
        "compression_ratio": 1.6289752650176679,
        "end": 1309.48,
        "id": 396,
        "no_speech_prob": 0.10817821323871613,
        "seek": 130648,
        "start": 1306.48,
        "temperature": 0,
        "text": " I'm just going to be grayish, reddish.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          312,
          10855,
          742,
          11,
          2182,
          40974,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20181554363619897,
        "compression_ratio": 1.6289752650176679,
        "end": 1311.48,
        "id": 397,
        "no_speech_prob": 0.10817821323871613,
        "seek": 130648,
        "start": 1309.48,
        "temperature": 0,
        "text": " So I'm adding some data.",
        "tokens": [
          50514,
          407,
          286,
          478,
          5127,
          512,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20181554363619897,
        "compression_ratio": 1.6289752650176679,
        "end": 1312.48,
        "id": 398,
        "no_speech_prob": 0.10817821323871613,
        "seek": 130648,
        "start": 1311.48,
        "temperature": 0,
        "text": " Purpleish.",
        "tokens": [
          50614,
          28483,
          742,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20181554363619897,
        "compression_ratio": 1.6289752650176679,
        "end": 1320.48,
        "id": 399,
        "no_speech_prob": 0.10817821323871613,
        "seek": 130648,
        "start": 1312.48,
        "temperature": 0,
        "text": " So thank you to all the people who you can check the GitHub repository in the commit history to see everyone who submitted a bunch of these changes to improve the visual design.",
        "tokens": [
          50664,
          407,
          1309,
          291,
          281,
          439,
          264,
          561,
          567,
          291,
          393,
          1520,
          264,
          23331,
          25841,
          294,
          264,
          5599,
          2503,
          281,
          536,
          1518,
          567,
          14405,
          257,
          3840,
          295,
          613,
          2962,
          281,
          3470,
          264,
          5056,
          1715,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20181554363619897,
        "compression_ratio": 1.6289752650176679,
        "end": 1330.48,
        "id": 400,
        "no_speech_prob": 0.10817821323871613,
        "seek": 130648,
        "start": 1320.48,
        "temperature": 0,
        "text": " Now, unfortunately, I made a little bit of a mistake, which is that, I don't know, a mistake, but I left the database, the Firebase database, completely open.",
        "tokens": [
          51064,
          823,
          11,
          7015,
          11,
          286,
          1027,
          257,
          707,
          857,
          295,
          257,
          6146,
          11,
          597,
          307,
          300,
          11,
          286,
          500,
          380,
          458,
          11,
          257,
          6146,
          11,
          457,
          286,
          1411,
          264,
          8149,
          11,
          264,
          35173,
          8149,
          11,
          2584,
          1269,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20181554363619897,
        "compression_ratio": 1.6289752650176679,
        "end": 1332.48,
        "id": 401,
        "no_speech_prob": 0.10817821323871613,
        "seek": 130648,
        "start": 1330.48,
        "temperature": 0,
        "text": " And I thought, why not?",
        "tokens": [
          51564,
          400,
          286,
          1194,
          11,
          983,
          406,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.20181554363619897,
        "compression_ratio": 1.6289752650176679,
        "end": 1333.48,
        "id": 402,
        "no_speech_prob": 0.10817821323871613,
        "seek": 130648,
        "start": 1332.48,
        "temperature": 0,
        "text": " It's going to be easiest.",
        "tokens": [
          51664,
          467,
          311,
          516,
          281,
          312,
          12889,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1337.48,
        "id": 403,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1333.48,
        "temperature": 0,
        "text": " I trust you, the viewing audience, to not mess with the database too much.",
        "tokens": [
          50364,
          286,
          3361,
          291,
          11,
          264,
          17480,
          4034,
          11,
          281,
          406,
          2082,
          365,
          264,
          8149,
          886,
          709,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1339.48,
        "id": 404,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1337.48,
        "temperature": 0,
        "text": " But it went off the rails a little bit.",
        "tokens": [
          50564,
          583,
          309,
          1437,
          766,
          264,
          27649,
          257,
          707,
          857,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1342.48,
        "id": 405,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1339.48,
        "temperature": 0,
        "text": " And so I want to thank.",
        "tokens": [
          50664,
          400,
          370,
          286,
          528,
          281,
          1309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1346.48,
        "id": 406,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1342.48,
        "temperature": 0,
        "text": " I'm totally going in the wrong order here.",
        "tokens": [
          50814,
          286,
          478,
          3879,
          516,
          294,
          264,
          2085,
          1668,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1347.48,
        "id": 407,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1346.48,
        "temperature": 0,
        "text": " Let me start over.",
        "tokens": [
          51014,
          961,
          385,
          722,
          670,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1349.48,
        "id": 408,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1347.48,
        "temperature": 0,
        "text": " But maybe it doesn't really matter.",
        "tokens": [
          51064,
          583,
          1310,
          309,
          1177,
          380,
          534,
          1871,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1354.48,
        "id": 409,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1349.48,
        "temperature": 0,
        "text": " I also didn't like that a sort of like color that I couldn't see came up.",
        "tokens": [
          51164,
          286,
          611,
          994,
          380,
          411,
          300,
          257,
          1333,
          295,
          411,
          2017,
          300,
          286,
          2809,
          380,
          536,
          1361,
          493,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1869275687944771,
        "compression_ratio": 1.5674418604651164,
        "end": 1362.48,
        "id": 410,
        "no_speech_prob": 0.3485873341560364,
        "seek": 133348,
        "start": 1354.48,
        "temperature": 0,
        "text": " So let me just start over.",
        "tokens": [
          51414,
          407,
          718,
          385,
          445,
          722,
          670,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1363.48,
        "id": 411,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1362.48,
        "temperature": 0,
        "text": " Choose one.",
        "tokens": [
          50364,
          21661,
          472,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1365.48,
        "id": 412,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1363.48,
        "temperature": 0,
        "text": " It's not super important in the end.",
        "tokens": [
          50414,
          467,
          311,
          406,
          1687,
          1021,
          294,
          264,
          917,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1366.48,
        "id": 413,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1365.48,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50514,
          286,
          500,
          380,
          458,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1367.48,
        "id": 414,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1366.48,
        "temperature": 0,
        "text": " Oh, are you all talking about Adam?",
        "tokens": [
          50564,
          876,
          11,
          366,
          291,
          439,
          1417,
          466,
          7938,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1369.48,
        "id": 415,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1367.48,
        "temperature": 0,
        "text": " You know, here's the thing.",
        "tokens": [
          50614,
          509,
          458,
          11,
          510,
          311,
          264,
          551,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1377.48,
        "id": 416,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1369.48,
        "temperature": 0,
        "text": " When people tell me to switch to a different editor because it's better or cooler or more current, that usually has the reverse effect on me.",
        "tokens": [
          50714,
          1133,
          561,
          980,
          385,
          281,
          3679,
          281,
          257,
          819,
          9839,
          570,
          309,
          311,
          1101,
          420,
          15566,
          420,
          544,
          2190,
          11,
          300,
          2673,
          575,
          264,
          9943,
          1802,
          322,
          385,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1378.48,
        "id": 417,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1377.48,
        "temperature": 0,
        "text": " I'm like, no, no, no.",
        "tokens": [
          51114,
          286,
          478,
          411,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1382.48,
        "id": 418,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1378.48,
        "temperature": 0,
        "text": " I'm going to stick with my editor because the point is it doesn't really matter so much.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          2897,
          365,
          452,
          9839,
          570,
          264,
          935,
          307,
          309,
          1177,
          380,
          534,
          1871,
          370,
          709,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1383.48,
        "id": 419,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1382.48,
        "temperature": 0,
        "text": " Although it kind of does matter.",
        "tokens": [
          51364,
          5780,
          309,
          733,
          295,
          775,
          1871,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1387.48,
        "id": 420,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1383.48,
        "temperature": 0,
        "text": " But let's not discuss.",
        "tokens": [
          51414,
          583,
          718,
          311,
          406,
          2248,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20157499958698014,
        "compression_ratio": 1.6159420289855073,
        "end": 1389.48,
        "id": 421,
        "no_speech_prob": 0.3665549159049988,
        "seek": 136248,
        "start": 1387.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51614,
          1057,
          558,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17293750429616392,
        "compression_ratio": 1.7440944881889764,
        "end": 1397.48,
        "id": 422,
        "no_speech_prob": 0.5154391527175903,
        "seek": 138948,
        "start": 1389.48,
        "temperature": 0,
        "text": " Hello, welcome to the third video in my build a classifier with p5.js and TensorFlow.js.",
        "tokens": [
          50364,
          2425,
          11,
          2928,
          281,
          264,
          2636,
          960,
          294,
          452,
          1322,
          257,
          1508,
          9902,
          365,
          280,
          20,
          13,
          25530,
          293,
          37624,
          13,
          25530,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17293750429616392,
        "compression_ratio": 1.7440944881889764,
        "end": 1398.48,
        "id": 423,
        "no_speech_prob": 0.5154391527175903,
        "seek": 138948,
        "start": 1397.48,
        "temperature": 0,
        "text": " And there's a neural network in there.",
        "tokens": [
          50764,
          400,
          456,
          311,
          257,
          18161,
          3209,
          294,
          456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17293750429616392,
        "compression_ratio": 1.7440944881889764,
        "end": 1401.48,
        "id": 424,
        "no_speech_prob": 0.5154391527175903,
        "seek": 138948,
        "start": 1398.48,
        "temperature": 0,
        "text": " So I'm really exploring this machine learning library TensorFlow.js.",
        "tokens": [
          50814,
          407,
          286,
          478,
          534,
          12736,
          341,
          3479,
          2539,
          6405,
          37624,
          13,
          25530,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17293750429616392,
        "compression_ratio": 1.7440944881889764,
        "end": 1412.48,
        "id": 425,
        "no_speech_prob": 0.5154391527175903,
        "seek": 138948,
        "start": 1401.48,
        "temperature": 0,
        "text": " And I wanted to come up with a creative example that shows the full classification process from collecting data, training, and then deploying a machine learning model.",
        "tokens": [
          50964,
          400,
          286,
          1415,
          281,
          808,
          493,
          365,
          257,
          5880,
          1365,
          300,
          3110,
          264,
          1577,
          21538,
          1399,
          490,
          12510,
          1412,
          11,
          3097,
          11,
          293,
          550,
          34198,
          257,
          3479,
          2539,
          2316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17293750429616392,
        "compression_ratio": 1.7440944881889764,
        "end": 1417.48,
        "id": 426,
        "no_speech_prob": 0.5154391527175903,
        "seek": 138948,
        "start": 1412.48,
        "temperature": 0,
        "text": " And so the example that I'm working with is this idea of color classification.",
        "tokens": [
          51514,
          400,
          370,
          264,
          1365,
          300,
          286,
          478,
          1364,
          365,
          307,
          341,
          1558,
          295,
          2017,
          21538,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1421.48,
        "id": 427,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1417.48,
        "temperature": 0,
        "text": " So I'm crowdsourcing this data from you, the viewing audience.",
        "tokens": [
          50364,
          407,
          286,
          478,
          26070,
          41849,
          341,
          1412,
          490,
          291,
          11,
          264,
          17480,
          4034,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1428.48,
        "id": 428,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1421.48,
        "temperature": 0,
        "text": " And if I look at this, so you might remember I built this little web app in the previous video, I think.",
        "tokens": [
          50564,
          400,
          498,
          286,
          574,
          412,
          341,
          11,
          370,
          291,
          1062,
          1604,
          286,
          3094,
          341,
          707,
          3670,
          724,
          294,
          264,
          3894,
          960,
          11,
          286,
          519,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1429.48,
        "id": 429,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1428.48,
        "temperature": 0,
        "text": " That was yesterday.",
        "tokens": [
          50914,
          663,
          390,
          5186,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1431.48,
        "id": 430,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1429.48,
        "temperature": 0,
        "text": " And then now it's today, 24 hours later.",
        "tokens": [
          50964,
          400,
          550,
          586,
          309,
          311,
          965,
          11,
          4022,
          2496,
          1780,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1432.48,
        "id": 431,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1431.48,
        "temperature": 0,
        "text": " It's been improved.",
        "tokens": [
          51064,
          467,
          311,
          668,
          9689,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1437.48,
        "id": 432,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1432.48,
        "temperature": 0,
        "text": " Thank you to the internet, the wonderful people who have pull requested various design fixes and updates.",
        "tokens": [
          51114,
          1044,
          291,
          281,
          264,
          4705,
          11,
          264,
          3715,
          561,
          567,
          362,
          2235,
          16436,
          3683,
          1715,
          32539,
          293,
          9205,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1440.48,
        "id": 433,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1437.48,
        "temperature": 0,
        "text": " You can check all that out on GitHub to see who the contributors were.",
        "tokens": [
          51364,
          509,
          393,
          1520,
          439,
          300,
          484,
          322,
          23331,
          281,
          536,
          567,
          264,
          45627,
          645,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1443.48,
        "id": 434,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1440.48,
        "temperature": 0,
        "text": " Now, let me add a few things here.",
        "tokens": [
          51514,
          823,
          11,
          718,
          385,
          909,
          257,
          1326,
          721,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.200919609943419,
        "compression_ratio": 1.5774193548387097,
        "end": 1446.48,
        "id": 435,
        "no_speech_prob": 0.19434241950511932,
        "seek": 141748,
        "start": 1443.48,
        "temperature": 0,
        "text": " Brown, that's kind of brown.",
        "tokens": [
          51664,
          8030,
          11,
          300,
          311,
          733,
          295,
          6292,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17569454645706437,
        "compression_ratio": 1.667870036101083,
        "end": 1448.48,
        "id": 436,
        "no_speech_prob": 0.00806162878870964,
        "seek": 144648,
        "start": 1446.48,
        "temperature": 0,
        "text": " That's purplish.",
        "tokens": [
          50364,
          663,
          311,
          1864,
          564,
          742,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17569454645706437,
        "compression_ratio": 1.667870036101083,
        "end": 1449.48,
        "id": 437,
        "no_speech_prob": 0.00806162878870964,
        "seek": 144648,
        "start": 1448.48,
        "temperature": 0,
        "text": " That's bluish.",
        "tokens": [
          50464,
          663,
          311,
          888,
          33786,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17569454645706437,
        "compression_ratio": 1.667870036101083,
        "end": 1456.48,
        "id": 438,
        "no_speech_prob": 0.00806162878870964,
        "seek": 144648,
        "start": 1449.48,
        "temperature": 0,
        "text": " Now, one thing I will mention, thank you to Bruno who brought this up in the patron Slack channel.",
        "tokens": [
          50514,
          823,
          11,
          472,
          551,
          286,
          486,
          2152,
          11,
          1309,
          291,
          281,
          23046,
          567,
          3038,
          341,
          493,
          294,
          264,
          21843,
          37211,
          2269,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17569454645706437,
        "compression_ratio": 1.667870036101083,
        "end": 1460.48,
        "id": 439,
        "no_speech_prob": 0.00806162878870964,
        "seek": 144648,
        "start": 1456.48,
        "temperature": 0,
        "text": " I sort of said yesterday, you know, I just want to pick a trivial data set.",
        "tokens": [
          50864,
          286,
          1333,
          295,
          848,
          5186,
          11,
          291,
          458,
          11,
          286,
          445,
          528,
          281,
          1888,
          257,
          26703,
          1412,
          992,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17569454645706437,
        "compression_ratio": 1.667870036101083,
        "end": 1467.48,
        "id": 440,
        "no_speech_prob": 0.00806162878870964,
        "seek": 144648,
        "start": 1460.48,
        "temperature": 0,
        "text": " I want to make something that's not, that has very little sort of like meaningfulness to it just to sort of demonstrate the whole process.",
        "tokens": [
          51064,
          286,
          528,
          281,
          652,
          746,
          300,
          311,
          406,
          11,
          300,
          575,
          588,
          707,
          1333,
          295,
          411,
          10995,
          1287,
          281,
          309,
          445,
          281,
          1333,
          295,
          11698,
          264,
          1379,
          1399,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17569454645706437,
        "compression_ratio": 1.667870036101083,
        "end": 1474.48,
        "id": 441,
        "no_speech_prob": 0.00806162878870964,
        "seek": 144648,
        "start": 1467.48,
        "temperature": 0,
        "text": " But there is something kind of interesting going on here in theory, which is that we're looking at human perception.",
        "tokens": [
          51414,
          583,
          456,
          307,
          746,
          733,
          295,
          1880,
          516,
          322,
          510,
          294,
          5261,
          11,
          597,
          307,
          300,
          321,
          434,
          1237,
          412,
          1952,
          12860,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18777282870545678,
        "compression_ratio": 1.7063492063492063,
        "end": 1482.48,
        "id": 442,
        "no_speech_prob": 0.22264139354228973,
        "seek": 147448,
        "start": 1474.48,
        "temperature": 0,
        "text": " And I'm not mathematically calculating, like labeling a color according to the RGB values.",
        "tokens": [
          50364,
          400,
          286,
          478,
          406,
          44003,
          28258,
          11,
          411,
          40244,
          257,
          2017,
          4650,
          281,
          264,
          31231,
          4190,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18777282870545678,
        "compression_ratio": 1.7063492063492063,
        "end": 1485.48,
        "id": 443,
        "no_speech_prob": 0.22264139354228973,
        "seek": 147448,
        "start": 1482.48,
        "temperature": 0,
        "text": " I'm asking you, the viewers, to tell me what you think a color is.",
        "tokens": [
          50764,
          286,
          478,
          3365,
          291,
          11,
          264,
          8499,
          11,
          281,
          980,
          385,
          437,
          291,
          519,
          257,
          2017,
          307,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18777282870545678,
        "compression_ratio": 1.7063492063492063,
        "end": 1488.48,
        "id": 444,
        "no_speech_prob": 0.22264139354228973,
        "seek": 147448,
        "start": 1485.48,
        "temperature": 0,
        "text": " And so there is a lot of interesting scientific research in this area.",
        "tokens": [
          50914,
          400,
          370,
          456,
          307,
          257,
          688,
          295,
          1880,
          8134,
          2132,
          294,
          341,
          1859,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18777282870545678,
        "compression_ratio": 1.7063492063492063,
        "end": 1498.48,
        "id": 445,
        "no_speech_prob": 0.22264139354228973,
        "seek": 147448,
        "start": 1488.48,
        "temperature": 0,
        "text": " And I'll reference this video that talks about Berkeley researchers and other research around the surprising pattern behind color names around the world.",
        "tokens": [
          51064,
          400,
          286,
          603,
          6408,
          341,
          960,
          300,
          6686,
          466,
          23684,
          10309,
          293,
          661,
          2132,
          926,
          264,
          8830,
          5102,
          2261,
          2017,
          5288,
          926,
          264,
          1002,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18777282870545678,
        "compression_ratio": 1.7063492063492063,
        "end": 1500.48,
        "id": 446,
        "no_speech_prob": 0.22264139354228973,
        "seek": 147448,
        "start": 1498.48,
        "temperature": 0,
        "text": " So there's a lot there that you could dig into.",
        "tokens": [
          51564,
          407,
          456,
          311,
          257,
          688,
          456,
          300,
          291,
          727,
          2528,
          666,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1944160268764303,
        "compression_ratio": 1.6762295081967213,
        "end": 1504.48,
        "id": 447,
        "no_speech_prob": 0.10086866468191147,
        "seek": 150048,
        "start": 1500.48,
        "temperature": 0,
        "text": " So maybe there's more here than I might originally have thought.",
        "tokens": [
          50364,
          407,
          1310,
          456,
          311,
          544,
          510,
          813,
          286,
          1062,
          7993,
          362,
          1194,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1944160268764303,
        "compression_ratio": 1.6762295081967213,
        "end": 1511.48,
        "id": 448,
        "no_speech_prob": 0.10086866468191147,
        "seek": 150048,
        "start": 1504.48,
        "temperature": 0,
        "text": " The problem with what I built over here is that, you know, you're wonderful.",
        "tokens": [
          50564,
          440,
          1154,
          365,
          437,
          286,
          3094,
          670,
          510,
          307,
          300,
          11,
          291,
          458,
          11,
          291,
          434,
          3715,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1944160268764303,
        "compression_ratio": 1.6762295081967213,
        "end": 1517.48,
        "id": 449,
        "no_speech_prob": 0.10086866468191147,
        "seek": 150048,
        "start": 1511.48,
        "temperature": 0,
        "text": " I love all of you who watch these videos and leave me nice feedback, leave me critical feedback and all that sort of stuff.",
        "tokens": [
          50914,
          286,
          959,
          439,
          295,
          291,
          567,
          1159,
          613,
          2145,
          293,
          1856,
          385,
          1481,
          5824,
          11,
          1856,
          385,
          4924,
          5824,
          293,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1944160268764303,
        "compression_ratio": 1.6762295081967213,
        "end": 1523.48,
        "id": 450,
        "no_speech_prob": 0.10086866468191147,
        "seek": 150048,
        "start": 1517.48,
        "temperature": 0,
        "text": " But the database is a little bit off the rails because I just left the rules wide open.",
        "tokens": [
          51214,
          583,
          264,
          8149,
          307,
          257,
          707,
          857,
          766,
          264,
          27649,
          570,
          286,
          445,
          1411,
          264,
          4474,
          4874,
          1269,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1944160268764303,
        "compression_ratio": 1.6762295081967213,
        "end": 1526.48,
        "id": 451,
        "no_speech_prob": 0.10086866468191147,
        "seek": 150048,
        "start": 1523.48,
        "temperature": 0,
        "text": " Anybody can write and anybody can read to the database.",
        "tokens": [
          51514,
          19082,
          393,
          2464,
          293,
          4472,
          393,
          1401,
          281,
          264,
          8149,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21125768773696002,
        "compression_ratio": 1.5398230088495575,
        "end": 1543.48,
        "id": 452,
        "no_speech_prob": 0.03846244513988495,
        "seek": 152648,
        "start": 1527.48,
        "temperature": 0,
        "text": " And so, thankfully, Panzer on GitHub left a pull request analyzing the data and looking at kind of like, OK, well, there's a lot of stuff here that looks wrong.",
        "tokens": [
          50414,
          400,
          370,
          11,
          27352,
          11,
          45932,
          260,
          322,
          23331,
          1411,
          257,
          2235,
          5308,
          23663,
          264,
          1412,
          293,
          1237,
          412,
          733,
          295,
          411,
          11,
          2264,
          11,
          731,
          11,
          456,
          311,
          257,
          688,
          295,
          1507,
          510,
          300,
          1542,
          2085,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21125768773696002,
        "compression_ratio": 1.5398230088495575,
        "end": 1546.48,
        "id": 453,
        "no_speech_prob": 0.03846244513988495,
        "seek": 152648,
        "start": 1543.48,
        "temperature": 0,
        "text": " Maybe there were some bots that started classifying colors.",
        "tokens": [
          51214,
          2704,
          456,
          645,
          512,
          35410,
          300,
          1409,
          1508,
          5489,
          4577,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21125768773696002,
        "compression_ratio": 1.5398230088495575,
        "end": 1550.48,
        "id": 454,
        "no_speech_prob": 0.03846244513988495,
        "seek": 152648,
        "start": 1546.48,
        "temperature": 0,
        "text": " And so I wrote all these functions to analyze and filter the data.",
        "tokens": [
          51364,
          400,
          370,
          286,
          4114,
          439,
          613,
          6828,
          281,
          12477,
          293,
          6608,
          264,
          1412,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21125768773696002,
        "compression_ratio": 1.5398230088495575,
        "end": 1553.48,
        "id": 455,
        "no_speech_prob": 0.03846244513988495,
        "seek": 152648,
        "start": 1550.48,
        "temperature": 0,
        "text": " So I encourage you to check out this wonderful pull request.",
        "tokens": [
          51564,
          407,
          286,
          5373,
          291,
          281,
          1520,
          484,
          341,
          3715,
          2235,
          5308,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2362682342529297,
        "compression_ratio": 1.6367713004484306,
        "end": 1556.48,
        "id": 456,
        "no_speech_prob": 0.08755705505609512,
        "seek": 155348,
        "start": 1553.48,
        "temperature": 0,
        "text": " This pull request is now part of the repository.",
        "tokens": [
          50364,
          639,
          2235,
          5308,
          307,
          586,
          644,
          295,
          264,
          25841,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2362682342529297,
        "compression_ratio": 1.6367713004484306,
        "end": 1567.48,
        "id": 457,
        "no_speech_prob": 0.08755705505609512,
        "seek": 155348,
        "start": 1556.48,
        "temperature": 0,
        "text": " However, I took a slightly different approach, which is, and thanks to me, I am so me, who helped me with this, which is that I changed the rules.",
        "tokens": [
          50514,
          2908,
          11,
          286,
          1890,
          257,
          4748,
          819,
          3109,
          11,
          597,
          307,
          11,
          293,
          3231,
          281,
          385,
          11,
          286,
          669,
          370,
          385,
          11,
          567,
          4254,
          385,
          365,
          341,
          11,
          597,
          307,
          300,
          286,
          3105,
          264,
          4474,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2362682342529297,
        "compression_ratio": 1.6367713004484306,
        "end": 1572.48,
        "id": 458,
        "no_speech_prob": 0.08755705505609512,
        "seek": 155348,
        "start": 1567.48,
        "temperature": 0,
        "text": " So the rules yesterday were just basically read true, write true.",
        "tokens": [
          51064,
          407,
          264,
          4474,
          5186,
          645,
          445,
          1936,
          1401,
          2074,
          11,
          2464,
          2074,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2362682342529297,
        "compression_ratio": 1.6367713004484306,
        "end": 1574.48,
        "id": 459,
        "no_speech_prob": 0.08755705505609512,
        "seek": 155348,
        "start": 1572.48,
        "temperature": 0,
        "text": " These are the Firebase rules.",
        "tokens": [
          51314,
          1981,
          366,
          264,
          35173,
          4474,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2362682342529297,
        "compression_ratio": 1.6367713004484306,
        "end": 1579.48,
        "id": 460,
        "no_speech_prob": 0.08755705505609512,
        "seek": 155348,
        "start": 1574.48,
        "temperature": 0,
        "text": " And me, I am so me helped me look into how you could customize the rules.",
        "tokens": [
          51414,
          400,
          385,
          11,
          286,
          669,
          370,
          385,
          4254,
          385,
          574,
          666,
          577,
          291,
          727,
          19734,
          264,
          4474,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16597653198242188,
        "compression_ratio": 1.7925170068027212,
        "end": 1590.48,
        "id": 461,
        "no_speech_prob": 0.3106570839881897,
        "seek": 157948,
        "start": 1579.48,
        "temperature": 0,
        "text": " And the things that have been added to the rules now are we have some things to validate to make sure the RGB values being put in the database are actually numbers.",
        "tokens": [
          50364,
          400,
          264,
          721,
          300,
          362,
          668,
          3869,
          281,
          264,
          4474,
          586,
          366,
          321,
          362,
          512,
          721,
          281,
          29562,
          281,
          652,
          988,
          264,
          31231,
          4190,
          885,
          829,
          294,
          264,
          8149,
          366,
          767,
          3547,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16597653198242188,
        "compression_ratio": 1.7925170068027212,
        "end": 1591.48,
        "id": 462,
        "no_speech_prob": 0.3106570839881897,
        "seek": 157948,
        "start": 1590.48,
        "temperature": 0,
        "text": " So you can see how this looks here.",
        "tokens": [
          50914,
          407,
          291,
          393,
          536,
          577,
          341,
          1542,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16597653198242188,
        "compression_ratio": 1.7925170068027212,
        "end": 1594.48,
        "id": 463,
        "no_speech_prob": 0.3106570839881897,
        "seek": 157948,
        "start": 1591.48,
        "temperature": 0,
        "text": " New data is a number and it's between 0 and 255.",
        "tokens": [
          50964,
          1873,
          1412,
          307,
          257,
          1230,
          293,
          309,
          311,
          1296,
          1958,
          293,
          3552,
          20,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16597653198242188,
        "compression_ratio": 1.7925170068027212,
        "end": 1603.48,
        "id": 464,
        "no_speech_prob": 0.3106570839881897,
        "seek": 157948,
        "start": 1594.48,
        "temperature": 0,
        "text": " We have something to validate that the label, you know, one of the things that people put other words that weren't part of my set of classification labels into the database.",
        "tokens": [
          51114,
          492,
          362,
          746,
          281,
          29562,
          300,
          264,
          7645,
          11,
          291,
          458,
          11,
          472,
          295,
          264,
          721,
          300,
          561,
          829,
          661,
          2283,
          300,
          4999,
          380,
          644,
          295,
          452,
          992,
          295,
          21538,
          16949,
          666,
          264,
          8149,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16597653198242188,
        "compression_ratio": 1.7925170068027212,
        "end": 1608.48,
        "id": 465,
        "no_speech_prob": 0.3106570839881897,
        "seek": 157948,
        "start": 1603.48,
        "temperature": 0,
        "text": " So I have to check that it's a string and that the actual data's value matches this regular expression.",
        "tokens": [
          51564,
          407,
          286,
          362,
          281,
          1520,
          300,
          309,
          311,
          257,
          6798,
          293,
          300,
          264,
          3539,
          1412,
          311,
          2158,
          10676,
          341,
          3890,
          6114,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19784168620685955,
        "compression_ratio": 1.6886792452830188,
        "end": 1614.48,
        "id": 466,
        "no_speech_prob": 0.07263003289699554,
        "seek": 160848,
        "start": 1608.48,
        "temperature": 0,
        "text": " So if you've never seen regular expressions before, I do happen to have a video series about that that you could go watch.",
        "tokens": [
          50364,
          407,
          498,
          291,
          600,
          1128,
          1612,
          3890,
          15277,
          949,
          11,
          286,
          360,
          1051,
          281,
          362,
          257,
          960,
          2638,
          466,
          300,
          300,
          291,
          727,
          352,
          1159,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19784168620685955,
        "compression_ratio": 1.6886792452830188,
        "end": 1617.48,
        "id": 467,
        "no_speech_prob": 0.07263003289699554,
        "seek": 160848,
        "start": 1614.48,
        "temperature": 0,
        "text": " But this, you can see that it matches any of these dash-ish.",
        "tokens": [
          50664,
          583,
          341,
          11,
          291,
          393,
          536,
          300,
          309,
          10676,
          604,
          295,
          613,
          8240,
          12,
          742,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19784168620685955,
        "compression_ratio": 1.6886792452830188,
        "end": 1618.48,
        "id": 468,
        "no_speech_prob": 0.07263003289699554,
        "seek": 160848,
        "start": 1617.48,
        "temperature": 0,
        "text": " So that's protecting.",
        "tokens": [
          50814,
          407,
          300,
          311,
          12316,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19784168620685955,
        "compression_ratio": 1.6886792452830188,
        "end": 1622.48,
        "id": 469,
        "no_speech_prob": 0.07263003289699554,
        "seek": 160848,
        "start": 1618.48,
        "temperature": 0,
        "text": " And then authentication was turned on.",
        "tokens": [
          50864,
          400,
          550,
          26643,
          390,
          3574,
          322,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19784168620685955,
        "compression_ratio": 1.6886792452830188,
        "end": 1629.48,
        "id": 470,
        "no_speech_prob": 0.07263003289699554,
        "seek": 160848,
        "start": 1622.48,
        "temperature": 0,
        "text": " So what you don't see is that it's anonymous authentication, but you can only write if you've been authenticated.",
        "tokens": [
          51064,
          407,
          437,
          291,
          500,
          380,
          536,
          307,
          300,
          309,
          311,
          24932,
          26643,
          11,
          457,
          291,
          393,
          787,
          2464,
          498,
          291,
          600,
          668,
          9214,
          3587,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18052331391755524,
        "compression_ratio": 1.6979591836734693,
        "end": 1631.48,
        "id": 471,
        "no_speech_prob": 0.5350104570388794,
        "seek": 162948,
        "start": 1630.48,
        "temperature": 0,
        "text": " This way, it's anonymous.",
        "tokens": [
          50414,
          639,
          636,
          11,
          309,
          311,
          24932,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18052331391755524,
        "compression_ratio": 1.6979591836734693,
        "end": 1634.48,
        "id": 472,
        "no_speech_prob": 0.5350104570388794,
        "seek": 162948,
        "start": 1631.48,
        "temperature": 0,
        "text": " I can track every person or every entry.",
        "tokens": [
          50464,
          286,
          393,
          2837,
          633,
          954,
          420,
          633,
          8729,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18052331391755524,
        "compression_ratio": 1.6979591836734693,
        "end": 1641.48,
        "id": 473,
        "no_speech_prob": 0.5350104570388794,
        "seek": 162948,
        "start": 1634.48,
        "temperature": 0,
        "text": " It's not necessarily a person, but every entry from a particular IP address into the database with a unique ID.",
        "tokens": [
          50614,
          467,
          311,
          406,
          4725,
          257,
          954,
          11,
          457,
          633,
          8729,
          490,
          257,
          1729,
          8671,
          2985,
          666,
          264,
          8149,
          365,
          257,
          3845,
          7348,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18052331391755524,
        "compression_ratio": 1.6979591836734693,
        "end": 1647.48,
        "id": 474,
        "no_speech_prob": 0.5350104570388794,
        "seek": 162948,
        "start": 1641.48,
        "temperature": 0,
        "text": " So if I can see that there's a bot that's just flooding the database, I could either block it or just like clean that data out of it.",
        "tokens": [
          50964,
          407,
          498,
          286,
          393,
          536,
          300,
          456,
          311,
          257,
          10592,
          300,
          311,
          445,
          24132,
          264,
          8149,
          11,
          286,
          727,
          2139,
          3461,
          309,
          420,
          445,
          411,
          2541,
          300,
          1412,
          484,
          295,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18052331391755524,
        "compression_ratio": 1.6979591836734693,
        "end": 1649.48,
        "id": 475,
        "no_speech_prob": 0.5350104570388794,
        "seek": 162948,
        "start": 1647.48,
        "temperature": 0,
        "text": " So that's what I'm going to do in this video.",
        "tokens": [
          51264,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          341,
          960,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18052331391755524,
        "compression_ratio": 1.6979591836734693,
        "end": 1654.48,
        "id": 476,
        "no_speech_prob": 0.5350104570388794,
        "seek": 162948,
        "start": 1649.48,
        "temperature": 0,
        "text": " I'm going to use a similar approach to this pull request.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          764,
          257,
          2531,
          3109,
          281,
          341,
          2235,
          5308,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17218633798452523,
        "compression_ratio": 1.6160337552742616,
        "end": 1661.48,
        "id": 477,
        "no_speech_prob": 0.025563538074493408,
        "seek": 165448,
        "start": 1654.48,
        "temperature": 0,
        "text": " I'm going to actually read the data from the database, and then I'm going to analyze it and delete stuff if it seems like it's no good,",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          767,
          1401,
          264,
          1412,
          490,
          264,
          8149,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          12477,
          309,
          293,
          12097,
          1507,
          498,
          309,
          2544,
          411,
          309,
          311,
          572,
          665,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.17218633798452523,
        "compression_ratio": 1.6160337552742616,
        "end": 1667.48,
        "id": 478,
        "no_speech_prob": 0.025563538074493408,
        "seek": 165448,
        "start": 1661.48,
        "temperature": 0,
        "text": " and then download a JSON file that I'll then use in the TensorFlow.js example that I'm going to build.",
        "tokens": [
          50714,
          293,
          550,
          5484,
          257,
          31828,
          3991,
          300,
          286,
          603,
          550,
          764,
          294,
          264,
          37624,
          13,
          25530,
          1365,
          300,
          286,
          478,
          516,
          281,
          1322,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17218633798452523,
        "compression_ratio": 1.6160337552742616,
        "end": 1671.48,
        "id": 479,
        "no_speech_prob": 0.025563538074493408,
        "seek": 165448,
        "start": 1667.48,
        "temperature": 0,
        "text": " Did I just spend the whole video introducing this topic?",
        "tokens": [
          51014,
          2589,
          286,
          445,
          3496,
          264,
          1379,
          960,
          15424,
          341,
          4829,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.17218633798452523,
        "compression_ratio": 1.6160337552742616,
        "end": 1674.48,
        "id": 480,
        "no_speech_prob": 0.025563538074493408,
        "seek": 165448,
        "start": 1671.48,
        "temperature": 0,
        "text": " I think I might have, but I'm going to move on and keep going anyway.",
        "tokens": [
          51214,
          286,
          519,
          286,
          1062,
          362,
          11,
          457,
          286,
          478,
          516,
          281,
          1286,
          322,
          293,
          1066,
          516,
          4033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17218633798452523,
        "compression_ratio": 1.6160337552742616,
        "end": 1675.48,
        "id": 481,
        "no_speech_prob": 0.025563538074493408,
        "seek": 165448,
        "start": 1674.48,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          51364,
          31973,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17218633798452523,
        "compression_ratio": 1.6160337552742616,
        "end": 1681.48,
        "id": 482,
        "no_speech_prob": 0.025563538074493408,
        "seek": 165448,
        "start": 1679.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51614,
          1057,
          558,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1954274437644265,
        "compression_ratio": 1.556910569105691,
        "end": 1685.48,
        "id": 483,
        "no_speech_prob": 0.019717620685696602,
        "seek": 168148,
        "start": 1681.48,
        "temperature": 0,
        "text": " Please, please be nice to each other and don't argue about IDEs in the chat.",
        "tokens": [
          50364,
          2555,
          11,
          1767,
          312,
          1481,
          281,
          1184,
          661,
          293,
          500,
          380,
          9695,
          466,
          7348,
          20442,
          294,
          264,
          5081,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1954274437644265,
        "compression_ratio": 1.556910569105691,
        "end": 1692.48,
        "id": 484,
        "no_speech_prob": 0.019717620685696602,
        "seek": 168148,
        "start": 1685.48,
        "temperature": 0,
        "text": " Just for once, one day, could you just say like, your IDE is great and so is mine.",
        "tokens": [
          50564,
          1449,
          337,
          1564,
          11,
          472,
          786,
          11,
          727,
          291,
          445,
          584,
          411,
          11,
          428,
          40930,
          307,
          869,
          293,
          370,
          307,
          3892,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1954274437644265,
        "compression_ratio": 1.556910569105691,
        "end": 1696.48,
        "id": 485,
        "no_speech_prob": 0.019717620685696602,
        "seek": 168148,
        "start": 1692.48,
        "temperature": 0,
        "text": " Isn't it nice how we use two different ones and maybe we could learn from each other?",
        "tokens": [
          50914,
          6998,
          380,
          309,
          1481,
          577,
          321,
          764,
          732,
          819,
          2306,
          293,
          1310,
          321,
          727,
          1466,
          490,
          1184,
          661,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.1954274437644265,
        "compression_ratio": 1.556910569105691,
        "end": 1698.48,
        "id": 486,
        "no_speech_prob": 0.019717620685696602,
        "seek": 168148,
        "start": 1696.48,
        "temperature": 0,
        "text": " That could be a thing, right?",
        "tokens": [
          51114,
          663,
          727,
          312,
          257,
          551,
          11,
          558,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.1954274437644265,
        "compression_ratio": 1.556910569105691,
        "end": 1707.48,
        "id": 487,
        "no_speech_prob": 0.019717620685696602,
        "seek": 168148,
        "start": 1702.48,
        "temperature": 0,
        "text": " And of course, I forgot to reference this, which I wanted to do, but that's okay.",
        "tokens": [
          51414,
          400,
          295,
          1164,
          11,
          286,
          5298,
          281,
          6408,
          341,
          11,
          597,
          286,
          1415,
          281,
          360,
          11,
          457,
          300,
          311,
          1392,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1954274437644265,
        "compression_ratio": 1.556910569105691,
        "end": 1708.48,
        "id": 488,
        "no_speech_prob": 0.019717620685696602,
        "seek": 168148,
        "start": 1707.48,
        "temperature": 0,
        "text": " I will come back to that.",
        "tokens": [
          51664,
          286,
          486,
          808,
          646,
          281,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20897711240328276,
        "compression_ratio": 1.4901960784313726,
        "end": 1721.48,
        "id": 489,
        "no_speech_prob": 0.0034833529498428106,
        "seek": 170848,
        "start": 1709.48,
        "temperature": 0,
        "text": " The next thing I need to do is actually start writing the code to look at the data.",
        "tokens": [
          50414,
          440,
          958,
          551,
          286,
          643,
          281,
          360,
          307,
          767,
          722,
          3579,
          264,
          3089,
          281,
          574,
          412,
          264,
          1412,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20897711240328276,
        "compression_ratio": 1.4901960784313726,
        "end": 1723.48,
        "id": 490,
        "no_speech_prob": 0.0034833529498428106,
        "seek": 170848,
        "start": 1721.48,
        "temperature": 0,
        "text": " I should probably turn off.",
        "tokens": [
          51014,
          286,
          820,
          1391,
          1261,
          766,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20897711240328276,
        "compression_ratio": 1.4901960784313726,
        "end": 1728.48,
        "id": 491,
        "no_speech_prob": 0.0034833529498428106,
        "seek": 170848,
        "start": 1723.48,
        "temperature": 0,
        "text": " Now I should set the thing to false because I just don't want it to.",
        "tokens": [
          51114,
          823,
          286,
          820,
          992,
          264,
          551,
          281,
          7908,
          570,
          286,
          445,
          500,
          380,
          528,
          309,
          281,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20897711240328276,
        "compression_ratio": 1.4901960784313726,
        "end": 1730.48,
        "id": 492,
        "no_speech_prob": 0.0034833529498428106,
        "seek": 170848,
        "start": 1728.48,
        "temperature": 0,
        "text": " I think I'm going to set it to false right now.",
        "tokens": [
          51364,
          286,
          519,
          286,
          478,
          516,
          281,
          992,
          309,
          281,
          7908,
          558,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2666305639804938,
        "compression_ratio": 1.4529411764705882,
        "end": 1733.48,
        "id": 493,
        "no_speech_prob": 0.004755006171762943,
        "seek": 173048,
        "start": 1731.48,
        "temperature": 0,
        "text": " Just so.",
        "tokens": [
          50414,
          1449,
          370,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2666305639804938,
        "compression_ratio": 1.4529411764705882,
        "end": 1741.48,
        "id": 494,
        "no_speech_prob": 0.004755006171762943,
        "seek": 173048,
        "start": 1735.48,
        "temperature": 0,
        "text": " I'm just setting it to false so if you're watching this live, you currently can't submit any more entries.",
        "tokens": [
          50614,
          286,
          478,
          445,
          3287,
          309,
          281,
          7908,
          370,
          498,
          291,
          434,
          1976,
          341,
          1621,
          11,
          291,
          4362,
          393,
          380,
          10315,
          604,
          544,
          23041,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2666305639804938,
        "compression_ratio": 1.4529411764705882,
        "end": 1746.48,
        "id": 495,
        "no_speech_prob": 0.004755006171762943,
        "seek": 173048,
        "start": 1741.48,
        "temperature": 0,
        "text": " I just want to have it be fixed while I'm doing this.",
        "tokens": [
          50914,
          286,
          445,
          528,
          281,
          362,
          309,
          312,
          6806,
          1339,
          286,
          478,
          884,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2666305639804938,
        "compression_ratio": 1.4529411764705882,
        "end": 1748.48,
        "id": 496,
        "no_speech_prob": 0.004755006171762943,
        "seek": 173048,
        "start": 1746.48,
        "temperature": 0,
        "text": " And then this.",
        "tokens": [
          51164,
          400,
          550,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2666305639804938,
        "compression_ratio": 1.4529411764705882,
        "end": 1749.48,
        "id": 497,
        "no_speech_prob": 0.004755006171762943,
        "seek": 173048,
        "start": 1748.48,
        "temperature": 0,
        "text": " I can close this.",
        "tokens": [
          51264,
          286,
          393,
          1998,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2666305639804938,
        "compression_ratio": 1.4529411764705882,
        "end": 1751.48,
        "id": 498,
        "no_speech_prob": 0.004755006171762943,
        "seek": 173048,
        "start": 1749.48,
        "temperature": 0,
        "text": " Oh, I should leave Firebase open.",
        "tokens": [
          51314,
          876,
          11,
          286,
          820,
          1856,
          35173,
          1269,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2666305639804938,
        "compression_ratio": 1.4529411764705882,
        "end": 1755.48,
        "id": 499,
        "no_speech_prob": 0.004755006171762943,
        "seek": 173048,
        "start": 1754.48,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          51564,
          467,
          311,
          2489,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2378990026620718,
        "compression_ratio": 1.3020134228187918,
        "end": 1757.48,
        "id": 500,
        "no_speech_prob": 0.0002492304483894259,
        "seek": 175548,
        "start": 1756.48,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          50414,
          467,
          311,
          2489,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2378990026620718,
        "compression_ratio": 1.3020134228187918,
        "end": 1762.48,
        "id": 501,
        "no_speech_prob": 0.0002492304483894259,
        "seek": 175548,
        "start": 1759.48,
        "temperature": 0,
        "text": " And then this, I want this to say clean data.",
        "tokens": [
          50564,
          400,
          550,
          341,
          11,
          286,
          528,
          341,
          281,
          584,
          2541,
          1412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2378990026620718,
        "compression_ratio": 1.3020134228187918,
        "end": 1770.48,
        "id": 502,
        "no_speech_prob": 0.0002492304483894259,
        "seek": 175548,
        "start": 1767.48,
        "temperature": 0,
        "text": " Wow, the chat is so quiet today in this.",
        "tokens": [
          50964,
          3153,
          11,
          264,
          5081,
          307,
          370,
          5677,
          965,
          294,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2378990026620718,
        "compression_ratio": 1.3020134228187918,
        "end": 1775.48,
        "id": 503,
        "no_speech_prob": 0.0002492304483894259,
        "seek": 175548,
        "start": 1772.48,
        "temperature": 0,
        "text": " Thank you, Fuji, for repeating my words exactly.",
        "tokens": [
          51214,
          1044,
          291,
          11,
          38119,
          11,
          337,
          18617,
          452,
          2283,
          2293,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2378990026620718,
        "compression_ratio": 1.3020134228187918,
        "end": 1778.48,
        "id": 504,
        "no_speech_prob": 0.0002492304483894259,
        "seek": 175548,
        "start": 1777.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51464,
          1057,
          558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2378990026620718,
        "compression_ratio": 1.3020134228187918,
        "end": 1783.48,
        "id": 505,
        "no_speech_prob": 0.0002492304483894259,
        "seek": 175548,
        "start": 1779.48,
        "temperature": 0,
        "text": " So I think I'm ready to do this now.",
        "tokens": [
          51564,
          407,
          286,
          519,
          286,
          478,
          1919,
          281,
          360,
          341,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1788.48,
        "id": 506,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1786.48,
        "temperature": 0,
        "text": " Oh, shoot.",
        "tokens": [
          50414,
          876,
          11,
          3076,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1789.48,
        "id": 507,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1788.48,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50514,
          876,
          11,
          452,
          8387,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1790.48,
        "id": 508,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1789.48,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50564,
          821,
          321,
          352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1794.48,
        "id": 509,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1790.48,
        "temperature": 0,
        "text": " Before I dig into the code, let me just reference one more web page to you.",
        "tokens": [
          50614,
          4546,
          286,
          2528,
          666,
          264,
          3089,
          11,
          718,
          385,
          445,
          6408,
          472,
          544,
          3670,
          3028,
          281,
          291,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1797.48,
        "id": 510,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1794.48,
        "temperature": 0,
        "text": " I want to show you this is a project that's at the time of this recording.",
        "tokens": [
          50814,
          286,
          528,
          281,
          855,
          291,
          341,
          307,
          257,
          1716,
          300,
          311,
          412,
          264,
          565,
          295,
          341,
          6613,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1801.48,
        "id": 511,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1797.48,
        "temperature": 0,
        "text": " It hasn't technically been released yet, although you can find it at ml5js.org.",
        "tokens": [
          50964,
          467,
          6132,
          380,
          12120,
          668,
          4736,
          1939,
          11,
          4878,
          291,
          393,
          915,
          309,
          412,
          23271,
          20,
          25530,
          13,
          4646,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1802.48,
        "id": 512,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1801.48,
        "temperature": 0,
        "text": " And it probably has a link to it.",
        "tokens": [
          51164,
          400,
          309,
          1391,
          575,
          257,
          2113,
          281,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1803.48,
        "id": 513,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1802.48,
        "temperature": 0,
        "text": " But I want to show you this.",
        "tokens": [
          51214,
          583,
          286,
          528,
          281,
          855,
          291,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1805.48,
        "id": 514,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1803.48,
        "temperature": 0,
        "text": " This is a project that's been working for a while.",
        "tokens": [
          51264,
          639,
          307,
          257,
          1716,
          300,
          311,
          668,
          1364,
          337,
          257,
          1339,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1807.48,
        "id": 515,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1805.48,
        "temperature": 0,
        "text": " It's called the ML5JS.",
        "tokens": [
          51364,
          467,
          311,
          1219,
          264,
          220,
          12683,
          20,
          41,
          50,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1809.48,
        "id": 516,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1807.48,
        "temperature": 0,
        "text": " And it's a project that's been working for a while.",
        "tokens": [
          51464,
          400,
          309,
          311,
          257,
          1716,
          300,
          311,
          668,
          1364,
          337,
          257,
          1339,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.6353808403015136,
        "compression_ratio": 1.9768339768339769,
        "end": 1811.48,
        "id": 517,
        "no_speech_prob": 0.003706841031089425,
        "seek": 178548,
        "start": 1809.48,
        "temperature": 0,
        "text": " And it's a project that's been working for a while.",
        "tokens": [
          51564,
          400,
          309,
          311,
          257,
          1716,
          300,
          311,
          668,
          1364,
          337,
          257,
          1339,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1814.48,
        "id": 518,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1812.48,
        "temperature": 1,
        "text": " So it's called the ML5JS.",
        "tokens": [
          50414,
          220,
          6455,
          309,
          311,
          1219,
          264,
          21601,
          20,
          41,
          50,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1816.48,
        "id": 519,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1814.48,
        "temperature": 1,
        "text": " And it's a project that's been working for a while.",
        "tokens": [
          50514,
          400,
          309,
          311,
          257,
          1716,
          300,
          311,
          668,
          1364,
          337,
          257,
          1339,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1818.48,
        "id": 520,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1816.48,
        "temperature": 1,
        "text": " And it's entirely new to companies now",
        "tokens": [
          50614,
          400,
          309,
          311,
          7696,
          297,
          1023,
          281,
          3431,
          586,
          50714
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1822.48,
        "id": 521,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1818.48,
        "temperature": 1,
        "text": " and is nowhere near as plugged right now become this software.",
        "tokens": [
          50714,
          293,
          307,
          11159,
          2651,
          382,
          499,
          3562,
          292,
          558,
          586,
          1813,
          341,
          4722,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1826.48,
        "id": 522,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1822.48,
        "temperature": 1,
        "text": " And, of course, some companies are looking at making the market",
        "tokens": [
          50914,
          220,
          7828,
          67,
          11,
          295,
          1164,
          11,
          512,
          3431,
          366,
          1237,
          412,
          1455,
          264,
          2142,
          51114
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1828.48,
        "id": 523,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1826.48,
        "temperature": 1,
        "text": " more comparable to other productionized problems",
        "tokens": [
          51114,
          544,
          395,
          42012,
          281,
          661,
          447,
          40335,
          1602,
          2740,
          51214
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1830.48,
        "id": 524,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1828.48,
        "temperature": 1,
        "text": " and in some diplomatic areas.",
        "tokens": [
          51214,
          293,
          294,
          512,
          20053,
          2399,
          3179,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1833.48,
        "id": 525,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1830.48,
        "temperature": 1,
        "text": " So it's the project they're working on,",
        "tokens": [
          51314,
          407,
          309,
          311,
          264,
          447,
          2884,
          349,
          256,
          17230,
          434,
          261,
          1284,
          278,
          322,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1834.48,
        "id": 526,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1833.48,
        "temperature": 1,
        "text": " but I don't know which team.",
        "tokens": [
          51464,
          457,
          286,
          500,
          380,
          350,
          3785,
          597,
          1469,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1835.48,
        "id": 527,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1834.48,
        "temperature": 1,
        "text": " But they put it together.",
        "tokens": [
          51514,
          220,
          7835,
          436,
          829,
          309,
          1214,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1837.48,
        "id": 528,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1835.48,
        "temperature": 1,
        "text": " It's an minicomponent of their framework.",
        "tokens": [
          51564,
          467,
          311,
          364,
          923,
          299,
          8586,
          30365,
          295,
          641,
          21405,
          1023,
          1284,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -2.6030447823660716,
        "compression_ratio": 1.577922077922078,
        "end": 1839.48,
        "id": 529,
        "no_speech_prob": 0.5808897614479065,
        "seek": 181148,
        "start": 1837.48,
        "temperature": 1,
        "text": " It's a 제� książ ͡°",
        "tokens": [
          51664,
          467,
          311,
          257,
          23406,
          39311,
          40130,
          51764
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1841.48,
        "id": 530,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1839.48,
        "temperature": 0,
        "text": " I'm going to come back to this topic again and again",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          341,
          4829,
          797,
          293,
          797,
          50464
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1842.48,
        "id": 531,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1841.48,
        "temperature": 0,
        "text": " in my video tutorials.",
        "tokens": [
          50464,
          294,
          452,
          960,
          17616,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1843.48,
        "id": 532,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1842.48,
        "temperature": 0,
        "text": " But I would encourage you to check this out",
        "tokens": [
          50514,
          583,
          286,
          576,
          5373,
          291,
          281,
          1520,
          341,
          484,
          50564
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1844.48,
        "id": 533,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1843.48,
        "temperature": 0,
        "text": " and really think about it.",
        "tokens": [
          50564,
          293,
          534,
          519,
          466,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1847.48,
        "id": 534,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1844.48,
        "temperature": 0,
        "text": " One thing we could think about here is, number one,",
        "tokens": [
          50614,
          1485,
          551,
          321,
          727,
          519,
          466,
          510,
          307,
          11,
          1230,
          472,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1850.48,
        "id": 535,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1847.48,
        "temperature": 0,
        "text": " I'm building an example that requires people",
        "tokens": [
          50764,
          286,
          478,
          2390,
          364,
          1365,
          300,
          7029,
          561,
          50914
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1851.48,
        "id": 536,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1850.48,
        "temperature": 0,
        "text": " to see the colors.",
        "tokens": [
          50914,
          281,
          536,
          264,
          4577,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1854.48,
        "id": 537,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1851.48,
        "temperature": 0,
        "text": " So what about people who are colorblind, low vision,",
        "tokens": [
          50964,
          407,
          437,
          466,
          561,
          567,
          366,
          2017,
          47494,
          11,
          2295,
          5201,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1855.48,
        "id": 538,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1854.48,
        "temperature": 0,
        "text": " or blind?",
        "tokens": [
          51114,
          420,
          6865,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1857.48,
        "id": 539,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1855.48,
        "temperature": 0,
        "text": " That's something I really should be thoughtful about",
        "tokens": [
          51164,
          663,
          311,
          746,
          286,
          534,
          820,
          312,
          21566,
          466,
          51264
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1858.48,
        "id": 540,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1857.48,
        "temperature": 0,
        "text": " in this example.",
        "tokens": [
          51264,
          294,
          341,
          1365,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1860.48,
        "id": 541,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1858.48,
        "temperature": 0,
        "text": " How can I approach that?",
        "tokens": [
          51314,
          1012,
          393,
          286,
          3109,
          300,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1863.48,
        "id": 542,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1860.48,
        "temperature": 0,
        "text": " And then who's really able to participate",
        "tokens": [
          51414,
          400,
          550,
          567,
          311,
          534,
          1075,
          281,
          8197,
          51564
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1865.48,
        "id": 543,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1863.48,
        "temperature": 0,
        "text": " in tagging and submitting data?",
        "tokens": [
          51564,
          294,
          6162,
          3249,
          293,
          31836,
          1412,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.18461472458309597,
        "compression_ratio": 1.702970297029703,
        "end": 1866.48,
        "id": 544,
        "no_speech_prob": 0.20418749749660492,
        "seek": 183948,
        "start": 1865.48,
        "temperature": 0,
        "text": " Who's being left out?",
        "tokens": [
          51664,
          2102,
          311,
          885,
          1411,
          484,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1868.48,
        "id": 545,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1866.48,
        "temperature": 0,
        "text": " So I think the good news for me is",
        "tokens": [
          50364,
          407,
          286,
          519,
          264,
          665,
          2583,
          337,
          385,
          307,
          50464
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1870.48,
        "id": 546,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1868.48,
        "temperature": 0,
        "text": " that this is meant to be somewhat of a generic tutorial",
        "tokens": [
          50464,
          300,
          341,
          307,
          4140,
          281,
          312,
          8344,
          295,
          257,
          19577,
          7073,
          50564
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1873.48,
        "id": 547,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1870.48,
        "temperature": 0,
        "text": " and the data, wow, doesn't matter so much",
        "tokens": [
          50564,
          293,
          264,
          1412,
          11,
          6076,
          11,
          1177,
          380,
          1871,
          370,
          709,
          50714
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1876.48,
        "id": 548,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1873.48,
        "temperature": 0,
        "text": " if it's perfect, because I just want to show",
        "tokens": [
          50714,
          498,
          309,
          311,
          2176,
          11,
          570,
          286,
          445,
          528,
          281,
          855,
          50864
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1877.48,
        "id": 549,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1876.48,
        "temperature": 0,
        "text": " that whole process.",
        "tokens": [
          50864,
          300,
          1379,
          1399,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1879.48,
        "id": 550,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1877.48,
        "temperature": 0,
        "text": " But you then actually being a person",
        "tokens": [
          50914,
          583,
          291,
          550,
          767,
          885,
          257,
          954,
          51014
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1881.48,
        "id": 551,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1879.48,
        "temperature": 0,
        "text": " who might work with machine learning",
        "tokens": [
          51014,
          567,
          1062,
          589,
          365,
          3479,
          2539,
          51114
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1882.48,
        "id": 552,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1881.48,
        "temperature": 0,
        "text": " out in the real world,",
        "tokens": [
          51114,
          484,
          294,
          264,
          957,
          1002,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1886.48,
        "id": 553,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1882.48,
        "temperature": 0,
        "text": " you really want to be thoughtful about that data.",
        "tokens": [
          51164,
          291,
          534,
          528,
          281,
          312,
          21566,
          466,
          300,
          1412,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1889.48,
        "id": 554,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1886.48,
        "temperature": 0,
        "text": " And I hope that I can link to more resources about that",
        "tokens": [
          51364,
          400,
          286,
          1454,
          300,
          286,
          393,
          2113,
          281,
          544,
          3593,
          466,
          300,
          51514
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1891.48,
        "id": 555,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1889.48,
        "temperature": 0,
        "text": " and cover that more on this channel as well.",
        "tokens": [
          51514,
          293,
          2060,
          300,
          544,
          322,
          341,
          2269,
          382,
          731,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1809353298611111,
        "compression_ratio": 1.6885813148788926,
        "end": 1894.48,
        "id": 556,
        "no_speech_prob": 0.006796570029109716,
        "seek": 186648,
        "start": 1891.48,
        "temperature": 0,
        "text": " So all that aside, now I'm ready to dig in",
        "tokens": [
          51614,
          407,
          439,
          300,
          7359,
          11,
          586,
          286,
          478,
          1919,
          281,
          2528,
          294,
          51764
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1896.48,
        "id": 557,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1894.48,
        "temperature": 0,
        "text": " and look at the data and do the thing",
        "tokens": [
          50364,
          293,
          574,
          412,
          264,
          1412,
          293,
          360,
          264,
          551,
          50464
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1898.48,
        "id": 558,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1896.48,
        "temperature": 0,
        "text": " that's probably going to take me the next 24 hours",
        "tokens": [
          50464,
          300,
          311,
          1391,
          516,
          281,
          747,
          385,
          264,
          958,
          4022,
          2496,
          50564
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1900.48,
        "id": 559,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1898.48,
        "temperature": 0,
        "text": " or three days or three weeks,",
        "tokens": [
          50564,
          420,
          1045,
          1708,
          420,
          1045,
          3259,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1902.48,
        "id": 560,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1900.48,
        "temperature": 0,
        "text": " try to clean the data and make it usable for me.",
        "tokens": [
          50664,
          853,
          281,
          2541,
          264,
          1412,
          293,
          652,
          309,
          29975,
          337,
          385,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1906.48,
        "id": 561,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1902.48,
        "temperature": 0,
        "text": " So yeah, that's what I'm going to do.",
        "tokens": [
          50764,
          407,
          1338,
          11,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1909.48,
        "id": 562,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1906.48,
        "temperature": 0,
        "text": " Okay, so I have a client.",
        "tokens": [
          50964,
          1033,
          11,
          370,
          286,
          362,
          257,
          6423,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1910.48,
        "id": 563,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1909.48,
        "temperature": 0,
        "text": " I mean, I could do this.",
        "tokens": [
          51114,
          286,
          914,
          11,
          286,
          727,
          360,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1912.48,
        "id": 564,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1910.48,
        "temperature": 0,
        "text": " I could download the data directly from Firebase",
        "tokens": [
          51164,
          286,
          727,
          5484,
          264,
          1412,
          3838,
          490,
          35173,
          51264
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1914.48,
        "id": 565,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1912.48,
        "temperature": 0,
        "text": " and just put it in a Google Sheet to look at it.",
        "tokens": [
          51264,
          293,
          445,
          829,
          309,
          294,
          257,
          3329,
          1240,
          302,
          281,
          574,
          412,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1916.48,
        "id": 566,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1914.48,
        "temperature": 0,
        "text": " That might be useful.",
        "tokens": [
          51364,
          663,
          1062,
          312,
          4420,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1918.48,
        "id": 567,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1916.48,
        "temperature": 0,
        "text": " But what I'm going to do is I'm just going to actually",
        "tokens": [
          51464,
          583,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          767,
          51564
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1921.48,
        "id": 568,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1918.48,
        "temperature": 0,
        "text": " write a p5 sketch or just a JavaScript program",
        "tokens": [
          51564,
          2464,
          257,
          280,
          20,
          12325,
          420,
          445,
          257,
          15778,
          1461,
          51714
        ]
      },
      {
        "avg_logprob": -0.18156703624850004,
        "compression_ratio": 1.7719298245614035,
        "end": 1923.48,
        "id": 569,
        "no_speech_prob": 0.11594905704259872,
        "seek": 189448,
        "start": 1921.48,
        "temperature": 0,
        "text": " to look at the data first.",
        "tokens": [
          51714,
          281,
          574,
          412,
          264,
          1412,
          700,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1925.48,
        "id": 570,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1923.48,
        "temperature": 0,
        "text": " So I have this sketch.",
        "tokens": [
          50364,
          407,
          286,
          362,
          341,
          12325,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1927.48,
        "id": 571,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1925.48,
        "temperature": 0,
        "text": " All that's in it so far is just that connect to Firebase",
        "tokens": [
          50464,
          1057,
          300,
          311,
          294,
          309,
          370,
          1400,
          307,
          445,
          300,
          1745,
          281,
          35173,
          50564
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1929.48,
        "id": 572,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1927.48,
        "temperature": 0,
        "text": " and authenticate.",
        "tokens": [
          50564,
          293,
          9214,
          8700,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1931.48,
        "id": 573,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1929.48,
        "temperature": 0,
        "text": " So what I want to do is to retrieve data.",
        "tokens": [
          50664,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          281,
          30254,
          1412,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1937.48,
        "id": 574,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1931.48,
        "temperature": 0,
        "text": " I think I say something like database once, value,",
        "tokens": [
          50764,
          286,
          519,
          286,
          584,
          746,
          411,
          8149,
          1564,
          11,
          2158,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1940.48,
        "id": 575,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1937.48,
        "temperature": 0,
        "text": " and then I have a callback like got data.",
        "tokens": [
          51064,
          293,
          550,
          286,
          362,
          257,
          818,
          3207,
          411,
          658,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1944.48,
        "id": 576,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1940.48,
        "temperature": 0,
        "text": " I don't know if this is right.",
        "tokens": [
          51214,
          286,
          500,
          380,
          458,
          498,
          341,
          307,
          558,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1946.48,
        "id": 577,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1944.48,
        "temperature": 0,
        "text": " And by the way, I've learned that the JavaScript recently,",
        "tokens": [
          51414,
          400,
          538,
          264,
          636,
          11,
          286,
          600,
          3264,
          300,
          264,
          15778,
          3938,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.19968318080042932,
        "compression_ratio": 1.603305785123967,
        "end": 1949.48,
        "id": 578,
        "no_speech_prob": 0.001388505450449884,
        "seek": 192348,
        "start": 1946.48,
        "temperature": 0,
        "text": " the JavaScript convention, which is not how p5 necessarily works,",
        "tokens": [
          51514,
          264,
          15778,
          10286,
          11,
          597,
          307,
          406,
          577,
          280,
          20,
          4725,
          1985,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1953.48,
        "id": 579,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1949.48,
        "temperature": 0,
        "text": " is often the error is first as callback arguments",
        "tokens": [
          50364,
          307,
          2049,
          264,
          6713,
          307,
          700,
          382,
          818,
          3207,
          12869,
          50564
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1956.48,
        "id": 580,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1953.48,
        "temperature": 0,
        "text": " and then the results is second.",
        "tokens": [
          50564,
          293,
          550,
          264,
          3542,
          307,
          1150,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1957.48,
        "id": 581,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1956.48,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50714,
          286,
          500,
          380,
          458,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1960.48,
        "id": 582,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1957.48,
        "temperature": 0,
        "text": " I'm just speculating what the Firebase API might be like.",
        "tokens": [
          50764,
          286,
          478,
          445,
          1608,
          12162,
          437,
          264,
          35173,
          9362,
          1062,
          312,
          411,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1961.48,
        "id": 583,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1960.48,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50914,
          961,
          311,
          536,
          437,
          2314,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1963.48,
        "id": 584,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1961.48,
        "temperature": 0,
        "text": " Database once is not a function.",
        "tokens": [
          50964,
          40461,
          651,
          1564,
          307,
          406,
          257,
          2445,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1966.48,
        "id": 585,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1963.48,
        "temperature": 0,
        "text": " I probably need.ref and then I probably need like colors",
        "tokens": [
          51064,
          286,
          1391,
          643,
          2411,
          33115,
          293,
          550,
          286,
          1391,
          643,
          411,
          4577,
          51214
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1968.48,
        "id": 586,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1966.48,
        "temperature": 0,
        "text": " or something, right?",
        "tokens": [
          51214,
          420,
          746,
          11,
          558,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1970.48,
        "id": 587,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1968.48,
        "temperature": 0,
        "text": " It's probably something like this.",
        "tokens": [
          51314,
          467,
          311,
          1391,
          746,
          411,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1973.48,
        "id": 588,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1970.48,
        "temperature": 0,
        "text": " I could just go and look on the documentation.",
        "tokens": [
          51414,
          286,
          727,
          445,
          352,
          293,
          574,
          322,
          264,
          14333,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1975.48,
        "id": 589,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1973.48,
        "temperature": 0,
        "text": " I also have this Firebase tutorial.",
        "tokens": [
          51564,
          286,
          611,
          362,
          341,
          35173,
          7073,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15223345947265626,
        "compression_ratio": 1.702290076335878,
        "end": 1978.48,
        "id": 590,
        "no_speech_prob": 0.03846418112516403,
        "seek": 194948,
        "start": 1975.48,
        "temperature": 0,
        "text": " Oh, yeah, I need the database reference",
        "tokens": [
          51664,
          876,
          11,
          1338,
          11,
          286,
          643,
          264,
          8149,
          6408,
          51814
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 1983.48,
        "id": 591,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1978.48,
        "temperature": 0,
        "text": " and then in my tutorial I say.on, but really, oh, got one",
        "tokens": [
          50364,
          293,
          550,
          294,
          452,
          7073,
          286,
          584,
          2411,
          266,
          11,
          457,
          534,
          11,
          1954,
          11,
          658,
          472,
          50614
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 1984.48,
        "id": 592,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1983.48,
        "temperature": 0,
        "text": " and got error data.",
        "tokens": [
          50614,
          293,
          658,
          6713,
          1412,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 1985.48,
        "id": 593,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1984.48,
        "temperature": 0,
        "text": " So maybe there's two callbacks.",
        "tokens": [
          50664,
          407,
          1310,
          456,
          311,
          732,
          818,
          17758,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 1986.48,
        "id": 594,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1985.48,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50714,
          2102,
          3255,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 1987.48,
        "id": 595,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1986.48,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50764,
          2102,
          3255,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 1991.48,
        "id": 596,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1987.48,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          50814,
          961,
          311,
          360,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 1996.48,
        "id": 597,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1991.48,
        "temperature": 0,
        "text": " Let ref equal database ref colors",
        "tokens": [
          51014,
          961,
          1895,
          2681,
          8149,
          1895,
          4577,
          51264
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 2000.48,
        "id": 598,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 1996.48,
        "temperature": 0,
        "text": " and then let's say ref once value got data",
        "tokens": [
          51264,
          293,
          550,
          718,
          311,
          584,
          1895,
          1564,
          2158,
          658,
          1412,
          51464
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 2005.48,
        "id": 599,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 2000.48,
        "temperature": 0,
        "text": " and let's look and see what comes back.",
        "tokens": [
          51464,
          293,
          718,
          311,
          574,
          293,
          536,
          437,
          1487,
          646,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20540249347686768,
        "compression_ratio": 1.5628415300546448,
        "end": 2007.48,
        "id": 600,
        "no_speech_prob": 0.00027372108888812363,
        "seek": 197848,
        "start": 2005.48,
        "temperature": 0,
        "text": " Let's go back to here.",
        "tokens": [
          51714,
          961,
          311,
          352,
          646,
          281,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2011.48,
        "id": 601,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2007.48,
        "temperature": 0,
        "text": " All right, something came back.",
        "tokens": [
          50364,
          1057,
          558,
          11,
          746,
          1361,
          646,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2012.48,
        "id": 602,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2011.48,
        "temperature": 0,
        "text": " No, nothing came back.",
        "tokens": [
          50564,
          883,
          11,
          1825,
          1361,
          646,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2018.48,
        "id": 603,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2012.48,
        "temperature": 0,
        "text": " 19.",
        "tokens": [
          50614,
          1294,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2019.48,
        "id": 604,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2018.48,
        "temperature": 0,
        "text": " Oh, no, 18.",
        "tokens": [
          50914,
          876,
          11,
          572,
          11,
          2443,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2023.48,
        "id": 605,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2019.48,
        "temperature": 0,
        "text": " This is...",
        "tokens": [
          50964,
          639,
          307,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2025.48,
        "id": 606,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2023.48,
        "temperature": 0,
        "text": " Hold on, time out a second.",
        "tokens": [
          51164,
          6962,
          322,
          11,
          565,
          484,
          257,
          1150,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2031.48,
        "id": 607,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2025.48,
        "temperature": 0,
        "text": " Take a break for a second.",
        "tokens": [
          51264,
          3664,
          257,
          1821,
          337,
          257,
          1150,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2452002661568778,
        "compression_ratio": 1.3714285714285714,
        "end": 2034.48,
        "id": 608,
        "no_speech_prob": 0.0036499612033367157,
        "seek": 200748,
        "start": 2031.48,
        "temperature": 0,
        "text": " I mean, like, now that I have consistent video editing,",
        "tokens": [
          51564,
          286,
          914,
          11,
          411,
          11,
          586,
          300,
          286,
          362,
          8398,
          960,
          10000,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2037.48,
        "id": 609,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2034.48,
        "temperature": 0,
        "text": " I really, I really, I truly have a very different world",
        "tokens": [
          50364,
          286,
          534,
          11,
          286,
          534,
          11,
          286,
          4908,
          362,
          257,
          588,
          819,
          1002,
          50514
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2040.48,
        "id": 610,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2037.48,
        "temperature": 0,
        "text": " which is like I just need to take a break and edit it out.",
        "tokens": [
          50514,
          597,
          307,
          411,
          286,
          445,
          643,
          281,
          747,
          257,
          1821,
          293,
          8129,
          309,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2042.48,
        "id": 611,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2040.48,
        "temperature": 0,
        "text": " I used to do that and never edited it out",
        "tokens": [
          50664,
          286,
          1143,
          281,
          360,
          300,
          293,
          1128,
          23016,
          309,
          484,
          50764
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2044.48,
        "id": 612,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2042.48,
        "temperature": 0,
        "text": " and I also couldn't take breaks.",
        "tokens": [
          50764,
          293,
          286,
          611,
          2809,
          380,
          747,
          9857,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2045.48,
        "id": 613,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2044.48,
        "temperature": 0,
        "text": " Not that I'm taking a break.",
        "tokens": [
          50864,
          1726,
          300,
          286,
          478,
          1940,
          257,
          1821,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2051.48,
        "id": 614,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2045.48,
        "temperature": 0,
        "text": " I just need like a mental break.",
        "tokens": [
          50914,
          286,
          445,
          643,
          411,
          257,
          4973,
          1821,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2053.48,
        "id": 615,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2051.48,
        "temperature": 0,
        "text": " All right, what's going on here?",
        "tokens": [
          51214,
          1057,
          558,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2056.48,
        "id": 616,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2053.48,
        "temperature": 0,
        "text": " Maybe I should go back and look at my actual example.",
        "tokens": [
          51314,
          2704,
          286,
          820,
          352,
          646,
          293,
          574,
          412,
          452,
          3539,
          1365,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2058.48,
        "id": 617,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2056.48,
        "temperature": 0,
        "text": " Got one, error data.",
        "tokens": [
          51464,
          5803,
          472,
          11,
          6713,
          1412,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2060.48,
        "id": 618,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2058.48,
        "temperature": 0,
        "text": " So let's...",
        "tokens": [
          51564,
          407,
          718,
          311,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.20804263270178505,
        "compression_ratio": 1.648,
        "end": 2063.48,
        "id": 619,
        "no_speech_prob": 0.0510806068778038,
        "seek": 203448,
        "start": 2060.48,
        "temperature": 0,
        "text": " Oh, that's a pointer to the data, right.",
        "tokens": [
          51664,
          876,
          11,
          300,
          311,
          257,
          23918,
          281,
          264,
          1412,
          11,
          558,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2069.48,
        "id": 620,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2063.48,
        "temperature": 0,
        "text": " So actually the data, so it actually is a separate callback for error.",
        "tokens": [
          50364,
          407,
          767,
          264,
          1412,
          11,
          370,
          309,
          767,
          307,
          257,
          4994,
          818,
          3207,
          337,
          6713,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2071.48,
        "id": 621,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2069.48,
        "temperature": 0,
        "text": " Looks like.",
        "tokens": [
          50664,
          10027,
          411,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2074.48,
        "id": 622,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2071.48,
        "temperature": 0,
        "text": " So I'm going to like not worry about the error callback right now.",
        "tokens": [
          50764,
          407,
          286,
          478,
          516,
          281,
          411,
          406,
          3292,
          466,
          264,
          6713,
          818,
          3207,
          558,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2076.48,
        "id": 623,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2074.48,
        "temperature": 0,
        "text": " I'm going to use got data",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          764,
          658,
          1412,
          51014
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2082.48,
        "id": 624,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2076.48,
        "temperature": 0,
        "text": " and then let's look at the results.",
        "tokens": [
          51014,
          293,
          550,
          718,
          311,
          574,
          412,
          264,
          3542,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2083.48,
        "id": 625,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2082.48,
        "temperature": 0,
        "text": " And so, yeah, this looks weird.",
        "tokens": [
          51314,
          400,
          370,
          11,
          1338,
          11,
          341,
          1542,
          3657,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2084.48,
        "id": 626,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2083.48,
        "temperature": 0,
        "text": " Like how could I possibly use this?",
        "tokens": [
          51364,
          1743,
          577,
          727,
          286,
          6264,
          764,
          341,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2087.48,
        "id": 627,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2084.48,
        "temperature": 0,
        "text": " So what you're actually getting back is like this pointer to the data.",
        "tokens": [
          51414,
          407,
          437,
          291,
          434,
          767,
          1242,
          646,
          307,
          411,
          341,
          23918,
          281,
          264,
          1412,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17370179120232077,
        "compression_ratio": 1.7458333333333333,
        "end": 2090.48,
        "id": 628,
        "no_speech_prob": 0.0011879008961841464,
        "seek": 206348,
        "start": 2087.48,
        "temperature": 0,
        "text": " You've got to call functions on it to actually look at what's there.",
        "tokens": [
          51564,
          509,
          600,
          658,
          281,
          818,
          6828,
          322,
          309,
          281,
          767,
          574,
          412,
          437,
          311,
          456,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2095.48,
        "id": 629,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2090.48,
        "temperature": 0,
        "text": " Presumably something like results.value is probably what the API is.",
        "tokens": [
          50364,
          2718,
          449,
          1188,
          746,
          411,
          3542,
          13,
          29155,
          307,
          1391,
          437,
          264,
          9362,
          307,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2097.48,
        "id": 630,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2095.48,
        "temperature": 0,
        "text": " No, it's not a function.",
        "tokens": [
          50614,
          883,
          11,
          309,
          311,
          406,
          257,
          2445,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2099.48,
        "id": 631,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2097.48,
        "temperature": 0,
        "text": " So I have to go back and look at my tutorial.",
        "tokens": [
          50714,
          407,
          286,
          362,
          281,
          352,
          646,
          293,
          574,
          412,
          452,
          7073,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2103.48,
        "id": 632,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2099.48,
        "temperature": 0,
        "text": ".val, let's try that.",
        "tokens": [
          50814,
          2411,
          3337,
          11,
          718,
          311,
          853,
          300,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2108.48,
        "id": 633,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2103.48,
        "temperature": 0,
        "text": " Let's try.val.",
        "tokens": [
          51014,
          961,
          311,
          853,
          2411,
          3337,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2110.48,
        "id": 634,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2108.48,
        "temperature": 0,
        "text": " And there we go, look at this.",
        "tokens": [
          51264,
          400,
          456,
          321,
          352,
          11,
          574,
          412,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2111.48,
        "id": 635,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2110.48,
        "temperature": 0,
        "text": " Oh, it's a lot of data.",
        "tokens": [
          51364,
          876,
          11,
          309,
          311,
          257,
          688,
          295,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2114.48,
        "id": 636,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2111.48,
        "temperature": 0,
        "text": " Boy, the console is not able to render this.",
        "tokens": [
          51414,
          9486,
          11,
          264,
          11076,
          307,
          406,
          1075,
          281,
          15529,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16026347151426512,
        "compression_ratio": 1.5121951219512195,
        "end": 2117.48,
        "id": 637,
        "no_speech_prob": 0.05184439942240715,
        "seek": 209048,
        "start": 2114.48,
        "temperature": 0,
        "text": " So now, is this actually an array?",
        "tokens": [
          51564,
          407,
          586,
          11,
          307,
          341,
          767,
          364,
          10225,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2120.48,
        "id": 638,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2117.48,
        "temperature": 0,
        "text": " Ah, it's just actually an object with all the data in it.",
        "tokens": [
          50364,
          2438,
          11,
          309,
          311,
          445,
          767,
          364,
          2657,
          365,
          439,
          264,
          1412,
          294,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2122.48,
        "id": 639,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2120.48,
        "temperature": 0,
        "text": " So I need to turn that into an array.",
        "tokens": [
          50514,
          407,
          286,
          643,
          281,
          1261,
          300,
          666,
          364,
          10225,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2125.48,
        "id": 640,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2122.48,
        "temperature": 0,
        "text": " Because I kind of want to loop through it.",
        "tokens": [
          50614,
          1436,
          286,
          733,
          295,
          528,
          281,
          6367,
          807,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2127.48,
        "id": 641,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2125.48,
        "temperature": 0,
        "text": " I wonder what the, oh, you know what I'll do?",
        "tokens": [
          50764,
          286,
          2441,
          437,
          264,
          11,
          1954,
          11,
          291,
          458,
          437,
          286,
          603,
          360,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2130.48,
        "id": 642,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2127.48,
        "temperature": 0,
        "text": " This is what I'm going to do.",
        "tokens": [
          50864,
          639,
          307,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2133.48,
        "id": 643,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2130.48,
        "temperature": 0,
        "text": " I am going to, so now I'm going to process the data.",
        "tokens": [
          51014,
          286,
          669,
          516,
          281,
          11,
          370,
          586,
          286,
          478,
          516,
          281,
          1399,
          264,
          1412,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2136.48,
        "id": 644,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2133.48,
        "temperature": 0,
        "text": " So first, let me just get all the keys.",
        "tokens": [
          51164,
          407,
          700,
          11,
          718,
          385,
          445,
          483,
          439,
          264,
          9317,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2138.48,
        "id": 645,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2136.48,
        "temperature": 0,
        "text": " So I can say objects.keys.",
        "tokens": [
          51314,
          407,
          286,
          393,
          584,
          6565,
          13,
          18847,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2143.48,
        "id": 646,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2138.48,
        "temperature": 0,
        "text": " So let me just say let data equal results.val.",
        "tokens": [
          51414,
          407,
          718,
          385,
          445,
          584,
          718,
          1412,
          2681,
          3542,
          13,
          3337,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17772922659278811,
        "compression_ratio": 1.6900826446280992,
        "end": 2145.48,
        "id": 647,
        "no_speech_prob": 0.038465164601802826,
        "seek": 211748,
        "start": 2143.48,
        "temperature": 0,
        "text": " Let's not console log that.",
        "tokens": [
          51664,
          961,
          311,
          406,
          11076,
          3565,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20386926862928603,
        "compression_ratio": 1.489795918367347,
        "end": 2148.48,
        "id": 648,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 214548,
        "start": 2145.48,
        "temperature": 0,
        "text": " Object.keys.data.",
        "tokens": [
          50364,
          24753,
          13,
          18847,
          13,
          67,
          3274,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20386926862928603,
        "compression_ratio": 1.489795918367347,
        "end": 2153.48,
        "id": 649,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 214548,
        "start": 2148.48,
        "temperature": 0,
        "text": " And then console.log keys.length.",
        "tokens": [
          50514,
          400,
          550,
          11076,
          13,
          4987,
          9317,
          13,
          45390,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20386926862928603,
        "compression_ratio": 1.489795918367347,
        "end": 2156.48,
        "id": 650,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 214548,
        "start": 2153.48,
        "temperature": 0,
        "text": " And I don't need this page anymore.",
        "tokens": [
          50764,
          400,
          286,
          500,
          380,
          643,
          341,
          3028,
          3602,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20386926862928603,
        "compression_ratio": 1.489795918367347,
        "end": 2160.48,
        "id": 651,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 214548,
        "start": 2156.48,
        "temperature": 0,
        "text": " I'm going back to here, clean data.",
        "tokens": [
          50914,
          286,
          478,
          516,
          646,
          281,
          510,
          11,
          2541,
          1412,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20386926862928603,
        "compression_ratio": 1.489795918367347,
        "end": 2165.48,
        "id": 652,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 214548,
        "start": 2160.48,
        "temperature": 0,
        "text": " So there's 5,902 entries into the database.",
        "tokens": [
          51114,
          407,
          456,
          311,
          1025,
          11,
          7771,
          17,
          23041,
          666,
          264,
          8149,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20386926862928603,
        "compression_ratio": 1.489795918367347,
        "end": 2168.48,
        "id": 653,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 214548,
        "start": 2165.48,
        "temperature": 0,
        "text": " This is never going to change, because just while I'm recording this video,",
        "tokens": [
          51364,
          639,
          307,
          1128,
          516,
          281,
          1319,
          11,
          570,
          445,
          1339,
          286,
          478,
          6613,
          341,
          960,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20386926862928603,
        "compression_ratio": 1.489795918367347,
        "end": 2172.48,
        "id": 654,
        "no_speech_prob": 0.0009253754396922886,
        "seek": 214548,
        "start": 2168.48,
        "temperature": 0,
        "text": " I shut off the ability to write to the database.",
        "tokens": [
          51514,
          286,
          5309,
          766,
          264,
          3485,
          281,
          2464,
          281,
          264,
          8149,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17265256863195919,
        "compression_ratio": 1.6376811594202898,
        "end": 2175.48,
        "id": 655,
        "no_speech_prob": 0.000273718498647213,
        "seek": 217248,
        "start": 2172.48,
        "temperature": 0,
        "text": " OK, so what we can actually start to do now is I could say",
        "tokens": [
          50364,
          2264,
          11,
          370,
          437,
          321,
          393,
          767,
          722,
          281,
          360,
          586,
          307,
          286,
          727,
          584,
          50514
        ]
      },
      {
        "avg_logprob": -0.17265256863195919,
        "compression_ratio": 1.6376811594202898,
        "end": 2179.48,
        "id": 656,
        "no_speech_prob": 0.000273718498647213,
        "seek": 217248,
        "start": 2175.48,
        "temperature": 0,
        "text": " for let key of keys.",
        "tokens": [
          50514,
          337,
          718,
          2141,
          295,
          9317,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17265256863195919,
        "compression_ratio": 1.6376811594202898,
        "end": 2186.48,
        "id": 657,
        "no_speech_prob": 0.000273718498647213,
        "seek": 217248,
        "start": 2179.48,
        "temperature": 0,
        "text": " And I could say let record equals data key.",
        "tokens": [
          50714,
          400,
          286,
          727,
          584,
          718,
          2136,
          6915,
          1412,
          2141,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17265256863195919,
        "compression_ratio": 1.6376811594202898,
        "end": 2189.48,
        "id": 658,
        "no_speech_prob": 0.000273718498647213,
        "seek": 217248,
        "start": 2186.48,
        "temperature": 0,
        "text": " And I could say console.log record.",
        "tokens": [
          51064,
          400,
          286,
          727,
          584,
          11076,
          13,
          4987,
          2136,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17265256863195919,
        "compression_ratio": 1.6376811594202898,
        "end": 2193.48,
        "id": 659,
        "no_speech_prob": 0.000273718498647213,
        "seek": 217248,
        "start": 2189.48,
        "temperature": 0,
        "text": " So this is going to log all 5,000 of those one at a time, I think.",
        "tokens": [
          51214,
          407,
          341,
          307,
          516,
          281,
          3565,
          439,
          1025,
          11,
          1360,
          295,
          729,
          472,
          412,
          257,
          565,
          11,
          286,
          519,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17265256863195919,
        "compression_ratio": 1.6376811594202898,
        "end": 2197.48,
        "id": 660,
        "no_speech_prob": 0.000273718498647213,
        "seek": 217248,
        "start": 2193.48,
        "temperature": 0,
        "text": " So I can see these are all, it's just logging every single data point.",
        "tokens": [
          51414,
          407,
          286,
          393,
          536,
          613,
          366,
          439,
          11,
          309,
          311,
          445,
          27991,
          633,
          2167,
          1412,
          935,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17265256863195919,
        "compression_ratio": 1.6376811594202898,
        "end": 2199.48,
        "id": 661,
        "no_speech_prob": 0.000273718498647213,
        "seek": 217248,
        "start": 2197.48,
        "temperature": 0,
        "text": " And we can see that for every single one,",
        "tokens": [
          51614,
          400,
          321,
          393,
          536,
          300,
          337,
          633,
          2167,
          472,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.18344499569128056,
        "compression_ratio": 1.6523809523809523,
        "end": 2203.48,
        "id": 662,
        "no_speech_prob": 0.37016060948371887,
        "seek": 219948,
        "start": 2199.48,
        "temperature": 0,
        "text": " there's an R, a G, and a B, the label, and then this user ID.",
        "tokens": [
          50364,
          456,
          311,
          364,
          497,
          11,
          257,
          460,
          11,
          293,
          257,
          363,
          11,
          264,
          7645,
          11,
          293,
          550,
          341,
          4195,
          7348,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18344499569128056,
        "compression_ratio": 1.6523809523809523,
        "end": 2208.48,
        "id": 663,
        "no_speech_prob": 0.37016060948371887,
        "seek": 219948,
        "start": 2203.48,
        "temperature": 0,
        "text": " So now I think there was, I'm watching the database this morning,",
        "tokens": [
          50564,
          407,
          586,
          286,
          519,
          456,
          390,
          11,
          286,
          478,
          1976,
          264,
          8149,
          341,
          2446,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.18344499569128056,
        "compression_ratio": 1.6523809523809523,
        "end": 2211.48,
        "id": 664,
        "no_speech_prob": 0.37016060948371887,
        "seek": 219948,
        "start": 2208.48,
        "temperature": 0,
        "text": " I think there was a bot that was posting to it.",
        "tokens": [
          50814,
          286,
          519,
          456,
          390,
          257,
          10592,
          300,
          390,
          15978,
          281,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18344499569128056,
        "compression_ratio": 1.6523809523809523,
        "end": 2214.48,
        "id": 665,
        "no_speech_prob": 0.37016060948371887,
        "seek": 219948,
        "start": 2211.48,
        "temperature": 0,
        "text": " So now it's possible it could be that there's just one person",
        "tokens": [
          50964,
          407,
          586,
          309,
          311,
          1944,
          309,
          727,
          312,
          300,
          456,
          311,
          445,
          472,
          954,
          51114
        ]
      },
      {
        "avg_logprob": -0.18344499569128056,
        "compression_ratio": 1.6523809523809523,
        "end": 2217.48,
        "id": 666,
        "no_speech_prob": 0.37016060948371887,
        "seek": 219948,
        "start": 2214.48,
        "temperature": 0,
        "text": " who actually clicked a lot of times.",
        "tokens": [
          51114,
          567,
          767,
          23370,
          257,
          688,
          295,
          1413,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18344499569128056,
        "compression_ratio": 1.6523809523809523,
        "end": 2220.48,
        "id": 667,
        "no_speech_prob": 0.37016060948371887,
        "seek": 219948,
        "start": 2217.48,
        "temperature": 0,
        "text": " But what I'm going to do right now to just examine the data a little bit",
        "tokens": [
          51264,
          583,
          437,
          286,
          478,
          516,
          281,
          360,
          558,
          586,
          281,
          445,
          17496,
          264,
          1412,
          257,
          707,
          857,
          51414
        ]
      },
      {
        "avg_logprob": -0.17535921584728154,
        "compression_ratio": 1.5141242937853108,
        "end": 2228.48,
        "id": 668,
        "no_speech_prob": 0.03846174106001854,
        "seek": 222048,
        "start": 2221.48,
        "temperature": 0,
        "text": " is I am going to look at the user, by user ID,",
        "tokens": [
          50414,
          307,
          286,
          669,
          516,
          281,
          574,
          412,
          264,
          4195,
          11,
          538,
          4195,
          7348,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17535921584728154,
        "compression_ratio": 1.5141242937853108,
        "end": 2231.48,
        "id": 669,
        "no_speech_prob": 0.03846174106001854,
        "seek": 222048,
        "start": 2228.48,
        "temperature": 0,
        "text": " and count up how many entries for each user ID.",
        "tokens": [
          50764,
          293,
          1207,
          493,
          577,
          867,
          23041,
          337,
          1184,
          4195,
          7348,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17535921584728154,
        "compression_ratio": 1.5141242937853108,
        "end": 2234.48,
        "id": 670,
        "no_speech_prob": 0.03846174106001854,
        "seek": 222048,
        "start": 2231.48,
        "temperature": 0,
        "text": " So I basically need to do something like a concordance.",
        "tokens": [
          50914,
          407,
          286,
          1936,
          643,
          281,
          360,
          746,
          411,
          257,
          1588,
          765,
          719,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17535921584728154,
        "compression_ratio": 1.5141242937853108,
        "end": 2242.48,
        "id": 671,
        "no_speech_prob": 0.03846174106001854,
        "seek": 222048,
        "start": 2234.48,
        "temperature": 0,
        "text": " So if I say UID, if I look at that,",
        "tokens": [
          51064,
          407,
          498,
          286,
          584,
          624,
          2777,
          11,
          498,
          286,
          574,
          412,
          300,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.17535921584728154,
        "compression_ratio": 1.5141242937853108,
        "end": 2245.48,
        "id": 672,
        "no_speech_prob": 0.03846174106001854,
        "seek": 222048,
        "start": 2242.48,
        "temperature": 0,
        "text": " we can see there's all the user IDs.",
        "tokens": [
          51464,
          321,
          393,
          536,
          456,
          311,
          439,
          264,
          4195,
          48212,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17535921584728154,
        "compression_ratio": 1.5141242937853108,
        "end": 2248.48,
        "id": 673,
        "no_speech_prob": 0.03846174106001854,
        "seek": 222048,
        "start": 2245.48,
        "temperature": 0,
        "text": " And what I want to do now is just associate,",
        "tokens": [
          51614,
          400,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          445,
          14644,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.20950813293457032,
        "compression_ratio": 1.3571428571428572,
        "end": 2253.48,
        "id": 674,
        "no_speech_prob": 0.016914406791329384,
        "seek": 224848,
        "start": 2248.48,
        "temperature": 0,
        "text": " so I'm going to just say user ID by count.",
        "tokens": [
          50364,
          370,
          286,
          478,
          516,
          281,
          445,
          584,
          4195,
          7348,
          538,
          1207,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20950813293457032,
        "compression_ratio": 1.3571428571428572,
        "end": 2260.48,
        "id": 675,
        "no_speech_prob": 0.016914406791329384,
        "seek": 224848,
        "start": 2253.48,
        "temperature": 0,
        "text": " And I'm going to say is an object.",
        "tokens": [
          50614,
          400,
          286,
          478,
          516,
          281,
          584,
          307,
          364,
          2657,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20950813293457032,
        "compression_ratio": 1.3571428571428572,
        "end": 2271.48,
        "id": 676,
        "no_speech_prob": 0.016914406791329384,
        "seek": 224848,
        "start": 2260.48,
        "temperature": 0,
        "text": " I'm sure there's all these higher order.",
        "tokens": [
          50964,
          286,
          478,
          988,
          456,
          311,
          439,
          613,
          2946,
          1668,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20950813293457032,
        "compression_ratio": 1.3571428571428572,
        "end": 2273.48,
        "id": 677,
        "no_speech_prob": 0.016914406791329384,
        "seek": 224848,
        "start": 2271.48,
        "temperature": 0,
        "text": " I'm sorry, I'm looking at the chat.",
        "tokens": [
          51514,
          286,
          478,
          2597,
          11,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20950813293457032,
        "compression_ratio": 1.3571428571428572,
        "end": 2276.48,
        "id": 678,
        "no_speech_prob": 0.016914406791329384,
        "seek": 224848,
        "start": 2273.48,
        "temperature": 0,
        "text": " Pause for a sec.",
        "tokens": [
          51614,
          31973,
          337,
          257,
          907,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2156010627746582,
        "compression_ratio": 1.3442622950819672,
        "end": 2283.48,
        "id": 679,
        "no_speech_prob": 0.025177637115120888,
        "seek": 227648,
        "start": 2276.48,
        "temperature": 0,
        "text": " Oh, I could have just done let record of data.",
        "tokens": [
          50364,
          876,
          11,
          286,
          727,
          362,
          445,
          1096,
          718,
          2136,
          295,
          1412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2156010627746582,
        "compression_ratio": 1.3442622950819672,
        "end": 2299.48,
        "id": 680,
        "no_speech_prob": 0.025177637115120888,
        "seek": 227648,
        "start": 2283.48,
        "temperature": 0,
        "text": " Yeah, the of works for an object, not just an array.",
        "tokens": [
          50714,
          865,
          11,
          264,
          295,
          1985,
          337,
          364,
          2657,
          11,
          406,
          445,
          364,
          10225,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2156010627746582,
        "compression_ratio": 1.3442622950819672,
        "end": 2302.48,
        "id": 681,
        "no_speech_prob": 0.025177637115120888,
        "seek": 227648,
        "start": 2299.48,
        "temperature": 0,
        "text": " Okay, interesting, interesting.",
        "tokens": [
          51514,
          1033,
          11,
          1880,
          11,
          1880,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2156010627746582,
        "compression_ratio": 1.3442622950819672,
        "end": 2304.48,
        "id": 682,
        "no_speech_prob": 0.025177637115120888,
        "seek": 227648,
        "start": 2302.48,
        "temperature": 0,
        "text": " Oh, pause for a second actually.",
        "tokens": [
          51664,
          876,
          11,
          10465,
          337,
          257,
          1150,
          767,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1748353330100455,
        "compression_ratio": 1.4666666666666666,
        "end": 2308.48,
        "id": 683,
        "no_speech_prob": 0.04146073758602142,
        "seek": 230448,
        "start": 2304.48,
        "temperature": 0,
        "text": " The chat just gave me some good feedback, which I actually,",
        "tokens": [
          50364,
          440,
          5081,
          445,
          2729,
          385,
          512,
          665,
          5824,
          11,
          597,
          286,
          767,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1748353330100455,
        "compression_ratio": 1.4666666666666666,
        "end": 2313.48,
        "id": 684,
        "no_speech_prob": 0.04146073758602142,
        "seek": 230448,
        "start": 2308.48,
        "temperature": 0,
        "text": " I guess the for of loop will work with an object, not just an array.",
        "tokens": [
          50564,
          286,
          2041,
          264,
          337,
          295,
          6367,
          486,
          589,
          365,
          364,
          2657,
          11,
          406,
          445,
          364,
          10225,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1748353330100455,
        "compression_ratio": 1.4666666666666666,
        "end": 2318.48,
        "id": 685,
        "no_speech_prob": 0.04146073758602142,
        "seek": 230448,
        "start": 2313.48,
        "temperature": 0,
        "text": " So I can actually just say let record of data.",
        "tokens": [
          50814,
          407,
          286,
          393,
          767,
          445,
          584,
          718,
          2136,
          295,
          1412,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1748353330100455,
        "compression_ratio": 1.4666666666666666,
        "end": 2321.48,
        "id": 686,
        "no_speech_prob": 0.04146073758602142,
        "seek": 230448,
        "start": 2318.48,
        "temperature": 0,
        "text": " And let me just do this.",
        "tokens": [
          51064,
          400,
          718,
          385,
          445,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1748353330100455,
        "compression_ratio": 1.4666666666666666,
        "end": 2322.48,
        "id": 687,
        "no_speech_prob": 0.04146073758602142,
        "seek": 230448,
        "start": 2321.48,
        "temperature": 0,
        "text": " No, that didn't work.",
        "tokens": [
          51214,
          883,
          11,
          300,
          994,
          380,
          589,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1748353330100455,
        "compression_ratio": 1.4666666666666666,
        "end": 2323.48,
        "id": 688,
        "no_speech_prob": 0.04146073758602142,
        "seek": 230448,
        "start": 2322.48,
        "temperature": 0,
        "text": " Data is not iterable.",
        "tokens": [
          51264,
          11888,
          307,
          406,
          17138,
          712,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1748353330100455,
        "compression_ratio": 1.4666666666666666,
        "end": 2330.48,
        "id": 689,
        "no_speech_prob": 0.04146073758602142,
        "seek": 230448,
        "start": 2323.48,
        "temperature": 0,
        "text": " Let record in data.",
        "tokens": [
          51314,
          961,
          2136,
          294,
          1412,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2336.48,
        "id": 690,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2330.48,
        "temperature": 0,
        "text": " All right, edit that out.",
        "tokens": [
          50364,
          1057,
          558,
          11,
          8129,
          300,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2338.48,
        "id": 691,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2336.48,
        "temperature": 0,
        "text": " Yeah, object on values.",
        "tokens": [
          50664,
          865,
          11,
          2657,
          322,
          4190,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2339.48,
        "id": 692,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2338.48,
        "temperature": 0,
        "text": " Yeah, it's fine.",
        "tokens": [
          50764,
          865,
          11,
          309,
          311,
          2489,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2341.48,
        "id": 693,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2339.48,
        "temperature": 0,
        "text": " I'm going to do it my way.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          360,
          309,
          452,
          636,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2342.48,
        "id": 694,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2341.48,
        "temperature": 0,
        "text": " I'm going to keep going.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          1066,
          516,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2345.48,
        "id": 695,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2342.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50964,
          1057,
          558,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2352.48,
        "id": 696,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2345.48,
        "temperature": 0,
        "text": " Me, I am to me, you've saved me so many times that you can do no wrong.",
        "tokens": [
          51114,
          1923,
          11,
          286,
          669,
          281,
          385,
          11,
          291,
          600,
          6624,
          385,
          370,
          867,
          1413,
          300,
          291,
          393,
          360,
          572,
          2085,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2312178554305111,
        "compression_ratio": 1.5,
        "end": 2356.48,
        "id": 697,
        "no_speech_prob": 0.41486290097236633,
        "seek": 233048,
        "start": 2352.48,
        "temperature": 0,
        "text": " All right, data record.",
        "tokens": [
          51464,
          1057,
          558,
          11,
          1412,
          2136,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1831574501929345,
        "compression_ratio": 1.5067567567567568,
        "end": 2360.48,
        "id": 698,
        "no_speech_prob": 0.007815823890268803,
        "seek": 235648,
        "start": 2356.48,
        "temperature": 0,
        "text": " Oh, right, I could, anyway.",
        "tokens": [
          50364,
          876,
          11,
          558,
          11,
          286,
          727,
          11,
          4033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1831574501929345,
        "compression_ratio": 1.5067567567567568,
        "end": 2364.48,
        "id": 699,
        "no_speech_prob": 0.007815823890268803,
        "seek": 235648,
        "start": 2360.48,
        "temperature": 0,
        "text": " I'm going to do it my way.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          360,
          309,
          452,
          636,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1831574501929345,
        "compression_ratio": 1.5067567567567568,
        "end": 2366.48,
        "id": 700,
        "no_speech_prob": 0.007815823890268803,
        "seek": 235648,
        "start": 2364.48,
        "temperature": 0,
        "text": " This is all about learning.",
        "tokens": [
          50764,
          639,
          307,
          439,
          466,
          2539,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1831574501929345,
        "compression_ratio": 1.5067567567567568,
        "end": 2375.48,
        "id": 701,
        "no_speech_prob": 0.007815823890268803,
        "seek": 235648,
        "start": 2366.48,
        "temperature": 0,
        "text": " I'll do it my way, you'll do it your way, we learn from each other.",
        "tokens": [
          50864,
          286,
          603,
          360,
          309,
          452,
          636,
          11,
          291,
          603,
          360,
          309,
          428,
          636,
          11,
          321,
          1466,
          490,
          1184,
          661,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1831574501929345,
        "compression_ratio": 1.5067567567567568,
        "end": 2383.48,
        "id": 702,
        "no_speech_prob": 0.007815823890268803,
        "seek": 235648,
        "start": 2375.48,
        "temperature": 0,
        "text": " Okay, so what I want to do is I want to say if user ID by count of that,",
        "tokens": [
          51314,
          1033,
          11,
          370,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          498,
          4195,
          7348,
          538,
          1207,
          295,
          300,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.16449842781856142,
        "compression_ratio": 1.4308943089430894,
        "end": 2388.48,
        "id": 703,
        "no_speech_prob": 0.016914421692490578,
        "seek": 238348,
        "start": 2383.48,
        "temperature": 0,
        "text": " so I need the ID, which is this.",
        "tokens": [
          50364,
          370,
          286,
          643,
          264,
          7348,
          11,
          597,
          307,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16449842781856142,
        "compression_ratio": 1.4308943089430894,
        "end": 2398.48,
        "id": 704,
        "no_speech_prob": 0.016914421692490578,
        "seek": 238348,
        "start": 2388.48,
        "temperature": 0,
        "text": " If user ID by count ID, it does not exist, then I want to set it to one.",
        "tokens": [
          50614,
          759,
          4195,
          7348,
          538,
          1207,
          7348,
          11,
          309,
          775,
          406,
          2514,
          11,
          550,
          286,
          528,
          281,
          992,
          309,
          281,
          472,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16449842781856142,
        "compression_ratio": 1.4308943089430894,
        "end": 2405.48,
        "id": 705,
        "no_speech_prob": 0.016914421692490578,
        "seek": 238348,
        "start": 2398.48,
        "temperature": 0,
        "text": " Otherwise, I want to increase it.",
        "tokens": [
          51114,
          10328,
          11,
          286,
          528,
          281,
          3488,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16449842781856142,
        "compression_ratio": 1.4308943089430894,
        "end": 2408.48,
        "id": 706,
        "no_speech_prob": 0.016914421692490578,
        "seek": 238348,
        "start": 2405.48,
        "temperature": 0,
        "text": " And then I want to console log that.",
        "tokens": [
          51464,
          400,
          550,
          286,
          528,
          281,
          11076,
          3565,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24672584948332413,
        "compression_ratio": 1.4145077720207253,
        "end": 2414.48,
        "id": 707,
        "no_speech_prob": 0.8517546653747559,
        "seek": 240848,
        "start": 2408.48,
        "temperature": 0,
        "text": " So let's look at this should give me all the user IDs.",
        "tokens": [
          50364,
          407,
          718,
          311,
          574,
          412,
          341,
          820,
          976,
          385,
          439,
          264,
          4195,
          48212,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24672584948332413,
        "compression_ratio": 1.4145077720207253,
        "end": 2419.48,
        "id": 708,
        "no_speech_prob": 0.8517546653747559,
        "seek": 240848,
        "start": 2414.48,
        "temperature": 0,
        "text": " By how many people, by how many entries they have.",
        "tokens": [
          50664,
          3146,
          577,
          867,
          561,
          11,
          538,
          577,
          867,
          23041,
          436,
          362,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24672584948332413,
        "compression_ratio": 1.4145077720207253,
        "end": 2428.48,
        "id": 709,
        "no_speech_prob": 0.8517546653747559,
        "seek": 240848,
        "start": 2419.48,
        "temperature": 0,
        "text": " So we can look 35, 33, 78, 147, 208, 189.",
        "tokens": [
          50914,
          407,
          321,
          393,
          574,
          6976,
          11,
          11816,
          11,
          26369,
          11,
          3499,
          22,
          11,
          945,
          23,
          11,
          2443,
          24,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24672584948332413,
        "compression_ratio": 1.4145077720207253,
        "end": 2429.48,
        "id": 710,
        "no_speech_prob": 0.8517546653747559,
        "seek": 240848,
        "start": 2428.48,
        "temperature": 0,
        "text": " What's the record here?",
        "tokens": [
          51364,
          708,
          311,
          264,
          2136,
          510,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.24672584948332413,
        "compression_ratio": 1.4145077720207253,
        "end": 2434.48,
        "id": 711,
        "no_speech_prob": 0.8517546653747559,
        "seek": 240848,
        "start": 2429.48,
        "temperature": 0,
        "text": " 201, there was something I've already forgot, 236.",
        "tokens": [
          51414,
          945,
          16,
          11,
          456,
          390,
          746,
          286,
          600,
          1217,
          5298,
          11,
          6673,
          21,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24672584948332413,
        "compression_ratio": 1.4145077720207253,
        "end": 2435.48,
        "id": 712,
        "no_speech_prob": 0.8517546653747559,
        "seek": 240848,
        "start": 2434.48,
        "temperature": 0,
        "text": " So what's this?",
        "tokens": [
          51664,
          407,
          437,
          311,
          341,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.24672584948332413,
        "compression_ratio": 1.4145077720207253,
        "end": 2437.48,
        "id": 713,
        "no_speech_prob": 0.8517546653747559,
        "seek": 240848,
        "start": 2435.48,
        "temperature": 0,
        "text": " Is there anything suspicious here?",
        "tokens": [
          51714,
          1119,
          456,
          1340,
          17931,
          510,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.15390911367204455,
        "compression_ratio": 1.1714285714285715,
        "end": 2441.48,
        "id": 714,
        "no_speech_prob": 0.037325043231248856,
        "seek": 243748,
        "start": 2437.48,
        "temperature": 0,
        "text": " That's the question.",
        "tokens": [
          50364,
          663,
          311,
          264,
          1168,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15390911367204455,
        "compression_ratio": 1.1714285714285715,
        "end": 2452.48,
        "id": 715,
        "no_speech_prob": 0.037325043231248856,
        "seek": 243748,
        "start": 2441.48,
        "temperature": 0,
        "text": " Let me think about this.",
        "tokens": [
          50564,
          961,
          385,
          519,
          466,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15390911367204455,
        "compression_ratio": 1.1714285714285715,
        "end": 2466.48,
        "id": 716,
        "no_speech_prob": 0.037325043231248856,
        "seek": 243748,
        "start": 2452.48,
        "temperature": 0,
        "text": " Do you remember the user ID of the thing that we detected was probably a bot?",
        "tokens": [
          51114,
          1144,
          291,
          1604,
          264,
          4195,
          7348,
          295,
          264,
          551,
          300,
          321,
          21896,
          390,
          1391,
          257,
          10592,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2469.48,
        "id": 717,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2466.48,
        "temperature": 0,
        "text": " I should sort these.",
        "tokens": [
          50364,
          286,
          820,
          1333,
          613,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2472.48,
        "id": 718,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2469.48,
        "temperature": 0,
        "text": " The problem is it's in an object, not an array.",
        "tokens": [
          50514,
          440,
          1154,
          307,
          309,
          311,
          294,
          364,
          2657,
          11,
          406,
          364,
          10225,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2476.48,
        "id": 719,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2472.48,
        "temperature": 0,
        "text": " It would be really easy to sort them if I made it into an array.",
        "tokens": [
          50664,
          467,
          576,
          312,
          534,
          1858,
          281,
          1333,
          552,
          498,
          286,
          1027,
          309,
          666,
          364,
          10225,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2481.48,
        "id": 720,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2476.48,
        "temperature": 0,
        "text": " I guess I could have the keys, I should sort them.",
        "tokens": [
          50864,
          286,
          2041,
          286,
          727,
          362,
          264,
          9317,
          11,
          286,
          820,
          1333,
          552,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2485.48,
        "id": 721,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2481.48,
        "temperature": 0,
        "text": " Let me sort them.",
        "tokens": [
          51114,
          961,
          385,
          1333,
          552,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2487.48,
        "id": 722,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2485.48,
        "temperature": 0,
        "text": " All right, it's probably worth me sorting this.",
        "tokens": [
          51314,
          1057,
          558,
          11,
          309,
          311,
          1391,
          3163,
          385,
          32411,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2490.48,
        "id": 723,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2487.48,
        "temperature": 0,
        "text": " This is why I should just put everything into a spreadsheet.",
        "tokens": [
          51414,
          639,
          307,
          983,
          286,
          820,
          445,
          829,
          1203,
          666,
          257,
          27733,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17268075294864987,
        "compression_ratio": 1.6778846153846154,
        "end": 2492.48,
        "id": 724,
        "no_speech_prob": 0.23932866752147675,
        "seek": 246648,
        "start": 2490.48,
        "temperature": 0,
        "text": " But I'm just going to sort it myself.",
        "tokens": [
          51564,
          583,
          286,
          478,
          445,
          516,
          281,
          1333,
          309,
          2059,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16011454508854792,
        "compression_ratio": 1.5,
        "end": 2496.48,
        "id": 725,
        "no_speech_prob": 0.37018781900405884,
        "seek": 249248,
        "start": 2493.48,
        "temperature": 0,
        "text": " In order to sort it, I want users.",
        "tokens": [
          50414,
          682,
          1668,
          281,
          1333,
          309,
          11,
          286,
          528,
          5022,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16011454508854792,
        "compression_ratio": 1.5,
        "end": 2499.48,
        "id": 726,
        "no_speech_prob": 0.37018781900405884,
        "seek": 249248,
        "start": 2496.48,
        "temperature": 0,
        "text": " I'm also going to have an array that I'm going to sort.",
        "tokens": [
          50564,
          286,
          478,
          611,
          516,
          281,
          362,
          364,
          10225,
          300,
          286,
          478,
          516,
          281,
          1333,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16011454508854792,
        "compression_ratio": 1.5,
        "end": 2504.48,
        "id": 727,
        "no_speech_prob": 0.37018781900405884,
        "seek": 249248,
        "start": 2499.48,
        "temperature": 0,
        "text": " If I find a new ID, I'll put that in the array.",
        "tokens": [
          50714,
          759,
          286,
          915,
          257,
          777,
          7348,
          11,
          286,
          603,
          829,
          300,
          294,
          264,
          10225,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16011454508854792,
        "compression_ratio": 1.5,
        "end": 2509.48,
        "id": 728,
        "no_speech_prob": 0.37018781900405884,
        "seek": 249248,
        "start": 2504.48,
        "temperature": 0,
        "text": " Then I want to say users.sort.",
        "tokens": [
          50964,
          1396,
          286,
          528,
          281,
          584,
          5022,
          13,
          82,
          477,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16011454508854792,
        "compression_ratio": 1.5,
        "end": 2516.48,
        "id": 729,
        "no_speech_prob": 0.37018781900405884,
        "seek": 249248,
        "start": 2509.48,
        "temperature": 0,
        "text": " Now I need a comparing function to compare two of them, A, B.",
        "tokens": [
          51214,
          823,
          286,
          643,
          257,
          15763,
          2445,
          281,
          6794,
          732,
          295,
          552,
          11,
          316,
          11,
          363,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19557639956474304,
        "compression_ratio": 1.4444444444444444,
        "end": 2531.48,
        "id": 730,
        "no_speech_prob": 0.10519721359014511,
        "seek": 251648,
        "start": 2516.48,
        "temperature": 0,
        "text": " I'm just going to say return user ID by count A minus user ID by count B.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          584,
          2736,
          4195,
          7348,
          538,
          1207,
          316,
          3175,
          4195,
          7348,
          538,
          1207,
          363,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19557639956474304,
        "compression_ratio": 1.4444444444444444,
        "end": 2536.48,
        "id": 731,
        "no_speech_prob": 0.10519721359014511,
        "seek": 251648,
        "start": 2531.48,
        "temperature": 0,
        "text": " That will sort the array.",
        "tokens": [
          51114,
          663,
          486,
          1333,
          264,
          10225,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19557639956474304,
        "compression_ratio": 1.4444444444444444,
        "end": 2539.48,
        "id": 732,
        "no_speech_prob": 0.10519721359014511,
        "seek": 251648,
        "start": 2536.48,
        "temperature": 0,
        "text": " Sorting probably makes a new array, I think.",
        "tokens": [
          51364,
          26149,
          278,
          1391,
          1669,
          257,
          777,
          10225,
          11,
          286,
          519,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19557639956474304,
        "compression_ratio": 1.4444444444444444,
        "end": 2540.48,
        "id": 733,
        "no_speech_prob": 0.10519721359014511,
        "seek": 251648,
        "start": 2539.48,
        "temperature": 0,
        "text": " I can't remember.",
        "tokens": [
          51514,
          286,
          393,
          380,
          1604,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19557639956474304,
        "compression_ratio": 1.4444444444444444,
        "end": 2544.48,
        "id": 734,
        "no_speech_prob": 0.10519721359014511,
        "seek": 251648,
        "start": 2540.48,
        "temperature": 0,
        "text": " Does it change the array or make a new array?",
        "tokens": [
          51564,
          4402,
          309,
          1319,
          264,
          10225,
          420,
          652,
          257,
          777,
          10225,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2571853523823752,
        "compression_ratio": 1.474820143884892,
        "end": 2546.48,
        "id": 735,
        "no_speech_prob": 0.04958274960517883,
        "seek": 254448,
        "start": 2544.48,
        "temperature": 0,
        "text": " I want to sort the users array.",
        "tokens": [
          50364,
          286,
          528,
          281,
          1333,
          264,
          5022,
          10225,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2571853523823752,
        "compression_ratio": 1.474820143884892,
        "end": 2553.48,
        "id": 736,
        "no_speech_prob": 0.04958274960517883,
        "seek": 254448,
        "start": 2546.48,
        "temperature": 0,
        "text": " Then I'm just going to do let ID of users.",
        "tokens": [
          50464,
          1396,
          286,
          478,
          445,
          516,
          281,
          360,
          718,
          7348,
          295,
          5022,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2571853523823752,
        "compression_ratio": 1.474820143884892,
        "end": 2555.48,
        "id": 737,
        "no_speech_prob": 0.04958274960517883,
        "seek": 254448,
        "start": 2553.48,
        "temperature": 0,
        "text": " I'm just going to iterate over the array.",
        "tokens": [
          50814,
          286,
          478,
          445,
          516,
          281,
          44497,
          670,
          264,
          10225,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2571853523823752,
        "compression_ratio": 1.474820143884892,
        "end": 2567.48,
        "id": 738,
        "no_speech_prob": 0.04958274960517883,
        "seek": 254448,
        "start": 2555.48,
        "temperature": 0,
        "text": " Console.log user ID plus user ID by count for that one.",
        "tokens": [
          50914,
          44152,
          13,
          4987,
          4195,
          7348,
          1804,
          4195,
          7348,
          538,
          1207,
          337,
          300,
          472,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2571853523823752,
        "compression_ratio": 1.474820143884892,
        "end": 2570.48,
        "id": 739,
        "no_speech_prob": 0.04958274960517883,
        "seek": 254448,
        "start": 2567.48,
        "temperature": 0,
        "text": " I know I'm kind of like, whoops.",
        "tokens": [
          51514,
          286,
          458,
          286,
          478,
          733,
          295,
          411,
          11,
          567,
          3370,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2573.48,
        "id": 740,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2570.48,
        "temperature": 0,
        "text": " This would be a good time for me to use those new string literals.",
        "tokens": [
          50364,
          639,
          576,
          312,
          257,
          665,
          565,
          337,
          385,
          281,
          764,
          729,
          777,
          6798,
          2733,
          1124,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2575.48,
        "id": 741,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2573.48,
        "temperature": 0,
        "text": " Someday I'll get to that.",
        "tokens": [
          50514,
          12297,
          16826,
          286,
          603,
          483,
          281,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2577.48,
        "id": 742,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2575.48,
        "temperature": 0,
        "text": " Let's take a look at this.",
        "tokens": [
          50614,
          961,
          311,
          747,
          257,
          574,
          412,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2579.48,
        "id": 743,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2577.48,
        "temperature": 0,
        "text": " What did I get wrong?",
        "tokens": [
          50714,
          708,
          630,
          286,
          483,
          2085,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2580.48,
        "id": 744,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2579.48,
        "temperature": 0,
        "text": " It looks like I did.",
        "tokens": [
          50814,
          467,
          1542,
          411,
          286,
          630,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2581.48,
        "id": 745,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2580.48,
        "temperature": 0,
        "text": " That worked.",
        "tokens": [
          50864,
          663,
          2732,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2582.48,
        "id": 746,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2581.48,
        "temperature": 0,
        "text": " Amazingly, that worked.",
        "tokens": [
          50914,
          14165,
          356,
          11,
          300,
          2732,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2584.48,
        "id": 747,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2582.48,
        "temperature": 0,
        "text": " We can see somebody just did one.",
        "tokens": [
          50964,
          492,
          393,
          536,
          2618,
          445,
          630,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2585.48,
        "id": 748,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2584.48,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51064,
          1044,
          291,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2589.48,
        "id": 749,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2585.48,
        "temperature": 0,
        "text": " Thank you, Noah who did one.",
        "tokens": [
          51114,
          1044,
          291,
          11,
          20895,
          567,
          630,
          472,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20722490713137007,
        "compression_ratio": 1.5275229357798166,
        "end": 2596.48,
        "id": 750,
        "no_speech_prob": 0.007695348933339119,
        "seek": 257048,
        "start": 2589.48,
        "temperature": 0,
        "text": " Then we can see here 236 entries from this particular user.",
        "tokens": [
          51314,
          1396,
          321,
          393,
          536,
          510,
          6673,
          21,
          23041,
          490,
          341,
          1729,
          4195,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.4673134803771973,
        "compression_ratio": 1.1168831168831168,
        "end": 2601.48,
        "id": 751,
        "no_speech_prob": 0.1520228534936905,
        "seek": 259648,
        "start": 2597.48,
        "temperature": 0,
        "text": " Sort is in place.",
        "tokens": [
          50414,
          26149,
          307,
          294,
          1081,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.4673134803771973,
        "compression_ratio": 1.1168831168831168,
        "end": 2605.48,
        "id": 752,
        "no_speech_prob": 0.1520228534936905,
        "seek": 259648,
        "start": 2601.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.4673134803771973,
        "compression_ratio": 1.1168831168831168,
        "end": 2612.48,
        "id": 753,
        "no_speech_prob": 0.1520228534936905,
        "seek": 259648,
        "start": 2605.48,
        "temperature": 0,
        "text": " Which one is the bot?",
        "tokens": [
          50814,
          3013,
          472,
          307,
          264,
          10592,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.4673134803771973,
        "compression_ratio": 1.1168831168831168,
        "end": 2614.48,
        "id": 754,
        "no_speech_prob": 0.1520228534936905,
        "seek": 259648,
        "start": 2612.48,
        "temperature": 0,
        "text": " FPQ.",
        "tokens": [
          51164,
          479,
          47,
          48,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.4673134803771973,
        "compression_ratio": 1.1168831168831168,
        "end": 2616.48,
        "id": 755,
        "no_speech_prob": 0.1520228534936905,
        "seek": 259648,
        "start": 2614.48,
        "temperature": 0,
        "text": " This one.",
        "tokens": [
          51264,
          639,
          472,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.4673134803771973,
        "compression_ratio": 1.1168831168831168,
        "end": 2618.48,
        "id": 756,
        "no_speech_prob": 0.1520228534936905,
        "seek": 259648,
        "start": 2616.48,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51364,
          14711,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.4673134803771973,
        "compression_ratio": 1.1168831168831168,
        "end": 2620.48,
        "id": 757,
        "no_speech_prob": 0.1520228534936905,
        "seek": 259648,
        "start": 2618.48,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51464,
          14711,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2623.48,
        "id": 758,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2621.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2625.48,
        "id": 759,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2623.48,
        "temperature": 0,
        "text": " Template strings.",
        "tokens": [
          50514,
          39563,
          473,
          13985,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2627.48,
        "id": 760,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2625.48,
        "temperature": 0,
        "text": " Not template literals.",
        "tokens": [
          50614,
          1726,
          12379,
          2733,
          1124,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2629.48,
        "id": 761,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2627.48,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50714,
          2438,
          0,
          50814
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2631.48,
        "id": 762,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2629.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50814,
          1057,
          558,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2636.48,
        "id": 763,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2631.48,
        "temperature": 0,
        "text": " These, by the way, are called template literals is what I meant.",
        "tokens": [
          50914,
          1981,
          11,
          538,
          264,
          636,
          11,
          366,
          1219,
          12379,
          2733,
          1124,
          307,
          437,
          286,
          4140,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2639.48,
        "id": 764,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2636.48,
        "temperature": 0,
        "text": " By the way, since I mentioned it, let's actually use it.",
        "tokens": [
          51164,
          3146,
          264,
          636,
          11,
          1670,
          286,
          2835,
          309,
          11,
          718,
          311,
          767,
          764,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2641.48,
        "id": 765,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2639.48,
        "temperature": 0,
        "text": " This is a new feature of ES6.",
        "tokens": [
          51314,
          639,
          307,
          257,
          777,
          4111,
          295,
          12564,
          21,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2643.48,
        "id": 766,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2641.48,
        "temperature": 0,
        "text": " I'm here.",
        "tokens": [
          51414,
          286,
          478,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.28161493189194625,
        "compression_ratio": 1.4320987654320987,
        "end": 2645.48,
        "id": 767,
        "no_speech_prob": 0.06465031206607819,
        "seek": 262048,
        "start": 2643.48,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51514,
          1545,
          406,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2647065682844682,
        "compression_ratio": 1.2542372881355932,
        "end": 2659.48,
        "id": 768,
        "no_speech_prob": 0.1259126216173172,
        "seek": 264548,
        "start": 2646.48,
        "temperature": 0,
        "text": " Where if I use back tick, I can create a string that's just with variables with this syntax, I believe.",
        "tokens": [
          50414,
          2305,
          498,
          286,
          764,
          646,
          5204,
          11,
          286,
          393,
          1884,
          257,
          6798,
          300,
          311,
          445,
          365,
          9102,
          365,
          341,
          28431,
          11,
          286,
          1697,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2647065682844682,
        "compression_ratio": 1.2542372881355932,
        "end": 2661.48,
        "id": 769,
        "no_speech_prob": 0.1259126216173172,
        "seek": 264548,
        "start": 2659.48,
        "temperature": 0,
        "text": " Does this go out here?",
        "tokens": [
          51064,
          4402,
          341,
          352,
          484,
          510,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.2647065682844682,
        "compression_ratio": 1.2542372881355932,
        "end": 2663.48,
        "id": 770,
        "no_speech_prob": 0.1259126216173172,
        "seek": 264548,
        "start": 2661.48,
        "temperature": 0,
        "text": " Yes, that goes there.",
        "tokens": [
          51164,
          1079,
          11,
          300,
          1709,
          456,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2607855739363705,
        "compression_ratio": 1.4827586206896552,
        "end": 2673.48,
        "id": 771,
        "no_speech_prob": 0.050323259085416794,
        "seek": 266348,
        "start": 2663.48,
        "temperature": 0,
        "text": " What this does is, in other words, I could say user submitted.",
        "tokens": [
          50364,
          708,
          341,
          775,
          307,
          11,
          294,
          661,
          2283,
          11,
          286,
          727,
          584,
          4195,
          14405,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2607855739363705,
        "compression_ratio": 1.4827586206896552,
        "end": 2675.48,
        "id": 772,
        "no_speech_prob": 0.050323259085416794,
        "seek": 266348,
        "start": 2673.48,
        "temperature": 0,
        "text": " I can just write a full string.",
        "tokens": [
          50864,
          286,
          393,
          445,
          2464,
          257,
          1577,
          6798,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2607855739363705,
        "compression_ratio": 1.4827586206896552,
        "end": 2682.48,
        "id": 773,
        "no_speech_prob": 0.050323259085416794,
        "seek": 266348,
        "start": 2675.48,
        "temperature": 0,
        "text": " Then basically anything that's in between these dollar sign and curly brackets is rendered as a variable value.",
        "tokens": [
          50964,
          1396,
          1936,
          1340,
          300,
          311,
          294,
          1296,
          613,
          7241,
          1465,
          293,
          32066,
          26179,
          307,
          28748,
          382,
          257,
          7006,
          2158,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2607855739363705,
        "compression_ratio": 1.4827586206896552,
        "end": 2690.48,
        "id": 774,
        "no_speech_prob": 0.050323259085416794,
        "seek": 266348,
        "start": 2682.48,
        "temperature": 0,
        "text": " Now if I run this, again, I don't know why that didn't.",
        "tokens": [
          51314,
          823,
          498,
          286,
          1190,
          341,
          11,
          797,
          11,
          286,
          500,
          380,
          458,
          983,
          300,
          994,
          380,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2607855739363705,
        "compression_ratio": 1.4827586206896552,
        "end": 2692.48,
        "id": 775,
        "no_speech_prob": 0.050323259085416794,
        "seek": 266348,
        "start": 2690.48,
        "temperature": 0,
        "text": " Yes, you can see now it has that full.",
        "tokens": [
          51714,
          1079,
          11,
          291,
          393,
          536,
          586,
          309,
          575,
          300,
          1577,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23599759126320863,
        "compression_ratio": 1.4923857868020305,
        "end": 2694.48,
        "id": 776,
        "no_speech_prob": 0.045347992330789566,
        "seek": 269248,
        "start": 2692.48,
        "temperature": 0,
        "text": " I kind of don't want all this extra stuff.",
        "tokens": [
          50364,
          286,
          733,
          295,
          500,
          380,
          528,
          439,
          341,
          2857,
          1507,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23599759126320863,
        "compression_ratio": 1.4923857868020305,
        "end": 2697.48,
        "id": 777,
        "no_speech_prob": 0.045347992330789566,
        "seek": 269248,
        "start": 2694.48,
        "temperature": 0,
        "text": " I'm just showing you that you can put together a string.",
        "tokens": [
          50464,
          286,
          478,
          445,
          4099,
          291,
          300,
          291,
          393,
          829,
          1214,
          257,
          6798,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23599759126320863,
        "compression_ratio": 1.4923857868020305,
        "end": 2699.48,
        "id": 778,
        "no_speech_prob": 0.045347992330789566,
        "seek": 269248,
        "start": 2697.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23599759126320863,
        "compression_ratio": 1.4923857868020305,
        "end": 2708.48,
        "id": 779,
        "no_speech_prob": 0.045347992330789566,
        "seek": 269248,
        "start": 2699.48,
        "temperature": 0,
        "text": " I happen to know, based on earlier research of the day and watching, that this particular user is a bot.",
        "tokens": [
          50714,
          286,
          1051,
          281,
          458,
          11,
          2361,
          322,
          3071,
          2132,
          295,
          264,
          786,
          293,
          1976,
          11,
          300,
          341,
          1729,
          4195,
          307,
          257,
          10592,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23599759126320863,
        "compression_ratio": 1.4923857868020305,
        "end": 2716.48,
        "id": 780,
        "no_speech_prob": 0.045347992330789566,
        "seek": 269248,
        "start": 2708.48,
        "temperature": 0,
        "text": " I am getting the suggestion from the chat to just discard anything that's over 100.",
        "tokens": [
          51164,
          286,
          669,
          1242,
          264,
          16541,
          490,
          264,
          5081,
          281,
          445,
          31597,
          1340,
          300,
          311,
          670,
          2319,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.27348555379839085,
        "compression_ratio": 1.3445945945945945,
        "end": 2719.48,
        "id": 781,
        "no_speech_prob": 0.11595213413238525,
        "seek": 271648,
        "start": 2717.48,
        "temperature": 0,
        "text": " It looks like this.",
        "tokens": [
          50414,
          467,
          1542,
          411,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.27348555379839085,
        "compression_ratio": 1.3445945945945945,
        "end": 2722.48,
        "id": 782,
        "no_speech_prob": 0.11595213413238525,
        "seek": 271648,
        "start": 2719.48,
        "temperature": 0,
        "text": " Those are ways that I could do this.",
        "tokens": [
          50514,
          3950,
          366,
          2098,
          300,
          286,
          727,
          360,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.27348555379839085,
        "compression_ratio": 1.3445945945945945,
        "end": 2732.48,
        "id": 783,
        "no_speech_prob": 0.11595213413238525,
        "seek": 271648,
        "start": 2722.48,
        "temperature": 0,
        "text": " Boy, I'm just stopping and starting like crazy.",
        "tokens": [
          50664,
          9486,
          11,
          286,
          478,
          445,
          12767,
          293,
          2891,
          411,
          3219,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.27348555379839085,
        "compression_ratio": 1.3445945945945945,
        "end": 2734.48,
        "id": 784,
        "no_speech_prob": 0.11595213413238525,
        "seek": 271648,
        "start": 2732.48,
        "temperature": 0,
        "text": " I'm very sorry, Amatia.",
        "tokens": [
          51164,
          286,
          478,
          588,
          2597,
          11,
          2012,
          267,
          654,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.27348555379839085,
        "compression_ratio": 1.3445945945945945,
        "end": 2735.48,
        "id": 785,
        "no_speech_prob": 0.11595213413238525,
        "seek": 271648,
        "start": 2734.48,
        "temperature": 0,
        "text": " It's 1230.",
        "tokens": [
          51264,
          467,
          311,
          2272,
          3446,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.27348555379839085,
        "compression_ratio": 1.3445945945945945,
        "end": 2738.48,
        "id": 786,
        "no_speech_prob": 0.11595213413238525,
        "seek": 271648,
        "start": 2735.48,
        "temperature": 0,
        "text": " I'm just thinking about the time today and what to do next.",
        "tokens": [
          51314,
          286,
          478,
          445,
          1953,
          466,
          264,
          565,
          965,
          293,
          437,
          281,
          360,
          958,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2647231624972436,
        "compression_ratio": 1.4313725490196079,
        "end": 2746.48,
        "id": 787,
        "no_speech_prob": 0.033084187656641006,
        "seek": 273848,
        "start": 2738.48,
        "temperature": 0,
        "text": " I'd really like to visualize this data.",
        "tokens": [
          50364,
          286,
          1116,
          534,
          411,
          281,
          23273,
          341,
          1412,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2647231624972436,
        "compression_ratio": 1.4313725490196079,
        "end": 2748.48,
        "id": 788,
        "no_speech_prob": 0.033084187656641006,
        "seek": 273848,
        "start": 2746.48,
        "temperature": 0,
        "text": " I think that would be interesting.",
        "tokens": [
          50764,
          286,
          519,
          300,
          576,
          312,
          1880,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2647231624972436,
        "compression_ratio": 1.4313725490196079,
        "end": 2753.48,
        "id": 789,
        "no_speech_prob": 0.033084187656641006,
        "seek": 273848,
        "start": 2748.48,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50864,
          865,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2647231624972436,
        "compression_ratio": 1.4313725490196079,
        "end": 2755.48,
        "id": 790,
        "no_speech_prob": 0.033084187656641006,
        "seek": 273848,
        "start": 2753.48,
        "temperature": 0,
        "text": " Both changes the array and returns a new one.",
        "tokens": [
          51114,
          6767,
          2962,
          264,
          10225,
          293,
          11247,
          257,
          777,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2647231624972436,
        "compression_ratio": 1.4313725490196079,
        "end": 2759.48,
        "id": 791,
        "no_speech_prob": 0.033084187656641006,
        "seek": 273848,
        "start": 2755.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2647231624972436,
        "compression_ratio": 1.4313725490196079,
        "end": 2764.48,
        "id": 792,
        "no_speech_prob": 0.033084187656641006,
        "seek": 273848,
        "start": 2759.48,
        "temperature": 0,
        "text": " Another correction I just got is that I believe users.sort actually changes the array.",
        "tokens": [
          51414,
          3996,
          19984,
          286,
          445,
          658,
          307,
          300,
          286,
          1697,
          5022,
          13,
          82,
          477,
          767,
          2962,
          264,
          10225,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2772.48,
        "id": 793,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2765.48,
        "temperature": 0,
        "text": " Since I started using arrow syntax, I could write it this way, which is perhaps a bit more readable.",
        "tokens": [
          50414,
          4162,
          286,
          1409,
          1228,
          11610,
          28431,
          11,
          286,
          727,
          2464,
          309,
          341,
          636,
          11,
          597,
          307,
          4317,
          257,
          857,
          544,
          49857,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2773.48,
        "id": 794,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2772.48,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50764,
          2102,
          3255,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2774.48,
        "id": 795,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2773.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2775.48,
        "id": 796,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2774.48,
        "temperature": 0,
        "text": " Here's the question.",
        "tokens": [
          50864,
          1692,
          311,
          264,
          1168,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2777.48,
        "id": 797,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2775.48,
        "temperature": 0,
        "text": " What do I do to clean this data?",
        "tokens": [
          50914,
          708,
          360,
          286,
          360,
          281,
          2541,
          341,
          1412,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2780.48,
        "id": 798,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2777.48,
        "temperature": 0,
        "text": " One thing I could do first is actually analyze it.",
        "tokens": [
          51014,
          1485,
          551,
          286,
          727,
          360,
          700,
          307,
          767,
          12477,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2789.48,
        "id": 799,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2780.48,
        "temperature": 0,
        "text": " I'm going to go on to a new...",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          352,
          322,
          281,
          257,
          777,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.24886434728449042,
        "compression_ratio": 1.4242424242424243,
        "end": 2792.48,
        "id": 800,
        "no_speech_prob": 0.018832188099622726,
        "seek": 276448,
        "start": 2789.48,
        "temperature": 0,
        "text": " My brain is so faulty today.",
        "tokens": [
          51614,
          1222,
          3567,
          307,
          370,
          2050,
          5773,
          965,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19744728088378907,
        "compression_ratio": 1.5964125560538116,
        "end": 2794.48,
        "id": 801,
        "no_speech_prob": 0.008711177855730057,
        "seek": 279248,
        "start": 2792.48,
        "temperature": 0,
        "text": " I'm going to go to the next...",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          958,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.19744728088378907,
        "compression_ratio": 1.5964125560538116,
        "end": 2803.48,
        "id": 802,
        "no_speech_prob": 0.008711177855730057,
        "seek": 279248,
        "start": 2794.48,
        "temperature": 0,
        "text": " This was long enough, so I'm going to do another part.",
        "tokens": [
          50464,
          639,
          390,
          938,
          1547,
          11,
          370,
          286,
          478,
          516,
          281,
          360,
          1071,
          644,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19744728088378907,
        "compression_ratio": 1.5964125560538116,
        "end": 2804.48,
        "id": 803,
        "no_speech_prob": 0.008711177855730057,
        "seek": 279248,
        "start": 2803.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50914,
          1057,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19744728088378907,
        "compression_ratio": 1.5964125560538116,
        "end": 2807.48,
        "id": 804,
        "no_speech_prob": 0.008711177855730057,
        "seek": 279248,
        "start": 2804.48,
        "temperature": 0,
        "text": " So the question here really is what to do next.",
        "tokens": [
          50964,
          407,
          264,
          1168,
          510,
          534,
          307,
          437,
          281,
          360,
          958,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19744728088378907,
        "compression_ratio": 1.5964125560538116,
        "end": 2815.48,
        "id": 805,
        "no_speech_prob": 0.008711177855730057,
        "seek": 279248,
        "start": 2807.48,
        "temperature": 0,
        "text": " I know that this, from my analysis earlier, looking at the things being added to the database, that this appeared to be a bot.",
        "tokens": [
          51114,
          286,
          458,
          300,
          341,
          11,
          490,
          452,
          5215,
          3071,
          11,
          1237,
          412,
          264,
          721,
          885,
          3869,
          281,
          264,
          8149,
          11,
          300,
          341,
          8516,
          281,
          312,
          257,
          10592,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19744728088378907,
        "compression_ratio": 1.5964125560538116,
        "end": 2820.48,
        "id": 806,
        "no_speech_prob": 0.008711177855730057,
        "seek": 279248,
        "start": 2815.48,
        "temperature": 0,
        "text": " I also could, the chat suggested I could just remove everything.",
        "tokens": [
          51514,
          286,
          611,
          727,
          11,
          264,
          5081,
          10945,
          286,
          727,
          445,
          4159,
          1203,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19744728088378907,
        "compression_ratio": 1.5964125560538116,
        "end": 2821.48,
        "id": 807,
        "no_speech_prob": 0.008711177855730057,
        "seek": 279248,
        "start": 2820.48,
        "temperature": 0,
        "text": " That's 100 or more.",
        "tokens": [
          51764,
          663,
          311,
          2319,
          420,
          544,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2823.48,
        "id": 808,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2821.48,
        "temperature": 0,
        "text": " I'm actually going to stop this tutorial.",
        "tokens": [
          50364,
          286,
          478,
          767,
          516,
          281,
          1590,
          341,
          7073,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2825.48,
        "id": 809,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2823.48,
        "temperature": 0,
        "text": " This was sort of like getting to actually be able to look at the data.",
        "tokens": [
          50464,
          639,
          390,
          1333,
          295,
          411,
          1242,
          281,
          767,
          312,
          1075,
          281,
          574,
          412,
          264,
          1412,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2830.48,
        "id": 810,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2825.48,
        "temperature": 0,
        "text": " And I'm going to do a whole next video, because what I think might be useful is actually just look at the data.",
        "tokens": [
          50564,
          400,
          286,
          478,
          516,
          281,
          360,
          257,
          1379,
          958,
          960,
          11,
          570,
          437,
          286,
          519,
          1062,
          312,
          4420,
          307,
          767,
          445,
          574,
          412,
          264,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2833.48,
        "id": 811,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2830.48,
        "temperature": 0,
        "text": " Because this is information I can visualize.",
        "tokens": [
          50814,
          1436,
          341,
          307,
          1589,
          286,
          393,
          23273,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2835.48,
        "id": 812,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2833.48,
        "temperature": 0,
        "text": " I could say show me everything that's pinkish.",
        "tokens": [
          50964,
          286,
          727,
          584,
          855,
          385,
          1203,
          300,
          311,
          7022,
          742,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2836.48,
        "id": 813,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2835.48,
        "temperature": 0,
        "text": " Show me everything that's bluish.",
        "tokens": [
          51064,
          6895,
          385,
          1203,
          300,
          311,
          888,
          33786,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2838.48,
        "id": 814,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2836.48,
        "temperature": 0,
        "text": " And I could also say, like, ignore this.",
        "tokens": [
          51114,
          400,
          286,
          727,
          611,
          584,
          11,
          411,
          11,
          11200,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2840.48,
        "id": 815,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2838.48,
        "temperature": 0,
        "text": " I could see by user what they...",
        "tokens": [
          51214,
          286,
          727,
          536,
          538,
          4195,
          437,
          436,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2842.48,
        "id": 816,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2840.48,
        "temperature": 0,
        "text": " I could actually look at what they assigned.",
        "tokens": [
          51314,
          286,
          727,
          767,
          574,
          412,
          437,
          436,
          13279,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2846.48,
        "id": 817,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2842.48,
        "temperature": 0,
        "text": " I could try to see if something is really just way out there that maybe I shouldn't include.",
        "tokens": [
          51414,
          286,
          727,
          853,
          281,
          536,
          498,
          746,
          307,
          534,
          445,
          636,
          484,
          456,
          300,
          1310,
          286,
          4659,
          380,
          4090,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2847.48,
        "id": 818,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2846.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21412052427019393,
        "compression_ratio": 1.9619047619047618,
        "end": 2848.48,
        "id": 819,
        "no_speech_prob": 0.45700767636299133,
        "seek": 282148,
        "start": 2847.48,
        "temperature": 0,
        "text": " So that's what I'm going to do in the next video.",
        "tokens": [
          51664,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          264,
          958,
          960,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1854155933155733,
        "compression_ratio": 1.5238095238095237,
        "end": 2859.48,
        "id": 820,
        "no_speech_prob": 0.12938937544822693,
        "seek": 284848,
        "start": 2848.48,
        "temperature": 0,
        "text": " I'm going to add some tools to visualize the data.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          909,
          512,
          3873,
          281,
          23273,
          264,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1854155933155733,
        "compression_ratio": 1.5238095238095237,
        "end": 2861.48,
        "id": 821,
        "no_speech_prob": 0.12938937544822693,
        "seek": 284848,
        "start": 2859.48,
        "temperature": 0,
        "text": " And just while I'm...",
        "tokens": [
          50914,
          400,
          445,
          1339,
          286,
          478,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.1854155933155733,
        "compression_ratio": 1.5238095238095237,
        "end": 2864.48,
        "id": 822,
        "no_speech_prob": 0.12938937544822693,
        "seek": 284848,
        "start": 2861.48,
        "temperature": 0,
        "text": " In case it was mentioned, I apologize.",
        "tokens": [
          51014,
          682,
          1389,
          309,
          390,
          2835,
          11,
          286,
          12328,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1854155933155733,
        "compression_ratio": 1.5238095238095237,
        "end": 2867.48,
        "id": 823,
        "no_speech_prob": 0.12938937544822693,
        "seek": 284848,
        "start": 2864.48,
        "temperature": 0,
        "text": " The reading of the database is open.",
        "tokens": [
          51164,
          440,
          3760,
          295,
          264,
          8149,
          307,
          1269,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1854155933155733,
        "compression_ratio": 1.5238095238095237,
        "end": 2870.48,
        "id": 824,
        "no_speech_prob": 0.12938937544822693,
        "seek": 284848,
        "start": 2867.48,
        "temperature": 0,
        "text": " So while you can't write to it right now, you can read from it.",
        "tokens": [
          51314,
          407,
          1339,
          291,
          393,
          380,
          2464,
          281,
          309,
          558,
          586,
          11,
          291,
          393,
          1401,
          490,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1854155933155733,
        "compression_ratio": 1.5238095238095237,
        "end": 2877.48,
        "id": 825,
        "no_speech_prob": 0.12938937544822693,
        "seek": 284848,
        "start": 2870.48,
        "temperature": 0,
        "text": " And so if you want to use this code, this code is also on that GitHub repo.",
        "tokens": [
          51464,
          400,
          370,
          498,
          291,
          528,
          281,
          764,
          341,
          3089,
          11,
          341,
          3089,
          307,
          611,
          322,
          300,
          23331,
          49040,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2440990408261617,
        "compression_ratio": 0.9866666666666667,
        "end": 2889.48,
        "id": 826,
        "no_speech_prob": 0.24777010083198547,
        "seek": 287748,
        "start": 2877.48,
        "temperature": 0,
        "text": " If anybody wants to try, like, messing with it themselves, they can.",
        "tokens": [
          50364,
          759,
          4472,
          2738,
          281,
          853,
          11,
          411,
          11,
          23258,
          365,
          309,
          2969,
          11,
          436,
          393,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2440990408261617,
        "compression_ratio": 0.9866666666666667,
        "end": 2898.48,
        "id": 827,
        "no_speech_prob": 0.24777010083198547,
        "seek": 287748,
        "start": 2889.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2908.48,
        "id": 828,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2899.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2911.48,
        "id": 829,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2908.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2912.48,
        "id": 830,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2911.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51014,
          1057,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2913.48,
        "id": 831,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2912.48,
        "temperature": 0,
        "text": " Cleaning my data part two.",
        "tokens": [
          51064,
          8834,
          8415,
          452,
          1412,
          644,
          732,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2914.48,
        "id": 832,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2913.48,
        "temperature": 0,
        "text": " That's where we are.",
        "tokens": [
          51114,
          663,
          311,
          689,
          321,
          366,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2918.48,
        "id": 833,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2914.48,
        "temperature": 0,
        "text": " Where I last left off previously on cleaning your data.",
        "tokens": [
          51164,
          2305,
          286,
          1036,
          1411,
          766,
          8046,
          322,
          8924,
          428,
          1412,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2920.48,
        "id": 834,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2918.48,
        "temperature": 0,
        "text": " Whoa, the suspense was killing you, I know.",
        "tokens": [
          51364,
          7521,
          11,
          264,
          47803,
          390,
          8011,
          291,
          11,
          286,
          458,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2925.48,
        "id": 835,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2920.48,
        "temperature": 0,
        "text": " I had just retrieved all the data from Firebase.",
        "tokens": [
          51464,
          286,
          632,
          445,
          19817,
          937,
          439,
          264,
          1412,
          490,
          35173,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23958334865340267,
        "compression_ratio": 1.3978494623655915,
        "end": 2927.48,
        "id": 836,
        "no_speech_prob": 0.19679856300354004,
        "seek": 289848,
        "start": 2925.48,
        "temperature": 0,
        "text": " And I looked at it by anonymous user ID.",
        "tokens": [
          51714,
          400,
          286,
          2956,
          412,
          309,
          538,
          24932,
          4195,
          7348,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2930.48,
        "id": 837,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2927.48,
        "temperature": 0,
        "text": " How many entries had been submitted by each user.",
        "tokens": [
          50364,
          1012,
          867,
          23041,
          632,
          668,
          14405,
          538,
          1184,
          4195,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2936.48,
        "id": 838,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2930.48,
        "temperature": 0,
        "text": " And I have a suspicion that some of these that submitted a lot of entries maybe wasn't actually a person doing it manually.",
        "tokens": [
          50514,
          400,
          286,
          362,
          257,
          32020,
          300,
          512,
          295,
          613,
          300,
          14405,
          257,
          688,
          295,
          23041,
          1310,
          2067,
          380,
          767,
          257,
          954,
          884,
          309,
          16945,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2939.48,
        "id": 839,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2936.48,
        "temperature": 0,
        "text": " And maybe, like, a bot or something flooding the database.",
        "tokens": [
          50814,
          400,
          1310,
          11,
          411,
          11,
          257,
          10592,
          420,
          746,
          24132,
          264,
          8149,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2942.48,
        "id": 840,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2939.48,
        "temperature": 0,
        "text": " So let's try to investigate that and see what we can figure out.",
        "tokens": [
          50964,
          407,
          718,
          311,
          853,
          281,
          15013,
          300,
          293,
          536,
          437,
          321,
          393,
          2573,
          484,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2944.48,
        "id": 841,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2942.48,
        "temperature": 0,
        "text": " So the first thing I'm going to do is I'm just going to visualize the data.",
        "tokens": [
          51114,
          407,
          264,
          700,
          551,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          23273,
          264,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2946.48,
        "id": 842,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2944.48,
        "temperature": 0,
        "text": " I could visualize it by user ID.",
        "tokens": [
          51214,
          286,
          727,
          23273,
          309,
          538,
          4195,
          7348,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2947.48,
        "id": 843,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2946.48,
        "temperature": 0,
        "text": " There's so many things I could do.",
        "tokens": [
          51314,
          821,
          311,
          370,
          867,
          721,
          286,
          727,
          360,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2948.48,
        "id": 844,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2947.48,
        "temperature": 0,
        "text": " But let's think about it.",
        "tokens": [
          51364,
          583,
          718,
          311,
          519,
          466,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2951.48,
        "id": 845,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2948.48,
        "temperature": 0,
        "text": " So there are how many labels?",
        "tokens": [
          51414,
          407,
          456,
          366,
          577,
          867,
          16949,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2953.48,
        "id": 846,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2951.48,
        "temperature": 0,
        "text": " So let me think about this.",
        "tokens": [
          51564,
          407,
          718,
          385,
          519,
          466,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2954.48,
        "id": 847,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2953.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2955.48,
        "id": 848,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2954.48,
        "temperature": 0,
        "text": " This is my sketch.",
        "tokens": [
          51714,
          639,
          307,
          452,
          12325,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15563665790322387,
        "compression_ratio": 1.7894736842105263,
        "end": 2956.48,
        "id": 849,
        "no_speech_prob": 0.011686930432915688,
        "seek": 292748,
        "start": 2955.48,
        "temperature": 0,
        "text": " I know what the labels are.",
        "tokens": [
          51764,
          286,
          458,
          437,
          264,
          16949,
          366,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18759283029808188,
        "compression_ratio": 1.4173228346456692,
        "end": 2970.48,
        "id": 850,
        "no_speech_prob": 0.0006563701317645609,
        "seek": 295648,
        "start": 2956.48,
        "temperature": 0,
        "text": " So let me just set up a variable called data by color by label.",
        "tokens": [
          50364,
          407,
          718,
          385,
          445,
          992,
          493,
          257,
          7006,
          1219,
          1412,
          538,
          2017,
          538,
          7645,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18759283029808188,
        "compression_ratio": 1.4173228346456692,
        "end": 2973.48,
        "id": 851,
        "no_speech_prob": 0.0006563701317645609,
        "seek": 295648,
        "start": 2970.48,
        "temperature": 0,
        "text": " And this will be an object.",
        "tokens": [
          51064,
          400,
          341,
          486,
          312,
          364,
          2657,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18759283029808188,
        "compression_ratio": 1.4173228346456692,
        "end": 2983.48,
        "id": 852,
        "no_speech_prob": 0.0006563701317645609,
        "seek": 295648,
        "start": 2973.48,
        "temperature": 0,
        "text": " And the object will have empty arrays for each one of the labels.",
        "tokens": [
          51214,
          400,
          264,
          2657,
          486,
          362,
          6707,
          41011,
          337,
          1184,
          472,
          295,
          264,
          16949,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18759283029808188,
        "compression_ratio": 1.4173228346456692,
        "end": 2985.48,
        "id": 853,
        "no_speech_prob": 0.0006563701317645609,
        "seek": 295648,
        "start": 2983.48,
        "temperature": 0,
        "text": " So there was blue-ish.",
        "tokens": [
          51714,
          407,
          456,
          390,
          3344,
          12,
          742,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2987.48,
        "id": 854,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2985.48,
        "temperature": 0,
        "text": " I should have a list of this somewhere.",
        "tokens": [
          50364,
          286,
          820,
          362,
          257,
          1329,
          295,
          341,
          4079,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2988.48,
        "id": 855,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2987.48,
        "temperature": 0,
        "text": " Green-ish.",
        "tokens": [
          50464,
          6969,
          12,
          742,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2989.48,
        "id": 856,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2988.48,
        "temperature": 0,
        "text": " I'm doing this manually.",
        "tokens": [
          50514,
          286,
          478,
          884,
          341,
          16945,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2991.48,
        "id": 857,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2989.48,
        "temperature": 0,
        "text": " I could have actually pulled the labels from the database.",
        "tokens": [
          50564,
          286,
          727,
          362,
          767,
          7373,
          264,
          16949,
          490,
          264,
          8149,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2993.48,
        "id": 858,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2991.48,
        "temperature": 0,
        "text": " But this will be simpler.",
        "tokens": [
          50664,
          583,
          341,
          486,
          312,
          18587,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2994.48,
        "id": 859,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2993.48,
        "temperature": 0,
        "text": " Green-ish.",
        "tokens": [
          50764,
          6969,
          12,
          742,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2996.48,
        "id": 860,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2994.48,
        "temperature": 0,
        "text": " Pink-ish.",
        "tokens": [
          50814,
          17118,
          12,
          742,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 2999.48,
        "id": 861,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2996.48,
        "temperature": 0,
        "text": " I'm not doing this in any particular order.",
        "tokens": [
          50914,
          286,
          478,
          406,
          884,
          341,
          294,
          604,
          1729,
          1668,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3000.48,
        "id": 862,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 2999.48,
        "temperature": 0,
        "text": " Gray-ish.",
        "tokens": [
          51064,
          22668,
          12,
          742,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3002.48,
        "id": 863,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 3000.48,
        "temperature": 0,
        "text": " Red-ish.",
        "tokens": [
          51114,
          4477,
          12,
          742,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3004.48,
        "id": 864,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 3002.48,
        "temperature": 0,
        "text": " What am I missing?",
        "tokens": [
          51214,
          708,
          669,
          286,
          5361,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3006.48,
        "id": 865,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 3004.48,
        "temperature": 0,
        "text": " Purple-ish.",
        "tokens": [
          51314,
          28483,
          12,
          742,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3009.48,
        "id": 866,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 3006.48,
        "temperature": 0,
        "text": " There was a brown-ish.",
        "tokens": [
          51414,
          821,
          390,
          257,
          6292,
          12,
          742,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3011.48,
        "id": 867,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 3009.48,
        "temperature": 0,
        "text": " If I go to my crowdsource color.",
        "tokens": [
          51564,
          759,
          286,
          352,
          281,
          452,
          26070,
          2948,
          2017,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3013.48,
        "id": 868,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 3011.48,
        "temperature": 0,
        "text": " Reddish, greenish, bluish, orange-ish.",
        "tokens": [
          51664,
          4477,
          40974,
          11,
          3092,
          742,
          11,
          888,
          33786,
          11,
          7671,
          12,
          742,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.163893967223682,
        "compression_ratio": 1.6609442060085837,
        "end": 3014.48,
        "id": 869,
        "no_speech_prob": 0.007011523935943842,
        "seek": 298548,
        "start": 3013.48,
        "temperature": 0,
        "text": " Did I do orange?",
        "tokens": [
          51764,
          2589,
          286,
          360,
          7671,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3016.48,
        "id": 870,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3014.48,
        "temperature": 0,
        "text": " I don't think I did orange.",
        "tokens": [
          50364,
          286,
          500,
          380,
          519,
          286,
          630,
          7671,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3019.48,
        "id": 871,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3016.48,
        "temperature": 0,
        "text": " Orange-ish.",
        "tokens": [
          50464,
          17106,
          12,
          742,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3024.48,
        "id": 872,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3019.48,
        "temperature": 0,
        "text": " Purple-ish, gray-ish, brown-ish.",
        "tokens": [
          50614,
          28483,
          12,
          742,
          11,
          10855,
          12,
          742,
          11,
          6292,
          12,
          742,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3027.48,
        "id": 873,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3024.48,
        "temperature": 0,
        "text": " 1, 2, 3, 4, 5, 6, 7, 8, 9.",
        "tokens": [
          50864,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1649,
          11,
          1722,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3029.48,
        "id": 874,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3027.48,
        "temperature": 0,
        "text": " I'm missing one.",
        "tokens": [
          51014,
          286,
          478,
          5361,
          472,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3031.48,
        "id": 875,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3029.48,
        "temperature": 0,
        "text": " Blue, green, pink, gray.",
        "tokens": [
          51114,
          8510,
          11,
          3092,
          11,
          7022,
          11,
          10855,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3034.48,
        "id": 876,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3031.48,
        "temperature": 0,
        "text": " This is not a very systematic way to do this.",
        "tokens": [
          51214,
          639,
          307,
          406,
          257,
          588,
          27249,
          636,
          281,
          360,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3036.48,
        "id": 877,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3034.48,
        "temperature": 0,
        "text": " Red, green, blue, orange, purple.",
        "tokens": [
          51364,
          4477,
          11,
          3092,
          11,
          3344,
          11,
          7671,
          11,
          9656,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3037.48,
        "id": 878,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3036.48,
        "temperature": 0,
        "text": " But yellow-ish.",
        "tokens": [
          51464,
          583,
          5566,
          12,
          742,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3039.48,
        "id": 879,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3037.48,
        "temperature": 0,
        "text": " I didn't do yellow-ish.",
        "tokens": [
          51514,
          286,
          994,
          380,
          360,
          5566,
          12,
          742,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17294045798798913,
        "compression_ratio": 1.5082872928176796,
        "end": 3041.48,
        "id": 880,
        "no_speech_prob": 0.09008637070655823,
        "seek": 301448,
        "start": 3039.48,
        "temperature": 0,
        "text": " Yellow-ish.",
        "tokens": [
          51614,
          17550,
          12,
          742,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22979141984667098,
        "compression_ratio": 1.3308823529411764,
        "end": 3048.48,
        "id": 881,
        "no_speech_prob": 0.004754898138344288,
        "seek": 304148,
        "start": 3042.48,
        "temperature": 0,
        "text": " Now, while I am looping through the data, which I did in the previous video.",
        "tokens": [
          50414,
          823,
          11,
          1339,
          286,
          669,
          6367,
          278,
          807,
          264,
          1412,
          11,
          597,
          286,
          630,
          294,
          264,
          3894,
          960,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22979141984667098,
        "compression_ratio": 1.3308823529411764,
        "end": 3053.48,
        "id": 882,
        "no_speech_prob": 0.004754898138344288,
        "seek": 304148,
        "start": 3048.48,
        "temperature": 0,
        "text": " And I'm going to not worry about this users by count thing right now.",
        "tokens": [
          50714,
          400,
          286,
          478,
          516,
          281,
          406,
          3292,
          466,
          341,
          5022,
          538,
          1207,
          551,
          558,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22979141984667098,
        "compression_ratio": 1.3308823529411764,
        "end": 3055.48,
        "id": 883,
        "no_speech_prob": 0.004754898138344288,
        "seek": 304148,
        "start": 3053.48,
        "temperature": 0,
        "text": " I'll come back to that.",
        "tokens": [
          50964,
          286,
          603,
          808,
          646,
          281,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22979141984667098,
        "compression_ratio": 1.3308823529411764,
        "end": 3057.48,
        "id": 884,
        "no_speech_prob": 0.004754898138344288,
        "seek": 304148,
        "start": 3055.48,
        "temperature": 0,
        "text": " Ah, shoot.",
        "tokens": [
          51064,
          2438,
          11,
          3076,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3061.48,
        "id": 885,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3058.48,
        "temperature": 0,
        "text": " I'm going to not worry about this users by count thing right now.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          406,
          3292,
          466,
          341,
          5022,
          538,
          1207,
          551,
          558,
          586,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3064.48,
        "id": 886,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3061.48,
        "temperature": 0,
        "text": " I will come back to that later.",
        "tokens": [
          50564,
          286,
          486,
          808,
          646,
          281,
          300,
          1780,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3066.48,
        "id": 887,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3064.48,
        "temperature": 0,
        "text": " What I want to do is...",
        "tokens": [
          50714,
          708,
          286,
          528,
          281,
          360,
          307,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3067.48,
        "id": 888,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3066.48,
        "temperature": 0,
        "text": " Oh, sorry.",
        "tokens": [
          50814,
          876,
          11,
          2597,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3069.48,
        "id": 889,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3067.48,
        "temperature": 0,
        "text": " I do want this.",
        "tokens": [
          50864,
          286,
          360,
          528,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3072.48,
        "id": 890,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3069.48,
        "temperature": 0,
        "text": " So I want to look at each data point.",
        "tokens": [
          50964,
          407,
          286,
          528,
          281,
          574,
          412,
          1184,
          1412,
          935,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3075.48,
        "id": 891,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3072.48,
        "temperature": 0,
        "text": " And I'm going to do that.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3077.48,
        "id": 892,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3075.48,
        "temperature": 0,
        "text": " And I'm going to do that.",
        "tokens": [
          51264,
          400,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3079.48,
        "id": 893,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3077.48,
        "temperature": 0,
        "text": " And I'm going to do that.",
        "tokens": [
          51364,
          400,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3081.48,
        "id": 894,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3079.48,
        "temperature": 0,
        "text": " And I'm going to do that.",
        "tokens": [
          51464,
          400,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3083.48,
        "id": 895,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3081.48,
        "temperature": 0,
        "text": " And I'm going to do that.",
        "tokens": [
          51564,
          400,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3697199937773914,
        "compression_ratio": 2.295302013422819,
        "end": 3085.48,
        "id": 896,
        "no_speech_prob": 0.07693856209516525,
        "seek": 305748,
        "start": 3083.48,
        "temperature": 0,
        "text": " And I'm going to do that.",
        "tokens": [
          51664,
          400,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3089.48,
        "id": 897,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3086.48,
        "temperature": 0,
        "text": " And I want to look at the RG...",
        "tokens": [
          50414,
          400,
          286,
          528,
          281,
          574,
          412,
          264,
          497,
          38,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3091.48,
        "id": 898,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3089.48,
        "temperature": 0,
        "text": " So I want to look at the label.",
        "tokens": [
          50564,
          407,
          286,
          528,
          281,
          574,
          412,
          264,
          7645,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3094.48,
        "id": 899,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3091.48,
        "temperature": 0,
        "text": " And I want to say color by label.",
        "tokens": [
          50664,
          400,
          286,
          528,
          281,
          584,
          2017,
          538,
          7645,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3100.48,
        "id": 900,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3096.48,
        "temperature": 0,
        "text": " And then I want to record.label.",
        "tokens": [
          50914,
          400,
          550,
          286,
          528,
          281,
          2136,
          13,
          75,
          18657,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3102.48,
        "id": 901,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3100.48,
        "temperature": 0,
        "text": " Push.",
        "tokens": [
          51114,
          18229,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3105.48,
        "id": 902,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3102.48,
        "temperature": 0,
        "text": " And so I'm going to create a color.",
        "tokens": [
          51214,
          400,
          370,
          286,
          478,
          516,
          281,
          1884,
          257,
          2017,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3107.48,
        "id": 903,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3105.48,
        "temperature": 0,
        "text": " Let color equal...",
        "tokens": [
          51364,
          961,
          2017,
          2681,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.19790363311767578,
        "compression_ratio": 1.75,
        "end": 3114.48,
        "id": 904,
        "no_speech_prob": 0.0004728470812551677,
        "seek": 308548,
        "start": 3107.48,
        "temperature": 0,
        "text": " I'll use the p5 color function to say record.r, record.g, record.b.",
        "tokens": [
          51464,
          286,
          603,
          764,
          264,
          280,
          20,
          2017,
          2445,
          281,
          584,
          2136,
          13,
          81,
          11,
          2136,
          13,
          70,
          11,
          2136,
          13,
          65,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3118.48,
        "id": 905,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3115.48,
        "temperature": 0,
        "text": " Color by label, push color.",
        "tokens": [
          50414,
          10458,
          538,
          7645,
          11,
          2944,
          2017,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3123.48,
        "id": 906,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3120.48,
        "temperature": 0,
        "text": " And now what I should have...",
        "tokens": [
          50664,
          400,
          586,
          437,
          286,
          820,
          362,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3126.48,
        "id": 907,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3123.48,
        "temperature": 0,
        "text": " And I'm really risking breaking the console here.",
        "tokens": [
          50814,
          400,
          286,
          478,
          534,
          45235,
          7697,
          264,
          11076,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3130.48,
        "id": 908,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3126.48,
        "temperature": 0,
        "text": " Is I should have all the RGB values listed by the label.",
        "tokens": [
          50964,
          1119,
          286,
          820,
          362,
          439,
          264,
          31231,
          4190,
          10052,
          538,
          264,
          7645,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3132.48,
        "id": 909,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3130.48,
        "temperature": 0,
        "text": " So let's look at that.",
        "tokens": [
          51164,
          407,
          718,
          311,
          574,
          412,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3136.48,
        "id": 910,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3134.48,
        "temperature": 0,
        "text": " Oops, I'm in the wrong sketch.",
        "tokens": [
          51364,
          21726,
          11,
          286,
          478,
          294,
          264,
          2085,
          12325,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3139.48,
        "id": 911,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3138.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51564,
          1779,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.25114721410414753,
        "compression_ratio": 1.4680851063829787,
        "end": 3142.48,
        "id": 912,
        "no_speech_prob": 0.0007436650921590626,
        "seek": 311448,
        "start": 3139.48,
        "temperature": 0,
        "text": " So we can see there's a thousand blues, sixteen...",
        "tokens": [
          51614,
          407,
          321,
          393,
          536,
          456,
          311,
          257,
          4714,
          24244,
          11,
          27847,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3144.48,
        "id": 913,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3142.48,
        "temperature": 0,
        "text": " There's only two thirty-five grays.",
        "tokens": [
          50364,
          821,
          311,
          787,
          732,
          11790,
          12,
          18621,
          677,
          3772,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3148.48,
        "id": 914,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3144.48,
        "temperature": 0,
        "text": " So one thing that's also important about what I've done with my data set here...",
        "tokens": [
          50464,
          407,
          472,
          551,
          300,
          311,
          611,
          1021,
          466,
          437,
          286,
          600,
          1096,
          365,
          452,
          1412,
          992,
          510,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3155.48,
        "id": 915,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3148.48,
        "temperature": 0,
        "text": " Is I don't have a uniform amount of data points by label.",
        "tokens": [
          50664,
          1119,
          286,
          500,
          380,
          362,
          257,
          9452,
          2372,
          295,
          1412,
          2793,
          538,
          7645,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3157.48,
        "id": 916,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3155.48,
        "temperature": 0,
        "text": " I have many more green ones.",
        "tokens": [
          51014,
          286,
          362,
          867,
          544,
          3092,
          2306,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3162.48,
        "id": 917,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3157.48,
        "temperature": 0,
        "text": " And actually Eric in the patron group made a point that the way the colors are picked...",
        "tokens": [
          51114,
          400,
          767,
          9336,
          294,
          264,
          21843,
          1594,
          1027,
          257,
          935,
          300,
          264,
          636,
          264,
          4577,
          366,
          6183,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3164.48,
        "id": 918,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3162.48,
        "temperature": 0,
        "text": " The way my random number generator works...",
        "tokens": [
          51364,
          440,
          636,
          452,
          4974,
          1230,
          19265,
          1985,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3166.48,
        "id": 919,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3164.48,
        "temperature": 0,
        "text": " You're going to be more greenish looking colors.",
        "tokens": [
          51464,
          509,
          434,
          516,
          281,
          312,
          544,
          3092,
          742,
          1237,
          4577,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3168.48,
        "id": 920,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3166.48,
        "temperature": 0,
        "text": " Which is sort of interesting to think about.",
        "tokens": [
          51564,
          3013,
          307,
          1333,
          295,
          1880,
          281,
          519,
          466,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22706455654568142,
        "compression_ratio": 1.6423611111111112,
        "end": 3171.48,
        "id": 921,
        "no_speech_prob": 0.002631543902680278,
        "seek": 314248,
        "start": 3168.48,
        "temperature": 0,
        "text": " But at the very least what I can do now...",
        "tokens": [
          51664,
          583,
          412,
          264,
          588,
          1935,
          437,
          286,
          393,
          360,
          586,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3174.48,
        "id": 922,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3171.48,
        "temperature": 0,
        "text": " Is I can just draw all of the colors.",
        "tokens": [
          50364,
          1119,
          286,
          393,
          445,
          2642,
          439,
          295,
          264,
          4577,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3176.48,
        "id": 923,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3174.48,
        "temperature": 0,
        "text": " So I'm trying to think of what...",
        "tokens": [
          50514,
          407,
          286,
          478,
          1382,
          281,
          519,
          295,
          437,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3181.48,
        "id": 924,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3176.48,
        "temperature": 0,
        "text": " I probably want to do little rectangles and a p5 canvas maybe.",
        "tokens": [
          50614,
          286,
          1391,
          528,
          281,
          360,
          707,
          24077,
          904,
          293,
          257,
          280,
          20,
          16267,
          1310,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3185.48,
        "id": 925,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3181.48,
        "temperature": 0,
        "text": " So let me add create canvas.",
        "tokens": [
          50864,
          407,
          718,
          385,
          909,
          1884,
          16267,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3191.48,
        "id": 926,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3189.48,
        "temperature": 0,
        "text": " And let's make it 400 by 400.",
        "tokens": [
          51264,
          400,
          718,
          311,
          652,
          309,
          8423,
          538,
          8423,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3194.48,
        "id": 927,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3192.48,
        "temperature": 0,
        "text": " And let me...",
        "tokens": [
          51414,
          400,
          718,
          385,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3196.48,
        "id": 928,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3194.48,
        "temperature": 0,
        "text": " Let's do just one.",
        "tokens": [
          51514,
          961,
          311,
          360,
          445,
          472,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18484796479690907,
        "compression_ratio": 1.4576271186440677,
        "end": 3199.48,
        "id": 929,
        "no_speech_prob": 0.000025071440177271143,
        "seek": 317148,
        "start": 3196.48,
        "temperature": 0,
        "text": " Let's just start with a bluish.",
        "tokens": [
          51614,
          961,
          311,
          445,
          722,
          365,
          257,
          888,
          33786,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3204.48,
        "id": 930,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3202.48,
        "temperature": 0,
        "text": " And I'm going to say a four.",
        "tokens": [
          50414,
          400,
          286,
          478,
          516,
          281,
          584,
          257,
          1451,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3206.48,
        "id": 931,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3204.48,
        "temperature": 0,
        "text": " Let i equal zero.",
        "tokens": [
          50514,
          961,
          741,
          2681,
          4018,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3208.48,
        "id": 932,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3206.48,
        "temperature": 0,
        "text": " i is less than...",
        "tokens": [
          50614,
          741,
          307,
          1570,
          813,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3210.48,
        "id": 933,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3208.48,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          50714,
          407,
          718,
          311,
          536,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3214.48,
        "id": 934,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3210.48,
        "temperature": 0,
        "text": " I'm going to say let blues equal color by label blue-ish.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          584,
          718,
          24244,
          2681,
          2017,
          538,
          7645,
          3344,
          12,
          742,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3219.48,
        "id": 935,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3216.48,
        "temperature": 0,
        "text": " And I'm going to look at all those.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          574,
          412,
          439,
          729,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3225.48,
        "id": 936,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3222.48,
        "temperature": 0,
        "text": " And let's start with an x.",
        "tokens": [
          51414,
          400,
          718,
          311,
          722,
          365,
          364,
          2031,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3227.48,
        "id": 937,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3225.48,
        "temperature": 0,
        "text": " Let's start with a y.",
        "tokens": [
          51564,
          961,
          311,
          722,
          365,
          257,
          288,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2004335167702664,
        "compression_ratio": 1.6690140845070423,
        "end": 3229.48,
        "id": 938,
        "no_speech_prob": 0.00003269863373134285,
        "seek": 320148,
        "start": 3227.48,
        "temperature": 0,
        "text": " Let's say fill.",
        "tokens": [
          51664,
          961,
          311,
          584,
          2836,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3232.48,
        "id": 939,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3229.48,
        "temperature": 0,
        "text": " Blues index i.",
        "tokens": [
          50364,
          44979,
          8186,
          741,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3236.48,
        "id": 940,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3233.48,
        "temperature": 0,
        "text": " And then let's draw a rectangle at x, y.",
        "tokens": [
          50564,
          400,
          550,
          718,
          311,
          2642,
          257,
          21930,
          412,
          2031,
          11,
          288,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3238.48,
        "id": 941,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3236.48,
        "temperature": 0,
        "text": " That's 10, 10.",
        "tokens": [
          50714,
          663,
          311,
          1266,
          11,
          1266,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3240.48,
        "id": 942,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3238.48,
        "temperature": 0,
        "text": " We'll increase x by 10.",
        "tokens": [
          50814,
          492,
          603,
          3488,
          2031,
          538,
          1266,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3243.48,
        "id": 943,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3240.48,
        "temperature": 0,
        "text": " And if y is greater than or equal to width...",
        "tokens": [
          50914,
          400,
          498,
          288,
          307,
          5044,
          813,
          420,
          2681,
          281,
          11402,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3246.48,
        "id": 944,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3243.48,
        "temperature": 0,
        "text": " Then we will reset x back to zero.",
        "tokens": [
          51064,
          1396,
          321,
          486,
          14322,
          2031,
          646,
          281,
          4018,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3248.48,
        "id": 945,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3246.48,
        "temperature": 0,
        "text": " And increase y by 10.",
        "tokens": [
          51214,
          400,
          3488,
          288,
          538,
          1266,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3249.48,
        "id": 946,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3248.48,
        "temperature": 0,
        "text": " Now this is invariant.",
        "tokens": [
          51314,
          823,
          341,
          307,
          33270,
          394,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3251.48,
        "id": 947,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3249.48,
        "temperature": 0,
        "text": " Again, I'm not being that thoughtful about this.",
        "tokens": [
          51364,
          3764,
          11,
          286,
          478,
          406,
          885,
          300,
          21566,
          466,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3253.48,
        "id": 948,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3251.48,
        "temperature": 0,
        "text": " But in theory...",
        "tokens": [
          51464,
          583,
          294,
          5261,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3256.48,
        "id": 949,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3253.48,
        "temperature": 0,
        "text": " I should see now when I run this...",
        "tokens": [
          51564,
          286,
          820,
          536,
          586,
          562,
          286,
          1190,
          341,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.21499658667522928,
        "compression_ratio": 1.5112107623318385,
        "end": 3258.48,
        "id": 950,
        "no_speech_prob": 0.000021444764570333064,
        "seek": 322948,
        "start": 3256.48,
        "temperature": 0,
        "text": " All the blues.",
        "tokens": [
          51714,
          1057,
          264,
          24244,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3260.48,
        "id": 951,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3258.48,
        "temperature": 0,
        "text": " Why did it not wrap around?",
        "tokens": [
          50364,
          1545,
          630,
          309,
          406,
          7019,
          926,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3262.48,
        "id": 952,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3260.48,
        "temperature": 0,
        "text": " Oh, if x is greater than width.",
        "tokens": [
          50464,
          876,
          11,
          498,
          2031,
          307,
          5044,
          813,
          11402,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3264.48,
        "id": 953,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3262.48,
        "temperature": 0,
        "text": " And I want to say no stroke.",
        "tokens": [
          50564,
          400,
          286,
          528,
          281,
          584,
          572,
          12403,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3265.48,
        "id": 954,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3264.48,
        "temperature": 0,
        "text": " And I could sort...",
        "tokens": [
          50664,
          400,
          286,
          727,
          1333,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3267.48,
        "id": 955,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3265.48,
        "temperature": 0,
        "text": " I probably would want to sort these too.",
        "tokens": [
          50714,
          286,
          1391,
          576,
          528,
          281,
          1333,
          613,
          886,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3269.48,
        "id": 956,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3267.48,
        "temperature": 0,
        "text": " I could sort them by brightness.",
        "tokens": [
          50814,
          286,
          727,
          1333,
          552,
          538,
          21367,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3270.48,
        "id": 957,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3269.48,
        "temperature": 0,
        "text": " So we can see here...",
        "tokens": [
          50914,
          407,
          321,
          393,
          536,
          510,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3271.48,
        "id": 958,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3270.48,
        "temperature": 0,
        "text": " Ah, look at this.",
        "tokens": [
          50964,
          2438,
          11,
          574,
          412,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3273.48,
        "id": 959,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3271.48,
        "temperature": 0,
        "text": " These are all the blues...",
        "tokens": [
          51014,
          1981,
          366,
          439,
          264,
          24244,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3276.48,
        "id": 960,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3273.48,
        "temperature": 0,
        "text": " That were submitted to the database.",
        "tokens": [
          51114,
          663,
          645,
          14405,
          281,
          264,
          8149,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3280.48,
        "id": 961,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3277.48,
        "temperature": 0,
        "text": " So, you know, I kind of don't mind...",
        "tokens": [
          51314,
          407,
          11,
          291,
          458,
          11,
          286,
          733,
          295,
          500,
          380,
          1575,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3284.48,
        "id": 962,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3280.48,
        "temperature": 0,
        "text": " That the data has some noise in it.",
        "tokens": [
          51464,
          663,
          264,
          1412,
          575,
          512,
          5658,
          294,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3285.48,
        "id": 963,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3284.48,
        "temperature": 0,
        "text": " I mean, big deal.",
        "tokens": [
          51664,
          286,
          914,
          11,
          955,
          2028,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20377732715467467,
        "compression_ratio": 1.613899613899614,
        "end": 3287.48,
        "id": 964,
        "no_speech_prob": 0.0022518057376146317,
        "seek": 325848,
        "start": 3285.48,
        "temperature": 0,
        "text": " The point of this is to crowdsource it.",
        "tokens": [
          51714,
          440,
          935,
          295,
          341,
          307,
          281,
          26070,
          2948,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3289.48,
        "id": 965,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3287.48,
        "temperature": 0,
        "text": " And maybe training the model...",
        "tokens": [
          50364,
          400,
          1310,
          3097,
          264,
          2316,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3292.48,
        "id": 966,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3289.48,
        "temperature": 0,
        "text": " If there's enough data, it will sort of filter out the noise.",
        "tokens": [
          50464,
          759,
          456,
          311,
          1547,
          1412,
          11,
          309,
          486,
          1333,
          295,
          6608,
          484,
          264,
          5658,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3293.48,
        "id": 967,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3292.48,
        "temperature": 0,
        "text": " But, you know...",
        "tokens": [
          50614,
          583,
          11,
          291,
          458,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3294.48,
        "id": 968,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3293.48,
        "temperature": 0,
        "text": " And the question is...",
        "tokens": [
          50664,
          400,
          264,
          1168,
          307,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3295.48,
        "id": 969,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3294.48,
        "temperature": 0,
        "text": " Why is this here?",
        "tokens": [
          50714,
          1545,
          307,
          341,
          510,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3296.48,
        "id": 970,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3295.48,
        "temperature": 0,
        "text": " Why is this here?",
        "tokens": [
          50764,
          1545,
          307,
          341,
          510,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3298.48,
        "id": 971,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3296.48,
        "temperature": 0,
        "text": " What should I do about that?",
        "tokens": [
          50814,
          708,
          820,
          286,
          360,
          466,
          300,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3300.48,
        "id": 972,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3298.48,
        "temperature": 0,
        "text": " Let's just look at some other ones.",
        "tokens": [
          50914,
          961,
          311,
          445,
          574,
          412,
          512,
          661,
          2306,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3302.48,
        "id": 973,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3300.48,
        "temperature": 0,
        "text": " Let's look at red.",
        "tokens": [
          51014,
          961,
          311,
          574,
          412,
          2182,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3305.48,
        "id": 974,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3304.48,
        "temperature": 0,
        "text": " You can see...",
        "tokens": [
          51214,
          509,
          393,
          536,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3306.48,
        "id": 975,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3305.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3307.48,
        "id": 976,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3306.48,
        "temperature": 0,
        "text": " What's interesting is...",
        "tokens": [
          51314,
          708,
          311,
          1880,
          307,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3309.48,
        "id": 977,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3307.48,
        "temperature": 0,
        "text": " I think these are in the order by which they were submitted.",
        "tokens": [
          51364,
          286,
          519,
          613,
          366,
          294,
          264,
          1668,
          538,
          597,
          436,
          645,
          14405,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3311.48,
        "id": 978,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3309.48,
        "temperature": 0,
        "text": " So there probably was a time period here...",
        "tokens": [
          51464,
          407,
          456,
          1391,
          390,
          257,
          565,
          2896,
          510,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3312.48,
        "id": 979,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3311.48,
        "temperature": 0,
        "text": " Where...",
        "tokens": [
          51564,
          2305,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.20563475529950365,
        "compression_ratio": 1.6614173228346456,
        "end": 3316.48,
        "id": 980,
        "no_speech_prob": 0.0001852230925578624,
        "seek": 328748,
        "start": 3315.48,
        "temperature": 0,
        "text": " Where...",
        "tokens": [
          51764,
          2305,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3320.48,
        "id": 981,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3318.48,
        "temperature": 0,
        "text": " There probably was a time period here...",
        "tokens": [
          50414,
          821,
          1391,
          390,
          257,
          565,
          2896,
          510,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3323.48,
        "id": 982,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3320.48,
        "temperature": 0,
        "text": " Where some bad data was entered.",
        "tokens": [
          50514,
          2305,
          512,
          1578,
          1412,
          390,
          9065,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3325.48,
        "id": 983,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3323.48,
        "temperature": 0,
        "text": " Let's look at green.",
        "tokens": [
          50664,
          961,
          311,
          574,
          412,
          3092,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3328.48,
        "id": 984,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3325.48,
        "temperature": 0,
        "text": " Because green has the most, right?",
        "tokens": [
          50764,
          1436,
          3092,
          575,
          264,
          881,
          11,
          558,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3329.48,
        "id": 985,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3328.48,
        "temperature": 0,
        "text": " That's pretty good.",
        "tokens": [
          50914,
          663,
          311,
          1238,
          665,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3330.48,
        "id": 986,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3329.48,
        "temperature": 0,
        "text": " So what do I do?",
        "tokens": [
          50964,
          407,
          437,
          360,
          286,
          360,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3331.48,
        "id": 987,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3330.48,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          51014,
          876,
          11,
          3237,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3333.48,
        "id": 988,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3331.48,
        "temperature": 0,
        "text": " What do I do about this?",
        "tokens": [
          51064,
          708,
          360,
          286,
          360,
          466,
          341,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3337.48,
        "id": 989,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3335.48,
        "temperature": 0,
        "text": " Thinking pause for a second.",
        "tokens": [
          51264,
          24460,
          10465,
          337,
          257,
          1150,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3339.48,
        "id": 990,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3338.48,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          51414,
          876,
          0,
          51464
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3341.48,
        "id": 991,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3339.48,
        "temperature": 0,
        "text": " Oh, that's such a good idea.",
        "tokens": [
          51464,
          876,
          11,
          300,
          311,
          1270,
          257,
          665,
          1558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24356448093307353,
        "compression_ratio": 1.4951923076923077,
        "end": 3345.48,
        "id": 992,
        "no_speech_prob": 0.00005562131991609931,
        "seek": 331748,
        "start": 3342.48,
        "temperature": 0,
        "text": " Me, I am assuming, has a great idea in the chat.",
        "tokens": [
          51614,
          1923,
          11,
          286,
          669,
          11926,
          11,
          575,
          257,
          869,
          1558,
          294,
          264,
          5081,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3349.48,
        "id": 993,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3348.48,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50414,
          1779,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3350.48,
        "id": 994,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3349.48,
        "temperature": 0,
        "text": " Oh, that's a great point.",
        "tokens": [
          50464,
          876,
          11,
          300,
          311,
          257,
          869,
          935,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3352.48,
        "id": 995,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3350.48,
        "temperature": 0,
        "text": " Luke makes a great point.",
        "tokens": [
          50514,
          13044,
          1669,
          257,
          869,
          935,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3355.48,
        "id": 996,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3354.48,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50714,
          2798,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3357.48,
        "id": 997,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3355.48,
        "temperature": 0,
        "text": " So two great points just came up in the chat right now.",
        "tokens": [
          50764,
          407,
          732,
          869,
          2793,
          445,
          1361,
          493,
          294,
          264,
          5081,
          558,
          586,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3358.48,
        "id": 998,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3357.48,
        "temperature": 0,
        "text": " One is...",
        "tokens": [
          50864,
          1485,
          307,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3360.48,
        "id": 999,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3358.48,
        "temperature": 0,
        "text": " Luke B. writes...",
        "tokens": [
          50914,
          13044,
          363,
          13,
          13657,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3364.48,
        "id": 1000,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3360.48,
        "temperature": 0,
        "text": " Pretty good to have the outliers to encourage prevention of overfitting the neural network.",
        "tokens": [
          51014,
          10693,
          665,
          281,
          362,
          264,
          484,
          23646,
          281,
          5373,
          14630,
          295,
          670,
          69,
          2414,
          264,
          18161,
          3209,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3366.48,
        "id": 1001,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3364.48,
        "temperature": 0,
        "text": " So this is actually true in...",
        "tokens": [
          51214,
          407,
          341,
          307,
          767,
          2074,
          294,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3370.48,
        "id": 1002,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3366.48,
        "temperature": 0,
        "text": " You know, one thing you have to watch out for is that your...",
        "tokens": [
          51314,
          509,
          458,
          11,
          472,
          551,
          291,
          362,
          281,
          1159,
          484,
          337,
          307,
          300,
          428,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3372.48,
        "id": 1003,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3371.48,
        "temperature": 0,
        "text": " Your model...",
        "tokens": [
          51564,
          2260,
          2316,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.20047503612080558,
        "compression_ratio": 1.6626984126984128,
        "end": 3375.48,
        "id": 1004,
        "no_speech_prob": 0.0003799779515247792,
        "seek": 334748,
        "start": 3372.48,
        "temperature": 0,
        "text": " The model that I'm going to train to do this color classification...",
        "tokens": [
          51614,
          440,
          2316,
          300,
          286,
          478,
          516,
          281,
          3847,
          281,
          360,
          341,
          2017,
          21538,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3381.48,
        "id": 1005,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3375.48,
        "temperature": 0,
        "text": " What if it just works so well with the training data that it doesn't work so well with new data?",
        "tokens": [
          50364,
          708,
          498,
          309,
          445,
          1985,
          370,
          731,
          365,
          264,
          3097,
          1412,
          300,
          309,
          1177,
          380,
          589,
          370,
          731,
          365,
          777,
          1412,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3384.48,
        "id": 1006,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3381.48,
        "temperature": 0,
        "text": " And having a bit of noise in the training data can actually help with that.",
        "tokens": [
          50664,
          400,
          1419,
          257,
          857,
          295,
          5658,
          294,
          264,
          3097,
          1412,
          393,
          767,
          854,
          365,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3387.48,
        "id": 1007,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3386.48,
        "temperature": 0,
        "text": " Another...",
        "tokens": [
          50914,
          3996,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3389.48,
        "id": 1008,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3388.48,
        "temperature": 0,
        "text": " Me, I am assuming, writes...",
        "tokens": [
          51014,
          1923,
          11,
          286,
          669,
          11926,
          11,
          13657,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3393.48,
        "id": 1009,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3389.48,
        "temperature": 0,
        "text": " Make it so clicking on a pixel prints who did it.",
        "tokens": [
          51064,
          4387,
          309,
          370,
          9697,
          322,
          257,
          19261,
          22305,
          567,
          630,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3395.48,
        "id": 1010,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3393.48,
        "temperature": 0,
        "text": " The user ID, that is.",
        "tokens": [
          51264,
          440,
          4195,
          7348,
          11,
          300,
          307,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3398.48,
        "id": 1011,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3395.48,
        "temperature": 0,
        "text": " And also maybe highlights all the other ones with the same user ID.",
        "tokens": [
          51364,
          400,
          611,
          1310,
          14254,
          439,
          264,
          661,
          2306,
          365,
          264,
          912,
          4195,
          7348,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3399.48,
        "id": 1012,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3398.48,
        "temperature": 0,
        "text": " That I love.",
        "tokens": [
          51514,
          663,
          286,
          959,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3400.48,
        "id": 1013,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3399.48,
        "temperature": 0,
        "text": " So let's add that.",
        "tokens": [
          51564,
          407,
          718,
          311,
          909,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3401.48,
        "id": 1014,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3400.48,
        "temperature": 0,
        "text": " That's going to be...",
        "tokens": [
          51614,
          663,
          311,
          516,
          281,
          312,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.1884225163146527,
        "compression_ratio": 1.7407407407407407,
        "end": 3403.48,
        "id": 1015,
        "no_speech_prob": 0.001345799770206213,
        "seek": 337548,
        "start": 3401.48,
        "temperature": 0,
        "text": " That's not going to be the easiest thing, but it's worth doing.",
        "tokens": [
          51664,
          663,
          311,
          406,
          516,
          281,
          312,
          264,
          12889,
          551,
          11,
          457,
          309,
          311,
          3163,
          884,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3405.48,
        "id": 1016,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3403.48,
        "temperature": 0,
        "text": " Let me see if I can add that.",
        "tokens": [
          50364,
          961,
          385,
          536,
          498,
          286,
          393,
          909,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3406.48,
        "id": 1017,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3405.48,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50464,
          407,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3408.48,
        "id": 1018,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3407.48,
        "temperature": 0,
        "text": " Okay, so...",
        "tokens": [
          50564,
          1033,
          11,
          370,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3410.48,
        "id": 1019,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3408.48,
        "temperature": 0,
        "text": " If I click the mouse...",
        "tokens": [
          50614,
          759,
          286,
          2052,
          264,
          9719,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3414.48,
        "id": 1020,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3413.48,
        "temperature": 0,
        "text": " Mouse pressed...",
        "tokens": [
          50864,
          29383,
          17355,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3416.48,
        "id": 1021,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3415.48,
        "temperature": 0,
        "text": " I can...",
        "tokens": [
          50964,
          286,
          393,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3418.48,
        "id": 1022,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3417.48,
        "temperature": 0,
        "text": " I can...",
        "tokens": [
          51064,
          286,
          393,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3419.48,
        "id": 1023,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3418.48,
        "temperature": 0,
        "text": " I can sort of...",
        "tokens": [
          51114,
          286,
          393,
          1333,
          295,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3420.48,
        "id": 1024,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3419.48,
        "temperature": 0,
        "text": " Like, I would be...",
        "tokens": [
          51164,
          1743,
          11,
          286,
          576,
          312,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3423.48,
        "id": 1025,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3421.48,
        "temperature": 0,
        "text": " In theory, mouse X divided by 10.",
        "tokens": [
          51264,
          682,
          5261,
          11,
          9719,
          1783,
          6666,
          538,
          1266,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3425.48,
        "id": 1026,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3424.48,
        "temperature": 0,
        "text": " And J would be...",
        "tokens": [
          51414,
          400,
          508,
          576,
          312,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3426.48,
        "id": 1027,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3425.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51464,
          1779,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3428.48,
        "id": 1028,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3427.48,
        "temperature": 0,
        "text": " This is where I'm clicking.",
        "tokens": [
          51564,
          639,
          307,
          689,
          286,
          478,
          9697,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3429.48,
        "id": 1029,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3428.48,
        "temperature": 0,
        "text": " I'm looking for the I and J.",
        "tokens": [
          51614,
          286,
          478,
          1237,
          337,
          264,
          286,
          293,
          508,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20749640249991202,
        "compression_ratio": 1.550561797752809,
        "end": 3430.48,
        "id": 1030,
        "no_speech_prob": 0.014503009617328644,
        "seek": 340348,
        "start": 3429.48,
        "temperature": 0,
        "text": " Not the X and Y.",
        "tokens": [
          51664,
          1726,
          264,
          1783,
          293,
          398,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3431.48,
        "id": 1031,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3430.48,
        "temperature": 0,
        "text": " Not the X and Y.",
        "tokens": [
          50364,
          1726,
          264,
          1783,
          293,
          398,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3433.48,
        "id": 1032,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3431.48,
        "temperature": 0,
        "text": " Sort of like the I and J of what I'm clicking on.",
        "tokens": [
          50414,
          26149,
          295,
          411,
          264,
          286,
          293,
          508,
          295,
          437,
          286,
          478,
          9697,
          322,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3435.48,
        "id": 1033,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3434.48,
        "temperature": 0,
        "text": " Mouse Y divided by 10.",
        "tokens": [
          50564,
          29383,
          398,
          6666,
          538,
          1266,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3439.48,
        "id": 1034,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3436.48,
        "temperature": 0,
        "text": " And then I should be able to get the index then by saying...",
        "tokens": [
          50664,
          400,
          550,
          286,
          820,
          312,
          1075,
          281,
          483,
          264,
          8186,
          550,
          538,
          1566,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3443.48,
        "id": 1035,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3440.48,
        "temperature": 0,
        "text": " I plus J times...",
        "tokens": [
          50864,
          286,
          1804,
          508,
          1413,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3445.48,
        "id": 1036,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3443.48,
        "temperature": 0,
        "text": " And then the width divided by 10.",
        "tokens": [
          51014,
          400,
          550,
          264,
          11402,
          6666,
          538,
          1266,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3446.48,
        "id": 1037,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3445.48,
        "temperature": 0,
        "text": " Again...",
        "tokens": [
          51114,
          3764,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3451.48,
        "id": 1038,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3447.48,
        "temperature": 0,
        "text": " I really, really, really should be using variables for these numbers.",
        "tokens": [
          51214,
          286,
          534,
          11,
          534,
          11,
          534,
          820,
          312,
          1228,
          9102,
          337,
          613,
          3547,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3452.48,
        "id": 1039,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3451.48,
        "temperature": 0,
        "text": " Like 10.",
        "tokens": [
          51414,
          1743,
          1266,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3453.48,
        "id": 1040,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3452.48,
        "temperature": 0,
        "text": " And putting in...",
        "tokens": [
          51464,
          400,
          3372,
          294,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3457.48,
        "id": 1041,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3455.48,
        "temperature": 0,
        "text": " Like variables for columns and rows.",
        "tokens": [
          51614,
          1743,
          9102,
          337,
          13766,
          293,
          13241,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2088713241835772,
        "compression_ratio": 1.6666666666666667,
        "end": 3458.48,
        "id": 1042,
        "no_speech_prob": 0.025563659146428108,
        "seek": 343048,
        "start": 3457.48,
        "temperature": 0,
        "text": " But let's just try this right now.",
        "tokens": [
          51714,
          583,
          718,
          311,
          445,
          853,
          341,
          558,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3461.48,
        "id": 1043,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3458.48,
        "temperature": 0,
        "text": " Let's try then saying console.log.",
        "tokens": [
          50364,
          961,
          311,
          853,
          550,
          1566,
          11076,
          13,
          4987,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3463.48,
        "id": 1044,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3462.48,
        "temperature": 0,
        "text": " And so let me make a...",
        "tokens": [
          50564,
          400,
          370,
          718,
          385,
          652,
          257,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3468.48,
        "id": 1045,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3467.48,
        "temperature": 0,
        "text": " I'm going to call this...",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          818,
          341,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3470.48,
        "id": 1046,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3469.48,
        "temperature": 0,
        "text": " Color...",
        "tokens": [
          50914,
          10458,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3471.48,
        "id": 1047,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3470.48,
        "temperature": 0,
        "text": " I'm going to call this, like, label.",
        "tokens": [
          50964,
          286,
          478,
          516,
          281,
          818,
          341,
          11,
          411,
          11,
          7645,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3472.48,
        "id": 1048,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3471.48,
        "temperature": 0,
        "text": " I'm just going to call this label.",
        "tokens": [
          51014,
          286,
          478,
          445,
          516,
          281,
          818,
          341,
          7645,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3473.48,
        "id": 1049,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3472.48,
        "temperature": 0,
        "text": " And I'm going to...",
        "tokens": [
          51064,
          400,
          286,
          478,
          516,
          281,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3476.48,
        "id": 1050,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3473.48,
        "temperature": 0,
        "text": " Let's go with bluish to start again.",
        "tokens": [
          51114,
          961,
          311,
          352,
          365,
          888,
          33786,
          281,
          722,
          797,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3479.48,
        "id": 1051,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3477.48,
        "temperature": 0,
        "text": " So I'm going to use here...",
        "tokens": [
          51314,
          407,
          286,
          478,
          516,
          281,
          764,
          510,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3482.48,
        "id": 1052,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3481.48,
        "temperature": 0,
        "text": " Color by label.",
        "tokens": [
          51514,
          10458,
          538,
          7645,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18986522674560546,
        "compression_ratio": 1.7843137254901962,
        "end": 3484.48,
        "id": 1053,
        "no_speech_prob": 0.0006771759362891316,
        "seek": 345848,
        "start": 3483.48,
        "temperature": 0,
        "text": " Label.",
        "tokens": [
          51614,
          10137,
          338,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3488.48,
        "id": 1054,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3485.48,
        "temperature": 0,
        "text": " And let's make color by label...",
        "tokens": [
          50414,
          400,
          718,
          311,
          652,
          2017,
          538,
          7645,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3490.48,
        "id": 1055,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3488.48,
        "temperature": 0,
        "text": " Color by label already is a global variable.",
        "tokens": [
          50564,
          10458,
          538,
          7645,
          1217,
          307,
          257,
          4338,
          7006,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3493.48,
        "id": 1056,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3491.48,
        "temperature": 0,
        "text": " So I'm going to say console.log...",
        "tokens": [
          50714,
          407,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3494.48,
        "id": 1057,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3493.48,
        "temperature": 0,
        "text": " Okay, so...",
        "tokens": [
          50814,
          1033,
          11,
          370,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3500.48,
        "id": 1058,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3496.48,
        "temperature": 0,
        "text": " Let data equal color by label.",
        "tokens": [
          50964,
          961,
          1412,
          2681,
          2017,
          538,
          7645,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3502.48,
        "id": 1059,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3501.48,
        "temperature": 0,
        "text": " That label.",
        "tokens": [
          51214,
          663,
          7645,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3507.48,
        "id": 1060,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3505.48,
        "temperature": 0,
        "text": " And then I should be able to console.log...",
        "tokens": [
          51414,
          400,
          550,
          286,
          820,
          312,
          1075,
          281,
          11076,
          13,
          4987,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3510.48,
        "id": 1061,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3509.48,
        "temperature": 0,
        "text": " Data.",
        "tokens": [
          51614,
          11888,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18505065064681203,
        "compression_ratio": 1.5033557046979866,
        "end": 3513.48,
        "id": 1062,
        "no_speech_prob": 0.013427476398646832,
        "seek": 348448,
        "start": 3512.48,
        "temperature": 0,
        "text": " Index.",
        "tokens": [
          51764,
          33552,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3514.48,
        "id": 1063,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3513.48,
        "temperature": 0,
        "text": " I think this will be right.",
        "tokens": [
          50364,
          286,
          519,
          341,
          486,
          312,
          558,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3516.48,
        "id": 1064,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3514.48,
        "temperature": 0,
        "text": " I might have made some mistakes here.",
        "tokens": [
          50414,
          286,
          1062,
          362,
          1027,
          512,
          8038,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3518.48,
        "id": 1065,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3517.48,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50564,
          961,
          311,
          536,
          437,
          2314,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3521.48,
        "id": 1066,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3520.48,
        "temperature": 0,
        "text": " Alright, let me click here.",
        "tokens": [
          50714,
          2798,
          11,
          718,
          385,
          2052,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3523.48,
        "id": 1067,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3522.48,
        "temperature": 0,
        "text": " Alright, so I got something.",
        "tokens": [
          50814,
          2798,
          11,
          370,
          286,
          658,
          746,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3526.48,
        "id": 1068,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3525.48,
        "temperature": 0,
        "text": " Oh, ugh.",
        "tokens": [
          50964,
          876,
          11,
          38560,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3530.48,
        "id": 1069,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3526.48,
        "temperature": 0,
        "text": " So one thing that's kind of unfortunate is...",
        "tokens": [
          51014,
          407,
          472,
          551,
          300,
          311,
          733,
          295,
          17843,
          307,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3533.48,
        "id": 1070,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3532.48,
        "temperature": 0,
        "text": " Oh, I don't have the user ID.",
        "tokens": [
          51314,
          876,
          11,
          286,
          500,
          380,
          362,
          264,
          4195,
          7348,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3534.48,
        "id": 1071,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3533.48,
        "temperature": 0,
        "text": " Ah, I don't have the user...",
        "tokens": [
          51364,
          2438,
          11,
          286,
          500,
          380,
          362,
          264,
          4195,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3536.48,
        "id": 1072,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3534.48,
        "temperature": 0,
        "text": " So I got the color...",
        "tokens": [
          51414,
          407,
          286,
          658,
          264,
          2017,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3540.48,
        "id": 1073,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3537.48,
        "temperature": 0,
        "text": " But I'm not actually storing the full data thing.",
        "tokens": [
          51564,
          583,
          286,
          478,
          406,
          767,
          26085,
          264,
          1577,
          1412,
          551,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3541.48,
        "id": 1074,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3540.48,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51714,
          876,
          11,
          1338,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1942458230941022,
        "compression_ratio": 1.6559633027522935,
        "end": 3542.48,
        "id": 1075,
        "no_speech_prob": 0.0005976494867354631,
        "seek": 351348,
        "start": 3541.48,
        "temperature": 0,
        "text": " So color by label.",
        "tokens": [
          51764,
          407,
          2017,
          538,
          7645,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16108790196870504,
        "compression_ratio": 1.5783132530120483,
        "end": 3543.48,
        "id": 1076,
        "no_speech_prob": 0.0001852246350608766,
        "seek": 354248,
        "start": 3542.48,
        "temperature": 0,
        "text": " This is what I need to do.",
        "tokens": [
          50364,
          639,
          307,
          437,
          286,
          643,
          281,
          360,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16108790196870504,
        "compression_ratio": 1.5783132530120483,
        "end": 3546.48,
        "id": 1077,
        "no_speech_prob": 0.0001852246350608766,
        "seek": 354248,
        "start": 3543.48,
        "temperature": 0,
        "text": " I want color by label actually to store the whole record.",
        "tokens": [
          50414,
          286,
          528,
          2017,
          538,
          7645,
          767,
          281,
          3531,
          264,
          1379,
          2136,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16108790196870504,
        "compression_ratio": 1.5783132530120483,
        "end": 3549.48,
        "id": 1078,
        "no_speech_prob": 0.0001852246350608766,
        "seek": 354248,
        "start": 3548.48,
        "temperature": 0,
        "text": " We don't actually want to store the color.",
        "tokens": [
          50664,
          492,
          500,
          380,
          767,
          528,
          281,
          3531,
          264,
          2017,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16108790196870504,
        "compression_ratio": 1.5783132530120483,
        "end": 3550.48,
        "id": 1079,
        "no_speech_prob": 0.0001852246350608766,
        "seek": 354248,
        "start": 3549.48,
        "temperature": 0,
        "text": " Let's store the whole record.",
        "tokens": [
          50714,
          961,
          311,
          3531,
          264,
          1379,
          2136,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16108790196870504,
        "compression_ratio": 1.5783132530120483,
        "end": 3552.48,
        "id": 1080,
        "no_speech_prob": 0.0001852246350608766,
        "seek": 354248,
        "start": 3550.48,
        "temperature": 0,
        "text": " Then when I visualize it...",
        "tokens": [
          50764,
          1396,
          562,
          286,
          23273,
          309,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.16108790196870504,
        "compression_ratio": 1.5783132530120483,
        "end": 3557.48,
        "id": 1081,
        "no_speech_prob": 0.0001852246350608766,
        "seek": 354248,
        "start": 3554.48,
        "temperature": 0,
        "text": " I can just ask for the RGB values.",
        "tokens": [
          50964,
          286,
          393,
          445,
          1029,
          337,
          264,
          31231,
          4190,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16108790196870504,
        "compression_ratio": 1.5783132530120483,
        "end": 3570.48,
        "id": 1082,
        "no_speech_prob": 0.0001852246350608766,
        "seek": 354248,
        "start": 3567.48,
        "temperature": 0,
        "text": " Because then when I click on something...",
        "tokens": [
          51614,
          1436,
          550,
          562,
          286,
          2052,
          322,
          746,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3572.48,
        "id": 1083,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3571.48,
        "temperature": 0,
        "text": " This is now that entry.",
        "tokens": [
          50414,
          639,
          307,
          586,
          300,
          8729,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3574.48,
        "id": 1084,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3573.48,
        "temperature": 0,
        "text": " So I can see...",
        "tokens": [
          50514,
          407,
          286,
          393,
          536,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3575.48,
        "id": 1085,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3574.48,
        "temperature": 0,
        "text": " If I click on this...",
        "tokens": [
          50564,
          759,
          286,
          2052,
          322,
          341,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3578.48,
        "id": 1086,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3577.48,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50714,
          2053,
          412,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3579.48,
        "id": 1087,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3578.48,
        "temperature": 0,
        "text": " This user...",
        "tokens": [
          50764,
          639,
          4195,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3581.48,
        "id": 1088,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3579.48,
        "temperature": 0,
        "text": " I'm clicking on these.",
        "tokens": [
          50814,
          286,
          478,
          9697,
          322,
          613,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3583.48,
        "id": 1089,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3581.48,
        "temperature": 0,
        "text": " They're all the same user.",
        "tokens": [
          50914,
          814,
          434,
          439,
          264,
          912,
          4195,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3588.48,
        "id": 1090,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3583.48,
        "temperature": 0,
        "text": " This user YGDQ seems to have some faulty data.",
        "tokens": [
          51014,
          639,
          4195,
          398,
          38,
          35,
          48,
          2544,
          281,
          362,
          512,
          2050,
          5773,
          1412,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3590.48,
        "id": 1091,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3588.48,
        "temperature": 0,
        "text": " So I could filter out this user.",
        "tokens": [
          51264,
          407,
          286,
          727,
          6608,
          484,
          341,
          4195,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3593.48,
        "id": 1092,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3590.48,
        "temperature": 0,
        "text": " I could do something nice where as I'm hovering, I highlight everything.",
        "tokens": [
          51364,
          286,
          727,
          360,
          746,
          1481,
          689,
          382,
          286,
          478,
          44923,
          11,
          286,
          5078,
          1203,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3595.48,
        "id": 1093,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3593.48,
        "temperature": 0,
        "text": " But I think I'm not going to go that far.",
        "tokens": [
          51514,
          583,
          286,
          519,
          286,
          478,
          406,
          516,
          281,
          352,
          300,
          1400,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3597.48,
        "id": 1094,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3595.48,
        "temperature": 0,
        "text": " I'll let anybody who wants to contribute...",
        "tokens": [
          51614,
          286,
          603,
          718,
          4472,
          567,
          2738,
          281,
          10586,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.2024774124373251,
        "compression_ratio": 1.685483870967742,
        "end": 3599.48,
        "id": 1095,
        "no_speech_prob": 0.0006563591305166483,
        "seek": 357048,
        "start": 3597.48,
        "temperature": 0,
        "text": " I'll let you try that on your own maybe.",
        "tokens": [
          51714,
          286,
          603,
          718,
          291,
          853,
          300,
          322,
          428,
          1065,
          1310,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3605.48,
        "id": 1096,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3599.48,
        "temperature": 0,
        "text": " So let me make a list here of users that I might want to filter out.",
        "tokens": [
          50364,
          407,
          718,
          385,
          652,
          257,
          1329,
          510,
          295,
          5022,
          300,
          286,
          1062,
          528,
          281,
          6608,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3610.48,
        "id": 1097,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3607.48,
        "temperature": 0,
        "text": " Whether I'm happy to have the noise or not, that's a question.",
        "tokens": [
          50764,
          8503,
          286,
          478,
          2055,
          281,
          362,
          264,
          5658,
          420,
          406,
          11,
          300,
          311,
          257,
          1168,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3611.48,
        "id": 1098,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3610.48,
        "temperature": 0,
        "text": " But let's...",
        "tokens": [
          50914,
          583,
          718,
          311,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3617.48,
        "id": 1099,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3615.48,
        "temperature": 0,
        "text": " Let me just make this a little smaller.",
        "tokens": [
          51164,
          961,
          385,
          445,
          652,
          341,
          257,
          707,
          4356,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3620.48,
        "id": 1100,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3617.48,
        "temperature": 0,
        "text": " It's a little harder for you to see it, but I think it's going to be easier in terms of space.",
        "tokens": [
          51264,
          467,
          311,
          257,
          707,
          6081,
          337,
          291,
          281,
          536,
          309,
          11,
          457,
          286,
          519,
          309,
          311,
          516,
          281,
          312,
          3571,
          294,
          2115,
          295,
          1901,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3625.48,
        "id": 1101,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3621.48,
        "temperature": 0,
        "text": " So let's look at a few more that are maybe clearly not good.",
        "tokens": [
          51464,
          407,
          718,
          311,
          574,
          412,
          257,
          1326,
          544,
          300,
          366,
          1310,
          4448,
          406,
          665,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3626.48,
        "id": 1102,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3625.48,
        "temperature": 0,
        "text": " Same user.",
        "tokens": [
          51664,
          10635,
          4195,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20306127113208436,
        "compression_ratio": 1.6,
        "end": 3628.48,
        "id": 1103,
        "no_speech_prob": 0.00019109869026578963,
        "seek": 359948,
        "start": 3626.48,
        "temperature": 0,
        "text": " It's all that same user.",
        "tokens": [
          51714,
          467,
          311,
          439,
          300,
          912,
          4195,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3629.48,
        "id": 1104,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3628.48,
        "temperature": 0,
        "text": " I haven't found the...",
        "tokens": [
          50364,
          286,
          2378,
          380,
          1352,
          264,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3630.48,
        "id": 1105,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3629.48,
        "temperature": 0,
        "text": " Let's look up here.",
        "tokens": [
          50414,
          961,
          311,
          574,
          493,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3631.48,
        "id": 1106,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3630.48,
        "temperature": 0,
        "text": " Ah, different user.",
        "tokens": [
          50464,
          2438,
          11,
          819,
          4195,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3637.48,
        "id": 1107,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3634.48,
        "temperature": 0,
        "text": " So this user also looks like it maybe has some bad data.",
        "tokens": [
          50664,
          407,
          341,
          4195,
          611,
          1542,
          411,
          309,
          1310,
          575,
          512,
          1578,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3639.48,
        "id": 1108,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3638.48,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50864,
          21726,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3645.48,
        "id": 1109,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3643.48,
        "temperature": 0,
        "text": " Let's look at a different color.",
        "tokens": [
          51114,
          961,
          311,
          574,
          412,
          257,
          819,
          2017,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3649.48,
        "id": 1110,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3646.48,
        "temperature": 0,
        "text": " Let's look at what was like there was very little of.",
        "tokens": [
          51264,
          961,
          311,
          574,
          412,
          437,
          390,
          411,
          456,
          390,
          588,
          707,
          295,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24355269767142632,
        "compression_ratio": 1.5034013605442176,
        "end": 3651.48,
        "id": 1111,
        "no_speech_prob": 0.00004069385613547638,
        "seek": 362848,
        "start": 3649.48,
        "temperature": 0,
        "text": " Grayish.",
        "tokens": [
          51414,
          22668,
          742,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3653.48,
        "id": 1112,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3652.48,
        "temperature": 0,
        "text": " That's...",
        "tokens": [
          50414,
          663,
          311,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3655.48,
        "id": 1113,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3653.48,
        "temperature": 0,
        "text": " This user is now suspect.",
        "tokens": [
          50464,
          639,
          4195,
          307,
          586,
          9091,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3662.48,
        "id": 1114,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3660.48,
        "temperature": 0,
        "text": " You know, the thing is, a user might have misclicked.",
        "tokens": [
          50814,
          509,
          458,
          11,
          264,
          551,
          307,
          11,
          257,
          4195,
          1062,
          362,
          3346,
          3474,
          12598,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3664.48,
        "id": 1115,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3662.48,
        "temperature": 0,
        "text": " So unless I see it consistently...",
        "tokens": [
          50914,
          407,
          5969,
          286,
          536,
          309,
          14961,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3667.48,
        "id": 1116,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3665.48,
        "temperature": 0,
        "text": " Yeah, I'm not going to...",
        "tokens": [
          51064,
          865,
          11,
          286,
          478,
          406,
          516,
          281,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3673.48,
        "id": 1117,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3671.48,
        "temperature": 0,
        "text": " A user could have misclicked.",
        "tokens": [
          51364,
          316,
          4195,
          727,
          362,
          3346,
          3474,
          12598,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3674.48,
        "id": 1118,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3673.48,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51464,
          2798,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3676.48,
        "id": 1119,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3674.48,
        "temperature": 0,
        "text": " So you get the idea.",
        "tokens": [
          51514,
          407,
          291,
          483,
          264,
          1558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3677.48,
        "id": 1120,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3676.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2632038917070554,
        "compression_ratio": 1.4322580645161291,
        "end": 3678.48,
        "id": 1121,
        "no_speech_prob": 0.001573063200339675,
        "seek": 365148,
        "start": 3677.48,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          51664,
          407,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3679.48,
        "id": 1122,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3678.48,
        "temperature": 0,
        "text": " You get the idea.",
        "tokens": [
          50364,
          509,
          483,
          264,
          1558,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3682.48,
        "id": 1123,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3679.48,
        "temperature": 0,
        "text": " Now, there's so many ways that I could be more thoughtful about this",
        "tokens": [
          50414,
          823,
          11,
          456,
          311,
          370,
          867,
          2098,
          300,
          286,
          727,
          312,
          544,
          21566,
          466,
          341,
          50564
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3685.48,
        "id": 1124,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3682.48,
        "temperature": 0,
        "text": " and add more features to work on cleaning the data.",
        "tokens": [
          50564,
          293,
          909,
          544,
          4122,
          281,
          589,
          322,
          8924,
          264,
          1412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3687.48,
        "id": 1125,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3685.48,
        "temperature": 0,
        "text": " But let's just say for right now...",
        "tokens": [
          50714,
          583,
          718,
          311,
          445,
          584,
          337,
          558,
          586,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3691.48,
        "id": 1126,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3688.48,
        "temperature": 0,
        "text": " And people are suggesting, like, I could algorithmically...",
        "tokens": [
          50864,
          400,
          561,
          366,
          18094,
          11,
          411,
          11,
          286,
          727,
          9284,
          984,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3694.48,
        "id": 1127,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3691.48,
        "temperature": 0,
        "text": " I could actually evaluate the numbers and see...",
        "tokens": [
          51014,
          286,
          727,
          767,
          13059,
          264,
          3547,
          293,
          536,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3697.48,
        "id": 1128,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3694.48,
        "temperature": 0,
        "text": " Like, compute the hue and see if the hue matches the label.",
        "tokens": [
          51164,
          1743,
          11,
          14722,
          264,
          24967,
          293,
          536,
          498,
          264,
          24967,
          10676,
          264,
          7645,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3698.48,
        "id": 1129,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3697.48,
        "temperature": 0,
        "text": " But I don't...",
        "tokens": [
          51314,
          583,
          286,
          500,
          380,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3700.48,
        "id": 1130,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3698.48,
        "temperature": 0,
        "text": " I specifically do not want to do that.",
        "tokens": [
          51364,
          286,
          4682,
          360,
          406,
          528,
          281,
          360,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.271968753521259,
        "compression_ratio": 1.7118055555555556,
        "end": 3705.48,
        "id": 1131,
        "no_speech_prob": 0.006289599929004908,
        "seek": 367848,
        "start": 3700.48,
        "temperature": 0,
        "text": " Because what I specifically want from this is this idea of human perception of what's going on.",
        "tokens": [
          51464,
          1436,
          437,
          286,
          4682,
          528,
          490,
          341,
          307,
          341,
          1558,
          295,
          1952,
          12860,
          295,
          437,
          311,
          516,
          322,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3708.48,
        "id": 1132,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3705.48,
        "temperature": 0,
        "text": " What I specifically want from this is this idea of human perception of color.",
        "tokens": [
          50364,
          708,
          286,
          4682,
          528,
          490,
          341,
          307,
          341,
          1558,
          295,
          1952,
          12860,
          295,
          2017,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3710.48,
        "id": 1133,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3708.48,
        "temperature": 0,
        "text": " And I don't want to use math.",
        "tokens": [
          50514,
          400,
          286,
          500,
          380,
          528,
          281,
          764,
          5221,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3712.48,
        "id": 1134,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3710.48,
        "temperature": 0,
        "text": " Because I could create my own data set with math.",
        "tokens": [
          50614,
          1436,
          286,
          727,
          1884,
          452,
          1065,
          1412,
          992,
          365,
          5221,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3715.48,
        "id": 1135,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3712.48,
        "temperature": 0,
        "text": " Of, like, putting colors into certain buckets.",
        "tokens": [
          50714,
          2720,
          11,
          411,
          11,
          3372,
          4577,
          666,
          1629,
          32191,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3717.48,
        "id": 1136,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3715.48,
        "temperature": 0,
        "text": " And in a way, I don't even want to do what I just did right here.",
        "tokens": [
          50864,
          400,
          294,
          257,
          636,
          11,
          286,
          500,
          380,
          754,
          528,
          281,
          360,
          437,
          286,
          445,
          630,
          558,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3719.48,
        "id": 1137,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3717.48,
        "temperature": 0,
        "text": " Which is eliminate certain users.",
        "tokens": [
          50964,
          3013,
          307,
          13819,
          1629,
          5022,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3721.48,
        "id": 1138,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3719.48,
        "temperature": 0,
        "text": " And I probably should just visualize...",
        "tokens": [
          51064,
          400,
          286,
          1391,
          820,
          445,
          23273,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3724.48,
        "id": 1139,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3721.48,
        "temperature": 0,
        "text": " What I should do with these users now is...",
        "tokens": [
          51164,
          708,
          286,
          820,
          360,
          365,
          613,
          5022,
          586,
          307,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3726.48,
        "id": 1140,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3724.48,
        "temperature": 0,
        "text": " Actually, let me do this.",
        "tokens": [
          51314,
          5135,
          11,
          718,
          385,
          360,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3731.48,
        "id": 1141,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3726.48,
        "temperature": 0,
        "text": " What I'm going to do with these users now is I'm actually just going to look at all of their entries.",
        "tokens": [
          51414,
          708,
          286,
          478,
          516,
          281,
          360,
          365,
          613,
          5022,
          586,
          307,
          286,
          478,
          767,
          445,
          516,
          281,
          574,
          412,
          439,
          295,
          641,
          23041,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3732.48,
        "id": 1142,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3731.48,
        "temperature": 0,
        "text": " And see.",
        "tokens": [
          51664,
          400,
          536,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1743428054129242,
        "compression_ratio": 1.7955271565495208,
        "end": 3734.48,
        "id": 1143,
        "no_speech_prob": 0.12419254332780838,
        "seek": 370548,
        "start": 3732.48,
        "temperature": 0,
        "text": " So let's add that as one more thing.",
        "tokens": [
          51714,
          407,
          718,
          311,
          909,
          300,
          382,
          472,
          544,
          551,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3736.48,
        "id": 1144,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3734.48,
        "temperature": 0,
        "text": " You can stop watching this video and just go on.",
        "tokens": [
          50364,
          509,
          393,
          1590,
          1976,
          341,
          960,
          293,
          445,
          352,
          322,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3738.48,
        "id": 1145,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3736.48,
        "temperature": 0,
        "text": " Because I'm going to build a machine learning model in future videos.",
        "tokens": [
          50464,
          1436,
          286,
          478,
          516,
          281,
          1322,
          257,
          3479,
          2539,
          2316,
          294,
          2027,
          2145,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3740.48,
        "id": 1146,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3738.48,
        "temperature": 0,
        "text": " But if you want to keep watching, I'm going to do...",
        "tokens": [
          50564,
          583,
          498,
          291,
          528,
          281,
          1066,
          1976,
          11,
          286,
          478,
          516,
          281,
          360,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3741.48,
        "id": 1147,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3740.48,
        "temperature": 0,
        "text": " Let's do one more thing.",
        "tokens": [
          50664,
          961,
          311,
          360,
          472,
          544,
          551,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3743.48,
        "id": 1148,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3741.48,
        "temperature": 0,
        "text": " Like, let's take this user.",
        "tokens": [
          50714,
          1743,
          11,
          718,
          311,
          747,
          341,
          4195,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3749.48,
        "id": 1149,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3743.48,
        "temperature": 0,
        "text": " And what I'm going to do now is...",
        "tokens": [
          50814,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          307,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3755.48,
        "id": 1150,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3749.48,
        "temperature": 0,
        "text": " I'm going to comment out this drawing thing that I'm doing.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          2871,
          484,
          341,
          6316,
          551,
          300,
          286,
          478,
          884,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16735593555043043,
        "compression_ratio": 1.7164179104477613,
        "end": 3760.48,
        "id": 1151,
        "no_speech_prob": 0.0037071858532726765,
        "seek": 373448,
        "start": 3755.48,
        "temperature": 0,
        "text": " And I want to create a...",
        "tokens": [
          51414,
          400,
          286,
          528,
          281,
          1884,
          257,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.20686208284818208,
        "compression_ratio": 1.4201680672268908,
        "end": 3767.48,
        "id": 1152,
        "no_speech_prob": 0.0037653616163879633,
        "seek": 376048,
        "start": 3761.48,
        "temperature": 0,
        "text": " I want to say color data by user.",
        "tokens": [
          50414,
          286,
          528,
          281,
          584,
          2017,
          1412,
          538,
          4195,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20686208284818208,
        "compression_ratio": 1.4201680672268908,
        "end": 3771.48,
        "id": 1153,
        "no_speech_prob": 0.0037653616163879633,
        "seek": 376048,
        "start": 3767.48,
        "temperature": 0,
        "text": " And I'm going to make that an array.",
        "tokens": [
          50714,
          400,
          286,
          478,
          516,
          281,
          652,
          300,
          364,
          10225,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20686208284818208,
        "compression_ratio": 1.4201680672268908,
        "end": 3781.48,
        "id": 1154,
        "no_speech_prob": 0.0037653616163879633,
        "seek": 376048,
        "start": 3771.48,
        "temperature": 0,
        "text": " And I just want to say if record user ID equals a particular user...",
        "tokens": [
          50914,
          400,
          286,
          445,
          528,
          281,
          584,
          498,
          2136,
          4195,
          7348,
          6915,
          257,
          1729,
          4195,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.20686208284818208,
        "compression_ratio": 1.4201680672268908,
        "end": 3789.48,
        "id": 1155,
        "no_speech_prob": 0.0037653616163879633,
        "seek": 376048,
        "start": 3781.48,
        "temperature": 0,
        "text": " Then I want to say user data.",
        "tokens": [
          51414,
          1396,
          286,
          528,
          281,
          584,
          4195,
          1412,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3791.48,
        "id": 1156,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3789.48,
        "temperature": 0,
        "text": " And I could build an interface to do all this.",
        "tokens": [
          50364,
          400,
          286,
          727,
          1322,
          364,
          9226,
          281,
          360,
          439,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3792.48,
        "id": 1157,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3791.48,
        "temperature": 0,
        "text": " It would be so much better.",
        "tokens": [
          50464,
          467,
          576,
          312,
          370,
          709,
          1101,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3796.48,
        "id": 1158,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3792.48,
        "temperature": 0,
        "text": " But I don't really have time to do all that in this particular series.",
        "tokens": [
          50514,
          583,
          286,
          500,
          380,
          534,
          362,
          565,
          281,
          360,
          439,
          300,
          294,
          341,
          1729,
          2638,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3798.48,
        "id": 1159,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3796.48,
        "temperature": 0,
        "text": " So that might be an exercise to do for yourself.",
        "tokens": [
          50714,
          407,
          300,
          1062,
          312,
          364,
          5380,
          281,
          360,
          337,
          1803,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3803.48,
        "id": 1160,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3798.48,
        "temperature": 0,
        "text": " User data dot push the record.",
        "tokens": [
          50814,
          32127,
          1412,
          5893,
          2944,
          264,
          2136,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3808.48,
        "id": 1161,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3803.48,
        "temperature": 0,
        "text": " And then down here I could use this exact same algorithm.",
        "tokens": [
          51064,
          400,
          550,
          760,
          510,
          286,
          727,
          764,
          341,
          1900,
          912,
          9284,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3809.48,
        "id": 1162,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3808.48,
        "temperature": 0,
        "text": " But you know what?",
        "tokens": [
          51314,
          583,
          291,
          458,
          437,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3810.48,
        "id": 1163,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3809.48,
        "temperature": 0,
        "text": " I don't want to do it this way.",
        "tokens": [
          51364,
          286,
          500,
          380,
          528,
          281,
          360,
          309,
          341,
          636,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3811.48,
        "id": 1164,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3810.48,
        "temperature": 0,
        "text": " What I want to do...",
        "tokens": [
          51414,
          708,
          286,
          528,
          281,
          360,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3812.48,
        "id": 1165,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3811.48,
        "temperature": 0,
        "text": " I'm going to use DOM elements now.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          764,
          35727,
          4959,
          586,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20835477113723755,
        "compression_ratio": 1.6771653543307086,
        "end": 3817.48,
        "id": 1166,
        "no_speech_prob": 0.0316169448196888,
        "seek": 378948,
        "start": 3812.48,
        "temperature": 0,
        "text": " I think I'm going to say for let...",
        "tokens": [
          51514,
          286,
          519,
          286,
          478,
          516,
          281,
          584,
          337,
          718,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.2654380248143123,
        "compression_ratio": 1.38,
        "end": 3823.48,
        "id": 1167,
        "no_speech_prob": 0.005301781930029392,
        "seek": 381748,
        "start": 3817.48,
        "temperature": 0,
        "text": " Color for let entry.",
        "tokens": [
          50364,
          10458,
          337,
          718,
          8729,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2654380248143123,
        "compression_ratio": 1.38,
        "end": 3828.48,
        "id": 1168,
        "no_speech_prob": 0.005301781930029392,
        "seek": 381748,
        "start": 3823.48,
        "temperature": 0,
        "text": " So entry of user data.",
        "tokens": [
          50664,
          407,
          8729,
          295,
          4195,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2654380248143123,
        "compression_ratio": 1.38,
        "end": 3835.48,
        "id": 1169,
        "no_speech_prob": 0.005301781930029392,
        "seek": 381748,
        "start": 3828.48,
        "temperature": 0,
        "text": " I'm going to say create div.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          584,
          1884,
          3414,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2654380248143123,
        "compression_ratio": 1.38,
        "end": 3836.48,
        "id": 1170,
        "no_speech_prob": 0.005301781930029392,
        "seek": 381748,
        "start": 3835.48,
        "temperature": 0,
        "text": " I'm going to just make a div.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          445,
          652,
          257,
          3414,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2654380248143123,
        "compression_ratio": 1.38,
        "end": 3842.48,
        "id": 1171,
        "no_speech_prob": 0.005301781930029392,
        "seek": 381748,
        "start": 3836.48,
        "temperature": 0,
        "text": " And then I'm going to say...",
        "tokens": [
          51314,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.2654380248143123,
        "compression_ratio": 1.38,
        "end": 3843.48,
        "id": 1172,
        "no_speech_prob": 0.005301781930029392,
        "seek": 381748,
        "start": 3842.48,
        "temperature": 0,
        "text": " Div...",
        "tokens": [
          51614,
          9886,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3848.48,
        "id": 1173,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3844.48,
        "temperature": 0,
        "text": " And actually let me create a div with entry dot label in it.",
        "tokens": [
          50414,
          400,
          767,
          718,
          385,
          1884,
          257,
          3414,
          365,
          8729,
          5893,
          7645,
          294,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3852.48,
        "id": 1174,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3848.48,
        "temperature": 0,
        "text": " So let's just try this.",
        "tokens": [
          50614,
          407,
          718,
          311,
          445,
          853,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3853.48,
        "id": 1175,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3852.48,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50814,
          45263,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3855.48,
        "id": 1176,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3853.48,
        "temperature": 0,
        "text": " Not the string.",
        "tokens": [
          50864,
          1726,
          264,
          6798,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3862.48,
        "id": 1177,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3855.48,
        "temperature": 0,
        "text": " And let me get rid of the canvas.",
        "tokens": [
          50964,
          400,
          718,
          385,
          483,
          3973,
          295,
          264,
          16267,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3865.48,
        "id": 1178,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3862.48,
        "temperature": 0,
        "text": " So these are all...",
        "tokens": [
          51314,
          407,
          613,
          366,
          439,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3868.48,
        "id": 1179,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3865.48,
        "temperature": 0,
        "text": " These are all of this particular user's entries.",
        "tokens": [
          51464,
          1981,
          366,
          439,
          295,
          341,
          1729,
          4195,
          311,
          23041,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20527312630101255,
        "compression_ratio": 1.4491017964071857,
        "end": 3870.48,
        "id": 1180,
        "no_speech_prob": 0.2909415662288666,
        "seek": 384348,
        "start": 3868.48,
        "temperature": 0,
        "text": " Maybe I should sort them by...",
        "tokens": [
          51614,
          2704,
          286,
          820,
          1333,
          552,
          538,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.21871120589120047,
        "compression_ratio": 1.3962264150943395,
        "end": 3873.48,
        "id": 1181,
        "no_speech_prob": 0.11123402416706085,
        "seek": 387048,
        "start": 3870.48,
        "temperature": 0,
        "text": " Let's sort them by the label.",
        "tokens": [
          50364,
          961,
          311,
          1333,
          552,
          538,
          264,
          7645,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21871120589120047,
        "compression_ratio": 1.3962264150943395,
        "end": 3877.48,
        "id": 1182,
        "no_speech_prob": 0.11123402416706085,
        "seek": 387048,
        "start": 3873.48,
        "temperature": 0,
        "text": " So let's...",
        "tokens": [
          50514,
          407,
          718,
          311,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.21871120589120047,
        "compression_ratio": 1.3962264150943395,
        "end": 3880.48,
        "id": 1183,
        "no_speech_prob": 0.11123402416706085,
        "seek": 387048,
        "start": 3877.48,
        "temperature": 0,
        "text": " So let's say user data.",
        "tokens": [
          50714,
          407,
          718,
          311,
          584,
          4195,
          1412,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21871120589120047,
        "compression_ratio": 1.3962264150943395,
        "end": 3886.48,
        "id": 1184,
        "no_speech_prob": 0.11123402416706085,
        "seek": 387048,
        "start": 3880.48,
        "temperature": 0,
        "text": " Sort a comma b.",
        "tokens": [
          50864,
          26149,
          257,
          22117,
          272,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21871120589120047,
        "compression_ratio": 1.3962264150943395,
        "end": 3892.48,
        "id": 1185,
        "no_speech_prob": 0.11123402416706085,
        "seek": 387048,
        "start": 3886.48,
        "temperature": 0,
        "text": " Return a dot label greater than b dot label.",
        "tokens": [
          51164,
          24350,
          257,
          5893,
          7645,
          5044,
          813,
          272,
          5893,
          7645,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21871120589120047,
        "compression_ratio": 1.3962264150943395,
        "end": 3894.48,
        "id": 1186,
        "no_speech_prob": 0.11123402416706085,
        "seek": 387048,
        "start": 3892.48,
        "temperature": 0,
        "text": " So this is...",
        "tokens": [
          51464,
          407,
          341,
          307,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.21871120589120047,
        "compression_ratio": 1.3962264150943395,
        "end": 3898.48,
        "id": 1187,
        "no_speech_prob": 0.11123402416706085,
        "seek": 387048,
        "start": 3894.48,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51564,
          45263,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3902.48,
        "id": 1188,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3898.48,
        "temperature": 0,
        "text": " Oh, and I don't need to say return if I use the arrow syntax.",
        "tokens": [
          50364,
          876,
          11,
          293,
          286,
          500,
          380,
          643,
          281,
          584,
          2736,
          498,
          286,
          764,
          264,
          11610,
          28431,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3905.48,
        "id": 1189,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3902.48,
        "temperature": 0,
        "text": " I'm really just off the deep end here in this video.",
        "tokens": [
          50564,
          286,
          478,
          534,
          445,
          766,
          264,
          2452,
          917,
          510,
          294,
          341,
          960,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3906.48,
        "id": 1190,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3905.48,
        "temperature": 0,
        "text": " I'm going to...",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3907.48,
        "id": 1191,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3906.48,
        "temperature": 0,
        "text": " I think this is right.",
        "tokens": [
          50764,
          286,
          519,
          341,
          307,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3909.48,
        "id": 1192,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3907.48,
        "temperature": 0,
        "text": " That should sort it.",
        "tokens": [
          50814,
          663,
          820,
          1333,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3910.48,
        "id": 1193,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3909.48,
        "temperature": 0,
        "text": " Yes, there we go.",
        "tokens": [
          50914,
          1079,
          11,
          456,
          321,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3912.48,
        "id": 1194,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3910.48,
        "temperature": 0,
        "text": " So we can see now it's...",
        "tokens": [
          50964,
          407,
          321,
          393,
          536,
          586,
          309,
          311,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.1835012552214832,
        "compression_ratio": 1.4146341463414633,
        "end": 3927.48,
        "id": 1195,
        "no_speech_prob": 0.13293030858039856,
        "seek": 389848,
        "start": 3912.48,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51064,
          663,
          311,
          3657,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3931.48,
        "id": 1196,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3928.48,
        "temperature": 0,
        "text": " Just pausing for a second.",
        "tokens": [
          50414,
          1449,
          2502,
          7981,
          337,
          257,
          1150,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3933.48,
        "id": 1197,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3931.48,
        "temperature": 0,
        "text": " There's a great comment in the chat from Sam D.",
        "tokens": [
          50564,
          821,
          311,
          257,
          869,
          2871,
          294,
          264,
          5081,
          490,
          4832,
          413,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3940.48,
        "id": 1198,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3933.48,
        "temperature": 0,
        "text": " Could we separate out the different things into functions by color, by user, by whatever classifier, rather than commenting out lots of stuff?",
        "tokens": [
          50664,
          7497,
          321,
          4994,
          484,
          264,
          819,
          721,
          666,
          6828,
          538,
          2017,
          11,
          538,
          4195,
          11,
          538,
          2035,
          1508,
          9902,
          11,
          2831,
          813,
          29590,
          484,
          3195,
          295,
          1507,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3941.48,
        "id": 1199,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3940.48,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51014,
          1079,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3942.48,
        "id": 1200,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3941.48,
        "temperature": 0,
        "text": " This would be an absolutely great thing to do.",
        "tokens": [
          51064,
          639,
          576,
          312,
          364,
          3122,
          869,
          551,
          281,
          360,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3949.48,
        "id": 1201,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3942.48,
        "temperature": 0,
        "text": " So I'm going to publish this and I would love to get user comments and user submissions of like making a nice interface for this.",
        "tokens": [
          51114,
          407,
          286,
          478,
          516,
          281,
          11374,
          341,
          293,
          286,
          576,
          959,
          281,
          483,
          4195,
          3053,
          293,
          4195,
          40429,
          295,
          411,
          1455,
          257,
          1481,
          9226,
          337,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3953.48,
        "id": 1202,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3949.48,
        "temperature": 0,
        "text": " But I'm trying to figure out why it didn't sort this right now.",
        "tokens": [
          51464,
          583,
          286,
          478,
          1382,
          281,
          2573,
          484,
          983,
          309,
          994,
          380,
          1333,
          341,
          558,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18706584745837795,
        "compression_ratio": 1.6401384083044983,
        "end": 3956.48,
        "id": 1203,
        "no_speech_prob": 0.1293790638446808,
        "seek": 392748,
        "start": 3953.48,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51664,
          961,
          311,
          536,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3960.48,
        "id": 1204,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3956.48,
        "temperature": 0,
        "text": " I thought...",
        "tokens": [
          50364,
          286,
          1194,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3965.48,
        "id": 1205,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3960.48,
        "temperature": 0,
        "text": " Sort...",
        "tokens": [
          50564,
          26149,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3966.48,
        "id": 1206,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3965.48,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50814,
          876,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3968.48,
        "id": 1207,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3966.48,
        "temperature": 0,
        "text": " Oh, I have to return zero.",
        "tokens": [
          50864,
          876,
          11,
          286,
          362,
          281,
          2736,
          4018,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3973.48,
        "id": 1208,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3968.48,
        "temperature": 0,
        "text": " I can't return true or false.",
        "tokens": [
          50964,
          286,
          393,
          380,
          2736,
          2074,
          420,
          7908,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3974.48,
        "id": 1209,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3973.48,
        "temperature": 0,
        "text": " Compare...",
        "tokens": [
          51214,
          48523,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3976.48,
        "id": 1210,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3974.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1977713291461651,
        "compression_ratio": 1.205607476635514,
        "end": 3985.48,
        "id": 1211,
        "no_speech_prob": 0.03461810201406479,
        "seek": 395648,
        "start": 3976.48,
        "temperature": 0,
        "text": " Oh, because these are strings.",
        "tokens": [
          51364,
          876,
          11,
          570,
          613,
          366,
          13985,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1814786048784648,
        "compression_ratio": 1.5202702702702702,
        "end": 3987.48,
        "id": 1212,
        "no_speech_prob": 0.012053584679961205,
        "seek": 398548,
        "start": 3985.48,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50364,
          865,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1814786048784648,
        "compression_ratio": 1.5202702702702702,
        "end": 3991.48,
        "id": 1213,
        "no_speech_prob": 0.012053584679961205,
        "seek": 398548,
        "start": 3987.48,
        "temperature": 0,
        "text": " Yes, yes, yes, yes, yes, yes, yes, yes.",
        "tokens": [
          50464,
          1079,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1814786048784648,
        "compression_ratio": 1.5202702702702702,
        "end": 3992.48,
        "id": 1214,
        "no_speech_prob": 0.012053584679961205,
        "seek": 398548,
        "start": 3991.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1814786048784648,
        "compression_ratio": 1.5202702702702702,
        "end": 3993.48,
        "id": 1215,
        "no_speech_prob": 0.012053584679961205,
        "seek": 398548,
        "start": 3992.48,
        "temperature": 0,
        "text": " These are strings.",
        "tokens": [
          50714,
          1981,
          366,
          13985,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1814786048784648,
        "compression_ratio": 1.5202702702702702,
        "end": 3999.48,
        "id": 1216,
        "no_speech_prob": 0.012053584679961205,
        "seek": 398548,
        "start": 3993.48,
        "temperature": 0,
        "text": " So this is going to give me a true or false, but the sort function wants like a negative or positive number.",
        "tokens": [
          50764,
          407,
          341,
          307,
          516,
          281,
          976,
          385,
          257,
          2074,
          420,
          7908,
          11,
          457,
          264,
          1333,
          2445,
          2738,
          411,
          257,
          3671,
          420,
          3353,
          1230,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1814786048784648,
        "compression_ratio": 1.5202702702702702,
        "end": 4001.48,
        "id": 1217,
        "no_speech_prob": 0.012053584679961205,
        "seek": 398548,
        "start": 3999.48,
        "temperature": 0,
        "text": " So I'm actually just going to break this out.",
        "tokens": [
          51064,
          407,
          286,
          478,
          767,
          445,
          516,
          281,
          1821,
          341,
          484,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24871844053268433,
        "compression_ratio": 1.380952380952381,
        "end": 4019.48,
        "id": 1218,
        "no_speech_prob": 0.3629247546195984,
        "seek": 400148,
        "start": 4001.48,
        "temperature": 0,
        "text": " So I could do this with those ternary operators, but I'm just going to say if return one, else return negative one.",
        "tokens": [
          50364,
          407,
          286,
          727,
          360,
          341,
          365,
          729,
          256,
          1248,
          822,
          19077,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          584,
          498,
          2736,
          472,
          11,
          1646,
          2736,
          3671,
          472,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24871844053268433,
        "compression_ratio": 1.380952380952381,
        "end": 4023.48,
        "id": 1219,
        "no_speech_prob": 0.3629247546195984,
        "seek": 400148,
        "start": 4019.48,
        "temperature": 0,
        "text": " And this should do the trick.",
        "tokens": [
          51264,
          400,
          341,
          820,
          360,
          264,
          4282,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24871844053268433,
        "compression_ratio": 1.380952380952381,
        "end": 4024.48,
        "id": 1220,
        "no_speech_prob": 0.3629247546195984,
        "seek": 400148,
        "start": 4023.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51464,
          1057,
          558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24871844053268433,
        "compression_ratio": 1.380952380952381,
        "end": 4026.48,
        "id": 1221,
        "no_speech_prob": 0.3629247546195984,
        "seek": 400148,
        "start": 4024.48,
        "temperature": 0,
        "text": " So let's take a look at this now.",
        "tokens": [
          51514,
          407,
          718,
          311,
          747,
          257,
          574,
          412,
          341,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24871844053268433,
        "compression_ratio": 1.380952380952381,
        "end": 4027.48,
        "id": 1222,
        "no_speech_prob": 0.3629247546195984,
        "seek": 400148,
        "start": 4026.48,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51614,
          821,
          321,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24604426203547297,
        "compression_ratio": 1.5316455696202531,
        "end": 4031.48,
        "id": 1223,
        "no_speech_prob": 0.9206580519676208,
        "seek": 402748,
        "start": 4028.48,
        "temperature": 0,
        "text": " So we can see this is now sorted by that particular user.",
        "tokens": [
          50414,
          407,
          321,
          393,
          536,
          341,
          307,
          586,
          25462,
          538,
          300,
          1729,
          4195,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24604426203547297,
        "compression_ratio": 1.5316455696202531,
        "end": 4036.48,
        "id": 1224,
        "no_speech_prob": 0.9206580519676208,
        "seek": 402748,
        "start": 4031.48,
        "temperature": 0,
        "text": " And then all I need to do is add...",
        "tokens": [
          50564,
          400,
          550,
          439,
          286,
          643,
          281,
          360,
          307,
          909,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.24604426203547297,
        "compression_ratio": 1.5316455696202531,
        "end": 4044.48,
        "id": 1225,
        "no_speech_prob": 0.9206580519676208,
        "seek": 402748,
        "start": 4036.48,
        "temperature": 0,
        "text": " Boy, I need to make something that color box...",
        "tokens": [
          50814,
          9486,
          11,
          286,
          643,
          281,
          652,
          746,
          300,
          2017,
          2424,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.24604426203547297,
        "compression_ratio": 1.5316455696202531,
        "end": 4049.48,
        "id": 1226,
        "no_speech_prob": 0.9206580519676208,
        "seek": 402748,
        "start": 4044.48,
        "temperature": 0,
        "text": " I guess I could make that a div that lives inside.",
        "tokens": [
          51214,
          286,
          2041,
          286,
          727,
          652,
          300,
          257,
          3414,
          300,
          2909,
          1854,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24604426203547297,
        "compression_ratio": 1.5316455696202531,
        "end": 4053.48,
        "id": 1227,
        "no_speech_prob": 0.9206580519676208,
        "seek": 402748,
        "start": 4049.48,
        "temperature": 0,
        "text": " Color box size, 10, 10.",
        "tokens": [
          51464,
          10458,
          2424,
          2744,
          11,
          1266,
          11,
          1266,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24604426203547297,
        "compression_ratio": 1.5316455696202531,
        "end": 4055.48,
        "id": 1228,
        "no_speech_prob": 0.9206580519676208,
        "seek": 402748,
        "start": 4053.48,
        "temperature": 0,
        "text": " And then color box style.",
        "tokens": [
          51664,
          400,
          550,
          2017,
          2424,
          3758,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2556936410757212,
        "compression_ratio": 1.2887323943661972,
        "end": 4058.48,
        "id": 1229,
        "no_speech_prob": 0.04603268951177597,
        "seek": 405548,
        "start": 4055.48,
        "temperature": 0,
        "text": " And these are all p5 DOM functions.",
        "tokens": [
          50364,
          400,
          613,
          366,
          439,
          280,
          20,
          35727,
          6828,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2556936410757212,
        "compression_ratio": 1.2887323943661972,
        "end": 4060.48,
        "id": 1230,
        "no_speech_prob": 0.04603268951177597,
        "seek": 405548,
        "start": 4058.48,
        "temperature": 0,
        "text": " Background color.",
        "tokens": [
          50514,
          36904,
          2017,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2556936410757212,
        "compression_ratio": 1.2887323943661972,
        "end": 4072.48,
        "id": 1231,
        "no_speech_prob": 0.04603268951177597,
        "seek": 405548,
        "start": 4060.48,
        "temperature": 0,
        "text": " Oh, now this would be a great time to use those template literals, because what I want to do is say RGB.",
        "tokens": [
          50614,
          876,
          11,
          586,
          341,
          576,
          312,
          257,
          869,
          565,
          281,
          764,
          729,
          12379,
          2733,
          1124,
          11,
          570,
          437,
          286,
          528,
          281,
          360,
          307,
          584,
          31231,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2556936410757212,
        "compression_ratio": 1.2887323943661972,
        "end": 4075.48,
        "id": 1232,
        "no_speech_prob": 0.04603268951177597,
        "seek": 405548,
        "start": 4072.48,
        "temperature": 0,
        "text": " Entry.",
        "tokens": [
          51214,
          3951,
          627,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2556936410757212,
        "compression_ratio": 1.2887323943661972,
        "end": 4079.48,
        "id": 1233,
        "no_speech_prob": 0.04603268951177597,
        "seek": 405548,
        "start": 4075.48,
        "temperature": 0,
        "text": " Entry.r.",
        "tokens": [
          51364,
          3951,
          627,
          13,
          81,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2556936410757212,
        "compression_ratio": 1.2887323943661972,
        "end": 4082.48,
        "id": 1234,
        "no_speech_prob": 0.04603268951177597,
        "seek": 405548,
        "start": 4079.48,
        "temperature": 0,
        "text": " Entry.g.",
        "tokens": [
          51564,
          3951,
          627,
          13,
          70,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4083.48,
        "id": 1235,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4082.48,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          50364,
          400,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4089.48,
        "id": 1236,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4083.48,
        "temperature": 0,
        "text": " What happened?",
        "tokens": [
          50414,
          708,
          2011,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4093.48,
        "id": 1237,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4089.48,
        "temperature": 0,
        "text": " Entry.b.",
        "tokens": [
          50714,
          3951,
          627,
          13,
          65,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4094.48,
        "id": 1238,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4093.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50914,
          1779,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4100.48,
        "id": 1239,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4094.48,
        "temperature": 0,
        "text": " This is CSS for making an RGB color, I believe.",
        "tokens": [
          50964,
          639,
          307,
          24387,
          337,
          1455,
          364,
          31231,
          2017,
          11,
          286,
          1697,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4102.48,
        "id": 1240,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4100.48,
        "temperature": 0,
        "text": " Let's see how this works.",
        "tokens": [
          51264,
          961,
          311,
          536,
          577,
          341,
          1985,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4104.48,
        "id": 1241,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4102.48,
        "temperature": 0,
        "text": " What's the chance this works?",
        "tokens": [
          51364,
          708,
          311,
          264,
          2931,
          341,
          1985,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4105.48,
        "id": 1242,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4104.48,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51464,
          2438,
          0,
          51514
        ]
      },
      {
        "avg_logprob": -0.22851611721900203,
        "compression_ratio": 1.1705426356589148,
        "end": 4106.48,
        "id": 1243,
        "no_speech_prob": 0.0008693612762726843,
        "seek": 408248,
        "start": 4105.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21632647110243974,
        "compression_ratio": 1.3389830508474576,
        "end": 4111.48,
        "id": 1244,
        "no_speech_prob": 0.23085495829582214,
        "seek": 410648,
        "start": 4106.48,
        "temperature": 0,
        "text": " Oh, but now what I want to do is say...",
        "tokens": [
          50364,
          876,
          11,
          457,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          584,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.21632647110243974,
        "compression_ratio": 1.3389830508474576,
        "end": 4115.48,
        "id": 1245,
        "no_speech_prob": 0.23085495829582214,
        "seek": 410648,
        "start": 4111.48,
        "temperature": 0,
        "text": " Color box parent.",
        "tokens": [
          50614,
          10458,
          2424,
          2596,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21632647110243974,
        "compression_ratio": 1.3389830508474576,
        "end": 4117.48,
        "id": 1246,
        "no_speech_prob": 0.23085495829582214,
        "seek": 410648,
        "start": 4115.48,
        "temperature": 0,
        "text": " And I want it to be inline.",
        "tokens": [
          50814,
          400,
          286,
          528,
          309,
          281,
          312,
          294,
          1889,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21632647110243974,
        "compression_ratio": 1.3389830508474576,
        "end": 4118.48,
        "id": 1247,
        "no_speech_prob": 0.23085495829582214,
        "seek": 410648,
        "start": 4117.48,
        "temperature": 0,
        "text": " So how do I do that?",
        "tokens": [
          50914,
          407,
          577,
          360,
          286,
          360,
          300,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.21632647110243974,
        "compression_ratio": 1.3389830508474576,
        "end": 4125.48,
        "id": 1248,
        "no_speech_prob": 0.23085495829582214,
        "seek": 410648,
        "start": 4118.48,
        "temperature": 0,
        "text": " Color box style display inline.",
        "tokens": [
          50964,
          10458,
          2424,
          3758,
          4674,
          294,
          1889,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21632647110243974,
        "compression_ratio": 1.3389830508474576,
        "end": 4128.48,
        "id": 1249,
        "no_speech_prob": 0.23085495829582214,
        "seek": 410648,
        "start": 4125.48,
        "temperature": 0,
        "text": " Is that what it is?",
        "tokens": [
          51314,
          1119,
          300,
          437,
          309,
          307,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.251199687610973,
        "compression_ratio": 1.3525179856115108,
        "end": 4136.48,
        "id": 1250,
        "no_speech_prob": 0.2226521521806717,
        "seek": 412848,
        "start": 4128.48,
        "temperature": 0,
        "text": " No?",
        "tokens": [
          50364,
          883,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.251199687610973,
        "compression_ratio": 1.3525179856115108,
        "end": 4140.48,
        "id": 1251,
        "no_speech_prob": 0.2226521521806717,
        "seek": 412848,
        "start": 4136.48,
        "temperature": 0,
        "text": " Well, you get the idea.",
        "tokens": [
          50764,
          1042,
          11,
          291,
          483,
          264,
          1558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.251199687610973,
        "compression_ratio": 1.3525179856115108,
        "end": 4143.48,
        "id": 1252,
        "no_speech_prob": 0.2226521521806717,
        "seek": 412848,
        "start": 4140.48,
        "temperature": 0,
        "text": " Some of these, as you can see, is pretty inconsistent.",
        "tokens": [
          50964,
          2188,
          295,
          613,
          11,
          382,
          291,
          393,
          536,
          11,
          307,
          1238,
          36891,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.251199687610973,
        "compression_ratio": 1.3525179856115108,
        "end": 4155.48,
        "id": 1253,
        "no_speech_prob": 0.2226521521806717,
        "seek": 412848,
        "start": 4143.48,
        "temperature": 0,
        "text": " The colors are just so wildly different that I think we can kind of say that this user we can filter out.",
        "tokens": [
          51114,
          440,
          4577,
          366,
          445,
          370,
          34731,
          819,
          300,
          286,
          519,
          321,
          393,
          733,
          295,
          584,
          300,
          341,
          4195,
          321,
          393,
          6608,
          484,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4157.48,
        "id": 1254,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4155.48,
        "temperature": 0,
        "text": " And I could look at some of these other users now.",
        "tokens": [
          50364,
          400,
          286,
          727,
          574,
          412,
          512,
          295,
          613,
          661,
          5022,
          586,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4160.48,
        "id": 1255,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4157.48,
        "temperature": 0,
        "text": " Like, let's look at this user.",
        "tokens": [
          50464,
          1743,
          11,
          718,
          311,
          574,
          412,
          341,
          4195,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4161.48,
        "id": 1256,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4160.48,
        "temperature": 0,
        "text": " Where did I...",
        "tokens": [
          50614,
          2305,
          630,
          286,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4167.48,
        "id": 1257,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4161.48,
        "temperature": 0,
        "text": " Let's look at this user.",
        "tokens": [
          50664,
          961,
          311,
          574,
          412,
          341,
          4195,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4169.48,
        "id": 1258,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4167.48,
        "temperature": 0,
        "text": " Everything seems to be bluish.",
        "tokens": [
          50964,
          5471,
          2544,
          281,
          312,
          888,
          33786,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4171.48,
        "id": 1259,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4169.48,
        "temperature": 0,
        "text": " That doesn't look like great data.",
        "tokens": [
          51064,
          663,
          1177,
          380,
          574,
          411,
          869,
          1412,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4174.48,
        "id": 1260,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4171.48,
        "temperature": 0,
        "text": " And let me look at this user.",
        "tokens": [
          51164,
          400,
          718,
          385,
          574,
          412,
          341,
          4195,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4178.48,
        "id": 1261,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4174.48,
        "temperature": 0,
        "text": " And again, I'm doing this so manually in my code.",
        "tokens": [
          51314,
          400,
          797,
          11,
          286,
          478,
          884,
          341,
          370,
          16945,
          294,
          452,
          3089,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1745602607727051,
        "compression_ratio": 1.6770833333333333,
        "end": 4182.48,
        "id": 1262,
        "no_speech_prob": 0.05664503574371338,
        "seek": 415548,
        "start": 4178.48,
        "temperature": 0,
        "text": " I could easily build an interface to look at all this.",
        "tokens": [
          51514,
          286,
          727,
          3612,
          1322,
          364,
          9226,
          281,
          574,
          412,
          439,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4185.48,
        "id": 1263,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4182.48,
        "temperature": 0,
        "text": " Grayish, grayish, greenish, greenish, brownish, bluish, bluish.",
        "tokens": [
          50364,
          22668,
          742,
          11,
          10855,
          742,
          11,
          3092,
          742,
          11,
          3092,
          742,
          11,
          6292,
          742,
          11,
          888,
          33786,
          11,
          888,
          33786,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4187.48,
        "id": 1264,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4185.48,
        "temperature": 0,
        "text": " This looks too inconsistent.",
        "tokens": [
          50514,
          639,
          1542,
          886,
          36891,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4190.48,
        "id": 1265,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4187.48,
        "temperature": 0,
        "text": " So, you know, it's fine to have some...",
        "tokens": [
          50614,
          407,
          11,
          291,
          458,
          11,
          309,
          311,
          2489,
          281,
          362,
          512,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4191.48,
        "id": 1266,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4190.48,
        "temperature": 0,
        "text": " So I think we're done here.",
        "tokens": [
          50764,
          407,
          286,
          519,
          321,
          434,
          1096,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4193.48,
        "id": 1267,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4191.48,
        "temperature": 0,
        "text": " You get the point.",
        "tokens": [
          50814,
          509,
          483,
          264,
          935,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4195.48,
        "id": 1268,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4193.48,
        "temperature": 0,
        "text": " We're not completely done.",
        "tokens": [
          50914,
          492,
          434,
          406,
          2584,
          1096,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4199.48,
        "id": 1269,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4195.48,
        "temperature": 0,
        "text": " Because I want to just create a JSON file of all of the data.",
        "tokens": [
          51014,
          1436,
          286,
          528,
          281,
          445,
          1884,
          257,
          31828,
          3991,
          295,
          439,
          295,
          264,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4202.48,
        "id": 1270,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4199.48,
        "temperature": 0,
        "text": " And I'll do that in the next video.",
        "tokens": [
          51214,
          400,
          286,
          603,
          360,
          300,
          294,
          264,
          958,
          960,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4204.48,
        "id": 1271,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4202.48,
        "temperature": 0,
        "text": " Because I don't know if anybody is still watching this right now.",
        "tokens": [
          51364,
          1436,
          286,
          500,
          380,
          458,
          498,
          4472,
          307,
          920,
          1976,
          341,
          558,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4208.48,
        "id": 1272,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4204.48,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          51464,
          407,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.237092186422909,
        "compression_ratio": 1.6394052044609666,
        "end": 4211.48,
        "id": 1273,
        "no_speech_prob": 0.341544508934021,
        "seek": 418248,
        "start": 4208.48,
        "temperature": 0,
        "text": " Right, I could add some background to the text and some padding.",
        "tokens": [
          51664,
          1779,
          11,
          286,
          727,
          909,
          512,
          3678,
          281,
          264,
          2487,
          293,
          512,
          39562,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19865096561492435,
        "compression_ratio": 1.6556776556776556,
        "end": 4213.48,
        "id": 1274,
        "no_speech_prob": 0.2813381552696228,
        "seek": 421148,
        "start": 4211.48,
        "temperature": 0,
        "text": " There's all sorts of ways I could visualize this.",
        "tokens": [
          50364,
          821,
          311,
          439,
          7527,
          295,
          2098,
          286,
          727,
          23273,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19865096561492435,
        "compression_ratio": 1.6556776556776556,
        "end": 4216.48,
        "id": 1275,
        "no_speech_prob": 0.2813381552696228,
        "seek": 421148,
        "start": 4213.48,
        "temperature": 0,
        "text": " If I had any sort of talent or knowledge about CSS and design.",
        "tokens": [
          50464,
          759,
          286,
          632,
          604,
          1333,
          295,
          8301,
          420,
          3601,
          466,
          24387,
          293,
          1715,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19865096561492435,
        "compression_ratio": 1.6556776556776556,
        "end": 4219.48,
        "id": 1276,
        "no_speech_prob": 0.2813381552696228,
        "seek": 421148,
        "start": 4216.48,
        "temperature": 0,
        "text": " But you, the viewer, will hopefully improve this.",
        "tokens": [
          50614,
          583,
          291,
          11,
          264,
          16767,
          11,
          486,
          4696,
          3470,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19865096561492435,
        "compression_ratio": 1.6556776556776556,
        "end": 4223.48,
        "id": 1277,
        "no_speech_prob": 0.2813381552696228,
        "seek": 421148,
        "start": 4219.48,
        "temperature": 0,
        "text": " But you can sort of see the process of looking at the data, visualizing it, and getting a sense of it.",
        "tokens": [
          50764,
          583,
          291,
          393,
          1333,
          295,
          536,
          264,
          1399,
          295,
          1237,
          412,
          264,
          1412,
          11,
          5056,
          3319,
          309,
          11,
          293,
          1242,
          257,
          2020,
          295,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19865096561492435,
        "compression_ratio": 1.6556776556776556,
        "end": 4226.48,
        "id": 1278,
        "no_speech_prob": 0.2813381552696228,
        "seek": 421148,
        "start": 4223.48,
        "temperature": 0,
        "text": " And now what I might want to do is actually, like, filter and save the data.",
        "tokens": [
          50964,
          400,
          586,
          437,
          286,
          1062,
          528,
          281,
          360,
          307,
          767,
          11,
          411,
          11,
          6608,
          293,
          3155,
          264,
          1412,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19865096561492435,
        "compression_ratio": 1.6556776556776556,
        "end": 4233.48,
        "id": 1279,
        "no_speech_prob": 0.2813381552696228,
        "seek": 421148,
        "start": 4226.48,
        "temperature": 0,
        "text": " And I will do that in the next video, which will be a very short one, I think.",
        "tokens": [
          51114,
          400,
          286,
          486,
          360,
          300,
          294,
          264,
          958,
          960,
          11,
          597,
          486,
          312,
          257,
          588,
          2099,
          472,
          11,
          286,
          519,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19865096561492435,
        "compression_ratio": 1.6556776556776556,
        "end": 4238.48,
        "id": 1280,
        "no_speech_prob": 0.2813381552696228,
        "seek": 421148,
        "start": 4233.48,
        "temperature": 0,
        "text": " Oh, I forgot to check the bot.",
        "tokens": [
          51464,
          876,
          11,
          286,
          5298,
          281,
          1520,
          264,
          10592,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15723060369491576,
        "compression_ratio": 1.1789473684210525,
        "end": 4242.48,
        "id": 1281,
        "no_speech_prob": 0.0014547405298799276,
        "seek": 423848,
        "start": 4238.48,
        "temperature": 0,
        "text": " Let me check the bot.",
        "tokens": [
          50364,
          961,
          385,
          1520,
          264,
          10592,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15723060369491576,
        "compression_ratio": 1.1789473684210525,
        "end": 4250.48,
        "id": 1282,
        "no_speech_prob": 0.0014547405298799276,
        "seek": 423848,
        "start": 4242.48,
        "temperature": 0,
        "text": " How come I don't have the bot here?",
        "tokens": [
          50564,
          1012,
          808,
          286,
          500,
          380,
          362,
          264,
          10592,
          510,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.15723060369491576,
        "compression_ratio": 1.1789473684210525,
        "end": 4259.48,
        "id": 1283,
        "no_speech_prob": 0.0014547405298799276,
        "seek": 423848,
        "start": 4250.48,
        "temperature": 0,
        "text": " Let's do this real quick.",
        "tokens": [
          50964,
          961,
          311,
          360,
          341,
          957,
          1702,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15723060369491576,
        "compression_ratio": 1.1789473684210525,
        "end": 4263.48,
        "id": 1284,
        "no_speech_prob": 0.0014547405298799276,
        "seek": 423848,
        "start": 4259.48,
        "temperature": 0,
        "text": " Which one was the bot again?",
        "tokens": [
          51414,
          3013,
          472,
          390,
          264,
          10592,
          797,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2264219171860639,
        "compression_ratio": 1.1111111111111112,
        "end": 4277.48,
        "id": 1285,
        "no_speech_prob": 0.18240447342395782,
        "seek": 426348,
        "start": 4263.48,
        "temperature": 0,
        "text": " This one.",
        "tokens": [
          50364,
          639,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2264219171860639,
        "compression_ratio": 1.1111111111111112,
        "end": 4279.48,
        "id": 1286,
        "no_speech_prob": 0.18240447342395782,
        "seek": 426348,
        "start": 4277.48,
        "temperature": 0,
        "text": " What a mess.",
        "tokens": [
          51064,
          708,
          257,
          2082,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2264219171860639,
        "compression_ratio": 1.1111111111111112,
        "end": 4285.48,
        "id": 1287,
        "no_speech_prob": 0.18240447342395782,
        "seek": 426348,
        "start": 4279.48,
        "temperature": 0,
        "text": " What a mess I'm making of all this.",
        "tokens": [
          51164,
          708,
          257,
          2082,
          286,
          478,
          1455,
          295,
          439,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2264219171860639,
        "compression_ratio": 1.1111111111111112,
        "end": 4290.48,
        "id": 1288,
        "no_speech_prob": 0.18240447342395782,
        "seek": 426348,
        "start": 4285.48,
        "temperature": 0,
        "text": " The bot's not so bad.",
        "tokens": [
          51464,
          440,
          10592,
          311,
          406,
          370,
          1578,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24395428825827206,
        "compression_ratio": 1.7988505747126438,
        "end": 4299.48,
        "id": 1289,
        "no_speech_prob": 0.6000746488571167,
        "seek": 429048,
        "start": 4290.48,
        "temperature": 0,
        "text": " The bot actually has... The thing I thought was the bot has good data.",
        "tokens": [
          50364,
          440,
          10592,
          767,
          575,
          485,
          440,
          551,
          286,
          1194,
          390,
          264,
          10592,
          575,
          665,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24395428825827206,
        "compression_ratio": 1.7988505747126438,
        "end": 4302.48,
        "id": 1290,
        "no_speech_prob": 0.6000746488571167,
        "seek": 429048,
        "start": 4299.48,
        "temperature": 0,
        "text": " That's really interesting.",
        "tokens": [
          50814,
          663,
          311,
          534,
          1880,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24395428825827206,
        "compression_ratio": 1.7988505747126438,
        "end": 4307.48,
        "id": 1291,
        "no_speech_prob": 0.6000746488571167,
        "seek": 429048,
        "start": 4302.48,
        "temperature": 0,
        "text": " The thing we thought was the bot seems to have good data.",
        "tokens": [
          50964,
          440,
          551,
          321,
          1194,
          390,
          264,
          10592,
          2544,
          281,
          362,
          665,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24395428825827206,
        "compression_ratio": 1.7988505747126438,
        "end": 4309.48,
        "id": 1292,
        "no_speech_prob": 0.6000746488571167,
        "seek": 429048,
        "start": 4307.48,
        "temperature": 0,
        "text": " My apologies to the bot.",
        "tokens": [
          51214,
          1222,
          34929,
          281,
          264,
          10592,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24395428825827206,
        "compression_ratio": 1.7988505747126438,
        "end": 4312.48,
        "id": 1293,
        "no_speech_prob": 0.6000746488571167,
        "seek": 429048,
        "start": 4309.48,
        "temperature": 0,
        "text": " It was the thing I thought was the bot.",
        "tokens": [
          51314,
          467,
          390,
          264,
          551,
          286,
          1194,
          390,
          264,
          10592,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24395428825827206,
        "compression_ratio": 1.7988505747126438,
        "end": 4316.48,
        "id": 1294,
        "no_speech_prob": 0.6000746488571167,
        "seek": 429048,
        "start": 4312.48,
        "temperature": 0,
        "text": " I mean, you know, you could make the argument that some of these might not be exactly right.",
        "tokens": [
          51464,
          286,
          914,
          11,
          291,
          458,
          11,
          291,
          727,
          652,
          264,
          6770,
          300,
          512,
          295,
          613,
          1062,
          406,
          312,
          2293,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23382802528910118,
        "compression_ratio": 1.5892857142857142,
        "end": 4321.48,
        "id": 1295,
        "no_speech_prob": 0.6075568795204163,
        "seek": 431648,
        "start": 4317.48,
        "temperature": 0,
        "text": " Oh, it's only doing... No, it's got pink and orange and purple in there.",
        "tokens": [
          50414,
          876,
          11,
          309,
          311,
          787,
          884,
          485,
          883,
          11,
          309,
          311,
          658,
          7022,
          293,
          7671,
          293,
          9656,
          294,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23382802528910118,
        "compression_ratio": 1.5892857142857142,
        "end": 4323.48,
        "id": 1296,
        "no_speech_prob": 0.6075568795204163,
        "seek": 431648,
        "start": 4321.48,
        "temperature": 0,
        "text": " That's not a bot.",
        "tokens": [
          50614,
          663,
          311,
          406,
          257,
          10592,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23382802528910118,
        "compression_ratio": 1.5892857142857142,
        "end": 4326.48,
        "id": 1297,
        "no_speech_prob": 0.6075568795204163,
        "seek": 431648,
        "start": 4323.48,
        "temperature": 0,
        "text": " So I was wrong.",
        "tokens": [
          50714,
          407,
          286,
          390,
          2085,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23382802528910118,
        "compression_ratio": 1.5892857142857142,
        "end": 4332.48,
        "id": 1298,
        "no_speech_prob": 0.6075568795204163,
        "seek": 431648,
        "start": 4326.48,
        "temperature": 0,
        "text": " So the reason why I thought it was a bot was because the moment I wiped the database,",
        "tokens": [
          50864,
          407,
          264,
          1778,
          983,
          286,
          1194,
          309,
          390,
          257,
          10592,
          390,
          570,
          264,
          1623,
          286,
          26879,
          264,
          8149,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.23382802528910118,
        "compression_ratio": 1.5892857142857142,
        "end": 4340.48,
        "id": 1299,
        "no_speech_prob": 0.6075568795204163,
        "seek": 431648,
        "start": 4332.48,
        "temperature": 0,
        "text": " I wiped the database at one point, then I just saw consistently at, like, very distinct intervals,",
        "tokens": [
          51164,
          286,
          26879,
          264,
          8149,
          412,
          472,
          935,
          11,
          550,
          286,
          445,
          1866,
          14961,
          412,
          11,
          411,
          11,
          588,
          10644,
          26651,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.23382802528910118,
        "compression_ratio": 1.5892857142857142,
        "end": 4343.48,
        "id": 1300,
        "no_speech_prob": 0.6075568795204163,
        "seek": 431648,
        "start": 4340.48,
        "temperature": 0,
        "text": " entering stuff in really, really fast.",
        "tokens": [
          51564,
          11104,
          1507,
          294,
          534,
          11,
          534,
          2370,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23382802528910118,
        "compression_ratio": 1.5892857142857142,
        "end": 4345.48,
        "id": 1301,
        "no_speech_prob": 0.6075568795204163,
        "seek": 431648,
        "start": 4343.48,
        "temperature": 0,
        "text": " Could have been a person.",
        "tokens": [
          51714,
          7497,
          362,
          668,
          257,
          954,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17456478975257095,
        "compression_ratio": 1.5025641025641026,
        "end": 4348.48,
        "id": 1302,
        "no_speech_prob": 0.07807435840368271,
        "seek": 434548,
        "start": 4345.48,
        "temperature": 0,
        "text": " I'm not sure it's a bot.",
        "tokens": [
          50364,
          286,
          478,
          406,
          988,
          309,
          311,
          257,
          10592,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17456478975257095,
        "compression_ratio": 1.5025641025641026,
        "end": 4353.48,
        "id": 1303,
        "no_speech_prob": 0.07807435840368271,
        "seek": 434548,
        "start": 4348.48,
        "temperature": 0,
        "text": " And it looks like it's generating the data with a hue.",
        "tokens": [
          50514,
          400,
          309,
          1542,
          411,
          309,
          311,
          17746,
          264,
          1412,
          365,
          257,
          24967,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17456478975257095,
        "compression_ratio": 1.5025641025641026,
        "end": 4356.48,
        "id": 1304,
        "no_speech_prob": 0.07807435840368271,
        "seek": 434548,
        "start": 4353.48,
        "temperature": 0,
        "text": " So maybe this data is too good.",
        "tokens": [
          50764,
          407,
          1310,
          341,
          1412,
          307,
          886,
          665,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17456478975257095,
        "compression_ratio": 1.5025641025641026,
        "end": 4358.48,
        "id": 1305,
        "no_speech_prob": 0.07807435840368271,
        "seek": 434548,
        "start": 4356.48,
        "temperature": 0,
        "text": " Anyway, I'm not going to worry about this too much.",
        "tokens": [
          50914,
          5684,
          11,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          341,
          886,
          709,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17456478975257095,
        "compression_ratio": 1.5025641025641026,
        "end": 4360.48,
        "id": 1306,
        "no_speech_prob": 0.07807435840368271,
        "seek": 434548,
        "start": 4358.48,
        "temperature": 0,
        "text": " I've got to move on.",
        "tokens": [
          51014,
          286,
          600,
          658,
          281,
          1286,
          322,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17456478975257095,
        "compression_ratio": 1.5025641025641026,
        "end": 4367.48,
        "id": 1307,
        "no_speech_prob": 0.07807435840368271,
        "seek": 434548,
        "start": 4360.48,
        "temperature": 0,
        "text": " Also, it's 1 o'clock, so I only have about 45 minutes.",
        "tokens": [
          51114,
          2743,
          11,
          309,
          311,
          502,
          277,
          6,
          9023,
          11,
          370,
          286,
          787,
          362,
          466,
          6905,
          2077,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17456478975257095,
        "compression_ratio": 1.5025641025641026,
        "end": 4372.48,
        "id": 1308,
        "no_speech_prob": 0.07807435840368271,
        "seek": 434548,
        "start": 4367.48,
        "temperature": 0,
        "text": " Yeah, some of those are, you could say, are greenish.",
        "tokens": [
          51464,
          865,
          11,
          512,
          295,
          729,
          366,
          11,
          291,
          727,
          584,
          11,
          366,
          3092,
          742,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20405180492098368,
        "compression_ratio": 1.425,
        "end": 4377.48,
        "id": 1309,
        "no_speech_prob": 0.0007793342811055481,
        "seek": 437248,
        "start": 4372.48,
        "temperature": 0,
        "text": " Oh, and I'm out of my caffeinated beverage, which is really bad.",
        "tokens": [
          50364,
          876,
          11,
          293,
          286,
          478,
          484,
          295,
          452,
          29118,
          5410,
          35519,
          11,
          597,
          307,
          534,
          1578,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20405180492098368,
        "compression_ratio": 1.425,
        "end": 4379.48,
        "id": 1310,
        "no_speech_prob": 0.0007793342811055481,
        "seek": 437248,
        "start": 4377.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20405180492098368,
        "compression_ratio": 1.425,
        "end": 4381.48,
        "id": 1311,
        "no_speech_prob": 0.0007793342811055481,
        "seek": 437248,
        "start": 4379.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50714,
          1057,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20405180492098368,
        "compression_ratio": 1.425,
        "end": 4389.48,
        "id": 1312,
        "no_speech_prob": 0.0007793342811055481,
        "seek": 437248,
        "start": 4386.48,
        "temperature": 0,
        "text": " So I'm going to let this be.",
        "tokens": [
          51064,
          407,
          286,
          478,
          516,
          281,
          718,
          341,
          312,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20405180492098368,
        "compression_ratio": 1.425,
        "end": 4395.48,
        "id": 1313,
        "no_speech_prob": 0.0007793342811055481,
        "seek": 437248,
        "start": 4392.48,
        "temperature": 0,
        "text": " I'm going to let this be.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          718,
          341,
          312,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20405180492098368,
        "compression_ratio": 1.425,
        "end": 4398.48,
        "id": 1314,
        "no_speech_prob": 0.0007793342811055481,
        "seek": 437248,
        "start": 4395.48,
        "temperature": 0,
        "text": " And now I'm going to make a new...",
        "tokens": [
          51514,
          400,
          586,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.2780197605942235,
        "compression_ratio": 1.123456790123457,
        "end": 4401.48,
        "id": 1315,
        "no_speech_prob": 0.004263861570507288,
        "seek": 439848,
        "start": 4399.48,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50414,
          45263,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2780197605942235,
        "compression_ratio": 1.123456790123457,
        "end": 4406.48,
        "id": 1316,
        "no_speech_prob": 0.004263861570507288,
        "seek": 439848,
        "start": 4404.48,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50664,
          883,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2780197605942235,
        "compression_ratio": 1.123456790123457,
        "end": 4412.48,
        "id": 1317,
        "no_speech_prob": 0.004263861570507288,
        "seek": 439848,
        "start": 4406.48,
        "temperature": 0,
        "text": " I'm going to just make a new sketch called Download Data.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          445,
          652,
          257,
          777,
          12325,
          1219,
          32282,
          11888,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2780197605942235,
        "compression_ratio": 1.123456790123457,
        "end": 4416.48,
        "id": 1318,
        "no_speech_prob": 0.004263861570507288,
        "seek": 439848,
        "start": 4414.48,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51164,
          400,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.2780197605942235,
        "compression_ratio": 1.123456790123457,
        "end": 4427.48,
        "id": 1319,
        "no_speech_prob": 0.004263861570507288,
        "seek": 439848,
        "start": 4425.48,
        "temperature": 0,
        "text": " Download Data.",
        "tokens": [
          51714,
          32282,
          11888,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23549910651312933,
        "compression_ratio": 1.2454545454545454,
        "end": 4432.48,
        "id": 1320,
        "no_speech_prob": 0.00021318229846656322,
        "seek": 442848,
        "start": 4429.48,
        "temperature": 0,
        "text": " So what do we think?",
        "tokens": [
          50414,
          407,
          437,
          360,
          321,
          519,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.23549910651312933,
        "compression_ratio": 1.2454545454545454,
        "end": 4435.48,
        "id": 1321,
        "no_speech_prob": 0.00021318229846656322,
        "seek": 442848,
        "start": 4432.48,
        "temperature": 0,
        "text": " Should I keep this one or...",
        "tokens": [
          50564,
          6454,
          286,
          1066,
          341,
          472,
          420,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.23549910651312933,
        "compression_ratio": 1.2454545454545454,
        "end": 4439.48,
        "id": 1322,
        "no_speech_prob": 0.00021318229846656322,
        "seek": 442848,
        "start": 4435.48,
        "temperature": 0,
        "text": " Sort the entries by their key.",
        "tokens": [
          50714,
          26149,
          264,
          23041,
          538,
          641,
          2141,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23549910651312933,
        "compression_ratio": 1.2454545454545454,
        "end": 4441.48,
        "id": 1323,
        "no_speech_prob": 0.00021318229846656322,
        "seek": 442848,
        "start": 4439.48,
        "temperature": 0,
        "text": " Oh, that's interesting.",
        "tokens": [
          50914,
          876,
          11,
          300,
          311,
          1880,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23549910651312933,
        "compression_ratio": 1.2454545454545454,
        "end": 4447.48,
        "id": 1324,
        "no_speech_prob": 0.00021318229846656322,
        "seek": 442848,
        "start": 4444.48,
        "temperature": 0,
        "text": " That would be interesting to do.",
        "tokens": [
          51164,
          663,
          576,
          312,
          1880,
          281,
          360,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.29477187991142273,
        "compression_ratio": 1.0853658536585367,
        "end": 4449.48,
        "id": 1325,
        "no_speech_prob": 0.0008828543941490352,
        "seek": 444748,
        "start": 4447.48,
        "temperature": 0,
        "text": " Ha.",
        "tokens": [
          50364,
          4064,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.29477187991142273,
        "compression_ratio": 1.0853658536585367,
        "end": 4459.48,
        "id": 1326,
        "no_speech_prob": 0.0008828543941490352,
        "seek": 444748,
        "start": 4453.48,
        "temperature": 0,
        "text": " So I am now going to go to Download Data.",
        "tokens": [
          50664,
          407,
          286,
          669,
          586,
          516,
          281,
          352,
          281,
          32282,
          11888,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.29477187991142273,
        "compression_ratio": 1.0853658536585367,
        "end": 4465.48,
        "id": 1327,
        "no_speech_prob": 0.0008828543941490352,
        "seek": 444748,
        "start": 4462.48,
        "temperature": 0,
        "text": " And I'm going to get rid of all this stuff.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          439,
          341,
          1507,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.4096706884878653,
        "compression_ratio": 1.0384615384615385,
        "end": 4481.48,
        "id": 1328,
        "no_speech_prob": 0.0006459382711909711,
        "seek": 447748,
        "start": 4478.48,
        "temperature": 0,
        "text": " So I just have...",
        "tokens": [
          50414,
          407,
          286,
          445,
          362,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.4096706884878653,
        "compression_ratio": 1.0384615384615385,
        "end": 4487.48,
        "id": 1329,
        "no_speech_prob": 0.0006459382711909711,
        "seek": 447748,
        "start": 4484.48,
        "temperature": 0,
        "text": " The stuff I had from before.",
        "tokens": [
          50714,
          440,
          1507,
          286,
          632,
          490,
          949,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.4096706884878653,
        "compression_ratio": 1.0384615384615385,
        "end": 4503.48,
        "id": 1330,
        "no_speech_prob": 0.0006459382711909711,
        "seek": 447748,
        "start": 4500.48,
        "temperature": 0,
        "text": " This should actually be an object.",
        "tokens": [
          51514,
          639,
          820,
          767,
          312,
          364,
          2657,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1804796814918518,
        "compression_ratio": 0.8095238095238095,
        "end": 4507.48,
        "id": 1331,
        "no_speech_prob": 0.0779581069946289,
        "seek": 450348,
        "start": 4503.48,
        "temperature": 0,
        "text": " This should actually be an object.",
        "tokens": [
          50414,
          639,
          820,
          767,
          312,
          364,
          2657,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4536.48,
        "id": 1332,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4534.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4543.48,
        "id": 1333,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4539.48,
        "temperature": 0,
        "text": " So my question is, should I filter all four of these?",
        "tokens": [
          50664,
          407,
          452,
          1168,
          307,
          11,
          820,
          286,
          6608,
          439,
          1451,
          295,
          613,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4546.48,
        "id": 1334,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4543.48,
        "temperature": 0,
        "text": " Or should I leave that bot one?",
        "tokens": [
          50864,
          1610,
          820,
          286,
          1856,
          300,
          10592,
          472,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4548.48,
        "id": 1335,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4546.48,
        "temperature": 0,
        "text": " That one we think is a bot.",
        "tokens": [
          51014,
          663,
          472,
          321,
          519,
          307,
          257,
          10592,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4550.48,
        "id": 1336,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4548.48,
        "temperature": 0,
        "text": " Are you out there?",
        "tokens": [
          51114,
          2014,
          291,
          484,
          456,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4552.48,
        "id": 1337,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4550.48,
        "temperature": 0,
        "text": " Are you out there, person who wrote the bot?",
        "tokens": [
          51214,
          2014,
          291,
          484,
          456,
          11,
          954,
          567,
          4114,
          264,
          10592,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4556.48,
        "id": 1338,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4552.48,
        "temperature": 0,
        "text": " Or human being who wasn't a bot but actually was clicking?",
        "tokens": [
          51314,
          1610,
          1952,
          885,
          567,
          2067,
          380,
          257,
          10592,
          457,
          767,
          390,
          9697,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2319392300723644,
        "compression_ratio": 1.541237113402062,
        "end": 4561.48,
        "id": 1339,
        "no_speech_prob": 0.022625040262937546,
        "seek": 453348,
        "start": 4557.48,
        "temperature": 0,
        "text": " Stillion writes, is Dan actually reading these comments?",
        "tokens": [
          51564,
          745,
          11836,
          13657,
          11,
          307,
          3394,
          767,
          3760,
          613,
          3053,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.21928325566378506,
        "compression_ratio": 1.7291666666666667,
        "end": 4564.48,
        "id": 1340,
        "no_speech_prob": 0.003537631593644619,
        "seek": 456148,
        "start": 4561.48,
        "temperature": 0,
        "text": " Every once in a while I am, yes.",
        "tokens": [
          50364,
          2048,
          1564,
          294,
          257,
          1339,
          286,
          669,
          11,
          2086,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21928325566378506,
        "compression_ratio": 1.7291666666666667,
        "end": 4567.48,
        "id": 1341,
        "no_speech_prob": 0.003537631593644619,
        "seek": 456148,
        "start": 4564.48,
        "temperature": 0,
        "text": " So let's just say we want to filter these out.",
        "tokens": [
          50514,
          407,
          718,
          311,
          445,
          584,
          321,
          528,
          281,
          6608,
          613,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21928325566378506,
        "compression_ratio": 1.7291666666666667,
        "end": 4575.48,
        "id": 1342,
        "no_speech_prob": 0.003537631593644619,
        "seek": 456148,
        "start": 4573.48,
        "temperature": 0,
        "text": " That's interesting.",
        "tokens": [
          50964,
          663,
          311,
          1880,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21928325566378506,
        "compression_ratio": 1.7291666666666667,
        "end": 4578.48,
        "id": 1343,
        "no_speech_prob": 0.003537631593644619,
        "seek": 456148,
        "start": 4575.48,
        "temperature": 0,
        "text": " Simon has an interesting suggestion to say to filter the noise out,",
        "tokens": [
          51064,
          13193,
          575,
          364,
          1880,
          16541,
          281,
          584,
          281,
          6608,
          264,
          5658,
          484,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.21928325566378506,
        "compression_ratio": 1.7291666666666667,
        "end": 4581.48,
        "id": 1344,
        "no_speech_prob": 0.003537631593644619,
        "seek": 456148,
        "start": 4578.48,
        "temperature": 0,
        "text": " you can calculate the average for each color,",
        "tokens": [
          51214,
          291,
          393,
          8873,
          264,
          4274,
          337,
          1184,
          2017,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.21928325566378506,
        "compression_ratio": 1.7291666666666667,
        "end": 4585.48,
        "id": 1345,
        "no_speech_prob": 0.003537631593644619,
        "seek": 456148,
        "start": 4581.48,
        "temperature": 0,
        "text": " and if the distance in between each color and the average color is greater than some threshold,",
        "tokens": [
          51364,
          293,
          498,
          264,
          4560,
          294,
          1296,
          1184,
          2017,
          293,
          264,
          4274,
          2017,
          307,
          5044,
          813,
          512,
          14678,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.21928325566378506,
        "compression_ratio": 1.7291666666666667,
        "end": 4587.48,
        "id": 1346,
        "no_speech_prob": 0.003537631593644619,
        "seek": 456148,
        "start": 4585.48,
        "temperature": 0,
        "text": " you can filter it out.",
        "tokens": [
          51564,
          291,
          393,
          6608,
          309,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23715713749761166,
        "compression_ratio": 1.5238095238095237,
        "end": 4590.48,
        "id": 1347,
        "no_speech_prob": 0.00012930919183418155,
        "seek": 458748,
        "start": 4587.48,
        "temperature": 0,
        "text": " So I'm going to...",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.23715713749761166,
        "compression_ratio": 1.5238095238095237,
        "end": 4596.48,
        "id": 1348,
        "no_speech_prob": 0.00012930919183418155,
        "seek": 458748,
        "start": 4594.48,
        "temperature": 0,
        "text": " The bot is good. Keep the bot.",
        "tokens": [
          50714,
          440,
          10592,
          307,
          665,
          13,
          5527,
          264,
          10592,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23715713749761166,
        "compression_ratio": 1.5238095238095237,
        "end": 4599.48,
        "id": 1349,
        "no_speech_prob": 0.00012930919183418155,
        "seek": 458748,
        "start": 4596.48,
        "temperature": 0,
        "text": " Alright, people are saying... It doesn't really matter.",
        "tokens": [
          50814,
          2798,
          11,
          561,
          366,
          1566,
          485,
          467,
          1177,
          380,
          534,
          1871,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23715713749761166,
        "compression_ratio": 1.5238095238095237,
        "end": 4604.48,
        "id": 1350,
        "no_speech_prob": 0.00012930919183418155,
        "seek": 458748,
        "start": 4599.48,
        "temperature": 0,
        "text": " In the end, the point is for this tutorial series, for me, is to just show the process.",
        "tokens": [
          50964,
          682,
          264,
          917,
          11,
          264,
          935,
          307,
          337,
          341,
          7073,
          2638,
          11,
          337,
          385,
          11,
          307,
          281,
          445,
          855,
          264,
          1399,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23715713749761166,
        "compression_ratio": 1.5238095238095237,
        "end": 4609.48,
        "id": 1351,
        "no_speech_prob": 0.00012930919183418155,
        "seek": 458748,
        "start": 4604.48,
        "temperature": 0,
        "text": " And I'd like to do the process in a reasonable manner, but if I can't, I can't.",
        "tokens": [
          51214,
          400,
          286,
          1116,
          411,
          281,
          360,
          264,
          1399,
          294,
          257,
          10585,
          9060,
          11,
          457,
          498,
          286,
          393,
          380,
          11,
          286,
          393,
          380,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23715713749761166,
        "compression_ratio": 1.5238095238095237,
        "end": 4612.48,
        "id": 1352,
        "no_speech_prob": 0.00012930919183418155,
        "seek": 458748,
        "start": 4610.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23715713749761166,
        "compression_ratio": 1.5238095238095237,
        "end": 4615.48,
        "id": 1353,
        "no_speech_prob": 0.00012930919183418155,
        "seek": 458748,
        "start": 4613.48,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51664,
          2798,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2989379492673007,
        "compression_ratio": 1,
        "end": 4617.48,
        "id": 1354,
        "no_speech_prob": 0.0028305891901254654,
        "seek": 461548,
        "start": 4615.48,
        "temperature": 0,
        "text": " So now...",
        "tokens": [
          50364,
          407,
          586,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2989379492673007,
        "compression_ratio": 1,
        "end": 4620.48,
        "id": 1355,
        "no_speech_prob": 0.0028305891901254654,
        "seek": 461548,
        "start": 4618.48,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50514,
          1692,
          321,
          352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2989379492673007,
        "compression_ratio": 1,
        "end": 4633.48,
        "id": 1356,
        "no_speech_prob": 0.0028305891901254654,
        "seek": 461548,
        "start": 4631.48,
        "temperature": 0,
        "text": " Uh... Okay.",
        "tokens": [
          51164,
          4019,
          485,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2989379492673007,
        "compression_ratio": 1,
        "end": 4635.48,
        "id": 1357,
        "no_speech_prob": 0.0028305891901254654,
        "seek": 461548,
        "start": 4633.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4648.48,
        "id": 1358,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4646.48,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50414,
          21726,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4650.48,
        "id": 1359,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4648.48,
        "temperature": 0,
        "text": " Where's the bot?",
        "tokens": [
          50514,
          2305,
          311,
          264,
          10592,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4652.48,
        "id": 1360,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4650.48,
        "temperature": 0,
        "text": " I felt like I needed to do a...",
        "tokens": [
          50614,
          286,
          2762,
          411,
          286,
          2978,
          281,
          360,
          257,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4655.48,
        "id": 1361,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4652.48,
        "temperature": 0,
        "text": " Dedicate a song to the bot.",
        "tokens": [
          50714,
          41300,
          8700,
          257,
          2153,
          281,
          264,
          10592,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4663.48,
        "id": 1362,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4659.48,
        "temperature": 0,
        "text": " F, P, Q, S, D",
        "tokens": [
          51064,
          479,
          11,
          430,
          11,
          1249,
          11,
          318,
          11,
          413,
          51264
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4667.48,
        "id": 1363,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4664.48,
        "temperature": 0,
        "text": " 6, C, V, N, F",
        "tokens": [
          51314,
          1386,
          11,
          383,
          11,
          691,
          11,
          426,
          11,
          479,
          51464
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4671.48,
        "id": 1364,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4668.48,
        "temperature": 0,
        "text": " Q, M",
        "tokens": [
          51514,
          1249,
          11,
          376,
          51664
        ]
      },
      {
        "avg_logprob": -0.18942505763127254,
        "compression_ratio": 1.1214953271028036,
        "end": 4674.48,
        "id": 1365,
        "no_speech_prob": 0.009843851439654827,
        "seek": 464548,
        "start": 4671.48,
        "temperature": 0,
        "text": " R, P",
        "tokens": [
          51664,
          497,
          11,
          430,
          51814
        ]
      },
      {
        "avg_logprob": -0.1599904280442458,
        "compression_ratio": 1.1370967741935485,
        "end": 4682.48,
        "id": 1366,
        "no_speech_prob": 0.0007436078740283847,
        "seek": 467548,
        "start": 4676.48,
        "temperature": 0,
        "text": " J, D, D, I, Q, J, M, 3, 2",
        "tokens": [
          50414,
          508,
          11,
          413,
          11,
          413,
          11,
          286,
          11,
          1249,
          11,
          508,
          11,
          376,
          11,
          805,
          11,
          568,
          50714
        ]
      },
      {
        "avg_logprob": -0.1599904280442458,
        "compression_ratio": 1.1370967741935485,
        "end": 4684.48,
        "id": 1367,
        "no_speech_prob": 0.0007436078740283847,
        "seek": 467548,
        "start": 4682.48,
        "temperature": 0,
        "text": " Thank you, bot.",
        "tokens": [
          50714,
          1044,
          291,
          11,
          10592,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1599904280442458,
        "compression_ratio": 1.1370967741935485,
        "end": 4688.48,
        "id": 1368,
        "no_speech_prob": 0.0007436078740283847,
        "seek": 467548,
        "start": 4686.48,
        "temperature": 0,
        "text": " I don't know. The ukulele was a bad idea.",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          13,
          440,
          26769,
          2271,
          306,
          390,
          257,
          1578,
          1558,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1599904280442458,
        "compression_ratio": 1.1370967741935485,
        "end": 4690.48,
        "id": 1369,
        "no_speech_prob": 0.0007436078740283847,
        "seek": 467548,
        "start": 4688.48,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51014,
          2798,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1599904280442458,
        "compression_ratio": 1.1370967741935485,
        "end": 4692.48,
        "id": 1370,
        "no_speech_prob": 0.0007436078740283847,
        "seek": 467548,
        "start": 4690.48,
        "temperature": 0,
        "text": " Let's move on.",
        "tokens": [
          51114,
          961,
          311,
          1286,
          322,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1599904280442458,
        "compression_ratio": 1.1370967741935485,
        "end": 4696.48,
        "id": 1371,
        "no_speech_prob": 0.0007436078740283847,
        "seek": 467548,
        "start": 4693.48,
        "temperature": 0,
        "text": " I'm going to cycle those cameras.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          6586,
          729,
          8622,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4699.48,
        "id": 1372,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4697.48,
        "temperature": 0,
        "text": "...",
        "tokens": [
          50414,
          1097,
          50514
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4701.48,
        "id": 1373,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4699.48,
        "temperature": 0,
        "text": "...",
        "tokens": [
          50514,
          1097,
          50614
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4703.48,
        "id": 1374,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4701.48,
        "temperature": 0,
        "text": "...",
        "tokens": [
          50614,
          1097,
          50714
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4706.48,
        "id": 1375,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4703.48,
        "temperature": 0,
        "text": " Will I get to TensorFlow.js today?",
        "tokens": [
          50714,
          3099,
          286,
          483,
          281,
          37624,
          13,
          25530,
          965,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4709.48,
        "id": 1376,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4706.48,
        "temperature": 0,
        "text": " Seems unlikely.",
        "tokens": [
          50864,
          22524,
          17518,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4714.48,
        "id": 1377,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4710.48,
        "temperature": 0,
        "text": " Seems unlikely, but not impossible.",
        "tokens": [
          51064,
          22524,
          17518,
          11,
          457,
          406,
          6243,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4716.48,
        "id": 1378,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4714.48,
        "temperature": 0,
        "text": " Not impossible.",
        "tokens": [
          51264,
          1726,
          6243,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4721.48,
        "id": 1379,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4719.48,
        "temperature": 0,
        "text": "...",
        "tokens": [
          51514,
          1097,
          51614
        ]
      },
      {
        "avg_logprob": -0.37956016540527343,
        "compression_ratio": 1.2989690721649485,
        "end": 4723.48,
        "id": 1380,
        "no_speech_prob": 0.04399597644805908,
        "seek": 469648,
        "start": 4721.48,
        "temperature": 0,
        "text": " Oh, hello.",
        "tokens": [
          51614,
          876,
          11,
          7751,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4728.48,
        "id": 1381,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4723.48,
        "temperature": 0,
        "text": " I'm here, part 3 of cleaning the data, supposedly.",
        "tokens": [
          50364,
          286,
          478,
          510,
          11,
          644,
          805,
          295,
          8924,
          264,
          1412,
          11,
          20581,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4730.48,
        "id": 1382,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4728.48,
        "temperature": 0,
        "text": " It's a lot of work.",
        "tokens": [
          50614,
          467,
          311,
          257,
          688,
          295,
          589,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4734.48,
        "id": 1383,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4730.48,
        "temperature": 0,
        "text": " Just dealing with data is a whole project unto itself.",
        "tokens": [
          50714,
          1449,
          6260,
          365,
          1412,
          307,
          257,
          1379,
          1716,
          16521,
          2564,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4739.48,
        "id": 1384,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4734.48,
        "temperature": 0,
        "text": " I've been here for like 72 hours straight, and I haven't even looked at TensorFlow.js yet.",
        "tokens": [
          50914,
          286,
          600,
          668,
          510,
          337,
          411,
          18731,
          2496,
          2997,
          11,
          293,
          286,
          2378,
          380,
          754,
          2956,
          412,
          37624,
          13,
          25530,
          1939,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4742.48,
        "id": 1385,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4739.48,
        "temperature": 0,
        "text": " I'm just looking at my data, and all I'm doing is color classification.",
        "tokens": [
          51164,
          286,
          478,
          445,
          1237,
          412,
          452,
          1412,
          11,
          293,
          439,
          286,
          478,
          884,
          307,
          2017,
          21538,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4743.48,
        "id": 1386,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4742.48,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51314,
          2798,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4746.48,
        "id": 1387,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4743.48,
        "temperature": 0,
        "text": " I kid, I kid a little bit, but it's true, it's true.",
        "tokens": [
          51364,
          286,
          1636,
          11,
          286,
          1636,
          257,
          707,
          857,
          11,
          457,
          309,
          311,
          2074,
          11,
          309,
          311,
          2074,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4747.48,
        "id": 1388,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4746.48,
        "temperature": 0,
        "text": " So this is the third video.",
        "tokens": [
          51514,
          407,
          341,
          307,
          264,
          2636,
          960,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2242885276452819,
        "compression_ratio": 1.583050847457627,
        "end": 4752.48,
        "id": 1389,
        "no_speech_prob": 0.13458463549613953,
        "seek": 472348,
        "start": 4747.48,
        "temperature": 0,
        "text": " If you watched the previous two, I started trying to visualize what the data looked like",
        "tokens": [
          51564,
          759,
          291,
          6337,
          264,
          3894,
          732,
          11,
          286,
          1409,
          1382,
          281,
          23273,
          437,
          264,
          1412,
          2956,
          411,
          51814
        ]
      },
      {
        "avg_logprob": -0.22063996499044852,
        "compression_ratio": 1.657992565055762,
        "end": 4755.48,
        "id": 1390,
        "no_speech_prob": 0.01168645080178976,
        "seek": 475248,
        "start": 4752.48,
        "temperature": 0,
        "text": " and kind of examine are there certain users that I should filter out that's bad data.",
        "tokens": [
          50364,
          293,
          733,
          295,
          17496,
          366,
          456,
          1629,
          5022,
          300,
          286,
          820,
          6608,
          484,
          300,
          311,
          1578,
          1412,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22063996499044852,
        "compression_ratio": 1.657992565055762,
        "end": 4757.48,
        "id": 1391,
        "no_speech_prob": 0.01168645080178976,
        "seek": 475248,
        "start": 4755.48,
        "temperature": 0,
        "text": " Maybe I should just leave it all in there anyway.",
        "tokens": [
          50514,
          2704,
          286,
          820,
          445,
          1856,
          309,
          439,
          294,
          456,
          4033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22063996499044852,
        "compression_ratio": 1.657992565055762,
        "end": 4766.48,
        "id": 1392,
        "no_speech_prob": 0.01168645080178976,
        "seek": 475248,
        "start": 4757.48,
        "temperature": 0,
        "text": " I'm trying to build a model that looks at a color and classifies it into one of these buckets.",
        "tokens": [
          50614,
          286,
          478,
          1382,
          281,
          1322,
          257,
          2316,
          300,
          1542,
          412,
          257,
          2017,
          293,
          1508,
          11221,
          309,
          666,
          472,
          295,
          613,
          32191,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22063996499044852,
        "compression_ratio": 1.657992565055762,
        "end": 4771.48,
        "id": 1393,
        "no_speech_prob": 0.01168645080178976,
        "seek": 475248,
        "start": 4766.48,
        "temperature": 0,
        "text": " And this is my crowdsource system that allows people to look at colors and click on one of these buckets.",
        "tokens": [
          51064,
          400,
          341,
          307,
          452,
          26070,
          2948,
          1185,
          300,
          4045,
          561,
          281,
          574,
          412,
          4577,
          293,
          2052,
          322,
          472,
          295,
          613,
          32191,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22063996499044852,
        "compression_ratio": 1.657992565055762,
        "end": 4773.48,
        "id": 1394,
        "no_speech_prob": 0.01168645080178976,
        "seek": 475248,
        "start": 4771.48,
        "temperature": 0,
        "text": " So this is a little bit about human perception.",
        "tokens": [
          51314,
          407,
          341,
          307,
          257,
          707,
          857,
          466,
          1952,
          12860,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22063996499044852,
        "compression_ratio": 1.657992565055762,
        "end": 4777.48,
        "id": 1395,
        "no_speech_prob": 0.01168645080178976,
        "seek": 475248,
        "start": 4773.48,
        "temperature": 0,
        "text": " What does the eye sort of see in terms of RGB color?",
        "tokens": [
          51414,
          708,
          775,
          264,
          3313,
          1333,
          295,
          536,
          294,
          2115,
          295,
          31231,
          2017,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.22063996499044852,
        "compression_ratio": 1.657992565055762,
        "end": 4778.48,
        "id": 1396,
        "no_speech_prob": 0.01168645080178976,
        "seek": 475248,
        "start": 4777.48,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51614,
          2798,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19599469006061554,
        "compression_ratio": 1.6493055555555556,
        "end": 4782.48,
        "id": 1397,
        "no_speech_prob": 0.02297593466937542,
        "seek": 477848,
        "start": 4778.48,
        "temperature": 0,
        "text": " So the code base that I'm starting with is from the previous video.",
        "tokens": [
          50364,
          407,
          264,
          3089,
          3096,
          300,
          286,
          478,
          2891,
          365,
          307,
          490,
          264,
          3894,
          960,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19599469006061554,
        "compression_ratio": 1.6493055555555556,
        "end": 4788.48,
        "id": 1398,
        "no_speech_prob": 0.02297593466937542,
        "seek": 477848,
        "start": 4782.48,
        "temperature": 0,
        "text": " I'm just connecting to the Firebase database, and I am looping through and looking at each record one at a time.",
        "tokens": [
          50564,
          286,
          478,
          445,
          11015,
          281,
          264,
          35173,
          8149,
          11,
          293,
          286,
          669,
          6367,
          278,
          807,
          293,
          1237,
          412,
          1184,
          2136,
          472,
          412,
          257,
          565,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19599469006061554,
        "compression_ratio": 1.6493055555555556,
        "end": 4791.48,
        "id": 1399,
        "no_speech_prob": 0.02297593466937542,
        "seek": 477848,
        "start": 4788.48,
        "temperature": 0,
        "text": " Each record has a user ID, which is anonymous.",
        "tokens": [
          50864,
          6947,
          2136,
          575,
          257,
          4195,
          7348,
          11,
          597,
          307,
          24932,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19599469006061554,
        "compression_ratio": 1.6493055555555556,
        "end": 4794.48,
        "id": 1400,
        "no_speech_prob": 0.02297593466937542,
        "seek": 477848,
        "start": 4791.48,
        "temperature": 0,
        "text": " It has an R, a G, a B, and a label.",
        "tokens": [
          51014,
          467,
          575,
          364,
          497,
          11,
          257,
          460,
          11,
          257,
          363,
          11,
          293,
          257,
          7645,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19599469006061554,
        "compression_ratio": 1.6493055555555556,
        "end": 4801.48,
        "id": 1401,
        "no_speech_prob": 0.02297593466937542,
        "seek": 477848,
        "start": 4794.48,
        "temperature": 0,
        "text": " So I determined, you know, not somewhat loosely, I really needed to spend more time and be more thoughtful about this.",
        "tokens": [
          51164,
          407,
          286,
          9540,
          11,
          291,
          458,
          11,
          406,
          8344,
          37966,
          11,
          286,
          534,
          2978,
          281,
          3496,
          544,
          565,
          293,
          312,
          544,
          21566,
          466,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19599469006061554,
        "compression_ratio": 1.6493055555555556,
        "end": 4803.48,
        "id": 1402,
        "no_speech_prob": 0.02297593466937542,
        "seek": 477848,
        "start": 4801.48,
        "temperature": 0,
        "text": " There's an extra comma here.",
        "tokens": [
          51514,
          821,
          311,
          364,
          2857,
          22117,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19599469006061554,
        "compression_ratio": 1.6493055555555556,
        "end": 4806.48,
        "id": 1403,
        "no_speech_prob": 0.02297593466937542,
        "seek": 477848,
        "start": 4803.48,
        "temperature": 0,
        "text": " That these are the three users that I would like to filter out.",
        "tokens": [
          51614,
          663,
          613,
          366,
          264,
          1045,
          5022,
          300,
          286,
          576,
          411,
          281,
          6608,
          484,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16614424443877904,
        "compression_ratio": 1.6135458167330676,
        "end": 4814.48,
        "id": 1404,
        "no_speech_prob": 0.016914550215005875,
        "seek": 480648,
        "start": 4806.48,
        "temperature": 0,
        "text": " So what I want to do in this video by the end of it is have a JSON file that I can print if I wanted to.",
        "tokens": [
          50364,
          407,
          437,
          286,
          528,
          281,
          360,
          294,
          341,
          960,
          538,
          264,
          917,
          295,
          309,
          307,
          362,
          257,
          31828,
          3991,
          300,
          286,
          393,
          4482,
          498,
          286,
          1415,
          281,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16614424443877904,
        "compression_ratio": 1.6135458167330676,
        "end": 4815.48,
        "id": 1405,
        "no_speech_prob": 0.016914550215005875,
        "seek": 480648,
        "start": 4814.48,
        "temperature": 0,
        "text": " I'm not going to print it.",
        "tokens": [
          50764,
          286,
          478,
          406,
          516,
          281,
          4482,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16614424443877904,
        "compression_ratio": 1.6135458167330676,
        "end": 4816.48,
        "id": 1406,
        "no_speech_prob": 0.016914550215005875,
        "seek": 480648,
        "start": 4815.48,
        "temperature": 0,
        "text": " Hold in my virtual hands.",
        "tokens": [
          50814,
          6962,
          294,
          452,
          6374,
          2377,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16614424443877904,
        "compression_ratio": 1.6135458167330676,
        "end": 4819.48,
        "id": 1407,
        "no_speech_prob": 0.016914550215005875,
        "seek": 480648,
        "start": 4816.48,
        "temperature": 0,
        "text": " These are my real hands.",
        "tokens": [
          50864,
          1981,
          366,
          452,
          957,
          2377,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16614424443877904,
        "compression_ratio": 1.6135458167330676,
        "end": 4824.48,
        "id": 1408,
        "no_speech_prob": 0.016914550215005875,
        "seek": 480648,
        "start": 4819.48,
        "temperature": 0,
        "text": " And use that to actually build a machine learning model from.",
        "tokens": [
          51014,
          400,
          764,
          300,
          281,
          767,
          1322,
          257,
          3479,
          2539,
          2316,
          490,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16614424443877904,
        "compression_ratio": 1.6135458167330676,
        "end": 4835.48,
        "id": 1409,
        "no_speech_prob": 0.016914550215005875,
        "seek": 480648,
        "start": 4824.48,
        "temperature": 0,
        "text": " So all I need to do if I want to filter these out is what I did is I made an object that just has those three user IDs as keys arbitrarily with a value of true.",
        "tokens": [
          51264,
          407,
          439,
          286,
          643,
          281,
          360,
          498,
          286,
          528,
          281,
          6608,
          613,
          484,
          307,
          437,
          286,
          630,
          307,
          286,
          1027,
          364,
          2657,
          300,
          445,
          575,
          729,
          1045,
          4195,
          48212,
          382,
          9317,
          19071,
          3289,
          365,
          257,
          2158,
          295,
          2074,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18972439399132363,
        "compression_ratio": 1.5070422535211268,
        "end": 4849.48,
        "id": 1410,
        "no_speech_prob": 0.0010649549076333642,
        "seek": 483548,
        "start": 4835.48,
        "temperature": 0,
        "text": " And then what I can do is I could say if filter does not include this record's user ID.",
        "tokens": [
          50364,
          400,
          550,
          437,
          286,
          393,
          360,
          307,
          286,
          727,
          584,
          498,
          6608,
          775,
          406,
          4090,
          341,
          2136,
          311,
          4195,
          7348,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18972439399132363,
        "compression_ratio": 1.5070422535211268,
        "end": 4855.48,
        "id": 1411,
        "no_speech_prob": 0.0010649549076333642,
        "seek": 483548,
        "start": 4849.48,
        "temperature": 0,
        "text": " And so let's just say let ID equal record user ID.",
        "tokens": [
          51064,
          400,
          370,
          718,
          311,
          445,
          584,
          718,
          7348,
          2681,
          2136,
          4195,
          7348,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18972439399132363,
        "compression_ratio": 1.5070422535211268,
        "end": 4864.48,
        "id": 1412,
        "no_speech_prob": 0.0010649549076333642,
        "seek": 483548,
        "start": 4855.48,
        "temperature": 0,
        "text": " If it's not in the filter, let's make a, let's say all data is a big array.",
        "tokens": [
          51364,
          759,
          309,
          311,
          406,
          294,
          264,
          6608,
          11,
          718,
          311,
          652,
          257,
          11,
          718,
          311,
          584,
          439,
          1412,
          307,
          257,
          955,
          10225,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4867.48,
        "id": 1413,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4864.48,
        "temperature": 0,
        "text": " And actually what I'm going to do is I'm going to make it an object.",
        "tokens": [
          50364,
          400,
          767,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          652,
          309,
          364,
          2657,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4869.48,
        "id": 1414,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4867.48,
        "temperature": 0,
        "text": " You'll see why in a second.",
        "tokens": [
          50514,
          509,
          603,
          536,
          983,
          294,
          257,
          1150,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4873.48,
        "id": 1415,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4869.48,
        "temperature": 0,
        "text": " That has, I'm just going to call it like entries.",
        "tokens": [
          50614,
          663,
          575,
          11,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          411,
          23041,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4875.48,
        "id": 1416,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4873.48,
        "temperature": 0,
        "text": " Which is an array.",
        "tokens": [
          50814,
          3013,
          307,
          364,
          10225,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4883.48,
        "id": 1417,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4875.48,
        "temperature": 0,
        "text": " Then I'm going to say all data.entries.push that record.",
        "tokens": [
          50914,
          1396,
          286,
          478,
          516,
          281,
          584,
          439,
          1412,
          13,
          317,
          2244,
          13,
          79,
          1498,
          300,
          2136,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4886.48,
        "id": 1418,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4883.48,
        "temperature": 0,
        "text": " So what I want to do is I want to look at every single data point.",
        "tokens": [
          51314,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          574,
          412,
          633,
          2167,
          1412,
          935,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4891.48,
        "id": 1419,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4886.48,
        "temperature": 0,
        "text": " And again, there's probably some nice higher order function I could do this in one line of code.",
        "tokens": [
          51464,
          400,
          797,
          11,
          456,
          311,
          1391,
          512,
          1481,
          2946,
          1668,
          2445,
          286,
          727,
          360,
          341,
          294,
          472,
          1622,
          295,
          3089,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1950249481201172,
        "compression_ratio": 1.6867469879518073,
        "end": 4892.48,
        "id": 1420,
        "no_speech_prob": 0.1422235071659088,
        "seek": 486448,
        "start": 4891.48,
        "temperature": 0,
        "text": " But I'm doing this very manually.",
        "tokens": [
          51714,
          583,
          286,
          478,
          884,
          341,
          588,
          16945,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18048350578915756,
        "compression_ratio": 1.6782608695652175,
        "end": 4894.48,
        "id": 1421,
        "no_speech_prob": 0.22813546657562256,
        "seek": 489248,
        "start": 4892.48,
        "temperature": 0,
        "text": " I'm going to look at every record.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          574,
          412,
          633,
          2136,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18048350578915756,
        "compression_ratio": 1.6782608695652175,
        "end": 4895.48,
        "id": 1422,
        "no_speech_prob": 0.22813546657562256,
        "seek": 489248,
        "start": 4894.48,
        "temperature": 0,
        "text": " I'm going to check the user ID.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          1520,
          264,
          4195,
          7348,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18048350578915756,
        "compression_ratio": 1.6782608695652175,
        "end": 4902.48,
        "id": 1423,
        "no_speech_prob": 0.22813546657562256,
        "seek": 489248,
        "start": 4895.48,
        "temperature": 0,
        "text": " If as long as that isn't one of my user IDs that I'm filtering out, I'm going to put it in my all data.entries array.",
        "tokens": [
          50514,
          759,
          382,
          938,
          382,
          300,
          1943,
          380,
          472,
          295,
          452,
          4195,
          48212,
          300,
          286,
          478,
          30822,
          484,
          11,
          286,
          478,
          516,
          281,
          829,
          309,
          294,
          452,
          439,
          1412,
          13,
          317,
          2244,
          10225,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18048350578915756,
        "compression_ratio": 1.6782608695652175,
        "end": 4914.48,
        "id": 1424,
        "no_speech_prob": 0.22813546657562256,
        "seek": 489248,
        "start": 4902.48,
        "temperature": 0,
        "text": " And then I'm going to say save JSON color data.JSON all data.",
        "tokens": [
          50864,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          3155,
          31828,
          2017,
          1412,
          13,
          41,
          10388,
          439,
          1412,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18048350578915756,
        "compression_ratio": 1.6782608695652175,
        "end": 4919.48,
        "id": 1425,
        "no_speech_prob": 0.22813546657562256,
        "seek": 489248,
        "start": 4914.48,
        "temperature": 0,
        "text": " Now this is a p5 function that will then put this JSON file into my downloads directory.",
        "tokens": [
          51464,
          823,
          341,
          307,
          257,
          280,
          20,
          2445,
          300,
          486,
          550,
          829,
          341,
          31828,
          3991,
          666,
          452,
          36553,
          21120,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18048350578915756,
        "compression_ratio": 1.6782608695652175,
        "end": 4921.48,
        "id": 1426,
        "no_speech_prob": 0.22813546657562256,
        "seek": 489248,
        "start": 4919.48,
        "temperature": 0,
        "text": " And I could be doing this in node and server side.",
        "tokens": [
          51714,
          400,
          286,
          727,
          312,
          884,
          341,
          294,
          9984,
          293,
          7154,
          1252,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4924.48,
        "id": 1427,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4921.48,
        "temperature": 0,
        "text": " There's no reason for me to have client side code doing this.",
        "tokens": [
          50364,
          821,
          311,
          572,
          1778,
          337,
          385,
          281,
          362,
          6423,
          1252,
          3089,
          884,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4926.48,
        "id": 1428,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4924.48,
        "temperature": 0,
        "text": " But that's what I'm doing right now.",
        "tokens": [
          50514,
          583,
          300,
          311,
          437,
          286,
          478,
          884,
          558,
          586,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4929.48,
        "id": 1429,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4926.48,
        "temperature": 0,
        "text": " So let's run this and see what happens.",
        "tokens": [
          50614,
          407,
          718,
          311,
          1190,
          341,
          293,
          536,
          437,
          2314,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4933.48,
        "id": 1430,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4929.48,
        "temperature": 0,
        "text": " This is my download data script.",
        "tokens": [
          50764,
          639,
          307,
          452,
          5484,
          1412,
          5755,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4936.48,
        "id": 1431,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4933.48,
        "temperature": 0,
        "text": " A index of is not a function Firebase.",
        "tokens": [
          50964,
          316,
          8186,
          295,
          307,
          406,
          257,
          2445,
          35173,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4938.48,
        "id": 1432,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4936.48,
        "temperature": 0,
        "text": " I don't know, save JSON.",
        "tokens": [
          51114,
          286,
          500,
          380,
          458,
          11,
          3155,
          31828,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4939.48,
        "id": 1433,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4938.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4944.48,
        "id": 1434,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4939.48,
        "temperature": 0,
        "text": " So this maybe, let's look at, maybe it actually goes like this.",
        "tokens": [
          51264,
          407,
          341,
          1310,
          11,
          718,
          311,
          574,
          412,
          11,
          1310,
          309,
          767,
          1709,
          411,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4946.48,
        "id": 1435,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4944.48,
        "temperature": 0,
        "text": " The data and then the file name.",
        "tokens": [
          51514,
          440,
          1412,
          293,
          550,
          264,
          3991,
          1315,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4948.48,
        "id": 1436,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4946.48,
        "temperature": 0,
        "text": " I think that's what it is.",
        "tokens": [
          51614,
          286,
          519,
          300,
          311,
          437,
          309,
          307,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4949.48,
        "id": 1437,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4948.48,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51714,
          1079,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21339705682569934,
        "compression_ratio": 1.563265306122449,
        "end": 4950.48,
        "id": 1438,
        "no_speech_prob": 0.05920742079615593,
        "seek": 492148,
        "start": 4949.48,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51764,
          821,
          321,
          352,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4952.48,
        "id": 1439,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4950.48,
        "temperature": 0,
        "text": " So I have right here this downloaded.",
        "tokens": [
          50364,
          407,
          286,
          362,
          558,
          510,
          341,
          21748,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4959.48,
        "id": 1440,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4952.48,
        "temperature": 0,
        "text": " Now I can take a look at this file.",
        "tokens": [
          50464,
          823,
          286,
          393,
          747,
          257,
          574,
          412,
          341,
          3991,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4960.48,
        "id": 1441,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4959.48,
        "temperature": 0,
        "text": " I can open that file up.",
        "tokens": [
          50814,
          286,
          393,
          1269,
          300,
          3991,
          493,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4962.48,
        "id": 1442,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4960.48,
        "temperature": 0,
        "text": " And we can see, there we go.",
        "tokens": [
          50864,
          400,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4964.48,
        "id": 1443,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4962.48,
        "temperature": 0,
        "text": " Here is my data set.",
        "tokens": [
          50964,
          1692,
          307,
          452,
          1412,
          992,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4966.48,
        "id": 1444,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4964.48,
        "temperature": 0,
        "text": " Hi, this was the shortest video ever.",
        "tokens": [
          51064,
          2421,
          11,
          341,
          390,
          264,
          31875,
          960,
          1562,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4969.48,
        "id": 1445,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4966.48,
        "temperature": 0,
        "text": " So now I have this data set.",
        "tokens": [
          51164,
          407,
          586,
          286,
          362,
          341,
          1412,
          992,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4973.48,
        "id": 1446,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4969.48,
        "temperature": 0,
        "text": " Do I want to, so things that I need to do is I need to normalize the data set.",
        "tokens": [
          51314,
          1144,
          286,
          528,
          281,
          11,
          370,
          721,
          300,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          2710,
          1125,
          264,
          1412,
          992,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20567082491787997,
        "compression_ratio": 1.6682926829268292,
        "end": 4977.48,
        "id": 1447,
        "no_speech_prob": 0.021947888657450676,
        "seek": 495048,
        "start": 4973.48,
        "temperature": 0,
        "text": " And I need to assign the labels numeric values.",
        "tokens": [
          51514,
          400,
          286,
          643,
          281,
          6269,
          264,
          16949,
          7866,
          299,
          4190,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 4983.48,
        "id": 1448,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 4977.48,
        "temperature": 0,
        "text": " Because I'm going to need that for what I want to do with TensorFlow.js.",
        "tokens": [
          50364,
          1436,
          286,
          478,
          516,
          281,
          643,
          300,
          337,
          437,
          286,
          528,
          281,
          360,
          365,
          37624,
          13,
          25530,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 4984.48,
        "id": 1449,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 4983.48,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50664,
          8239,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 4988.48,
        "id": 1450,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 4984.48,
        "temperature": 0,
        "text": " So I think I'm going to need to reshape the data.",
        "tokens": [
          50714,
          407,
          286,
          519,
          286,
          478,
          516,
          281,
          643,
          281,
          725,
          42406,
          264,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 4992.48,
        "id": 1451,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 4988.48,
        "temperature": 0,
        "text": " And turn it into tensors.",
        "tokens": [
          50914,
          400,
          1261,
          309,
          666,
          10688,
          830,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 4994.48,
        "id": 1452,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 4992.48,
        "temperature": 0,
        "text": " I'll do that in the next video.",
        "tokens": [
          51114,
          286,
          603,
          360,
          300,
          294,
          264,
          958,
          960,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 4996.48,
        "id": 1453,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 4994.48,
        "temperature": 0,
        "text": " I might as well just keep sequencing this.",
        "tokens": [
          51214,
          286,
          1062,
          382,
          731,
          445,
          1066,
          32693,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 5000.48,
        "id": 1454,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 4996.48,
        "temperature": 0,
        "text": " So, you know, maybe you could be more thoughtful about, I don't know,",
        "tokens": [
          51314,
          407,
          11,
          291,
          458,
          11,
          1310,
          291,
          727,
          312,
          544,
          21566,
          466,
          11,
          286,
          500,
          380,
          458,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 5002.48,
        "id": 1455,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 5000.48,
        "temperature": 0,
        "text": " I'm trying to give you an exercise to do at the end of this video.",
        "tokens": [
          51514,
          286,
          478,
          1382,
          281,
          976,
          291,
          364,
          5380,
          281,
          360,
          412,
          264,
          917,
          295,
          341,
          960,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 5003.48,
        "id": 1456,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 5002.48,
        "temperature": 0,
        "text": " I got nothing for you.",
        "tokens": [
          51614,
          286,
          658,
          1825,
          337,
          291,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20026165691774284,
        "compression_ratio": 1.6867924528301887,
        "end": 5006.48,
        "id": 1457,
        "no_speech_prob": 0.006692718714475632,
        "seek": 497748,
        "start": 5003.48,
        "temperature": 0,
        "text": " But you could build an interface for this where you could,",
        "tokens": [
          51664,
          583,
          291,
          727,
          1322,
          364,
          9226,
          337,
          341,
          689,
          291,
          727,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5008.48,
        "id": 1458,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5006.48,
        "temperature": 0,
        "text": " maybe you could port this to like a server-side script.",
        "tokens": [
          50364,
          1310,
          291,
          727,
          2436,
          341,
          281,
          411,
          257,
          7154,
          12,
          1812,
          5755,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5010.48,
        "id": 1459,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5008.48,
        "temperature": 0,
        "text": " Maybe you could save it to a CSV file.",
        "tokens": [
          50464,
          2704,
          291,
          727,
          3155,
          309,
          281,
          257,
          48814,
          3991,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5012.48,
        "id": 1460,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5010.48,
        "temperature": 0,
        "text": " Those are some things you could try.",
        "tokens": [
          50564,
          3950,
          366,
          512,
          721,
          291,
          727,
          853,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5014.48,
        "id": 1461,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5012.48,
        "temperature": 0,
        "text": " But in the next video, what I'm going to do,",
        "tokens": [
          50664,
          583,
          294,
          264,
          958,
          960,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5016.48,
        "id": 1462,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5014.48,
        "temperature": 0,
        "text": " I'm going to actually start working with TensorFlow.js.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          767,
          722,
          1364,
          365,
          37624,
          13,
          25530,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5019.48,
        "id": 1463,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5016.48,
        "temperature": 0,
        "text": " I need to turn all of these things into tensors.",
        "tokens": [
          50864,
          286,
          643,
          281,
          1261,
          439,
          295,
          613,
          721,
          666,
          10688,
          830,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5025.48,
        "id": 1464,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5019.48,
        "temperature": 0,
        "text": " Because tensors are the thing that I need to create,",
        "tokens": [
          51014,
          1436,
          10688,
          830,
          366,
          264,
          551,
          300,
          286,
          643,
          281,
          1884,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5027.48,
        "id": 1465,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5025.48,
        "temperature": 0,
        "text": " to train my machine learning model.",
        "tokens": [
          51314,
          281,
          3847,
          452,
          3479,
          2539,
          2316,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5028.48,
        "id": 1466,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5027.48,
        "temperature": 0,
        "text": " Whew.",
        "tokens": [
          51414,
          46029,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5032.48,
        "id": 1467,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5028.48,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51464,
          15528,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16216355315909897,
        "compression_ratio": 1.6224899598393574,
        "end": 5034.48,
        "id": 1468,
        "no_speech_prob": 0.003075342858210206,
        "seek": 500648,
        "start": 5032.48,
        "temperature": 0,
        "text": " Oh, wait a second.",
        "tokens": [
          51664,
          876,
          11,
          1699,
          257,
          1150,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18505571734520695,
        "compression_ratio": 1.3553719008264462,
        "end": 5037.48,
        "id": 1469,
        "no_speech_prob": 0.00831552967429161,
        "seek": 503448,
        "start": 5034.48,
        "temperature": 0,
        "text": " No, did I get the removed ones by accident?",
        "tokens": [
          50364,
          883,
          11,
          630,
          286,
          483,
          264,
          7261,
          2306,
          538,
          6398,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.18505571734520695,
        "compression_ratio": 1.3553719008264462,
        "end": 5046.48,
        "id": 1470,
        "no_speech_prob": 0.00831552967429161,
        "seek": 503448,
        "start": 5037.48,
        "temperature": 0,
        "text": " No, I don't think so.",
        "tokens": [
          50514,
          883,
          11,
          286,
          500,
          380,
          519,
          370,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18505571734520695,
        "compression_ratio": 1.3553719008264462,
        "end": 5047.48,
        "id": 1471,
        "no_speech_prob": 0.00831552967429161,
        "seek": 503448,
        "start": 5046.48,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50964,
          883,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18505571734520695,
        "compression_ratio": 1.3553719008264462,
        "end": 5051.48,
        "id": 1472,
        "no_speech_prob": 0.00831552967429161,
        "seek": 503448,
        "start": 5047.48,
        "temperature": 0,
        "text": " No, these are the not removed ones.",
        "tokens": [
          51014,
          883,
          11,
          613,
          366,
          264,
          406,
          7261,
          2306,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18505571734520695,
        "compression_ratio": 1.3553719008264462,
        "end": 5055.48,
        "id": 1473,
        "no_speech_prob": 0.00831552967429161,
        "seek": 503448,
        "start": 5051.48,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          51214,
          2438,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18505571734520695,
        "compression_ratio": 1.3553719008264462,
        "end": 5057.48,
        "id": 1474,
        "no_speech_prob": 0.00831552967429161,
        "seek": 503448,
        "start": 5055.48,
        "temperature": 0,
        "text": " I did something in reverse here.",
        "tokens": [
          51414,
          286,
          630,
          746,
          294,
          9943,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18505571734520695,
        "compression_ratio": 1.3553719008264462,
        "end": 5058.48,
        "id": 1475,
        "no_speech_prob": 0.00831552967429161,
        "seek": 503448,
        "start": 5057.48,
        "temperature": 0,
        "text": " All right, let's see.",
        "tokens": [
          51514,
          1057,
          558,
          11,
          718,
          311,
          536,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15562792051406132,
        "compression_ratio": 1.0957446808510638,
        "end": 5066.48,
        "id": 1476,
        "no_speech_prob": 0.3557083010673523,
        "seek": 505848,
        "start": 5058.48,
        "temperature": 0,
        "text": " Did I?",
        "tokens": [
          50364,
          2589,
          286,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.15562792051406132,
        "compression_ratio": 1.0957446808510638,
        "end": 5070.48,
        "id": 1477,
        "no_speech_prob": 0.3557083010673523,
        "seek": 505848,
        "start": 5066.48,
        "temperature": 0,
        "text": " I think if it's not there, add it.",
        "tokens": [
          50764,
          286,
          519,
          498,
          309,
          311,
          406,
          456,
          11,
          909,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15562792051406132,
        "compression_ratio": 1.0957446808510638,
        "end": 5074.48,
        "id": 1478,
        "no_speech_prob": 0.3557083010673523,
        "seek": 505848,
        "start": 5070.48,
        "temperature": 0,
        "text": " I think I'm okay.",
        "tokens": [
          50964,
          286,
          519,
          286,
          478,
          1392,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15562792051406132,
        "compression_ratio": 1.0957446808510638,
        "end": 5086.48,
        "id": 1479,
        "no_speech_prob": 0.3557083010673523,
        "seek": 505848,
        "start": 5074.48,
        "temperature": 0,
        "text": " Let's, let me not save the JSON file again.",
        "tokens": [
          51164,
          961,
          311,
          11,
          718,
          385,
          406,
          3155,
          264,
          31828,
          3991,
          797,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5087.48,
        "id": 1480,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5086.48,
        "temperature": 0,
        "text": " Yeah, 5, 6, 4, 3.",
        "tokens": [
          50364,
          865,
          11,
          1025,
          11,
          1386,
          11,
          1017,
          11,
          805,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5089.48,
        "id": 1481,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5087.48,
        "temperature": 0,
        "text": " I think I'm good.",
        "tokens": [
          50414,
          286,
          519,
          286,
          478,
          665,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5090.48,
        "id": 1482,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5089.48,
        "temperature": 0,
        "text": " Oh, the bot.",
        "tokens": [
          50514,
          876,
          11,
          264,
          10592,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5091.48,
        "id": 1483,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5090.48,
        "temperature": 0,
        "text": " Yes, the bot is in there.",
        "tokens": [
          50564,
          1079,
          11,
          264,
          10592,
          307,
          294,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5092.48,
        "id": 1484,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5091.48,
        "temperature": 0,
        "text": " Yeah, I got it.",
        "tokens": [
          50614,
          865,
          11,
          286,
          658,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5097.48,
        "id": 1485,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5092.48,
        "temperature": 0,
        "text": " I got it correct.",
        "tokens": [
          50664,
          286,
          658,
          309,
          3006,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5100.48,
        "id": 1486,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5097.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50914,
          1057,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5103.48,
        "id": 1487,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5100.48,
        "temperature": 0,
        "text": " I'm probably going to be coming back on Monday to finish this.",
        "tokens": [
          51064,
          286,
          478,
          1391,
          516,
          281,
          312,
          1348,
          646,
          322,
          8138,
          281,
          2413,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5105.48,
        "id": 1488,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5103.48,
        "temperature": 0,
        "text": " Go watch Boarding T with CJ.",
        "tokens": [
          51214,
          1037,
          1159,
          10008,
          278,
          314,
          365,
          42285,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5106.48,
        "id": 1489,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5105.48,
        "temperature": 0,
        "text": " It's on YouTube right now.",
        "tokens": [
          51314,
          467,
          311,
          322,
          3088,
          558,
          586,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5112.48,
        "id": 1490,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5106.48,
        "temperature": 0,
        "text": " I'm getting a notification.",
        "tokens": [
          51364,
          286,
          478,
          1242,
          257,
          11554,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5113.48,
        "id": 1491,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5112.48,
        "temperature": 0,
        "text": " 112.",
        "tokens": [
          51664,
          502,
          4762,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1524070348495092,
        "compression_ratio": 1.4519230769230769,
        "end": 5115.48,
        "id": 1492,
        "no_speech_prob": 0.14607805013656616,
        "seek": 508648,
        "start": 5113.48,
        "temperature": 0,
        "text": " I'm running out of steam here.",
        "tokens": [
          51714,
          286,
          478,
          2614,
          484,
          295,
          11952,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.230598276311701,
        "compression_ratio": 0.8723404255319149,
        "end": 5120.48,
        "id": 1493,
        "no_speech_prob": 0.19191767275333405,
        "seek": 511548,
        "start": 5115.48,
        "temperature": 0,
        "text": " Boy, this is a lot of work.",
        "tokens": [
          50364,
          9486,
          11,
          341,
          307,
          257,
          688,
          295,
          589,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.230598276311701,
        "compression_ratio": 0.8723404255319149,
        "end": 5122.48,
        "id": 1494,
        "no_speech_prob": 0.19191767275333405,
        "seek": 511548,
        "start": 5120.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.230598276311701,
        "compression_ratio": 0.8723404255319149,
        "end": 5126.48,
        "id": 1495,
        "no_speech_prob": 0.19191767275333405,
        "seek": 511548,
        "start": 5122.48,
        "temperature": 0,
        "text": " So now.",
        "tokens": [
          50714,
          407,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2678520312676063,
        "compression_ratio": 0.7948717948717948,
        "end": 5154.48,
        "id": 1496,
        "no_speech_prob": 0.3883167505264282,
        "seek": 512648,
        "start": 5127.48,
        "temperature": 0,
        "text": " Now what I need to do, desktop.",
        "tokens": [
          50414,
          823,
          437,
          286,
          643,
          281,
          360,
          11,
          14502,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3151755523681641,
        "compression_ratio": 1.1946902654867257,
        "end": 5159.48,
        "id": 1497,
        "no_speech_prob": 0.7459831833839417,
        "seek": 515448,
        "start": 5155.48,
        "temperature": 0,
        "text": " I'm looking for P5 TensorFlow.",
        "tokens": [
          50414,
          286,
          478,
          1237,
          337,
          430,
          20,
          37624,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3151755523681641,
        "compression_ratio": 1.1946902654867257,
        "end": 5163.48,
        "id": 1498,
        "no_speech_prob": 0.7459831833839417,
        "seek": 515448,
        "start": 5159.48,
        "temperature": 0,
        "text": " Color classifier.",
        "tokens": [
          50614,
          10458,
          1508,
          9902,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3151755523681641,
        "compression_ratio": 1.1946902654867257,
        "end": 5168.48,
        "id": 1499,
        "no_speech_prob": 0.7459831833839417,
        "seek": 515448,
        "start": 5163.48,
        "temperature": 0,
        "text": " So this is now.",
        "tokens": [
          50814,
          407,
          341,
          307,
          586,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3151755523681641,
        "compression_ratio": 1.1946902654867257,
        "end": 5171.48,
        "id": 1500,
        "no_speech_prob": 0.7459831833839417,
        "seek": 515448,
        "start": 5168.48,
        "temperature": 0,
        "text": " Oh, I need to.",
        "tokens": [
          51064,
          876,
          11,
          286,
          643,
          281,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3151755523681641,
        "compression_ratio": 1.1946902654867257,
        "end": 5176.48,
        "id": 1501,
        "no_speech_prob": 0.7459831833839417,
        "seek": 515448,
        "start": 5171.48,
        "temperature": 0,
        "text": " Now I need to.",
        "tokens": [
          51214,
          823,
          286,
          643,
          281,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3151755523681641,
        "compression_ratio": 1.1946902654867257,
        "end": 5183.48,
        "id": 1502,
        "no_speech_prob": 0.7459831833839417,
        "seek": 515448,
        "start": 5176.48,
        "temperature": 0,
        "text": " Get myself a reference to TensorFlow JS.",
        "tokens": [
          51464,
          3240,
          2059,
          257,
          6408,
          281,
          37624,
          33063,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2230765731246383,
        "compression_ratio": 0.9178082191780822,
        "end": 5187.48,
        "id": 1503,
        "no_speech_prob": 0.2845296859741211,
        "seek": 518348,
        "start": 5183.48,
        "temperature": 0,
        "text": " No more Firebase.",
        "tokens": [
          50364,
          883,
          544,
          35173,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2230765731246383,
        "compression_ratio": 0.9178082191780822,
        "end": 5195.48,
        "id": 1504,
        "no_speech_prob": 0.2845296859741211,
        "seek": 518348,
        "start": 5187.48,
        "temperature": 0,
        "text": " Color classifier.",
        "tokens": [
          50564,
          10458,
          1508,
          9902,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2230765731246383,
        "compression_ratio": 0.9178082191780822,
        "end": 5200.48,
        "id": 1505,
        "no_speech_prob": 0.2845296859741211,
        "seek": 518348,
        "start": 5195.48,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50964,
          400,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2230765731246383,
        "compression_ratio": 0.9178082191780822,
        "end": 5211.48,
        "id": 1506,
        "no_speech_prob": 0.2845296859741211,
        "seek": 518348,
        "start": 5200.48,
        "temperature": 0,
        "text": " Then I need the JSON file.",
        "tokens": [
          51214,
          1396,
          286,
          643,
          264,
          31828,
          3991,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5215.48,
        "id": 1507,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5212.48,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50414,
          400,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5220.48,
        "id": 1508,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5215.48,
        "temperature": 0,
        "text": " Let me rename this to one because I might kind of save it.",
        "tokens": [
          50564,
          961,
          385,
          36741,
          341,
          281,
          472,
          570,
          286,
          1062,
          733,
          295,
          3155,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5223.48,
        "id": 1509,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5220.48,
        "temperature": 0,
        "text": " The source code with each one.",
        "tokens": [
          50814,
          440,
          4009,
          3089,
          365,
          1184,
          472,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5228.48,
        "id": 1510,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5223.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5229.48,
        "id": 1511,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5228.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5233.48,
        "id": 1512,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5229.48,
        "temperature": 0,
        "text": " Don't overcharge my laptop.",
        "tokens": [
          51264,
          1468,
          380,
          670,
          13604,
          452,
          10732,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5234.48,
        "id": 1513,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5233.48,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51464,
          876,
          452,
          8387,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5238.48,
        "id": 1514,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5234.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51514,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2687794367472331,
        "compression_ratio": 1.2919708029197081,
        "end": 5239.48,
        "id": 1515,
        "no_speech_prob": 0.13844606280326843,
        "seek": 521148,
        "start": 5238.48,
        "temperature": 0,
        "text": " So what's next here?",
        "tokens": [
          51714,
          407,
          437,
          311,
          958,
          510,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.17878406926205284,
        "compression_ratio": 0.8870967741935484,
        "end": 5264.48,
        "id": 1516,
        "no_speech_prob": 0.26275312900543213,
        "seek": 523948,
        "start": 5239.48,
        "temperature": 0,
        "text": " Let me erase the whiteboard.",
        "tokens": [
          50364,
          961,
          385,
          23525,
          264,
          2418,
          3787,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17878406926205284,
        "compression_ratio": 0.8870967741935484,
        "end": 5266.48,
        "id": 1517,
        "no_speech_prob": 0.26275312900543213,
        "seek": 523948,
        "start": 5264.48,
        "temperature": 0,
        "text": " So many things to discuss.",
        "tokens": [
          51614,
          407,
          867,
          721,
          281,
          2248,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2417616049448649,
        "compression_ratio": 1.3157894736842106,
        "end": 5270.48,
        "id": 1518,
        "no_speech_prob": 0.22538582980632782,
        "seek": 526648,
        "start": 5267.48,
        "temperature": 0,
        "text": " I've got to talk about Softmax, cross entropy.",
        "tokens": [
          50414,
          286,
          600,
          658,
          281,
          751,
          466,
          16985,
          41167,
          11,
          3278,
          30867,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2417616049448649,
        "compression_ratio": 1.3157894736842106,
        "end": 5274.48,
        "id": 1519,
        "no_speech_prob": 0.22538582980632782,
        "seek": 526648,
        "start": 5270.48,
        "temperature": 0,
        "text": " These are new concepts that I haven't used in any video before.",
        "tokens": [
          50564,
          1981,
          366,
          777,
          10392,
          300,
          286,
          2378,
          380,
          1143,
          294,
          604,
          960,
          949,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2417616049448649,
        "compression_ratio": 1.3157894736842106,
        "end": 5289.48,
        "id": 1520,
        "no_speech_prob": 0.22538582980632782,
        "seek": 526648,
        "start": 5274.48,
        "temperature": 0,
        "text": " One hot encoding is something that I'm going to want to discuss.",
        "tokens": [
          50764,
          1485,
          2368,
          43430,
          307,
          746,
          300,
          286,
          478,
          516,
          281,
          528,
          281,
          2248,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5297.48,
        "id": 1521,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5290.48,
        "temperature": 0,
        "text": " My plan in my head is to make a ML5 version of this.",
        "tokens": [
          50414,
          1222,
          1393,
          294,
          452,
          1378,
          307,
          281,
          652,
          257,
          21601,
          20,
          3037,
          295,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5301.48,
        "id": 1522,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5297.48,
        "temperature": 0,
        "text": " In which you don't have to architect the model.",
        "tokens": [
          50764,
          682,
          597,
          291,
          500,
          380,
          362,
          281,
          6331,
          264,
          2316,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5305.48,
        "id": 1523,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5301.48,
        "temperature": 0,
        "text": " And you also don't have to worry about the one hot encoding.",
        "tokens": [
          50964,
          400,
          291,
          611,
          500,
          380,
          362,
          281,
          3292,
          466,
          264,
          472,
          2368,
          43430,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5307.48,
        "id": 1524,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5305.48,
        "temperature": 0,
        "text": " I realize most of you watching this probably don't know what it is.",
        "tokens": [
          51164,
          286,
          4325,
          881,
          295,
          291,
          1976,
          341,
          1391,
          500,
          380,
          458,
          437,
          309,
          307,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5309.48,
        "id": 1525,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5307.48,
        "temperature": 0,
        "text": " I didn't know what it is until very recently.",
        "tokens": [
          51264,
          286,
          994,
          380,
          458,
          437,
          309,
          307,
          1826,
          588,
          3938,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5310.48,
        "id": 1526,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5309.48,
        "temperature": 0,
        "text": " And I'm not even sure I know what it is.",
        "tokens": [
          51364,
          400,
          286,
          478,
          406,
          754,
          988,
          286,
          458,
          437,
          309,
          307,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5311.48,
        "id": 1527,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5310.48,
        "temperature": 0,
        "text": " But I think I know what it is.",
        "tokens": [
          51414,
          583,
          286,
          519,
          286,
          458,
          437,
          309,
          307,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5315.48,
        "id": 1528,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5311.48,
        "temperature": 0,
        "text": " So I'm conflicted about how I'm doing this.",
        "tokens": [
          51464,
          407,
          286,
          478,
          6596,
          292,
          466,
          577,
          286,
          478,
          884,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22767248887282152,
        "compression_ratio": 1.7611336032388665,
        "end": 5317.48,
        "id": 1529,
        "no_speech_prob": 0.5810061693191528,
        "seek": 528948,
        "start": 5315.48,
        "temperature": 0,
        "text": " Because I'm all in a sort of strange order.",
        "tokens": [
          51664,
          1436,
          286,
          478,
          439,
          294,
          257,
          1333,
          295,
          5861,
          1668,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5319.48,
        "id": 1530,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5317.48,
        "temperature": 0,
        "text": " But it is what it is.",
        "tokens": [
          50364,
          583,
          309,
          307,
          437,
          309,
          307,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5323.48,
        "id": 1531,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5319.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5325.48,
        "id": 1532,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5323.48,
        "temperature": 0,
        "text": " I definitely want to do some more TVEX stuff.",
        "tokens": [
          50664,
          286,
          2138,
          528,
          281,
          360,
          512,
          544,
          314,
          7540,
          55,
          1507,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5326.48,
        "id": 1533,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5325.48,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50764,
          1079,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5330.48,
        "id": 1534,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5326.48,
        "temperature": 0,
        "text": " Matthew Cohen in the chat requests, suggests.",
        "tokens": [
          50814,
          12434,
          32968,
          294,
          264,
          5081,
          12475,
          11,
          13409,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5332.48,
        "id": 1535,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5330.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5339.48,
        "id": 1536,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5332.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2777310756214878,
        "compression_ratio": 1.2148760330578512,
        "end": 5345.48,
        "id": 1537,
        "no_speech_prob": 0.14996689558029175,
        "seek": 531748,
        "start": 5339.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51464,
          1057,
          558,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5349.48,
        "id": 1538,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5345.48,
        "temperature": 0,
        "text": " This video merits a train whistle.",
        "tokens": [
          50364,
          639,
          960,
          40923,
          257,
          3847,
          23470,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5351.48,
        "id": 1539,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5349.48,
        "temperature": 0,
        "text": " I am in my series.",
        "tokens": [
          50564,
          286,
          669,
          294,
          452,
          2638,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5354.48,
        "id": 1540,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5351.48,
        "temperature": 0,
        "text": " I'm on video 731.",
        "tokens": [
          50664,
          286,
          478,
          322,
          960,
          1614,
          12967,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5356.48,
        "id": 1541,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5354.48,
        "temperature": 0,
        "text": " Or something like that.",
        "tokens": [
          50814,
          1610,
          746,
          411,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5358.48,
        "id": 1542,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5356.48,
        "temperature": 0,
        "text": " About building a color classifier.",
        "tokens": [
          50914,
          7769,
          2390,
          257,
          2017,
          1508,
          9902,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5362.48,
        "id": 1543,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5358.48,
        "temperature": 0,
        "text": " I'm trying to look at the overall concept of machine learning.",
        "tokens": [
          51014,
          286,
          478,
          1382,
          281,
          574,
          412,
          264,
          4787,
          3410,
          295,
          3479,
          2539,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5364.48,
        "id": 1544,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5362.48,
        "temperature": 0,
        "text": " And building a color classifier.",
        "tokens": [
          51214,
          400,
          2390,
          257,
          2017,
          1508,
          9902,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5365.48,
        "id": 1545,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5364.48,
        "temperature": 0,
        "text": " So where am I?",
        "tokens": [
          51314,
          407,
          689,
          669,
          286,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5369.48,
        "id": 1546,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5365.48,
        "temperature": 0,
        "text": " I spent a bunch of videos crowdsourcing and cleaning data.",
        "tokens": [
          51364,
          286,
          4418,
          257,
          3840,
          295,
          2145,
          26070,
          41849,
          293,
          8924,
          1412,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5372.48,
        "id": 1547,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5369.48,
        "temperature": 0,
        "text": " And where I left off, I have this JSON file.",
        "tokens": [
          51564,
          400,
          689,
          286,
          1411,
          766,
          11,
          286,
          362,
          341,
          31828,
          3991,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17328877284609037,
        "compression_ratio": 1.6115702479338843,
        "end": 5374.48,
        "id": 1548,
        "no_speech_prob": 0.09137239307165146,
        "seek": 534548,
        "start": 5372.48,
        "temperature": 0,
        "text": " That has a whole bunch of data points in it.",
        "tokens": [
          51714,
          663,
          575,
          257,
          1379,
          3840,
          295,
          1412,
          2793,
          294,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5378.48,
        "id": 1549,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5374.48,
        "temperature": 0,
        "text": " Each entry has an RGB value and a label.",
        "tokens": [
          50364,
          6947,
          8729,
          575,
          364,
          31231,
          2158,
          293,
          257,
          7645,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5380.48,
        "id": 1550,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5378.48,
        "temperature": 0,
        "text": " So there are nine labels.",
        "tokens": [
          50564,
          407,
          456,
          366,
          4949,
          16949,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5383.48,
        "id": 1551,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5380.48,
        "temperature": 0,
        "text": " And there are obviously millions of possibilities for the RGB values.",
        "tokens": [
          50664,
          400,
          456,
          366,
          2745,
          6803,
          295,
          12178,
          337,
          264,
          31231,
          4190,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5387.48,
        "id": 1552,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5383.48,
        "temperature": 0,
        "text": " So what's the next step here?",
        "tokens": [
          50814,
          407,
          437,
          311,
          264,
          958,
          1823,
          510,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5389.48,
        "id": 1553,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5387.48,
        "temperature": 0,
        "text": " So many things to think about.",
        "tokens": [
          51014,
          407,
          867,
          721,
          281,
          519,
          466,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5392.48,
        "id": 1554,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5389.48,
        "temperature": 0,
        "text": " Let's go back to this tutorial that I referenced.",
        "tokens": [
          51114,
          961,
          311,
          352,
          646,
          281,
          341,
          7073,
          300,
          286,
          32734,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5394.48,
        "id": 1555,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5392.48,
        "temperature": 0,
        "text": " That's part of the ML5 project.",
        "tokens": [
          51264,
          663,
          311,
          644,
          295,
          264,
          21601,
          20,
          1716,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5396.48,
        "id": 1556,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5394.48,
        "temperature": 0,
        "text": " Called making your own data sets.",
        "tokens": [
          51364,
          45001,
          1455,
          428,
          1065,
          1412,
          6352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5398.48,
        "id": 1557,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5396.48,
        "temperature": 0,
        "text": " This is by artist and researcher Hannah Davis.",
        "tokens": [
          51464,
          639,
          307,
          538,
          5748,
          293,
          21751,
          21754,
          15658,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5401.48,
        "id": 1558,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5398.48,
        "temperature": 0,
        "text": " And other contributors who may have also edited this page.",
        "tokens": [
          51564,
          400,
          661,
          45627,
          567,
          815,
          362,
          611,
          23016,
          341,
          3028,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18192562387009298,
        "compression_ratio": 1.6236559139784945,
        "end": 5403.48,
        "id": 1559,
        "no_speech_prob": 0.0022871666587889194,
        "seek": 537448,
        "start": 5401.48,
        "temperature": 0,
        "text": " But it started with Hannah Davis.",
        "tokens": [
          51714,
          583,
          309,
          1409,
          365,
          21754,
          15658,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5408.48,
        "id": 1560,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5403.48,
        "temperature": 0,
        "text": " I'll link to information about her in this page in the video's description.",
        "tokens": [
          50364,
          286,
          603,
          2113,
          281,
          1589,
          466,
          720,
          294,
          341,
          3028,
          294,
          264,
          960,
          311,
          3855,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5411.48,
        "id": 1561,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5408.48,
        "temperature": 0,
        "text": " Now one thing you want to look here that I think is important.",
        "tokens": [
          50614,
          823,
          472,
          551,
          291,
          528,
          281,
          574,
          510,
          300,
          286,
          519,
          307,
          1021,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5414.48,
        "id": 1562,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5411.48,
        "temperature": 0,
        "text": " Is preparing your data set for machine learning.",
        "tokens": [
          50764,
          1119,
          10075,
          428,
          1412,
          992,
          337,
          3479,
          2539,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5417.48,
        "id": 1563,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5414.48,
        "temperature": 0,
        "text": " Trading, testing, and validation.",
        "tokens": [
          50914,
          49929,
          11,
          4997,
          11,
          293,
          24071,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5419.48,
        "id": 1564,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5417.48,
        "temperature": 0,
        "text": " So I forget.",
        "tokens": [
          51064,
          407,
          286,
          2870,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5421.48,
        "id": 1565,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5419.48,
        "temperature": 0,
        "text": " The first thing, let me do something first here.",
        "tokens": [
          51164,
          440,
          700,
          551,
          11,
          718,
          385,
          360,
          746,
          700,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5423.48,
        "id": 1566,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5421.48,
        "temperature": 0,
        "text": " Let me actually write some code, strangely enough.",
        "tokens": [
          51264,
          961,
          385,
          767,
          2464,
          512,
          3089,
          11,
          39851,
          1547,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5425.48,
        "id": 1567,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5423.48,
        "temperature": 0,
        "text": " And I've got P5 loaded up here.",
        "tokens": [
          51364,
          400,
          286,
          600,
          658,
          430,
          20,
          13210,
          493,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2415391871359496,
        "compression_ratio": 1.5909090909090908,
        "end": 5429.48,
        "id": 1568,
        "no_speech_prob": 0.002115607960149646,
        "seek": 540348,
        "start": 5425.48,
        "temperature": 0,
        "text": " As kind of like a base JavaScript library that I use.",
        "tokens": [
          51464,
          1018,
          733,
          295,
          411,
          257,
          3096,
          15778,
          6405,
          300,
          286,
          764,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5434.48,
        "id": 1569,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5430.48,
        "temperature": 0,
        "text": " And I'm going to add the preload function.",
        "tokens": [
          50414,
          400,
          286,
          478,
          516,
          281,
          909,
          264,
          659,
          2907,
          2445,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5438.48,
        "id": 1570,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5434.48,
        "temperature": 0,
        "text": " And I'm going to say let data.",
        "tokens": [
          50614,
          400,
          286,
          478,
          516,
          281,
          584,
          718,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5442.48,
        "id": 1571,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5438.48,
        "temperature": 0,
        "text": " And I'm going to say data equals load JSON.",
        "tokens": [
          50814,
          400,
          286,
          478,
          516,
          281,
          584,
          1412,
          6915,
          3677,
          31828,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5445.48,
        "id": 1572,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5442.48,
        "temperature": 0,
        "text": " And it's called color data dot JSON.",
        "tokens": [
          51014,
          400,
          309,
          311,
          1219,
          2017,
          1412,
          5893,
          31828,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5447.48,
        "id": 1573,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5445.48,
        "temperature": 0,
        "text": " So I just want to load that file.",
        "tokens": [
          51164,
          407,
          286,
          445,
          528,
          281,
          3677,
          300,
          3991,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5451.48,
        "id": 1574,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5447.48,
        "temperature": 0,
        "text": " And then I'm going to say console dot log data dot entries dot length.",
        "tokens": [
          51264,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11076,
          5893,
          3565,
          1412,
          5893,
          23041,
          5893,
          4641,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5454.48,
        "id": 1575,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5451.48,
        "temperature": 0,
        "text": " So let's just see how many data points do I have.",
        "tokens": [
          51464,
          407,
          718,
          311,
          445,
          536,
          577,
          867,
          1412,
          2793,
          360,
          286,
          362,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.161540395563299,
        "compression_ratio": 1.8217821782178218,
        "end": 5457.48,
        "id": 1576,
        "no_speech_prob": 0.06277642399072647,
        "seek": 542948,
        "start": 5454.48,
        "temperature": 0,
        "text": " Let me make sure I can indeed load that file into my code.",
        "tokens": [
          51614,
          961,
          385,
          652,
          988,
          286,
          393,
          6451,
          3677,
          300,
          3991,
          666,
          452,
          3089,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5460.48,
        "id": 1577,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5457.48,
        "temperature": 0,
        "text": " And look at how many data points I have.",
        "tokens": [
          50364,
          400,
          574,
          412,
          577,
          867,
          1412,
          2793,
          286,
          362,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5461.48,
        "id": 1578,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5460.48,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          50514,
          407,
          510,
          321,
          352,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5463.48,
        "id": 1579,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5461.48,
        "temperature": 0,
        "text": " Oh, I'm in the wrong sketch.",
        "tokens": [
          50564,
          876,
          11,
          286,
          478,
          294,
          264,
          2085,
          12325,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5465.48,
        "id": 1580,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5463.48,
        "temperature": 0,
        "text": " I changed it to here.",
        "tokens": [
          50664,
          286,
          3105,
          309,
          281,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5468.48,
        "id": 1581,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5465.48,
        "temperature": 0,
        "text": " 5,643.",
        "tokens": [
          50764,
          1025,
          11,
          21,
          17201,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5470.48,
        "id": 1582,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5468.48,
        "temperature": 0,
        "text": " I can read numbers.",
        "tokens": [
          50914,
          286,
          393,
          1401,
          3547,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5471.48,
        "id": 1583,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5470.48,
        "temperature": 0,
        "text": " Is that number perhaps?",
        "tokens": [
          51014,
          1119,
          300,
          1230,
          4317,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5474.48,
        "id": 1584,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5471.48,
        "temperature": 0,
        "text": " Perhaps that number could be found somewhere in my random number book.",
        "tokens": [
          51064,
          10517,
          300,
          1230,
          727,
          312,
          1352,
          4079,
          294,
          452,
          4974,
          1230,
          1446,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5477.48,
        "id": 1585,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5474.48,
        "temperature": 0,
        "text": " But that's a, I'll look for it later.",
        "tokens": [
          51214,
          583,
          300,
          311,
          257,
          11,
          286,
          603,
          574,
          337,
          309,
          1780,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5480.48,
        "id": 1586,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5477.48,
        "temperature": 0,
        "text": " So okay, why did I say that?",
        "tokens": [
          51364,
          407,
          1392,
          11,
          983,
          630,
          286,
          584,
          300,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1809595711210854,
        "compression_ratio": 1.5344827586206897,
        "end": 5483.48,
        "id": 1587,
        "no_speech_prob": 0.010327917523682117,
        "seek": 545748,
        "start": 5480.48,
        "temperature": 0,
        "text": " So if we come over back to this page that I was referencing.",
        "tokens": [
          51514,
          407,
          498,
          321,
          808,
          670,
          646,
          281,
          341,
          3028,
          300,
          286,
          390,
          40582,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19087378619468376,
        "compression_ratio": 1.5575757575757576,
        "end": 5488.48,
        "id": 1588,
        "no_speech_prob": 0.004905355162918568,
        "seek": 548348,
        "start": 5484.48,
        "temperature": 0,
        "text": " We need to, if I'm going to build a classifier,",
        "tokens": [
          50414,
          492,
          643,
          281,
          11,
          498,
          286,
          478,
          516,
          281,
          1322,
          257,
          1508,
          9902,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.19087378619468376,
        "compression_ratio": 1.5575757575757576,
        "end": 5496.48,
        "id": 1589,
        "no_speech_prob": 0.004905355162918568,
        "seek": 548348,
        "start": 5488.48,
        "temperature": 0,
        "text": " the way I'm going to do this is by having training data and testing data.",
        "tokens": [
          50614,
          264,
          636,
          286,
          478,
          516,
          281,
          360,
          341,
          307,
          538,
          1419,
          3097,
          1412,
          293,
          4997,
          1412,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19087378619468376,
        "compression_ratio": 1.5575757575757576,
        "end": 5502.48,
        "id": 1590,
        "no_speech_prob": 0.004905355162918568,
        "seek": 548348,
        "start": 5496.48,
        "temperature": 0,
        "text": " Now, there is also something called validation data.",
        "tokens": [
          51014,
          823,
          11,
          456,
          307,
          611,
          746,
          1219,
          24071,
          1412,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19087378619468376,
        "compression_ratio": 1.5575757575757576,
        "end": 5506.48,
        "id": 1591,
        "no_speech_prob": 0.004905355162918568,
        "seek": 548348,
        "start": 5502.48,
        "temperature": 0,
        "text": " Let's go look back at this web page.",
        "tokens": [
          51314,
          961,
          311,
          352,
          574,
          646,
          412,
          341,
          3670,
          3028,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19087378619468376,
        "compression_ratio": 1.5575757575757576,
        "end": 5509.48,
        "id": 1592,
        "no_speech_prob": 0.004905355162918568,
        "seek": 548348,
        "start": 5506.48,
        "temperature": 0,
        "text": " Training data set is used to train the model.",
        "tokens": [
          51514,
          20620,
          1412,
          992,
          307,
          1143,
          281,
          3847,
          264,
          2316,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18132848006028396,
        "compression_ratio": 1.7777777777777777,
        "end": 5514.48,
        "id": 1593,
        "no_speech_prob": 0.015424060635268688,
        "seek": 550948,
        "start": 5509.48,
        "temperature": 0,
        "text": " Validation data sets are used to change the parameters of the model.",
        "tokens": [
          50364,
          7188,
          327,
          399,
          1412,
          6352,
          366,
          1143,
          281,
          1319,
          264,
          9834,
          295,
          264,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18132848006028396,
        "compression_ratio": 1.7777777777777777,
        "end": 5518.48,
        "id": 1594,
        "no_speech_prob": 0.015424060635268688,
        "seek": 550948,
        "start": 5514.48,
        "temperature": 0,
        "text": " So I'm going to, for the purpose of this video,",
        "tokens": [
          50614,
          407,
          286,
          478,
          516,
          281,
          11,
          337,
          264,
          4334,
          295,
          341,
          960,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.18132848006028396,
        "compression_ratio": 1.7777777777777777,
        "end": 5521.48,
        "id": 1595,
        "no_speech_prob": 0.015424060635268688,
        "seek": 550948,
        "start": 5518.48,
        "temperature": 0,
        "text": " kind of simplify by not worrying about validation data.",
        "tokens": [
          50814,
          733,
          295,
          20460,
          538,
          406,
          18788,
          466,
          24071,
          1412,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18132848006028396,
        "compression_ratio": 1.7777777777777777,
        "end": 5526.48,
        "id": 1596,
        "no_speech_prob": 0.015424060635268688,
        "seek": 550948,
        "start": 5521.48,
        "temperature": 0,
        "text": " And I am just going to use training data and testing data.",
        "tokens": [
          50964,
          400,
          286,
          669,
          445,
          516,
          281,
          764,
          3097,
          1412,
          293,
          4997,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18132848006028396,
        "compression_ratio": 1.7777777777777777,
        "end": 5531.48,
        "id": 1597,
        "no_speech_prob": 0.015424060635268688,
        "seek": 550948,
        "start": 5526.48,
        "temperature": 0,
        "text": " And the idea here is that what I want to do is train the model with my training data.",
        "tokens": [
          51214,
          400,
          264,
          1558,
          510,
          307,
          300,
          437,
          286,
          528,
          281,
          360,
          307,
          3847,
          264,
          2316,
          365,
          452,
          3097,
          1412,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18132848006028396,
        "compression_ratio": 1.7777777777777777,
        "end": 5536.48,
        "id": 1598,
        "no_speech_prob": 0.015424060635268688,
        "seek": 550948,
        "start": 5531.48,
        "temperature": 0,
        "text": " But then I want to feed it the testing data and see if the labels that it returns,",
        "tokens": [
          51464,
          583,
          550,
          286,
          528,
          281,
          3154,
          309,
          264,
          4997,
          1412,
          293,
          536,
          498,
          264,
          16949,
          300,
          309,
          11247,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.19310861475327434,
        "compression_ratio": 1.7137546468401488,
        "end": 5540.48,
        "id": 1599,
        "no_speech_prob": 0.007232544478029013,
        "seek": 553648,
        "start": 5536.48,
        "temperature": 0,
        "text": " oh, it thinks this color is bluish, is that actually what it is labeled with?",
        "tokens": [
          50364,
          1954,
          11,
          309,
          7309,
          341,
          2017,
          307,
          888,
          33786,
          11,
          307,
          300,
          767,
          437,
          309,
          307,
          21335,
          365,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.19310861475327434,
        "compression_ratio": 1.7137546468401488,
        "end": 5543.48,
        "id": 1600,
        "no_speech_prob": 0.007232544478029013,
        "seek": 553648,
        "start": 5540.48,
        "temperature": 0,
        "text": " And I'll get some type of accuracy score from that.",
        "tokens": [
          50564,
          400,
          286,
          603,
          483,
          512,
          2010,
          295,
          14170,
          6175,
          490,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19310861475327434,
        "compression_ratio": 1.7137546468401488,
        "end": 5549.48,
        "id": 1601,
        "no_speech_prob": 0.007232544478029013,
        "seek": 553648,
        "start": 5543.48,
        "temperature": 0,
        "text": " And I'll know more about, I don't want to test it with stuff that I've trained it with,",
        "tokens": [
          50714,
          400,
          286,
          603,
          458,
          544,
          466,
          11,
          286,
          500,
          380,
          528,
          281,
          1500,
          309,
          365,
          1507,
          300,
          286,
          600,
          8895,
          309,
          365,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.19310861475327434,
        "compression_ratio": 1.7137546468401488,
        "end": 5552.48,
        "id": 1602,
        "no_speech_prob": 0.007232544478029013,
        "seek": 553648,
        "start": 5549.48,
        "temperature": 0,
        "text": " because of course it's going to ultimately get that right.",
        "tokens": [
          51014,
          570,
          295,
          1164,
          309,
          311,
          516,
          281,
          6284,
          483,
          300,
          558,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19310861475327434,
        "compression_ratio": 1.7137546468401488,
        "end": 5558.48,
        "id": 1603,
        "no_speech_prob": 0.007232544478029013,
        "seek": 553648,
        "start": 5552.48,
        "temperature": 0,
        "text": " Machine learning models are very good at returning the result that you tell them about.",
        "tokens": [
          51164,
          22155,
          2539,
          5245,
          366,
          588,
          665,
          412,
          12678,
          264,
          1874,
          300,
          291,
          980,
          552,
          466,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19310861475327434,
        "compression_ratio": 1.7137546468401488,
        "end": 5563.48,
        "id": 1604,
        "no_speech_prob": 0.007232544478029013,
        "seek": 553648,
        "start": 5558.48,
        "temperature": 0,
        "text": " And we need to see, does it also return the result of new data that it hasn't been trained with?",
        "tokens": [
          51464,
          400,
          321,
          643,
          281,
          536,
          11,
          775,
          309,
          611,
          2736,
          264,
          1874,
          295,
          777,
          1412,
          300,
          309,
          6132,
          380,
          668,
          8895,
          365,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5567.48,
        "id": 1605,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5563.48,
        "temperature": 0,
        "text": " If it works really well with the training data, but not with the testing data,",
        "tokens": [
          50364,
          759,
          309,
          1985,
          534,
          731,
          365,
          264,
          3097,
          1412,
          11,
          457,
          406,
          365,
          264,
          4997,
          1412,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5570.48,
        "id": 1606,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5567.48,
        "temperature": 0,
        "text": " this can be known as overfitting.",
        "tokens": [
          50564,
          341,
          393,
          312,
          2570,
          382,
          670,
          69,
          2414,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5573.48,
        "id": 1607,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5570.48,
        "temperature": 0,
        "text": " Meaning the model is just incredibly good.",
        "tokens": [
          50714,
          19948,
          264,
          2316,
          307,
          445,
          6252,
          665,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5576.48,
        "id": 1608,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5573.48,
        "temperature": 0,
        "text": " It's so exact that it doesn't really know what to do,",
        "tokens": [
          50864,
          467,
          311,
          370,
          1900,
          300,
          309,
          1177,
          380,
          534,
          458,
          437,
          281,
          360,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5579.48,
        "id": 1609,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5576.48,
        "temperature": 0,
        "text": " except for the exact data that it was trained with.",
        "tokens": [
          51014,
          3993,
          337,
          264,
          1900,
          1412,
          300,
          309,
          390,
          8895,
          365,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5581.48,
        "id": 1610,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5579.48,
        "temperature": 0,
        "text": " So this is what we want to watch out for.",
        "tokens": [
          51164,
          407,
          341,
          307,
          437,
          321,
          528,
          281,
          1159,
          484,
          337,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5586.48,
        "id": 1611,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5581.48,
        "temperature": 0,
        "text": " And a kind of convention, let's say I have 5,000 data points.",
        "tokens": [
          51264,
          400,
          257,
          733,
          295,
          10286,
          11,
          718,
          311,
          584,
          286,
          362,
          1025,
          11,
          1360,
          1412,
          2793,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16763200431034483,
        "compression_ratio": 1.6385542168674698,
        "end": 5589.48,
        "id": 1612,
        "no_speech_prob": 0.07585383206605911,
        "seek": 556348,
        "start": 5586.48,
        "temperature": 0,
        "text": " A convention might be to use 80% of those.",
        "tokens": [
          51514,
          316,
          10286,
          1062,
          312,
          281,
          764,
          4688,
          4,
          295,
          729,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22456325954861112,
        "compression_ratio": 1.4802259887005649,
        "end": 5593.48,
        "id": 1613,
        "no_speech_prob": 0.035676561295986176,
        "seek": 558948,
        "start": 5589.48,
        "temperature": 0,
        "text": " So 10% is 500, so like 4,000.",
        "tokens": [
          50364,
          407,
          1266,
          4,
          307,
          5923,
          11,
          370,
          411,
          1017,
          11,
          1360,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22456325954861112,
        "compression_ratio": 1.4802259887005649,
        "end": 5598.48,
        "id": 1614,
        "no_speech_prob": 0.035676561295986176,
        "seek": 558948,
        "start": 5593.48,
        "temperature": 0,
        "text": " 4,000 is 80% of 5,000 I think.",
        "tokens": [
          50564,
          1017,
          11,
          1360,
          307,
          4688,
          4,
          295,
          1025,
          11,
          1360,
          286,
          519,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22456325954861112,
        "compression_ratio": 1.4802259887005649,
        "end": 5607.48,
        "id": 1615,
        "no_speech_prob": 0.035676561295986176,
        "seek": 558948,
        "start": 5598.48,
        "temperature": 0,
        "text": " As my training data, and then save 1,000, or 20%, 1 5th as my testing data.",
        "tokens": [
          50814,
          1018,
          452,
          3097,
          1412,
          11,
          293,
          550,
          3155,
          502,
          11,
          1360,
          11,
          420,
          945,
          8923,
          502,
          1025,
          392,
          382,
          452,
          4997,
          1412,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22456325954861112,
        "compression_ratio": 1.4802259887005649,
        "end": 5611.48,
        "id": 1616,
        "no_speech_prob": 0.035676561295986176,
        "seek": 558948,
        "start": 5607.48,
        "temperature": 0,
        "text": " Alright, so I need to at least at the beginning right now,",
        "tokens": [
          51264,
          2798,
          11,
          370,
          286,
          643,
          281,
          412,
          1935,
          412,
          264,
          2863,
          558,
          586,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.22456325954861112,
        "compression_ratio": 1.4802259887005649,
        "end": 5615.48,
        "id": 1617,
        "no_speech_prob": 0.035676561295986176,
        "seek": 558948,
        "start": 5611.48,
        "temperature": 0,
        "text": " divide it, and I might just sort of pick randomly to divide it up.",
        "tokens": [
          51464,
          9845,
          309,
          11,
          293,
          286,
          1062,
          445,
          1333,
          295,
          1888,
          16979,
          281,
          9845,
          309,
          493,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5618.48,
        "id": 1618,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5616.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5623.48,
        "id": 1619,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5618.48,
        "temperature": 0,
        "text": " What I like is that when I switch cameras,",
        "tokens": [
          50514,
          708,
          286,
          411,
          307,
          300,
          562,
          286,
          3679,
          8622,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5628.48,
        "id": 1620,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5623.48,
        "temperature": 0,
        "text": " I can easily have like a little break for a second.",
        "tokens": [
          50764,
          286,
          393,
          3612,
          362,
          411,
          257,
          707,
          1821,
          337,
          257,
          1150,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5630.48,
        "id": 1621,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5628.48,
        "temperature": 0,
        "text": " Not easily, but I'm going to cycle these,",
        "tokens": [
          51014,
          1726,
          3612,
          11,
          457,
          286,
          478,
          516,
          281,
          6586,
          613,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5635.48,
        "id": 1622,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5630.48,
        "temperature": 0,
        "text": " because I don't know when I last cycled them.",
        "tokens": [
          51114,
          570,
          286,
          500,
          380,
          458,
          562,
          286,
          1036,
          3185,
          24804,
          552,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5638.48,
        "id": 1623,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5637.48,
        "temperature": 0,
        "text": " What time is it?",
        "tokens": [
          51464,
          708,
          565,
          307,
          309,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5639.48,
        "id": 1624,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5638.48,
        "temperature": 0,
        "text": " Oh, 1 20.",
        "tokens": [
          51514,
          876,
          11,
          502,
          945,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5641.48,
        "id": 1625,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5639.48,
        "temperature": 0,
        "text": " Okay, I'm going to be here another half an hour,",
        "tokens": [
          51564,
          1033,
          11,
          286,
          478,
          516,
          281,
          312,
          510,
          1071,
          1922,
          364,
          1773,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.23756000518798828,
        "compression_ratio": 1.5076142131979695,
        "end": 5643.48,
        "id": 1626,
        "no_speech_prob": 0.008576679974794388,
        "seek": 561548,
        "start": 5641.48,
        "temperature": 0,
        "text": " and then I've got to go I think.",
        "tokens": [
          51664,
          293,
          550,
          286,
          600,
          658,
          281,
          352,
          286,
          519,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21869865021148285,
        "compression_ratio": 1.5771428571428572,
        "end": 5649.48,
        "id": 1627,
        "no_speech_prob": 0.0006461954326368868,
        "seek": 564348,
        "start": 5644.48,
        "temperature": 0,
        "text": " So the question though is, the thing that I need to figure out is,",
        "tokens": [
          50414,
          407,
          264,
          1168,
          1673,
          307,
          11,
          264,
          551,
          300,
          286,
          643,
          281,
          2573,
          484,
          307,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.21869865021148285,
        "compression_ratio": 1.5771428571428572,
        "end": 5654.48,
        "id": 1628,
        "no_speech_prob": 0.0006461954326368868,
        "seek": 564348,
        "start": 5649.48,
        "temperature": 0,
        "text": " should I split up the data before I convert it to tensors,",
        "tokens": [
          50664,
          820,
          286,
          7472,
          493,
          264,
          1412,
          949,
          286,
          7620,
          309,
          281,
          10688,
          830,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.21869865021148285,
        "compression_ratio": 1.5771428571428572,
        "end": 5657.48,
        "id": 1629,
        "no_speech_prob": 0.0006461954326368868,
        "seek": 564348,
        "start": 5654.48,
        "temperature": 0,
        "text": " or should I convert it to tensors and then split it up?",
        "tokens": [
          50914,
          420,
          820,
          286,
          7620,
          309,
          281,
          10688,
          830,
          293,
          550,
          7472,
          309,
          493,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.21869865021148285,
        "compression_ratio": 1.5771428571428572,
        "end": 5661.48,
        "id": 1630,
        "no_speech_prob": 0.0006461954326368868,
        "seek": 564348,
        "start": 5657.48,
        "temperature": 0,
        "text": " Anybody have an opinion of what's going to make the most sense?",
        "tokens": [
          51064,
          19082,
          362,
          364,
          4800,
          295,
          437,
          311,
          516,
          281,
          652,
          264,
          881,
          2020,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.21869865021148285,
        "compression_ratio": 1.5771428571428572,
        "end": 5663.48,
        "id": 1631,
        "no_speech_prob": 0.0006461954326368868,
        "seek": 564348,
        "start": 5661.48,
        "temperature": 0,
        "text": " I really could use some water.",
        "tokens": [
          51264,
          286,
          534,
          727,
          764,
          512,
          1281,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5665.48,
        "id": 1632,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5663.48,
        "temperature": 1,
        "text": " Maybe I'll just split it up.",
        "tokens": [
          50364,
          2704,
          286,
          603,
          445,
          637,
          23062,
          309,
          493,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5667.48,
        "id": 1633,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5665.48,
        "temperature": 1,
        "text": " I'm going to split it up.",
        "tokens": [
          50464,
          286,
          478,
          220,
          8102,
          281,
          7472,
          741,
          83,
          493,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5670.48,
        "id": 1634,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5667.48,
        "temperature": 1,
        "text": " Let's see.",
        "tokens": [
          50564,
          961,
          311,
          536,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5675.48,
        "id": 1635,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5670.48,
        "temperature": 1,
        "text": " $5,000, we're almost there.",
        "tokens": [
          50714,
          1848,
          20,
          11,
          1360,
          11,
          321,
          434,
          1920,
          456,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5680.48,
        "id": 1636,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5678.48,
        "temperature": 1,
        "text": " $100,000.",
        "tokens": [
          51114,
          1848,
          6879,
          11,
          1360,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5683.48,
        "id": 1637,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5680.48,
        "temperature": 1,
        "text": " $850,000.",
        "tokens": [
          51214,
          1848,
          23,
          2803,
          11,
          1360,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5685.48,
        "id": 1638,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5683.48,
        "temperature": 1,
        "text": " So we've got a lot of data here.",
        "tokens": [
          51364,
          220,
          6455,
          321,
          600,
          658,
          257,
          688,
          295,
          1412,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5686.48,
        "id": 1639,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5685.48,
        "temperature": 1,
        "text": " Alright.",
        "tokens": [
          51464,
          967,
          7065,
          357,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5688.48,
        "id": 1640,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5686.48,
        "temperature": 1,
        "text": " First question I've sort of sorted it out.",
        "tokens": [
          51514,
          28164,
          372,
          1168,
          286,
          600,
          1333,
          295,
          25462,
          741,
          83,
          484,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -1.6925888061523438,
        "compression_ratio": 1.4024390243902438,
        "end": 5690.48,
        "id": 1641,
        "no_speech_prob": 0.011867226101458073,
        "seek": 566348,
        "start": 5688.48,
        "temperature": 1,
        "text": " I would say the number of data,",
        "tokens": [
          51614,
          286,
          576,
          584,
          256,
          675,
          1230,
          295,
          1412,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5692.48,
        "id": 1642,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5690.48,
        "temperature": 0,
        "text": " I'll just split it up.",
        "tokens": [
          50364,
          286,
          603,
          445,
          7472,
          309,
          493,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5694.48,
        "id": 1643,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5692.48,
        "temperature": 0,
        "text": " I'm going to split it up.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          7472,
          309,
          493,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5697.48,
        "id": 1644,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5694.48,
        "temperature": 0,
        "text": " Because it's going to be so easy to do.",
        "tokens": [
          50564,
          1436,
          309,
          311,
          516,
          281,
          312,
          370,
          1858,
          281,
          360,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5700.48,
        "id": 1645,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5697.48,
        "temperature": 0,
        "text": " And that's what I was just talking about.",
        "tokens": [
          50714,
          400,
          300,
          311,
          437,
          286,
          390,
          445,
          1417,
          466,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5703.48,
        "id": 1646,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5700.48,
        "temperature": 0,
        "text": " The chat is so far behind,",
        "tokens": [
          50864,
          440,
          5081,
          307,
          370,
          1400,
          2261,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5705.48,
        "id": 1647,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5703.48,
        "temperature": 0,
        "text": " like 30 seconds behind real time.",
        "tokens": [
          51014,
          411,
          2217,
          3949,
          2261,
          957,
          565,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5707.48,
        "id": 1648,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5705.48,
        "temperature": 0,
        "text": " Convert then split.",
        "tokens": [
          51114,
          2656,
          3281,
          550,
          7472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5709.48,
        "id": 1649,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5707.48,
        "temperature": 0,
        "text": " That was the first comment that came.",
        "tokens": [
          51214,
          663,
          390,
          264,
          700,
          2871,
          300,
          1361,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5712.48,
        "id": 1650,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5709.48,
        "temperature": 0,
        "text": " Convert then split.",
        "tokens": [
          51314,
          2656,
          3281,
          550,
          7472,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5715.48,
        "id": 1651,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5712.48,
        "temperature": 0,
        "text": " Which was different than where I arrived to in my head.",
        "tokens": [
          51464,
          3013,
          390,
          819,
          813,
          689,
          286,
          6678,
          281,
          294,
          452,
          1378,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21292734146118164,
        "compression_ratio": 1.6712962962962963,
        "end": 5717.48,
        "id": 1652,
        "no_speech_prob": 0.22267252206802368,
        "seek": 569048,
        "start": 5715.48,
        "temperature": 0,
        "text": " Clean the data first then split it.",
        "tokens": [
          51614,
          18463,
          264,
          1412,
          700,
          550,
          7472,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5719.48,
        "id": 1653,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5717.48,
        "temperature": 0,
        "text": " First make the sense.",
        "tokens": [
          50364,
          2386,
          652,
          264,
          2020,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5721.48,
        "id": 1654,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5719.48,
        "temperature": 0,
        "text": " Tensor then split.",
        "tokens": [
          50464,
          34306,
          550,
          7472,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5723.48,
        "id": 1655,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5721.48,
        "temperature": 0,
        "text": " Alexa, flip a coin.",
        "tokens": [
          50564,
          22595,
          11,
          7929,
          257,
          11464,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5728.48,
        "id": 1656,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5726.48,
        "temperature": 0,
        "text": " Is there a convention?",
        "tokens": [
          50814,
          1119,
          456,
          257,
          10286,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5730.48,
        "id": 1657,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5728.48,
        "temperature": 0,
        "text": " What would be the convention?",
        "tokens": [
          50914,
          708,
          576,
          312,
          264,
          10286,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5732.48,
        "id": 1658,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5730.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5738.48,
        "id": 1659,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5734.48,
        "temperature": 0,
        "text": " Convert first so you can use the GPU optimally.",
        "tokens": [
          51214,
          2656,
          3281,
          700,
          370,
          291,
          393,
          764,
          264,
          18407,
          5028,
          379,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5742.48,
        "id": 1660,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5738.48,
        "temperature": 0,
        "text": " Yeah, because the tensors have functionality probably to split.",
        "tokens": [
          51414,
          865,
          11,
          570,
          264,
          10688,
          830,
          362,
          14980,
          1391,
          281,
          7472,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24595939949767232,
        "compression_ratio": 1.4166666666666667,
        "end": 5744.48,
        "id": 1661,
        "no_speech_prob": 0.0005357663612812757,
        "seek": 571748,
        "start": 5742.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51614,
          1779,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5750.48,
        "id": 1662,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5747.48,
        "temperature": 0,
        "text": " I assume that...",
        "tokens": [
          50364,
          286,
          6552,
          300,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5756.48,
        "id": 1663,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5754.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50714,
          1779,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5758.48,
        "id": 1664,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5756.48,
        "temperature": 0,
        "text": " Like scalar...",
        "tokens": [
          50814,
          1743,
          39684,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5763.48,
        "id": 1665,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5761.48,
        "temperature": 0,
        "text": " Buffer...",
        "tokens": [
          51064,
          20254,
          260,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5765.48,
        "id": 1666,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5763.48,
        "temperature": 0,
        "text": " Clone.",
        "tokens": [
          51164,
          45536,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5767.48,
        "id": 1667,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5765.48,
        "temperature": 0,
        "text": " Same values.",
        "tokens": [
          51264,
          10635,
          4190,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5769.48,
        "id": 1668,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5767.48,
        "temperature": 0,
        "text": " Fill.",
        "tokens": [
          51364,
          25315,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.36536468159068713,
        "compression_ratio": 1.0594059405940595,
        "end": 5773.48,
        "id": 1669,
        "no_speech_prob": 0.009855474345386028,
        "seek": 574748,
        "start": 5769.48,
        "temperature": 0,
        "text": " One hot I definitely need to do.",
        "tokens": [
          51464,
          1485,
          2368,
          286,
          2138,
          643,
          281,
          360,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5780.48,
        "id": 1670,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5778.48,
        "temperature": 0,
        "text": " Truncated.",
        "tokens": [
          50414,
          1765,
          409,
          66,
          770,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5782.48,
        "id": 1671,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5780.48,
        "temperature": 0,
        "text": " Variable.",
        "tokens": [
          50514,
          32511,
          712,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5784.48,
        "id": 1672,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5782.48,
        "temperature": 0,
        "text": " Zeroes.",
        "tokens": [
          50614,
          17182,
          279,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5790.48,
        "id": 1673,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5788.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          50914,
          5015,
          42406,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5792.48,
        "id": 1674,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5790.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51014,
          5015,
          42406,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5794.48,
        "id": 1675,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5792.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51114,
          5015,
          42406,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5796.48,
        "id": 1676,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5794.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51214,
          5015,
          42406,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5798.48,
        "id": 1677,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5796.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51314,
          5015,
          42406,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5800.48,
        "id": 1678,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5798.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51414,
          5015,
          42406,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5802.48,
        "id": 1679,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5800.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51514,
          5015,
          42406,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5804.48,
        "id": 1680,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5802.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51614,
          5015,
          42406,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3336123824119568,
        "compression_ratio": 2.369565217391304,
        "end": 5806.48,
        "id": 1681,
        "no_speech_prob": 0.010311102494597435,
        "seek": 577748,
        "start": 5804.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          51714,
          5015,
          42406,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5808.48,
        "id": 1682,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5806.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          50364,
          5015,
          42406,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5810.48,
        "id": 1683,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5808.48,
        "temperature": 0,
        "text": " Reshape.",
        "tokens": [
          50464,
          5015,
          42406,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5812.48,
        "id": 1684,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5810.48,
        "temperature": 0,
        "text": " Squeeze.",
        "tokens": [
          50564,
          47603,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5814.48,
        "id": 1685,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5812.48,
        "temperature": 0,
        "text": " Clone.",
        "tokens": [
          50664,
          45536,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5816.48,
        "id": 1686,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5814.48,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          50764,
          8063,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5822.48,
        "id": 1687,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5820.48,
        "temperature": 0,
        "text": " Don't normalize the data altogether.",
        "tokens": [
          51064,
          1468,
          380,
          2710,
          1125,
          264,
          1412,
          19051,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5824.48,
        "id": 1688,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5822.48,
        "temperature": 0,
        "text": " Separate training and testing first.",
        "tokens": [
          51164,
          43480,
          473,
          3097,
          293,
          4997,
          700,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.32803550421022903,
        "compression_ratio": 1.208695652173913,
        "end": 5828.48,
        "id": 1689,
        "no_speech_prob": 0.005639599170535803,
        "seek": 580648,
        "start": 5824.48,
        "temperature": 0,
        "text": " That sounds like a very...",
        "tokens": [
          51264,
          663,
          3263,
          411,
          257,
          588,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5831.48,
        "id": 1690,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5829.48,
        "temperature": 0,
        "text": " Very...",
        "tokens": [
          50414,
          4372,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5834.48,
        "id": 1691,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5831.48,
        "temperature": 0,
        "text": " That sounds like that was written with conviction.",
        "tokens": [
          50514,
          663,
          3263,
          411,
          300,
          390,
          3720,
          365,
          24837,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5837.48,
        "id": 1692,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5834.48,
        "temperature": 0,
        "text": " It made an impact on me.",
        "tokens": [
          50664,
          467,
          1027,
          364,
          2712,
          322,
          385,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5842.48,
        "id": 1693,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5837.48,
        "temperature": 0,
        "text": " I feel like just narrative wise with the flow that I'm doing, I'm actually going to split it.",
        "tokens": [
          50814,
          286,
          841,
          411,
          445,
          9977,
          10829,
          365,
          264,
          3095,
          300,
          286,
          478,
          884,
          11,
          286,
          478,
          767,
          516,
          281,
          7472,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5846.48,
        "id": 1694,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5842.48,
        "temperature": 0,
        "text": " And then I'll write a function that makes a tensor from...",
        "tokens": [
          51064,
          400,
          550,
          286,
          603,
          2464,
          257,
          2445,
          300,
          1669,
          257,
          40863,
          490,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5851.48,
        "id": 1695,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5849.48,
        "temperature": 0,
        "text": " Yeah, I don't know.",
        "tokens": [
          51414,
          865,
          11,
          286,
          500,
          380,
          458,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5854.48,
        "id": 1696,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5851.48,
        "temperature": 0,
        "text": " I never know what to do here.",
        "tokens": [
          51514,
          286,
          1128,
          458,
          437,
          281,
          360,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23979898678359166,
        "compression_ratio": 1.5339805825242718,
        "end": 5857.48,
        "id": 1697,
        "no_speech_prob": 0.015183201059699059,
        "seek": 582848,
        "start": 5854.48,
        "temperature": 0,
        "text": " There is a TF split function.",
        "tokens": [
          51664,
          821,
          307,
          257,
          40964,
          7472,
          2445,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22600369226364864,
        "compression_ratio": 1.1473684210526316,
        "end": 5859.48,
        "id": 1698,
        "no_speech_prob": 0.004467153921723366,
        "seek": 585748,
        "start": 5857.48,
        "temperature": 0,
        "text": " How come I don't...",
        "tokens": [
          50364,
          1012,
          808,
          286,
          500,
          380,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.22600369226364864,
        "compression_ratio": 1.1473684210526316,
        "end": 5861.48,
        "id": 1699,
        "no_speech_prob": 0.004467153921723366,
        "seek": 585748,
        "start": 5859.48,
        "temperature": 0,
        "text": " How come I didn't see that?",
        "tokens": [
          50464,
          1012,
          808,
          286,
          994,
          380,
          536,
          300,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.22600369226364864,
        "compression_ratio": 1.1473684210526316,
        "end": 5873.48,
        "id": 1700,
        "no_speech_prob": 0.004467153921723366,
        "seek": 585748,
        "start": 5871.48,
        "temperature": 0,
        "text": " Alright, let me look at this.",
        "tokens": [
          51064,
          2798,
          11,
          718,
          385,
          574,
          412,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22600369226364864,
        "compression_ratio": 1.1473684210526316,
        "end": 5878.48,
        "id": 1701,
        "no_speech_prob": 0.004467153921723366,
        "seek": 585748,
        "start": 5876.48,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          51314,
          7521,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22600369226364864,
        "compression_ratio": 1.1473684210526316,
        "end": 5882.48,
        "id": 1702,
        "no_speech_prob": 0.004467153921723366,
        "seek": 585748,
        "start": 5879.48,
        "temperature": 0,
        "text": " Number or size of splits.",
        "tokens": [
          51464,
          5118,
          420,
          2744,
          295,
          37741,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.27960057576497394,
        "compression_ratio": 1.5583756345177664,
        "end": 5887.48,
        "id": 1703,
        "no_speech_prob": 0.005217617377638817,
        "seek": 588248,
        "start": 5883.48,
        "temperature": 0,
        "text": " The dimension along which to split.",
        "tokens": [
          50414,
          440,
          10139,
          2051,
          597,
          281,
          7472,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27960057576497394,
        "compression_ratio": 1.5583756345177664,
        "end": 5889.48,
        "id": 1704,
        "no_speech_prob": 0.005217617377638817,
        "seek": 588248,
        "start": 5887.48,
        "temperature": 0,
        "text": " Well, this seems confusing to me.",
        "tokens": [
          50614,
          1042,
          11,
          341,
          2544,
          13181,
          281,
          385,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.27960057576497394,
        "compression_ratio": 1.5583756345177664,
        "end": 5899.48,
        "id": 1705,
        "no_speech_prob": 0.005217617377638817,
        "seek": 588248,
        "start": 5889.48,
        "temperature": 0,
        "text": " Either an integer indicating the number of splits along the axis or an array of integers containing the sizes of each output tensor along the axis.",
        "tokens": [
          50714,
          13746,
          364,
          24922,
          25604,
          264,
          1230,
          295,
          37741,
          2051,
          264,
          10298,
          420,
          364,
          10225,
          295,
          41674,
          19273,
          264,
          11602,
          295,
          1184,
          5598,
          40863,
          2051,
          264,
          10298,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.27960057576497394,
        "compression_ratio": 1.5583756345177664,
        "end": 5903.48,
        "id": 1706,
        "no_speech_prob": 0.005217617377638817,
        "seek": 588248,
        "start": 5901.48,
        "temperature": 0,
        "text": " So I definitely can use that.",
        "tokens": [
          51314,
          407,
          286,
          2138,
          393,
          764,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.27960057576497394,
        "compression_ratio": 1.5583756345177664,
        "end": 5907.48,
        "id": 1707,
        "no_speech_prob": 0.005217617377638817,
        "seek": 588248,
        "start": 5903.48,
        "temperature": 0,
        "text": " It just hurts my brain to think about how to do it exactly.",
        "tokens": [
          51414,
          467,
          445,
          11051,
          452,
          3567,
          281,
          519,
          466,
          577,
          281,
          360,
          309,
          2293,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.36543857134305513,
        "compression_ratio": 1.3652173913043477,
        "end": 5913.48,
        "id": 1708,
        "no_speech_prob": 0.007694664411246777,
        "seek": 590748,
        "start": 5907.48,
        "temperature": 0,
        "text": " Like if this is a 2D tensor and then it splits...",
        "tokens": [
          50364,
          1743,
          498,
          341,
          307,
          257,
          568,
          35,
          40863,
          293,
          550,
          309,
          37741,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.36543857134305513,
        "compression_ratio": 1.3652173913043477,
        "end": 5916.48,
        "id": 1709,
        "no_speech_prob": 0.007694664411246777,
        "seek": 590748,
        "start": 5913.48,
        "temperature": 0,
        "text": " I want to see what this does.",
        "tokens": [
          50664,
          286,
          528,
          281,
          536,
          437,
          341,
          775,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.36543857134305513,
        "compression_ratio": 1.3652173913043477,
        "end": 5923.48,
        "id": 1710,
        "no_speech_prob": 0.007694664411246777,
        "seek": 590748,
        "start": 5921.48,
        "temperature": 0,
        "text": " Let's...",
        "tokens": [
          51064,
          961,
          311,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.36543857134305513,
        "compression_ratio": 1.3652173913043477,
        "end": 5927.48,
        "id": 1711,
        "no_speech_prob": 0.007694664411246777,
        "seek": 590748,
        "start": 5925.48,
        "temperature": 0,
        "text": " Let me try to understand what this does.",
        "tokens": [
          51264,
          961,
          385,
          853,
          281,
          1223,
          437,
          341,
          775,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.36543857134305513,
        "compression_ratio": 1.3652173913043477,
        "end": 5934.48,
        "id": 1712,
        "no_speech_prob": 0.007694664411246777,
        "seek": 590748,
        "start": 5932.48,
        "temperature": 0,
        "text": " So let me think about this.",
        "tokens": [
          51614,
          407,
          718,
          385,
          519,
          466,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5938.48,
        "id": 1713,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5935.48,
        "temperature": 0,
        "text": " So let me think about what I'm going to have.",
        "tokens": [
          50414,
          407,
          718,
          385,
          519,
          466,
          437,
          286,
          478,
          516,
          281,
          362,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5943.48,
        "id": 1714,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5938.48,
        "temperature": 0,
        "text": " I'm going to have a tensor for the RGB values...",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          362,
          257,
          40863,
          337,
          264,
          31231,
          4190,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5947.48,
        "id": 1715,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5945.48,
        "temperature": 0,
        "text": " That looks like this.",
        "tokens": [
          50914,
          663,
          1542,
          411,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5949.48,
        "id": 1716,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5947.48,
        "temperature": 0,
        "text": " Like...",
        "tokens": [
          51014,
          1743,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5951.48,
        "id": 1717,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5949.48,
        "temperature": 0,
        "text": " 1, 1...",
        "tokens": [
          51114,
          502,
          11,
          502,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5953.48,
        "id": 1718,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5951.48,
        "temperature": 0,
        "text": " Let's see, 1, 2, 3...",
        "tokens": [
          51214,
          961,
          311,
          536,
          11,
          502,
          11,
          568,
          11,
          805,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5956.48,
        "id": 1719,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5954.48,
        "temperature": 0,
        "text": " 4, 5...",
        "tokens": [
          51364,
          1017,
          11,
          1025,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5958.48,
        "id": 1720,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5956.48,
        "temperature": 0,
        "text": " 6...",
        "tokens": [
          51464,
          1386,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.1975556747822822,
        "compression_ratio": 1.326086956521739,
        "end": 5962.48,
        "id": 1721,
        "no_speech_prob": 0.000027969168513664044,
        "seek": 593448,
        "start": 5958.48,
        "temperature": 0,
        "text": " 7, 8, 9, right?",
        "tokens": [
          51564,
          1614,
          11,
          1649,
          11,
          1722,
          11,
          558,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.1919395204574343,
        "compression_ratio": 1.515625,
        "end": 5964.48,
        "id": 1722,
        "no_speech_prob": 0.0003625835233833641,
        "seek": 596248,
        "start": 5962.48,
        "temperature": 0,
        "text": " This is what I'm going to have.",
        "tokens": [
          50364,
          639,
          307,
          437,
          286,
          478,
          516,
          281,
          362,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1919395204574343,
        "compression_ratio": 1.515625,
        "end": 5974.48,
        "id": 1723,
        "no_speech_prob": 0.0003625835233833641,
        "seek": 596248,
        "start": 5972.48,
        "temperature": 0,
        "text": " Let me just work this out right now.",
        "tokens": [
          50864,
          961,
          385,
          445,
          589,
          341,
          484,
          558,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1919395204574343,
        "compression_ratio": 1.515625,
        "end": 5980.48,
        "id": 1724,
        "no_speech_prob": 0.0003625835233833641,
        "seek": 596248,
        "start": 5976.48,
        "temperature": 0,
        "text": " So that's what I'm going to have. I'm going to have multiple RGB values.",
        "tokens": [
          51064,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          362,
          13,
          286,
          478,
          516,
          281,
          362,
          3866,
          31231,
          4190,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1919395204574343,
        "compression_ratio": 1.515625,
        "end": 5983.48,
        "id": 1725,
        "no_speech_prob": 0.0003625835233833641,
        "seek": 596248,
        "start": 5980.48,
        "temperature": 0,
        "text": " So if I want to say...",
        "tokens": [
          51264,
          407,
          498,
          286,
          528,
          281,
          584,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.1919395204574343,
        "compression_ratio": 1.515625,
        "end": 5988.48,
        "id": 1726,
        "no_speech_prob": 0.0003625835233833641,
        "seek": 596248,
        "start": 5985.48,
        "temperature": 0,
        "text": " Split it into train and test.",
        "tokens": [
          51514,
          45111,
          309,
          666,
          3847,
          293,
          1500,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.26291681017194474,
        "compression_ratio": 1.4066666666666667,
        "end": 5992.48,
        "id": 1727,
        "no_speech_prob": 0.0002913656353484839,
        "seek": 598848,
        "start": 5989.48,
        "temperature": 0,
        "text": " I would say tf.split x...",
        "tokens": [
          50414,
          286,
          576,
          584,
          256,
          69,
          13,
          46535,
          270,
          2031,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.26291681017194474,
        "compression_ratio": 1.4066666666666667,
        "end": 5999.48,
        "id": 1728,
        "no_speech_prob": 0.0002913656353484839,
        "seek": 598848,
        "start": 5997.48,
        "temperature": 0,
        "text": " I've lost here.",
        "tokens": [
          50814,
          286,
          600,
          2731,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.26291681017194474,
        "compression_ratio": 1.4066666666666667,
        "end": 6001.48,
        "id": 1729,
        "no_speech_prob": 0.0002913656353484839,
        "seek": 598848,
        "start": 5999.48,
        "temperature": 0,
        "text": " Let me read that documentation again.",
        "tokens": [
          50914,
          961,
          385,
          1401,
          300,
          14333,
          797,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.26291681017194474,
        "compression_ratio": 1.4066666666666667,
        "end": 6005.48,
        "id": 1730,
        "no_speech_prob": 0.0002913656353484839,
        "seek": 598848,
        "start": 6003.48,
        "temperature": 0,
        "text": " Number or size of splits.",
        "tokens": [
          51114,
          5118,
          420,
          2744,
          295,
          37741,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26291681017194474,
        "compression_ratio": 1.4066666666666667,
        "end": 6008.48,
        "id": 1731,
        "no_speech_prob": 0.0002913656353484839,
        "seek": 598848,
        "start": 6006.48,
        "temperature": 0,
        "text": " Number of splits along the axis.",
        "tokens": [
          51264,
          5118,
          295,
          37741,
          2051,
          264,
          10298,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26291681017194474,
        "compression_ratio": 1.4066666666666667,
        "end": 6010.48,
        "id": 1732,
        "no_speech_prob": 0.0002913656353484839,
        "seek": 598848,
        "start": 6008.48,
        "temperature": 0,
        "text": " I just want to split once.",
        "tokens": [
          51364,
          286,
          445,
          528,
          281,
          7472,
          1564,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26291681017194474,
        "compression_ratio": 1.4066666666666667,
        "end": 6014.48,
        "id": 1733,
        "no_speech_prob": 0.0002913656353484839,
        "seek": 598848,
        "start": 6010.48,
        "temperature": 0,
        "text": " And then I guess I'm going to give it like...",
        "tokens": [
          51464,
          400,
          550,
          286,
          2041,
          286,
          478,
          516,
          281,
          976,
          309,
          411,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.2786884307861328,
        "compression_ratio": 1.4,
        "end": 6018.48,
        "id": 1734,
        "no_speech_prob": 0.0032223921734839678,
        "seek": 601448,
        "start": 6015.48,
        "temperature": 0,
        "text": " Let's say if I give it 1, 2, shouldn't I get...",
        "tokens": [
          50414,
          961,
          311,
          584,
          498,
          286,
          976,
          309,
          502,
          11,
          568,
          11,
          4659,
          380,
          286,
          483,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2786884307861328,
        "compression_ratio": 1.4,
        "end": 6022.48,
        "id": 1735,
        "no_speech_prob": 0.0032223921734839678,
        "seek": 601448,
        "start": 6019.48,
        "temperature": 0,
        "text": " And then I say train.print...",
        "tokens": [
          50614,
          400,
          550,
          286,
          584,
          3847,
          13,
          14030,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2786884307861328,
        "compression_ratio": 1.4,
        "end": 6025.48,
        "id": 1736,
        "no_speech_prob": 0.0032223921734839678,
        "seek": 601448,
        "start": 6023.48,
        "temperature": 0,
        "text": " And test.print.",
        "tokens": [
          50814,
          400,
          1500,
          13,
          14030,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2786884307861328,
        "compression_ratio": 1.4,
        "end": 6035.48,
        "id": 1737,
        "no_speech_prob": 0.0032223921734839678,
        "seek": 601448,
        "start": 6034.48,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51364,
          6962,
          322,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2786884307861328,
        "compression_ratio": 1.4,
        "end": 6037.48,
        "id": 1738,
        "no_speech_prob": 0.0032223921734839678,
        "seek": 601448,
        "start": 6035.48,
        "temperature": 0,
        "text": " Let me comment this stuff out here.",
        "tokens": [
          51414,
          961,
          385,
          2871,
          341,
          1507,
          484,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2786884307861328,
        "compression_ratio": 1.4,
        "end": 6043.48,
        "id": 1739,
        "no_speech_prob": 0.0032223921734839678,
        "seek": 601448,
        "start": 6039.48,
        "temperature": 0,
        "text": " All values in axis parameter must be in range negative 2 to 2, but got axis 2.",
        "tokens": [
          51614,
          1057,
          4190,
          294,
          10298,
          13075,
          1633,
          312,
          294,
          3613,
          3671,
          568,
          281,
          568,
          11,
          457,
          658,
          10298,
          568,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.27283255259195965,
        "compression_ratio": 1.1491228070175439,
        "end": 6044.48,
        "id": 1740,
        "no_speech_prob": 0.00031999163911677897,
        "seek": 604348,
        "start": 6043.48,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.27283255259195965,
        "compression_ratio": 1.1491228070175439,
        "end": 6048.48,
        "id": 1741,
        "no_speech_prob": 0.00031999163911677897,
        "seek": 604348,
        "start": 6047.48,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50564,
          883,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27283255259195965,
        "compression_ratio": 1.1491228070175439,
        "end": 6051.48,
        "id": 1742,
        "no_speech_prob": 0.00031999163911677897,
        "seek": 604348,
        "start": 6049.48,
        "temperature": 0,
        "text": " Must evenly divide the axis.",
        "tokens": [
          50664,
          13252,
          17658,
          9845,
          264,
          10298,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.27283255259195965,
        "compression_ratio": 1.1491228070175439,
        "end": 6054.48,
        "id": 1743,
        "no_speech_prob": 0.00031999163911677897,
        "seek": 604348,
        "start": 6052.48,
        "temperature": 0,
        "text": " It has to do it in half?",
        "tokens": [
          50814,
          467,
          575,
          281,
          360,
          309,
          294,
          1922,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.27283255259195965,
        "compression_ratio": 1.1491228070175439,
        "end": 6055.48,
        "id": 1744,
        "no_speech_prob": 0.00031999163911677897,
        "seek": 604348,
        "start": 6054.48,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50914,
          6962,
          322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.27283255259195965,
        "compression_ratio": 1.1491228070175439,
        "end": 6058.48,
        "id": 1745,
        "no_speech_prob": 0.00031999163911677897,
        "seek": 604348,
        "start": 6056.48,
        "temperature": 0,
        "text": " What if I just give it 2 arg... Ah!",
        "tokens": [
          51014,
          708,
          498,
          286,
          445,
          976,
          309,
          568,
          3882,
          485,
          2438,
          0,
          51114
        ]
      },
      {
        "avg_logprob": -0.27283255259195965,
        "compression_ratio": 1.1491228070175439,
        "end": 6065.48,
        "id": 1746,
        "no_speech_prob": 0.00031999163911677897,
        "seek": 604348,
        "start": 6063.48,
        "temperature": 0,
        "text": " Well, I lost my console.",
        "tokens": [
          51364,
          1042,
          11,
          286,
          2731,
          452,
          11076,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2801329294840495,
        "compression_ratio": 1.3621621621621622,
        "end": 6078.48,
        "id": 1747,
        "no_speech_prob": 0.010816754773259163,
        "seek": 607348,
        "start": 6074.48,
        "temperature": 0,
        "text": " Oh, P5, don't tell me about this.",
        "tokens": [
          50414,
          876,
          11,
          430,
          20,
          11,
          500,
          380,
          980,
          385,
          466,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2801329294840495,
        "compression_ratio": 1.3621621621621622,
        "end": 6082.48,
        "id": 1748,
        "no_speech_prob": 0.010816754773259163,
        "seek": 607348,
        "start": 6078.48,
        "temperature": 0,
        "text": " Cannot read property print of undefined at sketch.9.",
        "tokens": [
          50614,
          29866,
          310,
          1401,
          4707,
          4482,
          295,
          674,
          5666,
          2001,
          412,
          12325,
          13,
          24,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2801329294840495,
        "compression_ratio": 1.3621621621621622,
        "end": 6088.48,
        "id": 1749,
        "no_speech_prob": 0.010816754773259163,
        "seek": 607348,
        "start": 6087.48,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51064,
          961,
          311,
          536,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2801329294840495,
        "compression_ratio": 1.3621621621621622,
        "end": 6090.48,
        "id": 1750,
        "no_speech_prob": 0.010816754773259163,
        "seek": 607348,
        "start": 6088.48,
        "temperature": 0,
        "text": " Is anybody in the chat helping me?",
        "tokens": [
          51114,
          1119,
          4472,
          294,
          264,
          5081,
          4315,
          385,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.2801329294840495,
        "compression_ratio": 1.3621621621621622,
        "end": 6098.48,
        "id": 1751,
        "no_speech_prob": 0.010816754773259163,
        "seek": 607348,
        "start": 6095.48,
        "temperature": 0,
        "text": " Ideally, you'd have the same proportion of each label in the test set and the training set.",
        "tokens": [
          51464,
          40817,
          11,
          291,
          1116,
          362,
          264,
          912,
          16068,
          295,
          1184,
          7645,
          294,
          264,
          1500,
          992,
          293,
          264,
          3097,
          992,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2801329294840495,
        "compression_ratio": 1.3621621621621622,
        "end": 6099.48,
        "id": 1752,
        "no_speech_prob": 0.010816754773259163,
        "seek": 607348,
        "start": 6098.48,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51614,
          1079,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2801329294840495,
        "compression_ratio": 1.3621621621621622,
        "end": 6101.48,
        "id": 1753,
        "no_speech_prob": 0.010816754773259163,
        "seek": 607348,
        "start": 6099.48,
        "temperature": 0,
        "text": " That's very important.",
        "tokens": [
          51664,
          663,
          311,
          588,
          1021,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2814919714834176,
        "compression_ratio": 1.3076923076923077,
        "end": 6104.48,
        "id": 1754,
        "no_speech_prob": 0.0005792636075057089,
        "seek": 610148,
        "start": 6102.48,
        "temperature": 0,
        "text": " That's very important.",
        "tokens": [
          50414,
          663,
          311,
          588,
          1021,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2814919714834176,
        "compression_ratio": 1.3076923076923077,
        "end": 6111.48,
        "id": 1755,
        "no_speech_prob": 0.0005792636075057089,
        "seek": 610148,
        "start": 6107.48,
        "temperature": 0,
        "text": " I mean, if I had like a huge data set and I just split it up randomly,",
        "tokens": [
          50664,
          286,
          914,
          11,
          498,
          286,
          632,
          411,
          257,
          2603,
          1412,
          992,
          293,
          286,
          445,
          7472,
          309,
          493,
          16979,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2814919714834176,
        "compression_ratio": 1.3076923076923077,
        "end": 6115.48,
        "id": 1756,
        "no_speech_prob": 0.0005792636075057089,
        "seek": 610148,
        "start": 6111.48,
        "temperature": 0,
        "text": " it would sort of probably stay somewhat uniform.",
        "tokens": [
          50864,
          309,
          576,
          1333,
          295,
          1391,
          1754,
          8344,
          9452,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2814919714834176,
        "compression_ratio": 1.3076923076923077,
        "end": 6118.48,
        "id": 1757,
        "no_speech_prob": 0.0005792636075057089,
        "seek": 610148,
        "start": 6116.48,
        "temperature": 0,
        "text": " Clearly don't understand how TF split works.",
        "tokens": [
          51114,
          24120,
          500,
          380,
          1223,
          577,
          40964,
          7472,
          1985,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6136.48,
        "id": 1758,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6132.48,
        "temperature": 0,
        "text": " I just assumed somebody in the chat would give me the answer.",
        "tokens": [
          50414,
          286,
          445,
          15895,
          2618,
          294,
          264,
          5081,
          576,
          976,
          385,
          264,
          1867,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6137.48,
        "id": 1759,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6136.48,
        "temperature": 0,
        "text": " I stopped.",
        "tokens": [
          50614,
          286,
          5936,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6139.48,
        "id": 1760,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6137.48,
        "temperature": 0,
        "text": " My brain just stopped thinking.",
        "tokens": [
          50664,
          1222,
          3567,
          445,
          5936,
          1953,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6141.48,
        "id": 1761,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6139.48,
        "temperature": 0,
        "text": " I guess I have to figure this out myself.",
        "tokens": [
          50764,
          286,
          2041,
          286,
          362,
          281,
          2573,
          341,
          484,
          2059,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6152.48,
        "id": 1762,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6150.48,
        "temperature": 0,
        "text": " Size of each... Oh, oh, oh.",
        "tokens": [
          51314,
          35818,
          295,
          1184,
          485,
          876,
          11,
          1954,
          11,
          1954,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6155.48,
        "id": 1763,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6153.48,
        "temperature": 0,
        "text": " So, couldn't I do this?",
        "tokens": [
          51464,
          407,
          11,
          2809,
          380,
          286,
          360,
          341,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6157.48,
        "id": 1764,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6155.48,
        "temperature": 0,
        "text": " Like 2,1?",
        "tokens": [
          51564,
          1743,
          568,
          11,
          16,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2603126271565755,
        "compression_ratio": 1.3190184049079754,
        "end": 6158.48,
        "id": 1765,
        "no_speech_prob": 0.01590459980070591,
        "seek": 613148,
        "start": 6157.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51664,
          1779,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6160.48,
        "id": 1766,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6158.48,
        "temperature": 0,
        "text": " And that would give me...",
        "tokens": [
          50364,
          400,
          300,
          576,
          976,
          385,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6165.48,
        "id": 1767,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6164.48,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50664,
          1079,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6166.48,
        "id": 1768,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6165.48,
        "temperature": 0,
        "text": " That's what I want.",
        "tokens": [
          50714,
          663,
          311,
          437,
          286,
          528,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6169.48,
        "id": 1769,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6167.48,
        "temperature": 0,
        "text": " So, like, it's splitting it up.",
        "tokens": [
          50814,
          407,
          11,
          411,
          11,
          309,
          311,
          30348,
          309,
          493,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6173.48,
        "id": 1770,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6169.48,
        "temperature": 0,
        "text": " So, if I wanted... If I had 5,000, then I...",
        "tokens": [
          50914,
          407,
          11,
          498,
          286,
          1415,
          485,
          759,
          286,
          632,
          1025,
          11,
          1360,
          11,
          550,
          286,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6175.48,
        "id": 1771,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6173.48,
        "temperature": 0,
        "text": " I wish I could do this by percentage.",
        "tokens": [
          51114,
          286,
          3172,
          286,
          727,
          360,
          341,
          538,
          9668,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6180.48,
        "id": 1772,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6175.48,
        "temperature": 0,
        "text": " Like I could just say like 80%, 20%.",
        "tokens": [
          51214,
          1743,
          286,
          727,
          445,
          584,
          411,
          4688,
          8923,
          945,
          6856,
          51464
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6181.48,
        "id": 1773,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6180.48,
        "temperature": 0,
        "text": " But...",
        "tokens": [
          51464,
          583,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.21609095164707728,
        "compression_ratio": 1.3647798742138364,
        "end": 6185.48,
        "id": 1774,
        "no_speech_prob": 0.00023413242888636887,
        "seek": 615848,
        "start": 6184.48,
        "temperature": 0,
        "text": " But no.",
        "tokens": [
          51664,
          583,
          572,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16805505080961844,
        "compression_ratio": 1.4829931972789117,
        "end": 6186.48,
        "id": 1775,
        "no_speech_prob": 0.00040447260835208,
        "seek": 618548,
        "start": 6185.48,
        "temperature": 0,
        "text": " But no.",
        "tokens": [
          50364,
          583,
          572,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16805505080961844,
        "compression_ratio": 1.4829931972789117,
        "end": 6188.48,
        "id": 1776,
        "no_speech_prob": 0.00040447260835208,
        "seek": 618548,
        "start": 6186.48,
        "temperature": 0,
        "text": " Okay, so I'm going to convert all of it",
        "tokens": [
          50414,
          1033,
          11,
          370,
          286,
          478,
          516,
          281,
          7620,
          439,
          295,
          309,
          50514
        ]
      },
      {
        "avg_logprob": -0.16805505080961844,
        "compression_ratio": 1.4829931972789117,
        "end": 6192.48,
        "id": 1777,
        "no_speech_prob": 0.00040447260835208,
        "seek": 618548,
        "start": 6188.48,
        "temperature": 0,
        "text": " and then I'm going to shuffle it and then split it.",
        "tokens": [
          50514,
          293,
          550,
          286,
          478,
          516,
          281,
          39426,
          309,
          293,
          550,
          7472,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16805505080961844,
        "compression_ratio": 1.4829931972789117,
        "end": 6194.48,
        "id": 1778,
        "no_speech_prob": 0.00040447260835208,
        "seek": 618548,
        "start": 6193.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16805505080961844,
        "compression_ratio": 1.4829931972789117,
        "end": 6200.48,
        "id": 1779,
        "no_speech_prob": 0.00040447260835208,
        "seek": 618548,
        "start": 6197.48,
        "temperature": 0,
        "text": " Boy, I really don't remember where I was in this whole thing.",
        "tokens": [
          50964,
          9486,
          11,
          286,
          534,
          500,
          380,
          1604,
          689,
          286,
          390,
          294,
          341,
          1379,
          551,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16805505080961844,
        "compression_ratio": 1.4829931972789117,
        "end": 6213.48,
        "id": 1780,
        "no_speech_prob": 0.00040447260835208,
        "seek": 618548,
        "start": 6210.48,
        "temperature": 0,
        "text": " All right, so the next step that I'm doing here...",
        "tokens": [
          51614,
          1057,
          558,
          11,
          370,
          264,
          958,
          1823,
          300,
          286,
          478,
          884,
          510,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6214.48,
        "id": 1781,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6213.48,
        "temperature": 0,
        "text": " All right, let's see.",
        "tokens": [
          50364,
          1057,
          558,
          11,
          718,
          311,
          536,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6216.48,
        "id": 1782,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6214.48,
        "temperature": 0,
        "text": " I think I actually already said that.",
        "tokens": [
          50414,
          286,
          519,
          286,
          767,
          1217,
          848,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6220.48,
        "id": 1783,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6218.48,
        "temperature": 0,
        "text": " Okay, so conceivably what I want to do now",
        "tokens": [
          50614,
          1033,
          11,
          370,
          10413,
          592,
          1188,
          437,
          286,
          528,
          281,
          360,
          586,
          50714
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6222.48,
        "id": 1784,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6220.48,
        "temperature": 0,
        "text": " is look at this data.entries",
        "tokens": [
          50714,
          307,
          574,
          412,
          341,
          1412,
          13,
          317,
          2244,
          50814
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6224.48,
        "id": 1785,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6222.48,
        "temperature": 0,
        "text": " and divide it into two different arrays,",
        "tokens": [
          50814,
          293,
          9845,
          309,
          666,
          732,
          819,
          41011,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6225.48,
        "id": 1786,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6224.48,
        "temperature": 0,
        "text": " training and testing.",
        "tokens": [
          50914,
          3097,
          293,
          4997,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6226.48,
        "id": 1787,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6225.48,
        "temperature": 0,
        "text": " But here's the thing.",
        "tokens": [
          50964,
          583,
          510,
          311,
          264,
          551,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6228.48,
        "id": 1788,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6227.48,
        "temperature": 0,
        "text": " What I want...",
        "tokens": [
          51064,
          708,
          286,
          528,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6229.48,
        "id": 1789,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6228.48,
        "temperature": 0,
        "text": " I'm kind of talking about...",
        "tokens": [
          51114,
          286,
          478,
          733,
          295,
          1417,
          466,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6231.48,
        "id": 1790,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6229.48,
        "temperature": 0,
        "text": " I'm talking to myself in circles here,",
        "tokens": [
          51164,
          286,
          478,
          1417,
          281,
          2059,
          294,
          13040,
          510,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6232.48,
        "id": 1791,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6231.48,
        "temperature": 0,
        "text": " but I don't want to split it just yet,",
        "tokens": [
          51264,
          457,
          286,
          500,
          380,
          528,
          281,
          7472,
          309,
          445,
          1939,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6235.48,
        "id": 1792,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6232.48,
        "temperature": 0,
        "text": " even though that was an important point for me to make.",
        "tokens": [
          51314,
          754,
          1673,
          300,
          390,
          364,
          1021,
          935,
          337,
          385,
          281,
          652,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6238.48,
        "id": 1793,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6236.48,
        "temperature": 0,
        "text": " I'm using TensorFlow.js here",
        "tokens": [
          51514,
          286,
          478,
          1228,
          37624,
          13,
          25530,
          510,
          51614
        ]
      },
      {
        "avg_logprob": -0.1837711067466469,
        "compression_ratio": 1.6655052264808363,
        "end": 6241.48,
        "id": 1794,
        "no_speech_prob": 0.001206554938107729,
        "seek": 621348,
        "start": 6238.48,
        "temperature": 0,
        "text": " and TensorFlow.js actually has a function called split",
        "tokens": [
          51614,
          293,
          37624,
          13,
          25530,
          767,
          575,
          257,
          2445,
          1219,
          7472,
          51764
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6244.48,
        "id": 1795,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6241.48,
        "temperature": 0,
        "text": " that will let me take a long list of data points",
        "tokens": [
          50364,
          300,
          486,
          718,
          385,
          747,
          257,
          938,
          1329,
          295,
          1412,
          2793,
          50514
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6247.48,
        "id": 1796,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6244.48,
        "temperature": 0,
        "text": " and split them into two different lists of data points.",
        "tokens": [
          50514,
          293,
          7472,
          552,
          666,
          732,
          819,
          14511,
          295,
          1412,
          2793,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6249.48,
        "id": 1797,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6247.48,
        "temperature": 0,
        "text": " So what I actually want to do first",
        "tokens": [
          50664,
          407,
          437,
          286,
          767,
          528,
          281,
          360,
          700,
          50764
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6252.48,
        "id": 1798,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6249.48,
        "temperature": 0,
        "text": " is get the data into tensors,",
        "tokens": [
          50764,
          307,
          483,
          264,
          1412,
          666,
          10688,
          830,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6255.48,
        "id": 1799,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6252.48,
        "temperature": 0,
        "text": " the TensorFlow.js thing that I need to use it,",
        "tokens": [
          50914,
          264,
          37624,
          13,
          25530,
          551,
          300,
          286,
          643,
          281,
          764,
          309,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6258.48,
        "id": 1800,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6255.48,
        "temperature": 0,
        "text": " and then I'll call tf.split to do the 80-20 split.",
        "tokens": [
          51064,
          293,
          550,
          286,
          603,
          818,
          256,
          69,
          13,
          46535,
          270,
          281,
          360,
          264,
          4688,
          12,
          2009,
          7472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6259.48,
        "id": 1801,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6258.48,
        "temperature": 0,
        "text": " So how am I going to do this?",
        "tokens": [
          51214,
          407,
          577,
          669,
          286,
          516,
          281,
          360,
          341,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6261.48,
        "id": 1802,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6259.48,
        "temperature": 0,
        "text": " How am I going to convert it into tensors?",
        "tokens": [
          51264,
          1012,
          669,
          286,
          516,
          281,
          7620,
          309,
          666,
          10688,
          830,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6262.48,
        "id": 1803,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6261.48,
        "temperature": 0,
        "text": " Now, first of all,",
        "tokens": [
          51364,
          823,
          11,
          700,
          295,
          439,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6264.48,
        "id": 1804,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6262.48,
        "temperature": 0,
        "text": " if you have never looked at TensorFlow.js before,",
        "tokens": [
          51414,
          498,
          291,
          362,
          1128,
          2956,
          412,
          37624,
          13,
          25530,
          949,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6265.48,
        "id": 1805,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6264.48,
        "temperature": 0,
        "text": " I might encourage you to go watch",
        "tokens": [
          51514,
          286,
          1062,
          5373,
          291,
          281,
          352,
          1159,
          51564
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6268.48,
        "id": 1806,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6265.48,
        "temperature": 0,
        "text": " my TensorFlow.js tutorial series",
        "tokens": [
          51564,
          452,
          37624,
          13,
          25530,
          7073,
          2638,
          51714
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6269.48,
        "id": 1807,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6268.48,
        "temperature": 0,
        "text": " and it looks at what is a tensor",
        "tokens": [
          51714,
          293,
          309,
          1542,
          412,
          437,
          307,
          257,
          40863,
          51764
        ]
      },
      {
        "avg_logprob": -0.1493063733621609,
        "compression_ratio": 1.8266666666666667,
        "end": 6270.48,
        "id": 1808,
        "no_speech_prob": 0.00348336948081851,
        "seek": 624148,
        "start": 6269.48,
        "temperature": 0,
        "text": " and what are the possibilities there.",
        "tokens": [
          51764,
          293,
          437,
          366,
          264,
          12178,
          456,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6271.48,
        "id": 1809,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6270.48,
        "temperature": 0,
        "text": " But just thinking about it,",
        "tokens": [
          50364,
          583,
          445,
          1953,
          466,
          309,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6274.48,
        "id": 1810,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6271.48,
        "temperature": 0,
        "text": " the thing that I need to do also is think about,",
        "tokens": [
          50414,
          264,
          551,
          300,
          286,
          643,
          281,
          360,
          611,
          307,
          519,
          466,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6277.48,
        "id": 1811,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6274.48,
        "temperature": 0,
        "text": " I have the inputs,",
        "tokens": [
          50564,
          286,
          362,
          264,
          15743,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6281.48,
        "id": 1812,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6278.48,
        "temperature": 0,
        "text": " which are the RGB values,",
        "tokens": [
          50764,
          597,
          366,
          264,
          31231,
          4190,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6284.48,
        "id": 1813,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6281.48,
        "temperature": 0,
        "text": " and then I have the target outputs,",
        "tokens": [
          50914,
          293,
          550,
          286,
          362,
          264,
          3779,
          23930,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6287.48,
        "id": 1814,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6285.48,
        "temperature": 0,
        "text": " the target outputs,",
        "tokens": [
          51114,
          264,
          3779,
          23930,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6289.48,
        "id": 1815,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6287.48,
        "temperature": 0,
        "text": " which are the labels.",
        "tokens": [
          51214,
          597,
          366,
          264,
          16949,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6291.48,
        "id": 1816,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6289.48,
        "temperature": 0,
        "text": " And so when I create my tensors,",
        "tokens": [
          51314,
          400,
          370,
          562,
          286,
          1884,
          452,
          10688,
          830,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6294.48,
        "id": 1817,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6291.48,
        "temperature": 0,
        "text": " I'm actually going to do this somewhat separately.",
        "tokens": [
          51414,
          286,
          478,
          767,
          516,
          281,
          360,
          341,
          8344,
          14759,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6296.48,
        "id": 1818,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6294.48,
        "temperature": 0,
        "text": " So let's just worry only about the inputs.",
        "tokens": [
          51564,
          407,
          718,
          311,
          445,
          3292,
          787,
          466,
          264,
          15743,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1712806246696262,
        "compression_ratio": 1.740566037735849,
        "end": 6299.48,
        "id": 1819,
        "no_speech_prob": 0.00009915243572322652,
        "seek": 627048,
        "start": 6296.48,
        "temperature": 0,
        "text": " This is going to be the easier part first.",
        "tokens": [
          51664,
          639,
          307,
          516,
          281,
          312,
          264,
          3571,
          644,
          700,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6301.48,
        "id": 1820,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6299.48,
        "temperature": 0,
        "text": " So the inputs basically,",
        "tokens": [
          50364,
          407,
          264,
          15743,
          1936,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6306.48,
        "id": 1821,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6301.48,
        "temperature": 0,
        "text": " the tensor shape that I want is a 2D tensor, right?",
        "tokens": [
          50464,
          264,
          40863,
          3909,
          300,
          286,
          528,
          307,
          257,
          568,
          35,
          40863,
          11,
          558,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6309.48,
        "id": 1822,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6306.48,
        "temperature": 0,
        "text": " Because each input has three values,",
        "tokens": [
          50714,
          1436,
          1184,
          4846,
          575,
          1045,
          4190,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6313.48,
        "id": 1823,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6310.48,
        "temperature": 0,
        "text": " maybe a R, G, and a B value,",
        "tokens": [
          50914,
          1310,
          257,
          497,
          11,
          460,
          11,
          293,
          257,
          363,
          2158,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6315.48,
        "id": 1824,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6313.48,
        "temperature": 0,
        "text": " and then I have a lot of those.",
        "tokens": [
          51064,
          293,
          550,
          286,
          362,
          257,
          688,
          295,
          729,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6321.48,
        "id": 1825,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6317.48,
        "temperature": 0,
        "text": " So a 1D tensor, like a one-dimensional array,",
        "tokens": [
          51264,
          407,
          257,
          502,
          35,
          40863,
          11,
          411,
          257,
          472,
          12,
          18759,
          10225,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6323.48,
        "id": 1826,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6321.48,
        "temperature": 0,
        "text": " just has a single set of RGB values,",
        "tokens": [
          51464,
          445,
          575,
          257,
          2167,
          992,
          295,
          31231,
          4190,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.20206952602305311,
        "compression_ratio": 1.5698324022346368,
        "end": 6325.48,
        "id": 1827,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 629948,
        "start": 6323.48,
        "temperature": 0,
        "text": " but I have a 2D tensor,",
        "tokens": [
          51564,
          457,
          286,
          362,
          257,
          568,
          35,
          40863,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.20139042106834618,
        "compression_ratio": 1.3757575757575757,
        "end": 6330.48,
        "id": 1828,
        "no_speech_prob": 0.0004108475986868143,
        "seek": 632548,
        "start": 6326.48,
        "temperature": 0,
        "text": " because my data set is a whole bunch of those data points.",
        "tokens": [
          50414,
          570,
          452,
          1412,
          992,
          307,
          257,
          1379,
          3840,
          295,
          729,
          1412,
          2793,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20139042106834618,
        "compression_ratio": 1.3757575757575757,
        "end": 6335.48,
        "id": 1829,
        "no_speech_prob": 0.0004108475986868143,
        "seek": 632548,
        "start": 6330.48,
        "temperature": 0,
        "text": " So let me first just create a tensor 2D",
        "tokens": [
          50614,
          407,
          718,
          385,
          700,
          445,
          1884,
          257,
          40863,
          568,
          35,
          50864
        ]
      },
      {
        "avg_logprob": -0.20139042106834618,
        "compression_ratio": 1.3757575757575757,
        "end": 6337.48,
        "id": 1830,
        "no_speech_prob": 0.0004108475986868143,
        "seek": 632548,
        "start": 6335.48,
        "temperature": 0,
        "text": " out of all of the RGB values.",
        "tokens": [
          50864,
          484,
          295,
          439,
          295,
          264,
          31231,
          4190,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20139042106834618,
        "compression_ratio": 1.3757575757575757,
        "end": 6345.48,
        "id": 1831,
        "no_speech_prob": 0.0004108475986868143,
        "seek": 632548,
        "start": 6344.48,
        "temperature": 0,
        "text": " Oh, oh.",
        "tokens": [
          51314,
          876,
          11,
          1954,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20139042106834618,
        "compression_ratio": 1.3757575757575757,
        "end": 6347.48,
        "id": 1832,
        "no_speech_prob": 0.0004108475986868143,
        "seek": 632548,
        "start": 6345.48,
        "temperature": 0,
        "text": " So by the way, in addition,",
        "tokens": [
          51364,
          407,
          538,
          264,
          636,
          11,
          294,
          4500,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20139042106834618,
        "compression_ratio": 1.3757575757575757,
        "end": 6349.48,
        "id": 1833,
        "no_speech_prob": 0.0004108475986868143,
        "seek": 632548,
        "start": 6347.48,
        "temperature": 0,
        "text": " when I get to fit,",
        "tokens": [
          51464,
          562,
          286,
          483,
          281,
          3318,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.20139042106834618,
        "compression_ratio": 1.3757575757575757,
        "end": 6353.48,
        "id": 1834,
        "no_speech_prob": 0.0004108475986868143,
        "seek": 632548,
        "start": 6351.48,
        "temperature": 0,
        "text": " fit actually will split the data up for me.",
        "tokens": [
          51664,
          3318,
          767,
          486,
          7472,
          264,
          1412,
          493,
          337,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6357.48,
        "id": 1835,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6355.48,
        "temperature": 0,
        "text": " Now I can't remember,",
        "tokens": [
          50364,
          823,
          286,
          393,
          380,
          1604,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6359.48,
        "id": 1836,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6357.48,
        "temperature": 0,
        "text": " let me just go quickly look at,",
        "tokens": [
          50464,
          718,
          385,
          445,
          352,
          2661,
          574,
          412,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6365.48,
        "id": 1837,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6362.48,
        "temperature": 0,
        "text": " let me look at my XOR code.",
        "tokens": [
          50714,
          718,
          385,
          574,
          412,
          452,
          1783,
          2483,
          3089,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6369.48,
        "id": 1838,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6366.48,
        "temperature": 0,
        "text": " I just want to see something in there really quickly.",
        "tokens": [
          50914,
          286,
          445,
          528,
          281,
          536,
          746,
          294,
          456,
          534,
          2661,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6371.48,
        "id": 1839,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6369.48,
        "temperature": 0,
        "text": " Mathieu, this is not,",
        "tokens": [
          51064,
          15776,
          19347,
          11,
          341,
          307,
          406,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6374.48,
        "id": 1840,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6371.48,
        "temperature": 0,
        "text": " this doesn't need to be part of the actual tutorial.",
        "tokens": [
          51164,
          341,
          1177,
          380,
          643,
          281,
          312,
          644,
          295,
          264,
          3539,
          7073,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6376.48,
        "id": 1841,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6374.48,
        "temperature": 0,
        "text": " I just want to check something.",
        "tokens": [
          51314,
          286,
          445,
          528,
          281,
          1520,
          746,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6377.48,
        "id": 1842,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6376.48,
        "temperature": 0,
        "text": " I can't remember.",
        "tokens": [
          51414,
          286,
          393,
          380,
          1604,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6380.48,
        "id": 1843,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6377.48,
        "temperature": 0,
        "text": " Yeah, yeah, I separated into Xs and Ys.",
        "tokens": [
          51464,
          865,
          11,
          1338,
          11,
          286,
          12005,
          666,
          1783,
          82,
          293,
          398,
          82,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17698368457479213,
        "compression_ratio": 1.6519607843137254,
        "end": 6382.48,
        "id": 1844,
        "no_speech_prob": 0.00005475941361510195,
        "seek": 635548,
        "start": 6380.48,
        "temperature": 0,
        "text": " Yeah, that's what I was looking for.",
        "tokens": [
          51614,
          865,
          11,
          300,
          311,
          437,
          286,
          390,
          1237,
          337,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6388.48,
        "id": 1845,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6386.48,
        "temperature": 0,
        "text": " Where am I here?",
        "tokens": [
          50414,
          2305,
          669,
          286,
          510,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6389.48,
        "id": 1846,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6388.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6399.48,
        "id": 1847,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6395.48,
        "temperature": 0,
        "text": " And by the way, if you watched my XOR coding challenge,",
        "tokens": [
          50864,
          400,
          538,
          264,
          636,
          11,
          498,
          291,
          6337,
          452,
          1783,
          2483,
          17720,
          3430,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6401.48,
        "id": 1848,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6399.48,
        "temperature": 0,
        "text": " where I did kind of a basic,",
        "tokens": [
          51064,
          689,
          286,
          630,
          733,
          295,
          257,
          3875,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6406.48,
        "id": 1849,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6402.48,
        "temperature": 0,
        "text": " where I trained a neural network to solve exclusive OR,",
        "tokens": [
          51214,
          689,
          286,
          8895,
          257,
          18161,
          3209,
          281,
          5039,
          13005,
          19654,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6409.48,
        "id": 1850,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6406.48,
        "temperature": 0,
        "text": " I also was calling these Xs.",
        "tokens": [
          51414,
          286,
          611,
          390,
          5141,
          613,
          1783,
          82,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6410.48,
        "id": 1851,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6409.48,
        "temperature": 0,
        "text": " Can you see that?",
        "tokens": [
          51564,
          1664,
          291,
          536,
          300,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6411.48,
        "id": 1852,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6410.48,
        "temperature": 0,
        "text": " Barely.",
        "tokens": [
          51614,
          43957,
          356,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18435914175851004,
        "compression_ratio": 1.4090909090909092,
        "end": 6413.48,
        "id": 1853,
        "no_speech_prob": 0.000031201776437228546,
        "seek": 638548,
        "start": 6411.48,
        "temperature": 0,
        "text": " And the outputs being the Ys.",
        "tokens": [
          51664,
          400,
          264,
          23930,
          885,
          264,
          398,
          82,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6414.48,
        "id": 1854,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6413.48,
        "temperature": 0,
        "text": " So that's the other,",
        "tokens": [
          50364,
          407,
          300,
          311,
          264,
          661,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6417.48,
        "id": 1855,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6414.48,
        "temperature": 0,
        "text": " the Xs are like the inputs to the machine learning model,",
        "tokens": [
          50414,
          264,
          1783,
          82,
          366,
          411,
          264,
          15743,
          281,
          264,
          3479,
          2539,
          2316,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6418.48,
        "id": 1856,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6417.48,
        "temperature": 0,
        "text": " the Ys are the output.",
        "tokens": [
          50564,
          264,
          398,
          82,
          366,
          264,
          5598,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6421.48,
        "id": 1857,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6418.48,
        "temperature": 0,
        "text": " So I might use that variable naming as well.",
        "tokens": [
          50614,
          407,
          286,
          1062,
          764,
          300,
          7006,
          25290,
          382,
          731,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6423.48,
        "id": 1858,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6421.48,
        "temperature": 0,
        "text": " Okay, now I'm really going back to the computer,",
        "tokens": [
          50764,
          1033,
          11,
          586,
          286,
          478,
          534,
          516,
          646,
          281,
          264,
          3820,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6425.48,
        "id": 1859,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6423.48,
        "temperature": 0,
        "text": " and I'm going to say,",
        "tokens": [
          50864,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6427.48,
        "id": 1860,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6426.48,
        "temperature": 0,
        "text": " so first, ah,",
        "tokens": [
          51014,
          370,
          700,
          11,
          3716,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6429.48,
        "id": 1861,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6427.48,
        "temperature": 0,
        "text": " so let me first,",
        "tokens": [
          51064,
          370,
          718,
          385,
          700,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6430.48,
        "id": 1862,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6429.48,
        "temperature": 0,
        "text": " to make a tensor,",
        "tokens": [
          51164,
          281,
          652,
          257,
          40863,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6434.48,
        "id": 1863,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6430.48,
        "temperature": 0,
        "text": " I need to normalize the data and put it into arrays.",
        "tokens": [
          51214,
          286,
          643,
          281,
          2710,
          1125,
          264,
          1412,
          293,
          829,
          309,
          666,
          41011,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6436.48,
        "id": 1864,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6434.48,
        "temperature": 0,
        "text": " So let me go here and say,",
        "tokens": [
          51414,
          407,
          718,
          385,
          352,
          510,
          293,
          584,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.1829291270329402,
        "compression_ratio": 1.7566371681415929,
        "end": 6442.48,
        "id": 1865,
        "no_speech_prob": 0.00013982127711642534,
        "seek": 641348,
        "start": 6436.48,
        "temperature": 0,
        "text": " first I'm going to say let the colors be an array.",
        "tokens": [
          51514,
          700,
          286,
          478,
          516,
          281,
          584,
          718,
          264,
          4577,
          312,
          364,
          10225,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6444.48,
        "id": 1866,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6442.48,
        "temperature": 0,
        "text": " Then I'm going to go through,",
        "tokens": [
          50364,
          1396,
          286,
          478,
          516,
          281,
          352,
          807,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6447.48,
        "id": 1867,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6444.48,
        "temperature": 0,
        "text": " let every record in data,",
        "tokens": [
          50464,
          718,
          633,
          2136,
          294,
          1412,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6450.48,
        "id": 1868,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6447.48,
        "temperature": 0,
        "text": " let record of data.entries.",
        "tokens": [
          50614,
          718,
          2136,
          295,
          1412,
          13,
          317,
          2244,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6453.48,
        "id": 1869,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6451.48,
        "temperature": 0,
        "text": " I'm going to say colors,",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          584,
          4577,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6455.48,
        "id": 1870,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6454.48,
        "temperature": 0,
        "text": " and then I'm going to say,",
        "tokens": [
          50964,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6457.48,
        "id": 1871,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6455.48,
        "temperature": 0,
        "text": " I'm going to have a specific color.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          362,
          257,
          2685,
          2017,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6458.48,
        "id": 1872,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6457.48,
        "temperature": 0,
        "text": " I'm not going to use the word color,",
        "tokens": [
          51114,
          286,
          478,
          406,
          516,
          281,
          764,
          264,
          1349,
          2017,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6460.48,
        "id": 1873,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6458.48,
        "temperature": 0,
        "text": " just going to say col,",
        "tokens": [
          51164,
          445,
          516,
          281,
          584,
          1173,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6466.48,
        "id": 1874,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6460.48,
        "temperature": 0,
        "text": " is record.r divided by 255,",
        "tokens": [
          51264,
          307,
          2136,
          13,
          81,
          6666,
          538,
          3552,
          20,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6469.48,
        "id": 1875,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6466.48,
        "temperature": 0,
        "text": " record.g divided by 255.",
        "tokens": [
          51564,
          2136,
          13,
          70,
          6666,
          538,
          3552,
          20,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17419225519353693,
        "compression_ratio": 1.8666666666666667,
        "end": 6471.48,
        "id": 1876,
        "no_speech_prob": 0.00006401939754141495,
        "seek": 644248,
        "start": 6469.48,
        "temperature": 0,
        "text": " And I'm dividing by 255",
        "tokens": [
          51714,
          400,
          286,
          478,
          26764,
          538,
          3552,
          20,
          51814
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6473.48,
        "id": 1877,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6471.48,
        "temperature": 0,
        "text": " because I want to normalize,",
        "tokens": [
          50364,
          570,
          286,
          528,
          281,
          2710,
          1125,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6474.48,
        "id": 1878,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6473.48,
        "temperature": 0,
        "text": " it's going to,",
        "tokens": [
          50464,
          309,
          311,
          516,
          281,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6477.48,
        "id": 1879,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6474.48,
        "temperature": 0,
        "text": " generally speaking for my inputs to a machine learning model,",
        "tokens": [
          50514,
          5101,
          4124,
          337,
          452,
          15743,
          281,
          257,
          3479,
          2539,
          2316,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6479.48,
        "id": 1880,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6477.48,
        "temperature": 0,
        "text": " I want to normalize to some strict range.",
        "tokens": [
          50664,
          286,
          528,
          281,
          2710,
          1125,
          281,
          512,
          10910,
          3613,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6482.48,
        "id": 1881,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6479.48,
        "temperature": 0,
        "text": " Between zero and one is a pretty good one to do.",
        "tokens": [
          50764,
          18967,
          4018,
          293,
          472,
          307,
          257,
          1238,
          665,
          472,
          281,
          360,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6487.48,
        "id": 1882,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6482.48,
        "temperature": 0,
        "text": " And then I'm going to say record.b divided by 255.",
        "tokens": [
          50914,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          2136,
          13,
          65,
          6666,
          538,
          3552,
          20,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6491.48,
        "id": 1883,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6487.48,
        "temperature": 0,
        "text": " And then I'm going to say colors.push col,",
        "tokens": [
          51164,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          4577,
          13,
          79,
          1498,
          1173,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6494.48,
        "id": 1884,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6491.48,
        "temperature": 0,
        "text": " and then just going to look at this,",
        "tokens": [
          51364,
          293,
          550,
          445,
          516,
          281,
          574,
          412,
          341,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6495.48,
        "id": 1885,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6494.48,
        "temperature": 0,
        "text": " colors, let's just look at this.",
        "tokens": [
          51514,
          4577,
          11,
          718,
          311,
          445,
          574,
          412,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6497.48,
        "id": 1886,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6495.48,
        "temperature": 0,
        "text": " So this is not a tensor yet.",
        "tokens": [
          51564,
          407,
          341,
          307,
          406,
          257,
          40863,
          1939,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20337778329849243,
        "compression_ratio": 1.707112970711297,
        "end": 6499.48,
        "id": 1887,
        "no_speech_prob": 0.00008750276174396276,
        "seek": 647148,
        "start": 6497.48,
        "temperature": 0,
        "text": " This is just 5000,",
        "tokens": [
          51664,
          639,
          307,
          445,
          23777,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6501.48,
        "id": 1888,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6499.48,
        "temperature": 0,
        "text": " and probably one thing I should do",
        "tokens": [
          50364,
          293,
          1391,
          472,
          551,
          286,
          820,
          360,
          50464
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6502.48,
        "id": 1889,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6501.48,
        "temperature": 0,
        "text": " while I'm working this out",
        "tokens": [
          50464,
          1339,
          286,
          478,
          1364,
          341,
          484,
          50514
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6504.48,
        "id": 1890,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6502.48,
        "temperature": 0,
        "text": " is I should work with a smaller data set.",
        "tokens": [
          50514,
          307,
          286,
          820,
          589,
          365,
          257,
          4356,
          1412,
          992,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6507.48,
        "id": 1891,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6504.48,
        "temperature": 0,
        "text": " But 5000 is so small anyway,",
        "tokens": [
          50614,
          583,
          23777,
          307,
          370,
          1359,
          4033,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6509.48,
        "id": 1892,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6507.48,
        "temperature": 0,
        "text": " but if I were doing this with a big data set",
        "tokens": [
          50764,
          457,
          498,
          286,
          645,
          884,
          341,
          365,
          257,
          955,
          1412,
          992,
          50864
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6511.48,
        "id": 1893,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6509.48,
        "temperature": 0,
        "text": " that had 5000 records in it,",
        "tokens": [
          50864,
          300,
          632,
          23777,
          7724,
          294,
          309,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6512.48,
        "id": 1894,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6511.48,
        "temperature": 0,
        "text": " I might sort of figuring out",
        "tokens": [
          50964,
          286,
          1062,
          1333,
          295,
          15213,
          484,
          51014
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6514.48,
        "id": 1895,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6512.48,
        "temperature": 0,
        "text": " I would want to do it for just 100 first,",
        "tokens": [
          51014,
          286,
          576,
          528,
          281,
          360,
          309,
          337,
          445,
          2319,
          700,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6516.48,
        "id": 1896,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6514.48,
        "temperature": 0,
        "text": " and then I could use the large data set.",
        "tokens": [
          51114,
          293,
          550,
          286,
          727,
          764,
          264,
          2416,
          1412,
          992,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6517.48,
        "id": 1897,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6516.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6519.48,
        "id": 1898,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6517.48,
        "temperature": 0,
        "text": " So we can see here this is a big array,",
        "tokens": [
          51264,
          407,
          321,
          393,
          536,
          510,
          341,
          307,
          257,
          955,
          10225,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6522.48,
        "id": 1899,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6519.48,
        "temperature": 0,
        "text": " and each element of that array",
        "tokens": [
          51364,
          293,
          1184,
          4478,
          295,
          300,
          10225,
          51514
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6525.48,
        "id": 1900,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6522.48,
        "temperature": 0,
        "text": " is another array with the normalized color values in it.",
        "tokens": [
          51514,
          307,
          1071,
          10225,
          365,
          264,
          48704,
          2017,
          4190,
          294,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19927386819881243,
        "compression_ratio": 1.6886446886446886,
        "end": 6526.48,
        "id": 1901,
        "no_speech_prob": 0.0011694944696500897,
        "seek": 649948,
        "start": 6525.48,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51664,
          10246,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20981664542692252,
        "compression_ratio": 1.4285714285714286,
        "end": 6529.48,
        "id": 1902,
        "no_speech_prob": 0.0016743942396715283,
        "seek": 652648,
        "start": 6526.48,
        "temperature": 0,
        "text": " So this now, I should be able to say now,",
        "tokens": [
          50364,
          407,
          341,
          586,
          11,
          286,
          820,
          312,
          1075,
          281,
          584,
          586,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20981664542692252,
        "compression_ratio": 1.4285714285714286,
        "end": 6538.48,
        "id": 1903,
        "no_speech_prob": 0.0016743942396715283,
        "seek": 652648,
        "start": 6530.48,
        "temperature": 0,
        "text": " let x's equal tf.tensor2d.colors.",
        "tokens": [
          50564,
          718,
          2031,
          311,
          2681,
          256,
          69,
          13,
          83,
          23153,
          17,
          67,
          13,
          8768,
          830,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20981664542692252,
        "compression_ratio": 1.4285714285714286,
        "end": 6542.48,
        "id": 1904,
        "no_speech_prob": 0.0016743942396715283,
        "seek": 652648,
        "start": 6539.48,
        "temperature": 0,
        "text": " So this is me turning those values,",
        "tokens": [
          51014,
          407,
          341,
          307,
          385,
          6246,
          729,
          4190,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.20981664542692252,
        "compression_ratio": 1.4285714285714286,
        "end": 6548.48,
        "id": 1905,
        "no_speech_prob": 0.0016743942396715283,
        "seek": 652648,
        "start": 6542.48,
        "temperature": 0,
        "text": " and I just want to say like console.log x's shape.",
        "tokens": [
          51164,
          293,
          286,
          445,
          528,
          281,
          584,
          411,
          11076,
          13,
          4987,
          2031,
          311,
          3909,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20981664542692252,
        "compression_ratio": 1.4285714285714286,
        "end": 6552.48,
        "id": 1906,
        "no_speech_prob": 0.0016743942396715283,
        "seek": 652648,
        "start": 6548.48,
        "temperature": 0,
        "text": " Let's look at the shape of the x's just to sort of see.",
        "tokens": [
          51464,
          961,
          311,
          574,
          412,
          264,
          3909,
          295,
          264,
          2031,
          311,
          445,
          281,
          1333,
          295,
          536,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20981664542692252,
        "compression_ratio": 1.4285714285714286,
        "end": 6555.48,
        "id": 1907,
        "no_speech_prob": 0.0016743942396715283,
        "seek": 652648,
        "start": 6553.48,
        "temperature": 0,
        "text": " Yes, right?",
        "tokens": [
          51714,
          1079,
          11,
          558,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6559.48,
        "id": 1908,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6555.48,
        "temperature": 0,
        "text": " There's 5643 entries each with three values.",
        "tokens": [
          50364,
          821,
          311,
          19687,
          17201,
          23041,
          1184,
          365,
          1045,
          4190,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6561.48,
        "id": 1909,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6559.48,
        "temperature": 0,
        "text": " So I think things are going right here.",
        "tokens": [
          50564,
          407,
          286,
          519,
          721,
          366,
          516,
          558,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6563.48,
        "id": 1910,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6561.48,
        "temperature": 0,
        "text": " I turned that into a tensor,",
        "tokens": [
          50664,
          286,
          3574,
          300,
          666,
          257,
          40863,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6566.48,
        "id": 1911,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6563.48,
        "temperature": 0,
        "text": " and then, oh boy, hey, this wasn't so hard.",
        "tokens": [
          50764,
          293,
          550,
          11,
          1954,
          3237,
          11,
          4177,
          11,
          341,
          2067,
          380,
          370,
          1152,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6568.48,
        "id": 1912,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6566.48,
        "temperature": 0,
        "text": " We're in good shape here.",
        "tokens": [
          50914,
          492,
          434,
          294,
          665,
          3909,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6569.48,
        "id": 1913,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6568.48,
        "temperature": 0,
        "text": " I haven't done the training or the testing.",
        "tokens": [
          51014,
          286,
          2378,
          380,
          1096,
          264,
          3097,
          420,
          264,
          4997,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6571.48,
        "id": 1914,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6569.48,
        "temperature": 0,
        "text": " Now I need to do the y's.",
        "tokens": [
          51064,
          823,
          286,
          643,
          281,
          360,
          264,
          288,
          311,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6577.48,
        "id": 1915,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6571.48,
        "temperature": 0,
        "text": " The y's involve a concept known as one-hot encoding, I think.",
        "tokens": [
          51164,
          440,
          288,
          311,
          9494,
          257,
          3410,
          2570,
          382,
          472,
          12,
          12194,
          43430,
          11,
          286,
          519,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6578.48,
        "id": 1916,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6577.48,
        "temperature": 0,
        "text": " One-hot vector.",
        "tokens": [
          51464,
          1485,
          12,
          12194,
          8062,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6579.48,
        "id": 1917,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6578.48,
        "temperature": 0,
        "text": " So you know what?",
        "tokens": [
          51514,
          407,
          291,
          458,
          437,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6580.48,
        "id": 1918,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6579.48,
        "temperature": 0,
        "text": " I'm going to pause here.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          10465,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6581.48,
        "id": 1919,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6580.48,
        "temperature": 0,
        "text": " I finished this thing.",
        "tokens": [
          51614,
          286,
          4335,
          341,
          551,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20586448245578343,
        "compression_ratio": 1.6451612903225807,
        "end": 6584.48,
        "id": 1920,
        "no_speech_prob": 0.012053563259541988,
        "seek": 655548,
        "start": 6581.48,
        "temperature": 0,
        "text": " I'm really dividing this series into like little chunks here.",
        "tokens": [
          51664,
          286,
          478,
          534,
          26764,
          341,
          2638,
          666,
          411,
          707,
          24004,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6587.48,
        "id": 1921,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6584.48,
        "temperature": 0,
        "text": " In the next video, I'm going to look at how to make the y's,",
        "tokens": [
          50364,
          682,
          264,
          958,
          960,
          11,
          286,
          478,
          516,
          281,
          574,
          412,
          577,
          281,
          652,
          264,
          288,
          311,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6590.48,
        "id": 1922,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6587.48,
        "temperature": 0,
        "text": " and I'm going to cover a concept known as one-hot.",
        "tokens": [
          50514,
          293,
          286,
          478,
          516,
          281,
          2060,
          257,
          3410,
          2570,
          382,
          472,
          12,
          12194,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6591.48,
        "id": 1923,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6590.48,
        "temperature": 0,
        "text": " One-hot.",
        "tokens": [
          50664,
          1485,
          12,
          12194,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6593.48,
        "id": 1924,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6591.48,
        "temperature": 0,
        "text": " What's the term that I'm looking for?",
        "tokens": [
          50714,
          708,
          311,
          264,
          1433,
          300,
          286,
          478,
          1237,
          337,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6595.48,
        "id": 1925,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6593.48,
        "temperature": 0,
        "text": " Is it one-hot encoding?",
        "tokens": [
          50814,
          1119,
          309,
          472,
          12,
          12194,
          43430,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6597.48,
        "id": 1926,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6595.48,
        "temperature": 0,
        "text": " One-hot encoding, yes.",
        "tokens": [
          50914,
          1485,
          12,
          12194,
          43430,
          11,
          2086,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6602.48,
        "id": 1927,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6598.48,
        "temperature": 0,
        "text": " So I'll cover that in the next video when I make the y's.",
        "tokens": [
          51064,
          407,
          286,
          603,
          2060,
          300,
          294,
          264,
          958,
          960,
          562,
          286,
          652,
          264,
          288,
          311,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1388822098573049,
        "compression_ratio": 1.6728395061728396,
        "end": 6603.48,
        "id": 1928,
        "no_speech_prob": 0.002396700670942664,
        "seek": 658448,
        "start": 6602.48,
        "temperature": 0,
        "text": " Thanks.",
        "tokens": [
          51264,
          2561,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2705852508544922,
        "compression_ratio": 1.2348484848484849,
        "end": 6607.48,
        "id": 1929,
        "no_speech_prob": 0.4687468409538269,
        "seek": 660348,
        "start": 6604.48,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          50414,
          2438,
          11,
          1392,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2705852508544922,
        "compression_ratio": 1.2348484848484849,
        "end": 6619.48,
        "id": 1930,
        "no_speech_prob": 0.4687468409538269,
        "seek": 660348,
        "start": 6616.48,
        "temperature": 0,
        "text": " Yeah, I'm going to need to one-hot encode the labels.",
        "tokens": [
          51014,
          865,
          11,
          286,
          478,
          516,
          281,
          643,
          281,
          472,
          12,
          12194,
          2058,
          1429,
          264,
          16949,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2705852508544922,
        "compression_ratio": 1.2348484848484849,
        "end": 6624.48,
        "id": 1931,
        "no_speech_prob": 0.4687468409538269,
        "seek": 660348,
        "start": 6623.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2705852508544922,
        "compression_ratio": 1.2348484848484849,
        "end": 6628.48,
        "id": 1932,
        "no_speech_prob": 0.4687468409538269,
        "seek": 660348,
        "start": 6626.48,
        "temperature": 0,
        "text": " I actually don't know how to do this with TensorFlow.",
        "tokens": [
          51514,
          286,
          767,
          500,
          380,
          458,
          577,
          281,
          360,
          341,
          365,
          37624,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2705852508544922,
        "compression_ratio": 1.2348484848484849,
        "end": 6630.48,
        "id": 1933,
        "no_speech_prob": 0.4687468409538269,
        "seek": 660348,
        "start": 6628.48,
        "temperature": 0,
        "text": " JS.",
        "tokens": [
          51614,
          33063,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2705852508544922,
        "compression_ratio": 1.2348484848484849,
        "end": 6631.48,
        "id": 1934,
        "no_speech_prob": 0.4687468409538269,
        "seek": 660348,
        "start": 6630.48,
        "temperature": 0,
        "text": " I think there's a one-hot function.",
        "tokens": [
          51714,
          286,
          519,
          456,
          311,
          257,
          472,
          12,
          12194,
          2445,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6632.48,
        "id": 1935,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6631.48,
        "temperature": 0,
        "text": " Let me just look.",
        "tokens": [
          50364,
          961,
          385,
          445,
          574,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6634.48,
        "id": 1936,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6632.48,
        "temperature": 0,
        "text": " TF one-hot.",
        "tokens": [
          50414,
          40964,
          472,
          12,
          12194,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6639.48,
        "id": 1937,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6636.48,
        "temperature": 0,
        "text": " So you give it...",
        "tokens": [
          50614,
          407,
          291,
          976,
          309,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6643.48,
        "id": 1938,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6641.48,
        "temperature": 0,
        "text": " Let me try to understand this.",
        "tokens": [
          50864,
          961,
          385,
          853,
          281,
          1223,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6649.48,
        "id": 1939,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6648.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6652.48,
        "id": 1940,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6650.48,
        "temperature": 0,
        "text": " One-hot, 1D.",
        "tokens": [
          51314,
          1485,
          12,
          12194,
          11,
          502,
          35,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6653.48,
        "id": 1941,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6652.48,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51414,
          663,
          311,
          3657,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6657.48,
        "id": 1942,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6656.48,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51614,
          876,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2085425974959034,
        "compression_ratio": 1.1121495327102804,
        "end": 6659.48,
        "id": 1943,
        "no_speech_prob": 0.0011878976365551353,
        "seek": 663148,
        "start": 6657.48,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          51664,
          876,
          0,
          51764
        ]
      },
      {
        "avg_logprob": -0.16600750153323254,
        "compression_ratio": 1.6753246753246753,
        "end": 6664.48,
        "id": 1944,
        "no_speech_prob": 0.000046112691052258015,
        "seek": 665948,
        "start": 6659.48,
        "temperature": 0,
        "text": " So if I were to do this, if I have a tensor that's like this,",
        "tokens": [
          50364,
          407,
          498,
          286,
          645,
          281,
          360,
          341,
          11,
          498,
          286,
          362,
          257,
          40863,
          300,
          311,
          411,
          341,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.16600750153323254,
        "compression_ratio": 1.6753246753246753,
        "end": 6665.48,
        "id": 1945,
        "no_speech_prob": 0.000046112691052258015,
        "seek": 665948,
        "start": 6664.48,
        "temperature": 0,
        "text": " this is what I have.",
        "tokens": [
          50614,
          341,
          307,
          437,
          286,
          362,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16600750153323254,
        "compression_ratio": 1.6753246753246753,
        "end": 6667.48,
        "id": 1946,
        "no_speech_prob": 0.000046112691052258015,
        "seek": 665948,
        "start": 6665.48,
        "temperature": 0,
        "text": " I have like...",
        "tokens": [
          50664,
          286,
          362,
          411,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.16600750153323254,
        "compression_ratio": 1.6753246753246753,
        "end": 6673.48,
        "id": 1947,
        "no_speech_prob": 0.000046112691052258015,
        "seek": 665948,
        "start": 6670.48,
        "temperature": 0,
        "text": " I have nine possibilities, right?",
        "tokens": [
          50914,
          286,
          362,
          4949,
          12178,
          11,
          558,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.16600750153323254,
        "compression_ratio": 1.6753246753246753,
        "end": 6675.48,
        "id": 1948,
        "no_speech_prob": 0.000046112691052258015,
        "seek": 665948,
        "start": 6673.48,
        "temperature": 0,
        "text": " So let's say I have...",
        "tokens": [
          51064,
          407,
          718,
          311,
          584,
          286,
          362,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.16600750153323254,
        "compression_ratio": 1.6753246753246753,
        "end": 6681.48,
        "id": 1949,
        "no_speech_prob": 0.000046112691052258015,
        "seek": 665948,
        "start": 6675.48,
        "temperature": 0,
        "text": " I make an array that's all of the index values for the labels.",
        "tokens": [
          51164,
          286,
          652,
          364,
          10225,
          300,
          311,
          439,
          295,
          264,
          8186,
          4190,
          337,
          264,
          16949,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16600750153323254,
        "compression_ratio": 1.6753246753246753,
        "end": 6686.48,
        "id": 1950,
        "no_speech_prob": 0.000046112691052258015,
        "seek": 665948,
        "start": 6683.48,
        "temperature": 0,
        "text": " So if I say these are like the labels...",
        "tokens": [
          51564,
          407,
          498,
          286,
          584,
          613,
          366,
          411,
          264,
          16949,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.27079350860030565,
        "compression_ratio": 1.146551724137931,
        "end": 6689.48,
        "id": 1951,
        "no_speech_prob": 0.000027969061193289235,
        "seek": 668648,
        "start": 6687.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50414,
          1779,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.27079350860030565,
        "compression_ratio": 1.146551724137931,
        "end": 6702.48,
        "id": 1952,
        "no_speech_prob": 0.000027969061193289235,
        "seek": 668648,
        "start": 6691.48,
        "temperature": 0,
        "text": " And then I could say the y's would be TF one-hot, the labels...",
        "tokens": [
          50614,
          400,
          550,
          286,
          727,
          584,
          264,
          288,
          311,
          576,
          312,
          40964,
          472,
          12,
          12194,
          11,
          264,
          16949,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.27079350860030565,
        "compression_ratio": 1.146551724137931,
        "end": 6707.48,
        "id": 1953,
        "no_speech_prob": 0.000027969061193289235,
        "seek": 668648,
        "start": 6705.48,
        "temperature": 0,
        "text": " Comma nine, right?",
        "tokens": [
          51314,
          3046,
          64,
          4949,
          11,
          558,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.27079350860030565,
        "compression_ratio": 1.146551724137931,
        "end": 6711.48,
        "id": 1954,
        "no_speech_prob": 0.000027969061193289235,
        "seek": 668648,
        "start": 6710.48,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          51564,
          7010,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.27079350860030565,
        "compression_ratio": 1.146551724137931,
        "end": 6712.48,
        "id": 1955,
        "no_speech_prob": 0.000027969061193289235,
        "seek": 668648,
        "start": 6711.48,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51614,
          8561,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.27079350860030565,
        "compression_ratio": 1.146551724137931,
        "end": 6714.48,
        "id": 1956,
        "no_speech_prob": 0.000027969061193289235,
        "seek": 668648,
        "start": 6712.48,
        "temperature": 0,
        "text": " Okay, I know how to do this now.",
        "tokens": [
          51664,
          1033,
          11,
          286,
          458,
          577,
          281,
          360,
          341,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6716.48,
        "id": 1957,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6715.48,
        "temperature": 0,
        "text": " Excellent.",
        "tokens": [
          50414,
          16723,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6718.48,
        "id": 1958,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6716.48,
        "temperature": 0,
        "text": " Woo, this is fun.",
        "tokens": [
          50464,
          10468,
          11,
          341,
          307,
          1019,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6720.48,
        "id": 1959,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6718.48,
        "temperature": 0,
        "text": " I think this might be where I stop today.",
        "tokens": [
          50564,
          286,
          519,
          341,
          1062,
          312,
          689,
          286,
          1590,
          965,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6723.48,
        "id": 1960,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6722.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50764,
          1057,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6731.48,
        "id": 1961,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6730.48,
        "temperature": 0,
        "text": " What if I...",
        "tokens": [
          51164,
          708,
          498,
          286,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6735.48,
        "id": 1962,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6731.48,
        "temperature": 0,
        "text": " I'm going to kill the console if I do this, right?",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          1961,
          264,
          11076,
          498,
          286,
          360,
          341,
          11,
          558,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6737.48,
        "id": 1963,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6736.48,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51464,
          286,
          500,
          380,
          458,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6738.48,
        "id": 1964,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6737.48,
        "temperature": 0,
        "text": " Oh, it's smart.",
        "tokens": [
          51514,
          876,
          11,
          309,
          311,
          4069,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6739.48,
        "id": 1965,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6738.48,
        "temperature": 0,
        "text": " It's smarter than me.",
        "tokens": [
          51564,
          467,
          311,
          20294,
          813,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6740.48,
        "id": 1966,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6739.48,
        "temperature": 0,
        "text": " Oh, I love how it's smart.",
        "tokens": [
          51614,
          876,
          11,
          286,
          959,
          577,
          309,
          311,
          4069,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15067130263133716,
        "compression_ratio": 1.4539877300613497,
        "end": 6741.48,
        "id": 1967,
        "no_speech_prob": 0.000007183255547715817,
        "seek": 671448,
        "start": 6740.48,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          51664,
          1033,
          11,
          869,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24027653229542267,
        "compression_ratio": 1.2083333333333333,
        "end": 6743.48,
        "id": 1968,
        "no_speech_prob": 0.0005976257380098104,
        "seek": 674148,
        "start": 6742.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24027653229542267,
        "compression_ratio": 1.2083333333333333,
        "end": 6744.48,
        "id": 1969,
        "no_speech_prob": 0.0005976257380098104,
        "seek": 674148,
        "start": 6743.48,
        "temperature": 0,
        "text": " Oh, this is good.",
        "tokens": [
          50464,
          876,
          11,
          341,
          307,
          665,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24027653229542267,
        "compression_ratio": 1.2083333333333333,
        "end": 6745.48,
        "id": 1970,
        "no_speech_prob": 0.0005976257380098104,
        "seek": 674148,
        "start": 6744.48,
        "temperature": 0,
        "text": " This is good stuff.",
        "tokens": [
          50514,
          639,
          307,
          665,
          1507,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24027653229542267,
        "compression_ratio": 1.2083333333333333,
        "end": 6764.48,
        "id": 1971,
        "no_speech_prob": 0.0005976257380098104,
        "seek": 674148,
        "start": 6753.48,
        "temperature": 0,
        "text": " If there are nine labels and a data point is categorized as label three,",
        "tokens": [
          50964,
          759,
          456,
          366,
          4949,
          16949,
          293,
          257,
          1412,
          935,
          307,
          19250,
          1602,
          382,
          7645,
          1045,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.2825671506215291,
        "compression_ratio": 1.6666666666666667,
        "end": 6776.48,
        "id": 1972,
        "no_speech_prob": 0.054190654307603836,
        "seek": 676448,
        "start": 6765.48,
        "temperature": 0,
        "text": " then the one-hot encoding would be zero, zero, one...",
        "tokens": [
          50414,
          550,
          264,
          472,
          12,
          12194,
          43430,
          576,
          312,
          4018,
          11,
          4018,
          11,
          472,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.2825671506215291,
        "compression_ratio": 1.6666666666666667,
        "end": 6777.48,
        "id": 1973,
        "no_speech_prob": 0.054190654307603836,
        "seek": 676448,
        "start": 6776.48,
        "temperature": 0,
        "text": " No, no, three...",
        "tokens": [
          50964,
          883,
          11,
          572,
          11,
          1045,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.2825671506215291,
        "compression_ratio": 1.6666666666666667,
        "end": 6782.48,
        "id": 1974,
        "no_speech_prob": 0.054190654307603836,
        "seek": 676448,
        "start": 6777.48,
        "temperature": 0,
        "text": " If there are nine, three, so it's a third, so it would really be index two, yeah.",
        "tokens": [
          51014,
          759,
          456,
          366,
          4949,
          11,
          1045,
          11,
          370,
          309,
          311,
          257,
          2636,
          11,
          370,
          309,
          576,
          534,
          312,
          8186,
          732,
          11,
          1338,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2825671506215291,
        "compression_ratio": 1.6666666666666667,
        "end": 6783.48,
        "id": 1975,
        "no_speech_prob": 0.054190654307603836,
        "seek": 676448,
        "start": 6782.48,
        "temperature": 0,
        "text": " Because the...",
        "tokens": [
          51264,
          1436,
          264,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.2825671506215291,
        "compression_ratio": 1.6666666666666667,
        "end": 6784.48,
        "id": 1976,
        "no_speech_prob": 0.054190654307603836,
        "seek": 676448,
        "start": 6783.48,
        "temperature": 0,
        "text": " Or the index...",
        "tokens": [
          51314,
          1610,
          264,
          8186,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.2825671506215291,
        "compression_ratio": 1.6666666666666667,
        "end": 6787.48,
        "id": 1977,
        "no_speech_prob": 0.054190654307603836,
        "seek": 676448,
        "start": 6784.48,
        "temperature": 0,
        "text": " No, the indexes would be zero through eight, right?",
        "tokens": [
          51364,
          883,
          11,
          264,
          8186,
          279,
          576,
          312,
          4018,
          807,
          3180,
          11,
          558,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2825671506215291,
        "compression_ratio": 1.6666666666666667,
        "end": 6789.48,
        "id": 1978,
        "no_speech_prob": 0.054190654307603836,
        "seek": 676448,
        "start": 6787.48,
        "temperature": 0,
        "text": " Zero through eight.",
        "tokens": [
          51514,
          17182,
          807,
          3180,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22752839547616463,
        "compression_ratio": 1.5638297872340425,
        "end": 6792.48,
        "id": 1979,
        "no_speech_prob": 0.0011159462155774236,
        "seek": 678948,
        "start": 6790.48,
        "temperature": 0,
        "text": " Zero...",
        "tokens": [
          50414,
          17182,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.22752839547616463,
        "compression_ratio": 1.5638297872340425,
        "end": 6795.48,
        "id": 1980,
        "no_speech_prob": 0.0011159462155774236,
        "seek": 678948,
        "start": 6792.48,
        "temperature": 0,
        "text": " So the label is three, it's really the fourth.",
        "tokens": [
          50514,
          407,
          264,
          7645,
          307,
          1045,
          11,
          309,
          311,
          534,
          264,
          6409,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22752839547616463,
        "compression_ratio": 1.5638297872340425,
        "end": 6797.48,
        "id": 1981,
        "no_speech_prob": 0.0011159462155774236,
        "seek": 678948,
        "start": 6795.48,
        "temperature": 0,
        "text": " Index three, index three.",
        "tokens": [
          50664,
          33552,
          1045,
          11,
          8186,
          1045,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22752839547616463,
        "compression_ratio": 1.5638297872340425,
        "end": 6798.48,
        "id": 1982,
        "no_speech_prob": 0.0011159462155774236,
        "seek": 678948,
        "start": 6797.48,
        "temperature": 0,
        "text": " There's nine.",
        "tokens": [
          50764,
          821,
          311,
          4949,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22752839547616463,
        "compression_ratio": 1.5638297872340425,
        "end": 6812.48,
        "id": 1983,
        "no_speech_prob": 0.0011159462155774236,
        "seek": 678948,
        "start": 6798.48,
        "temperature": 0,
        "text": " Zero, zero, zero, one, zero, zero, zero, zero, zero.",
        "tokens": [
          50814,
          17182,
          11,
          4018,
          11,
          4018,
          11,
          472,
          11,
          4018,
          11,
          4018,
          11,
          4018,
          11,
          4018,
          11,
          4018,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6814.48,
        "id": 1984,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6813.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6823.48,
        "id": 1985,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6814.48,
        "temperature": 0,
        "text": " Yeah, this is going to be much easier than I thought.",
        "tokens": [
          50464,
          865,
          11,
          341,
          307,
          516,
          281,
          312,
          709,
          3571,
          813,
          286,
          1194,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6826.48,
        "id": 1986,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6823.48,
        "temperature": 0,
        "text": " Thank you, TensorFlow.js.",
        "tokens": [
          50914,
          1044,
          291,
          11,
          37624,
          13,
          25530,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6827.48,
        "id": 1987,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6826.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6832.48,
        "id": 1988,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6827.48,
        "temperature": 0,
        "text": " We're still working with our data.",
        "tokens": [
          51114,
          492,
          434,
          920,
          1364,
          365,
          527,
          1412,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6835.48,
        "id": 1989,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6832.48,
        "temperature": 0,
        "text": " At some point, we're going to start training a model.",
        "tokens": [
          51364,
          1711,
          512,
          935,
          11,
          321,
          434,
          516,
          281,
          722,
          3097,
          257,
          2316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6836.48,
        "id": 1990,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6835.48,
        "temperature": 0,
        "text": " What have I done so far?",
        "tokens": [
          51514,
          708,
          362,
          286,
          1096,
          370,
          1400,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.24431188106536866,
        "compression_ratio": 1.3595505617977528,
        "end": 6839.48,
        "id": 1991,
        "no_speech_prob": 0.08386963605880737,
        "seek": 681248,
        "start": 6836.48,
        "temperature": 0,
        "text": " Okay, so just to recap for a second.",
        "tokens": [
          51564,
          1033,
          11,
          370,
          445,
          281,
          20928,
          337,
          257,
          1150,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6844.48,
        "id": 1992,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6839.48,
        "temperature": 0,
        "text": " I've got this whole database of crowdsourced colors with a label.",
        "tokens": [
          50364,
          286,
          600,
          658,
          341,
          1379,
          8149,
          295,
          26070,
          396,
          1232,
          4577,
          365,
          257,
          7645,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6847.48,
        "id": 1993,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6844.48,
        "temperature": 0,
        "text": " And now I've converted all that stuff to tensors.",
        "tokens": [
          50614,
          400,
          586,
          286,
          600,
          16424,
          439,
          300,
          1507,
          281,
          10688,
          830,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6850.48,
        "id": 1994,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6847.48,
        "temperature": 0,
        "text": " So, and I'm just looking at the inputs now,",
        "tokens": [
          50764,
          407,
          11,
          293,
          286,
          478,
          445,
          1237,
          412,
          264,
          15743,
          586,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6852.48,
        "id": 1995,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6850.48,
        "temperature": 0,
        "text": " the inputs that I want to use for my machine learning model.",
        "tokens": [
          50914,
          264,
          15743,
          300,
          286,
          528,
          281,
          764,
          337,
          452,
          3479,
          2539,
          2316,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6856.48,
        "id": 1996,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6852.48,
        "temperature": 0,
        "text": " So I have 5,643 RGB values.",
        "tokens": [
          51014,
          407,
          286,
          362,
          1025,
          11,
          21,
          17201,
          31231,
          4190,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6860.48,
        "id": 1997,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6856.48,
        "temperature": 0,
        "text": " So the shape of the tensor is 5,643,3.",
        "tokens": [
          51214,
          407,
          264,
          3909,
          295,
          264,
          40863,
          307,
          1025,
          11,
          21,
          17201,
          11,
          18,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6861.48,
        "id": 1998,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6860.48,
        "temperature": 0,
        "text": " And I can look at it here.",
        "tokens": [
          51414,
          400,
          286,
          393,
          574,
          412,
          309,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6865.48,
        "id": 1999,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6861.48,
        "temperature": 0,
        "text": " I have all the RGB values normalized to zero between zero and one.",
        "tokens": [
          51464,
          286,
          362,
          439,
          264,
          31231,
          4190,
          48704,
          281,
          4018,
          1296,
          4018,
          293,
          472,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17384791374206543,
        "compression_ratio": 1.6150793650793651,
        "end": 6868.48,
        "id": 2000,
        "no_speech_prob": 0.21729563176631927,
        "seek": 683948,
        "start": 6865.48,
        "temperature": 0,
        "text": " Now, I need to do the Ys.",
        "tokens": [
          51664,
          823,
          11,
          286,
          643,
          281,
          360,
          264,
          398,
          82,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1803031285603841,
        "compression_ratio": 1.7007299270072993,
        "end": 6873.48,
        "id": 2001,
        "no_speech_prob": 0.010986732318997383,
        "seek": 686848,
        "start": 6868.48,
        "temperature": 0,
        "text": " I need to figure out what are the target outputs associated with each RGB value.",
        "tokens": [
          50364,
          286,
          643,
          281,
          2573,
          484,
          437,
          366,
          264,
          3779,
          23930,
          6615,
          365,
          1184,
          31231,
          2158,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1803031285603841,
        "compression_ratio": 1.7007299270072993,
        "end": 6876.48,
        "id": 2002,
        "no_speech_prob": 0.010986732318997383,
        "seek": 686848,
        "start": 6873.48,
        "temperature": 0,
        "text": " And this is exciting because we are going to cover,",
        "tokens": [
          50614,
          400,
          341,
          307,
          4670,
          570,
          321,
          366,
          516,
          281,
          2060,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1803031285603841,
        "compression_ratio": 1.7007299270072993,
        "end": 6879.48,
        "id": 2003,
        "no_speech_prob": 0.010986732318997383,
        "seek": 686848,
        "start": 6876.48,
        "temperature": 0,
        "text": " we being me and you being the person watching,",
        "tokens": [
          50764,
          321,
          885,
          385,
          293,
          291,
          885,
          264,
          954,
          1976,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1803031285603841,
        "compression_ratio": 1.7007299270072993,
        "end": 6883.48,
        "id": 2004,
        "no_speech_prob": 0.010986732318997383,
        "seek": 686848,
        "start": 6879.48,
        "temperature": 0,
        "text": " I am going to cover a concept known as one-hot encoding.",
        "tokens": [
          50914,
          286,
          669,
          516,
          281,
          2060,
          257,
          3410,
          2570,
          382,
          472,
          12,
          12194,
          43430,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1803031285603841,
        "compression_ratio": 1.7007299270072993,
        "end": 6888.48,
        "id": 2005,
        "no_speech_prob": 0.010986732318997383,
        "seek": 686848,
        "start": 6883.48,
        "temperature": 0,
        "text": " So we have to understand why we're going to do one-hot encoding.",
        "tokens": [
          51114,
          407,
          321,
          362,
          281,
          1223,
          983,
          321,
          434,
          516,
          281,
          360,
          472,
          12,
          12194,
          43430,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1803031285603841,
        "compression_ratio": 1.7007299270072993,
        "end": 6893.48,
        "id": 2006,
        "no_speech_prob": 0.010986732318997383,
        "seek": 686848,
        "start": 6888.48,
        "temperature": 0,
        "text": " We need to jump all the way to what would essentially be like the very end of this video series.",
        "tokens": [
          51364,
          492,
          643,
          281,
          3012,
          439,
          264,
          636,
          281,
          437,
          576,
          4476,
          312,
          411,
          264,
          588,
          917,
          295,
          341,
          960,
          2638,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1803031285603841,
        "compression_ratio": 1.7007299270072993,
        "end": 6896.48,
        "id": 2007,
        "no_speech_prob": 0.010986732318997383,
        "seek": 686848,
        "start": 6893.48,
        "temperature": 0,
        "text": " What am I asking the neural network that I'm going to build, right?",
        "tokens": [
          51614,
          708,
          669,
          286,
          3365,
          264,
          18161,
          3209,
          300,
          286,
          478,
          516,
          281,
          1322,
          11,
          558,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6901.48,
        "id": 2008,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6896.48,
        "temperature": 0,
        "text": " The neural network that I'm going to build is going to have three inputs, RGB.",
        "tokens": [
          50364,
          440,
          18161,
          3209,
          300,
          286,
          478,
          516,
          281,
          1322,
          307,
          516,
          281,
          362,
          1045,
          15743,
          11,
          31231,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6905.48,
        "id": 2009,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6901.48,
        "temperature": 0,
        "text": " It's going to have some architecture, some configuration of all the stuff in the middle.",
        "tokens": [
          50614,
          467,
          311,
          516,
          281,
          362,
          512,
          9482,
          11,
          512,
          11694,
          295,
          439,
          264,
          1507,
          294,
          264,
          2808,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6909.48,
        "id": 2010,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6905.48,
        "temperature": 0,
        "text": " And then the idea, I'm getting a phone call.",
        "tokens": [
          50814,
          400,
          550,
          264,
          1558,
          11,
          286,
          478,
          1242,
          257,
          2593,
          818,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6914.48,
        "id": 2011,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6909.48,
        "temperature": 0,
        "text": " Really? And my volume is on and my watch is giving me a notification.",
        "tokens": [
          51014,
          4083,
          30,
          400,
          452,
          5523,
          307,
          322,
          293,
          452,
          1159,
          307,
          2902,
          385,
          257,
          11554,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6917.48,
        "id": 2012,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6914.48,
        "temperature": 0,
        "text": " By the way, it says, I wish you could see this.",
        "tokens": [
          51264,
          3146,
          264,
          636,
          11,
          309,
          1619,
          11,
          286,
          3172,
          291,
          727,
          536,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6919.48,
        "id": 2013,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6917.48,
        "temperature": 0,
        "text": " It says, scam likely.",
        "tokens": [
          51414,
          467,
          1619,
          11,
          26917,
          3700,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6923.48,
        "id": 2014,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6919.48,
        "temperature": 0,
        "text": " That's the decline.",
        "tokens": [
          51514,
          663,
          311,
          264,
          15635,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21116411685943604,
        "compression_ratio": 1.617283950617284,
        "end": 6925.48,
        "id": 2015,
        "no_speech_prob": 0.0009849955094978213,
        "seek": 689648,
        "start": 6923.48,
        "temperature": 0,
        "text": " Turn off the volume.",
        "tokens": [
          51714,
          7956,
          766,
          264,
          5523,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19567132227629133,
        "compression_ratio": 1.5933014354066986,
        "end": 6928.48,
        "id": 2016,
        "no_speech_prob": 0.0008295823354274035,
        "seek": 692548,
        "start": 6926.48,
        "temperature": 0,
        "text": " Off the notifications.",
        "tokens": [
          50414,
          6318,
          264,
          13426,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19567132227629133,
        "compression_ratio": 1.5933014354066986,
        "end": 6930.48,
        "id": 2017,
        "no_speech_prob": 0.0008295823354274035,
        "seek": 692548,
        "start": 6928.48,
        "temperature": 0,
        "text": " I'm so thrilled about this video topic.",
        "tokens": [
          50514,
          286,
          478,
          370,
          18744,
          466,
          341,
          960,
          4829,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19567132227629133,
        "compression_ratio": 1.5933014354066986,
        "end": 6933.48,
        "id": 2018,
        "no_speech_prob": 0.0008295823354274035,
        "seek": 692548,
        "start": 6930.48,
        "temperature": 0,
        "text": " I'm going to leave that in there. I don't care.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          1856,
          300,
          294,
          456,
          13,
          286,
          500,
          380,
          1127,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19567132227629133,
        "compression_ratio": 1.5933014354066986,
        "end": 6941.48,
        "id": 2019,
        "no_speech_prob": 0.0008295823354274035,
        "seek": 692548,
        "start": 6935.48,
        "temperature": 0,
        "text": " The inputs being RGB, what do I want the outputs to be?",
        "tokens": [
          50864,
          440,
          15743,
          885,
          31231,
          11,
          437,
          360,
          286,
          528,
          264,
          23930,
          281,
          312,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.19567132227629133,
        "compression_ratio": 1.5933014354066986,
        "end": 6944.48,
        "id": 2020,
        "no_speech_prob": 0.0008295823354274035,
        "seek": 692548,
        "start": 6941.48,
        "temperature": 0,
        "text": " The output should be a label, right?",
        "tokens": [
          51164,
          440,
          5598,
          820,
          312,
          257,
          7645,
          11,
          558,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.19567132227629133,
        "compression_ratio": 1.5933014354066986,
        "end": 6949.48,
        "id": 2021,
        "no_speech_prob": 0.0008295823354274035,
        "seek": 692548,
        "start": 6944.48,
        "temperature": 0,
        "text": " I want to say, is it reddish? Is it bluish?",
        "tokens": [
          51314,
          286,
          528,
          281,
          584,
          11,
          307,
          309,
          2182,
          40974,
          30,
          1119,
          309,
          888,
          33786,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19567132227629133,
        "compression_ratio": 1.5933014354066986,
        "end": 6954.48,
        "id": 2022,
        "no_speech_prob": 0.0008295823354274035,
        "seek": 692548,
        "start": 6949.48,
        "temperature": 0,
        "text": " But this is just the label that I've used as a human being to say what I think it is.",
        "tokens": [
          51564,
          583,
          341,
          307,
          445,
          264,
          7645,
          300,
          286,
          600,
          1143,
          382,
          257,
          1952,
          885,
          281,
          584,
          437,
          286,
          519,
          309,
          307,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18608984034112158,
        "compression_ratio": 1.5223214285714286,
        "end": 6959.48,
        "id": 2023,
        "no_speech_prob": 0.0010162347462028265,
        "seek": 695448,
        "start": 6954.48,
        "temperature": 0,
        "text": " If I was doing image classification, the label would be cat or dog or rainbow or unicorn.",
        "tokens": [
          50364,
          759,
          286,
          390,
          884,
          3256,
          21538,
          11,
          264,
          7645,
          576,
          312,
          3857,
          420,
          3000,
          420,
          18526,
          420,
          28122,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18608984034112158,
        "compression_ratio": 1.5223214285714286,
        "end": 6967.48,
        "id": 2024,
        "no_speech_prob": 0.0010162347462028265,
        "seek": 695448,
        "start": 6959.48,
        "temperature": 0,
        "text": " But those strings are not going to be meaningful in the numbers-based neural network system that I'm building.",
        "tokens": [
          50614,
          583,
          729,
          13985,
          366,
          406,
          516,
          281,
          312,
          10995,
          294,
          264,
          3547,
          12,
          6032,
          18161,
          3209,
          1185,
          300,
          286,
          478,
          2390,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18608984034112158,
        "compression_ratio": 1.5223214285714286,
        "end": 6970.48,
        "id": 2025,
        "no_speech_prob": 0.0010162347462028265,
        "seek": 695448,
        "start": 6967.48,
        "temperature": 0,
        "text": " I need this to return a number.",
        "tokens": [
          51014,
          286,
          643,
          341,
          281,
          2736,
          257,
          1230,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18608984034112158,
        "compression_ratio": 1.5223214285714286,
        "end": 6978.48,
        "id": 2026,
        "no_speech_prob": 0.0010162347462028265,
        "seek": 695448,
        "start": 6970.48,
        "temperature": 0,
        "text": " So we could think if there are nine possible labels, I could return the number 0, 1, 2, 3, 4, 5, 6, 7, or 8.",
        "tokens": [
          51164,
          407,
          321,
          727,
          519,
          498,
          456,
          366,
          4949,
          1944,
          16949,
          11,
          286,
          727,
          2736,
          264,
          1230,
          1958,
          11,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          420,
          1649,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2321643526591952,
        "compression_ratio": 1.7849462365591398,
        "end": 6988.48,
        "id": 2027,
        "no_speech_prob": 0.005819613113999367,
        "seek": 697848,
        "start": 6979.48,
        "temperature": 0,
        "text": " Now, while I could try to do something where I just have one output, and it's a floating point number that I round to the nearest integer that indicates the label,",
        "tokens": [
          50414,
          823,
          11,
          1339,
          286,
          727,
          853,
          281,
          360,
          746,
          689,
          286,
          445,
          362,
          472,
          5598,
          11,
          293,
          309,
          311,
          257,
          12607,
          935,
          1230,
          300,
          286,
          3098,
          281,
          264,
          23831,
          24922,
          300,
          16203,
          264,
          7645,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2321643526591952,
        "compression_ratio": 1.7849462365591398,
        "end": 6990.48,
        "id": 2028,
        "no_speech_prob": 0.005819613113999367,
        "seek": 697848,
        "start": 6988.48,
        "temperature": 0,
        "text": " that's not going to work so well.",
        "tokens": [
          50864,
          300,
          311,
          406,
          516,
          281,
          589,
          370,
          731,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2321643526591952,
        "compression_ratio": 1.7849462365591398,
        "end": 6993.48,
        "id": 2029,
        "no_speech_prob": 0.005819613113999367,
        "seek": 697848,
        "start": 6990.48,
        "temperature": 0,
        "text": " What I actually really want is I want a probability value.",
        "tokens": [
          50964,
          708,
          286,
          767,
          534,
          528,
          307,
          286,
          528,
          257,
          8482,
          2158,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2321643526591952,
        "compression_ratio": 1.7849462365591398,
        "end": 6996.48,
        "id": 2030,
        "no_speech_prob": 0.005819613113999367,
        "seek": 697848,
        "start": 6993.48,
        "temperature": 0,
        "text": " I want a probability value for each one of these labels.",
        "tokens": [
          51114,
          286,
          528,
          257,
          8482,
          2158,
          337,
          1184,
          472,
          295,
          613,
          16949,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2321643526591952,
        "compression_ratio": 1.7849462365591398,
        "end": 7000.48,
        "id": 2031,
        "no_speech_prob": 0.005819613113999367,
        "seek": 697848,
        "start": 6996.48,
        "temperature": 0,
        "text": " So we could imagine if there are nine labels.",
        "tokens": [
          51264,
          407,
          321,
          727,
          3811,
          498,
          456,
          366,
          4949,
          16949,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2321643526591952,
        "compression_ratio": 1.7849462365591398,
        "end": 7003.48,
        "id": 2032,
        "no_speech_prob": 0.005819613113999367,
        "seek": 697848,
        "start": 7000.48,
        "temperature": 0,
        "text": " Nine is such a... I should have made it ten.",
        "tokens": [
          51464,
          18939,
          307,
          1270,
          257,
          485,
          286,
          820,
          362,
          1027,
          309,
          2064,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2321643526591952,
        "compression_ratio": 1.7849462365591398,
        "end": 7007.48,
        "id": 2033,
        "no_speech_prob": 0.005819613113999367,
        "seek": 697848,
        "start": 7003.48,
        "temperature": 0,
        "text": " If I could travel back in time and start this whole series over, I would have made ten labels",
        "tokens": [
          51614,
          759,
          286,
          727,
          3147,
          646,
          294,
          565,
          293,
          722,
          341,
          1379,
          2638,
          670,
          11,
          286,
          576,
          362,
          1027,
          2064,
          16949,
          51814
        ]
      },
      {
        "avg_logprob": -0.13618737414367216,
        "compression_ratio": 1.5884773662551441,
        "end": 7009.48,
        "id": 2034,
        "no_speech_prob": 0.026354409754276276,
        "seek": 700748,
        "start": 7007.48,
        "temperature": 0,
        "text": " because all of this would be so much easier to work out.",
        "tokens": [
          50364,
          570,
          439,
          295,
          341,
          576,
          312,
          370,
          709,
          3571,
          281,
          589,
          484,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.13618737414367216,
        "compression_ratio": 1.5884773662551441,
        "end": 7011.48,
        "id": 2035,
        "no_speech_prob": 0.026354409754276276,
        "seek": 700748,
        "start": 7009.48,
        "temperature": 0,
        "text": " But imagine there are nine labels.",
        "tokens": [
          50464,
          583,
          3811,
          456,
          366,
          4949,
          16949,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.13618737414367216,
        "compression_ratio": 1.5884773662551441,
        "end": 7015.48,
        "id": 2036,
        "no_speech_prob": 0.026354409754276276,
        "seek": 700748,
        "start": 7011.48,
        "temperature": 0,
        "text": " I don't know why I'm drawing it like this, but 1, 2, 3, 4, 5, 6, 7, 8, 9.",
        "tokens": [
          50564,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          6316,
          309,
          411,
          341,
          11,
          457,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1649,
          11,
          1722,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.13618737414367216,
        "compression_ratio": 1.5884773662551441,
        "end": 7017.48,
        "id": 2037,
        "no_speech_prob": 0.026354409754276276,
        "seek": 700748,
        "start": 7015.48,
        "temperature": 0,
        "text": " What if I had a probability?",
        "tokens": [
          50764,
          708,
          498,
          286,
          632,
          257,
          8482,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.13618737414367216,
        "compression_ratio": 1.5884773662551441,
        "end": 7024.48,
        "id": 2038,
        "no_speech_prob": 0.026354409754276276,
        "seek": 700748,
        "start": 7017.48,
        "temperature": 0,
        "text": " Like, oh, there's a 10% chance it's the first label, and there's a 20% chance it's the second label,",
        "tokens": [
          50864,
          1743,
          11,
          1954,
          11,
          456,
          311,
          257,
          1266,
          4,
          2931,
          309,
          311,
          264,
          700,
          7645,
          11,
          293,
          456,
          311,
          257,
          945,
          4,
          2931,
          309,
          311,
          264,
          1150,
          7645,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.13618737414367216,
        "compression_ratio": 1.5884773662551441,
        "end": 7028.48,
        "id": 2039,
        "no_speech_prob": 0.026354409754276276,
        "seek": 700748,
        "start": 7024.48,
        "temperature": 0,
        "text": " and then 0, 0, 0, 0, and then a 70% chance 0, 0.",
        "tokens": [
          51214,
          293,
          550,
          1958,
          11,
          1958,
          11,
          1958,
          11,
          1958,
          11,
          293,
          550,
          257,
          5285,
          4,
          2931,
          1958,
          11,
          1958,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.13618737414367216,
        "compression_ratio": 1.5884773662551441,
        "end": 7033.48,
        "id": 2040,
        "no_speech_prob": 0.026354409754276276,
        "seek": 700748,
        "start": 7028.48,
        "temperature": 0,
        "text": " All of these values might add up to 100%.",
        "tokens": [
          51414,
          1057,
          295,
          613,
          4190,
          1062,
          909,
          493,
          281,
          2319,
          6856,
          51664
        ]
      },
      {
        "avg_logprob": -0.12109426850254096,
        "compression_ratio": 1.553763440860215,
        "end": 7041.48,
        "id": 2041,
        "no_speech_prob": 0.012431365437805653,
        "seek": 703348,
        "start": 7033.48,
        "temperature": 0,
        "text": " And we could say, ah, it's most likely this one, which is index 0, 1, 2, 3, 4, 5, 6,",
        "tokens": [
          50364,
          400,
          321,
          727,
          584,
          11,
          3716,
          11,
          309,
          311,
          881,
          3700,
          341,
          472,
          11,
          597,
          307,
          8186,
          1958,
          11,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.12109426850254096,
        "compression_ratio": 1.553763440860215,
        "end": 7044.48,
        "id": 2042,
        "no_speech_prob": 0.012431365437805653,
        "seek": 703348,
        "start": 7041.48,
        "temperature": 0,
        "text": " which maps to, you know, purplish.",
        "tokens": [
          50764,
          597,
          11317,
          281,
          11,
          291,
          458,
          11,
          1864,
          564,
          742,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.12109426850254096,
        "compression_ratio": 1.553763440860215,
        "end": 7048.48,
        "id": 2043,
        "no_speech_prob": 0.012431365437805653,
        "seek": 703348,
        "start": 7044.48,
        "temperature": 0,
        "text": " So I'm trying to create the target outputs.",
        "tokens": [
          50914,
          407,
          286,
          478,
          1382,
          281,
          1884,
          264,
          3779,
          23930,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.12109426850254096,
        "compression_ratio": 1.553763440860215,
        "end": 7053.48,
        "id": 2044,
        "no_speech_prob": 0.012431365437805653,
        "seek": 703348,
        "start": 7048.48,
        "temperature": 0,
        "text": " If I know that this particular color should be purplish,",
        "tokens": [
          51114,
          759,
          286,
          458,
          300,
          341,
          1729,
          2017,
          820,
          312,
          1864,
          564,
          742,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.12109426850254096,
        "compression_ratio": 1.553763440860215,
        "end": 7062.48,
        "id": 2045,
        "no_speech_prob": 0.012431365437805653,
        "seek": 703348,
        "start": 7053.48,
        "temperature": 0,
        "text": " the target output that I want is actually 0, 0, 0, 0, 0, 0, 1, 0, 0.",
        "tokens": [
          51364,
          264,
          3779,
          5598,
          300,
          286,
          528,
          307,
          767,
          1958,
          11,
          1958,
          11,
          1958,
          11,
          1958,
          11,
          1958,
          11,
          1958,
          11,
          502,
          11,
          1958,
          11,
          1958,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1511126953421287,
        "compression_ratio": 1.449339207048458,
        "end": 7065.48,
        "id": 2046,
        "no_speech_prob": 0.0012644187081605196,
        "seek": 706248,
        "start": 7062.48,
        "temperature": 0,
        "text": " 0, 1, 2, 3, 4, 5, 6, 7, 8.",
        "tokens": [
          50364,
          1958,
          11,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1649,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1511126953421287,
        "compression_ratio": 1.449339207048458,
        "end": 7068.48,
        "id": 2047,
        "no_speech_prob": 0.0012644187081605196,
        "seek": 706248,
        "start": 7065.48,
        "temperature": 0,
        "text": " Nine labels, 0 through 8 indices.",
        "tokens": [
          50514,
          18939,
          16949,
          11,
          1958,
          807,
          1649,
          43840,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1511126953421287,
        "compression_ratio": 1.449339207048458,
        "end": 7070.48,
        "id": 2048,
        "no_speech_prob": 0.0012644187081605196,
        "seek": 706248,
        "start": 7068.48,
        "temperature": 0,
        "text": " This is one-hot encoding.",
        "tokens": [
          50664,
          639,
          307,
          472,
          12,
          12194,
          43430,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1511126953421287,
        "compression_ratio": 1.449339207048458,
        "end": 7078.48,
        "id": 2049,
        "no_speech_prob": 0.0012644187081605196,
        "seek": 706248,
        "start": 7070.48,
        "temperature": 0,
        "text": " I am taking the idea of index 6 and making a vector, a one-dimensional vector,",
        "tokens": [
          50764,
          286,
          669,
          1940,
          264,
          1558,
          295,
          8186,
          1386,
          293,
          1455,
          257,
          8062,
          11,
          257,
          472,
          12,
          18759,
          8062,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.1511126953421287,
        "compression_ratio": 1.449339207048458,
        "end": 7083.48,
        "id": 2050,
        "no_speech_prob": 0.0012644187081605196,
        "seek": 706248,
        "start": 7078.48,
        "temperature": 0,
        "text": " full of zeros with a 1 in the spot that matches the label.",
        "tokens": [
          51164,
          1577,
          295,
          35193,
          365,
          257,
          502,
          294,
          264,
          4008,
          300,
          10676,
          264,
          7645,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1511126953421287,
        "compression_ratio": 1.449339207048458,
        "end": 7089.48,
        "id": 2051,
        "no_speech_prob": 0.0012644187081605196,
        "seek": 706248,
        "start": 7083.48,
        "temperature": 0,
        "text": " A 100% chance, because if the neural network was working perfectly, this is the output that I would get.",
        "tokens": [
          51414,
          316,
          2319,
          4,
          2931,
          11,
          570,
          498,
          264,
          18161,
          3209,
          390,
          1364,
          6239,
          11,
          341,
          307,
          264,
          5598,
          300,
          286,
          576,
          483,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20396048175401923,
        "compression_ratio": 1.6551724137931034,
        "end": 7096.48,
        "id": 2052,
        "no_speech_prob": 0.0037071951664984226,
        "seek": 708948,
        "start": 7089.48,
        "temperature": 0,
        "text": " So one-hot encoding is the idea of creating your vector, having all zeros,",
        "tokens": [
          50364,
          407,
          472,
          12,
          12194,
          43430,
          307,
          264,
          1558,
          295,
          4084,
          428,
          8062,
          11,
          1419,
          439,
          35193,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20396048175401923,
        "compression_ratio": 1.6551724137931034,
        "end": 7101.48,
        "id": 2053,
        "no_speech_prob": 0.0037071951664984226,
        "seek": 708948,
        "start": 7096.48,
        "temperature": 0,
        "text": " and sort of flipping a bit on in a way, and just one of them, a switch goes on, and that's assigned 1.",
        "tokens": [
          50714,
          293,
          1333,
          295,
          26886,
          257,
          857,
          322,
          294,
          257,
          636,
          11,
          293,
          445,
          472,
          295,
          552,
          11,
          257,
          3679,
          1709,
          322,
          11,
          293,
          300,
          311,
          13279,
          502,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20396048175401923,
        "compression_ratio": 1.6551724137931034,
        "end": 7106.48,
        "id": 2054,
        "no_speech_prob": 0.0037071951664984226,
        "seek": 708948,
        "start": 7101.48,
        "temperature": 0,
        "text": " Now, I could come up with an algorithm pretty easily, probably, not easily,",
        "tokens": [
          50964,
          823,
          11,
          286,
          727,
          808,
          493,
          365,
          364,
          9284,
          1238,
          3612,
          11,
          1391,
          11,
          406,
          3612,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.20396048175401923,
        "compression_ratio": 1.6551724137931034,
        "end": 7108.48,
        "id": 2055,
        "no_speech_prob": 0.0037071951664984226,
        "seek": 708948,
        "start": 7106.48,
        "temperature": 0,
        "text": " but I could work hard on it and try it. It would be hard.",
        "tokens": [
          51214,
          457,
          286,
          727,
          589,
          1152,
          322,
          309,
          293,
          853,
          309,
          13,
          467,
          576,
          312,
          1152,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20396048175401923,
        "compression_ratio": 1.6551724137931034,
        "end": 7111.48,
        "id": 2056,
        "no_speech_prob": 0.0037071951664984226,
        "seek": 708948,
        "start": 7108.48,
        "temperature": 0,
        "text": " And I could say, take all of my labels,",
        "tokens": [
          51314,
          400,
          286,
          727,
          584,
          11,
          747,
          439,
          295,
          452,
          16949,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20396048175401923,
        "compression_ratio": 1.6551724137931034,
        "end": 7115.48,
        "id": 2057,
        "no_speech_prob": 0.0037071951664984226,
        "seek": 708948,
        "start": 7111.48,
        "temperature": 0,
        "text": " and I could convert every single label into an array with a 1 in the right spot.",
        "tokens": [
          51464,
          293,
          286,
          727,
          7620,
          633,
          2167,
          7645,
          666,
          364,
          10225,
          365,
          257,
          502,
          294,
          264,
          558,
          4008,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1899170923714686,
        "compression_ratio": 1.47979797979798,
        "end": 7122.48,
        "id": 2058,
        "no_speech_prob": 0.11755536496639252,
        "seek": 711548,
        "start": 7115.48,
        "temperature": 0,
        "text": " Luckily for us, we're using TensorFlow.js, and it has a function called tf.oneHot.",
        "tokens": [
          50364,
          19726,
          337,
          505,
          11,
          321,
          434,
          1228,
          37624,
          13,
          25530,
          11,
          293,
          309,
          575,
          257,
          2445,
          1219,
          256,
          69,
          13,
          546,
          39,
          310,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1899170923714686,
        "compression_ratio": 1.47979797979798,
        "end": 7128.48,
        "id": 2059,
        "no_speech_prob": 0.11755536496639252,
        "seek": 711548,
        "start": 7122.48,
        "temperature": 0,
        "text": " So I'm going to create the y's for this system using the tf.oneHot function,",
        "tokens": [
          50714,
          407,
          286,
          478,
          516,
          281,
          1884,
          264,
          288,
          311,
          337,
          341,
          1185,
          1228,
          264,
          256,
          69,
          13,
          546,
          39,
          310,
          2445,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.1899170923714686,
        "compression_ratio": 1.47979797979798,
        "end": 7130.48,
        "id": 2060,
        "no_speech_prob": 0.11755536496639252,
        "seek": 711548,
        "start": 7128.48,
        "temperature": 0,
        "text": " and that's what I'm going to go do next.",
        "tokens": [
          51014,
          293,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          352,
          360,
          958,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1899170923714686,
        "compression_ratio": 1.47979797979798,
        "end": 7136.48,
        "id": 2061,
        "no_speech_prob": 0.11755536496639252,
        "seek": 711548,
        "start": 7134.48,
        "temperature": 0,
        "text": " Hold on a sec, everybody.",
        "tokens": [
          51314,
          6962,
          322,
          257,
          907,
          11,
          2201,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1899170923714686,
        "compression_ratio": 1.47979797979798,
        "end": 7139.48,
        "id": 2062,
        "no_speech_prob": 0.11755536496639252,
        "seek": 711548,
        "start": 7137.48,
        "temperature": 0,
        "text": " Yeah, default ringtone.",
        "tokens": [
          51464,
          865,
          11,
          7576,
          4875,
          41656,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1899170923714686,
        "compression_ratio": 1.47979797979798,
        "end": 7141.48,
        "id": 2063,
        "no_speech_prob": 0.11755536496639252,
        "seek": 711548,
        "start": 7139.48,
        "temperature": 0,
        "text": " You know, I don't usually...",
        "tokens": [
          51564,
          509,
          458,
          11,
          286,
          500,
          380,
          2673,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.1899170923714686,
        "compression_ratio": 1.47979797979798,
        "end": 7143.48,
        "id": 2064,
        "no_speech_prob": 0.11755536496639252,
        "seek": 711548,
        "start": 7141.48,
        "temperature": 0,
        "text": " Embarrassing.",
        "tokens": [
          51664,
          24234,
          8596,
          278,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7145.48,
        "id": 2065,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7143.48,
        "temperature": 0,
        "text": " I don't even have the chat open yet.",
        "tokens": [
          50364,
          286,
          500,
          380,
          754,
          362,
          264,
          5081,
          1269,
          1939,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7147.48,
        "id": 2066,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7145.48,
        "temperature": 0,
        "text": " Oh, I'm looking at my email.",
        "tokens": [
          50464,
          876,
          11,
          286,
          478,
          1237,
          412,
          452,
          3796,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7150.48,
        "id": 2067,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7149.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7151.48,
        "id": 2068,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7150.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7152.48,
        "id": 2069,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7151.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7160.48,
        "id": 2070,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7156.48,
        "temperature": 0,
        "text": " Alright, so let's go look at the code, and now what I need to do...",
        "tokens": [
          51014,
          2798,
          11,
          370,
          718,
          311,
          352,
          574,
          412,
          264,
          3089,
          11,
          293,
          586,
          437,
          286,
          643,
          281,
          360,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7162.48,
        "id": 2071,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7160.48,
        "temperature": 0,
        "text": " I made this colors array.",
        "tokens": [
          51214,
          286,
          1027,
          341,
          4577,
          10225,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7165.48,
        "id": 2072,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7162.48,
        "temperature": 0,
        "text": " Now let me make this labels array.",
        "tokens": [
          51314,
          823,
          718,
          385,
          652,
          341,
          16949,
          10225,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7169.48,
        "id": 2073,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7165.48,
        "temperature": 0,
        "text": " And if I say labels.push...",
        "tokens": [
          51464,
          400,
          498,
          286,
          584,
          16949,
          13,
          79,
          1498,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.19084795316060385,
        "compression_ratio": 1.5290697674418605,
        "end": 7171.48,
        "id": 2074,
        "no_speech_prob": 0.000027535557819646783,
        "seek": 714348,
        "start": 7169.48,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          51664,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7172.48,
        "id": 2075,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7171.48,
        "temperature": 0,
        "text": " What I want is for this...",
        "tokens": [
          50364,
          708,
          286,
          528,
          307,
          337,
          341,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7175.48,
        "id": 2076,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7172.48,
        "temperature": 0,
        "text": " I mean, I could just push the label in it, so let's just do that.",
        "tokens": [
          50414,
          286,
          914,
          11,
          286,
          727,
          445,
          2944,
          264,
          7645,
          294,
          309,
          11,
          370,
          718,
          311,
          445,
          360,
          300,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7177.48,
        "id": 2077,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7175.48,
        "temperature": 0,
        "text": " A record.label.",
        "tokens": [
          50564,
          316,
          2136,
          13,
          75,
          18657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7179.48,
        "id": 2078,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7177.48,
        "temperature": 0,
        "text": " Let's just look at this real quick,",
        "tokens": [
          50664,
          961,
          311,
          445,
          574,
          412,
          341,
          957,
          1702,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7183.48,
        "id": 2079,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7179.48,
        "temperature": 0,
        "text": " and I'm going to comment out the console logging,",
        "tokens": [
          50764,
          293,
          286,
          478,
          516,
          281,
          2871,
          484,
          264,
          11076,
          27991,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7187.48,
        "id": 2080,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7183.48,
        "temperature": 0,
        "text": " and I'm going to say console.log labels.",
        "tokens": [
          50964,
          293,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          16949,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7188.48,
        "id": 2081,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7187.48,
        "temperature": 0,
        "text": " So let's just see.",
        "tokens": [
          51164,
          407,
          718,
          311,
          445,
          536,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7189.48,
        "id": 2082,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7188.48,
        "temperature": 0,
        "text": " This should be...",
        "tokens": [
          51214,
          639,
          820,
          312,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7190.48,
        "id": 2083,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7189.48,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51264,
          1779,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7192.48,
        "id": 2084,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7190.48,
        "temperature": 0,
        "text": " This is all the labels, the strings of the labels.",
        "tokens": [
          51314,
          639,
          307,
          439,
          264,
          16949,
          11,
          264,
          13985,
          295,
          264,
          16949,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7197.48,
        "id": 2085,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7192.48,
        "temperature": 0,
        "text": " So the first thing I need to do is convert each one of these into an index value.",
        "tokens": [
          51414,
          407,
          264,
          700,
          551,
          286,
          643,
          281,
          360,
          307,
          7620,
          1184,
          472,
          295,
          613,
          666,
          364,
          8186,
          2158,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14753243582589284,
        "compression_ratio": 1.7265625,
        "end": 7199.48,
        "id": 2086,
        "no_speech_prob": 0.00021654284500982612,
        "seek": 717148,
        "start": 7197.48,
        "temperature": 0,
        "text": " So I need a mapping for that.",
        "tokens": [
          51664,
          407,
          286,
          643,
          257,
          18350,
          337,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7201.48,
        "id": 2087,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7199.48,
        "temperature": 0,
        "text": " And I really wish...",
        "tokens": [
          50364,
          400,
          286,
          534,
          3172,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7204.48,
        "id": 2088,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7201.48,
        "temperature": 0,
        "text": " I should have this somewhere, but I'm just going to...",
        "tokens": [
          50464,
          286,
          820,
          362,
          341,
          4079,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7209.48,
        "id": 2089,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7206.48,
        "temperature": 0,
        "text": " I'm going to just create something called labels index really quick,",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          445,
          1884,
          746,
          1219,
          16949,
          8186,
          534,
          1702,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7211.48,
        "id": 2090,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7209.48,
        "temperature": 0,
        "text": " and I did this in a previous...",
        "tokens": [
          50864,
          293,
          286,
          630,
          341,
          294,
          257,
          3894,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7213.48,
        "id": 2091,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7211.48,
        "temperature": 0,
        "text": " Where did I do this?",
        "tokens": [
          50964,
          2305,
          630,
          286,
          360,
          341,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7214.48,
        "id": 2092,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7213.48,
        "temperature": 0,
        "text": " Didn't I do this in some other...",
        "tokens": [
          51064,
          11151,
          380,
          286,
          360,
          341,
          294,
          512,
          661,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7217.48,
        "id": 2093,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7214.48,
        "temperature": 0,
        "text": " One of my other examples.",
        "tokens": [
          51114,
          1485,
          295,
          452,
          661,
          5110,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7219.48,
        "id": 2094,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7217.48,
        "temperature": 0,
        "text": " I have, like, an array of all the labels.",
        "tokens": [
          51264,
          286,
          362,
          11,
          411,
          11,
          364,
          10225,
          295,
          439,
          264,
          16949,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7221.48,
        "id": 2095,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7219.48,
        "temperature": 0,
        "text": " Ah, here we go.",
        "tokens": [
          51364,
          2438,
          11,
          510,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7222.48,
        "id": 2096,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7221.48,
        "temperature": 0,
        "text": " So here...",
        "tokens": [
          51464,
          407,
          510,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7223.48,
        "id": 2097,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7222.48,
        "temperature": 0,
        "text": " Here's one of my examples.",
        "tokens": [
          51514,
          1692,
          311,
          472,
          295,
          452,
          5110,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7225.48,
        "id": 2098,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7223.48,
        "temperature": 0,
        "text": " I had all the labels.",
        "tokens": [
          51564,
          286,
          632,
          439,
          264,
          16949,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18295231461524963,
        "compression_ratio": 1.7173913043478262,
        "end": 7228.48,
        "id": 2099,
        "no_speech_prob": 0.0035380420740693808,
        "seek": 719948,
        "start": 7225.48,
        "temperature": 0,
        "text": " I lost where I was.",
        "tokens": [
          51664,
          286,
          2731,
          689,
          286,
          390,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7229.48,
        "id": 2100,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7228.48,
        "temperature": 0,
        "text": " I'm going to paste this in here.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          9163,
          341,
          294,
          510,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7235.48,
        "id": 2101,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7229.48,
        "temperature": 0,
        "text": " I'm going to search buttons.push create button.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          3164,
          9905,
          13,
          79,
          1498,
          1884,
          2960,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7239.48,
        "id": 2102,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7235.48,
        "temperature": 0,
        "text": " I'm just going to eliminate this, replace all.",
        "tokens": [
          50714,
          286,
          478,
          445,
          516,
          281,
          13819,
          341,
          11,
          7406,
          439,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7240.48,
        "id": 2103,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7239.48,
        "temperature": 0,
        "text": " I don't need that.",
        "tokens": [
          50914,
          286,
          500,
          380,
          643,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7241.48,
        "id": 2104,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7240.48,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          50964,
          400,
          550,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7244.48,
        "id": 2105,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7241.48,
        "temperature": 0,
        "text": " Oh, I want the apostrophe.",
        "tokens": [
          51014,
          876,
          11,
          286,
          528,
          264,
          19484,
          27194,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7245.48,
        "id": 2106,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7244.48,
        "temperature": 0,
        "text": " I'm going to put that back in.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          829,
          300,
          646,
          294,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7247.48,
        "id": 2107,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7245.48,
        "temperature": 0,
        "text": " I could have used, like, a regular expression, but I...",
        "tokens": [
          51214,
          286,
          727,
          362,
          1143,
          11,
          411,
          11,
          257,
          3890,
          6114,
          11,
          457,
          286,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7248.48,
        "id": 2108,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7247.48,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51314,
          2438,
          0,
          51364
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7249.48,
        "id": 2109,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7248.48,
        "temperature": 0,
        "text": " No!",
        "tokens": [
          51364,
          883,
          0,
          51414
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7250.48,
        "id": 2110,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7249.48,
        "temperature": 0,
        "text": " Sorry!",
        "tokens": [
          51414,
          4919,
          0,
          51464
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7252.48,
        "id": 2111,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7250.48,
        "temperature": 0,
        "text": " I can't believe you're watching a video where I am clumsily trying to...",
        "tokens": [
          51464,
          286,
          393,
          380,
          1697,
          291,
          434,
          1976,
          257,
          960,
          689,
          286,
          669,
          596,
          8099,
          953,
          1382,
          281,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.16792217653189132,
        "compression_ratio": 1.6088709677419355,
        "end": 7257.48,
        "id": 2112,
        "no_speech_prob": 0.0005614706315100193,
        "seek": 722848,
        "start": 7254.48,
        "temperature": 0,
        "text": " Okay, let's see if it just comes back.",
        "tokens": [
          51664,
          1033,
          11,
          718,
          311,
          536,
          498,
          309,
          445,
          1487,
          646,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7261.48,
        "id": 2113,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7259.48,
        "temperature": 0,
        "text": " Okay, I think I'm just back.",
        "tokens": [
          50414,
          1033,
          11,
          286,
          519,
          286,
          478,
          445,
          646,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7264.48,
        "id": 2114,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7261.48,
        "temperature": 0,
        "text": " I think it just comes back now that I'm doing this event thing.",
        "tokens": [
          50514,
          286,
          519,
          309,
          445,
          1487,
          646,
          586,
          300,
          286,
          478,
          884,
          341,
          2280,
          551,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7270.48,
        "id": 2115,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7264.48,
        "temperature": 0,
        "text": " So if you could tell me in the chat that I'm back.",
        "tokens": [
          50664,
          407,
          498,
          291,
          727,
          980,
          385,
          294,
          264,
          5081,
          300,
          286,
          478,
          646,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7271.48,
        "id": 2116,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7270.48,
        "temperature": 0,
        "text": " Okay, it's back.",
        "tokens": [
          50964,
          1033,
          11,
          309,
          311,
          646,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7272.48,
        "id": 2117,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7271.48,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51014,
          3769,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7273.48,
        "id": 2118,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7272.48,
        "temperature": 0,
        "text": " Sorry about that.",
        "tokens": [
          51064,
          4919,
          466,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7274.48,
        "id": 2119,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7273.48,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51114,
          286,
          500,
          380,
          458,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7275.48,
        "id": 2120,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7274.48,
        "temperature": 0,
        "text": " The computer froze.",
        "tokens": [
          51164,
          440,
          3820,
          46077,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7276.48,
        "id": 2121,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7275.48,
        "temperature": 0,
        "text": " I restarted.",
        "tokens": [
          51214,
          286,
          21022,
          292,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7277.48,
        "id": 2122,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7276.48,
        "temperature": 0,
        "text": " I don't have the YouTube chat up.",
        "tokens": [
          51264,
          286,
          500,
          380,
          362,
          264,
          3088,
          5081,
          493,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7278.48,
        "id": 2123,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7277.48,
        "temperature": 0,
        "text": " And I think...",
        "tokens": [
          51314,
          400,
          286,
          519,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7279.48,
        "id": 2124,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7278.48,
        "temperature": 0,
        "text": " Hopefully the...",
        "tokens": [
          51364,
          10429,
          264,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7282.48,
        "id": 2125,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7279.48,
        "temperature": 0,
        "text": " So let me grab that real quick.",
        "tokens": [
          51414,
          407,
          718,
          385,
          4444,
          300,
          957,
          1702,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7283.48,
        "id": 2126,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7282.48,
        "temperature": 0,
        "text": " History...",
        "tokens": [
          51564,
          12486,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.18898908103384623,
        "compression_ratio": 1.608294930875576,
        "end": 7286.48,
        "id": 2127,
        "no_speech_prob": 0.00009170045814244077,
        "seek": 725848,
        "start": 7285.48,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51714,
          45263,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20081274060235507,
        "compression_ratio": 1.3486842105263157,
        "end": 7290.48,
        "id": 2128,
        "no_speech_prob": 0.0008167040650732815,
        "seek": 728648,
        "start": 7287.48,
        "temperature": 0,
        "text": " Ah, the cameras are all shutting off, which is fine.",
        "tokens": [
          50414,
          2438,
          11,
          264,
          8622,
          366,
          439,
          36057,
          766,
          11,
          597,
          307,
          2489,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20081274060235507,
        "compression_ratio": 1.3486842105263157,
        "end": 7297.48,
        "id": 2129,
        "no_speech_prob": 0.0008167040650732815,
        "seek": 728648,
        "start": 7293.48,
        "temperature": 0,
        "text": " Let me just get the YouTube chat back up here so I can see it.",
        "tokens": [
          50714,
          961,
          385,
          445,
          483,
          264,
          3088,
          5081,
          646,
          493,
          510,
          370,
          286,
          393,
          536,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20081274060235507,
        "compression_ratio": 1.3486842105263157,
        "end": 7301.48,
        "id": 2130,
        "no_speech_prob": 0.0008167040650732815,
        "seek": 728648,
        "start": 7300.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20081274060235507,
        "compression_ratio": 1.3486842105263157,
        "end": 7311.48,
        "id": 2131,
        "no_speech_prob": 0.0008167040650732815,
        "seek": 728648,
        "start": 7307.48,
        "temperature": 0,
        "text": " So I don't know what YouTube is going to have in the end.",
        "tokens": [
          51414,
          407,
          286,
          500,
          380,
          458,
          437,
          3088,
          307,
          516,
          281,
          362,
          294,
          264,
          917,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20081274060235507,
        "compression_ratio": 1.3486842105263157,
        "end": 7312.48,
        "id": 2132,
        "no_speech_prob": 0.0008167040650732815,
        "seek": 728648,
        "start": 7311.48,
        "temperature": 0,
        "text": " Oh, was I...",
        "tokens": [
          51614,
          876,
          11,
          390,
          286,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.20081274060235507,
        "compression_ratio": 1.3486842105263157,
        "end": 7313.48,
        "id": 2133,
        "no_speech_prob": 0.0008167040650732815,
        "seek": 728648,
        "start": 7312.48,
        "temperature": 0,
        "text": " And was I...",
        "tokens": [
          51664,
          400,
          390,
          286,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7317.48,
        "id": 2134,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7313.48,
        "temperature": 0,
        "text": " Did I write something way out of bounds?",
        "tokens": [
          50364,
          2589,
          286,
          2464,
          746,
          636,
          484,
          295,
          29905,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7320.48,
        "id": 2135,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7317.48,
        "temperature": 0,
        "text": " Oh, tf.onehot.",
        "tokens": [
          50564,
          876,
          11,
          256,
          69,
          13,
          546,
          12194,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7321.48,
        "id": 2136,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7320.48,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          50714,
          663,
          311,
          2489,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7327.48,
        "id": 2137,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7326.48,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51014,
          663,
          311,
          2489,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7329.48,
        "id": 2138,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7327.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51064,
          1057,
          558,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7330.48,
        "id": 2139,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7329.48,
        "temperature": 0,
        "text": " So I was...",
        "tokens": [
          51164,
          407,
          286,
          390,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7332.48,
        "id": 2140,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7330.48,
        "temperature": 0,
        "text": " Let me go back.",
        "tokens": [
          51214,
          961,
          385,
          352,
          646,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7337.48,
        "id": 2141,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7332.48,
        "temperature": 0,
        "text": " I was about to do this, which now I feel like is silly.",
        "tokens": [
          51314,
          286,
          390,
          466,
          281,
          360,
          341,
          11,
          597,
          586,
          286,
          841,
          411,
          307,
          11774,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17764210406644845,
        "compression_ratio": 1.3544303797468353,
        "end": 7339.48,
        "id": 2142,
        "no_speech_prob": 0.000063027509895619,
        "seek": 731348,
        "start": 7337.48,
        "temperature": 0,
        "text": " Like, shouldn't I just make an array?",
        "tokens": [
          51564,
          1743,
          11,
          4659,
          380,
          286,
          445,
          652,
          364,
          10225,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7348.48,
        "id": 2143,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7344.48,
        "temperature": 0,
        "text": " Shouldn't I just make an array of the labels?",
        "tokens": [
          50414,
          34170,
          380,
          286,
          445,
          652,
          364,
          10225,
          295,
          264,
          16949,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7351.48,
        "id": 2144,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7348.48,
        "temperature": 0,
        "text": " And then I could get the index, right?",
        "tokens": [
          50614,
          400,
          550,
          286,
          727,
          483,
          264,
          8186,
          11,
          558,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7352.48,
        "id": 2145,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7351.48,
        "temperature": 0,
        "text": " Isn't there...",
        "tokens": [
          50764,
          6998,
          380,
          456,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7354.48,
        "id": 2146,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7352.48,
        "temperature": 0,
        "text": " There must be a way, like, right?",
        "tokens": [
          50814,
          821,
          1633,
          312,
          257,
          636,
          11,
          411,
          11,
          558,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7356.48,
        "id": 2147,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7354.48,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          50914,
          7521,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7358.48,
        "id": 2148,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7356.48,
        "temperature": 0,
        "text": " Whoa, what just...",
        "tokens": [
          51014,
          7521,
          11,
          437,
          445,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7360.48,
        "id": 2149,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7358.48,
        "temperature": 0,
        "text": " What happened to the Chrome?",
        "tokens": [
          51114,
          708,
          2011,
          281,
          264,
          15327,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.3004558397376019,
        "compression_ratio": 1.3793103448275863,
        "end": 7361.48,
        "id": 2150,
        "no_speech_prob": 0.00003373706931597553,
        "seek": 734348,
        "start": 7360.48,
        "temperature": 0,
        "text": " Chrome died.",
        "tokens": [
          51214,
          15327,
          4539,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23242668483568274,
        "compression_ratio": 1.201834862385321,
        "end": 7362.48,
        "id": 2151,
        "no_speech_prob": 0.012431144714355469,
        "seek": 736148,
        "start": 7361.48,
        "temperature": 0.4,
        "text": " What happened to the Chrome?",
        "tokens": [
          50364,
          708,
          2011,
          281,
          264,
          15327,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.23242668483568274,
        "compression_ratio": 1.201834862385321,
        "end": 7363.48,
        "id": 2152,
        "no_speech_prob": 0.012431144714355469,
        "seek": 736148,
        "start": 7362.48,
        "temperature": 0.4,
        "text": " Chrome died.",
        "tokens": [
          50414,
          15327,
          4539,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23242668483568274,
        "compression_ratio": 1.201834862385321,
        "end": 7375.48,
        "id": 2153,
        "no_speech_prob": 0.012431144714355469,
        "seek": 736148,
        "start": 7373.48,
        "temperature": 0.4,
        "text": " I don't need this.",
        "tokens": [
          50964,
          286,
          500,
          380,
          643,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23242668483568274,
        "compression_ratio": 1.201834862385321,
        "end": 7387.48,
        "id": 2154,
        "no_speech_prob": 0.012431144714355469,
        "seek": 736148,
        "start": 7384.48,
        "temperature": 0.4,
        "text": " Why do I have this, like, debugger thing on?",
        "tokens": [
          51514,
          1545,
          360,
          286,
          362,
          341,
          11,
          411,
          11,
          24083,
          1321,
          551,
          322,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.23242668483568274,
        "compression_ratio": 1.201834862385321,
        "end": 7389.48,
        "id": 2155,
        "no_speech_prob": 0.012431144714355469,
        "seek": 736148,
        "start": 7387.48,
        "temperature": 0.4,
        "text": " Where did that come from?",
        "tokens": [
          51664,
          2305,
          630,
          300,
          808,
          490,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7391.48,
        "id": 2156,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7390.48,
        "temperature": 0,
        "text": " How did I get this?",
        "tokens": [
          50414,
          1012,
          630,
          286,
          483,
          341,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7393.48,
        "id": 2157,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7391.48,
        "temperature": 0,
        "text": " What is this thing?",
        "tokens": [
          50464,
          708,
          307,
          341,
          551,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7394.48,
        "id": 2158,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7393.48,
        "temperature": 0,
        "text": " Go away.",
        "tokens": [
          50564,
          1037,
          1314,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7395.48,
        "id": 2159,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7394.48,
        "temperature": 0,
        "text": " What is this tab here?",
        "tokens": [
          50614,
          708,
          307,
          341,
          4421,
          510,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7397.48,
        "id": 2160,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7395.48,
        "temperature": 0,
        "text": " I've never seen that tab.",
        "tokens": [
          50664,
          286,
          600,
          1128,
          1612,
          300,
          4421,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7398.48,
        "id": 2161,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7397.48,
        "temperature": 0,
        "text": " Oh, hide...",
        "tokens": [
          50764,
          876,
          11,
          6479,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7399.48,
        "id": 2162,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7398.48,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50814,
          821,
          321,
          352,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7400.48,
        "id": 2163,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7399.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7403.48,
        "id": 2164,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7401.48,
        "temperature": 0,
        "text": " One single array of strings, right?",
        "tokens": [
          50964,
          1485,
          2167,
          10225,
          295,
          13985,
          11,
          558,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7405.48,
        "id": 2165,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7403.48,
        "temperature": 0,
        "text": " Like, what if I do...",
        "tokens": [
          51064,
          1743,
          11,
          437,
          498,
          286,
          360,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7412.48,
        "id": 2166,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7408.48,
        "temperature": 0,
        "text": " Right, then I can say index of b, right?",
        "tokens": [
          51314,
          1779,
          11,
          550,
          286,
          393,
          584,
          8186,
          295,
          272,
          11,
          558,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7413.48,
        "id": 2167,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7412.48,
        "temperature": 0,
        "text": " Yeah, okay.",
        "tokens": [
          51514,
          865,
          11,
          1392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7415.48,
        "id": 2168,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7413.48,
        "temperature": 0,
        "text": " So that's what I'm going to do.",
        "tokens": [
          51564,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7417.48,
        "id": 2169,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7415.48,
        "temperature": 0,
        "text": " I don't know why I didn't think of that before.",
        "tokens": [
          51664,
          286,
          500,
          380,
          458,
          983,
          286,
          994,
          380,
          519,
          295,
          300,
          949,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15695108032226562,
        "compression_ratio": 1.5402843601895735,
        "end": 7418.48,
        "id": 2170,
        "no_speech_prob": 0.000020785102606168948,
        "seek": 738948,
        "start": 7417.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51764,
          1033,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19609665870666504,
        "compression_ratio": 1.4774193548387098,
        "end": 7420.48,
        "id": 2171,
        "no_speech_prob": 0.000226930933422409,
        "seek": 741848,
        "start": 7418.48,
        "temperature": 0,
        "text": " So let me go back.",
        "tokens": [
          50364,
          407,
          718,
          385,
          352,
          646,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19609665870666504,
        "compression_ratio": 1.4774193548387098,
        "end": 7425.48,
        "id": 2172,
        "no_speech_prob": 0.000226930933422409,
        "seek": 741848,
        "start": 7420.48,
        "temperature": 0,
        "text": " Mathieu, I'm going to go back to where I was looking for the list of labels.",
        "tokens": [
          50464,
          15776,
          19347,
          11,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          689,
          286,
          390,
          1237,
          337,
          264,
          1329,
          295,
          16949,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19609665870666504,
        "compression_ratio": 1.4774193548387098,
        "end": 7431.48,
        "id": 2173,
        "no_speech_prob": 0.000226930933422409,
        "seek": 741848,
        "start": 7429.48,
        "temperature": 0,
        "text": " So I need to find that list of labels,",
        "tokens": [
          50914,
          407,
          286,
          643,
          281,
          915,
          300,
          1329,
          295,
          16949,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.19609665870666504,
        "compression_ratio": 1.4774193548387098,
        "end": 7437.48,
        "id": 2174,
        "no_speech_prob": 0.000226930933422409,
        "seek": 741848,
        "start": 7431.48,
        "temperature": 0,
        "text": " which I believe I had in the original crowdsource color thing.",
        "tokens": [
          51014,
          597,
          286,
          1697,
          286,
          632,
          294,
          264,
          3380,
          26070,
          2948,
          2017,
          551,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19609665870666504,
        "compression_ratio": 1.4774193548387098,
        "end": 7438.48,
        "id": 2175,
        "no_speech_prob": 0.000226930933422409,
        "seek": 741848,
        "start": 7437.48,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51314,
          883,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19609665870666504,
        "compression_ratio": 1.4774193548387098,
        "end": 7441.48,
        "id": 2176,
        "no_speech_prob": 0.000226930933422409,
        "seek": 741848,
        "start": 7439.48,
        "temperature": 0,
        "text": " No, wait, hold on.",
        "tokens": [
          51414,
          883,
          11,
          1699,
          11,
          1797,
          322,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19609665870666504,
        "compression_ratio": 1.4774193548387098,
        "end": 7442.48,
        "id": 2177,
        "no_speech_prob": 0.000226930933422409,
        "seek": 741848,
        "start": 7441.48,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51514,
          6962,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7450.48,
        "id": 2178,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7448.48,
        "temperature": 0,
        "text": " Where actually was that?",
        "tokens": [
          50364,
          2305,
          767,
          390,
          300,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7453.48,
        "id": 2179,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7452.48,
        "temperature": 0,
        "text": " Oh, yeah, here it is.",
        "tokens": [
          50564,
          876,
          11,
          1338,
          11,
          510,
          309,
          307,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7454.48,
        "id": 2180,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7453.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7459.48,
        "id": 2181,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7458.48,
        "temperature": 0,
        "text": " Okay, sorry.",
        "tokens": [
          50864,
          1033,
          11,
          2597,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7466.48,
        "id": 2182,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7462.48,
        "temperature": 0,
        "text": " Download data, sketch, color classifier.",
        "tokens": [
          51064,
          32282,
          1412,
          11,
          12325,
          11,
          2017,
          1508,
          9902,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7468.48,
        "id": 2183,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7467.48,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          51314,
          2305,
          669,
          286,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7472.48,
        "id": 2184,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7469.48,
        "temperature": 0,
        "text": " Okay, hopefully this will edit together fine.",
        "tokens": [
          51414,
          1033,
          11,
          4696,
          341,
          486,
          8129,
          1214,
          2489,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7474.48,
        "id": 2185,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7472.48,
        "temperature": 0,
        "text": " I'm going to just...",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          445,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.18887812951031854,
        "compression_ratio": 1.3082191780821917,
        "end": 7476.48,
        "id": 2186,
        "no_speech_prob": 0.0007436470477841794,
        "seek": 744848,
        "start": 7475.48,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51714,
          865,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7481.48,
        "id": 2187,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7479.48,
        "temperature": 0,
        "text": " All right, so I need to find my list of labels.",
        "tokens": [
          50414,
          1057,
          558,
          11,
          370,
          286,
          643,
          281,
          915,
          452,
          1329,
          295,
          16949,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7483.48,
        "id": 2188,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7481.48,
        "temperature": 0,
        "text": " I could just type them out.",
        "tokens": [
          50514,
          286,
          727,
          445,
          2010,
          552,
          484,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7485.48,
        "id": 2189,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7483.48,
        "temperature": 0,
        "text": " Labels...",
        "tokens": [
          50614,
          10137,
          1625,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7491.48,
        "id": 2190,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7485.48,
        "temperature": 0,
        "text": " Oh, no, but all labels equals...",
        "tokens": [
          50714,
          876,
          11,
          572,
          11,
          457,
          439,
          16949,
          6915,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7493.48,
        "id": 2191,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7491.48,
        "temperature": 0,
        "text": " I could say label list.",
        "tokens": [
          51014,
          286,
          727,
          584,
          7645,
          1329,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7494.48,
        "id": 2192,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7493.48,
        "temperature": 0,
        "text": " Let me call it label list.",
        "tokens": [
          51114,
          961,
          385,
          818,
          309,
          7645,
          1329,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7497.48,
        "id": 2193,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7494.48,
        "temperature": 0,
        "text": " Grayish, bluish, but I have that right here, right?",
        "tokens": [
          51164,
          22668,
          742,
          11,
          888,
          33786,
          11,
          457,
          286,
          362,
          300,
          558,
          510,
          11,
          558,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7499.48,
        "id": 2194,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7497.48,
        "temperature": 0,
        "text": " In crowdsource color.",
        "tokens": [
          51314,
          682,
          26070,
          2948,
          2017,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7501.48,
        "id": 2195,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7499.48,
        "temperature": 0,
        "text": " When I made those buttons, these are all the labels.",
        "tokens": [
          51414,
          1133,
          286,
          1027,
          729,
          9905,
          11,
          613,
          366,
          439,
          264,
          16949,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7503.48,
        "id": 2196,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7501.48,
        "temperature": 0,
        "text": " One, two, three, four, five, six, seven, eight, nine.",
        "tokens": [
          51514,
          1485,
          11,
          732,
          11,
          1045,
          11,
          1451,
          11,
          1732,
          11,
          2309,
          11,
          3407,
          11,
          3180,
          11,
          4949,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1782369401719835,
        "compression_ratio": 1.6428571428571428,
        "end": 7507.48,
        "id": 2197,
        "no_speech_prob": 0.000040063419874059036,
        "seek": 747848,
        "start": 7503.48,
        "temperature": 0,
        "text": " So if I come back to what I'm doing here and just put this here",
        "tokens": [
          51614,
          407,
          498,
          286,
          808,
          646,
          281,
          437,
          286,
          478,
          884,
          510,
          293,
          445,
          829,
          341,
          510,
          51814
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7511.48,
        "id": 2198,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7507.48,
        "temperature": 0,
        "text": " and then let me just do a find replace.",
        "tokens": [
          50364,
          293,
          550,
          718,
          385,
          445,
          360,
          257,
          915,
          7406,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7512.48,
        "id": 2199,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7511.48,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50564,
          45263,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7515.48,
        "id": 2200,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7513.48,
        "temperature": 0,
        "text": " Let me do a find replace for...",
        "tokens": [
          50664,
          961,
          385,
          360,
          257,
          915,
          7406,
          337,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7519.48,
        "id": 2201,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7518.48,
        "temperature": 0,
        "text": " Just this.",
        "tokens": [
          50914,
          1449,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7520.48,
        "id": 2202,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7519.48,
        "temperature": 0,
        "text": " I just need to get rid of this.",
        "tokens": [
          50964,
          286,
          445,
          643,
          281,
          483,
          3973,
          295,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7524.48,
        "id": 2203,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7521.48,
        "temperature": 0,
        "text": " Boy, yes, you're watching me like...",
        "tokens": [
          51064,
          9486,
          11,
          2086,
          11,
          291,
          434,
          1976,
          385,
          411,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7527.48,
        "id": 2204,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7525.48,
        "temperature": 0,
        "text": " failing at doing find replace.",
        "tokens": [
          51264,
          18223,
          412,
          884,
          915,
          7406,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24937540690104168,
        "compression_ratio": 1.5714285714285714,
        "end": 7532.48,
        "id": 2205,
        "no_speech_prob": 0.00029136647935956717,
        "seek": 750748,
        "start": 7527.48,
        "temperature": 0,
        "text": " And then let me look for ish.",
        "tokens": [
          51364,
          400,
          550,
          718,
          385,
          574,
          337,
          307,
          71,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7537.48,
        "id": 2206,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7533.48,
        "temperature": 0,
        "text": " And replace that with ish, comma.",
        "tokens": [
          50414,
          400,
          7406,
          300,
          365,
          307,
          71,
          11,
          22117,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7539.48,
        "id": 2207,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7537.48,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50614,
          821,
          321,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7542.48,
        "id": 2208,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7539.48,
        "temperature": 0,
        "text": " Now I have my array, my label list array.",
        "tokens": [
          50714,
          823,
          286,
          362,
          452,
          10225,
          11,
          452,
          7645,
          1329,
          10225,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7546.48,
        "id": 2209,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7542.48,
        "temperature": 0,
        "text": " So now what I want to put in the labels array",
        "tokens": [
          50864,
          407,
          586,
          437,
          286,
          528,
          281,
          829,
          294,
          264,
          16949,
          10225,
          51064
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7548.48,
        "id": 2210,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7546.48,
        "temperature": 0,
        "text": " is not the actual string of the label,",
        "tokens": [
          51064,
          307,
          406,
          264,
          3539,
          6798,
          295,
          264,
          7645,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7553.48,
        "id": 2211,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7548.48,
        "temperature": 0,
        "text": " but label list index of that label.",
        "tokens": [
          51164,
          457,
          7645,
          1329,
          8186,
          295,
          300,
          7645,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7555.48,
        "id": 2212,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7553.48,
        "temperature": 0,
        "text": " So the index of function...",
        "tokens": [
          51414,
          407,
          264,
          8186,
          295,
          2445,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7556.48,
        "id": 2213,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7555.48,
        "temperature": 0,
        "text": " I need another parenthesis there.",
        "tokens": [
          51514,
          286,
          643,
          1071,
          23350,
          9374,
          456,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2053433708522631,
        "compression_ratio": 1.664835164835165,
        "end": 7558.48,
        "id": 2214,
        "no_speech_prob": 0.0005274764844216406,
        "seek": 753248,
        "start": 7556.48,
        "temperature": 0,
        "text": " The index of function will say,",
        "tokens": [
          51564,
          440,
          8186,
          295,
          2445,
          486,
          584,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7560.48,
        "id": 2215,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7558.48,
        "temperature": 0,
        "text": " look for this particular element in the array",
        "tokens": [
          50364,
          574,
          337,
          341,
          1729,
          4478,
          294,
          264,
          10225,
          50464
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7562.48,
        "id": 2216,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7560.48,
        "temperature": 0,
        "text": " and give me back its index.",
        "tokens": [
          50464,
          293,
          976,
          385,
          646,
          1080,
          8186,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7564.48,
        "id": 2217,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7562.48,
        "temperature": 0,
        "text": " So let's look at that now.",
        "tokens": [
          50564,
          407,
          718,
          311,
          574,
          412,
          300,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7566.48,
        "id": 2218,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7564.48,
        "temperature": 0,
        "text": " Let me run this again.",
        "tokens": [
          50664,
          961,
          385,
          1190,
          341,
          797,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7567.48,
        "id": 2219,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7566.48,
        "temperature": 0,
        "text": " And we can see, there we go.",
        "tokens": [
          50764,
          400,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7573.48,
        "id": 2220,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7567.48,
        "temperature": 0,
        "text": " Now I have 5,643 index values.",
        "tokens": [
          50814,
          823,
          286,
          362,
          1025,
          11,
          21,
          17201,
          8186,
          4190,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7574.48,
        "id": 2221,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7573.48,
        "temperature": 0,
        "text": " And guess what?",
        "tokens": [
          51114,
          400,
          2041,
          437,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7576.48,
        "id": 2222,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7574.48,
        "temperature": 0,
        "text": " This is when I now want to go...",
        "tokens": [
          51164,
          639,
          307,
          562,
          286,
          586,
          528,
          281,
          352,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7577.48,
        "id": 2223,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7576.48,
        "temperature": 0,
        "text": " And I apologize.",
        "tokens": [
          51264,
          400,
          286,
          12328,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7580.48,
        "id": 2224,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7577.48,
        "temperature": 0,
        "text": " I wrote tf.one hot up there.",
        "tokens": [
          51314,
          286,
          4114,
          256,
          69,
          13,
          546,
          2368,
          493,
          456,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7581.48,
        "id": 2225,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7580.48,
        "temperature": 0,
        "text": " You can't see it.",
        "tokens": [
          51464,
          509,
          393,
          380,
          536,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7582.48,
        "id": 2226,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7581.48,
        "temperature": 0,
        "text": " So let me just write that again.",
        "tokens": [
          51514,
          407,
          718,
          385,
          445,
          2464,
          300,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1653298814167348,
        "compression_ratio": 1.5569620253164558,
        "end": 7585.48,
        "id": 2227,
        "no_speech_prob": 0.2043229043483734,
        "seek": 755848,
        "start": 7582.48,
        "temperature": 0,
        "text": " tf.one hot is the name of the function.",
        "tokens": [
          51564,
          256,
          69,
          13,
          546,
          2368,
          307,
          264,
          1315,
          295,
          264,
          2445,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7589.48,
        "id": 2228,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7585.48,
        "temperature": 0,
        "text": " Let's go to the TensorFlow.js documentation page.",
        "tokens": [
          50364,
          961,
          311,
          352,
          281,
          264,
          37624,
          13,
          25530,
          14333,
          3028,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7591.48,
        "id": 2229,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7589.48,
        "temperature": 0,
        "text": " Right over here.",
        "tokens": [
          50564,
          1779,
          670,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7593.48,
        "id": 2230,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7591.48,
        "temperature": 0,
        "text": " And look, I already have it open to one hot.",
        "tokens": [
          50664,
          400,
          574,
          11,
          286,
          1217,
          362,
          309,
          1269,
          281,
          472,
          2368,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7594.48,
        "id": 2231,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7593.48,
        "temperature": 0,
        "text": " How convenient.",
        "tokens": [
          50764,
          1012,
          10851,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7596.48,
        "id": 2232,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7594.48,
        "temperature": 0,
        "text": " And basically, this documentation...",
        "tokens": [
          50814,
          400,
          1936,
          11,
          341,
          14333,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7598.48,
        "id": 2233,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7596.48,
        "temperature": 0,
        "text": " Let's see if we can understand this.",
        "tokens": [
          50914,
          961,
          311,
          536,
          498,
          321,
          393,
          1223,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7600.48,
        "id": 2234,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7598.48,
        "temperature": 0,
        "text": " I need to give it all the indices.",
        "tokens": [
          51014,
          286,
          643,
          281,
          976,
          309,
          439,
          264,
          43840,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7602.48,
        "id": 2235,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7600.48,
        "temperature": 0,
        "text": " That's what I already have.",
        "tokens": [
          51114,
          663,
          311,
          437,
          286,
          1217,
          362,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7603.48,
        "id": 2236,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7602.48,
        "temperature": 0,
        "text": " Oh, but you know what?",
        "tokens": [
          51214,
          876,
          11,
          457,
          291,
          458,
          437,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7606.48,
        "id": 2237,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7603.48,
        "temperature": 0,
        "text": " These have to be a tensor already.",
        "tokens": [
          51264,
          1981,
          362,
          281,
          312,
          257,
          40863,
          1217,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7609.48,
        "id": 2238,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7606.48,
        "temperature": 0,
        "text": " So first I need to make a tensor of all those indices.",
        "tokens": [
          51414,
          407,
          700,
          286,
          643,
          281,
          652,
          257,
          40863,
          295,
          439,
          729,
          43840,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17058542569478352,
        "compression_ratio": 1.6752136752136753,
        "end": 7611.48,
        "id": 2239,
        "no_speech_prob": 0.04271987825632095,
        "seek": 758548,
        "start": 7609.48,
        "temperature": 0,
        "text": " Let's do that.",
        "tokens": [
          51564,
          961,
          311,
          360,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24179214028751148,
        "compression_ratio": 1.5844155844155845,
        "end": 7618.48,
        "id": 2240,
        "no_speech_prob": 0.017711563035845757,
        "seek": 761148,
        "start": 7612.48,
        "temperature": 0,
        "text": " So I want to say let label tensor...",
        "tokens": [
          50414,
          407,
          286,
          528,
          281,
          584,
          718,
          7645,
          40863,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.24179214028751148,
        "compression_ratio": 1.5844155844155845,
        "end": 7621.48,
        "id": 2241,
        "no_speech_prob": 0.017711563035845757,
        "seek": 761148,
        "start": 7618.48,
        "temperature": 0,
        "text": " Labels tensor, let's call it.",
        "tokens": [
          50714,
          10137,
          1625,
          40863,
          11,
          718,
          311,
          818,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24179214028751148,
        "compression_ratio": 1.5844155844155845,
        "end": 7626.48,
        "id": 2242,
        "no_speech_prob": 0.017711563035845757,
        "seek": 761148,
        "start": 7621.48,
        "temperature": 0,
        "text": " Equal tf.tensor1d labels.",
        "tokens": [
          50864,
          15624,
          304,
          256,
          69,
          13,
          83,
          23153,
          16,
          67,
          16949,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24179214028751148,
        "compression_ratio": 1.5844155844155845,
        "end": 7628.48,
        "id": 2243,
        "no_speech_prob": 0.017711563035845757,
        "seek": 761148,
        "start": 7626.48,
        "temperature": 0,
        "text": " And let's just look at that.",
        "tokens": [
          51114,
          400,
          718,
          311,
          445,
          574,
          412,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24179214028751148,
        "compression_ratio": 1.5844155844155845,
        "end": 7633.48,
        "id": 2244,
        "no_speech_prob": 0.017711563035845757,
        "seek": 761148,
        "start": 7628.48,
        "temperature": 0,
        "text": " Labels tensor dot print.",
        "tokens": [
          51214,
          10137,
          1625,
          40863,
          5893,
          4482,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24179214028751148,
        "compression_ratio": 1.5844155844155845,
        "end": 7635.48,
        "id": 2245,
        "no_speech_prob": 0.017711563035845757,
        "seek": 761148,
        "start": 7633.48,
        "temperature": 0,
        "text": " Let's just make sure that's kind of...",
        "tokens": [
          51464,
          961,
          311,
          445,
          652,
          988,
          300,
          311,
          733,
          295,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.24179214028751148,
        "compression_ratio": 1.5844155844155845,
        "end": 7639.48,
        "id": 2246,
        "no_speech_prob": 0.017711563035845757,
        "seek": 761148,
        "start": 7635.48,
        "temperature": 0,
        "text": " We can see that's a big, long tensor of all of the labels.",
        "tokens": [
          51564,
          492,
          393,
          536,
          300,
          311,
          257,
          955,
          11,
          938,
          40863,
          295,
          439,
          295,
          264,
          16949,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7644.48,
        "id": 2247,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7639.48,
        "temperature": 0,
        "text": " And then, now the wise is tf.one hot.",
        "tokens": [
          50364,
          400,
          550,
          11,
          586,
          264,
          10829,
          307,
          256,
          69,
          13,
          546,
          2368,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7647.48,
        "id": 2248,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7644.48,
        "temperature": 0,
        "text": " So if I go back and look at this,",
        "tokens": [
          50614,
          407,
          498,
          286,
          352,
          646,
          293,
          574,
          412,
          341,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7651.48,
        "id": 2249,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7647.48,
        "temperature": 0,
        "text": " one hot needs the list of all of those index values,",
        "tokens": [
          50764,
          472,
          2368,
          2203,
          264,
          1329,
          295,
          439,
          295,
          729,
          8186,
          4190,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7654.48,
        "id": 2250,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7651.48,
        "temperature": 0,
        "text": " which are 0 through 8, and the depth.",
        "tokens": [
          50964,
          597,
          366,
          1958,
          807,
          1649,
          11,
          293,
          264,
          7161,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7657.48,
        "id": 2251,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7654.48,
        "temperature": 0,
        "text": " The depth means how many possibilities are there,",
        "tokens": [
          51114,
          440,
          7161,
          1355,
          577,
          867,
          12178,
          366,
          456,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7659.48,
        "id": 2252,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7657.48,
        "temperature": 0,
        "text": " and there are nine possibilities.",
        "tokens": [
          51264,
          293,
          456,
          366,
          4949,
          12178,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7661.48,
        "id": 2253,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7659.48,
        "temperature": 0,
        "text": " And on value will default to 1,",
        "tokens": [
          51364,
          400,
          322,
          2158,
          486,
          7576,
          281,
          502,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7663.48,
        "id": 2254,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7661.48,
        "temperature": 0,
        "text": " and the off value defaults to 0.",
        "tokens": [
          51464,
          293,
          264,
          766,
          2158,
          7576,
          82,
          281,
          1958,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7666.48,
        "id": 2255,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7663.48,
        "temperature": 0,
        "text": " But if for some reason I wanted to one hot encode with 3,",
        "tokens": [
          51564,
          583,
          498,
          337,
          512,
          1778,
          286,
          1415,
          281,
          472,
          2368,
          2058,
          1429,
          365,
          805,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.208490229835195,
        "compression_ratio": 1.6514522821576763,
        "end": 7668.48,
        "id": 2256,
        "no_speech_prob": 0.013427983038127422,
        "seek": 763948,
        "start": 7666.48,
        "temperature": 0,
        "text": " the number 3 for every spot,",
        "tokens": [
          51714,
          264,
          1230,
          805,
          337,
          633,
          4008,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7671.48,
        "id": 2257,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7668.48,
        "temperature": 0,
        "text": " or the number 0.1 for every non-spot,",
        "tokens": [
          50364,
          420,
          264,
          1230,
          1958,
          13,
          16,
          337,
          633,
          2107,
          12,
          4952,
          310,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7673.48,
        "id": 2258,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7671.48,
        "temperature": 0,
        "text": " I could change those values.",
        "tokens": [
          50514,
          286,
          727,
          1319,
          729,
          4190,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7682.48,
        "id": 2259,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7673.48,
        "temperature": 0,
        "text": " But all I need to do then is say one hot labels tensor and 9.",
        "tokens": [
          50614,
          583,
          439,
          286,
          643,
          281,
          360,
          550,
          307,
          584,
          472,
          2368,
          16949,
          40863,
          293,
          1722,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7686.48,
        "id": 2260,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7682.48,
        "temperature": 0,
        "text": " And then I could say wise dot print.",
        "tokens": [
          51064,
          400,
          550,
          286,
          727,
          584,
          10829,
          5893,
          4482,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7689.48,
        "id": 2261,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7686.48,
        "temperature": 0,
        "text": " So x's dot print and y's dot print.",
        "tokens": [
          51264,
          407,
          2031,
          311,
          5893,
          4482,
          293,
          288,
          311,
          5893,
          4482,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7692.48,
        "id": 2262,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7689.48,
        "temperature": 0,
        "text": " So now I have my x's and y's.",
        "tokens": [
          51414,
          407,
          586,
          286,
          362,
          452,
          2031,
          311,
          293,
          288,
          311,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7694.48,
        "id": 2263,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7692.48,
        "temperature": 0,
        "text": " Remember, the previous video I did this,",
        "tokens": [
          51564,
          5459,
          11,
          264,
          3894,
          960,
          286,
          630,
          341,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.22581574468329402,
        "compression_ratio": 1.5431472081218274,
        "end": 7696.48,
        "id": 2264,
        "no_speech_prob": 0.0022872183471918106,
        "seek": 766848,
        "start": 7694.48,
        "temperature": 0,
        "text": " I looked at all the RGB values,",
        "tokens": [
          51664,
          286,
          2956,
          412,
          439,
          264,
          31231,
          4190,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7698.48,
        "id": 2265,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7696.48,
        "temperature": 0,
        "text": " and I got 255.",
        "tokens": [
          50364,
          293,
          286,
          658,
          3552,
          20,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7705.48,
        "id": 2266,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7698.48,
        "temperature": 0,
        "text": " And then I, sorry, I lost my train choo-choo thought here.",
        "tokens": [
          50464,
          400,
          550,
          286,
          11,
          2597,
          11,
          286,
          2731,
          452,
          3847,
          1586,
          78,
          12,
          339,
          1986,
          1194,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7707.48,
        "id": 2267,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7705.48,
        "temperature": 0,
        "text": " And then I made those into a 2D tensor.",
        "tokens": [
          50814,
          400,
          550,
          286,
          1027,
          729,
          666,
          257,
          568,
          35,
          40863,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7709.48,
        "id": 2268,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7707.48,
        "temperature": 0,
        "text": " And now I've made the wise.",
        "tokens": [
          50914,
          400,
          586,
          286,
          600,
          1027,
          264,
          10829,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7712.48,
        "id": 2269,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7709.48,
        "temperature": 0,
        "text": " And what I do want to see is console log,",
        "tokens": [
          51014,
          400,
          437,
          286,
          360,
          528,
          281,
          536,
          307,
          11076,
          3565,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7715.48,
        "id": 2270,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7712.48,
        "temperature": 0,
        "text": " let's look at x's dot shape,",
        "tokens": [
          51164,
          718,
          311,
          574,
          412,
          2031,
          311,
          5893,
          3909,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7719.48,
        "id": 2271,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7715.48,
        "temperature": 0,
        "text": " and console dot log y's dot shape also.",
        "tokens": [
          51314,
          293,
          11076,
          5893,
          3565,
          288,
          311,
          5893,
          3909,
          611,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7720.48,
        "id": 2272,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7719.48,
        "temperature": 0,
        "text": " OK, ready?",
        "tokens": [
          51514,
          2264,
          11,
          1919,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.2730082574291764,
        "compression_ratio": 1.5685279187817258,
        "end": 7723.48,
        "id": 2273,
        "no_speech_prob": 0.07920647412538528,
        "seek": 769648,
        "start": 7720.48,
        "temperature": 0,
        "text": " Let's look and see if everything seems right.",
        "tokens": [
          51564,
          961,
          311,
          574,
          293,
          536,
          498,
          1203,
          2544,
          558,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7728.48,
        "id": 2274,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7723.48,
        "temperature": 0,
        "text": " Ah, indices must be of data type int32.",
        "tokens": [
          50364,
          2438,
          11,
          43840,
          1633,
          312,
          295,
          1412,
          2010,
          560,
          11440,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7730.48,
        "id": 2275,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7728.48,
        "temperature": 0,
        "text": " Oh, interesting.",
        "tokens": [
          50614,
          876,
          11,
          1880,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7735.48,
        "id": 2276,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7730.48,
        "temperature": 0,
        "text": " So when I made this tensor, my labels, if we look at them,",
        "tokens": [
          50714,
          407,
          562,
          286,
          1027,
          341,
          40863,
          11,
          452,
          16949,
          11,
          498,
          321,
          574,
          412,
          552,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7741.48,
        "id": 2277,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7735.48,
        "temperature": 0,
        "text": " are actually, like if I go back and console log the labels,",
        "tokens": [
          50964,
          366,
          767,
          11,
          411,
          498,
          286,
          352,
          646,
          293,
          11076,
          3565,
          264,
          16949,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7743.48,
        "id": 2278,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7741.48,
        "temperature": 0,
        "text": " those are floating point numbers,",
        "tokens": [
          51264,
          729,
          366,
          12607,
          935,
          3547,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7745.48,
        "id": 2279,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7743.48,
        "temperature": 0,
        "text": " because I wasn't really worrying about it",
        "tokens": [
          51364,
          570,
          286,
          2067,
          380,
          534,
          18788,
          466,
          309,
          51464
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7747.48,
        "id": 2280,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7745.48,
        "temperature": 0,
        "text": " when I was just working with regular JavaScript arrays.",
        "tokens": [
          51464,
          562,
          286,
          390,
          445,
          1364,
          365,
          3890,
          15778,
          41011,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18401089718467312,
        "compression_ratio": 1.5108225108225108,
        "end": 7750.48,
        "id": 2281,
        "no_speech_prob": 0.0002531559148337692,
        "seek": 772348,
        "start": 7747.48,
        "temperature": 0,
        "text": " But I need to very specifically make sure",
        "tokens": [
          51564,
          583,
          286,
          643,
          281,
          588,
          4682,
          652,
          988,
          51714
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7753.48,
        "id": 2282,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7750.48,
        "temperature": 0,
        "text": " that I set the data type index values for a one-hot vector,",
        "tokens": [
          50364,
          300,
          286,
          992,
          264,
          1412,
          2010,
          8186,
          4190,
          337,
          257,
          472,
          12,
          12194,
          8062,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7755.48,
        "id": 2283,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7753.48,
        "temperature": 0,
        "text": " cannot be floating point values.",
        "tokens": [
          50514,
          2644,
          312,
          12607,
          935,
          4190,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7760.48,
        "id": 2284,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7755.48,
        "temperature": 0,
        "text": " So I think if I do this, we can see that fixed it, right?",
        "tokens": [
          50614,
          407,
          286,
          519,
          498,
          286,
          360,
          341,
          11,
          321,
          393,
          536,
          300,
          6806,
          309,
          11,
          558,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7762.48,
        "id": 2285,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7760.48,
        "temperature": 0,
        "text": " So now I have the shape, right?",
        "tokens": [
          50864,
          407,
          586,
          286,
          362,
          264,
          3909,
          11,
          558,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7763.48,
        "id": 2286,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7762.48,
        "temperature": 0,
        "text": " This makes sense.",
        "tokens": [
          50964,
          639,
          1669,
          2020,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7766.48,
        "id": 2287,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7763.48,
        "temperature": 0,
        "text": " There's 5,643 data points.",
        "tokens": [
          51014,
          821,
          311,
          1025,
          11,
          21,
          17201,
          1412,
          2793,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7770.48,
        "id": 2288,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7766.48,
        "temperature": 0,
        "text": " Each data point for the inputs for the x's has an RGB,",
        "tokens": [
          51164,
          6947,
          1412,
          935,
          337,
          264,
          15743,
          337,
          264,
          2031,
          311,
          575,
          364,
          31231,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7773.48,
        "id": 2289,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7770.48,
        "temperature": 0,
        "text": " that's three, and there are nine possible labels.",
        "tokens": [
          51364,
          300,
          311,
          1045,
          11,
          293,
          456,
          366,
          4949,
          1944,
          16949,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1574060616373014,
        "compression_ratio": 1.646551724137931,
        "end": 7777.48,
        "id": 2290,
        "no_speech_prob": 0.07807368785142899,
        "seek": 775048,
        "start": 7773.48,
        "temperature": 0,
        "text": " So I have the shape is 5,643, nine possibilities,",
        "tokens": [
          51514,
          407,
          286,
          362,
          264,
          3909,
          307,
          1025,
          11,
          21,
          17201,
          11,
          4949,
          12178,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7780.48,
        "id": 2291,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7777.48,
        "temperature": 0,
        "text": " and each one of those just is one-hot encoded.",
        "tokens": [
          50364,
          293,
          1184,
          472,
          295,
          729,
          445,
          307,
          472,
          12,
          12194,
          2058,
          12340,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7783.48,
        "id": 2292,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7780.48,
        "temperature": 0,
        "text": " So this means bluish, and this means purplish,",
        "tokens": [
          50514,
          407,
          341,
          1355,
          888,
          33786,
          11,
          293,
          341,
          1355,
          1864,
          564,
          742,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7785.48,
        "id": 2293,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7783.48,
        "temperature": 0,
        "text": " or whatever the mapping is, I don't remember.",
        "tokens": [
          50664,
          420,
          2035,
          264,
          18350,
          307,
          11,
          286,
          500,
          380,
          1604,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7792.48,
        "id": 2294,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7785.48,
        "temperature": 0,
        "text": " The second one is greenish, and 0, 1, 2, 3, 4, 5.",
        "tokens": [
          50764,
          440,
          1150,
          472,
          307,
          3092,
          742,
          11,
          293,
          1958,
          11,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7796.48,
        "id": 2295,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7792.48,
        "temperature": 0,
        "text": " The sixth one is 0, 1, 2, 3, 4, 5 is pinkish.",
        "tokens": [
          51114,
          440,
          15102,
          472,
          307,
          1958,
          11,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          307,
          7022,
          742,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7797.48,
        "id": 2296,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7796.48,
        "temperature": 0,
        "text": " That's the sixth one.",
        "tokens": [
          51314,
          663,
          311,
          264,
          15102,
          472,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7798.48,
        "id": 2297,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7797.48,
        "temperature": 0,
        "text": " Yes, whatever.",
        "tokens": [
          51364,
          1079,
          11,
          2035,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7800.48,
        "id": 2298,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7798.48,
        "temperature": 0,
        "text": " So this is going to be really important.",
        "tokens": [
          51414,
          407,
          341,
          307,
          516,
          281,
          312,
          534,
          1021,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7803.48,
        "id": 2299,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7800.48,
        "temperature": 0,
        "text": " Which labels actually go with index values",
        "tokens": [
          51514,
          3013,
          16949,
          767,
          352,
          365,
          8186,
          4190,
          51664
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7805.48,
        "id": 2300,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7803.48,
        "temperature": 0,
        "text": " is something that I'm going to have to save",
        "tokens": [
          51664,
          307,
          746,
          300,
          286,
          478,
          516,
          281,
          362,
          281,
          3155,
          51764
        ]
      },
      {
        "avg_logprob": -0.13620791401896443,
        "compression_ratio": 1.6953125,
        "end": 7806.48,
        "id": 2301,
        "no_speech_prob": 0.07807362079620361,
        "seek": 777748,
        "start": 7805.48,
        "temperature": 0,
        "text": " for the duration of this project,",
        "tokens": [
          51764,
          337,
          264,
          16365,
          295,
          341,
          1716,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7809.48,
        "id": 2302,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7806.48,
        "temperature": 0,
        "text": " because when I show the results to the user,",
        "tokens": [
          50364,
          570,
          562,
          286,
          855,
          264,
          3542,
          281,
          264,
          4195,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7812.48,
        "id": 2303,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7809.48,
        "temperature": 0,
        "text": " I want to actually show the strings, not the number value.",
        "tokens": [
          50514,
          286,
          528,
          281,
          767,
          855,
          264,
          13985,
          11,
          406,
          264,
          1230,
          2158,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7814.48,
        "id": 2304,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7812.48,
        "temperature": 0,
        "text": " Okay, so I am now ready to try to fit,",
        "tokens": [
          50664,
          1033,
          11,
          370,
          286,
          669,
          586,
          1919,
          281,
          853,
          281,
          3318,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7815.48,
        "id": 2305,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7814.48,
        "temperature": 0,
        "text": " so what's next?",
        "tokens": [
          50764,
          370,
          437,
          311,
          958,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7818.48,
        "id": 2306,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7815.48,
        "temperature": 0,
        "text": " I need to architect the model, right?",
        "tokens": [
          50814,
          286,
          643,
          281,
          6331,
          264,
          2316,
          11,
          558,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7821.48,
        "id": 2307,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7818.48,
        "temperature": 0,
        "text": " I got all of the input data, and I got all of the output data.",
        "tokens": [
          50964,
          286,
          658,
          439,
          295,
          264,
          4846,
          1412,
          11,
          293,
          286,
          658,
          439,
          295,
          264,
          5598,
          1412,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7824.48,
        "id": 2308,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7821.48,
        "temperature": 0,
        "text": " I need to divide into trading and testing,",
        "tokens": [
          51114,
          286,
          643,
          281,
          9845,
          666,
          9529,
          293,
          4997,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7826.48,
        "id": 2309,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7824.48,
        "temperature": 0,
        "text": " architect the model, fit the model,",
        "tokens": [
          51264,
          6331,
          264,
          2316,
          11,
          3318,
          264,
          2316,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7829.48,
        "id": 2310,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7826.48,
        "temperature": 0,
        "text": " and then I'm sort of done, maybe.",
        "tokens": [
          51364,
          293,
          550,
          286,
          478,
          1333,
          295,
          1096,
          11,
          1310,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7832.48,
        "id": 2311,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7829.48,
        "temperature": 0,
        "text": " So that's going to be like many more videos into the future.",
        "tokens": [
          51514,
          407,
          300,
          311,
          516,
          281,
          312,
          411,
          867,
          544,
          2145,
          666,
          264,
          2027,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17547408794534616,
        "compression_ratio": 1.8544776119402986,
        "end": 7834.48,
        "id": 2312,
        "no_speech_prob": 0.0004728531639557332,
        "seek": 780648,
        "start": 7832.48,
        "temperature": 0,
        "text": " So I got at least three or four little more steps to build here",
        "tokens": [
          51664,
          407,
          286,
          658,
          412,
          1935,
          1045,
          420,
          1451,
          707,
          544,
          4439,
          281,
          1322,
          510,
          51764
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7838.48,
        "id": 2313,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7834.48,
        "temperature": 0,
        "text": " until I have this final version of this color classifier,",
        "tokens": [
          50364,
          1826,
          286,
          362,
          341,
          2572,
          3037,
          295,
          341,
          2017,
          1508,
          9902,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7840.48,
        "id": 2314,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7838.48,
        "temperature": 0,
        "text": " built with TensorFlow.js.",
        "tokens": [
          50564,
          3094,
          365,
          37624,
          13,
          25530,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7847.48,
        "id": 2315,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7844.48,
        "temperature": 0,
        "text": " Oh, dispose!",
        "tokens": [
          50864,
          876,
          11,
          42537,
          0,
          51014
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7850.48,
        "id": 2316,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7848.48,
        "temperature": 0,
        "text": " Wait, wait!",
        "tokens": [
          51064,
          3802,
          11,
          1699,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7853.48,
        "id": 2317,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7850.48,
        "temperature": 0,
        "text": " Don't leave just yet.",
        "tokens": [
          51164,
          1468,
          380,
          1856,
          445,
          1939,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7856.48,
        "id": 2318,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7853.48,
        "temperature": 0,
        "text": " I do want to think about memory management,",
        "tokens": [
          51314,
          286,
          360,
          528,
          281,
          519,
          466,
          4675,
          4592,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7859.48,
        "id": 2319,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7856.48,
        "temperature": 0,
        "text": " and maybe I'm going to think about memory management later,",
        "tokens": [
          51464,
          293,
          1310,
          286,
          478,
          516,
          281,
          519,
          466,
          4675,
          4592,
          1780,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.22489329444037542,
        "compression_ratio": 1.5578947368421052,
        "end": 7863.48,
        "id": 2320,
        "no_speech_prob": 0.002757582115009427,
        "seek": 783448,
        "start": 7859.48,
        "temperature": 0,
        "text": " and the Xs and Ys I'm going to want to use in the next video,",
        "tokens": [
          51614,
          293,
          264,
          1783,
          82,
          293,
          398,
          82,
          286,
          478,
          516,
          281,
          528,
          281,
          764,
          294,
          264,
          958,
          960,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7867.48,
        "id": 2321,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7863.48,
        "temperature": 0,
        "text": " but I probably should after I make the one hot vector.",
        "tokens": [
          50364,
          457,
          286,
          1391,
          820,
          934,
          286,
          652,
          264,
          472,
          2368,
          8062,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7868.48,
        "id": 2322,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7867.48,
        "temperature": 0,
        "text": " I don't need...",
        "tokens": [
          50564,
          286,
          500,
          380,
          643,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7871.48,
        "id": 2323,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7868.48,
        "temperature": 0,
        "text": " When I'm working with lower-level TensorFlow.js,",
        "tokens": [
          50614,
          1133,
          286,
          478,
          1364,
          365,
          3126,
          12,
          12418,
          37624,
          13,
          25530,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7873.48,
        "id": 2324,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7871.48,
        "temperature": 0,
        "text": " I've got to clean up stuff I'm not going to use anymore,",
        "tokens": [
          50764,
          286,
          600,
          658,
          281,
          2541,
          493,
          1507,
          286,
          478,
          406,
          516,
          281,
          764,
          3602,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7875.48,
        "id": 2325,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7873.48,
        "temperature": 0,
        "text": " and I don't need these labels anymore,",
        "tokens": [
          50864,
          293,
          286,
          500,
          380,
          643,
          613,
          16949,
          3602,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7877.48,
        "id": 2326,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7875.48,
        "temperature": 0,
        "text": " so I can dispose that one.",
        "tokens": [
          50964,
          370,
          286,
          393,
          42537,
          300,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7879.48,
        "id": 2327,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7877.48,
        "temperature": 0,
        "text": " So that was just the last little tidbit here,",
        "tokens": [
          51064,
          407,
          300,
          390,
          445,
          264,
          1036,
          707,
          9422,
          5260,
          510,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7880.48,
        "id": 2328,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7879.48,
        "temperature": 0,
        "text": " and then I'll move on.",
        "tokens": [
          51164,
          293,
          550,
          286,
          603,
          1286,
          322,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7882.48,
        "id": 2329,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7880.48,
        "temperature": 0,
        "text": " In the next video, I'm going to start creating",
        "tokens": [
          51214,
          682,
          264,
          958,
          960,
          11,
          286,
          478,
          516,
          281,
          722,
          4084,
          51314
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7884.48,
        "id": 2330,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7882.48,
        "temperature": 0,
        "text": " the architecture of the neural network model itself,",
        "tokens": [
          51314,
          264,
          9482,
          295,
          264,
          18161,
          3209,
          2316,
          2564,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7886.48,
        "id": 2331,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7884.48,
        "temperature": 0,
        "text": " and, oh, I'm going to introduce some new concepts,",
        "tokens": [
          51414,
          293,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          5366,
          512,
          777,
          10392,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7889.48,
        "id": 2332,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7886.48,
        "temperature": 0,
        "text": " softmax and cross-entropy.",
        "tokens": [
          51514,
          2787,
          41167,
          293,
          3278,
          12,
          317,
          27514,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1837306022644043,
        "compression_ratio": 1.683168316831683,
        "end": 7890.48,
        "id": 2333,
        "no_speech_prob": 0.0012448267079889774,
        "seek": 786348,
        "start": 7889.48,
        "temperature": 0,
        "text": " Isn't that exciting?",
        "tokens": [
          51664,
          6998,
          380,
          300,
          4670,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7893.48,
        "id": 2334,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7891.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7897.48,
        "id": 2335,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7895.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50614,
          1057,
          558,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7899.48,
        "id": 2336,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7897.48,
        "temperature": 0,
        "text": " Oh, my boy! Okay.",
        "tokens": [
          50714,
          876,
          11,
          452,
          3237,
          0,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7901.48,
        "id": 2337,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7899.48,
        "temperature": 0,
        "text": " All right, everyone, it's 2 o'clock.",
        "tokens": [
          50814,
          1057,
          558,
          11,
          1518,
          11,
          309,
          311,
          568,
          277,
          6,
          9023,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7903.48,
        "id": 2338,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7901.48,
        "temperature": 0,
        "text": " I didn't get through this whole thing.",
        "tokens": [
          50914,
          286,
          994,
          380,
          483,
          807,
          341,
          1379,
          551,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7905.48,
        "id": 2339,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7903.48,
        "temperature": 0,
        "text": " I have to stop.",
        "tokens": [
          51014,
          286,
          362,
          281,
          1590,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7907.48,
        "id": 2340,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7905.48,
        "temperature": 0,
        "text": " So the rest...",
        "tokens": [
          51114,
          407,
          264,
          1472,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7909.48,
        "id": 2341,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7907.48,
        "temperature": 0,
        "text": " I think I'm going to be back on Monday.",
        "tokens": [
          51214,
          286,
          519,
          286,
          478,
          516,
          281,
          312,
          646,
          322,
          8138,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7912.48,
        "id": 2342,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7909.48,
        "temperature": 0,
        "text": " I'm going to see if I can finish this on Monday.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          536,
          498,
          286,
          393,
          2413,
          341,
          322,
          8138,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7914.48,
        "id": 2343,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7912.48,
        "temperature": 0,
        "text": " But stay tuned.",
        "tokens": [
          51464,
          583,
          1754,
          10870,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18181082781623392,
        "compression_ratio": 1.5747126436781609,
        "end": 7918.48,
        "id": 2344,
        "no_speech_prob": 0.002844668459147215,
        "seek": 789048,
        "start": 7916.48,
        "temperature": 0,
        "text": " And I'll be back on Monday.",
        "tokens": [
          51664,
          400,
          286,
          603,
          312,
          646,
          322,
          8138,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.199802213244968,
        "compression_ratio": 0.8490566037735849,
        "end": 7920.48,
        "id": 2345,
        "no_speech_prob": 0.006272026337683201,
        "seek": 791848,
        "start": 7918.48,
        "temperature": 0,
        "text": " I don't know what else to say.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          437,
          1646,
          281,
          584,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.199802213244968,
        "compression_ratio": 0.8490566037735849,
        "end": 7931.48,
        "id": 2346,
        "no_speech_prob": 0.006272026337683201,
        "seek": 791848,
        "start": 7929.48,
        "temperature": 0,
        "text": " Any questions?",
        "tokens": [
          50914,
          2639,
          1651,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.5846040950101965,
        "compression_ratio": 0.7777777777777778,
        "end": 7933.48,
        "id": 2347,
        "no_speech_prob": 0.04581897705793381,
        "seek": 793148,
        "start": 7931.48,
        "temperature": 0,
        "text": " 🎵",
        "tokens": [
          50364,
          220,
          172,
          253,
          236,
          113,
          50464
        ]
      },
      {
        "avg_logprob": -0.5846040950101965,
        "compression_ratio": 0.7777777777777778,
        "end": 7953.48,
        "id": 2348,
        "no_speech_prob": 0.04581897705793381,
        "seek": 793148,
        "start": 7951.48,
        "temperature": 0,
        "text": " I'm really out of tune.",
        "tokens": [
          51364,
          286,
          478,
          534,
          484,
          295,
          10864,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24367376474233773,
        "compression_ratio": 0.8095238095238095,
        "end": 7963.48,
        "id": 2349,
        "no_speech_prob": 0.008053499273955822,
        "seek": 796148,
        "start": 7961.48,
        "temperature": 0,
        "text": " 🎵",
        "tokens": [
          50364,
          25674,
          50464
        ]
      },
      {
        "avg_logprob": -0.24367376474233773,
        "compression_ratio": 0.8095238095238095,
        "end": 7989.48,
        "id": 2350,
        "no_speech_prob": 0.008053499273955822,
        "seek": 796148,
        "start": 7987.48,
        "temperature": 0,
        "text": " Can you make music tutorials?",
        "tokens": [
          51664,
          1664,
          291,
          652,
          1318,
          17616,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 7991.48,
        "id": 2351,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 7989.48,
        "temperature": 0,
        "text": " No, definitely not.",
        "tokens": [
          50364,
          883,
          11,
          2138,
          406,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 7995.48,
        "id": 2352,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 7993.48,
        "temperature": 0,
        "text": " Oh, Alka!",
        "tokens": [
          50564,
          876,
          11,
          967,
          2330,
          0,
          50664
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8000.48,
        "id": 2353,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 7996.48,
        "temperature": 0,
        "text": " Did Alka just maybe just woke up and is now watching?",
        "tokens": [
          50714,
          2589,
          967,
          2330,
          445,
          1310,
          445,
          12852,
          493,
          293,
          307,
          586,
          1976,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8002.48,
        "id": 2354,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 8000.48,
        "temperature": 0,
        "text": " It says, Alka is typing.",
        "tokens": [
          50914,
          467,
          1619,
          11,
          967,
          2330,
          307,
          18444,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8004.48,
        "id": 2355,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 8002.48,
        "temperature": 0,
        "text": " All right, so let me just mention a couple things.",
        "tokens": [
          51014,
          1057,
          558,
          11,
          370,
          718,
          385,
          445,
          2152,
          257,
          1916,
          721,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8006.48,
        "id": 2356,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 8004.48,
        "temperature": 0,
        "text": " I hope to be back on Monday.",
        "tokens": [
          51114,
          286,
          1454,
          281,
          312,
          646,
          322,
          8138,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8009.48,
        "id": 2357,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 8006.48,
        "temperature": 0,
        "text": " I will not be here definitely any day next week,",
        "tokens": [
          51214,
          286,
          486,
          406,
          312,
          510,
          2138,
          604,
          786,
          958,
          1243,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8011.48,
        "id": 2358,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 8009.48,
        "temperature": 0,
        "text": " Tuesdays through Friday, because I am traveling.",
        "tokens": [
          51364,
          10017,
          82,
          807,
          6984,
          11,
          570,
          286,
          669,
          9712,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8013.48,
        "id": 2359,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 8011.48,
        "temperature": 0,
        "text": " Unless I do some kind of crazy livestream",
        "tokens": [
          51464,
          16581,
          286,
          360,
          512,
          733,
          295,
          3219,
          29782,
          51564
        ]
      },
      {
        "avg_logprob": -0.22320613682827103,
        "compression_ratio": 1.5,
        "end": 8015.48,
        "id": 2360,
        "no_speech_prob": 0.006096952129155397,
        "seek": 798948,
        "start": 8013.48,
        "temperature": 0,
        "text": " from my television phone.",
        "tokens": [
          51564,
          490,
          452,
          8815,
          2593,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8018.48,
        "id": 2361,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8016.48,
        "temperature": 0,
        "text": " But I will be traveling the rest of next week.",
        "tokens": [
          50414,
          583,
          286,
          486,
          312,
          9712,
          264,
          1472,
          295,
          958,
          1243,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8020.48,
        "id": 2362,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8018.48,
        "temperature": 0,
        "text": " I'm also moving to a new apartment.",
        "tokens": [
          50514,
          286,
          478,
          611,
          2684,
          281,
          257,
          777,
          9587,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8022.48,
        "id": 2363,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8020.48,
        "temperature": 0,
        "text": " So I've got a lot of stuff to deal with.",
        "tokens": [
          50614,
          407,
          286,
          600,
          658,
          257,
          688,
          295,
          1507,
          281,
          2028,
          365,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8028.48,
        "id": 2364,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8025.48,
        "temperature": 0,
        "text": " Oh, could you go on green screen and come in saying,",
        "tokens": [
          50864,
          876,
          11,
          727,
          291,
          352,
          322,
          3092,
          2568,
          293,
          808,
          294,
          1566,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8030.48,
        "id": 2365,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8028.48,
        "temperature": 0,
        "text": " wait, wait, wait, I have an idea.",
        "tokens": [
          51014,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          286,
          362,
          364,
          1558,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8032.48,
        "id": 2366,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8030.48,
        "temperature": 0,
        "text": " Yes, I can.",
        "tokens": [
          51114,
          1079,
          11,
          286,
          393,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8035.48,
        "id": 2367,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8032.48,
        "temperature": 0,
        "text": " Should I be singing, playing the ukulele?",
        "tokens": [
          51214,
          6454,
          286,
          312,
          6726,
          11,
          2433,
          264,
          26769,
          2271,
          306,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8037.48,
        "id": 2368,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8035.48,
        "temperature": 0,
        "text": " Or no ukulele.",
        "tokens": [
          51364,
          1610,
          572,
          26769,
          2271,
          306,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8042.48,
        "id": 2369,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8039.48,
        "temperature": 0,
        "text": " I will definitely indulge Alka in this.",
        "tokens": [
          51564,
          286,
          486,
          2138,
          28626,
          432,
          967,
          2330,
          294,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2818026860555013,
        "compression_ratio": 1.5565217391304347,
        "end": 8044.48,
        "id": 2370,
        "no_speech_prob": 0.01542023103684187,
        "seek": 801548,
        "start": 8042.48,
        "temperature": 0,
        "text": " Do you really need to be on the phone?",
        "tokens": [
          51714,
          1144,
          291,
          534,
          643,
          281,
          312,
          322,
          264,
          2593,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8046.48,
        "id": 2371,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8044.48,
        "temperature": 0,
        "text": " Do you really know how to play the guitar?",
        "tokens": [
          50364,
          1144,
          291,
          534,
          458,
          577,
          281,
          862,
          264,
          7531,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8049.48,
        "id": 2372,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8046.48,
        "temperature": 0,
        "text": " No, I mean, that's not, that's a ukulele,",
        "tokens": [
          50464,
          883,
          11,
          286,
          914,
          11,
          300,
          311,
          406,
          11,
          300,
          311,
          257,
          26769,
          2271,
          306,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8051.48,
        "id": 2373,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8049.48,
        "temperature": 0,
        "text": " which I bought two weeks ago",
        "tokens": [
          50614,
          597,
          286,
          4243,
          732,
          3259,
          2057,
          50714
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8053.48,
        "id": 2374,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8051.48,
        "temperature": 0,
        "text": " and tried to teach myself some chords.",
        "tokens": [
          50714,
          293,
          3031,
          281,
          2924,
          2059,
          512,
          21733,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8055.48,
        "id": 2375,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8053.48,
        "temperature": 0,
        "text": " So that's about as far as I am.",
        "tokens": [
          50814,
          407,
          300,
          311,
          466,
          382,
          1400,
          382,
          286,
          669,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8059.48,
        "id": 2376,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8056.48,
        "temperature": 0,
        "text": " All right, green only.",
        "tokens": [
          50964,
          1057,
          558,
          11,
          3092,
          787,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8067.48,
        "id": 2377,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8066.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.205616209242079,
        "compression_ratio": 1.4171779141104295,
        "end": 8072.48,
        "id": 2378,
        "no_speech_prob": 0.0008423925610259175,
        "seek": 804448,
        "start": 8070.48,
        "temperature": 0,
        "text": " Wait, wait, wait.",
        "tokens": [
          51664,
          3802,
          11,
          1699,
          11,
          1699,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22705266247056935,
        "compression_ratio": 1.656,
        "end": 8076.48,
        "id": 2379,
        "no_speech_prob": 0.0011314830044284463,
        "seek": 807448,
        "start": 8075.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22705266247056935,
        "compression_ratio": 1.656,
        "end": 8080.48,
        "id": 2380,
        "no_speech_prob": 0.0011314830044284463,
        "seek": 807448,
        "start": 8078.48,
        "temperature": 0,
        "text": " Wait a sec, wait, wait, wait, wait, wait.",
        "tokens": [
          50564,
          3802,
          257,
          907,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22705266247056935,
        "compression_ratio": 1.656,
        "end": 8089.48,
        "id": 2381,
        "no_speech_prob": 0.0011314830044284463,
        "seek": 807448,
        "start": 8086.48,
        "temperature": 0,
        "text": " You guys know I'll always stay for wasting time.",
        "tokens": [
          50964,
          509,
          1074,
          458,
          286,
          603,
          1009,
          1754,
          337,
          20457,
          565,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22705266247056935,
        "compression_ratio": 1.656,
        "end": 8091.48,
        "id": 2382,
        "no_speech_prob": 0.0011314830044284463,
        "seek": 807448,
        "start": 8089.48,
        "temperature": 0,
        "text": " I just can't do any more coding.",
        "tokens": [
          51114,
          286,
          445,
          393,
          380,
          360,
          604,
          544,
          17720,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22705266247056935,
        "compression_ratio": 1.656,
        "end": 8093.48,
        "id": 2383,
        "no_speech_prob": 0.0011314830044284463,
        "seek": 807448,
        "start": 8091.48,
        "temperature": 0,
        "text": " My brain is fried.",
        "tokens": [
          51214,
          1222,
          3567,
          307,
          10425,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22705266247056935,
        "compression_ratio": 1.656,
        "end": 8102.48,
        "id": 2384,
        "no_speech_prob": 0.0011314830044284463,
        "seek": 807448,
        "start": 8097.48,
        "temperature": 0,
        "text": " Wait, wait, wait, wait, wait, wait, wait, wait, wait.",
        "tokens": [
          51514,
          3802,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8106.48,
        "id": 2385,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8104.48,
        "temperature": 0,
        "text": " Wait, please wait for me.",
        "tokens": [
          50364,
          3802,
          11,
          1767,
          1699,
          337,
          385,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8108.48,
        "id": 2386,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8106.48,
        "temperature": 0,
        "text": " Oh, wait for me.",
        "tokens": [
          50464,
          876,
          11,
          1699,
          337,
          385,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8112.48,
        "id": 2387,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8108.48,
        "temperature": 0,
        "text": " Wait, wait, wait, wait, wait, wait, wait, wait, wait, wait.",
        "tokens": [
          50564,
          3802,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8114.48,
        "id": 2388,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8113.48,
        "temperature": 0,
        "text": " That's got to be good enough",
        "tokens": [
          50814,
          663,
          311,
          658,
          281,
          312,
          665,
          1547,
          50864
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8116.48,
        "id": 2389,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8114.48,
        "temperature": 0,
        "text": " for whatever you're cooking up, Alka.",
        "tokens": [
          50864,
          337,
          2035,
          291,
          434,
          6361,
          493,
          11,
          967,
          2330,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8126.48,
        "id": 2390,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8124.48,
        "temperature": 0,
        "text": " Oh, Simon writes, great timing.",
        "tokens": [
          51364,
          876,
          11,
          13193,
          13657,
          11,
          869,
          10822,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8129.48,
        "id": 2391,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8126.48,
        "temperature": 0,
        "text": " I'm entering the tunnel now.",
        "tokens": [
          51464,
          286,
          478,
          11104,
          264,
          13186,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2952341826065727,
        "compression_ratio": 1.6204819277108433,
        "end": 8131.48,
        "id": 2392,
        "no_speech_prob": 0.0002694111899472773,
        "seek": 810448,
        "start": 8129.48,
        "temperature": 0,
        "text": " So we'll probably lose the 40 seconds.",
        "tokens": [
          51614,
          407,
          321,
          603,
          1391,
          3624,
          264,
          3356,
          3949,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8133.48,
        "id": 2393,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8131.48,
        "temperature": 0,
        "text": " I'm entering the tunnel now.",
        "tokens": [
          50364,
          286,
          478,
          11104,
          264,
          13186,
          586,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8134.48,
        "id": 2394,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8133.48,
        "temperature": 0,
        "text": " So we'll probably lose the 40.",
        "tokens": [
          50464,
          407,
          321,
          603,
          1391,
          3624,
          264,
          3356,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8137.48,
        "id": 2395,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8134.48,
        "temperature": 0,
        "text": " You've been watching this while driving or on a train?",
        "tokens": [
          50514,
          509,
          600,
          668,
          1976,
          341,
          1339,
          4840,
          420,
          322,
          257,
          3847,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8138.48,
        "id": 2396,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8137.48,
        "temperature": 0,
        "text": " That's amazing.",
        "tokens": [
          50664,
          663,
          311,
          2243,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8140.48,
        "id": 2397,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8139.48,
        "temperature": 0,
        "text": " Can you reopen entries",
        "tokens": [
          50764,
          1664,
          291,
          33861,
          23041,
          50814
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8143.48,
        "id": 2398,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8140.48,
        "temperature": 0,
        "text": " on the color classification database just for fun?",
        "tokens": [
          50814,
          322,
          264,
          2017,
          21538,
          8149,
          445,
          337,
          1019,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8145.48,
        "id": 2399,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8143.48,
        "temperature": 0,
        "text": " Yeah, why not?",
        "tokens": [
          50964,
          865,
          11,
          983,
          406,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8147.48,
        "id": 2400,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8146.48,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51114,
          1545,
          406,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8149.48,
        "id": 2401,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8147.48,
        "temperature": 0,
        "text": " How do you manage time with a uni",
        "tokens": [
          51164,
          1012,
          360,
          291,
          3067,
          565,
          365,
          257,
          36435,
          51264
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8151.48,
        "id": 2402,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8149.48,
        "temperature": 0,
        "text": " and a YouTube channel, writes Art.",
        "tokens": [
          51264,
          293,
          257,
          3088,
          2269,
          11,
          13657,
          5735,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20002349217732748,
        "compression_ratio": 1.4793388429752066,
        "end": 8159.48,
        "id": 2403,
        "no_speech_prob": 0.0032728274818509817,
        "seek": 813148,
        "start": 8154.48,
        "temperature": 0,
        "text": " It's, you know, I think that I need to manage my time better",
        "tokens": [
          51514,
          467,
          311,
          11,
          291,
          458,
          11,
          286,
          519,
          300,
          286,
          643,
          281,
          3067,
          452,
          565,
          1101,
          51764
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8163.48,
        "id": 2404,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8159.48,
        "temperature": 0,
        "text": " and I need to, the other thing is I have a project",
        "tokens": [
          50364,
          293,
          286,
          643,
          281,
          11,
          264,
          661,
          551,
          307,
          286,
          362,
          257,
          1716,
          50564
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8165.48,
        "id": 2405,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8163.48,
        "temperature": 0,
        "text": " that I really want to do this summer,",
        "tokens": [
          50564,
          300,
          286,
          534,
          528,
          281,
          360,
          341,
          4266,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8168.48,
        "id": 2406,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8165.48,
        "temperature": 0,
        "text": " which is an updated version of the Nature of Code book.",
        "tokens": [
          50664,
          597,
          307,
          364,
          10588,
          3037,
          295,
          264,
          20159,
          295,
          15549,
          1446,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8171.48,
        "id": 2407,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8168.48,
        "temperature": 0,
        "text": " And I think that I need to take a break from live streaming",
        "tokens": [
          50814,
          400,
          286,
          519,
          300,
          286,
          643,
          281,
          747,
          257,
          1821,
          490,
          1621,
          11791,
          50964
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8174.48,
        "id": 2408,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8171.48,
        "temperature": 0,
        "text": " or like slow that down a little bit",
        "tokens": [
          50964,
          420,
          411,
          2964,
          300,
          760,
          257,
          707,
          857,
          51114
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8176.48,
        "id": 2409,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8174.48,
        "temperature": 0,
        "text": " to give myself more time to work on that.",
        "tokens": [
          51114,
          281,
          976,
          2059,
          544,
          565,
          281,
          589,
          322,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8179.48,
        "id": 2410,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8176.48,
        "temperature": 0,
        "text": " But now that I have the Patreon and the sponsors,",
        "tokens": [
          51214,
          583,
          586,
          300,
          286,
          362,
          264,
          15692,
          293,
          264,
          22593,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8181.48,
        "id": 2411,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8179.48,
        "temperature": 0,
        "text": " I'm sort of not sure how to do that",
        "tokens": [
          51364,
          286,
          478,
          1333,
          295,
          406,
          988,
          577,
          281,
          360,
          300,
          51464
        ]
      },
      {
        "avg_logprob": -0.1967379860256029,
        "compression_ratio": 1.6334661354581674,
        "end": 8183.48,
        "id": 2412,
        "no_speech_prob": 0.002115475246682763,
        "seek": 815948,
        "start": 8181.48,
        "temperature": 0,
        "text": " because I want to keep the content going.",
        "tokens": [
          51464,
          570,
          286,
          528,
          281,
          1066,
          264,
          2701,
          516,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23462295532226562,
        "compression_ratio": 1.4433962264150944,
        "end": 8188.48,
        "id": 2413,
        "no_speech_prob": 0.028434213250875473,
        "seek": 818348,
        "start": 8183.48,
        "temperature": 0,
        "text": " So, but let me turn the, let me turn",
        "tokens": [
          50364,
          407,
          11,
          457,
          718,
          385,
          1261,
          264,
          11,
          718,
          385,
          1261,
          50614
        ]
      },
      {
        "avg_logprob": -0.23462295532226562,
        "compression_ratio": 1.4433962264150944,
        "end": 8195.48,
        "id": 2414,
        "no_speech_prob": 0.028434213250875473,
        "seek": 818348,
        "start": 8190.48,
        "temperature": 0,
        "text": " the writing to the database back on, I guess.",
        "tokens": [
          50714,
          264,
          3579,
          281,
          264,
          8149,
          646,
          322,
          11,
          286,
          2041,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23462295532226562,
        "compression_ratio": 1.4433962264150944,
        "end": 8205.48,
        "id": 2415,
        "no_speech_prob": 0.028434213250875473,
        "seek": 818348,
        "start": 8200.48,
        "temperature": 0,
        "text": " So rules and write is true.",
        "tokens": [
          51214,
          407,
          4474,
          293,
          2464,
          307,
          2074,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23462295532226562,
        "compression_ratio": 1.4433962264150944,
        "end": 8211.48,
        "id": 2416,
        "no_speech_prob": 0.028434213250875473,
        "seek": 818348,
        "start": 8208.48,
        "temperature": 0,
        "text": " Okay, you can write to the database again.",
        "tokens": [
          51614,
          1033,
          11,
          291,
          393,
          2464,
          281,
          264,
          8149,
          797,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8215.48,
        "id": 2417,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8213.48,
        "temperature": 0,
        "text": " Ricardo asks, are you a uni professor?",
        "tokens": [
          50364,
          42634,
          8962,
          11,
          366,
          291,
          257,
          36435,
          8304,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8219.48,
        "id": 2418,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8215.48,
        "temperature": 0,
        "text": " So I teach at New York University,",
        "tokens": [
          50464,
          407,
          286,
          2924,
          412,
          1873,
          3609,
          3535,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8221.48,
        "id": 2419,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8219.48,
        "temperature": 0,
        "text": " part of a program called ITP,",
        "tokens": [
          50664,
          644,
          295,
          257,
          1461,
          1219,
          6783,
          47,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8223.48,
        "id": 2420,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8221.48,
        "temperature": 0,
        "text": " which is part of Tisch School of the Arts.",
        "tokens": [
          50764,
          597,
          307,
          644,
          295,
          48192,
          5070,
          295,
          264,
          12407,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8225.48,
        "id": 2421,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8223.48,
        "temperature": 0,
        "text": " And you can find out more information on the website.",
        "tokens": [
          50864,
          400,
          291,
          393,
          915,
          484,
          544,
          1589,
          322,
          264,
          3144,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8228.48,
        "id": 2422,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8225.48,
        "temperature": 0,
        "text": " And this fall, we're starting a new undergrad program.",
        "tokens": [
          50964,
          400,
          341,
          2100,
          11,
          321,
          434,
          2891,
          257,
          777,
          14295,
          1461,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8230.48,
        "id": 2423,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8228.48,
        "temperature": 0,
        "text": " So, woohoo.",
        "tokens": [
          51114,
          407,
          11,
          21657,
          19069,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8236.48,
        "id": 2424,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8233.48,
        "temperature": 0,
        "text": " No, remove the false and, yes.",
        "tokens": [
          51364,
          883,
          11,
          4159,
          264,
          7908,
          293,
          11,
          2086,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8237.48,
        "id": 2425,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8236.48,
        "temperature": 0,
        "text": " Oh, that's, yes.",
        "tokens": [
          51514,
          876,
          11,
          300,
          311,
          11,
          2086,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8239.48,
        "id": 2426,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8237.48,
        "temperature": 0,
        "text": " Ah, shoot, shoot, shoot.",
        "tokens": [
          51564,
          2438,
          11,
          3076,
          11,
          3076,
          11,
          3076,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1956400644211542,
        "compression_ratio": 1.579591836734694,
        "end": 8242.48,
        "id": 2427,
        "no_speech_prob": 0.04335955157876015,
        "seek": 821348,
        "start": 8239.48,
        "temperature": 0,
        "text": " No, no, no, I didn't, that didn't just happen.",
        "tokens": [
          51664,
          883,
          11,
          572,
          11,
          572,
          11,
          286,
          994,
          380,
          11,
          300,
          994,
          380,
          445,
          1051,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8245.48,
        "id": 2428,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8243.48,
        "temperature": 0,
        "text": " Quick, I totally did the wrong thing.",
        "tokens": [
          50364,
          12101,
          11,
          286,
          3879,
          630,
          264,
          2085,
          551,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8253.48,
        "id": 2429,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8251.48,
        "temperature": 0,
        "text": " Totally did the wrong thing.",
        "tokens": [
          50764,
          22837,
          630,
          264,
          2085,
          551,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8256.48,
        "id": 2430,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8253.48,
        "temperature": 0,
        "text": " Rules, quick, let me put this false.",
        "tokens": [
          50864,
          38897,
          11,
          1702,
          11,
          718,
          385,
          829,
          341,
          7908,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8259.48,
        "id": 2431,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8257.48,
        "temperature": 0,
        "text": " All right, so there was a brief moment in time",
        "tokens": [
          51064,
          1057,
          558,
          11,
          370,
          456,
          390,
          257,
          5353,
          1623,
          294,
          565,
          51164
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8261.48,
        "id": 2432,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8259.48,
        "temperature": 0,
        "text": " where the whole thing was open to writing anything.",
        "tokens": [
          51164,
          689,
          264,
          1379,
          551,
          390,
          1269,
          281,
          3579,
          1340,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8263.48,
        "id": 2433,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8261.48,
        "temperature": 0,
        "text": " But now this is what I want to remove.",
        "tokens": [
          51264,
          583,
          586,
          341,
          307,
          437,
          286,
          528,
          281,
          4159,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8266.48,
        "id": 2434,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8265.48,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          51464,
          1044,
          291,
          588,
          709,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8268.48,
        "id": 2435,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8266.48,
        "temperature": 0,
        "text": " Okay, everything should be okay now.",
        "tokens": [
          51514,
          1033,
          11,
          1203,
          820,
          312,
          1392,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19120212223218835,
        "compression_ratio": 1.597938144329897,
        "end": 8270.48,
        "id": 2436,
        "no_speech_prob": 0.00011591830843826756,
        "seek": 824348,
        "start": 8269.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51664,
          1057,
          558,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8273.48,
        "id": 2437,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8271.48,
        "temperature": 0,
        "text": " Ah, Belisarith asks,",
        "tokens": [
          50414,
          2438,
          11,
          6248,
          271,
          289,
          355,
          8962,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8276.48,
        "id": 2438,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8273.48,
        "temperature": 0,
        "text": " Dan, could you please explain how to get the Slack invitation?",
        "tokens": [
          50514,
          3394,
          11,
          727,
          291,
          1767,
          2903,
          577,
          281,
          483,
          264,
          37211,
          17890,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8279.48,
        "id": 2439,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8276.48,
        "temperature": 0,
        "text": " So, unfortunately, for better or worse,",
        "tokens": [
          50664,
          407,
          11,
          7015,
          11,
          337,
          1101,
          420,
          5324,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8281.48,
        "id": 2440,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8279.48,
        "temperature": 0,
        "text": " the Slack invitation is only open",
        "tokens": [
          50814,
          264,
          37211,
          17890,
          307,
          787,
          1269,
          50914
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8284.48,
        "id": 2441,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8281.48,
        "temperature": 0,
        "text": " to either sponsors of the YouTube channel",
        "tokens": [
          50914,
          281,
          2139,
          22593,
          295,
          264,
          3088,
          2269,
          51064
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8287.48,
        "id": 2442,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8284.48,
        "temperature": 0,
        "text": " or patrons via Patreon.",
        "tokens": [
          51064,
          420,
          27559,
          5766,
          15692,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8290.48,
        "id": 2443,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8287.48,
        "temperature": 0,
        "text": " And you can find more information about that",
        "tokens": [
          51214,
          400,
          291,
          393,
          915,
          544,
          1589,
          466,
          300,
          51364
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8292.48,
        "id": 2444,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8290.48,
        "temperature": 0,
        "text": " at patreon.com.",
        "tokens": [
          51364,
          412,
          33161,
          13,
          1112,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8293.48,
        "id": 2445,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8292.48,
        "temperature": 0,
        "text": " There's like a sponsor button already",
        "tokens": [
          51464,
          821,
          311,
          411,
          257,
          16198,
          2960,
          1217,
          51514
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8294.48,
        "id": 2446,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8293.48,
        "temperature": 0,
        "text": " as part of the YouTube channel.",
        "tokens": [
          51514,
          382,
          644,
          295,
          264,
          3088,
          2269,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8297.48,
        "id": 2447,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8294.48,
        "temperature": 0,
        "text": " I don't love the idea of having a closed community",
        "tokens": [
          51564,
          286,
          500,
          380,
          959,
          264,
          1558,
          295,
          1419,
          257,
          5395,
          1768,
          51714
        ]
      },
      {
        "avg_logprob": -0.2130408044588768,
        "compression_ratio": 1.631578947368421,
        "end": 8299.48,
        "id": 2448,
        "no_speech_prob": 0.0016484330408275127,
        "seek": 827048,
        "start": 8297.48,
        "temperature": 0,
        "text": " that requires people to pay.",
        "tokens": [
          51714,
          300,
          7029,
          561,
          281,
          1689,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8301.48,
        "id": 2449,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8299.48,
        "temperature": 0,
        "text": " But it is, at the moment,",
        "tokens": [
          50364,
          583,
          309,
          307,
          11,
          412,
          264,
          1623,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8302.48,
        "id": 2450,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8301.48,
        "temperature": 0,
        "text": " the benefits that I get out of it",
        "tokens": [
          50464,
          264,
          5311,
          300,
          286,
          483,
          484,
          295,
          309,
          50514
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8304.48,
        "id": 2451,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8302.48,
        "temperature": 0,
        "text": " is it's a smaller group of people",
        "tokens": [
          50514,
          307,
          309,
          311,
          257,
          4356,
          1594,
          295,
          561,
          50614
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8306.48,
        "id": 2452,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8304.48,
        "temperature": 0,
        "text": " who are sort of dedicated to participating",
        "tokens": [
          50614,
          567,
          366,
          1333,
          295,
          8374,
          281,
          13950,
          50714
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8308.48,
        "id": 2453,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8306.48,
        "temperature": 0,
        "text": " in the community of the channel.",
        "tokens": [
          50714,
          294,
          264,
          1768,
          295,
          264,
          2269,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8312.48,
        "id": 2454,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8309.48,
        "temperature": 0,
        "text": " And it helps me make these videos,",
        "tokens": [
          50864,
          400,
          309,
          3665,
          385,
          652,
          613,
          2145,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8314.48,
        "id": 2455,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8312.48,
        "temperature": 0,
        "text": " having the funding, frankly.",
        "tokens": [
          51014,
          1419,
          264,
          6137,
          11,
          11939,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8316.48,
        "id": 2456,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8314.48,
        "temperature": 0,
        "text": " It allows me to have more time to do it",
        "tokens": [
          51114,
          467,
          4045,
          385,
          281,
          362,
          544,
          565,
          281,
          360,
          309,
          51214
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8318.48,
        "id": 2457,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8316.48,
        "temperature": 0,
        "text": " and it sort of makes me feel like it's an obligation",
        "tokens": [
          51214,
          293,
          309,
          1333,
          295,
          1669,
          385,
          841,
          411,
          309,
          311,
          364,
          20326,
          51314
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8320.48,
        "id": 2458,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8318.48,
        "temperature": 0,
        "text": " in a good way, I think.",
        "tokens": [
          51314,
          294,
          257,
          665,
          636,
          11,
          286,
          519,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8323.48,
        "id": 2459,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8321.48,
        "temperature": 0,
        "text": " So that's at the moment the system I have.",
        "tokens": [
          51464,
          407,
          300,
          311,
          412,
          264,
          1623,
          264,
          1185,
          286,
          362,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8325.48,
        "id": 2460,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8323.48,
        "temperature": 0,
        "text": " I am very happy for people to self-organize",
        "tokens": [
          51564,
          286,
          669,
          588,
          2055,
          337,
          561,
          281,
          2698,
          12,
          12372,
          1125,
          51664
        ]
      },
      {
        "avg_logprob": -0.16903784615652903,
        "compression_ratio": 1.6925795053003534,
        "end": 8328.48,
        "id": 2461,
        "no_speech_prob": 0.00006501493771793321,
        "seek": 829948,
        "start": 8325.48,
        "temperature": 0,
        "text": " into their own free and open communities.",
        "tokens": [
          51664,
          666,
          641,
          1065,
          1737,
          293,
          1269,
          4456,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8330.48,
        "id": 2462,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8328.48,
        "temperature": 0,
        "text": " The idea is I want to do more",
        "tokens": [
          50364,
          440,
          1558,
          307,
          286,
          528,
          281,
          360,
          544,
          50464
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8332.48,
        "id": 2463,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8330.48,
        "temperature": 0,
        "text": " to be able to have the audience of this channel",
        "tokens": [
          50464,
          281,
          312,
          1075,
          281,
          362,
          264,
          4034,
          295,
          341,
          2269,
          50564
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8334.48,
        "id": 2464,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8332.48,
        "temperature": 0,
        "text": " be more inclusive.",
        "tokens": [
          50564,
          312,
          544,
          13429,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8337.48,
        "id": 2465,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8334.48,
        "temperature": 0,
        "text": " And I'm always open to anyone who has any thoughts",
        "tokens": [
          50664,
          400,
          286,
          478,
          1009,
          1269,
          281,
          2878,
          567,
          575,
          604,
          4598,
          50814
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8339.48,
        "id": 2466,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8337.48,
        "temperature": 0,
        "text": " or ideas that can help and ways for me",
        "tokens": [
          50814,
          420,
          3487,
          300,
          393,
          854,
          293,
          2098,
          337,
          385,
          50914
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8342.48,
        "id": 2467,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8339.48,
        "temperature": 0,
        "text": " to think about doing a better job with that.",
        "tokens": [
          50914,
          281,
          519,
          466,
          884,
          257,
          1101,
          1691,
          365,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8348.48,
        "id": 2468,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8345.48,
        "temperature": 0,
        "text": " Tips on time management, I got nothing for you.",
        "tokens": [
          51214,
          36887,
          322,
          565,
          4592,
          11,
          286,
          658,
          1825,
          337,
          291,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8353.48,
        "id": 2469,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8350.48,
        "temperature": 0,
        "text": " Oh, and so, but if you do sponsor the channel,",
        "tokens": [
          51464,
          876,
          11,
          293,
          370,
          11,
          457,
          498,
          291,
          360,
          16198,
          264,
          2269,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.22922632532212342,
        "compression_ratio": 1.6527777777777777,
        "end": 8356.48,
        "id": 2470,
        "no_speech_prob": 0.001896813279017806,
        "seek": 832848,
        "start": 8355.48,
        "temperature": 0,
        "text": " if you do sponsor the channel,",
        "tokens": [
          51714,
          498,
          291,
          360,
          16198,
          264,
          2269,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8358.48,
        "id": 2471,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8356.48,
        "temperature": 0,
        "text": " and I'll also sign up via Patreon,",
        "tokens": [
          50364,
          293,
          286,
          603,
          611,
          1465,
          493,
          5766,
          15692,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8360.48,
        "id": 2472,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8358.48,
        "temperature": 0,
        "text": " I don't have a good system of,",
        "tokens": [
          50464,
          286,
          500,
          380,
          362,
          257,
          665,
          1185,
          295,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8363.48,
        "id": 2473,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8362.48,
        "temperature": 0,
        "text": " there's no automatic system,",
        "tokens": [
          50664,
          456,
          311,
          572,
          12509,
          1185,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8365.48,
        "id": 2474,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8363.48,
        "temperature": 0,
        "text": " I have to add you to Slack manually.",
        "tokens": [
          50714,
          286,
          362,
          281,
          909,
          291,
          281,
          37211,
          16945,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8367.48,
        "id": 2475,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8365.48,
        "temperature": 0,
        "text": " So you can,",
        "tokens": [
          50814,
          407,
          291,
          393,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8371.48,
        "id": 2476,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8369.48,
        "temperature": 0,
        "text": " the best way would be to tweet me at Schiffman,",
        "tokens": [
          51014,
          264,
          1151,
          636,
          576,
          312,
          281,
          15258,
          385,
          412,
          2065,
          3661,
          1601,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8374.48,
        "id": 2477,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8371.48,
        "temperature": 0,
        "text": " but if you're a sponsor on YouTube,",
        "tokens": [
          51114,
          457,
          498,
          291,
          434,
          257,
          16198,
          322,
          3088,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8375.48,
        "id": 2478,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8374.48,
        "temperature": 0,
        "text": " if you go to the community tab,",
        "tokens": [
          51264,
          498,
          291,
          352,
          281,
          264,
          1768,
          4421,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8377.48,
        "id": 2479,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8375.48,
        "temperature": 0,
        "text": " there's a post there that has a link to a Google forum",
        "tokens": [
          51314,
          456,
          311,
          257,
          2183,
          456,
          300,
          575,
          257,
          2113,
          281,
          257,
          3329,
          17542,
          51414
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8379.48,
        "id": 2480,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8377.48,
        "temperature": 0,
        "text": " that's only for sponsors,",
        "tokens": [
          51414,
          300,
          311,
          787,
          337,
          22593,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8381.48,
        "id": 2481,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8379.48,
        "temperature": 0,
        "text": " and Patreon, I get your email and I send an invite,",
        "tokens": [
          51514,
          293,
          15692,
          11,
          286,
          483,
          428,
          3796,
          293,
          286,
          2845,
          364,
          7980,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8383.48,
        "id": 2482,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8381.48,
        "temperature": 0,
        "text": " but sometimes it ends up in a spam folder",
        "tokens": [
          51614,
          457,
          2171,
          309,
          5314,
          493,
          294,
          257,
          24028,
          10820,
          51714
        ]
      },
      {
        "avg_logprob": -0.20513370865625694,
        "compression_ratio": 1.6900369003690037,
        "end": 8385.48,
        "id": 2483,
        "no_speech_prob": 0.0004727767372969538,
        "seek": 835648,
        "start": 8383.48,
        "temperature": 0,
        "text": " and sometimes I forget.",
        "tokens": [
          51714,
          293,
          2171,
          286,
          2870,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8387.48,
        "id": 2484,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8385.48,
        "temperature": 0,
        "text": " Link to the site with colors.",
        "tokens": [
          50364,
          8466,
          281,
          264,
          3621,
          365,
          4577,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8389.48,
        "id": 2485,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8387.48,
        "temperature": 0,
        "text": " The site with colors is",
        "tokens": [
          50464,
          440,
          3621,
          365,
          4577,
          307,
          50564
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8392.48,
        "id": 2486,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8391.48,
        "temperature": 0,
        "text": " github.com,",
        "tokens": [
          50664,
          290,
          355,
          836,
          13,
          1112,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8396.48,
        "id": 2487,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8394.48,
        "temperature": 0,
        "text": " crowdsource, and I also should say,",
        "tokens": [
          50814,
          26070,
          2948,
          11,
          293,
          286,
          611,
          820,
          584,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8398.48,
        "id": 2488,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8396.48,
        "temperature": 0,
        "text": " one of the things that I'm not able to do effectively",
        "tokens": [
          50914,
          472,
          295,
          264,
          721,
          300,
          286,
          478,
          406,
          1075,
          281,
          360,
          8659,
          51014
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8401.48,
        "id": 2489,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8398.48,
        "temperature": 0,
        "text": " is manage all the pull requests and issues",
        "tokens": [
          51014,
          307,
          3067,
          439,
          264,
          2235,
          12475,
          293,
          2663,
          51164
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8403.48,
        "id": 2490,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8401.48,
        "temperature": 0,
        "text": " on these GitHub repos.",
        "tokens": [
          51164,
          322,
          613,
          23331,
          1085,
          329,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8404.48,
        "id": 2491,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8403.48,
        "temperature": 0,
        "text": " I would love,",
        "tokens": [
          51264,
          286,
          576,
          959,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8406.48,
        "id": 2492,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8404.48,
        "temperature": 0,
        "text": " I do consider that a possibility",
        "tokens": [
          51314,
          286,
          360,
          1949,
          300,
          257,
          7959,
          51414
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8408.48,
        "id": 2493,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8406.48,
        "temperature": 0,
        "text": " if that could actually be like a paid position",
        "tokens": [
          51414,
          498,
          300,
          727,
          767,
          312,
          411,
          257,
          4835,
          2535,
          51514
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8410.48,
        "id": 2494,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8408.48,
        "temperature": 0,
        "text": " of somebody who's a community manager",
        "tokens": [
          51514,
          295,
          2618,
          567,
          311,
          257,
          1768,
          6598,
          51614
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8412.48,
        "id": 2495,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8410.48,
        "temperature": 0,
        "text": " for all the GitHub repos,",
        "tokens": [
          51614,
          337,
          439,
          264,
          23331,
          1085,
          329,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.18712434536073266,
        "compression_ratio": 1.623015873015873,
        "end": 8413.48,
        "id": 2496,
        "no_speech_prob": 0.00008219967276090756,
        "seek": 838548,
        "start": 8412.48,
        "temperature": 0,
        "text": " but I haven't figured out, A,",
        "tokens": [
          51714,
          457,
          286,
          2378,
          380,
          8932,
          484,
          11,
          316,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8414.48,
        "id": 2497,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8413.48,
        "temperature": 0,
        "text": " if I have the budget to do that",
        "tokens": [
          50364,
          498,
          286,
          362,
          264,
          4706,
          281,
          360,
          300,
          50414
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8417.48,
        "id": 2498,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8414.48,
        "temperature": 0,
        "text": " and who the right person would be for that.",
        "tokens": [
          50414,
          293,
          567,
          264,
          558,
          954,
          576,
          312,
          337,
          300,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8419.48,
        "id": 2499,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8417.48,
        "temperature": 0,
        "text": " At the moment, there are a lot of wonderful volunteers",
        "tokens": [
          50564,
          1711,
          264,
          1623,
          11,
          456,
          366,
          257,
          688,
          295,
          3715,
          14352,
          50664
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8421.48,
        "id": 2500,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8419.48,
        "temperature": 0,
        "text": " who help,",
        "tokens": [
          50664,
          567,
          854,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8424.48,
        "id": 2501,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8421.48,
        "temperature": 0,
        "text": " who are members of the Coding Train GitHub organization",
        "tokens": [
          50764,
          567,
          366,
          2679,
          295,
          264,
          383,
          8616,
          28029,
          23331,
          4475,
          50914
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8426.48,
        "id": 2502,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8424.48,
        "temperature": 0,
        "text": " and help kind of like manage and pull requests",
        "tokens": [
          50914,
          293,
          854,
          733,
          295,
          411,
          3067,
          293,
          2235,
          12475,
          51014
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8429.48,
        "id": 2503,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8426.48,
        "temperature": 0,
        "text": " and write issues here and there as they have time.",
        "tokens": [
          51014,
          293,
          2464,
          2663,
          510,
          293,
          456,
          382,
          436,
          362,
          565,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8435.48,
        "id": 2504,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8431.48,
        "temperature": 0,
        "text": " Oh, Oliver posted in the YouTube channel.",
        "tokens": [
          51264,
          876,
          11,
          23440,
          9437,
          294,
          264,
          3088,
          2269,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8437.48,
        "id": 2505,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8435.48,
        "temperature": 0,
        "text": " Okay, and so here it is right here.",
        "tokens": [
          51464,
          1033,
          11,
          293,
          370,
          510,
          309,
          307,
          558,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8439.48,
        "id": 2506,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8437.48,
        "temperature": 0,
        "text": " This is at present,",
        "tokens": [
          51564,
          639,
          307,
          412,
          1974,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8441.48,
        "id": 2507,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8439.48,
        "temperature": 0,
        "text": " and let's just make sure this is working again.",
        "tokens": [
          51664,
          293,
          718,
          311,
          445,
          652,
          988,
          341,
          307,
          1364,
          797,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19463607788085938,
        "compression_ratio": 1.6123188405797102,
        "end": 8442.48,
        "id": 2508,
        "no_speech_prob": 0.00042385567212477326,
        "seek": 841348,
        "start": 8441.48,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          51764,
          7010,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8447.48,
        "id": 2509,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8442.48,
        "temperature": 0,
        "text": " So now this is once again accepting new data points",
        "tokens": [
          50364,
          407,
          586,
          341,
          307,
          1564,
          797,
          17391,
          777,
          1412,
          2793,
          50614
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8451.48,
        "id": 2510,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8449.48,
        "temperature": 0,
        "text": " for the color classifier.",
        "tokens": [
          50714,
          337,
          264,
          2017,
          1508,
          9902,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8452.48,
        "id": 2511,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8451.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8454.48,
        "id": 2512,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8452.48,
        "temperature": 0,
        "text": " Oh yes, and Maren, thank you,",
        "tokens": [
          50864,
          876,
          2086,
          11,
          293,
          376,
          4484,
          11,
          1309,
          291,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8455.48,
        "id": 2513,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8454.48,
        "temperature": 0,
        "text": " and so many wonderful members of the community",
        "tokens": [
          50964,
          293,
          370,
          867,
          3715,
          2679,
          295,
          264,
          1768,
          51014
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8458.48,
        "id": 2514,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8455.48,
        "temperature": 0,
        "text": " that I can't seem to remember to mention.",
        "tokens": [
          51014,
          300,
          286,
          393,
          380,
          1643,
          281,
          1604,
          281,
          2152,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8459.48,
        "id": 2515,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8458.48,
        "temperature": 0,
        "text": " I am in New York City.",
        "tokens": [
          51164,
          286,
          669,
          294,
          1873,
          3609,
          4392,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8461.48,
        "id": 2516,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8459.48,
        "temperature": 0,
        "text": " I'm not in Hong Kong.",
        "tokens": [
          51214,
          286,
          478,
          406,
          294,
          8868,
          9832,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8462.48,
        "id": 2517,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8461.48,
        "temperature": 0,
        "text": " Ricardo asked,",
        "tokens": [
          51314,
          42634,
          2351,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8464.48,
        "id": 2518,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8462.48,
        "temperature": 0,
        "text": " are you familiar with functional programming in JS?",
        "tokens": [
          51364,
          366,
          291,
          4963,
          365,
          11745,
          9410,
          294,
          33063,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8466.48,
        "id": 2519,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8465.48,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51514,
          7951,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8469.48,
        "id": 2520,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8466.48,
        "temperature": 0,
        "text": " Ada asked, almost a half a million subs.",
        "tokens": [
          51564,
          32276,
          2351,
          11,
          1920,
          257,
          1922,
          257,
          2459,
          2090,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2033615272586085,
        "compression_ratio": 1.503875968992248,
        "end": 8470.48,
        "id": 2521,
        "no_speech_prob": 0.003075317246839404,
        "seek": 844248,
        "start": 8469.48,
        "temperature": 0,
        "text": " How do you feel about that?",
        "tokens": [
          51714,
          1012,
          360,
          291,
          841,
          466,
          300,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8472.48,
        "id": 2522,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8470.48,
        "temperature": 0,
        "text": " I'm very excited.",
        "tokens": [
          50364,
          286,
          478,
          588,
          2919,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8476.48,
        "id": 2523,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8472.48,
        "temperature": 0,
        "text": " I feel very honored or humbled, those kind of words.",
        "tokens": [
          50464,
          286,
          841,
          588,
          14556,
          420,
          46199,
          11,
          729,
          733,
          295,
          2283,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8478.48,
        "id": 2524,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8476.48,
        "temperature": 0,
        "text": " I feel a little bit surprised.",
        "tokens": [
          50664,
          286,
          841,
          257,
          707,
          857,
          6100,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8479.48,
        "id": 2525,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8478.48,
        "temperature": 0,
        "text": " Like I did not,",
        "tokens": [
          50764,
          1743,
          286,
          630,
          406,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8481.48,
        "id": 2526,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8479.48,
        "temperature": 0,
        "text": " this was not my expectation for the channel.",
        "tokens": [
          50814,
          341,
          390,
          406,
          452,
          14334,
          337,
          264,
          2269,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8484.48,
        "id": 2527,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8481.48,
        "temperature": 0,
        "text": " I feel like I need to do better.",
        "tokens": [
          50914,
          286,
          841,
          411,
          286,
          643,
          281,
          360,
          1101,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8487.48,
        "id": 2528,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8484.48,
        "temperature": 0,
        "text": " I'm always trying to improve what I'm doing,",
        "tokens": [
          51064,
          286,
          478,
          1009,
          1382,
          281,
          3470,
          437,
          286,
          478,
          884,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8491.48,
        "id": 2529,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8487.48,
        "temperature": 0,
        "text": " and yeah, it's exciting.",
        "tokens": [
          51214,
          293,
          1338,
          11,
          309,
          311,
          4670,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8494.48,
        "id": 2530,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8491.48,
        "temperature": 0,
        "text": " I would like to do something to celebrate 500,000 subscribers.",
        "tokens": [
          51414,
          286,
          576,
          411,
          281,
          360,
          746,
          281,
          8098,
          5923,
          11,
          1360,
          11092,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8495.48,
        "id": 2531,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8494.48,
        "temperature": 0,
        "text": " I should probably do,",
        "tokens": [
          51564,
          286,
          820,
          1391,
          360,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.176429194262904,
        "compression_ratio": 1.6337448559670782,
        "end": 8498.48,
        "id": 2532,
        "no_speech_prob": 0.013427378609776497,
        "seek": 847048,
        "start": 8495.48,
        "temperature": 0,
        "text": " I was saying that I should just do whatever is",
        "tokens": [
          51614,
          286,
          390,
          1566,
          300,
          286,
          820,
          445,
          360,
          2035,
          307,
          51764
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8501.48,
        "id": 2533,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8498.48,
        "temperature": 0,
        "text": " the suggestion number 500 in here,",
        "tokens": [
          50364,
          264,
          16541,
          1230,
          5923,
          294,
          510,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8507.48,
        "id": 2534,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8504.48,
        "temperature": 0,
        "text": " which is make an AI that solves the 15 tile sliding puzzle,",
        "tokens": [
          50664,
          597,
          307,
          652,
          364,
          7318,
          300,
          39890,
          264,
          2119,
          20590,
          21169,
          12805,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8509.48,
        "id": 2535,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8507.48,
        "temperature": 0,
        "text": " so I might try to do that at some point.",
        "tokens": [
          50814,
          370,
          286,
          1062,
          853,
          281,
          360,
          300,
          412,
          512,
          935,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8510.48,
        "id": 2536,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8509.48,
        "temperature": 0,
        "text": " If anybody has any other ideas",
        "tokens": [
          50914,
          759,
          4472,
          575,
          604,
          661,
          3487,
          50964
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8513.48,
        "id": 2537,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8510.48,
        "temperature": 0,
        "text": " for celebrating 500,000 subscribers,",
        "tokens": [
          50964,
          337,
          15252,
          5923,
          11,
          1360,
          11092,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8515.48,
        "id": 2538,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8513.48,
        "temperature": 0,
        "text": " assuming not everybody is just unsubscribed right now,",
        "tokens": [
          51114,
          11926,
          406,
          2201,
          307,
          445,
          2693,
          5432,
          18732,
          558,
          586,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8517.48,
        "id": 2539,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8515.48,
        "temperature": 0,
        "text": " which would be fine also.",
        "tokens": [
          51214,
          597,
          576,
          312,
          2489,
          611,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8519.48,
        "id": 2540,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8517.48,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51314,
          865,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8523.48,
        "id": 2541,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8520.48,
        "temperature": 0,
        "text": " This has been a really great stream, writes K. Wigman,",
        "tokens": [
          51464,
          639,
          575,
          668,
          257,
          534,
          869,
          4309,
          11,
          13657,
          591,
          13,
          343,
          328,
          1601,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8525.48,
        "id": 2542,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8523.48,
        "temperature": 0,
        "text": " like a microcosm of the entire data science pipeline.",
        "tokens": [
          51614,
          411,
          257,
          4532,
          6877,
          76,
          295,
          264,
          2302,
          1412,
          3497,
          15517,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2512882800141642,
        "compression_ratio": 1.5342960288808665,
        "end": 8526.48,
        "id": 2543,
        "no_speech_prob": 0.024796923622488976,
        "seek": 849848,
        "start": 8525.48,
        "temperature": 0,
        "text": " It's really nice to hear,",
        "tokens": [
          51714,
          467,
          311,
          534,
          1481,
          281,
          1568,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8527.48,
        "id": 2544,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8526.48,
        "temperature": 0,
        "text": " because this is the new,",
        "tokens": [
          50364,
          570,
          341,
          307,
          264,
          777,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8530.48,
        "id": 2545,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8527.48,
        "temperature": 0,
        "text": " I don't know what my expertise is exactly,",
        "tokens": [
          50414,
          286,
          500,
          380,
          458,
          437,
          452,
          11769,
          307,
          2293,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8534.48,
        "id": 2546,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8530.48,
        "temperature": 0,
        "text": " but certainly data science and working with machine learning,",
        "tokens": [
          50564,
          457,
          3297,
          1412,
          3497,
          293,
          1364,
          365,
          3479,
          2539,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8537.48,
        "id": 2547,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8534.48,
        "temperature": 0,
        "text": " this is not something that I spent years and years",
        "tokens": [
          50764,
          341,
          307,
          406,
          746,
          300,
          286,
          4418,
          924,
          293,
          924,
          50914
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8539.48,
        "id": 2548,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8537.48,
        "temperature": 0,
        "text": " studying and thinking about.",
        "tokens": [
          50914,
          7601,
          293,
          1953,
          466,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8541.48,
        "id": 2549,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8539.48,
        "temperature": 0,
        "text": " It's something that I've come to as a person",
        "tokens": [
          51014,
          467,
          311,
          746,
          300,
          286,
          600,
          808,
          281,
          382,
          257,
          954,
          51114
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8543.48,
        "id": 2550,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8541.48,
        "temperature": 0,
        "text": " who worked on kind of open source",
        "tokens": [
          51114,
          567,
          2732,
          322,
          733,
          295,
          1269,
          4009,
          51214
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8545.48,
        "id": 2551,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8543.48,
        "temperature": 0,
        "text": " creative coding platforms for many years.",
        "tokens": [
          51214,
          5880,
          17720,
          9473,
          337,
          867,
          924,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8547.48,
        "id": 2552,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8545.48,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8552.48,
        "id": 2553,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8549.48,
        "temperature": 0,
        "text": " I'm now going to leave the station.",
        "tokens": [
          51514,
          286,
          478,
          586,
          516,
          281,
          1856,
          264,
          5214,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19611323321307148,
        "compression_ratio": 1.6341463414634145,
        "end": 8554.48,
        "id": 2554,
        "no_speech_prob": 0.00011061097757192329,
        "seek": 852648,
        "start": 8552.48,
        "temperature": 0,
        "text": " Thank you for tuning in.",
        "tokens": [
          51664,
          1044,
          291,
          337,
          15164,
          294,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8557.48,
        "id": 2555,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8554.48,
        "temperature": 0,
        "text": " I hope to come back and finish this color classifier on Monday.",
        "tokens": [
          50364,
          286,
          1454,
          281,
          808,
          646,
          293,
          2413,
          341,
          2017,
          1508,
          9902,
          322,
          8138,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8560.48,
        "id": 2556,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8557.48,
        "temperature": 0,
        "text": " Next week is a really hard week for me,",
        "tokens": [
          50514,
          3087,
          1243,
          307,
          257,
          534,
          1152,
          1243,
          337,
          385,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8563.48,
        "id": 2557,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8560.48,
        "temperature": 0,
        "text": " so it's not confirmed that I'm doing that",
        "tokens": [
          50664,
          370,
          309,
          311,
          406,
          11341,
          300,
          286,
          478,
          884,
          300,
          50814
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8567.48,
        "id": 2558,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8563.48,
        "temperature": 0,
        "text": " until you see it scheduled on YouTube itself.",
        "tokens": [
          50814,
          1826,
          291,
          536,
          309,
          15678,
          322,
          3088,
          2564,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8570.48,
        "id": 2559,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8567.48,
        "temperature": 0,
        "text": " You know, if you're wondering how to get a notification,",
        "tokens": [
          51014,
          509,
          458,
          11,
          498,
          291,
          434,
          6359,
          577,
          281,
          483,
          257,
          11554,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8572.48,
        "id": 2560,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8570.48,
        "temperature": 0,
        "text": " you hit the subscribe button, the alarm bell,",
        "tokens": [
          51164,
          291,
          2045,
          264,
          3022,
          2960,
          11,
          264,
          14183,
          4549,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8573.48,
        "id": 2561,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8572.48,
        "temperature": 0,
        "text": " all that sort of stuff.",
        "tokens": [
          51264,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8577.48,
        "id": 2562,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8573.48,
        "temperature": 0,
        "text": " All right, so I'm going to hit stop streaming,",
        "tokens": [
          51314,
          1057,
          558,
          11,
          370,
          286,
          478,
          516,
          281,
          2045,
          1590,
          11791,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.1827242312224015,
        "compression_ratio": 1.5769230769230769,
        "end": 8581.48,
        "id": 2563,
        "no_speech_prob": 0.028432948514819145,
        "seek": 855448,
        "start": 8577.48,
        "temperature": 0,
        "text": " and I'll see you maybe, hopefully on Monday.",
        "tokens": [
          51514,
          293,
          286,
          603,
          536,
          291,
          1310,
          11,
          4696,
          322,
          8138,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8585.48,
        "id": 2564,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8581.48,
        "temperature": 0,
        "text": " If not, whenever I, at some point at the end of June.",
        "tokens": [
          50364,
          759,
          406,
          11,
          5699,
          286,
          11,
          412,
          512,
          935,
          412,
          264,
          917,
          295,
          6928,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8589.48,
        "id": 2565,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8585.48,
        "temperature": 0,
        "text": " Again, remember, I'm going to be away for half of July,",
        "tokens": [
          50564,
          3764,
          11,
          1604,
          11,
          286,
          478,
          516,
          281,
          312,
          1314,
          337,
          1922,
          295,
          7370,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8590.48,
        "id": 2566,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8589.48,
        "temperature": 0,
        "text": " so this will be a little bit lighter",
        "tokens": [
          50764,
          370,
          341,
          486,
          312,
          257,
          707,
          857,
          11546,
          50814
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8592.48,
        "id": 2567,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8590.48,
        "temperature": 0,
        "text": " over the summer during July and August,",
        "tokens": [
          50814,
          670,
          264,
          4266,
          1830,
          7370,
          293,
          6897,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8594.48,
        "id": 2568,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8592.48,
        "temperature": 0,
        "text": " but also I might, when I'm here,",
        "tokens": [
          50914,
          457,
          611,
          286,
          1062,
          11,
          562,
          286,
          478,
          510,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8598.48,
        "id": 2569,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8594.48,
        "temperature": 0,
        "text": " I might do two live streams in a week like I did this week.",
        "tokens": [
          51014,
          286,
          1062,
          360,
          732,
          1621,
          15842,
          294,
          257,
          1243,
          411,
          286,
          630,
          341,
          1243,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8601.48,
        "id": 2570,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8598.48,
        "temperature": 0,
        "text": " Does YouTube, oh, Ngramste asks,",
        "tokens": [
          51214,
          4402,
          3088,
          11,
          1954,
          11,
          426,
          1342,
          2941,
          8962,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8603.48,
        "id": 2571,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8601.48,
        "temperature": 0,
        "text": " does YouTube have an API that you could use",
        "tokens": [
          51364,
          775,
          3088,
          362,
          364,
          9362,
          300,
          291,
          727,
          764,
          51464
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8607.48,
        "id": 2572,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8603.48,
        "temperature": 0,
        "text": " for some cool data visualizations for 500K subscribers?",
        "tokens": [
          51464,
          337,
          512,
          1627,
          1412,
          5056,
          14455,
          337,
          5923,
          42,
          11092,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.22341207896961884,
        "compression_ratio": 1.5771812080536913,
        "end": 8609.48,
        "id": 2573,
        "no_speech_prob": 0.05920184403657913,
        "seek": 858148,
        "start": 8607.48,
        "temperature": 0,
        "text": " Word cloud of comments, or maybe I could visualize, like,",
        "tokens": [
          51664,
          8725,
          4588,
          295,
          3053,
          11,
          420,
          1310,
          286,
          727,
          23273,
          11,
          411,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8612.48,
        "id": 2574,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8609.48,
        "temperature": 0,
        "text": " all the locations all over the world where people are.",
        "tokens": [
          50364,
          439,
          264,
          9253,
          439,
          670,
          264,
          1002,
          689,
          561,
          366,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8614.48,
        "id": 2575,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8612.48,
        "temperature": 0,
        "text": " I don't know if I have access to that data.",
        "tokens": [
          50514,
          286,
          500,
          380,
          458,
          498,
          286,
          362,
          2105,
          281,
          300,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8615.48,
        "id": 2576,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8614.48,
        "temperature": 0,
        "text": " So yeah, I would consider that.",
        "tokens": [
          50614,
          407,
          1338,
          11,
          286,
          576,
          1949,
          300,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8616.48,
        "id": 2577,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8615.48,
        "temperature": 0,
        "text": " That's kind of like a fun idea.",
        "tokens": [
          50664,
          663,
          311,
          733,
          295,
          411,
          257,
          1019,
          1558,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8622.48,
        "id": 2578,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8616.48,
        "temperature": 0,
        "text": " So let's discuss that in the Slack channel.",
        "tokens": [
          50714,
          407,
          718,
          311,
          2248,
          300,
          294,
          264,
          37211,
          2269,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8623.48,
        "id": 2579,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8622.48,
        "temperature": 0,
        "text": " I would love to hear more suggestions.",
        "tokens": [
          51014,
          286,
          576,
          959,
          281,
          1568,
          544,
          13396,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8625.48,
        "id": 2580,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8623.48,
        "temperature": 0,
        "text": " Okay, goodbye, everybody.",
        "tokens": [
          51064,
          1033,
          11,
          12084,
          11,
          2201,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8626.48,
        "id": 2581,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8625.48,
        "temperature": 0,
        "text": " See you the next week, hopefully,",
        "tokens": [
          51164,
          3008,
          291,
          264,
          958,
          1243,
          11,
          4696,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8628.48,
        "id": 2582,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8626.48,
        "temperature": 0,
        "text": " if not the week after, hopefully, if not,",
        "tokens": [
          51214,
          498,
          406,
          264,
          1243,
          934,
          11,
          4696,
          11,
          498,
          406,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8630.48,
        "id": 2583,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8628.48,
        "temperature": 0,
        "text": " definitely sometime in July.",
        "tokens": [
          51314,
          2138,
          15053,
          294,
          7370,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8631.48,
        "id": 2584,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8630.48,
        "temperature": 0,
        "text": " Stay tuned.",
        "tokens": [
          51414,
          8691,
          10870,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8632.48,
        "id": 2585,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8631.48,
        "temperature": 0,
        "text": " I'll be posting on Twitter,",
        "tokens": [
          51464,
          286,
          603,
          312,
          15978,
          322,
          5794,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8634.48,
        "id": 2586,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8632.48,
        "temperature": 0,
        "text": " if I remember when I'm live streaming.",
        "tokens": [
          51514,
          498,
          286,
          1604,
          562,
          286,
          478,
          1621,
          11791,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8635.48,
        "id": 2587,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8634.48,
        "temperature": 0,
        "text": " Actually, at the Coding Train,",
        "tokens": [
          51614,
          5135,
          11,
          412,
          264,
          383,
          8616,
          28029,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.19024831167659403,
        "compression_ratio": 1.6572327044025157,
        "end": 8638.48,
        "id": 2588,
        "no_speech_prob": 0.011157459579408169,
        "seek": 860948,
        "start": 8635.48,
        "temperature": 0,
        "text": " auto-tweets, at shift-min if I remember,",
        "tokens": [
          51664,
          8399,
          12,
          83,
          826,
          1385,
          11,
          412,
          5513,
          12,
          2367,
          498,
          286,
          1604,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.18684671795557414,
        "compression_ratio": 1.3676470588235294,
        "end": 8643.48,
        "id": 2589,
        "no_speech_prob": 0.0003101522452197969,
        "seek": 863848,
        "start": 8638.48,
        "temperature": 0,
        "text": " and then, what was I going to say?",
        "tokens": [
          50364,
          293,
          550,
          11,
          437,
          390,
          286,
          516,
          281,
          584,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.18684671795557414,
        "compression_ratio": 1.3676470588235294,
        "end": 8645.48,
        "id": 2590,
        "no_speech_prob": 0.0003101522452197969,
        "seek": 863848,
        "start": 8643.48,
        "temperature": 0,
        "text": " And then also I schedule it on YouTube now.",
        "tokens": [
          50614,
          400,
          550,
          611,
          286,
          7567,
          309,
          322,
          3088,
          586,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18684671795557414,
        "compression_ratio": 1.3676470588235294,
        "end": 8648.48,
        "id": 2591,
        "no_speech_prob": 0.0003101522452197969,
        "seek": 863848,
        "start": 8645.48,
        "temperature": 0,
        "text": " Okay, goodbye.",
        "tokens": [
          50714,
          1033,
          11,
          12084,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18684671795557414,
        "compression_ratio": 1.3676470588235294,
        "end": 8650.48,
        "id": 2592,
        "no_speech_prob": 0.0003101522452197969,
        "seek": 863848,
        "start": 8648.48,
        "temperature": 0,
        "text": " Oh, no, I don't hit stop streaming there.",
        "tokens": [
          50864,
          876,
          11,
          572,
          11,
          286,
          500,
          380,
          2045,
          1590,
          11791,
          456,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18684671795557414,
        "compression_ratio": 1.3676470588235294,
        "end": 8653.48,
        "id": 2593,
        "no_speech_prob": 0.0003101522452197969,
        "seek": 863848,
        "start": 8650.48,
        "temperature": 0,
        "text": " I have to do it here.",
        "tokens": [
          50964,
          286,
          362,
          281,
          360,
          309,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18684671795557414,
        "compression_ratio": 1.3676470588235294,
        "end": 8655.48,
        "id": 2594,
        "no_speech_prob": 0.0003101522452197969,
        "seek": 863848,
        "start": 8653.48,
        "temperature": 0,
        "text": " Stop streaming, there we go.",
        "tokens": [
          51114,
          5535,
          11791,
          11,
          456,
          321,
          352,
          13,
          51214
        ]
      }
    ],
    "transcription": " Hello, I am here again, two days in a row! Woohoo! Oh, I forgot to put my cloaking device here, which I will do on my extra laptop, which now has all my ukulele chords on it. I don't see anyone actually saying anything to me in the chat, so I'm not sure if I've actually started or if I'm just imagining it. I'm going to check the patron group here. Uh, looking, oh, oh, oh, people are saying hello to me. Okay, so, good morning. It's not really the morning anymore, it's almost noon. I've got a couple hours here, and the project for today is a TensorFlow.js classification project. So, just to recap, I was here yesterday, and I did a couple coding challenges, if I recall correctly. There was the, oh, let's open them up. I haven't uploaded the code yet, actually, to, but let's just, they were so nice. I really liked them, so let's take a minute to review them. I have a feeling we're going to spend the entire two hours cleaning data. If that's what happens, that's going to be worth it, because that's kind of, I was going to say half the battle, but I think it's all of the battle in machine learning is really thinking about your data. Open recent. Oh, you know, I moved everything. I don't know why I'm looking for this. I just want to run, I want to run these. I enjoyed them so much yesterday. And I'm going to go here. I think I put them in here. What were they? Sandpiles. What was the other one? I don't remember. Sandpiles. What was it? Somebody's going to tell me before I remember, before I forget. Before I forget. Oh, boy. I think my brain is turned off today. This is bad. Oh, Barnsley Fern, that's right. I couldn't remember that. Sandpiles. Where did the sandpiles go? Let's look at the sandpiles. All right, here we go, sandpiles. Let's, let's see. Beautiful sandpiles. Oh, let's do this. You know, while people are taking their time joining here. I'm going to switch the live stream off. That'll probably leave a bias in the rest of the audience. I'm going to make that... Barnsley's Birds, Simon Thomas. All right. Let's see. Somebody sent me, Kay Wichman sent me some chords for Somewhere Over the Rainbow. Ah! I have to provide my email to get a free trial. What if I refresh this page? Here we go. What's E minor? This? ♫ Ooh, ooh, ooh. Okay. All right. So, I'm just getting myself kind of mentally into shape. We've got our sand piles. I meant to zoom in on these. And... Good morning. Hello. Good day. Good day. I wish you good day. I'm not prepared. I'm not ready for this. All right. So, let's check out where we are. Let's get ourselves centered and figure out what we're going to work on. So, I'm going to go to... github.com slash coding train. I am going to go to this crowdsource color data repository. Ooh, there's some new pull requests. Ooh! Ooh! Uh, okay. Uh, and... All right. So, what I'm going to do here is I'm going to go to this page. So, this is where we were yesterday. Ah! And, uh... Many people from the community made some pull requests and changed the design. I think that's brown. Uh, I think that's, like, greenish. Greenish. Greenish. Pinkish. All right. So, this is my crowdsource color data example. What's going on here? I need some tape. Um... Um... And, so, this is what I need. Now, I also need to go to... So, the next video in this, uh, sequence, tutorial sequence, I am going to talk about cleaning the data. And, so, what I'm going to do is actually... I think I'm going to write... I was going to just download it directly from, um... Firebase database. So, the, um... So, I need to talk about the rules that were updated. Um... And, I think what I'm going to also do is I'm going to, uh, turn off writing. So, can I put a comment in here? No. Is there any way to put a comment in... I wonder if this will work. If I change this to false... And then... temp, uh, like... For writing. Publish. Like, will it let me... Error saving rules. Um, oh... So, it needs expect line eight. Expected curly bracket. Hmm... I guess I just need to take this out. Just do false and. How do you know all this, me I am so me? How do you know all this? Uh, okay. So, let's go back to... Write. False. And. So, now... I changed the rules of the database. If I go here, hit refresh, and try to click greenish, great. Permission denied. Alright, so I just wanted to shut off. Writing to the database. Temporarily, I guess. Eh, why not just leave it on? Let's leave it on. That's so unlike me. Let's make sure it's back. That looks bluish to me. Great, alright. So, I need to talk about the data. The data, the data, the data. So, what I'm going to do in this video, and let me get a sketch going that reads the data. So, if p5 TensorFlow crowdsource color. Uh, let's see. Clean data. Let's open up a terminal. I did not sleep well last night. No, no, no. Did not sleep well last night. This evening, I will be attending Harry Potter and the Cursed Child on Broadway. Very excited about that. No spoilers, although I kind of know what's going to happen anyway. Since I haven't read before. What am I doing? Okay, desktop. P5 TensorFlow. No? Oh, I want to be in desktop. This is not boating well. Yeah, p5. There we go. All right, let's go to here. So, I've got Firebase. I've got this. I want to go to here. Closed. I want to reference this one. Okay. And, of course, the camera goes off right now. I don't know why I don't see the YouTube chat. There we go. So, Adam and a half in the chat asks, can we contribute to the crowdsourcing? So, yes. I kind of would say, like, hold off right now. I don't know why. I don't know why. I don't know why. I don't know why. I don't know why. I don't know why. I would say, like, hold off right now as I'm going to use what is currently there for the purpose of today's live stream. But, of course, I'm glad for it to continue to be improved, and then I will come back in future live streams potentially and reference it. Is the sound okay today? I just want to make sure the microphone is not peaking. I suppose I could listen to my own sound. I could listen to my own voice. Just to find out. Test one two. Test. Test. Test one two. I think it sounds fine. Okay. Okay. And so... Okay. And so... So then what I need to do is I want to go to clean data here. And I want to open up the Atom editor. I got to have a workflow day. A day just to, like, redo all my workflow stuff. Clean data. Okay. I'm going to get to some actual content in a moment. Okay. So, let's go to Firebase. Okay. Firebase. Let's go to shift.net. A2Z. Firebase. So, I think I have all the URLs I need. Push call back. I'm just looking for retrieving data. If only somebody would make a tutorial. I mean, I'm not sure I would be able to do that. I'm not sure I would be able to do that. I'm not sure I would be able to do that. Maybe I could. I'm not sure. I don't know. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. If somebody would make a tutorial on retrieving data from Firebase, then I would know how to do it. Hello, Meijer. Thank you, sponsor Meijer in the chat. Uh-oh. I think coding garden with CJ is happening right now. Oh, no. In 30 minutes. I'll be done by then. I'll be done by then. Right? Reference on. Got data. Air data. I think I want once. Right? I just want to use the once function. What did, what did Panzer on GitHub use to retrieve the data? Load data. Then show loading. Where's the load data function? Return database. Once. That's what I'm going to do. Return database. Once. That's what I want. Once. I don't know why I have this on. I want once. Close enough. Okay. Okay. Oops. I've totally lost the chat and everything here. All right. Once value callback is good. Yeah, you know, so me I am so me is asking not just going to export it from the console. So that was my original plan was to export it from the console and then like bring it into a Google doc spreadsheet. And then like, you know, clean it there. But then I realized I think I might actually be better at cleaning it from JavaScript itself. Because what I could quickly do is just like do like a count. I could visualize it. So I think I want to do just the first. So in this series, which is just to kind of remind myself where I am. If I go to the coding train and I go to neural networks and machine learning. I think I am at this point in session 7, which is building a classifier with building a classifier with TensorFlow.js. And so, so far what I have done is I just did I think one or two kind of short tutorials about crowdsourcing the data. And I also wanted to reference somebody. Maybe the Slack channel can help me out with this. Someone in the sent me a message, I believe in the patron Slack channel yesterday referencing a video about research into human perception and color that seemed kind of relevant. Somebody could share that with me again. That would be helpful. Okay, so I think other than that, I am ready to begin. I don't want this to be empty. And so I'm starting with here. I'm moving to here. And then I'm starting with here. Moving to here. Then to here. Then I'm going to, oh, then to here. Here. And then I'll need this as a reference. Okay, I think I am ready to begin. Nobody remembers this research that was somebody, I guess I could try to find it myself. Oh, the World Cup started. I made my picks. Want to hear my picks? I don't want to embarrass myself. And I don't want to cause the chat to go off the rails. So maybe I won't give you my picks. I mean like what do you call those things? A pool? A pool? I mean like what do you call those things? A pool? Friendly, $5. So I don't think I'm going to break the bank here, winning or losing. But I am kind of excited about the World Cup. Ah, okay. It was from Bruno. Oh, first of all, I've got to show this to everybody. Please, please humor me for just one moment. I'm going to go to Twitter. What am I logged in as? Coding train? Notifications? Let's find mentions. Oh, here it is already. This is like my favorite. So if you watched the stream yesterday. Okay, hold on. I need to, first of all, it's weird just that I'm here in front of it. I need to give you the sound from the laptop. Which is not going to come through unless I change. Oh, what a silly world we live in. If I do multi-output device, now you will get it. Okay, ready? I'm going to mute my microphone so I don't talk over this. Oops. Color data should actually be colors. Oops. Color data based on the way I wrote the code. Stop for a second. I need some errors here. Stop, stop, stop. Okay. So apologies for that. Now it's correcting. I made a bad mistake. I called the thing the wrong name. It's in my video that you're watching now. This time it's me just playing the ukulele in front of a green screen. Oh. Thank you, thank you, thank you. Okay. So thank you for indulging me. I really appreciated that Bruno took the time to remix all that insane footage from yesterday. I was doing something more important, though. And I am going to go back here and just put the sound back here. Then, ah, yes. The surprising pattern behind color names around the world. So let me find that. The surprising pattern behind color names around the world. Okay. All right. So coming back to the chat. Okay. Okay. So... All right. Okay. I wore the same hoodie yesterday. Have you not noticed that I just wear the same hoodie every day? I do have two of these, though. One says 2017 and this one says 2018 because this is the current ITP camp hoodie. And I was wearing this one yesterday. I also have some emergency hoodies here. Ah! Like a unicorn one. This is the old Coding Train branded hoodie. There's a new one that's in the store now. Anyway, I don't know. Let's get started here. Let's cycle these cameras. Definitely going to need to do some whiteboard erasing and using. All right. Hello, I'm back again in my, I think it's the third. I can't keep track of this stuff. So building a classification example using a neural network and TensorFlow.js. So where I last left off, which was actually in realtime yesterday, even though you might be watching these in sequence, I built this simple web app to crowdsource color classification. And the wonderful internet pull requested a bunch of nice features. And so you can see this right here. I'm just going to say this one looks greenish. And, oh, look at this. I'm just going to be grayish, reddish. So I'm adding some data. Purpleish. So thank you to all the people who you can check the GitHub repository in the commit history to see everyone who submitted a bunch of these changes to improve the visual design. Now, unfortunately, I made a little bit of a mistake, which is that, I don't know, a mistake, but I left the database, the Firebase database, completely open. And I thought, why not? It's going to be easiest. I trust you, the viewing audience, to not mess with the database too much. But it went off the rails a little bit. And so I want to thank. I'm totally going in the wrong order here. Let me start over. But maybe it doesn't really matter. I also didn't like that a sort of like color that I couldn't see came up. So let me just start over. Choose one. It's not super important in the end. I don't know. Oh, are you all talking about Adam? You know, here's the thing. When people tell me to switch to a different editor because it's better or cooler or more current, that usually has the reverse effect on me. I'm like, no, no, no. I'm going to stick with my editor because the point is it doesn't really matter so much. Although it kind of does matter. But let's not discuss. All right. Hello, welcome to the third video in my build a classifier with p5.js and TensorFlow.js. And there's a neural network in there. So I'm really exploring this machine learning library TensorFlow.js. And I wanted to come up with a creative example that shows the full classification process from collecting data, training, and then deploying a machine learning model. And so the example that I'm working with is this idea of color classification. So I'm crowdsourcing this data from you, the viewing audience. And if I look at this, so you might remember I built this little web app in the previous video, I think. That was yesterday. And then now it's today, 24 hours later. It's been improved. Thank you to the internet, the wonderful people who have pull requested various design fixes and updates. You can check all that out on GitHub to see who the contributors were. Now, let me add a few things here. Brown, that's kind of brown. That's purplish. That's bluish. Now, one thing I will mention, thank you to Bruno who brought this up in the patron Slack channel. I sort of said yesterday, you know, I just want to pick a trivial data set. I want to make something that's not, that has very little sort of like meaningfulness to it just to sort of demonstrate the whole process. But there is something kind of interesting going on here in theory, which is that we're looking at human perception. And I'm not mathematically calculating, like labeling a color according to the RGB values. I'm asking you, the viewers, to tell me what you think a color is. And so there is a lot of interesting scientific research in this area. And I'll reference this video that talks about Berkeley researchers and other research around the surprising pattern behind color names around the world. So there's a lot there that you could dig into. So maybe there's more here than I might originally have thought. The problem with what I built over here is that, you know, you're wonderful. I love all of you who watch these videos and leave me nice feedback, leave me critical feedback and all that sort of stuff. But the database is a little bit off the rails because I just left the rules wide open. Anybody can write and anybody can read to the database. And so, thankfully, Panzer on GitHub left a pull request analyzing the data and looking at kind of like, OK, well, there's a lot of stuff here that looks wrong. Maybe there were some bots that started classifying colors. And so I wrote all these functions to analyze and filter the data. So I encourage you to check out this wonderful pull request. This pull request is now part of the repository. However, I took a slightly different approach, which is, and thanks to me, I am so me, who helped me with this, which is that I changed the rules. So the rules yesterday were just basically read true, write true. These are the Firebase rules. And me, I am so me helped me look into how you could customize the rules. And the things that have been added to the rules now are we have some things to validate to make sure the RGB values being put in the database are actually numbers. So you can see how this looks here. New data is a number and it's between 0 and 255. We have something to validate that the label, you know, one of the things that people put other words that weren't part of my set of classification labels into the database. So I have to check that it's a string and that the actual data's value matches this regular expression. So if you've never seen regular expressions before, I do happen to have a video series about that that you could go watch. But this, you can see that it matches any of these dash-ish. So that's protecting. And then authentication was turned on. So what you don't see is that it's anonymous authentication, but you can only write if you've been authenticated. This way, it's anonymous. I can track every person or every entry. It's not necessarily a person, but every entry from a particular IP address into the database with a unique ID. So if I can see that there's a bot that's just flooding the database, I could either block it or just like clean that data out of it. So that's what I'm going to do in this video. I'm going to use a similar approach to this pull request. I'm going to actually read the data from the database, and then I'm going to analyze it and delete stuff if it seems like it's no good, and then download a JSON file that I'll then use in the TensorFlow.js example that I'm going to build. Did I just spend the whole video introducing this topic? I think I might have, but I'm going to move on and keep going anyway. Pause. All right. Please, please be nice to each other and don't argue about IDEs in the chat. Just for once, one day, could you just say like, your IDE is great and so is mine. Isn't it nice how we use two different ones and maybe we could learn from each other? That could be a thing, right? And of course, I forgot to reference this, which I wanted to do, but that's okay. I will come back to that. The next thing I need to do is actually start writing the code to look at the data. I should probably turn off. Now I should set the thing to false because I just don't want it to. I think I'm going to set it to false right now. Just so. I'm just setting it to false so if you're watching this live, you currently can't submit any more entries. I just want to have it be fixed while I'm doing this. And then this. I can close this. Oh, I should leave Firebase open. It's fine. It's fine. And then this, I want this to say clean data. Wow, the chat is so quiet today in this. Thank you, Fuji, for repeating my words exactly. All right. So I think I'm ready to do this now. Oh, shoot. Oh, my goodness. There we go. Before I dig into the code, let me just reference one more web page to you. I want to show you this is a project that's at the time of this recording. It hasn't technically been released yet, although you can find it at ml5js.org. And it probably has a link to it. But I want to show you this. This is a project that's been working for a while. It's called the ML5JS. And it's a project that's been working for a while. And it's a project that's been working for a while. So it's called the ML5JS. And it's a project that's been working for a while. And it's entirely new to companies now and is nowhere near as plugged right now become this software. And, of course, some companies are looking at making the market more comparable to other productionized problems and in some diplomatic areas. So it's the project they're working on, but I don't know which team. But they put it together. It's an minicomponent of their framework. It's a 제� książ ͡° I'm going to come back to this topic again and again in my video tutorials. But I would encourage you to check this out and really think about it. One thing we could think about here is, number one, I'm building an example that requires people to see the colors. So what about people who are colorblind, low vision, or blind? That's something I really should be thoughtful about in this example. How can I approach that? And then who's really able to participate in tagging and submitting data? Who's being left out? So I think the good news for me is that this is meant to be somewhat of a generic tutorial and the data, wow, doesn't matter so much if it's perfect, because I just want to show that whole process. But you then actually being a person who might work with machine learning out in the real world, you really want to be thoughtful about that data. And I hope that I can link to more resources about that and cover that more on this channel as well. So all that aside, now I'm ready to dig in and look at the data and do the thing that's probably going to take me the next 24 hours or three days or three weeks, try to clean the data and make it usable for me. So yeah, that's what I'm going to do. Okay, so I have a client. I mean, I could do this. I could download the data directly from Firebase and just put it in a Google Sheet to look at it. That might be useful. But what I'm going to do is I'm just going to actually write a p5 sketch or just a JavaScript program to look at the data first. So I have this sketch. All that's in it so far is just that connect to Firebase and authenticate. So what I want to do is to retrieve data. I think I say something like database once, value, and then I have a callback like got data. I don't know if this is right. And by the way, I've learned that the JavaScript recently, the JavaScript convention, which is not how p5 necessarily works, is often the error is first as callback arguments and then the results is second. I don't know. I'm just speculating what the Firebase API might be like. Let's see what happens. Database once is not a function. I probably need.ref and then I probably need like colors or something, right? It's probably something like this. I could just go and look on the documentation. I also have this Firebase tutorial. Oh, yeah, I need the database reference and then in my tutorial I say.on, but really, oh, got one and got error data. So maybe there's two callbacks. Who knows? Who knows? Let's do this. Let ref equal database ref colors and then let's say ref once value got data and let's look and see what comes back. Let's go back to here. All right, something came back. No, nothing came back. 19. Oh, no, 18. This is... Hold on, time out a second. Take a break for a second. I mean, like, now that I have consistent video editing, I really, I really, I truly have a very different world which is like I just need to take a break and edit it out. I used to do that and never edited it out and I also couldn't take breaks. Not that I'm taking a break. I just need like a mental break. All right, what's going on here? Maybe I should go back and look at my actual example. Got one, error data. So let's... Oh, that's a pointer to the data, right. So actually the data, so it actually is a separate callback for error. Looks like. So I'm going to like not worry about the error callback right now. I'm going to use got data and then let's look at the results. And so, yeah, this looks weird. Like how could I possibly use this? So what you're actually getting back is like this pointer to the data. You've got to call functions on it to actually look at what's there. Presumably something like results.value is probably what the API is. No, it's not a function. So I have to go back and look at my tutorial..val, let's try that. Let's try.val. And there we go, look at this. Oh, it's a lot of data. Boy, the console is not able to render this. So now, is this actually an array? Ah, it's just actually an object with all the data in it. So I need to turn that into an array. Because I kind of want to loop through it. I wonder what the, oh, you know what I'll do? This is what I'm going to do. I am going to, so now I'm going to process the data. So first, let me just get all the keys. So I can say objects.keys. So let me just say let data equal results.val. Let's not console log that. Object.keys.data. And then console.log keys.length. And I don't need this page anymore. I'm going back to here, clean data. So there's 5,902 entries into the database. This is never going to change, because just while I'm recording this video, I shut off the ability to write to the database. OK, so what we can actually start to do now is I could say for let key of keys. And I could say let record equals data key. And I could say console.log record. So this is going to log all 5,000 of those one at a time, I think. So I can see these are all, it's just logging every single data point. And we can see that for every single one, there's an R, a G, and a B, the label, and then this user ID. So now I think there was, I'm watching the database this morning, I think there was a bot that was posting to it. So now it's possible it could be that there's just one person who actually clicked a lot of times. But what I'm going to do right now to just examine the data a little bit is I am going to look at the user, by user ID, and count up how many entries for each user ID. So I basically need to do something like a concordance. So if I say UID, if I look at that, we can see there's all the user IDs. And what I want to do now is just associate, so I'm going to just say user ID by count. And I'm going to say is an object. I'm sure there's all these higher order. I'm sorry, I'm looking at the chat. Pause for a sec. Oh, I could have just done let record of data. Yeah, the of works for an object, not just an array. Okay, interesting, interesting. Oh, pause for a second actually. The chat just gave me some good feedback, which I actually, I guess the for of loop will work with an object, not just an array. So I can actually just say let record of data. And let me just do this. No, that didn't work. Data is not iterable. Let record in data. All right, edit that out. Yeah, object on values. Yeah, it's fine. I'm going to do it my way. I'm going to keep going. All right. Me, I am to me, you've saved me so many times that you can do no wrong. All right, data record. Oh, right, I could, anyway. I'm going to do it my way. This is all about learning. I'll do it my way, you'll do it your way, we learn from each other. Okay, so what I want to do is I want to say if user ID by count of that, so I need the ID, which is this. If user ID by count ID, it does not exist, then I want to set it to one. Otherwise, I want to increase it. And then I want to console log that. So let's look at this should give me all the user IDs. By how many people, by how many entries they have. So we can look 35, 33, 78, 147, 208, 189. What's the record here? 201, there was something I've already forgot, 236. So what's this? Is there anything suspicious here? That's the question. Let me think about this. Do you remember the user ID of the thing that we detected was probably a bot? I should sort these. The problem is it's in an object, not an array. It would be really easy to sort them if I made it into an array. I guess I could have the keys, I should sort them. Let me sort them. All right, it's probably worth me sorting this. This is why I should just put everything into a spreadsheet. But I'm just going to sort it myself. In order to sort it, I want users. I'm also going to have an array that I'm going to sort. If I find a new ID, I'll put that in the array. Then I want to say users.sort. Now I need a comparing function to compare two of them, A, B. I'm just going to say return user ID by count A minus user ID by count B. That will sort the array. Sorting probably makes a new array, I think. I can't remember. Does it change the array or make a new array? I want to sort the users array. Then I'm just going to do let ID of users. I'm just going to iterate over the array. Console.log user ID plus user ID by count for that one. I know I'm kind of like, whoops. This would be a good time for me to use those new string literals. Someday I'll get to that. Let's take a look at this. What did I get wrong? It looks like I did. That worked. Amazingly, that worked. We can see somebody just did one. Thank you. Thank you, Noah who did one. Then we can see here 236 entries from this particular user. Sort is in place. Okay. Which one is the bot? FPQ. This one. Interesting. Interesting. Okay. Template strings. Not template literals. Ah! All right. These, by the way, are called template literals is what I meant. By the way, since I mentioned it, let's actually use it. This is a new feature of ES6. I'm here. Why not? Where if I use back tick, I can create a string that's just with variables with this syntax, I believe. Does this go out here? Yes, that goes there. What this does is, in other words, I could say user submitted. I can just write a full string. Then basically anything that's in between these dollar sign and curly brackets is rendered as a variable value. Now if I run this, again, I don't know why that didn't. Yes, you can see now it has that full. I kind of don't want all this extra stuff. I'm just showing you that you can put together a string. Okay. I happen to know, based on earlier research of the day and watching, that this particular user is a bot. I am getting the suggestion from the chat to just discard anything that's over 100. It looks like this. Those are ways that I could do this. Boy, I'm just stopping and starting like crazy. I'm very sorry, Amatia. It's 1230. I'm just thinking about the time today and what to do next. I'd really like to visualize this data. I think that would be interesting. Yeah. Both changes the array and returns a new one. Okay. Another correction I just got is that I believe users.sort actually changes the array. Since I started using arrow syntax, I could write it this way, which is perhaps a bit more readable. Who knows? Okay. Here's the question. What do I do to clean this data? One thing I could do first is actually analyze it. I'm going to go on to a new... My brain is so faulty today. I'm going to go to the next... This was long enough, so I'm going to do another part. All right. So the question here really is what to do next. I know that this, from my analysis earlier, looking at the things being added to the database, that this appeared to be a bot. I also could, the chat suggested I could just remove everything. That's 100 or more. I'm actually going to stop this tutorial. This was sort of like getting to actually be able to look at the data. And I'm going to do a whole next video, because what I think might be useful is actually just look at the data. Because this is information I can visualize. I could say show me everything that's pinkish. Show me everything that's bluish. And I could also say, like, ignore this. I could see by user what they... I could actually look at what they assigned. I could try to see if something is really just way out there that maybe I shouldn't include. Okay. So that's what I'm going to do in the next video. I'm going to add some tools to visualize the data. And just while I'm... In case it was mentioned, I apologize. The reading of the database is open. So while you can't write to it right now, you can read from it. And so if you want to use this code, this code is also on that GitHub repo. If anybody wants to try, like, messing with it themselves, they can. Okay. Okay. Okay. All right. Cleaning my data part two. That's where we are. Where I last left off previously on cleaning your data. Whoa, the suspense was killing you, I know. I had just retrieved all the data from Firebase. And I looked at it by anonymous user ID. How many entries had been submitted by each user. And I have a suspicion that some of these that submitted a lot of entries maybe wasn't actually a person doing it manually. And maybe, like, a bot or something flooding the database. So let's try to investigate that and see what we can figure out. So the first thing I'm going to do is I'm just going to visualize the data. I could visualize it by user ID. There's so many things I could do. But let's think about it. So there are how many labels? So let me think about this. Okay. This is my sketch. I know what the labels are. So let me just set up a variable called data by color by label. And this will be an object. And the object will have empty arrays for each one of the labels. So there was blue-ish. I should have a list of this somewhere. Green-ish. I'm doing this manually. I could have actually pulled the labels from the database. But this will be simpler. Green-ish. Pink-ish. I'm not doing this in any particular order. Gray-ish. Red-ish. What am I missing? Purple-ish. There was a brown-ish. If I go to my crowdsource color. Reddish, greenish, bluish, orange-ish. Did I do orange? I don't think I did orange. Orange-ish. Purple-ish, gray-ish, brown-ish. 1, 2, 3, 4, 5, 6, 7, 8, 9. I'm missing one. Blue, green, pink, gray. This is not a very systematic way to do this. Red, green, blue, orange, purple. But yellow-ish. I didn't do yellow-ish. Yellow-ish. Now, while I am looping through the data, which I did in the previous video. And I'm going to not worry about this users by count thing right now. I'll come back to that. Ah, shoot. I'm going to not worry about this users by count thing right now. I will come back to that later. What I want to do is... Oh, sorry. I do want this. So I want to look at each data point. And I'm going to do that. And I'm going to do that. And I'm going to do that. And I'm going to do that. And I'm going to do that. And I'm going to do that. And I want to look at the RG... So I want to look at the label. And I want to say color by label. And then I want to record.label. Push. And so I'm going to create a color. Let color equal... I'll use the p5 color function to say record.r, record.g, record.b. Color by label, push color. And now what I should have... And I'm really risking breaking the console here. Is I should have all the RGB values listed by the label. So let's look at that. Oops, I'm in the wrong sketch. Right? So we can see there's a thousand blues, sixteen... There's only two thirty-five grays. So one thing that's also important about what I've done with my data set here... Is I don't have a uniform amount of data points by label. I have many more green ones. And actually Eric in the patron group made a point that the way the colors are picked... The way my random number generator works... You're going to be more greenish looking colors. Which is sort of interesting to think about. But at the very least what I can do now... Is I can just draw all of the colors. So I'm trying to think of what... I probably want to do little rectangles and a p5 canvas maybe. So let me add create canvas. And let's make it 400 by 400. And let me... Let's do just one. Let's just start with a bluish. And I'm going to say a four. Let i equal zero. i is less than... So let's see. I'm going to say let blues equal color by label blue-ish. And I'm going to look at all those. And let's start with an x. Let's start with a y. Let's say fill. Blues index i. And then let's draw a rectangle at x, y. That's 10, 10. We'll increase x by 10. And if y is greater than or equal to width... Then we will reset x back to zero. And increase y by 10. Now this is invariant. Again, I'm not being that thoughtful about this. But in theory... I should see now when I run this... All the blues. Why did it not wrap around? Oh, if x is greater than width. And I want to say no stroke. And I could sort... I probably would want to sort these too. I could sort them by brightness. So we can see here... Ah, look at this. These are all the blues... That were submitted to the database. So, you know, I kind of don't mind... That the data has some noise in it. I mean, big deal. The point of this is to crowdsource it. And maybe training the model... If there's enough data, it will sort of filter out the noise. But, you know... And the question is... Why is this here? Why is this here? What should I do about that? Let's just look at some other ones. Let's look at red. You can see... Okay. What's interesting is... I think these are in the order by which they were submitted. So there probably was a time period here... Where... Where... There probably was a time period here... Where some bad data was entered. Let's look at green. Because green has the most, right? That's pretty good. So what do I do? Oh, boy. What do I do about this? Thinking pause for a second. Oh! Oh, that's such a good idea. Me, I am assuming, has a great idea in the chat. Right. Oh, that's a great point. Luke makes a great point. Alright. So two great points just came up in the chat right now. One is... Luke B. writes... Pretty good to have the outliers to encourage prevention of overfitting the neural network. So this is actually true in... You know, one thing you have to watch out for is that your... Your model... The model that I'm going to train to do this color classification... What if it just works so well with the training data that it doesn't work so well with new data? And having a bit of noise in the training data can actually help with that. Another... Me, I am assuming, writes... Make it so clicking on a pixel prints who did it. The user ID, that is. And also maybe highlights all the other ones with the same user ID. That I love. So let's add that. That's going to be... That's not going to be the easiest thing, but it's worth doing. Let me see if I can add that. So... Okay, so... If I click the mouse... Mouse pressed... I can... I can... I can sort of... Like, I would be... In theory, mouse X divided by 10. And J would be... Right? This is where I'm clicking. I'm looking for the I and J. Not the X and Y. Not the X and Y. Sort of like the I and J of what I'm clicking on. Mouse Y divided by 10. And then I should be able to get the index then by saying... I plus J times... And then the width divided by 10. Again... I really, really, really should be using variables for these numbers. Like 10. And putting in... Like variables for columns and rows. But let's just try this right now. Let's try then saying console.log. And so let me make a... I'm going to call this... Color... I'm going to call this, like, label. I'm just going to call this label. And I'm going to... Let's go with bluish to start again. So I'm going to use here... Color by label. Label. And let's make color by label... Color by label already is a global variable. So I'm going to say console.log... Okay, so... Let data equal color by label. That label. And then I should be able to console.log... Data. Index. I think this will be right. I might have made some mistakes here. Let's see what happens. Alright, let me click here. Alright, so I got something. Oh, ugh. So one thing that's kind of unfortunate is... Oh, I don't have the user ID. Ah, I don't have the user... So I got the color... But I'm not actually storing the full data thing. Oh, yeah. So color by label. This is what I need to do. I want color by label actually to store the whole record. We don't actually want to store the color. Let's store the whole record. Then when I visualize it... I can just ask for the RGB values. Because then when I click on something... This is now that entry. So I can see... If I click on this... Look at this. This user... I'm clicking on these. They're all the same user. This user YGDQ seems to have some faulty data. So I could filter out this user. I could do something nice where as I'm hovering, I highlight everything. But I think I'm not going to go that far. I'll let anybody who wants to contribute... I'll let you try that on your own maybe. So let me make a list here of users that I might want to filter out. Whether I'm happy to have the noise or not, that's a question. But let's... Let me just make this a little smaller. It's a little harder for you to see it, but I think it's going to be easier in terms of space. So let's look at a few more that are maybe clearly not good. Same user. It's all that same user. I haven't found the... Let's look up here. Ah, different user. So this user also looks like it maybe has some bad data. Oops. Let's look at a different color. Let's look at what was like there was very little of. Grayish. That's... This user is now suspect. You know, the thing is, a user might have misclicked. So unless I see it consistently... Yeah, I'm not going to... A user could have misclicked. Alright. So you get the idea. Okay. So... You get the idea. Now, there's so many ways that I could be more thoughtful about this and add more features to work on cleaning the data. But let's just say for right now... And people are suggesting, like, I could algorithmically... I could actually evaluate the numbers and see... Like, compute the hue and see if the hue matches the label. But I don't... I specifically do not want to do that. Because what I specifically want from this is this idea of human perception of what's going on. What I specifically want from this is this idea of human perception of color. And I don't want to use math. Because I could create my own data set with math. Of, like, putting colors into certain buckets. And in a way, I don't even want to do what I just did right here. Which is eliminate certain users. And I probably should just visualize... What I should do with these users now is... Actually, let me do this. What I'm going to do with these users now is I'm actually just going to look at all of their entries. And see. So let's add that as one more thing. You can stop watching this video and just go on. Because I'm going to build a machine learning model in future videos. But if you want to keep watching, I'm going to do... Let's do one more thing. Like, let's take this user. And what I'm going to do now is... I'm going to comment out this drawing thing that I'm doing. And I want to create a... I want to say color data by user. And I'm going to make that an array. And I just want to say if record user ID equals a particular user... Then I want to say user data. And I could build an interface to do all this. It would be so much better. But I don't really have time to do all that in this particular series. So that might be an exercise to do for yourself. User data dot push the record. And then down here I could use this exact same algorithm. But you know what? I don't want to do it this way. What I want to do... I'm going to use DOM elements now. I think I'm going to say for let... Color for let entry. So entry of user data. I'm going to say create div. I'm going to just make a div. And then I'm going to say... Div... And actually let me create a div with entry dot label in it. So let's just try this. Whoops. Not the string. And let me get rid of the canvas. So these are all... These are all of this particular user's entries. Maybe I should sort them by... Let's sort them by the label. So let's... So let's say user data. Sort a comma b. Return a dot label greater than b dot label. So this is... Whoops. Oh, and I don't need to say return if I use the arrow syntax. I'm really just off the deep end here in this video. I'm going to... I think this is right. That should sort it. Yes, there we go. So we can see now it's... That's weird. Just pausing for a second. There's a great comment in the chat from Sam D. Could we separate out the different things into functions by color, by user, by whatever classifier, rather than commenting out lots of stuff? Yes. This would be an absolutely great thing to do. So I'm going to publish this and I would love to get user comments and user submissions of like making a nice interface for this. But I'm trying to figure out why it didn't sort this right now. Let's see. I thought... Sort... Oh. Oh, I have to return zero. I can't return true or false. Compare... Okay. Oh, because these are strings. Yeah. Yes, yes, yes, yes, yes, yes, yes, yes. Okay. These are strings. So this is going to give me a true or false, but the sort function wants like a negative or positive number. So I'm actually just going to break this out. So I could do this with those ternary operators, but I'm just going to say if return one, else return negative one. And this should do the trick. All right. So let's take a look at this now. There we go. So we can see this is now sorted by that particular user. And then all I need to do is add... Boy, I need to make something that color box... I guess I could make that a div that lives inside. Color box size, 10, 10. And then color box style. And these are all p5 DOM functions. Background color. Oh, now this would be a great time to use those template literals, because what I want to do is say RGB. Entry. Entry.r. Entry.g. And... What happened? Entry.b. Right? This is CSS for making an RGB color, I believe. Let's see how this works. What's the chance this works? Ah! Okay. Oh, but now what I want to do is say... Color box parent. And I want it to be inline. So how do I do that? Color box style display inline. Is that what it is? No? Well, you get the idea. Some of these, as you can see, is pretty inconsistent. The colors are just so wildly different that I think we can kind of say that this user we can filter out. And I could look at some of these other users now. Like, let's look at this user. Where did I... Let's look at this user. Everything seems to be bluish. That doesn't look like great data. And let me look at this user. And again, I'm doing this so manually in my code. I could easily build an interface to look at all this. Grayish, grayish, greenish, greenish, brownish, bluish, bluish. This looks too inconsistent. So, you know, it's fine to have some... So I think we're done here. You get the point. We're not completely done. Because I want to just create a JSON file of all of the data. And I'll do that in the next video. Because I don't know if anybody is still watching this right now. So... Right, I could add some background to the text and some padding. There's all sorts of ways I could visualize this. If I had any sort of talent or knowledge about CSS and design. But you, the viewer, will hopefully improve this. But you can sort of see the process of looking at the data, visualizing it, and getting a sense of it. And now what I might want to do is actually, like, filter and save the data. And I will do that in the next video, which will be a very short one, I think. Oh, I forgot to check the bot. Let me check the bot. How come I don't have the bot here? Let's do this real quick. Which one was the bot again? This one. What a mess. What a mess I'm making of all this. The bot's not so bad. The bot actually has... The thing I thought was the bot has good data. That's really interesting. The thing we thought was the bot seems to have good data. My apologies to the bot. It was the thing I thought was the bot. I mean, you know, you could make the argument that some of these might not be exactly right. Oh, it's only doing... No, it's got pink and orange and purple in there. That's not a bot. So I was wrong. So the reason why I thought it was a bot was because the moment I wiped the database, I wiped the database at one point, then I just saw consistently at, like, very distinct intervals, entering stuff in really, really fast. Could have been a person. I'm not sure it's a bot. And it looks like it's generating the data with a hue. So maybe this data is too good. Anyway, I'm not going to worry about this too much. I've got to move on. Also, it's 1 o'clock, so I only have about 45 minutes. Yeah, some of those are, you could say, are greenish. Oh, and I'm out of my caffeinated beverage, which is really bad. Okay. All right. So I'm going to let this be. I'm going to let this be. And now I'm going to make a new... Whoops. No. I'm going to just make a new sketch called Download Data. And... Download Data. So what do we think? Should I keep this one or... Sort the entries by their key. Oh, that's interesting. That would be interesting to do. Ha. So I am now going to go to Download Data. And I'm going to get rid of all this stuff. So I just have... The stuff I had from before. This should actually be an object. This should actually be an object. Okay. So my question is, should I filter all four of these? Or should I leave that bot one? That one we think is a bot. Are you out there? Are you out there, person who wrote the bot? Or human being who wasn't a bot but actually was clicking? Stillion writes, is Dan actually reading these comments? Every once in a while I am, yes. So let's just say we want to filter these out. That's interesting. Simon has an interesting suggestion to say to filter the noise out, you can calculate the average for each color, and if the distance in between each color and the average color is greater than some threshold, you can filter it out. So I'm going to... The bot is good. Keep the bot. Alright, people are saying... It doesn't really matter. In the end, the point is for this tutorial series, for me, is to just show the process. And I'd like to do the process in a reasonable manner, but if I can't, I can't. Okay. Alright. So now... Here we go. Uh... Okay. Okay. Oops. Where's the bot? I felt like I needed to do a... Dedicate a song to the bot. F, P, Q, S, D 6, C, V, N, F Q, M R, P J, D, D, I, Q, J, M, 3, 2 Thank you, bot. I don't know. The ukulele was a bad idea. Alright. Let's move on. I'm going to cycle those cameras.......... Will I get to TensorFlow.js today? Seems unlikely. Seems unlikely, but not impossible. Not impossible.... Oh, hello. I'm here, part 3 of cleaning the data, supposedly. It's a lot of work. Just dealing with data is a whole project unto itself. I've been here for like 72 hours straight, and I haven't even looked at TensorFlow.js yet. I'm just looking at my data, and all I'm doing is color classification. Alright. I kid, I kid a little bit, but it's true, it's true. So this is the third video. If you watched the previous two, I started trying to visualize what the data looked like and kind of examine are there certain users that I should filter out that's bad data. Maybe I should just leave it all in there anyway. I'm trying to build a model that looks at a color and classifies it into one of these buckets. And this is my crowdsource system that allows people to look at colors and click on one of these buckets. So this is a little bit about human perception. What does the eye sort of see in terms of RGB color? Alright. So the code base that I'm starting with is from the previous video. I'm just connecting to the Firebase database, and I am looping through and looking at each record one at a time. Each record has a user ID, which is anonymous. It has an R, a G, a B, and a label. So I determined, you know, not somewhat loosely, I really needed to spend more time and be more thoughtful about this. There's an extra comma here. That these are the three users that I would like to filter out. So what I want to do in this video by the end of it is have a JSON file that I can print if I wanted to. I'm not going to print it. Hold in my virtual hands. These are my real hands. And use that to actually build a machine learning model from. So all I need to do if I want to filter these out is what I did is I made an object that just has those three user IDs as keys arbitrarily with a value of true. And then what I can do is I could say if filter does not include this record's user ID. And so let's just say let ID equal record user ID. If it's not in the filter, let's make a, let's say all data is a big array. And actually what I'm going to do is I'm going to make it an object. You'll see why in a second. That has, I'm just going to call it like entries. Which is an array. Then I'm going to say all data.entries.push that record. So what I want to do is I want to look at every single data point. And again, there's probably some nice higher order function I could do this in one line of code. But I'm doing this very manually. I'm going to look at every record. I'm going to check the user ID. If as long as that isn't one of my user IDs that I'm filtering out, I'm going to put it in my all data.entries array. And then I'm going to say save JSON color data.JSON all data. Now this is a p5 function that will then put this JSON file into my downloads directory. And I could be doing this in node and server side. There's no reason for me to have client side code doing this. But that's what I'm doing right now. So let's run this and see what happens. This is my download data script. A index of is not a function Firebase. I don't know, save JSON. Okay. So this maybe, let's look at, maybe it actually goes like this. The data and then the file name. I think that's what it is. Yes. There we go. So I have right here this downloaded. Now I can take a look at this file. I can open that file up. And we can see, there we go. Here is my data set. Hi, this was the shortest video ever. So now I have this data set. Do I want to, so things that I need to do is I need to normalize the data set. And I need to assign the labels numeric values. Because I'm going to need that for what I want to do with TensorFlow.js. Hmm. So I think I'm going to need to reshape the data. And turn it into tensors. I'll do that in the next video. I might as well just keep sequencing this. So, you know, maybe you could be more thoughtful about, I don't know, I'm trying to give you an exercise to do at the end of this video. I got nothing for you. But you could build an interface for this where you could, maybe you could port this to like a server-side script. Maybe you could save it to a CSV file. Those are some things you could try. But in the next video, what I'm going to do, I'm going to actually start working with TensorFlow.js. I need to turn all of these things into tensors. Because tensors are the thing that I need to create, to train my machine learning model. Whew. Goodbye. Oh, wait a second. No, did I get the removed ones by accident? No, I don't think so. No. No, these are the not removed ones. Ah. I did something in reverse here. All right, let's see. Did I? I think if it's not there, add it. I think I'm okay. Let's, let me not save the JSON file again. Yeah, 5, 6, 4, 3. I think I'm good. Oh, the bot. Yes, the bot is in there. Yeah, I got it. I got it correct. All right. I'm probably going to be coming back on Monday to finish this. Go watch Boarding T with CJ. It's on YouTube right now. I'm getting a notification. 112. I'm running out of steam here. Boy, this is a lot of work. Okay. So now. Now what I need to do, desktop. I'm looking for P5 TensorFlow. Color classifier. So this is now. Oh, I need to. Now I need to. Get myself a reference to TensorFlow JS. No more Firebase. Color classifier. And. Then I need the JSON file. And. Let me rename this to one because I might kind of save it. The source code with each one. Okay. Okay. Don't overcharge my laptop. Oh my goodness. Okay. So what's next here? Let me erase the whiteboard. So many things to discuss. I've got to talk about Softmax, cross entropy. These are new concepts that I haven't used in any video before. One hot encoding is something that I'm going to want to discuss. My plan in my head is to make a ML5 version of this. In which you don't have to architect the model. And you also don't have to worry about the one hot encoding. I realize most of you watching this probably don't know what it is. I didn't know what it is until very recently. And I'm not even sure I know what it is. But I think I know what it is. So I'm conflicted about how I'm doing this. Because I'm all in a sort of strange order. But it is what it is. Okay. I definitely want to do some more TVEX stuff. Yes. Matthew Cohen in the chat requests, suggests. Okay. Okay. All right. This video merits a train whistle. I am in my series. I'm on video 731. Or something like that. About building a color classifier. I'm trying to look at the overall concept of machine learning. And building a color classifier. So where am I? I spent a bunch of videos crowdsourcing and cleaning data. And where I left off, I have this JSON file. That has a whole bunch of data points in it. Each entry has an RGB value and a label. So there are nine labels. And there are obviously millions of possibilities for the RGB values. So what's the next step here? So many things to think about. Let's go back to this tutorial that I referenced. That's part of the ML5 project. Called making your own data sets. This is by artist and researcher Hannah Davis. And other contributors who may have also edited this page. But it started with Hannah Davis. I'll link to information about her in this page in the video's description. Now one thing you want to look here that I think is important. Is preparing your data set for machine learning. Trading, testing, and validation. So I forget. The first thing, let me do something first here. Let me actually write some code, strangely enough. And I've got P5 loaded up here. As kind of like a base JavaScript library that I use. And I'm going to add the preload function. And I'm going to say let data. And I'm going to say data equals load JSON. And it's called color data dot JSON. So I just want to load that file. And then I'm going to say console dot log data dot entries dot length. So let's just see how many data points do I have. Let me make sure I can indeed load that file into my code. And look at how many data points I have. So here we go. Oh, I'm in the wrong sketch. I changed it to here. 5,643. I can read numbers. Is that number perhaps? Perhaps that number could be found somewhere in my random number book. But that's a, I'll look for it later. So okay, why did I say that? So if we come over back to this page that I was referencing. We need to, if I'm going to build a classifier, the way I'm going to do this is by having training data and testing data. Now, there is also something called validation data. Let's go look back at this web page. Training data set is used to train the model. Validation data sets are used to change the parameters of the model. So I'm going to, for the purpose of this video, kind of simplify by not worrying about validation data. And I am just going to use training data and testing data. And the idea here is that what I want to do is train the model with my training data. But then I want to feed it the testing data and see if the labels that it returns, oh, it thinks this color is bluish, is that actually what it is labeled with? And I'll get some type of accuracy score from that. And I'll know more about, I don't want to test it with stuff that I've trained it with, because of course it's going to ultimately get that right. Machine learning models are very good at returning the result that you tell them about. And we need to see, does it also return the result of new data that it hasn't been trained with? If it works really well with the training data, but not with the testing data, this can be known as overfitting. Meaning the model is just incredibly good. It's so exact that it doesn't really know what to do, except for the exact data that it was trained with. So this is what we want to watch out for. And a kind of convention, let's say I have 5,000 data points. A convention might be to use 80% of those. So 10% is 500, so like 4,000. 4,000 is 80% of 5,000 I think. As my training data, and then save 1,000, or 20%, 1 5th as my testing data. Alright, so I need to at least at the beginning right now, divide it, and I might just sort of pick randomly to divide it up. Okay. What I like is that when I switch cameras, I can easily have like a little break for a second. Not easily, but I'm going to cycle these, because I don't know when I last cycled them. What time is it? Oh, 1 20. Okay, I'm going to be here another half an hour, and then I've got to go I think. So the question though is, the thing that I need to figure out is, should I split up the data before I convert it to tensors, or should I convert it to tensors and then split it up? Anybody have an opinion of what's going to make the most sense? I really could use some water. Maybe I'll just split it up. I'm going to split it up. Let's see. $5,000, we're almost there. $100,000. $850,000. So we've got a lot of data here. Alright. First question I've sort of sorted it out. I would say the number of data, I'll just split it up. I'm going to split it up. Because it's going to be so easy to do. And that's what I was just talking about. The chat is so far behind, like 30 seconds behind real time. Convert then split. That was the first comment that came. Convert then split. Which was different than where I arrived to in my head. Clean the data first then split it. First make the sense. Tensor then split. Alexa, flip a coin. Is there a convention? What would be the convention? Okay. Convert first so you can use the GPU optimally. Yeah, because the tensors have functionality probably to split. Right? I assume that... Right? Like scalar... Buffer... Clone. Same values. Fill. One hot I definitely need to do. Truncated. Variable. Zeroes. Reshape. Reshape. Reshape. Reshape. Reshape. Reshape. Reshape. Reshape. Reshape. Reshape. Reshape. Squeeze. Clone. Huh. Don't normalize the data altogether. Separate training and testing first. That sounds like a very... Very... That sounds like that was written with conviction. It made an impact on me. I feel like just narrative wise with the flow that I'm doing, I'm actually going to split it. And then I'll write a function that makes a tensor from... Yeah, I don't know. I never know what to do here. There is a TF split function. How come I don't... How come I didn't see that? Alright, let me look at this. Whoa. Number or size of splits. The dimension along which to split. Well, this seems confusing to me. Either an integer indicating the number of splits along the axis or an array of integers containing the sizes of each output tensor along the axis. So I definitely can use that. It just hurts my brain to think about how to do it exactly. Like if this is a 2D tensor and then it splits... I want to see what this does. Let's... Let me try to understand what this does. So let me think about this. So let me think about what I'm going to have. I'm going to have a tensor for the RGB values... That looks like this. Like... 1, 1... Let's see, 1, 2, 3... 4, 5... 6... 7, 8, 9, right? This is what I'm going to have. Let me just work this out right now. So that's what I'm going to have. I'm going to have multiple RGB values. So if I want to say... Split it into train and test. I would say tf.split x... I've lost here. Let me read that documentation again. Number or size of splits. Number of splits along the axis. I just want to split once. And then I guess I'm going to give it like... Let's say if I give it 1, 2, shouldn't I get... And then I say train.print... And test.print. Hold on. Let me comment this stuff out here. All values in axis parameter must be in range negative 2 to 2, but got axis 2. Oh. No. Must evenly divide the axis. It has to do it in half? Hold on. What if I just give it 2 arg... Ah! Well, I lost my console. Oh, P5, don't tell me about this. Cannot read property print of undefined at sketch.9. Let's see. Is anybody in the chat helping me? Ideally, you'd have the same proportion of each label in the test set and the training set. Yes. That's very important. That's very important. I mean, if I had like a huge data set and I just split it up randomly, it would sort of probably stay somewhat uniform. Clearly don't understand how TF split works. I just assumed somebody in the chat would give me the answer. I stopped. My brain just stopped thinking. I guess I have to figure this out myself. Size of each... Oh, oh, oh. So, couldn't I do this? Like 2,1? Right? And that would give me... Yes. That's what I want. So, like, it's splitting it up. So, if I wanted... If I had 5,000, then I... I wish I could do this by percentage. Like I could just say like 80%, 20%. But... But no. But no. Okay, so I'm going to convert all of it and then I'm going to shuffle it and then split it. Okay. Boy, I really don't remember where I was in this whole thing. All right, so the next step that I'm doing here... All right, let's see. I think I actually already said that. Okay, so conceivably what I want to do now is look at this data.entries and divide it into two different arrays, training and testing. But here's the thing. What I want... I'm kind of talking about... I'm talking to myself in circles here, but I don't want to split it just yet, even though that was an important point for me to make. I'm using TensorFlow.js here and TensorFlow.js actually has a function called split that will let me take a long list of data points and split them into two different lists of data points. So what I actually want to do first is get the data into tensors, the TensorFlow.js thing that I need to use it, and then I'll call tf.split to do the 80-20 split. So how am I going to do this? How am I going to convert it into tensors? Now, first of all, if you have never looked at TensorFlow.js before, I might encourage you to go watch my TensorFlow.js tutorial series and it looks at what is a tensor and what are the possibilities there. But just thinking about it, the thing that I need to do also is think about, I have the inputs, which are the RGB values, and then I have the target outputs, the target outputs, which are the labels. And so when I create my tensors, I'm actually going to do this somewhat separately. So let's just worry only about the inputs. This is going to be the easier part first. So the inputs basically, the tensor shape that I want is a 2D tensor, right? Because each input has three values, maybe a R, G, and a B value, and then I have a lot of those. So a 1D tensor, like a one-dimensional array, just has a single set of RGB values, but I have a 2D tensor, because my data set is a whole bunch of those data points. So let me first just create a tensor 2D out of all of the RGB values. Oh, oh. So by the way, in addition, when I get to fit, fit actually will split the data up for me. Now I can't remember, let me just go quickly look at, let me look at my XOR code. I just want to see something in there really quickly. Mathieu, this is not, this doesn't need to be part of the actual tutorial. I just want to check something. I can't remember. Yeah, yeah, I separated into Xs and Ys. Yeah, that's what I was looking for. Where am I here? Okay. And by the way, if you watched my XOR coding challenge, where I did kind of a basic, where I trained a neural network to solve exclusive OR, I also was calling these Xs. Can you see that? Barely. And the outputs being the Ys. So that's the other, the Xs are like the inputs to the machine learning model, the Ys are the output. So I might use that variable naming as well. Okay, now I'm really going back to the computer, and I'm going to say, so first, ah, so let me first, to make a tensor, I need to normalize the data and put it into arrays. So let me go here and say, first I'm going to say let the colors be an array. Then I'm going to go through, let every record in data, let record of data.entries. I'm going to say colors, and then I'm going to say, I'm going to have a specific color. I'm not going to use the word color, just going to say col, is record.r divided by 255, record.g divided by 255. And I'm dividing by 255 because I want to normalize, it's going to, generally speaking for my inputs to a machine learning model, I want to normalize to some strict range. Between zero and one is a pretty good one to do. And then I'm going to say record.b divided by 255. And then I'm going to say colors.push col, and then just going to look at this, colors, let's just look at this. So this is not a tensor yet. This is just 5000, and probably one thing I should do while I'm working this out is I should work with a smaller data set. But 5000 is so small anyway, but if I were doing this with a big data set that had 5000 records in it, I might sort of figuring out I would want to do it for just 100 first, and then I could use the large data set. Okay. So we can see here this is a big array, and each element of that array is another array with the normalized color values in it. Perfect. So this now, I should be able to say now, let x's equal tf.tensor2d.colors. So this is me turning those values, and I just want to say like console.log x's shape. Let's look at the shape of the x's just to sort of see. Yes, right? There's 5643 entries each with three values. So I think things are going right here. I turned that into a tensor, and then, oh boy, hey, this wasn't so hard. We're in good shape here. I haven't done the training or the testing. Now I need to do the y's. The y's involve a concept known as one-hot encoding, I think. One-hot vector. So you know what? I'm going to pause here. I finished this thing. I'm really dividing this series into like little chunks here. In the next video, I'm going to look at how to make the y's, and I'm going to cover a concept known as one-hot. One-hot. What's the term that I'm looking for? Is it one-hot encoding? One-hot encoding, yes. So I'll cover that in the next video when I make the y's. Thanks. Ah, okay. Yeah, I'm going to need to one-hot encode the labels. Okay. I actually don't know how to do this with TensorFlow. JS. I think there's a one-hot function. Let me just look. TF one-hot. So you give it... Let me try to understand this. Okay. One-hot, 1D. That's weird. Oh. Oh! So if I were to do this, if I have a tensor that's like this, this is what I have. I have like... I have nine possibilities, right? So let's say I have... I make an array that's all of the index values for the labels. So if I say these are like the labels... Right? And then I could say the y's would be TF one-hot, the labels... Comma nine, right? Yep. Cool. Okay, I know how to do this now. Excellent. Woo, this is fun. I think this might be where I stop today. All right. What if I... I'm going to kill the console if I do this, right? I don't know. Oh, it's smart. It's smarter than me. Oh, I love how it's smart. Okay, great. Okay. Oh, this is good. This is good stuff. If there are nine labels and a data point is categorized as label three, then the one-hot encoding would be zero, zero, one... No, no, three... If there are nine, three, so it's a third, so it would really be index two, yeah. Because the... Or the index... No, the indexes would be zero through eight, right? Zero through eight. Zero... So the label is three, it's really the fourth. Index three, index three. There's nine. Zero, zero, zero, one, zero, zero, zero, zero, zero. Okay. Yeah, this is going to be much easier than I thought. Thank you, TensorFlow.js. Okay. We're still working with our data. At some point, we're going to start training a model. What have I done so far? Okay, so just to recap for a second. I've got this whole database of crowdsourced colors with a label. And now I've converted all that stuff to tensors. So, and I'm just looking at the inputs now, the inputs that I want to use for my machine learning model. So I have 5,643 RGB values. So the shape of the tensor is 5,643,3. And I can look at it here. I have all the RGB values normalized to zero between zero and one. Now, I need to do the Ys. I need to figure out what are the target outputs associated with each RGB value. And this is exciting because we are going to cover, we being me and you being the person watching, I am going to cover a concept known as one-hot encoding. So we have to understand why we're going to do one-hot encoding. We need to jump all the way to what would essentially be like the very end of this video series. What am I asking the neural network that I'm going to build, right? The neural network that I'm going to build is going to have three inputs, RGB. It's going to have some architecture, some configuration of all the stuff in the middle. And then the idea, I'm getting a phone call. Really? And my volume is on and my watch is giving me a notification. By the way, it says, I wish you could see this. It says, scam likely. That's the decline. Turn off the volume. Off the notifications. I'm so thrilled about this video topic. I'm going to leave that in there. I don't care. The inputs being RGB, what do I want the outputs to be? The output should be a label, right? I want to say, is it reddish? Is it bluish? But this is just the label that I've used as a human being to say what I think it is. If I was doing image classification, the label would be cat or dog or rainbow or unicorn. But those strings are not going to be meaningful in the numbers-based neural network system that I'm building. I need this to return a number. So we could think if there are nine possible labels, I could return the number 0, 1, 2, 3, 4, 5, 6, 7, or 8. Now, while I could try to do something where I just have one output, and it's a floating point number that I round to the nearest integer that indicates the label, that's not going to work so well. What I actually really want is I want a probability value. I want a probability value for each one of these labels. So we could imagine if there are nine labels. Nine is such a... I should have made it ten. If I could travel back in time and start this whole series over, I would have made ten labels because all of this would be so much easier to work out. But imagine there are nine labels. I don't know why I'm drawing it like this, but 1, 2, 3, 4, 5, 6, 7, 8, 9. What if I had a probability? Like, oh, there's a 10% chance it's the first label, and there's a 20% chance it's the second label, and then 0, 0, 0, 0, and then a 70% chance 0, 0. All of these values might add up to 100%. And we could say, ah, it's most likely this one, which is index 0, 1, 2, 3, 4, 5, 6, which maps to, you know, purplish. So I'm trying to create the target outputs. If I know that this particular color should be purplish, the target output that I want is actually 0, 0, 0, 0, 0, 0, 1, 0, 0. 0, 1, 2, 3, 4, 5, 6, 7, 8. Nine labels, 0 through 8 indices. This is one-hot encoding. I am taking the idea of index 6 and making a vector, a one-dimensional vector, full of zeros with a 1 in the spot that matches the label. A 100% chance, because if the neural network was working perfectly, this is the output that I would get. So one-hot encoding is the idea of creating your vector, having all zeros, and sort of flipping a bit on in a way, and just one of them, a switch goes on, and that's assigned 1. Now, I could come up with an algorithm pretty easily, probably, not easily, but I could work hard on it and try it. It would be hard. And I could say, take all of my labels, and I could convert every single label into an array with a 1 in the right spot. Luckily for us, we're using TensorFlow.js, and it has a function called tf.oneHot. So I'm going to create the y's for this system using the tf.oneHot function, and that's what I'm going to go do next. Hold on a sec, everybody. Yeah, default ringtone. You know, I don't usually... Embarrassing. I don't even have the chat open yet. Oh, I'm looking at my email. Okay. Okay. Okay. Alright, so let's go look at the code, and now what I need to do... I made this colors array. Now let me make this labels array. And if I say labels.push... Now, here's the thing. What I want is for this... I mean, I could just push the label in it, so let's just do that. A record.label. Let's just look at this real quick, and I'm going to comment out the console logging, and I'm going to say console.log labels. So let's just see. This should be... Right? This is all the labels, the strings of the labels. So the first thing I need to do is convert each one of these into an index value. So I need a mapping for that. And I really wish... I should have this somewhere, but I'm just going to... I'm going to just create something called labels index really quick, and I did this in a previous... Where did I do this? Didn't I do this in some other... One of my other examples. I have, like, an array of all the labels. Ah, here we go. So here... Here's one of my examples. I had all the labels. I lost where I was. I'm going to paste this in here. I'm going to search buttons.push create button. I'm just going to eliminate this, replace all. I don't need that. And then... Oh, I want the apostrophe. I'm going to put that back in. I could have used, like, a regular expression, but I... Ah! No! Sorry! I can't believe you're watching a video where I am clumsily trying to... Okay, let's see if it just comes back. Okay, I think I'm just back. I think it just comes back now that I'm doing this event thing. So if you could tell me in the chat that I'm back. Okay, it's back. Great. Sorry about that. I don't know. The computer froze. I restarted. I don't have the YouTube chat up. And I think... Hopefully the... So let me grab that real quick. History... Whoops. Ah, the cameras are all shutting off, which is fine. Let me just get the YouTube chat back up here so I can see it. Okay. So I don't know what YouTube is going to have in the end. Oh, was I... And was I... Did I write something way out of bounds? Oh, tf.onehot. That's fine. That's fine. All right. So I was... Let me go back. I was about to do this, which now I feel like is silly. Like, shouldn't I just make an array? Shouldn't I just make an array of the labels? And then I could get the index, right? Isn't there... There must be a way, like, right? Whoa. Whoa, what just... What happened to the Chrome? Chrome died. What happened to the Chrome? Chrome died. I don't need this. Why do I have this, like, debugger thing on? Where did that come from? How did I get this? What is this thing? Go away. What is this tab here? I've never seen that tab. Oh, hide... There we go. Okay. One single array of strings, right? Like, what if I do... Right, then I can say index of b, right? Yeah, okay. So that's what I'm going to do. I don't know why I didn't think of that before. Okay. So let me go back. Mathieu, I'm going to go back to where I was looking for the list of labels. So I need to find that list of labels, which I believe I had in the original crowdsource color thing. No. No, wait, hold on. Hold on. Where actually was that? Oh, yeah, here it is. Okay. Okay, sorry. Download data, sketch, color classifier. Where am I? Okay, hopefully this will edit together fine. I'm going to just... Yeah. All right, so I need to find my list of labels. I could just type them out. Labels... Oh, no, but all labels equals... I could say label list. Let me call it label list. Grayish, bluish, but I have that right here, right? In crowdsource color. When I made those buttons, these are all the labels. One, two, three, four, five, six, seven, eight, nine. So if I come back to what I'm doing here and just put this here and then let me just do a find replace. Whoops. Let me do a find replace for... Just this. I just need to get rid of this. Boy, yes, you're watching me like... failing at doing find replace. And then let me look for ish. And replace that with ish, comma. There we go. Now I have my array, my label list array. So now what I want to put in the labels array is not the actual string of the label, but label list index of that label. So the index of function... I need another parenthesis there. The index of function will say, look for this particular element in the array and give me back its index. So let's look at that now. Let me run this again. And we can see, there we go. Now I have 5,643 index values. And guess what? This is when I now want to go... And I apologize. I wrote tf.one hot up there. You can't see it. So let me just write that again. tf.one hot is the name of the function. Let's go to the TensorFlow.js documentation page. Right over here. And look, I already have it open to one hot. How convenient. And basically, this documentation... Let's see if we can understand this. I need to give it all the indices. That's what I already have. Oh, but you know what? These have to be a tensor already. So first I need to make a tensor of all those indices. Let's do that. So I want to say let label tensor... Labels tensor, let's call it. Equal tf.tensor1d labels. And let's just look at that. Labels tensor dot print. Let's just make sure that's kind of... We can see that's a big, long tensor of all of the labels. And then, now the wise is tf.one hot. So if I go back and look at this, one hot needs the list of all of those index values, which are 0 through 8, and the depth. The depth means how many possibilities are there, and there are nine possibilities. And on value will default to 1, and the off value defaults to 0. But if for some reason I wanted to one hot encode with 3, the number 3 for every spot, or the number 0.1 for every non-spot, I could change those values. But all I need to do then is say one hot labels tensor and 9. And then I could say wise dot print. So x's dot print and y's dot print. So now I have my x's and y's. Remember, the previous video I did this, I looked at all the RGB values, and I got 255. And then I, sorry, I lost my train choo-choo thought here. And then I made those into a 2D tensor. And now I've made the wise. And what I do want to see is console log, let's look at x's dot shape, and console dot log y's dot shape also. OK, ready? Let's look and see if everything seems right. Ah, indices must be of data type int32. Oh, interesting. So when I made this tensor, my labels, if we look at them, are actually, like if I go back and console log the labels, those are floating point numbers, because I wasn't really worrying about it when I was just working with regular JavaScript arrays. But I need to very specifically make sure that I set the data type index values for a one-hot vector, cannot be floating point values. So I think if I do this, we can see that fixed it, right? So now I have the shape, right? This makes sense. There's 5,643 data points. Each data point for the inputs for the x's has an RGB, that's three, and there are nine possible labels. So I have the shape is 5,643, nine possibilities, and each one of those just is one-hot encoded. So this means bluish, and this means purplish, or whatever the mapping is, I don't remember. The second one is greenish, and 0, 1, 2, 3, 4, 5. The sixth one is 0, 1, 2, 3, 4, 5 is pinkish. That's the sixth one. Yes, whatever. So this is going to be really important. Which labels actually go with index values is something that I'm going to have to save for the duration of this project, because when I show the results to the user, I want to actually show the strings, not the number value. Okay, so I am now ready to try to fit, so what's next? I need to architect the model, right? I got all of the input data, and I got all of the output data. I need to divide into trading and testing, architect the model, fit the model, and then I'm sort of done, maybe. So that's going to be like many more videos into the future. So I got at least three or four little more steps to build here until I have this final version of this color classifier, built with TensorFlow.js. Oh, dispose! Wait, wait! Don't leave just yet. I do want to think about memory management, and maybe I'm going to think about memory management later, and the Xs and Ys I'm going to want to use in the next video, but I probably should after I make the one hot vector. I don't need... When I'm working with lower-level TensorFlow.js, I've got to clean up stuff I'm not going to use anymore, and I don't need these labels anymore, so I can dispose that one. So that was just the last little tidbit here, and then I'll move on. In the next video, I'm going to start creating the architecture of the neural network model itself, and, oh, I'm going to introduce some new concepts, softmax and cross-entropy. Isn't that exciting? Okay. All right. Oh, my boy! Okay. All right, everyone, it's 2 o'clock. I didn't get through this whole thing. I have to stop. So the rest... I think I'm going to be back on Monday. I'm going to see if I can finish this on Monday. But stay tuned. And I'll be back on Monday. I don't know what else to say. Any questions? 🎵 I'm really out of tune. 🎵 Can you make music tutorials? No, definitely not. Oh, Alka! Did Alka just maybe just woke up and is now watching? It says, Alka is typing. All right, so let me just mention a couple things. I hope to be back on Monday. I will not be here definitely any day next week, Tuesdays through Friday, because I am traveling. Unless I do some kind of crazy livestream from my television phone. But I will be traveling the rest of next week. I'm also moving to a new apartment. So I've got a lot of stuff to deal with. Oh, could you go on green screen and come in saying, wait, wait, wait, I have an idea. Yes, I can. Should I be singing, playing the ukulele? Or no ukulele. I will definitely indulge Alka in this. Do you really need to be on the phone? Do you really know how to play the guitar? No, I mean, that's not, that's a ukulele, which I bought two weeks ago and tried to teach myself some chords. So that's about as far as I am. All right, green only. Okay. Wait, wait, wait. All right. Wait a sec, wait, wait, wait, wait, wait. You guys know I'll always stay for wasting time. I just can't do any more coding. My brain is fried. Wait, wait, wait, wait, wait, wait, wait, wait, wait. Wait, please wait for me. Oh, wait for me. Wait, wait, wait, wait, wait, wait, wait, wait, wait, wait. That's got to be good enough for whatever you're cooking up, Alka. Oh, Simon writes, great timing. I'm entering the tunnel now. So we'll probably lose the 40 seconds. I'm entering the tunnel now. So we'll probably lose the 40. You've been watching this while driving or on a train? That's amazing. Can you reopen entries on the color classification database just for fun? Yeah, why not? Why not? How do you manage time with a uni and a YouTube channel, writes Art. It's, you know, I think that I need to manage my time better and I need to, the other thing is I have a project that I really want to do this summer, which is an updated version of the Nature of Code book. And I think that I need to take a break from live streaming or like slow that down a little bit to give myself more time to work on that. But now that I have the Patreon and the sponsors, I'm sort of not sure how to do that because I want to keep the content going. So, but let me turn the, let me turn the writing to the database back on, I guess. So rules and write is true. Okay, you can write to the database again. Ricardo asks, are you a uni professor? So I teach at New York University, part of a program called ITP, which is part of Tisch School of the Arts. And you can find out more information on the website. And this fall, we're starting a new undergrad program. So, woohoo. No, remove the false and, yes. Oh, that's, yes. Ah, shoot, shoot, shoot. No, no, no, I didn't, that didn't just happen. Quick, I totally did the wrong thing. Totally did the wrong thing. Rules, quick, let me put this false. All right, so there was a brief moment in time where the whole thing was open to writing anything. But now this is what I want to remove. Thank you very much. Okay, everything should be okay now. All right. Ah, Belisarith asks, Dan, could you please explain how to get the Slack invitation? So, unfortunately, for better or worse, the Slack invitation is only open to either sponsors of the YouTube channel or patrons via Patreon. And you can find more information about that at patreon.com. There's like a sponsor button already as part of the YouTube channel. I don't love the idea of having a closed community that requires people to pay. But it is, at the moment, the benefits that I get out of it is it's a smaller group of people who are sort of dedicated to participating in the community of the channel. And it helps me make these videos, having the funding, frankly. It allows me to have more time to do it and it sort of makes me feel like it's an obligation in a good way, I think. So that's at the moment the system I have. I am very happy for people to self-organize into their own free and open communities. The idea is I want to do more to be able to have the audience of this channel be more inclusive. And I'm always open to anyone who has any thoughts or ideas that can help and ways for me to think about doing a better job with that. Tips on time management, I got nothing for you. Oh, and so, but if you do sponsor the channel, if you do sponsor the channel, and I'll also sign up via Patreon, I don't have a good system of, there's no automatic system, I have to add you to Slack manually. So you can, the best way would be to tweet me at Schiffman, but if you're a sponsor on YouTube, if you go to the community tab, there's a post there that has a link to a Google forum that's only for sponsors, and Patreon, I get your email and I send an invite, but sometimes it ends up in a spam folder and sometimes I forget. Link to the site with colors. The site with colors is github.com, crowdsource, and I also should say, one of the things that I'm not able to do effectively is manage all the pull requests and issues on these GitHub repos. I would love, I do consider that a possibility if that could actually be like a paid position of somebody who's a community manager for all the GitHub repos, but I haven't figured out, A, if I have the budget to do that and who the right person would be for that. At the moment, there are a lot of wonderful volunteers who help, who are members of the Coding Train GitHub organization and help kind of like manage and pull requests and write issues here and there as they have time. Oh, Oliver posted in the YouTube channel. Okay, and so here it is right here. This is at present, and let's just make sure this is working again. Yep. So now this is once again accepting new data points for the color classifier. Okay. Oh yes, and Maren, thank you, and so many wonderful members of the community that I can't seem to remember to mention. I am in New York City. I'm not in Hong Kong. Ricardo asked, are you familiar with functional programming in JS? Ooh. Ada asked, almost a half a million subs. How do you feel about that? I'm very excited. I feel very honored or humbled, those kind of words. I feel a little bit surprised. Like I did not, this was not my expectation for the channel. I feel like I need to do better. I'm always trying to improve what I'm doing, and yeah, it's exciting. I would like to do something to celebrate 500,000 subscribers. I should probably do, I was saying that I should just do whatever is the suggestion number 500 in here, which is make an AI that solves the 15 tile sliding puzzle, so I might try to do that at some point. If anybody has any other ideas for celebrating 500,000 subscribers, assuming not everybody is just unsubscribed right now, which would be fine also. Yeah. This has been a really great stream, writes K. Wigman, like a microcosm of the entire data science pipeline. It's really nice to hear, because this is the new, I don't know what my expertise is exactly, but certainly data science and working with machine learning, this is not something that I spent years and years studying and thinking about. It's something that I've come to as a person who worked on kind of open source creative coding platforms for many years. All right. I'm now going to leave the station. Thank you for tuning in. I hope to come back and finish this color classifier on Monday. Next week is a really hard week for me, so it's not confirmed that I'm doing that until you see it scheduled on YouTube itself. You know, if you're wondering how to get a notification, you hit the subscribe button, the alarm bell, all that sort of stuff. All right, so I'm going to hit stop streaming, and I'll see you maybe, hopefully on Monday. If not, whenever I, at some point at the end of June. Again, remember, I'm going to be away for half of July, so this will be a little bit lighter over the summer during July and August, but also I might, when I'm here, I might do two live streams in a week like I did this week. Does YouTube, oh, Ngramste asks, does YouTube have an API that you could use for some cool data visualizations for 500K subscribers? Word cloud of comments, or maybe I could visualize, like, all the locations all over the world where people are. I don't know if I have access to that data. So yeah, I would consider that. That's kind of like a fun idea. So let's discuss that in the Slack channel. I would love to hear more suggestions. Okay, goodbye, everybody. See you the next week, hopefully, if not the week after, hopefully, if not, definitely sometime in July. Stay tuned. I'll be posting on Twitter, if I remember when I'm live streaming. Actually, at the Coding Train, auto-tweets, at shift-min if I remember, and then, what was I going to say? And then also I schedule it on YouTube now. Okay, goodbye. Oh, no, I don't hit stop streaming there. I have to do it here. Stop streaming, there we go.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:50.0736Z",
  "started_at": "2023-09-26T21:18:15.169373Z",
  "completed_at": "2023-09-26T21:51:53.812191Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=jHnyFNMOffo",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 2018.642818
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/zhifmajblkuk7oqyruyhnp4hhu/cancel",
    "get": "https://api.replicate.com/v1/predictions/zhifmajblkuk7oqyruyhnp4hhu"
  }
}