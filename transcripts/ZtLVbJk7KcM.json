{
  "id": "iq3dv5rbnn5o76bsmpso4f2kqe",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/ZtLVbJk7KcM.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/106909 [00:00<?, ?frames/s]\n  3%|▎         | 2800/106909 [00:05<03:14, 535.03frames/s]\n  5%|▌         | 5700/106909 [00:12<03:41, 456.11frames/s]\n  8%|▊         | 8400/106909 [00:18<03:49, 428.95frames/s]\n 10%|█         | 11200/106909 [00:26<03:51, 413.04frames/s]\n 13%|█▎        | 13800/106909 [00:32<03:46, 411.33frames/s]\n 15%|█▌        | 16300/106909 [00:38<03:42, 407.11frames/s]\n 18%|█▊        | 19100/106909 [00:45<03:33, 410.37frames/s]\n 20%|██        | 21800/106909 [00:51<03:17, 431.29frames/s]\n 23%|██▎       | 24400/106909 [00:56<03:07, 440.76frames/s]\n 25%|██▌       | 27100/106909 [01:03<03:08, 423.36frames/s]\n 28%|██▊       | 29700/106909 [01:10<03:06, 412.92frames/s]\n 30%|███       | 32600/106909 [01:17<02:59, 413.52frames/s]\n 33%|███▎      | 35200/106909 [01:24<02:57, 404.56frames/s]\n 36%|███▌      | 38000/106909 [01:30<02:46, 414.25frames/s]\n 38%|███▊      | 40500/106909 [01:35<02:32, 436.42frames/s]\n 40%|████      | 43200/106909 [01:39<02:10, 486.78frames/s]\n 42%|████▏     | 45100/106909 [01:42<01:58, 523.56frames/s]\n 45%|████▍     | 48000/106909 [01:48<01:54, 515.51frames/s]\n 47%|████▋     | 50700/106909 [01:54<01:57, 476.72frames/s]\n 50%|█████     | 53600/106909 [02:00<01:49, 488.23frames/s]\n 52%|█████▏    | 55400/106909 [02:03<01:42, 502.48frames/s]\n 54%|█████▍    | 58000/106909 [02:07<01:28, 551.70frames/s]\n 57%|█████▋    | 60600/106909 [02:12<01:25, 540.78frames/s]\n 59%|█████▉    | 63200/106909 [02:17<01:22, 527.79frames/s]\n 61%|██████▏   | 65700/106909 [02:22<01:19, 519.50frames/s]\n 64%|██████▎   | 68000/106909 [02:27<01:19, 490.95frames/s]\n 66%|██████▌   | 70700/106909 [02:32<01:11, 509.77frames/s]\n 68%|██████▊   | 73200/106909 [02:37<01:07, 501.39frames/s]\n 71%|███████   | 76000/106909 [02:43<01:01, 500.73frames/s]\n 74%|███████▍  | 78900/106909 [02:48<00:54, 518.07frames/s]\n 76%|███████▋  | 81600/106909 [02:54<00:50, 499.45frames/s]\n 79%|███████▉  | 84200/106909 [02:59<00:45, 493.95frames/s]\n 81%|████████▏ | 87000/106909 [03:04<00:38, 515.15frames/s]\n 84%|████████▍ | 89800/106909 [03:11<00:34, 489.53frames/s]\n 86%|████████▋ | 92300/106909 [03:16<00:30, 478.10frames/s]\n 89%|████████▉ | 95100/106909 [03:21<00:23, 501.67frames/s]\n 92%|█████████▏| 98000/106909 [03:28<00:18, 483.71frames/s]\n 94%|█████████▍| 100900/106909 [03:34<00:12, 474.49frames/s]\n 97%|█████████▋| 103800/106909 [03:41<00:06, 446.64frames/s]\n 99%|█████████▉| 105900/106909 [03:47<00:02, 434.37frames/s]\n100%|██████████| 106909/106909 [03:48<00:00, 464.06frames/s]\n100%|██████████| 106909/106909 [03:48<00:00, 468.19frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2955071490743886,
        "compression_ratio": 1.68561872909699,
        "end": 5,
        "id": 0,
        "no_speech_prob": 0.007693180348724127,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello and welcome to module three of working with data and APIs in JavaScript.",
        "tokens": [
          50364,
          2425,
          293,
          2928,
          281,
          10088,
          1045,
          295,
          1364,
          365,
          1412,
          293,
          21445,
          294,
          15778,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2955071490743886,
        "compression_ratio": 1.68561872909699,
        "end": 10,
        "id": 1,
        "no_speech_prob": 0.007693180348724127,
        "seek": 0,
        "start": 5,
        "temperature": 0,
        "text": " So I just wrapped up module two, the second part, with a project called the Data Selfie app.",
        "tokens": [
          50614,
          407,
          286,
          445,
          14226,
          493,
          10088,
          732,
          11,
          264,
          1150,
          644,
          11,
          365,
          257,
          1716,
          1219,
          264,
          11888,
          16348,
          414,
          724,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2955071490743886,
        "compression_ratio": 1.68561872909699,
        "end": 15,
        "id": 2,
        "no_speech_prob": 0.007693180348724127,
        "seek": 0,
        "start": 10,
        "temperature": 0,
        "text": " And there were some new things, hopefully, to you that you learned and are excited to apply in future projects",
        "tokens": [
          50864,
          400,
          456,
          645,
          512,
          777,
          721,
          11,
          4696,
          11,
          281,
          291,
          300,
          291,
          3264,
          293,
          366,
          2919,
          281,
          3079,
          294,
          2027,
          4455,
          51114
        ]
      },
      {
        "avg_logprob": -0.2955071490743886,
        "compression_ratio": 1.68561872909699,
        "end": 20,
        "id": 3,
        "no_speech_prob": 0.007693180348724127,
        "seek": 0,
        "start": 15,
        "temperature": 0,
        "text": " like server-side programming and get requests and post requests and saving data to a database.",
        "tokens": [
          51114,
          411,
          7154,
          12,
          1812,
          9410,
          293,
          483,
          12475,
          293,
          2183,
          12475,
          293,
          6816,
          1412,
          281,
          257,
          8149,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2955071490743886,
        "compression_ratio": 1.68561872909699,
        "end": 21,
        "id": 4,
        "no_speech_prob": 0.007693180348724127,
        "seek": 0,
        "start": 20,
        "temperature": 0,
        "text": " All of the things.",
        "tokens": [
          51364,
          1057,
          295,
          264,
          721,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2955071490743886,
        "compression_ratio": 1.68561872909699,
        "end": 28,
        "id": 5,
        "no_speech_prob": 0.007693180348724127,
        "seek": 0,
        "start": 21,
        "temperature": 0,
        "text": " But I think there are some key elements of building a web application that involves data from external APIs",
        "tokens": [
          51414,
          583,
          286,
          519,
          456,
          366,
          512,
          2141,
          4959,
          295,
          2390,
          257,
          3670,
          3861,
          300,
          11626,
          1412,
          490,
          8320,
          21445,
          51764
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 30,
        "id": 6,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 28,
        "temperature": 0,
        "text": " and server-side and client-side that I missed.",
        "tokens": [
          50364,
          293,
          7154,
          12,
          1812,
          293,
          6423,
          12,
          1812,
          300,
          286,
          6721,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 35,
        "id": 7,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 30,
        "temperature": 0,
        "text": " One of the most crucial things, I think, is making an API request to an external data source from the server.",
        "tokens": [
          50464,
          1485,
          295,
          264,
          881,
          11462,
          721,
          11,
          286,
          519,
          11,
          307,
          1455,
          364,
          9362,
          5308,
          281,
          364,
          8320,
          1412,
          4009,
          490,
          264,
          7154,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 39,
        "id": 8,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 35,
        "temperature": 0,
        "text": " And there are a variety of reasons why you might want to do that or need to do that.",
        "tokens": [
          50714,
          400,
          456,
          366,
          257,
          5673,
          295,
          4112,
          983,
          291,
          1062,
          528,
          281,
          360,
          300,
          420,
          643,
          281,
          360,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 43,
        "id": 9,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 39,
        "temperature": 0,
        "text": " And I really want to demonstrate that in this new project called the Weather Here.",
        "tokens": [
          50914,
          400,
          286,
          534,
          528,
          281,
          11698,
          300,
          294,
          341,
          777,
          1716,
          1219,
          264,
          34441,
          1692,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 50,
        "id": 10,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 43,
        "temperature": 0,
        "text": " The original Weather Here project is, once again, by Joey Lee and was built for a course called Quant Humanists at NYU,",
        "tokens": [
          51114,
          440,
          3380,
          34441,
          1692,
          1716,
          307,
          11,
          1564,
          797,
          11,
          538,
          23764,
          6957,
          293,
          390,
          3094,
          337,
          257,
          1164,
          1219,
          26968,
          10294,
          1751,
          412,
          42682,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 51,
        "id": 11,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 50,
        "temperature": 0,
        "text": " where I also teach.",
        "tokens": [
          51464,
          689,
          286,
          611,
          2924,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 54,
        "id": 12,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 51,
        "temperature": 0,
        "text": " In Joey's project, the user arrives on a web page.",
        "tokens": [
          51514,
          682,
          23764,
          311,
          1716,
          11,
          264,
          4195,
          20116,
          322,
          257,
          3670,
          3028,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 56,
        "id": 13,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 54,
        "temperature": 0,
        "text": " There's information about latitude and longitude.",
        "tokens": [
          51664,
          821,
          311,
          1589,
          466,
          45436,
          293,
          938,
          4377,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18414143331689772,
        "compression_ratio": 1.7155172413793103,
        "end": 57,
        "id": 14,
        "no_speech_prob": 0.03567257523536682,
        "seek": 2800,
        "start": 56,
        "temperature": 0,
        "text": " We know how to do that already.",
        "tokens": [
          51764,
          492,
          458,
          577,
          281,
          360,
          300,
          1217,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 60,
        "id": 15,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 57,
        "temperature": 0,
        "text": " There's information about the current weather and air quality.",
        "tokens": [
          50364,
          821,
          311,
          1589,
          466,
          264,
          2190,
          5503,
          293,
          1988,
          3125,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 62,
        "id": 16,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 60,
        "temperature": 0,
        "text": " This will be new that we want to add.",
        "tokens": [
          50514,
          639,
          486,
          312,
          777,
          300,
          321,
          528,
          281,
          909,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 63,
        "id": 17,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 62,
        "temperature": 0,
        "text": " And then a big check-in button.",
        "tokens": [
          50614,
          400,
          550,
          257,
          955,
          1520,
          12,
          259,
          2960,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 65,
        "id": 18,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 63,
        "temperature": 0,
        "text": " So you press the check-in button.",
        "tokens": [
          50664,
          407,
          291,
          1886,
          264,
          1520,
          12,
          259,
          2960,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 67,
        "id": 19,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 65,
        "temperature": 0,
        "text": " All that information is logged to a database.",
        "tokens": [
          50764,
          1057,
          300,
          1589,
          307,
          27231,
          281,
          257,
          8149,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 73,
        "id": 20,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 67,
        "temperature": 0,
        "text": " And then there's also a view where you can view all the different check-ins plotted on a map with Leaflet.js.",
        "tokens": [
          50864,
          400,
          550,
          456,
          311,
          611,
          257,
          1910,
          689,
          291,
          393,
          1910,
          439,
          264,
          819,
          1520,
          12,
          1292,
          43288,
          322,
          257,
          4471,
          365,
          32290,
          2631,
          13,
          25530,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 78,
        "id": 21,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 73,
        "temperature": 0,
        "text": " Most of the functionality that I need for this Weather Here app we already have from the Data Selfie app.",
        "tokens": [
          51164,
          4534,
          295,
          264,
          14980,
          300,
          286,
          643,
          337,
          341,
          34441,
          1692,
          724,
          321,
          1217,
          362,
          490,
          264,
          11888,
          16348,
          414,
          724,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 80,
        "id": 22,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 78,
        "temperature": 0,
        "text": " But we can start with a sort of baseline of code from there.",
        "tokens": [
          51414,
          583,
          321,
          393,
          722,
          365,
          257,
          1333,
          295,
          20518,
          295,
          3089,
          490,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1610080744769122,
        "compression_ratio": 1.7924528301886793,
        "end": 84,
        "id": 23,
        "no_speech_prob": 0.00048784189857542515,
        "seek": 5700,
        "start": 80,
        "temperature": 0,
        "text": " But there are some new things that I want to demonstrate to you in this project.",
        "tokens": [
          51514,
          583,
          456,
          366,
          512,
          777,
          721,
          300,
          286,
          528,
          281,
          11698,
          281,
          291,
          294,
          341,
          1716,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19511784110099648,
        "compression_ratio": 1.86687306501548,
        "end": 87,
        "id": 24,
        "no_speech_prob": 0.22266294062137604,
        "seek": 8400,
        "start": 84,
        "temperature": 0,
        "text": " So number one is I want to add connecting to external APIs.",
        "tokens": [
          50364,
          407,
          1230,
          472,
          307,
          286,
          528,
          281,
          909,
          11015,
          281,
          8320,
          21445,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19511784110099648,
        "compression_ratio": 1.86687306501548,
        "end": 91,
        "id": 25,
        "no_speech_prob": 0.22266294062137604,
        "seek": 8400,
        "start": 87,
        "temperature": 0,
        "text": " So we're going to use two different APIs, one for weather information and one for air quality.",
        "tokens": [
          50514,
          407,
          321,
          434,
          516,
          281,
          764,
          732,
          819,
          21445,
          11,
          472,
          337,
          5503,
          1589,
          293,
          472,
          337,
          1988,
          3125,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19511784110099648,
        "compression_ratio": 1.86687306501548,
        "end": 97,
        "id": 26,
        "no_speech_prob": 0.22266294062137604,
        "seek": 8400,
        "start": 91,
        "temperature": 0,
        "text": " One of those APIs is going to require an API key and not actually even allow us to connect from the client side.",
        "tokens": [
          50714,
          1485,
          295,
          729,
          21445,
          307,
          516,
          281,
          3651,
          364,
          9362,
          2141,
          293,
          406,
          767,
          754,
          2089,
          505,
          281,
          1745,
          490,
          264,
          6423,
          1252,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19511784110099648,
        "compression_ratio": 1.86687306501548,
        "end": 103,
        "id": 27,
        "no_speech_prob": 0.22266294062137604,
        "seek": 8400,
        "start": 97,
        "temperature": 0,
        "text": " So we're going to have to look at, well, how do I connect to an API from Node but then have the client be able to display that information?",
        "tokens": [
          51014,
          407,
          321,
          434,
          516,
          281,
          362,
          281,
          574,
          412,
          11,
          731,
          11,
          577,
          360,
          286,
          1745,
          281,
          364,
          9362,
          490,
          38640,
          457,
          550,
          362,
          264,
          6423,
          312,
          1075,
          281,
          4674,
          300,
          1589,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.19511784110099648,
        "compression_ratio": 1.86687306501548,
        "end": 105,
        "id": 28,
        "no_speech_prob": 0.22266294062137604,
        "seek": 8400,
        "start": 103,
        "temperature": 0,
        "text": " Because that's going to be a key new thing.",
        "tokens": [
          51314,
          1436,
          300,
          311,
          516,
          281,
          312,
          257,
          2141,
          777,
          551,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19511784110099648,
        "compression_ratio": 1.86687306501548,
        "end": 107,
        "id": 29,
        "no_speech_prob": 0.22266294062137604,
        "seek": 8400,
        "start": 105,
        "temperature": 0,
        "text": " I also want to figure out how do I hide the API key.",
        "tokens": [
          51414,
          286,
          611,
          528,
          281,
          2573,
          484,
          577,
          360,
          286,
          6479,
          264,
          9362,
          2141,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19511784110099648,
        "compression_ratio": 1.86687306501548,
        "end": 112,
        "id": 30,
        "no_speech_prob": 0.22266294062137604,
        "seek": 8400,
        "start": 107,
        "temperature": 0,
        "text": " So if I open source and publish my code but I don't want to include my API keys, how do I do that?",
        "tokens": [
          51514,
          407,
          498,
          286,
          1269,
          4009,
          293,
          11374,
          452,
          3089,
          457,
          286,
          500,
          380,
          528,
          281,
          4090,
          452,
          9362,
          9317,
          11,
          577,
          360,
          286,
          360,
          300,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.1739867690705905,
        "compression_ratio": 1.7160493827160495,
        "end": 114,
        "id": 31,
        "no_speech_prob": 0.13659486174583435,
        "seek": 11200,
        "start": 112,
        "temperature": 0,
        "text": " That's going to be an important piece of this as well.",
        "tokens": [
          50364,
          663,
          311,
          516,
          281,
          312,
          364,
          1021,
          2522,
          295,
          341,
          382,
          731,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1739867690705905,
        "compression_ratio": 1.7160493827160495,
        "end": 117,
        "id": 32,
        "no_speech_prob": 0.13659486174583435,
        "seek": 11200,
        "start": 114,
        "temperature": 0,
        "text": " This project also allows us to kind of play with our logs page.",
        "tokens": [
          50464,
          639,
          1716,
          611,
          4045,
          505,
          281,
          733,
          295,
          862,
          365,
          527,
          20820,
          3028,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1739867690705905,
        "compression_ratio": 1.7160493827160495,
        "end": 120,
        "id": 33,
        "no_speech_prob": 0.13659486174583435,
        "seek": 11200,
        "start": 117,
        "temperature": 0,
        "text": " And let's look at instead of just a list of all the information from the database,",
        "tokens": [
          50614,
          400,
          718,
          311,
          574,
          412,
          2602,
          295,
          445,
          257,
          1329,
          295,
          439,
          264,
          1589,
          490,
          264,
          8149,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1739867690705905,
        "compression_ratio": 1.7160493827160495,
        "end": 124,
        "id": 34,
        "no_speech_prob": 0.13659486174583435,
        "seek": 11200,
        "start": 120,
        "temperature": 0,
        "text": " how do we pull a bunch of records from the database and plot them on a map?",
        "tokens": [
          50764,
          577,
          360,
          321,
          2235,
          257,
          3840,
          295,
          7724,
          490,
          264,
          8149,
          293,
          7542,
          552,
          322,
          257,
          4471,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.1739867690705905,
        "compression_ratio": 1.7160493827160495,
        "end": 131,
        "id": 35,
        "no_speech_prob": 0.13659486174583435,
        "seek": 11200,
        "start": 124,
        "temperature": 0,
        "text": " And mostly we can pull from the previous example I made with the International Space Station to create a map with Leaflet.js.",
        "tokens": [
          50964,
          400,
          5240,
          321,
          393,
          2235,
          490,
          264,
          3894,
          1365,
          286,
          1027,
          365,
          264,
          9157,
          8705,
          14467,
          281,
          1884,
          257,
          4471,
          365,
          32290,
          2631,
          13,
          25530,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1739867690705905,
        "compression_ratio": 1.7160493827160495,
        "end": 138,
        "id": 36,
        "no_speech_prob": 0.13659486174583435,
        "seek": 11200,
        "start": 131,
        "temperature": 0,
        "text": " And finally, before I go, before this series wraps up, I really think it's important to talk about deploying a project into the real world, so to speak.",
        "tokens": [
          51314,
          400,
          2721,
          11,
          949,
          286,
          352,
          11,
          949,
          341,
          2638,
          25831,
          493,
          11,
          286,
          534,
          519,
          309,
          311,
          1021,
          281,
          751,
          466,
          34198,
          257,
          1716,
          666,
          264,
          957,
          1002,
          11,
          370,
          281,
          1710,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2260886722140842,
        "compression_ratio": 1.7419354838709677,
        "end": 140,
        "id": 37,
        "no_speech_prob": 0.03460894897580147,
        "seek": 13800,
        "start": 138,
        "temperature": 0,
        "text": " So right now I'm tinkering and playing around and developing.",
        "tokens": [
          50364,
          407,
          558,
          586,
          286,
          478,
          256,
          475,
          1794,
          293,
          2433,
          926,
          293,
          6416,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2260886722140842,
        "compression_ratio": 1.7419354838709677,
        "end": 142,
        "id": 38,
        "no_speech_prob": 0.03460894897580147,
        "seek": 13800,
        "start": 140,
        "temperature": 0,
        "text": " The server is running here. The client is running here.",
        "tokens": [
          50464,
          440,
          7154,
          307,
          2614,
          510,
          13,
          440,
          6423,
          307,
          2614,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2260886722140842,
        "compression_ratio": 1.7419354838709677,
        "end": 145,
        "id": 39,
        "no_speech_prob": 0.03460894897580147,
        "seek": 13800,
        "start": 142,
        "temperature": 0,
        "text": " This is just all contained within my laptop.",
        "tokens": [
          50564,
          639,
          307,
          445,
          439,
          16212,
          1951,
          452,
          10732,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2260886722140842,
        "compression_ratio": 1.7419354838709677,
        "end": 153,
        "id": 40,
        "no_speech_prob": 0.03460894897580147,
        "seek": 13800,
        "start": 145,
        "temperature": 0,
        "text": " But if I want to deploy this project to a server so that it can live on the web, that many people could access it, share the data, participate in the...",
        "tokens": [
          50714,
          583,
          498,
          286,
          528,
          281,
          7274,
          341,
          1716,
          281,
          257,
          7154,
          370,
          300,
          309,
          393,
          1621,
          322,
          264,
          3670,
          11,
          300,
          867,
          561,
          727,
          2105,
          309,
          11,
          2073,
          264,
          1412,
          11,
          8197,
          294,
          264,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.2260886722140842,
        "compression_ratio": 1.7419354838709677,
        "end": 155,
        "id": 41,
        "no_speech_prob": 0.03460894897580147,
        "seek": 13800,
        "start": 153,
        "temperature": 0,
        "text": " and view the website, essentially, how do I do that?",
        "tokens": [
          51114,
          293,
          1910,
          264,
          3144,
          11,
          4476,
          11,
          577,
          360,
          286,
          360,
          300,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.2260886722140842,
        "compression_ratio": 1.7419354838709677,
        "end": 159,
        "id": 42,
        "no_speech_prob": 0.03460894897580147,
        "seek": 13800,
        "start": 155,
        "temperature": 0,
        "text": " So I want to look at a few different options for deploying your project onto the web.",
        "tokens": [
          51214,
          407,
          286,
          528,
          281,
          574,
          412,
          257,
          1326,
          819,
          3956,
          337,
          34198,
          428,
          1716,
          3911,
          264,
          3670,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2260886722140842,
        "compression_ratio": 1.7419354838709677,
        "end": 163,
        "id": 43,
        "no_speech_prob": 0.03460894897580147,
        "seek": 13800,
        "start": 159,
        "temperature": 0,
        "text": " Hopefully I'll give you some pointers to some options where you can do that for free,",
        "tokens": [
          51414,
          10429,
          286,
          603,
          976,
          291,
          512,
          44548,
          281,
          512,
          3956,
          689,
          291,
          393,
          360,
          300,
          337,
          1737,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.1597026643298921,
        "compression_ratio": 1.7460815047021943,
        "end": 168,
        "id": 44,
        "no_speech_prob": 0.14216886460781097,
        "seek": 16300,
        "start": 163,
        "temperature": 0,
        "text": " as well as if you have a larger project, what the considerations are for hosting services and paying for hosting.",
        "tokens": [
          50364,
          382,
          731,
          382,
          498,
          291,
          362,
          257,
          4833,
          1716,
          11,
          437,
          264,
          24070,
          366,
          337,
          16058,
          3328,
          293,
          6229,
          337,
          16058,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1597026643298921,
        "compression_ratio": 1.7460815047021943,
        "end": 170,
        "id": 45,
        "no_speech_prob": 0.14216886460781097,
        "seek": 16300,
        "start": 168,
        "temperature": 0,
        "text": " So this is where I'm going to begin.",
        "tokens": [
          50614,
          407,
          341,
          307,
          689,
          286,
          478,
          516,
          281,
          1841,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1597026643298921,
        "compression_ratio": 1.7460815047021943,
        "end": 173,
        "id": 46,
        "no_speech_prob": 0.14216886460781097,
        "seek": 16300,
        "start": 170,
        "temperature": 0,
        "text": " I've got just the very basic functionality from the Data Selfie app.",
        "tokens": [
          50714,
          286,
          600,
          658,
          445,
          264,
          588,
          3875,
          14980,
          490,
          264,
          11888,
          16348,
          414,
          724,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1597026643298921,
        "compression_ratio": 1.7460815047021943,
        "end": 177,
        "id": 47,
        "no_speech_prob": 0.14216886460781097,
        "seek": 16300,
        "start": 173,
        "temperature": 0,
        "text": " I've stripped away P5, the webcam, images, a lot of stuff.",
        "tokens": [
          50864,
          286,
          600,
          33221,
          1314,
          430,
          20,
          11,
          264,
          39490,
          11,
          5267,
          11,
          257,
          688,
          295,
          1507,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1597026643298921,
        "compression_ratio": 1.7460815047021943,
        "end": 180,
        "id": 48,
        "no_speech_prob": 0.14216886460781097,
        "seek": 16300,
        "start": 177,
        "temperature": 0,
        "text": " The page just loads and shows my latitude and longitude.",
        "tokens": [
          51064,
          440,
          3028,
          445,
          12668,
          293,
          3110,
          452,
          45436,
          293,
          938,
          4377,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1597026643298921,
        "compression_ratio": 1.7460815047021943,
        "end": 184,
        "id": 49,
        "no_speech_prob": 0.14216886460781097,
        "seek": 16300,
        "start": 180,
        "temperature": 0,
        "text": " When I click check-in, it's saving that current latitude and longitude and the timestamp to the database.",
        "tokens": [
          51214,
          1133,
          286,
          2052,
          1520,
          12,
          259,
          11,
          309,
          311,
          6816,
          300,
          2190,
          45436,
          293,
          938,
          4377,
          293,
          264,
          49108,
          1215,
          281,
          264,
          8149,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1597026643298921,
        "compression_ratio": 1.7460815047021943,
        "end": 191,
        "id": 50,
        "no_speech_prob": 0.14216886460781097,
        "seek": 16300,
        "start": 184,
        "temperature": 0,
        "text": " And when I go to view check-ins, I see a log of all of my recent check-ins at this latitude and longitude and time.",
        "tokens": [
          51414,
          400,
          562,
          286,
          352,
          281,
          1910,
          1520,
          12,
          1292,
          11,
          286,
          536,
          257,
          3565,
          295,
          439,
          295,
          452,
          5162,
          1520,
          12,
          1292,
          412,
          341,
          45436,
          293,
          938,
          4377,
          293,
          565,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.173042123967951,
        "compression_ratio": 1.7344827586206897,
        "end": 195,
        "id": 51,
        "no_speech_prob": 0.00012931294622831047,
        "seek": 19100,
        "start": 191,
        "temperature": 0,
        "text": " So the very first thing that I want to do in this series now is add weather.",
        "tokens": [
          50364,
          407,
          264,
          588,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          294,
          341,
          2638,
          586,
          307,
          909,
          5503,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.173042123967951,
        "compression_ratio": 1.7344827586206897,
        "end": 202,
        "id": 52,
        "no_speech_prob": 0.00012931294622831047,
        "seek": 19100,
        "start": 195,
        "temperature": 0,
        "text": " I want to be able to display on this page information about the current temperature outside at this latitude and longitude.",
        "tokens": [
          50564,
          286,
          528,
          281,
          312,
          1075,
          281,
          4674,
          322,
          341,
          3028,
          1589,
          466,
          264,
          2190,
          4292,
          2380,
          412,
          341,
          45436,
          293,
          938,
          4377,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.173042123967951,
        "compression_ratio": 1.7344827586206897,
        "end": 205,
        "id": 53,
        "no_speech_prob": 0.00012931294622831047,
        "seek": 19100,
        "start": 202,
        "temperature": 0,
        "text": " Now I have to figure out where am I going to get the weather information from.",
        "tokens": [
          50914,
          823,
          286,
          362,
          281,
          2573,
          484,
          689,
          669,
          286,
          516,
          281,
          483,
          264,
          5503,
          1589,
          490,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.173042123967951,
        "compression_ratio": 1.7344827586206897,
        "end": 210,
        "id": 54,
        "no_speech_prob": 0.00012931294622831047,
        "seek": 19100,
        "start": 205,
        "temperature": 0,
        "text": " So I don't really feel so inclined to build my own set of sensors and my own weather station.",
        "tokens": [
          51064,
          407,
          286,
          500,
          380,
          534,
          841,
          370,
          28173,
          281,
          1322,
          452,
          1065,
          992,
          295,
          14840,
          293,
          452,
          1065,
          5503,
          5214,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.173042123967951,
        "compression_ratio": 1.7344827586206897,
        "end": 218,
        "id": 55,
        "no_speech_prob": 0.00012931294622831047,
        "seek": 19100,
        "start": 210,
        "temperature": 0,
        "text": " So most likely I can find some type of API service that I can make a request to and get the data back, maybe even in JSON format.",
        "tokens": [
          51314,
          407,
          881,
          3700,
          286,
          393,
          915,
          512,
          2010,
          295,
          9362,
          2643,
          300,
          286,
          393,
          652,
          257,
          5308,
          281,
          293,
          483,
          264,
          1412,
          646,
          11,
          1310,
          754,
          294,
          31828,
          7877,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2164324925950736,
        "compression_ratio": 1.750809061488673,
        "end": 224,
        "id": 56,
        "no_speech_prob": 0.06186778470873833,
        "seek": 21800,
        "start": 218,
        "temperature": 0,
        "text": " This is very similar to what we did when we looked at the International Space Station latitude and longitude from an external API.",
        "tokens": [
          50364,
          639,
          307,
          588,
          2531,
          281,
          437,
          321,
          630,
          562,
          321,
          2956,
          412,
          264,
          9157,
          8705,
          14467,
          45436,
          293,
          938,
          4377,
          490,
          364,
          8320,
          9362,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2164324925950736,
        "compression_ratio": 1.750809061488673,
        "end": 226,
        "id": 57,
        "no_speech_prob": 0.06186778470873833,
        "seek": 21800,
        "start": 224,
        "temperature": 0,
        "text": " And there are many weather APIs.",
        "tokens": [
          50664,
          400,
          456,
          366,
          867,
          5503,
          21445,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2164324925950736,
        "compression_ratio": 1.750809061488673,
        "end": 230,
        "id": 58,
        "no_speech_prob": 0.06186778470873833,
        "seek": 21800,
        "start": 226,
        "temperature": 0,
        "text": " Google it. Google weather API, JSON data. You'll probably find a ton.",
        "tokens": [
          50764,
          3329,
          309,
          13,
          3329,
          5503,
          9362,
          11,
          31828,
          1412,
          13,
          509,
          603,
          1391,
          915,
          257,
          2952,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2164324925950736,
        "compression_ratio": 1.750809061488673,
        "end": 233,
        "id": 59,
        "no_speech_prob": 0.06186778470873833,
        "seek": 21800,
        "start": 230,
        "temperature": 0,
        "text": " One that I've used in previous video tutorials is Open Weather Map.",
        "tokens": [
          50964,
          1485,
          300,
          286,
          600,
          1143,
          294,
          3894,
          960,
          17616,
          307,
          7238,
          34441,
          22053,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2164324925950736,
        "compression_ratio": 1.750809061488673,
        "end": 235,
        "id": 60,
        "no_speech_prob": 0.06186778470873833,
        "seek": 21800,
        "start": 233,
        "temperature": 0,
        "text": " That's one that you could look into using.",
        "tokens": [
          51114,
          663,
          311,
          472,
          300,
          291,
          727,
          574,
          666,
          1228,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2164324925950736,
        "compression_ratio": 1.750809061488673,
        "end": 237,
        "id": 61,
        "no_speech_prob": 0.06186778470873833,
        "seek": 21800,
        "start": 235,
        "temperature": 0,
        "text": " The National Weather Service.",
        "tokens": [
          51214,
          440,
          4862,
          34441,
          9561,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2164324925950736,
        "compression_ratio": 1.750809061488673,
        "end": 244,
        "id": 62,
        "no_speech_prob": 0.06186778470873833,
        "seek": 21800,
        "start": 237,
        "temperature": 0,
        "text": " Probably there are other governmental organizations or public institutions that have public weather data that you could use that have APIs that you request data from.",
        "tokens": [
          51314,
          9210,
          456,
          366,
          661,
          43391,
          6150,
          420,
          1908,
          8142,
          300,
          362,
          1908,
          5503,
          1412,
          300,
          291,
          727,
          764,
          300,
          362,
          21445,
          300,
          291,
          5308,
          1412,
          490,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 247,
        "id": 63,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 244,
        "temperature": 0,
        "text": " I'm somewhat arbitrarily picking an API called Dark Sky.",
        "tokens": [
          50364,
          286,
          478,
          8344,
          19071,
          3289,
          8867,
          364,
          9362,
          1219,
          9563,
          9879,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 251,
        "id": 64,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 247,
        "temperature": 0,
        "text": " One of the things I look for when trying to pick an API is does it have good documentation?",
        "tokens": [
          50514,
          1485,
          295,
          264,
          721,
          286,
          574,
          337,
          562,
          1382,
          281,
          1888,
          364,
          9362,
          307,
          775,
          309,
          362,
          665,
          14333,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 253,
        "id": 65,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 251,
        "temperature": 0,
        "text": " Are the examples easy to follow?",
        "tokens": [
          50714,
          2014,
          264,
          5110,
          1858,
          281,
          1524,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 255,
        "id": 66,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 253,
        "temperature": 0,
        "text": " Can I get up and running with it fairly quickly?",
        "tokens": [
          50814,
          1664,
          286,
          483,
          493,
          293,
          2614,
          365,
          309,
          6457,
          2661,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 257,
        "id": 67,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 255,
        "temperature": 0,
        "text": " And looking at Dark Sky, I find that to be true.",
        "tokens": [
          50914,
          400,
          1237,
          412,
          9563,
          9879,
          11,
          286,
          915,
          300,
          281,
          312,
          2074,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 260,
        "id": 68,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 257,
        "temperature": 0,
        "text": " The documentation is pretty easy to follow and I can get up and running with it quickly.",
        "tokens": [
          51014,
          440,
          14333,
          307,
          1238,
          1858,
          281,
          1524,
          293,
          286,
          393,
          483,
          493,
          293,
          2614,
          365,
          309,
          2661,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 262,
        "id": 69,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 260,
        "temperature": 0,
        "text": " And it offers the data in JSON format.",
        "tokens": [
          51164,
          400,
          309,
          7736,
          264,
          1412,
          294,
          31828,
          7877,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 268,
        "id": 70,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 262,
        "temperature": 0,
        "text": " It also, while it's not entirely a free service, it lets you do a thousand API calls per day free.",
        "tokens": [
          51264,
          467,
          611,
          11,
          1339,
          309,
          311,
          406,
          7696,
          257,
          1737,
          2643,
          11,
          309,
          6653,
          291,
          360,
          257,
          4714,
          9362,
          5498,
          680,
          786,
          1737,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 270,
        "id": 71,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 268,
        "temperature": 0,
        "text": " And that's for demonstration purposes.",
        "tokens": [
          51564,
          400,
          300,
          311,
          337,
          16520,
          9932,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16996181563825796,
        "compression_ratio": 1.7297297297297298,
        "end": 271,
        "id": 72,
        "no_speech_prob": 0.31058332324028015,
        "seek": 24400,
        "start": 270,
        "temperature": 0,
        "text": " That's pretty much all I need.",
        "tokens": [
          51664,
          663,
          311,
          1238,
          709,
          439,
          286,
          643,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20237686264682825,
        "compression_ratio": 1.7721518987341771,
        "end": 278,
        "id": 73,
        "no_speech_prob": 0.3006363809108734,
        "seek": 27100,
        "start": 271,
        "temperature": 0,
        "text": " A risk here, of course, is that by the time you're watching this video, the Dark Sky API won't exist anymore or the way that it works will have completely changed.",
        "tokens": [
          50364,
          316,
          3148,
          510,
          11,
          295,
          1164,
          11,
          307,
          300,
          538,
          264,
          565,
          291,
          434,
          1976,
          341,
          960,
          11,
          264,
          9563,
          9879,
          9362,
          1582,
          380,
          2514,
          3602,
          420,
          264,
          636,
          300,
          309,
          1985,
          486,
          362,
          2584,
          3105,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20237686264682825,
        "compression_ratio": 1.7721518987341771,
        "end": 280,
        "id": 74,
        "no_speech_prob": 0.3006363809108734,
        "seek": 27100,
        "start": 278,
        "temperature": 0,
        "text": " But that's just a fact of life.",
        "tokens": [
          50714,
          583,
          300,
          311,
          445,
          257,
          1186,
          295,
          993,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20237686264682825,
        "compression_ratio": 1.7721518987341771,
        "end": 288,
        "id": 75,
        "no_speech_prob": 0.3006363809108734,
        "seek": 27100,
        "start": 280,
        "temperature": 0,
        "text": " So really what you should be taking away from this video is less the specifics of the Dark Sky API, but what you need to do when you find an API.",
        "tokens": [
          50814,
          407,
          534,
          437,
          291,
          820,
          312,
          1940,
          1314,
          490,
          341,
          960,
          307,
          1570,
          264,
          28454,
          295,
          264,
          9563,
          9879,
          9362,
          11,
          457,
          437,
          291,
          643,
          281,
          360,
          562,
          291,
          915,
          364,
          9362,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20237686264682825,
        "compression_ratio": 1.7721518987341771,
        "end": 290,
        "id": 76,
        "no_speech_prob": 0.3006363809108734,
        "seek": 27100,
        "start": 288,
        "temperature": 0,
        "text": " How to get your API key.",
        "tokens": [
          51214,
          1012,
          281,
          483,
          428,
          9362,
          2141,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20237686264682825,
        "compression_ratio": 1.7721518987341771,
        "end": 291,
        "id": 77,
        "no_speech_prob": 0.3006363809108734,
        "seek": 27100,
        "start": 290,
        "temperature": 0,
        "text": " How to make the request.",
        "tokens": [
          51314,
          1012,
          281,
          652,
          264,
          5308,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20237686264682825,
        "compression_ratio": 1.7721518987341771,
        "end": 292,
        "id": 78,
        "no_speech_prob": 0.3006363809108734,
        "seek": 27100,
        "start": 291,
        "temperature": 0,
        "text": " How to get the data and then present the data.",
        "tokens": [
          51364,
          1012,
          281,
          483,
          264,
          1412,
          293,
          550,
          1974,
          264,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20237686264682825,
        "compression_ratio": 1.7721518987341771,
        "end": 297,
        "id": 79,
        "no_speech_prob": 0.3006363809108734,
        "seek": 27100,
        "start": 292,
        "temperature": 0,
        "text": " And hopefully, you know, maybe follow this video along but use a completely different weather API while you're following.",
        "tokens": [
          51414,
          400,
          4696,
          11,
          291,
          458,
          11,
          1310,
          1524,
          341,
          960,
          2051,
          457,
          764,
          257,
          2584,
          819,
          5503,
          9362,
          1339,
          291,
          434,
          3480,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 304,
        "id": 80,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 298,
        "temperature": 0,
        "text": " So unlike the International Space Station API that we looked at in a previous video, the Dark Sky API requires you to authenticate.",
        "tokens": [
          50414,
          407,
          8343,
          264,
          9157,
          8705,
          14467,
          9362,
          300,
          321,
          2956,
          412,
          294,
          257,
          3894,
          960,
          11,
          264,
          9563,
          9879,
          9362,
          7029,
          291,
          281,
          9214,
          8700,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 306,
        "id": 81,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 304,
        "temperature": 0,
        "text": " It's pretty simple to authenticate.",
        "tokens": [
          50714,
          467,
          311,
          1238,
          2199,
          281,
          9214,
          8700,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 308,
        "id": 82,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 306,
        "temperature": 0,
        "text": " All you need is a single API key.",
        "tokens": [
          50814,
          1057,
          291,
          643,
          307,
          257,
          2167,
          9362,
          2141,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 310,
        "id": 83,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 308,
        "temperature": 0,
        "text": " Other APIs can have a much more involved process.",
        "tokens": [
          50914,
          5358,
          21445,
          393,
          362,
          257,
          709,
          544,
          3288,
          1399,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 316,
        "id": 84,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 310,
        "temperature": 0,
        "text": " But if you're going to follow along and use this, you're going to need to first go to darksky.net and click sign up.",
        "tokens": [
          51014,
          583,
          498,
          291,
          434,
          516,
          281,
          1524,
          2051,
          293,
          764,
          341,
          11,
          291,
          434,
          516,
          281,
          643,
          281,
          700,
          352,
          281,
          2877,
          25810,
          13,
          7129,
          293,
          2052,
          1465,
          493,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 320,
        "id": 85,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 316,
        "temperature": 0,
        "text": " You're going to want to register with your email address and make up a password.",
        "tokens": [
          51314,
          509,
          434,
          516,
          281,
          528,
          281,
          7280,
          365,
          428,
          3796,
          2985,
          293,
          652,
          493,
          257,
          11524,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 321,
        "id": 86,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 320,
        "temperature": 0,
        "text": " Now I've already done that.",
        "tokens": [
          51514,
          823,
          286,
          600,
          1217,
          1096,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 323,
        "id": 87,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 321,
        "temperature": 0,
        "text": " So I'm just going to go straight to logging in.",
        "tokens": [
          51564,
          407,
          286,
          478,
          445,
          516,
          281,
          352,
          2997,
          281,
          27991,
          294,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15777024412466809,
        "compression_ratio": 1.7076023391812865,
        "end": 326,
        "id": 88,
        "no_speech_prob": 0.1293637901544571,
        "seek": 29700,
        "start": 323,
        "temperature": 0,
        "text": " Once you're logged in, you'll arrive exactly to this page.",
        "tokens": [
          51664,
          3443,
          291,
          434,
          27231,
          294,
          11,
          291,
          603,
          8881,
          2293,
          281,
          341,
          3028,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 328,
        "id": 89,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 326,
        "temperature": 0,
        "text": " And you can see this is really important.",
        "tokens": [
          50364,
          400,
          291,
          393,
          536,
          341,
          307,
          534,
          1021,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 330,
        "id": 90,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 328,
        "temperature": 0,
        "text": " This is my API key.",
        "tokens": [
          50464,
          639,
          307,
          452,
          9362,
          2141,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 336,
        "id": 91,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 330,
        "temperature": 0,
        "text": " Now there's a little bit of irony here that I'm in this public video on YouTube showing you my API key right here.",
        "tokens": [
          50564,
          823,
          456,
          311,
          257,
          707,
          857,
          295,
          35365,
          510,
          300,
          286,
          478,
          294,
          341,
          1908,
          960,
          322,
          3088,
          4099,
          291,
          452,
          9362,
          2141,
          558,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 341,
        "id": 92,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 336,
        "temperature": 0,
        "text": " I will, by the time you're watching this, I'm going to have regenerated my API key and this one won't be valid.",
        "tokens": [
          50864,
          286,
          486,
          11,
          538,
          264,
          565,
          291,
          434,
          1976,
          341,
          11,
          286,
          478,
          516,
          281,
          362,
          26358,
          770,
          452,
          9362,
          2141,
          293,
          341,
          472,
          1582,
          380,
          312,
          7363,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 342,
        "id": 93,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 341,
        "temperature": 0,
        "text": " So don't try typing this one in.",
        "tokens": [
          51114,
          407,
          500,
          380,
          853,
          18444,
          341,
          472,
          294,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 344,
        "id": 94,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 342,
        "temperature": 0,
        "text": " You're going to need to get your own.",
        "tokens": [
          51164,
          509,
          434,
          516,
          281,
          643,
          281,
          483,
          428,
          1065,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 346,
        "id": 95,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 344,
        "temperature": 0,
        "text": " But while I'm making this video, this is the one that I'm going to use.",
        "tokens": [
          51264,
          583,
          1339,
          286,
          478,
          1455,
          341,
          960,
          11,
          341,
          307,
          264,
          472,
          300,
          286,
          478,
          516,
          281,
          764,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1656108751688918,
        "compression_ratio": 1.7789115646258504,
        "end": 352,
        "id": 96,
        "no_speech_prob": 0.003075318643823266,
        "seek": 32600,
        "start": 346,
        "temperature": 0,
        "text": " The other thing that I love about this is already, right, I need to read the documentation.",
        "tokens": [
          51364,
          440,
          661,
          551,
          300,
          286,
          959,
          466,
          341,
          307,
          1217,
          11,
          558,
          11,
          286,
          643,
          281,
          1401,
          264,
          14333,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 358,
        "id": 97,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 352,
        "temperature": 0,
        "text": " But even without reading the documentation, right here I can see a URL for making an API call.",
        "tokens": [
          50364,
          583,
          754,
          1553,
          3760,
          264,
          14333,
          11,
          558,
          510,
          286,
          393,
          536,
          257,
          12905,
          337,
          1455,
          364,
          9362,
          818,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 363,
        "id": 98,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 358,
        "temperature": 0,
        "text": " So if I want to get the forecast, all I need is api.darksky.net slash forecast.",
        "tokens": [
          50664,
          407,
          498,
          286,
          528,
          281,
          483,
          264,
          14330,
          11,
          439,
          286,
          643,
          307,
          1882,
          72,
          13,
          67,
          809,
          25810,
          13,
          7129,
          17330,
          14330,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 364,
        "id": 99,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 363,
        "temperature": 0,
        "text": " That's the endpoint.",
        "tokens": [
          50914,
          663,
          311,
          264,
          35795,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 366,
        "id": 100,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 364,
        "temperature": 0,
        "text": " We've learned about endpoints now.",
        "tokens": [
          50964,
          492,
          600,
          3264,
          466,
          917,
          20552,
          586,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 370,
        "id": 101,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 366,
        "temperature": 0,
        "text": " My API key and then slash latitude comma longitude.",
        "tokens": [
          51064,
          1222,
          9362,
          2141,
          293,
          550,
          17330,
          45436,
          22117,
          938,
          4377,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 378,
        "id": 102,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 370,
        "temperature": 0,
        "text": " So I can actually just click on this, open it in a new tab, and we can see, look, this is weather for, that's a latitude and longitude for Los Angeles.",
        "tokens": [
          51264,
          407,
          286,
          393,
          767,
          445,
          2052,
          322,
          341,
          11,
          1269,
          309,
          294,
          257,
          777,
          4421,
          11,
          293,
          321,
          393,
          536,
          11,
          574,
          11,
          341,
          307,
          5503,
          337,
          11,
          300,
          311,
          257,
          45436,
          293,
          938,
          4377,
          337,
          7632,
          12292,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 379,
        "id": 103,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 378,
        "temperature": 0,
        "text": " I'm getting a summary.",
        "tokens": [
          51664,
          286,
          478,
          1242,
          257,
          12691,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1769415122875269,
        "compression_ratio": 1.6838487972508591,
        "end": 380,
        "id": 104,
        "no_speech_prob": 0.10087200999259949,
        "seek": 35200,
        "start": 379,
        "temperature": 0,
        "text": " I'm getting near storm distance.",
        "tokens": [
          51714,
          286,
          478,
          1242,
          2651,
          7679,
          4560,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17190267421581126,
        "compression_ratio": 1.556910569105691,
        "end": 381,
        "id": 105,
        "no_speech_prob": 0.007232611998915672,
        "seek": 38000,
        "start": 380,
        "temperature": 0,
        "text": " All sorts of information.",
        "tokens": [
          50364,
          1057,
          7527,
          295,
          1589,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17190267421581126,
        "compression_ratio": 1.556910569105691,
        "end": 384,
        "id": 106,
        "no_speech_prob": 0.007232611998915672,
        "seek": 38000,
        "start": 381,
        "temperature": 0,
        "text": " I can use any of this in my application.",
        "tokens": [
          50414,
          286,
          393,
          764,
          604,
          295,
          341,
          294,
          452,
          3861,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17190267421581126,
        "compression_ratio": 1.556910569105691,
        "end": 392,
        "id": 107,
        "no_speech_prob": 0.007232611998915672,
        "seek": 38000,
        "start": 384,
        "temperature": 0,
        "text": " So let's assume what I want to do is now request this API endpoint in my client side JavaScript.",
        "tokens": [
          50564,
          407,
          718,
          311,
          6552,
          437,
          286,
          528,
          281,
          360,
          307,
          586,
          5308,
          341,
          9362,
          35795,
          294,
          452,
          6423,
          1252,
          15778,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17190267421581126,
        "compression_ratio": 1.556910569105691,
        "end": 393,
        "id": 108,
        "no_speech_prob": 0.007232611998915672,
        "seek": 38000,
        "start": 392,
        "temperature": 0,
        "text": " That's a thing that we've done before.",
        "tokens": [
          50964,
          663,
          311,
          257,
          551,
          300,
          321,
          600,
          1096,
          949,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17190267421581126,
        "compression_ratio": 1.556910569105691,
        "end": 395,
        "id": 109,
        "no_speech_prob": 0.007232611998915672,
        "seek": 38000,
        "start": 393,
        "temperature": 0,
        "text": " We did that with International Space Station.",
        "tokens": [
          51014,
          492,
          630,
          300,
          365,
          9157,
          8705,
          14467,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17190267421581126,
        "compression_ratio": 1.556910569105691,
        "end": 397,
        "id": 110,
        "no_speech_prob": 0.007232611998915672,
        "seek": 38000,
        "start": 395,
        "temperature": 0,
        "text": " So I'm going to grab this URL.",
        "tokens": [
          51114,
          407,
          286,
          478,
          516,
          281,
          4444,
          341,
          12905,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17190267421581126,
        "compression_ratio": 1.556910569105691,
        "end": 405,
        "id": 111,
        "no_speech_prob": 0.007232611998915672,
        "seek": 38000,
        "start": 397,
        "temperature": 0,
        "text": " So right here, once I geolocated, then I can say I can make an API URL, which is equal to exactly that.",
        "tokens": [
          51214,
          407,
          558,
          510,
          11,
          1564,
          286,
          1519,
          401,
          905,
          770,
          11,
          550,
          286,
          393,
          584,
          286,
          393,
          652,
          364,
          9362,
          12905,
          11,
          597,
          307,
          2681,
          281,
          2293,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18085600909064797,
        "compression_ratio": 1.6218905472636815,
        "end": 421,
        "id": 112,
        "no_speech_prob": 0.04401719942688942,
        "seek": 40500,
        "start": 405,
        "temperature": 0,
        "text": " But instead of, I'm going to make this a string literal because instead of hard coding in the latitude and longitude, I might as well say latitude comma longitude.",
        "tokens": [
          50364,
          583,
          2602,
          295,
          11,
          286,
          478,
          516,
          281,
          652,
          341,
          257,
          6798,
          20411,
          570,
          2602,
          295,
          1152,
          17720,
          294,
          264,
          45436,
          293,
          938,
          4377,
          11,
          286,
          1062,
          382,
          731,
          584,
          45436,
          22117,
          938,
          4377,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18085600909064797,
        "compression_ratio": 1.6218905472636815,
        "end": 424,
        "id": 113,
        "no_speech_prob": 0.04401719942688942,
        "seek": 40500,
        "start": 421,
        "temperature": 0,
        "text": " And then now I can say this is all stuff we've done before.",
        "tokens": [
          51164,
          400,
          550,
          586,
          286,
          393,
          584,
          341,
          307,
          439,
          1507,
          321,
          600,
          1096,
          949,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18085600909064797,
        "compression_ratio": 1.6218905472636815,
        "end": 427,
        "id": 114,
        "no_speech_prob": 0.04401719942688942,
        "seek": 40500,
        "start": 424,
        "temperature": 0,
        "text": " I can fetch, make a get request to that API URL.",
        "tokens": [
          51314,
          286,
          393,
          23673,
          11,
          652,
          257,
          483,
          5308,
          281,
          300,
          9362,
          12905,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18085600909064797,
        "compression_ratio": 1.6218905472636815,
        "end": 432,
        "id": 115,
        "no_speech_prob": 0.04401719942688942,
        "seek": 40500,
        "start": 427,
        "temperature": 0,
        "text": " So I can say the response equals await fetch API URL.",
        "tokens": [
          51464,
          407,
          286,
          393,
          584,
          264,
          4134,
          6915,
          19670,
          23673,
          9362,
          12905,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1898055076599121,
        "compression_ratio": 1.3636363636363635,
        "end": 439,
        "id": 116,
        "no_speech_prob": 0.019418541342020035,
        "seek": 43200,
        "start": 432,
        "temperature": 0,
        "text": " Now, since I'm using the keyword await, I need to add the async keyword up here to this callback function.",
        "tokens": [
          50364,
          823,
          11,
          1670,
          286,
          478,
          1228,
          264,
          20428,
          19670,
          11,
          286,
          643,
          281,
          909,
          264,
          382,
          34015,
          20428,
          493,
          510,
          281,
          341,
          818,
          3207,
          2445,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1898055076599121,
        "compression_ratio": 1.3636363636363635,
        "end": 448,
        "id": 117,
        "no_speech_prob": 0.019418541342020035,
        "seek": 43200,
        "start": 439,
        "temperature": 0,
        "text": " Then I can say JSON equals await response dot JSON.",
        "tokens": [
          50714,
          1396,
          286,
          393,
          584,
          31828,
          6915,
          19670,
          4134,
          5893,
          31828,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1898055076599121,
        "compression_ratio": 1.3636363636363635,
        "end": 451,
        "id": 118,
        "no_speech_prob": 0.019418541342020035,
        "seek": 43200,
        "start": 448,
        "temperature": 0,
        "text": " And then I can console log the data.",
        "tokens": [
          51164,
          400,
          550,
          286,
          393,
          11076,
          3565,
          264,
          1412,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20015110075473785,
        "compression_ratio": 1.6277372262773722,
        "end": 462,
        "id": 119,
        "no_speech_prob": 0.10519290715456009,
        "seek": 45100,
        "start": 451,
        "temperature": 0,
        "text": " So in theory now, the feature that I've added here, in addition to geolocating, I'm going to take that geolocation, send it to the darksky.net API, and get the weather information back.",
        "tokens": [
          50364,
          407,
          294,
          5261,
          586,
          11,
          264,
          4111,
          300,
          286,
          600,
          3869,
          510,
          11,
          294,
          4500,
          281,
          1519,
          401,
          905,
          990,
          11,
          286,
          478,
          516,
          281,
          747,
          300,
          1519,
          401,
          27943,
          11,
          2845,
          309,
          281,
          264,
          2877,
          25810,
          13,
          7129,
          9362,
          11,
          293,
          483,
          264,
          5503,
          1589,
          646,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20015110075473785,
        "compression_ratio": 1.6277372262773722,
        "end": 464,
        "id": 120,
        "no_speech_prob": 0.10519290715456009,
        "seek": 45100,
        "start": 462,
        "temperature": 0,
        "text": " Let's try giving that a run.",
        "tokens": [
          50914,
          961,
          311,
          853,
          2902,
          300,
          257,
          1190,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20015110075473785,
        "compression_ratio": 1.6277372262773722,
        "end": 466,
        "id": 121,
        "no_speech_prob": 0.10519290715456009,
        "seek": 45100,
        "start": 464,
        "temperature": 0,
        "text": " Going here to here, hitting refresh.",
        "tokens": [
          51014,
          10963,
          510,
          281,
          510,
          11,
          8850,
          15134,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20015110075473785,
        "compression_ratio": 1.6277372262773722,
        "end": 468,
        "id": 122,
        "no_speech_prob": 0.10519290715456009,
        "seek": 45100,
        "start": 466,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51114,
          2438,
          0,
          51214
        ]
      },
      {
        "avg_logprob": -0.20015110075473785,
        "compression_ratio": 1.6277372262773722,
        "end": 474,
        "id": 123,
        "no_speech_prob": 0.10519290715456009,
        "seek": 45100,
        "start": 468,
        "temperature": 0,
        "text": " I'm the only person in the entire world that's really excited to see the dreaded CORS error.",
        "tokens": [
          51214,
          286,
          478,
          264,
          787,
          954,
          294,
          264,
          2302,
          1002,
          300,
          311,
          534,
          2919,
          281,
          536,
          264,
          22236,
          292,
          43137,
          50,
          6713,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20015110075473785,
        "compression_ratio": 1.6277372262773722,
        "end": 477,
        "id": 124,
        "no_speech_prob": 0.10519290715456009,
        "seek": 45100,
        "start": 474,
        "temperature": 0,
        "text": " CORS stands for cross-origin resource sharing.",
        "tokens": [
          51514,
          43137,
          50,
          7382,
          337,
          3278,
          12,
          20632,
          259,
          7684,
          5414,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20015110075473785,
        "compression_ratio": 1.6277372262773722,
        "end": 480,
        "id": 125,
        "no_speech_prob": 0.10519290715456009,
        "seek": 45100,
        "start": 477,
        "temperature": 0,
        "text": " And it's the way that if it's enabled or disabled.",
        "tokens": [
          51664,
          400,
          309,
          311,
          264,
          636,
          300,
          498,
          309,
          311,
          15172,
          420,
          15191,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17461144019817484,
        "compression_ratio": 1.70625,
        "end": 486,
        "id": 126,
        "no_speech_prob": 0.048134945333004,
        "seek": 48000,
        "start": 480,
        "temperature": 0,
        "text": " If it's enabled, it's saying, like, hey, I want you as a separate server from a different origin to be able to share my resources.",
        "tokens": [
          50364,
          759,
          309,
          311,
          15172,
          11,
          309,
          311,
          1566,
          11,
          411,
          11,
          4177,
          11,
          286,
          528,
          291,
          382,
          257,
          4994,
          7154,
          490,
          257,
          819,
          4957,
          281,
          312,
          1075,
          281,
          2073,
          452,
          3593,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17461144019817484,
        "compression_ratio": 1.70625,
        "end": 494,
        "id": 127,
        "no_speech_prob": 0.048134945333004,
        "seek": 48000,
        "start": 486,
        "temperature": 0,
        "text": " Now, the thing that's sort of crucial here, if CORS is disabled, it's not that the API is saying you can't have access to my data.",
        "tokens": [
          50664,
          823,
          11,
          264,
          551,
          300,
          311,
          1333,
          295,
          11462,
          510,
          11,
          498,
          43137,
          50,
          307,
          15191,
          11,
          309,
          311,
          406,
          300,
          264,
          9362,
          307,
          1566,
          291,
          393,
          380,
          362,
          2105,
          281,
          452,
          1412,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17461144019817484,
        "compression_ratio": 1.70625,
        "end": 498,
        "id": 128,
        "no_speech_prob": 0.048134945333004,
        "seek": 48000,
        "start": 494,
        "temperature": 0,
        "text": " It's just requiring that you do it from your own server.",
        "tokens": [
          51064,
          467,
          311,
          445,
          24165,
          300,
          291,
          360,
          309,
          490,
          428,
          1065,
          7154,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17461144019817484,
        "compression_ratio": 1.70625,
        "end": 500,
        "id": 129,
        "no_speech_prob": 0.048134945333004,
        "seek": 48000,
        "start": 498,
        "temperature": 0,
        "text": " And this is something that's explained in the darksky API's FAQ.",
        "tokens": [
          51264,
          400,
          341,
          307,
          746,
          300,
          311,
          8825,
          294,
          264,
          2877,
          25810,
          9362,
          311,
          19894,
          48,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17461144019817484,
        "compression_ratio": 1.70625,
        "end": 504,
        "id": 130,
        "no_speech_prob": 0.048134945333004,
        "seek": 48000,
        "start": 500,
        "temperature": 0,
        "text": " If you scroll down, you'll find the question, why do I get the error no access control allow origin?",
        "tokens": [
          51364,
          759,
          291,
          11369,
          760,
          11,
          291,
          603,
          915,
          264,
          1168,
          11,
          983,
          360,
          286,
          483,
          264,
          6713,
          572,
          2105,
          1969,
          2089,
          4957,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.17461144019817484,
        "compression_ratio": 1.70625,
        "end": 507,
        "id": 131,
        "no_speech_prob": 0.048134945333004,
        "seek": 48000,
        "start": 504,
        "temperature": 0,
        "text": " And it's because they explain that it's for security reasons.",
        "tokens": [
          51564,
          400,
          309,
          311,
          570,
          436,
          2903,
          300,
          309,
          311,
          337,
          3825,
          4112,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1675601240064277,
        "compression_ratio": 1.7590361445783131,
        "end": 514,
        "id": 132,
        "no_speech_prob": 0.0025114475283771753,
        "seek": 50700,
        "start": 507,
        "temperature": 0,
        "text": " Because the API key is part of that request, they want you to enforce that you can't make that request from client-side code.",
        "tokens": [
          50364,
          1436,
          264,
          9362,
          2141,
          307,
          644,
          295,
          300,
          5308,
          11,
          436,
          528,
          291,
          281,
          24825,
          300,
          291,
          393,
          380,
          652,
          300,
          5308,
          490,
          6423,
          12,
          1812,
          3089,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1675601240064277,
        "compression_ratio": 1.7590361445783131,
        "end": 516,
        "id": 133,
        "no_speech_prob": 0.0025114475283771753,
        "seek": 50700,
        "start": 514,
        "temperature": 0,
        "text": " You can only do it from server-side code.",
        "tokens": [
          50714,
          509,
          393,
          787,
          360,
          309,
          490,
          7154,
          12,
          1812,
          3089,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1675601240064277,
        "compression_ratio": 1.7590361445783131,
        "end": 521,
        "id": 134,
        "no_speech_prob": 0.0025114475283771753,
        "seek": 50700,
        "start": 516,
        "temperature": 0,
        "text": " So this is a nice demonstration of how we're going to make that request from Node itself.",
        "tokens": [
          50814,
          407,
          341,
          307,
          257,
          1481,
          16520,
          295,
          577,
          321,
          434,
          516,
          281,
          652,
          300,
          5308,
          490,
          38640,
          2564,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1675601240064277,
        "compression_ratio": 1.7590361445783131,
        "end": 528,
        "id": 135,
        "no_speech_prob": 0.0025114475283771753,
        "seek": 50700,
        "start": 521,
        "temperature": 0,
        "text": " So, in fact, what I want to do is take this code itself and put it in the server.",
        "tokens": [
          51064,
          407,
          11,
          294,
          1186,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          747,
          341,
          3089,
          2564,
          293,
          829,
          309,
          294,
          264,
          7154,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1675601240064277,
        "compression_ratio": 1.7590361445783131,
        "end": 532,
        "id": 136,
        "no_speech_prob": 0.0025114475283771753,
        "seek": 50700,
        "start": 528,
        "temperature": 0,
        "text": " So go to index.js, and I'm just going to paste it in the bottom.",
        "tokens": [
          51414,
          407,
          352,
          281,
          8186,
          13,
          25530,
          11,
          293,
          286,
          478,
          445,
          516,
          281,
          9163,
          309,
          294,
          264,
          2767,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1675601240064277,
        "compression_ratio": 1.7590361445783131,
        "end": 536,
        "id": 137,
        "no_speech_prob": 0.0025114475283771753,
        "seek": 50700,
        "start": 532,
        "temperature": 0,
        "text": " But where do I want to call this?",
        "tokens": [
          51614,
          583,
          689,
          360,
          286,
          528,
          281,
          818,
          341,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.19672221848458954,
        "compression_ratio": 1.5477707006369428,
        "end": 543,
        "id": 138,
        "no_speech_prob": 0.0004512072482611984,
        "seek": 53600,
        "start": 536,
        "temperature": 0,
        "text": " I want to make a new endpoint in my server that receives the latitude and longitude,",
        "tokens": [
          50364,
          286,
          528,
          281,
          652,
          257,
          777,
          35795,
          294,
          452,
          7154,
          300,
          20717,
          264,
          45436,
          293,
          938,
          4377,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.19672221848458954,
        "compression_ratio": 1.5477707006369428,
        "end": 548,
        "id": 139,
        "no_speech_prob": 0.0004512072482611984,
        "seek": 53600,
        "start": 543,
        "temperature": 0,
        "text": " then makes a call out to darksky.net, and then returns that back.",
        "tokens": [
          50714,
          550,
          1669,
          257,
          818,
          484,
          281,
          2877,
          25810,
          13,
          7129,
          11,
          293,
          550,
          11247,
          300,
          646,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19672221848458954,
        "compression_ratio": 1.5477707006369428,
        "end": 551,
        "id": 140,
        "no_speech_prob": 0.0004512072482611984,
        "seek": 53600,
        "start": 548,
        "temperature": 0,
        "text": " So that I could actually have this still in my client.",
        "tokens": [
          50964,
          407,
          300,
          286,
          727,
          767,
          362,
          341,
          920,
          294,
          452,
          6423,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19672221848458954,
        "compression_ratio": 1.5477707006369428,
        "end": 554,
        "id": 141,
        "no_speech_prob": 0.0004512072482611984,
        "seek": 53600,
        "start": 551,
        "temperature": 0,
        "text": " I don't want to actually remove this.",
        "tokens": [
          51114,
          286,
          500,
          380,
          528,
          281,
          767,
          4159,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21141787937709264,
        "compression_ratio": 1.6022099447513811,
        "end": 565,
        "id": 142,
        "no_speech_prob": 0.00433145510032773,
        "seek": 55400,
        "start": 555,
        "temperature": 0,
        "text": " What I want is to change this URL maybe to just a local path, weather slash latitude longitude,",
        "tokens": [
          50414,
          708,
          286,
          528,
          307,
          281,
          1319,
          341,
          12905,
          1310,
          281,
          445,
          257,
          2654,
          3100,
          11,
          5503,
          17330,
          45436,
          938,
          4377,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.21141787937709264,
        "compression_ratio": 1.6022099447513811,
        "end": 570,
        "id": 143,
        "no_speech_prob": 0.00433145510032773,
        "seek": 55400,
        "start": 565,
        "temperature": 0,
        "text": " weather being the endpoint that I'm going to create, and then console.log it here.",
        "tokens": [
          50914,
          5503,
          885,
          264,
          35795,
          300,
          286,
          478,
          516,
          281,
          1884,
          11,
          293,
          550,
          11076,
          13,
          4987,
          309,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21141787937709264,
        "compression_ratio": 1.6022099447513811,
        "end": 580,
        "id": 144,
        "no_speech_prob": 0.00433145510032773,
        "seek": 55400,
        "start": 570,
        "temperature": 0,
        "text": " So I'm going to go into the server, I'm going to make a new endpoint for a get request, I'll call that weather.",
        "tokens": [
          51164,
          407,
          286,
          478,
          516,
          281,
          352,
          666,
          264,
          7154,
          11,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          35795,
          337,
          257,
          483,
          5308,
          11,
          286,
          603,
          818,
          300,
          5503,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24794498336649387,
        "compression_ratio": 1.649789029535865,
        "end": 585,
        "id": 145,
        "no_speech_prob": 0.0013670208863914013,
        "seek": 58000,
        "start": 581,
        "temperature": 0,
        "text": " This is now a function that gets closed off like this.",
        "tokens": [
          50414,
          639,
          307,
          586,
          257,
          2445,
          300,
          2170,
          5395,
          766,
          411,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24794498336649387,
        "compression_ratio": 1.649789029535865,
        "end": 588,
        "id": 146,
        "no_speech_prob": 0.0013670208863914013,
        "seek": 58000,
        "start": 585,
        "temperature": 0,
        "text": " And now, okay, I'm getting some errors here.",
        "tokens": [
          50614,
          400,
          586,
          11,
          1392,
          11,
          286,
          478,
          1242,
          512,
          13603,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24794498336649387,
        "compression_ratio": 1.649789029535865,
        "end": 590,
        "id": 147,
        "no_speech_prob": 0.0013670208863914013,
        "seek": 58000,
        "start": 588,
        "temperature": 0,
        "text": " What's the issue?",
        "tokens": [
          50764,
          708,
          311,
          264,
          2734,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.24794498336649387,
        "compression_ratio": 1.649789029535865,
        "end": 593,
        "id": 148,
        "no_speech_prob": 0.0013670208863914013,
        "seek": 58000,
        "start": 590,
        "temperature": 0,
        "text": " Okay, well, a couple things.",
        "tokens": [
          50864,
          1033,
          11,
          731,
          11,
          257,
          1916,
          721,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24794498336649387,
        "compression_ratio": 1.649789029535865,
        "end": 598,
        "id": 149,
        "no_speech_prob": 0.0013670208863914013,
        "seek": 58000,
        "start": 593,
        "temperature": 0,
        "text": " One is I shouldn't, the argument to the function is called response, so I really shouldn't call that response here.",
        "tokens": [
          51014,
          1485,
          307,
          286,
          4659,
          380,
          11,
          264,
          6770,
          281,
          264,
          2445,
          307,
          1219,
          4134,
          11,
          370,
          286,
          534,
          4659,
          380,
          818,
          300,
          4134,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24794498336649387,
        "compression_ratio": 1.649789029535865,
        "end": 604,
        "id": 150,
        "no_speech_prob": 0.0013670208863914013,
        "seek": 58000,
        "start": 598,
        "temperature": 0,
        "text": " So I'm just going to call this fetch response, and then say fetch response dot JSON.",
        "tokens": [
          51264,
          407,
          286,
          478,
          445,
          516,
          281,
          818,
          341,
          23673,
          4134,
          11,
          293,
          550,
          584,
          23673,
          4134,
          5893,
          31828,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24794498336649387,
        "compression_ratio": 1.649789029535865,
        "end": 606,
        "id": 151,
        "no_speech_prob": 0.0013670208863914013,
        "seek": 58000,
        "start": 604,
        "temperature": 0,
        "text": " But there's a missing piece here, actually.",
        "tokens": [
          51564,
          583,
          456,
          311,
          257,
          5361,
          2522,
          510,
          11,
          767,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16430338791438512,
        "compression_ratio": 1.5819672131147542,
        "end": 610,
        "id": 152,
        "no_speech_prob": 0.0013670147163793445,
        "seek": 60600,
        "start": 606,
        "temperature": 0,
        "text": " Number one is this needs to be an async function, because I'm using await.",
        "tokens": [
          50364,
          5118,
          472,
          307,
          341,
          2203,
          281,
          312,
          364,
          382,
          34015,
          2445,
          11,
          570,
          286,
          478,
          1228,
          19670,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16430338791438512,
        "compression_ratio": 1.5819672131147542,
        "end": 616,
        "id": 153,
        "no_speech_prob": 0.0013670147163793445,
        "seek": 60600,
        "start": 610,
        "temperature": 0,
        "text": " And then, instead of console.logging, I want to say response dot JSON, that JSON.",
        "tokens": [
          50564,
          400,
          550,
          11,
          2602,
          295,
          11076,
          13,
          4987,
          3249,
          11,
          286,
          528,
          281,
          584,
          4134,
          5893,
          31828,
          11,
          300,
          31828,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16430338791438512,
        "compression_ratio": 1.5819672131147542,
        "end": 622,
        "id": 154,
        "no_speech_prob": 0.0013670147163793445,
        "seek": 60600,
        "start": 616,
        "temperature": 0,
        "text": " So I'm going to make the API call from within here, and then send it back.",
        "tokens": [
          50864,
          407,
          286,
          478,
          516,
          281,
          652,
          264,
          9362,
          818,
          490,
          1951,
          510,
          11,
          293,
          550,
          2845,
          309,
          646,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16430338791438512,
        "compression_ratio": 1.5819672131147542,
        "end": 624,
        "id": 155,
        "no_speech_prob": 0.0013670147163793445,
        "seek": 60600,
        "start": 622,
        "temperature": 0,
        "text": " This is what's known as a proxy server.",
        "tokens": [
          51164,
          639,
          307,
          437,
          311,
          2570,
          382,
          257,
          29690,
          7154,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16430338791438512,
        "compression_ratio": 1.5819672131147542,
        "end": 628,
        "id": 156,
        "no_speech_prob": 0.0013670147163793445,
        "seek": 60600,
        "start": 624,
        "temperature": 0,
        "text": " It's basically the server is a proxy for darksky.net.",
        "tokens": [
          51264,
          467,
          311,
          1936,
          264,
          7154,
          307,
          257,
          29690,
          337,
          2877,
          25810,
          13,
          7129,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16430338791438512,
        "compression_ratio": 1.5819672131147542,
        "end": 632,
        "id": 157,
        "no_speech_prob": 0.0013670147163793445,
        "seek": 60600,
        "start": 628,
        "temperature": 0,
        "text": " I can't make the call to darksky.net directly in the client,",
        "tokens": [
          51464,
          286,
          393,
          380,
          652,
          264,
          818,
          281,
          2877,
          25810,
          13,
          7129,
          3838,
          294,
          264,
          6423,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.1691064567209404,
        "compression_ratio": 1.6581196581196582,
        "end": 637,
        "id": 158,
        "no_speech_prob": 0.16450247168540955,
        "seek": 63200,
        "start": 632,
        "temperature": 0,
        "text": " so I just send off the latitude and longitude, receive it here, and make that request.",
        "tokens": [
          50364,
          370,
          286,
          445,
          2845,
          766,
          264,
          45436,
          293,
          938,
          4377,
          11,
          4774,
          309,
          510,
          11,
          293,
          652,
          300,
          5308,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1691064567209404,
        "compression_ratio": 1.6581196581196582,
        "end": 639,
        "id": 159,
        "no_speech_prob": 0.16450247168540955,
        "seek": 63200,
        "start": 637,
        "temperature": 0,
        "text": " Ah, but wait a second.",
        "tokens": [
          50614,
          2438,
          11,
          457,
          1699,
          257,
          1150,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1691064567209404,
        "compression_ratio": 1.6581196581196582,
        "end": 643,
        "id": 160,
        "no_speech_prob": 0.16450247168540955,
        "seek": 63200,
        "start": 639,
        "temperature": 0,
        "text": " How do I have these variables latitude, longitude?",
        "tokens": [
          50714,
          1012,
          360,
          286,
          362,
          613,
          9102,
          45436,
          11,
          938,
          4377,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.1691064567209404,
        "compression_ratio": 1.6581196581196582,
        "end": 644,
        "id": 161,
        "no_speech_prob": 0.16450247168540955,
        "seek": 63200,
        "start": 643,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50914,
          876,
          11,
          3237,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1691064567209404,
        "compression_ratio": 1.6581196581196582,
        "end": 648,
        "id": 162,
        "no_speech_prob": 0.16450247168540955,
        "seek": 63200,
        "start": 644,
        "temperature": 0,
        "text": " This is opening up a can of worms about passing parameters within API.",
        "tokens": [
          50964,
          639,
          307,
          5193,
          493,
          257,
          393,
          295,
          28271,
          466,
          8437,
          9834,
          1951,
          9362,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1691064567209404,
        "compression_ratio": 1.6581196581196582,
        "end": 650,
        "id": 163,
        "no_speech_prob": 0.16450247168540955,
        "seek": 63200,
        "start": 648,
        "temperature": 0,
        "text": " Here I am in the client-side code.",
        "tokens": [
          51164,
          1692,
          286,
          669,
          294,
          264,
          6423,
          12,
          1812,
          3089,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1691064567209404,
        "compression_ratio": 1.6581196581196582,
        "end": 657,
        "id": 164,
        "no_speech_prob": 0.16450247168540955,
        "seek": 63200,
        "start": 650,
        "temperature": 0,
        "text": " I want to send to my new weather endpoint the latitude and longitude that I've gotten from the client-side code.",
        "tokens": [
          51264,
          286,
          528,
          281,
          2845,
          281,
          452,
          777,
          5503,
          35795,
          264,
          45436,
          293,
          938,
          4377,
          300,
          286,
          600,
          5768,
          490,
          264,
          6423,
          12,
          1812,
          3089,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17128243910527863,
        "compression_ratio": 1.7675438596491229,
        "end": 665,
        "id": 165,
        "no_speech_prob": 0.00009915261034620926,
        "seek": 65700,
        "start": 657,
        "temperature": 0,
        "text": " Then, somehow in the server, I need to pass, I need to receive those and put them in here when I send the dark sky.",
        "tokens": [
          50364,
          1396,
          11,
          6063,
          294,
          264,
          7154,
          11,
          286,
          643,
          281,
          1320,
          11,
          286,
          643,
          281,
          4774,
          729,
          293,
          829,
          552,
          294,
          510,
          562,
          286,
          2845,
          264,
          2877,
          5443,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17128243910527863,
        "compression_ratio": 1.7675438596491229,
        "end": 667,
        "id": 166,
        "no_speech_prob": 0.00009915261034620926,
        "seek": 65700,
        "start": 665,
        "temperature": 0,
        "text": " Now, I need to show you how this is going to work.",
        "tokens": [
          50764,
          823,
          11,
          286,
          643,
          281,
          855,
          291,
          577,
          341,
          307,
          516,
          281,
          589,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17128243910527863,
        "compression_ratio": 1.7675438596491229,
        "end": 670,
        "id": 167,
        "no_speech_prob": 0.00009915261034620926,
        "seek": 65700,
        "start": 667,
        "temperature": 0,
        "text": " But for right now, let's just make sure this is actually working.",
        "tokens": [
          50864,
          583,
          337,
          558,
          586,
          11,
          718,
          311,
          445,
          652,
          988,
          341,
          307,
          767,
          1364,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17128243910527863,
        "compression_ratio": 1.7675438596491229,
        "end": 674,
        "id": 168,
        "no_speech_prob": 0.00009915261034620926,
        "seek": 65700,
        "start": 670,
        "temperature": 0,
        "text": " Let's just hard code in the latitude and longitude.",
        "tokens": [
          51014,
          961,
          311,
          445,
          1152,
          3089,
          294,
          264,
          45436,
          293,
          938,
          4377,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17128243910527863,
        "compression_ratio": 1.7675438596491229,
        "end": 679,
        "id": 169,
        "no_speech_prob": 0.00009915261034620926,
        "seek": 65700,
        "start": 674,
        "temperature": 0,
        "text": " So I'm going to go back to this particular latitude and longitude that I know will work.",
        "tokens": [
          51214,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          341,
          1729,
          45436,
          293,
          938,
          4377,
          300,
          286,
          458,
          486,
          589,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17128243910527863,
        "compression_ratio": 1.7675438596491229,
        "end": 680,
        "id": 170,
        "no_speech_prob": 0.00009915261034620926,
        "seek": 65700,
        "start": 679,
        "temperature": 0,
        "text": " I'm going to go to my server.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          352,
          281,
          452,
          7154,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.14931471370956273,
        "compression_ratio": 1.8916256157635467,
        "end": 689,
        "id": 171,
        "no_speech_prob": 0.2479586899280548,
        "seek": 68000,
        "start": 680,
        "temperature": 0,
        "text": " I'm going to comment this out, and I'm going to paste in a hard coded latitude and longitude.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          2871,
          341,
          484,
          11,
          293,
          286,
          478,
          516,
          281,
          9163,
          294,
          257,
          1152,
          34874,
          45436,
          293,
          938,
          4377,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14931471370956273,
        "compression_ratio": 1.8916256157635467,
        "end": 694,
        "id": 172,
        "no_speech_prob": 0.2479586899280548,
        "seek": 68000,
        "start": 689,
        "temperature": 0,
        "text": " So now when I go to that endpoint, I don't need to pass in a latitude and longitude.",
        "tokens": [
          50814,
          407,
          586,
          562,
          286,
          352,
          281,
          300,
          35795,
          11,
          286,
          500,
          380,
          643,
          281,
          1320,
          294,
          257,
          45436,
          293,
          938,
          4377,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14931471370956273,
        "compression_ratio": 1.8916256157635467,
        "end": 698,
        "id": 173,
        "no_speech_prob": 0.2479586899280548,
        "seek": 68000,
        "start": 694,
        "temperature": 0,
        "text": " I am just going to get exactly the weather for Los Angeles.",
        "tokens": [
          51064,
          286,
          669,
          445,
          516,
          281,
          483,
          2293,
          264,
          5503,
          337,
          7632,
          12292,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14931471370956273,
        "compression_ratio": 1.8916256157635467,
        "end": 700,
        "id": 174,
        "no_speech_prob": 0.2479586899280548,
        "seek": 68000,
        "start": 698,
        "temperature": 0,
        "text": " I'm also going to do the same thing in the client.",
        "tokens": [
          51264,
          286,
          478,
          611,
          516,
          281,
          360,
          264,
          912,
          551,
          294,
          264,
          6423,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14931471370956273,
        "compression_ratio": 1.8916256157635467,
        "end": 707,
        "id": 175,
        "no_speech_prob": 0.2479586899280548,
        "seek": 68000,
        "start": 700,
        "temperature": 0,
        "text": " I'm going to just temporarily comment this out and then get rid of the latitude and longitude.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          445,
          23750,
          2871,
          341,
          484,
          293,
          550,
          483,
          3973,
          295,
          264,
          45436,
          293,
          938,
          4377,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 710,
        "id": 176,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 707,
        "temperature": 0,
        "text": " And I think for the paths to be correct, I should have included a slash here.",
        "tokens": [
          50364,
          400,
          286,
          519,
          337,
          264,
          14518,
          281,
          312,
          3006,
          11,
          286,
          820,
          362,
          5556,
          257,
          17330,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 712,
        "id": 177,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 710,
        "temperature": 0,
        "text": " Okay, so let's restart the server.",
        "tokens": [
          50514,
          1033,
          11,
          370,
          718,
          311,
          21022,
          264,
          7154,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 717,
        "id": 178,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 712,
        "temperature": 0,
        "text": " Let's go to the client and hit refresh.",
        "tokens": [
          50614,
          961,
          311,
          352,
          281,
          264,
          6423,
          293,
          2045,
          15134,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 721,
        "id": 179,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 717,
        "temperature": 0,
        "text": " Ah, wait, it's only valid in async function.",
        "tokens": [
          50864,
          2438,
          11,
          1699,
          11,
          309,
          311,
          787,
          7363,
          294,
          382,
          34015,
          2445,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 722,
        "id": 180,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 721,
        "temperature": 0,
        "text": " Sketch.js.",
        "tokens": [
          51064,
          49245,
          13,
          25530,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 725,
        "id": 181,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 722,
        "temperature": 0,
        "text": " I forgot to put my async function in here.",
        "tokens": [
          51114,
          286,
          5298,
          281,
          829,
          452,
          382,
          34015,
          2445,
          294,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 726,
        "id": 182,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 725,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 727,
        "id": 183,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 726,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          51314,
          8239,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 729,
        "id": 184,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 727,
        "temperature": 0,
        "text": " Ah, right.",
        "tokens": [
          51364,
          2438,
          11,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 731,
        "id": 185,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 729,
        "temperature": 0,
        "text": " Let's check the server.",
        "tokens": [
          51464,
          961,
          311,
          1520,
          264,
          7154,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22618311101740057,
        "compression_ratio": 1.5365853658536586,
        "end": 732,
        "id": 186,
        "no_speech_prob": 0.007011716719716787,
        "seek": 70700,
        "start": 731,
        "temperature": 0,
        "text": " Ah-ha, of course.",
        "tokens": [
          51564,
          2438,
          12,
          1641,
          11,
          295,
          1164,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1680543600035108,
        "compression_ratio": 1.705128205128205,
        "end": 737,
        "id": 187,
        "no_speech_prob": 0.2017917037010193,
        "seek": 73200,
        "start": 732,
        "temperature": 0,
        "text": " So up here it's going to give me a nice error that says fetch is not defined.",
        "tokens": [
          50364,
          407,
          493,
          510,
          309,
          311,
          516,
          281,
          976,
          385,
          257,
          1481,
          6713,
          300,
          1619,
          23673,
          307,
          406,
          7642,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1680543600035108,
        "compression_ratio": 1.705128205128205,
        "end": 738,
        "id": 188,
        "no_speech_prob": 0.2017917037010193,
        "seek": 73200,
        "start": 737,
        "temperature": 0,
        "text": " Fetch is not defined.",
        "tokens": [
          50614,
          479,
          7858,
          307,
          406,
          7642,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1680543600035108,
        "compression_ratio": 1.705128205128205,
        "end": 739,
        "id": 189,
        "no_speech_prob": 0.2017917037010193,
        "seek": 73200,
        "start": 738,
        "temperature": 0,
        "text": " I forgot about that.",
        "tokens": [
          50664,
          286,
          5298,
          466,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1680543600035108,
        "compression_ratio": 1.705128205128205,
        "end": 744,
        "id": 190,
        "no_speech_prob": 0.2017917037010193,
        "seek": 73200,
        "start": 739,
        "temperature": 0,
        "text": " Fetch, the web fetch API, is part of the client side browser API.",
        "tokens": [
          50714,
          479,
          7858,
          11,
          264,
          3670,
          23673,
          9362,
          11,
          307,
          644,
          295,
          264,
          6423,
          1252,
          11185,
          9362,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1680543600035108,
        "compression_ratio": 1.705128205128205,
        "end": 750,
        "id": 191,
        "no_speech_prob": 0.2017917037010193,
        "seek": 73200,
        "start": 744,
        "temperature": 0,
        "text": " If I want to use it from within Node, I can, but I need to install a Node package for that.",
        "tokens": [
          50964,
          759,
          286,
          528,
          281,
          764,
          309,
          490,
          1951,
          38640,
          11,
          286,
          393,
          11,
          457,
          286,
          643,
          281,
          3625,
          257,
          38640,
          7372,
          337,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1680543600035108,
        "compression_ratio": 1.705128205128205,
        "end": 753,
        "id": 192,
        "no_speech_prob": 0.2017917037010193,
        "seek": 73200,
        "start": 750,
        "temperature": 0,
        "text": " The package I can use to do that is called Node-fetch.",
        "tokens": [
          51264,
          440,
          7372,
          286,
          393,
          764,
          281,
          360,
          300,
          307,
          1219,
          38640,
          12,
          69,
          7858,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1680543600035108,
        "compression_ratio": 1.705128205128205,
        "end": 760,
        "id": 193,
        "no_speech_prob": 0.2017917037010193,
        "seek": 73200,
        "start": 753,
        "temperature": 0,
        "text": " So I'm going to go over back here and say npm install Node-fetch.",
        "tokens": [
          51414,
          407,
          286,
          478,
          516,
          281,
          352,
          670,
          646,
          510,
          293,
          584,
          297,
          14395,
          3625,
          38640,
          12,
          69,
          7858,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 765,
        "id": 194,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 760,
        "temperature": 0,
        "text": " If I go to my package.json, I can see that that's in there now.",
        "tokens": [
          50364,
          759,
          286,
          352,
          281,
          452,
          7372,
          13,
          73,
          3015,
          11,
          286,
          393,
          536,
          300,
          300,
          311,
          294,
          456,
          586,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 773,
        "id": 195,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 765,
        "temperature": 0,
        "text": " And then most likely what I need to also do is say const fetch equals require Node-fetch.",
        "tokens": [
          50614,
          400,
          550,
          881,
          3700,
          437,
          286,
          643,
          281,
          611,
          360,
          307,
          584,
          1817,
          23673,
          6915,
          3651,
          38640,
          12,
          69,
          7858,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 777,
        "id": 196,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 773,
        "temperature": 0,
        "text": " So that's going to pull the fetch function from Node-fetch.",
        "tokens": [
          51014,
          407,
          300,
          311,
          516,
          281,
          2235,
          264,
          23673,
          2445,
          490,
          38640,
          12,
          69,
          7858,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 779,
        "id": 197,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 777,
        "temperature": 0,
        "text": " So I can add that up here at the top.",
        "tokens": [
          51214,
          407,
          286,
          393,
          909,
          300,
          493,
          510,
          412,
          264,
          1192,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 782,
        "id": 198,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 779,
        "temperature": 0,
        "text": " Fetch equals require Node-fetch.",
        "tokens": [
          51314,
          479,
          7858,
          6915,
          3651,
          38640,
          12,
          69,
          7858,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 784,
        "id": 199,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 782,
        "temperature": 0,
        "text": " Rerun the server.",
        "tokens": [
          51464,
          497,
          260,
          409,
          264,
          7154,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 788,
        "id": 200,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 784,
        "temperature": 0,
        "text": " Give it one more refresh here.",
        "tokens": [
          51564,
          5303,
          309,
          472,
          544,
          15134,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14229781287057058,
        "compression_ratio": 1.6908212560386473,
        "end": 789,
        "id": 201,
        "no_speech_prob": 0.000060141457652207464,
        "seek": 76000,
        "start": 788,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51764,
          400,
          456,
          321,
          352,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 790,
        "id": 202,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 789,
        "temperature": 0,
        "text": " I'm done with that.",
        "tokens": [
          50364,
          286,
          478,
          1096,
          365,
          300,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 794,
        "id": 203,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 790,
        "temperature": 0,
        "text": " I now have the weather from Los Angeles right over there.",
        "tokens": [
          50414,
          286,
          586,
          362,
          264,
          5503,
          490,
          7632,
          12292,
          558,
          670,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 798,
        "id": 204,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 794,
        "temperature": 0,
        "text": " The last step here, I know this has been a bit of a longer video than usual,",
        "tokens": [
          50614,
          440,
          1036,
          1823,
          510,
          11,
          286,
          458,
          341,
          575,
          668,
          257,
          857,
          295,
          257,
          2854,
          960,
          813,
          7713,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 801,
        "id": 205,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 798,
        "temperature": 0,
        "text": " but I just want to finish off this one last step.",
        "tokens": [
          50814,
          457,
          286,
          445,
          528,
          281,
          2413,
          766,
          341,
          472,
          1036,
          1823,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 807,
        "id": 206,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 801,
        "temperature": 0,
        "text": " And this last step is sending from the client the latitude and longitude to the server",
        "tokens": [
          50964,
          400,
          341,
          1036,
          1823,
          307,
          7750,
          490,
          264,
          6423,
          264,
          45436,
          293,
          938,
          4377,
          281,
          264,
          7154,
          51264
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 811,
        "id": 207,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 807,
        "temperature": 0,
        "text": " so that the server can send that latitude and longitude to dark sky, get the weather,",
        "tokens": [
          51264,
          370,
          300,
          264,
          7154,
          393,
          2845,
          300,
          45436,
          293,
          938,
          4377,
          281,
          2877,
          5443,
          11,
          483,
          264,
          5503,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 813,
        "id": 208,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 811,
        "temperature": 0,
        "text": " and then send the weather back to the client.",
        "tokens": [
          51464,
          293,
          550,
          2845,
          264,
          5503,
          646,
          281,
          264,
          6423,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2057690808153528,
        "compression_ratio": 1.872093023255814,
        "end": 816,
        "id": 209,
        "no_speech_prob": 0.10520333796739578,
        "seek": 78900,
        "start": 813,
        "temperature": 0,
        "text": " The way that I'm going to do that is with route parameters.",
        "tokens": [
          51564,
          440,
          636,
          300,
          286,
          478,
          516,
          281,
          360,
          300,
          307,
          365,
          7955,
          9834,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17142573574133085,
        "compression_ratio": 1.6642335766423357,
        "end": 817,
        "id": 210,
        "no_speech_prob": 0.014063159003853798,
        "seek": 81600,
        "start": 816,
        "temperature": 0,
        "text": " Now we learned about routes.",
        "tokens": [
          50364,
          823,
          321,
          3264,
          466,
          18242,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17142573574133085,
        "compression_ratio": 1.6642335766423357,
        "end": 824,
        "id": 211,
        "no_speech_prob": 0.014063159003853798,
        "seek": 81600,
        "start": 817,
        "temperature": 0,
        "text": " If I have a get request or a post request, I set up a route, a path, an endpoint for that particular request.",
        "tokens": [
          50414,
          759,
          286,
          362,
          257,
          483,
          5308,
          420,
          257,
          2183,
          5308,
          11,
          286,
          992,
          493,
          257,
          7955,
          11,
          257,
          3100,
          11,
          364,
          35795,
          337,
          300,
          1729,
          5308,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17142573574133085,
        "compression_ratio": 1.6642335766423357,
        "end": 830,
        "id": 212,
        "no_speech_prob": 0.014063159003853798,
        "seek": 81600,
        "start": 824,
        "temperature": 0,
        "text": " Route parameters are extra parts of that path that you can name and capture as variables essentially",
        "tokens": [
          50764,
          39142,
          9834,
          366,
          2857,
          3166,
          295,
          300,
          3100,
          300,
          291,
          393,
          1315,
          293,
          7983,
          382,
          9102,
          4476,
          51064
        ]
      },
      {
        "avg_logprob": -0.17142573574133085,
        "compression_ratio": 1.6642335766423357,
        "end": 833,
        "id": 213,
        "no_speech_prob": 0.014063159003853798,
        "seek": 81600,
        "start": 830,
        "temperature": 0,
        "text": " with data that's sent from the client.",
        "tokens": [
          51064,
          365,
          1412,
          300,
          311,
          2279,
          490,
          264,
          6423,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17142573574133085,
        "compression_ratio": 1.6642335766423357,
        "end": 836,
        "id": 214,
        "no_speech_prob": 0.014063159003853798,
        "seek": 81600,
        "start": 833,
        "temperature": 0,
        "text": " Another way to do this is with something called a URL query string,",
        "tokens": [
          51214,
          3996,
          636,
          281,
          360,
          341,
          307,
          365,
          746,
          1219,
          257,
          12905,
          14581,
          6798,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17142573574133085,
        "compression_ratio": 1.6642335766423357,
        "end": 838,
        "id": 215,
        "no_speech_prob": 0.014063159003853798,
        "seek": 81600,
        "start": 836,
        "temperature": 0,
        "text": " which I cover in another video.",
        "tokens": [
          51364,
          597,
          286,
          2060,
          294,
          1071,
          960,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17142573574133085,
        "compression_ratio": 1.6642335766423357,
        "end": 842,
        "id": 216,
        "no_speech_prob": 0.014063159003853798,
        "seek": 81600,
        "start": 838,
        "temperature": 0,
        "text": " And so either way would work here, but I'm going to go with route parameters.",
        "tokens": [
          51464,
          400,
          370,
          2139,
          636,
          576,
          589,
          510,
          11,
          457,
          286,
          478,
          516,
          281,
          352,
          365,
          7955,
          9834,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20606650558172487,
        "compression_ratio": 1.6888888888888889,
        "end": 848,
        "id": 217,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 84200,
        "start": 842,
        "temperature": 0,
        "text": " So here on the express documentation, we can see that a route parameter is specified with a colon.",
        "tokens": [
          50364,
          407,
          510,
          322,
          264,
          5109,
          14333,
          11,
          321,
          393,
          536,
          300,
          257,
          7955,
          13075,
          307,
          22206,
          365,
          257,
          8255,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20606650558172487,
        "compression_ratio": 1.6888888888888889,
        "end": 854,
        "id": 218,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 84200,
        "start": 848,
        "temperature": 0,
        "text": " So the route is users, and then I might say users slash Daniel or users slash Shiffman,",
        "tokens": [
          50664,
          407,
          264,
          7955,
          307,
          5022,
          11,
          293,
          550,
          286,
          1062,
          584,
          5022,
          17330,
          8033,
          420,
          5022,
          17330,
          1160,
          3661,
          1601,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20606650558172487,
        "compression_ratio": 1.6888888888888889,
        "end": 858,
        "id": 219,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 84200,
        "start": 854,
        "temperature": 0,
        "text": " and that will come in as a user ID parameter.",
        "tokens": [
          50964,
          293,
          300,
          486,
          808,
          294,
          382,
          257,
          4195,
          7348,
          13075,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20606650558172487,
        "compression_ratio": 1.6888888888888889,
        "end": 862,
        "id": 220,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 84200,
        "start": 858,
        "temperature": 0,
        "text": " So to add that, I'm going to go back to the server.",
        "tokens": [
          51164,
          407,
          281,
          909,
          300,
          11,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          7154,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20606650558172487,
        "compression_ratio": 1.6888888888888889,
        "end": 870,
        "id": 221,
        "no_speech_prob": 0.0010484595550224185,
        "seek": 84200,
        "start": 862,
        "temperature": 0,
        "text": " I can remove this hard-coded lat long in and put back in the one that has the lat long latitude",
        "tokens": [
          51364,
          286,
          393,
          4159,
          341,
          1152,
          12,
          66,
          12340,
          4465,
          938,
          294,
          293,
          829,
          646,
          294,
          264,
          472,
          300,
          575,
          264,
          4465,
          938,
          45436,
          51764
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 872,
        "id": 222,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 870,
        "temperature": 0,
        "text": " and longitude variables.",
        "tokens": [
          50364,
          293,
          938,
          4377,
          9102,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 875,
        "id": 223,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 872,
        "temperature": 0,
        "text": " So now I need to add the route parameters.",
        "tokens": [
          50464,
          407,
          586,
          286,
          643,
          281,
          909,
          264,
          7955,
          9834,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 879,
        "id": 224,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 875,
        "temperature": 0,
        "text": " So one thing I could do is I could do slash colon lat slash colon long,",
        "tokens": [
          50614,
          407,
          472,
          551,
          286,
          727,
          360,
          307,
          286,
          727,
          360,
          17330,
          8255,
          4465,
          17330,
          8255,
          938,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 881,
        "id": 225,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 879,
        "temperature": 0,
        "text": " so I could have two parameters coming in.",
        "tokens": [
          50814,
          370,
          286,
          727,
          362,
          732,
          9834,
          1348,
          294,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 882,
        "id": 226,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 881,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 884,
        "id": 227,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 882,
        "temperature": 0,
        "text": " I think I'm going to just make it one.",
        "tokens": [
          50964,
          286,
          519,
          286,
          478,
          516,
          281,
          445,
          652,
          309,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 887,
        "id": 228,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 884,
        "temperature": 0,
        "text": " I'll call it lat long, and then I'll send it in with a comma.",
        "tokens": [
          51064,
          286,
          603,
          818,
          309,
          4465,
          938,
          11,
          293,
          550,
          286,
          603,
          2845,
          309,
          294,
          365,
          257,
          22117,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 891,
        "id": 229,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 887,
        "temperature": 0,
        "text": " And those, you can see I haven't used this request argument yet.",
        "tokens": [
          51214,
          400,
          729,
          11,
          291,
          393,
          536,
          286,
          2378,
          380,
          1143,
          341,
          5308,
          6770,
          1939,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 893,
        "id": 230,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 891,
        "temperature": 0,
        "text": " This is finally a chance to use that request object.",
        "tokens": [
          51414,
          639,
          307,
          2721,
          257,
          2931,
          281,
          764,
          300,
          5308,
          2657,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1363829012270327,
        "compression_ratio": 1.754646840148699,
        "end": 898,
        "id": 231,
        "no_speech_prob": 0.0011335635790601373,
        "seek": 87000,
        "start": 893,
        "temperature": 0,
        "text": " Inside of the request object is a property called params,",
        "tokens": [
          51514,
          15123,
          295,
          264,
          5308,
          2657,
          307,
          257,
          4707,
          1219,
          971,
          4070,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.14653486772017046,
        "compression_ratio": 1.81651376146789,
        "end": 901,
        "id": 232,
        "no_speech_prob": 0.028435194864869118,
        "seek": 89800,
        "start": 898,
        "temperature": 0,
        "text": " and inside that params object are all of the parameters.",
        "tokens": [
          50364,
          293,
          1854,
          300,
          971,
          4070,
          2657,
          366,
          439,
          295,
          264,
          9834,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14653486772017046,
        "compression_ratio": 1.81651376146789,
        "end": 904,
        "id": 233,
        "no_speech_prob": 0.028435194864869118,
        "seek": 89800,
        "start": 901,
        "temperature": 0,
        "text": " In this case, there's just one parameter, something called lat long.",
        "tokens": [
          50514,
          682,
          341,
          1389,
          11,
          456,
          311,
          445,
          472,
          13075,
          11,
          746,
          1219,
          4465,
          938,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.14653486772017046,
        "compression_ratio": 1.81651376146789,
        "end": 912,
        "id": 234,
        "no_speech_prob": 0.028435194864869118,
        "seek": 89800,
        "start": 904,
        "temperature": 0,
        "text": " So I could type in lat long, or I could also put that in brackets in quotes.",
        "tokens": [
          50664,
          407,
          286,
          727,
          2010,
          294,
          4465,
          938,
          11,
          420,
          286,
          727,
          611,
          829,
          300,
          294,
          26179,
          294,
          19963,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14653486772017046,
        "compression_ratio": 1.81651376146789,
        "end": 915,
        "id": 235,
        "no_speech_prob": 0.028435194864869118,
        "seek": 89800,
        "start": 912,
        "temperature": 0,
        "text": " So either way this will work.",
        "tokens": [
          51064,
          407,
          2139,
          636,
          341,
          486,
          589,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.14653486772017046,
        "compression_ratio": 1.81651376146789,
        "end": 918,
        "id": 236,
        "no_speech_prob": 0.028435194864869118,
        "seek": 89800,
        "start": 915,
        "temperature": 0,
        "text": " I'm going to just go with the dot syntax,",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          445,
          352,
          365,
          264,
          5893,
          28431,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.14653486772017046,
        "compression_ratio": 1.81651376146789,
        "end": 920,
        "id": 237,
        "no_speech_prob": 0.028435194864869118,
        "seek": 89800,
        "start": 918,
        "temperature": 0,
        "text": " and what I'm going to do is I'm going to put that in another variable.",
        "tokens": [
          51364,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          829,
          300,
          294,
          1071,
          7006,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14653486772017046,
        "compression_ratio": 1.81651376146789,
        "end": 923,
        "id": 238,
        "no_speech_prob": 0.028435194864869118,
        "seek": 89800,
        "start": 920,
        "temperature": 0,
        "text": " So I'm going to say constant lat long equals that,",
        "tokens": [
          51464,
          407,
          286,
          478,
          516,
          281,
          584,
          5754,
          4465,
          938,
          6915,
          300,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21209607805524552,
        "compression_ratio": 1.8083832335329342,
        "end": 929,
        "id": 239,
        "no_speech_prob": 0.004681800492107868,
        "seek": 92300,
        "start": 923,
        "temperature": 0,
        "text": " and then I will say actually what I'm going to do is I'm going to do dot split,",
        "tokens": [
          50364,
          293,
          550,
          286,
          486,
          584,
          220,
          578,
          671,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          360,
          5893,
          7472,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.21209607805524552,
        "compression_ratio": 1.8083832335329342,
        "end": 931,
        "id": 240,
        "no_speech_prob": 0.004681800492107868,
        "seek": 92300,
        "start": 929,
        "temperature": 0,
        "text": " and I'll split with a comma,",
        "tokens": [
          50664,
          293,
          286,
          603,
          7472,
          365,
          257,
          22117,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.21209607805524552,
        "compression_ratio": 1.8083832335329342,
        "end": 938,
        "id": 241,
        "no_speech_prob": 0.004681800492107868,
        "seek": 92300,
        "start": 931,
        "temperature": 0,
        "text": " and then the latitude is the lat long index 0,",
        "tokens": [
          50764,
          293,
          550,
          264,
          45436,
          307,
          264,
          4465,
          938,
          8186,
          1958,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.21209607805524552,
        "compression_ratio": 1.8083832335329342,
        "end": 941,
        "id": 242,
        "no_speech_prob": 0.004681800492107868,
        "seek": 92300,
        "start": 938,
        "temperature": 0,
        "text": " and the longitude is lat long index 1.",
        "tokens": [
          51114,
          293,
          264,
          938,
          4377,
          307,
          4465,
          938,
          8186,
          502,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21209607805524552,
        "compression_ratio": 1.8083832335329342,
        "end": 949,
        "id": 243,
        "no_speech_prob": 0.004681800492107868,
        "seek": 92300,
        "start": 941,
        "temperature": 0,
        "text": " So in theory, as long as I send in as the route parameter,",
        "tokens": [
          51264,
          407,
          294,
          5261,
          11,
          382,
          938,
          382,
          286,
          2845,
          294,
          382,
          264,
          7955,
          13075,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.21209607805524552,
        "compression_ratio": 1.8083832335329342,
        "end": 951,
        "id": 244,
        "no_speech_prob": 0.004681800492107868,
        "seek": 92300,
        "start": 949,
        "temperature": 0,
        "text": " the latitude and longitude separated by a comma,",
        "tokens": [
          51664,
          264,
          45436,
          293,
          938,
          4377,
          12005,
          538,
          257,
          22117,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.19339669489227565,
        "compression_ratio": 1.6747967479674797,
        "end": 955,
        "id": 245,
        "no_speech_prob": 0.004681788384914398,
        "seek": 95100,
        "start": 951,
        "temperature": 0,
        "text": " I can pull it out of request.params, split it by comma into an array,",
        "tokens": [
          50364,
          286,
          393,
          2235,
          309,
          484,
          295,
          5308,
          13,
          2181,
          4070,
          11,
          7472,
          309,
          538,
          22117,
          666,
          364,
          10225,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.19339669489227565,
        "compression_ratio": 1.6747967479674797,
        "end": 957,
        "id": 246,
        "no_speech_prob": 0.004681788384914398,
        "seek": 95100,
        "start": 955,
        "temperature": 0,
        "text": " and put them in each one of these variables.",
        "tokens": [
          50564,
          293,
          829,
          552,
          294,
          1184,
          472,
          295,
          613,
          9102,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19339669489227565,
        "compression_ratio": 1.6747967479674797,
        "end": 961,
        "id": 247,
        "no_speech_prob": 0.004681788384914398,
        "seek": 95100,
        "start": 957,
        "temperature": 0,
        "text": " So I probably should have done this more incrementally and console logged some stuff,",
        "tokens": [
          50664,
          407,
          286,
          1391,
          820,
          362,
          1096,
          341,
          544,
          26200,
          379,
          293,
          11076,
          27231,
          512,
          1507,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.19339669489227565,
        "compression_ratio": 1.6747967479674797,
        "end": 964,
        "id": 248,
        "no_speech_prob": 0.004681788384914398,
        "seek": 95100,
        "start": 961,
        "temperature": 0,
        "text": " but let's just hope that this works,",
        "tokens": [
          50864,
          457,
          718,
          311,
          445,
          1454,
          300,
          341,
          1985,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.19339669489227565,
        "compression_ratio": 1.6747967479674797,
        "end": 975,
        "id": 249,
        "no_speech_prob": 0.004681788384914398,
        "seek": 95100,
        "start": 964,
        "temperature": 0,
        "text": " and I'm going to add some console logs to debug just so I see in case something goes wrong.",
        "tokens": [
          51014,
          293,
          286,
          478,
          516,
          281,
          909,
          512,
          11076,
          20820,
          281,
          24083,
          445,
          370,
          286,
          536,
          294,
          1389,
          746,
          1709,
          2085,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19339669489227565,
        "compression_ratio": 1.6747967479674797,
        "end": 976,
        "id": 250,
        "no_speech_prob": 0.004681788384914398,
        "seek": 95100,
        "start": 975,
        "temperature": 0,
        "text": " Then I'm going to go back to the client.",
        "tokens": [
          51564,
          1396,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          6423,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19339669489227565,
        "compression_ratio": 1.6747967479674797,
        "end": 980,
        "id": 251,
        "no_speech_prob": 0.004681788384914398,
        "seek": 95100,
        "start": 976,
        "temperature": 0,
        "text": " Now I need to go back to the client code,",
        "tokens": [
          51614,
          823,
          286,
          643,
          281,
          352,
          646,
          281,
          264,
          6423,
          3089,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 983,
        "id": 252,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 980,
        "temperature": 0,
        "text": " and here I can go back to this, right,",
        "tokens": [
          50364,
          293,
          510,
          286,
          393,
          352,
          646,
          281,
          341,
          11,
          558,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 986,
        "id": 253,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 983,
        "temperature": 0,
        "text": " because this is exactly what I'm sending in.",
        "tokens": [
          50514,
          570,
          341,
          307,
          2293,
          437,
          286,
          478,
          7750,
          294,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 991,
        "id": 254,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 986,
        "temperature": 0,
        "text": " I'm going to the weather route with the parameters latitude comma longitude.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          264,
          5503,
          7955,
          365,
          264,
          9834,
          45436,
          22117,
          938,
          4377,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 992,
        "id": 255,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 991,
        "temperature": 0,
        "text": " All right, I already set that up.",
        "tokens": [
          50914,
          1057,
          558,
          11,
          286,
          1217,
          992,
          300,
          493,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 997,
        "id": 256,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 992,
        "temperature": 0,
        "text": " Okay, let me add one more console log, request.params,",
        "tokens": [
          50964,
          1033,
          11,
          718,
          385,
          909,
          472,
          544,
          11076,
          3565,
          11,
          5308,
          13,
          2181,
          4070,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 999,
        "id": 257,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 997,
        "temperature": 0,
        "text": " so we can see the raw request params,",
        "tokens": [
          51214,
          370,
          321,
          393,
          536,
          264,
          8936,
          5308,
          971,
          4070,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 1001,
        "id": 258,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 999,
        "temperature": 0,
        "text": " and let's hope that this works.",
        "tokens": [
          51314,
          293,
          718,
          311,
          1454,
          300,
          341,
          1985,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 1005,
        "id": 259,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 1001,
        "temperature": 0,
        "text": " Go back to the browser, hit refresh, and there we go.",
        "tokens": [
          51414,
          1037,
          646,
          281,
          264,
          11185,
          11,
          2045,
          15134,
          11,
          293,
          456,
          321,
          352,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20000611534414364,
        "compression_ratio": 1.7132075471698114,
        "end": 1009,
        "id": 260,
        "no_speech_prob": 0.007232622243463993,
        "seek": 98000,
        "start": 1005,
        "temperature": 0,
        "text": " I have got the correct latitude and longitude and the weather now from New York,",
        "tokens": [
          51614,
          286,
          362,
          658,
          264,
          3006,
          45436,
          293,
          938,
          4377,
          293,
          264,
          5503,
          586,
          490,
          1873,
          3609,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1013,
        "id": 261,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1009,
        "temperature": 0,
        "text": " the actual latitude and longitude that I sent to the server.",
        "tokens": [
          50364,
          264,
          3539,
          45436,
          293,
          938,
          4377,
          300,
          286,
          2279,
          281,
          264,
          7154,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1016,
        "id": 262,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1013,
        "temperature": 0,
        "text": " Let's check the server's logs, and you can see there we go.",
        "tokens": [
          50564,
          961,
          311,
          1520,
          264,
          7154,
          311,
          20820,
          11,
          293,
          291,
          393,
          536,
          456,
          321,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1019,
        "id": 263,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1016,
        "temperature": 0,
        "text": " So this is the request parameters that came in.",
        "tokens": [
          50714,
          407,
          341,
          307,
          264,
          5308,
          9834,
          300,
          1361,
          294,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1021,
        "id": 264,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1019,
        "temperature": 0,
        "text": " There was just one called lat long.",
        "tokens": [
          50864,
          821,
          390,
          445,
          472,
          1219,
          4465,
          938,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1024,
        "id": 265,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1021,
        "temperature": 0,
        "text": " Then I used split to turn it into an array,",
        "tokens": [
          50964,
          1396,
          286,
          1143,
          7472,
          281,
          1261,
          309,
          666,
          364,
          10225,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1027,
        "id": 266,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1024,
        "temperature": 0,
        "text": " and then I took the zero index of the array and the index number one of the array.",
        "tokens": [
          51114,
          293,
          550,
          286,
          1890,
          264,
          4018,
          8186,
          295,
          264,
          10225,
          293,
          264,
          8186,
          1230,
          472,
          295,
          264,
          10225,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1031,
        "id": 267,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1027,
        "temperature": 0,
        "text": " So luckily I wrote the correct code, and it actually worked.",
        "tokens": [
          51264,
          407,
          22880,
          286,
          4114,
          264,
          3006,
          3089,
          11,
          293,
          309,
          767,
          2732,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1034,
        "id": 268,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1031,
        "temperature": 0,
        "text": " The next step here would be to present that information.",
        "tokens": [
          51464,
          440,
          958,
          1823,
          510,
          576,
          312,
          281,
          1974,
          300,
          1589,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1035,
        "id": 269,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1034,
        "temperature": 0,
        "text": " I mean there's several next steps here.",
        "tokens": [
          51614,
          286,
          914,
          456,
          311,
          2940,
          958,
          4439,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18233988236407844,
        "compression_ratio": 1.8202614379084967,
        "end": 1038,
        "id": 270,
        "no_speech_prob": 0.0011879000812768936,
        "seek": 100900,
        "start": 1035,
        "temperature": 0,
        "text": " I need to save stuff in the database and all sorts of other things,",
        "tokens": [
          51664,
          286,
          643,
          281,
          3155,
          1507,
          294,
          264,
          8149,
          293,
          439,
          7527,
          295,
          661,
          721,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.17758101646346275,
        "compression_ratio": 1.737991266375546,
        "end": 1045,
        "id": 271,
        "no_speech_prob": 0.0009253606549464166,
        "seek": 103800,
        "start": 1038,
        "temperature": 0,
        "text": " but the small immediate next step would be to display the weather information here in the DOM itself.",
        "tokens": [
          50364,
          457,
          264,
          1359,
          11629,
          958,
          1823,
          576,
          312,
          281,
          4674,
          264,
          5503,
          1589,
          510,
          294,
          264,
          35727,
          2564,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17758101646346275,
        "compression_ratio": 1.737991266375546,
        "end": 1047,
        "id": 272,
        "no_speech_prob": 0.0009253606549464166,
        "seek": 103800,
        "start": 1045,
        "temperature": 0,
        "text": " So I'm going to leave that for you as an exercise.",
        "tokens": [
          50714,
          407,
          286,
          478,
          516,
          281,
          1856,
          300,
          337,
          291,
          382,
          364,
          5380,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17758101646346275,
        "compression_ratio": 1.737991266375546,
        "end": 1049,
        "id": 273,
        "no_speech_prob": 0.0009253606549464166,
        "seek": 103800,
        "start": 1047,
        "temperature": 0,
        "text": " I will do that at the beginning of the next video,",
        "tokens": [
          50814,
          286,
          486,
          360,
          300,
          412,
          264,
          2863,
          295,
          264,
          958,
          960,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17758101646346275,
        "compression_ratio": 1.737991266375546,
        "end": 1053,
        "id": 274,
        "no_speech_prob": 0.0009253606549464166,
        "seek": 103800,
        "start": 1049,
        "temperature": 0,
        "text": " and then I'm going to continue on and make a request to open air quality,",
        "tokens": [
          50914,
          293,
          550,
          286,
          478,
          516,
          281,
          2354,
          322,
          293,
          652,
          257,
          5308,
          281,
          1269,
          1988,
          3125,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.17758101646346275,
        "compression_ratio": 1.737991266375546,
        "end": 1056,
        "id": 275,
        "no_speech_prob": 0.0009253606549464166,
        "seek": 103800,
        "start": 1053,
        "temperature": 0,
        "text": " the open AQ API to get both the weather information",
        "tokens": [
          51114,
          264,
          1269,
          316,
          48,
          9362,
          281,
          483,
          1293,
          264,
          5503,
          1589,
          51264
        ]
      },
      {
        "avg_logprob": -0.17758101646346275,
        "compression_ratio": 1.737991266375546,
        "end": 1059,
        "id": 276,
        "no_speech_prob": 0.0009253606549464166,
        "seek": 103800,
        "start": 1056,
        "temperature": 0,
        "text": " and the air quality information for a single latitude and longitude.",
        "tokens": [
          51264,
          293,
          264,
          1988,
          3125,
          1589,
          337,
          257,
          2167,
          45436,
          293,
          938,
          4377,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.43065668554867015,
        "compression_ratio": 1.025,
        "end": 1064,
        "id": 277,
        "no_speech_prob": 0.8656726479530334,
        "seek": 105900,
        "start": 1059,
        "temperature": 0,
        "text": " Microsoft Mechanics",
        "tokens": [
          50364,
          8116,
          30175,
          1167,
          50614
        ]
      },
      {
        "avg_logprob": -0.43065668554867015,
        "compression_ratio": 1.025,
        "end": 1069,
        "id": 278,
        "no_speech_prob": 0.8656726479530334,
        "seek": 105900,
        "start": 1064,
        "temperature": 0,
        "text": " www.microsoft.com.com",
        "tokens": [
          50614,
          12520,
          13,
          13195,
          7856,
          13,
          1112,
          13,
          1291,
          76,
          50864
        ]
      }
    ],
    "transcription": " Hello and welcome to module three of working with data and APIs in JavaScript. So I just wrapped up module two, the second part, with a project called the Data Selfie app. And there were some new things, hopefully, to you that you learned and are excited to apply in future projects like server-side programming and get requests and post requests and saving data to a database. All of the things. But I think there are some key elements of building a web application that involves data from external APIs and server-side and client-side that I missed. One of the most crucial things, I think, is making an API request to an external data source from the server. And there are a variety of reasons why you might want to do that or need to do that. And I really want to demonstrate that in this new project called the Weather Here. The original Weather Here project is, once again, by Joey Lee and was built for a course called Quant Humanists at NYU, where I also teach. In Joey's project, the user arrives on a web page. There's information about latitude and longitude. We know how to do that already. There's information about the current weather and air quality. This will be new that we want to add. And then a big check-in button. So you press the check-in button. All that information is logged to a database. And then there's also a view where you can view all the different check-ins plotted on a map with Leaflet.js. Most of the functionality that I need for this Weather Here app we already have from the Data Selfie app. But we can start with a sort of baseline of code from there. But there are some new things that I want to demonstrate to you in this project. So number one is I want to add connecting to external APIs. So we're going to use two different APIs, one for weather information and one for air quality. One of those APIs is going to require an API key and not actually even allow us to connect from the client side. So we're going to have to look at, well, how do I connect to an API from Node but then have the client be able to display that information? Because that's going to be a key new thing. I also want to figure out how do I hide the API key. So if I open source and publish my code but I don't want to include my API keys, how do I do that? That's going to be an important piece of this as well. This project also allows us to kind of play with our logs page. And let's look at instead of just a list of all the information from the database, how do we pull a bunch of records from the database and plot them on a map? And mostly we can pull from the previous example I made with the International Space Station to create a map with Leaflet.js. And finally, before I go, before this series wraps up, I really think it's important to talk about deploying a project into the real world, so to speak. So right now I'm tinkering and playing around and developing. The server is running here. The client is running here. This is just all contained within my laptop. But if I want to deploy this project to a server so that it can live on the web, that many people could access it, share the data, participate in the... and view the website, essentially, how do I do that? So I want to look at a few different options for deploying your project onto the web. Hopefully I'll give you some pointers to some options where you can do that for free, as well as if you have a larger project, what the considerations are for hosting services and paying for hosting. So this is where I'm going to begin. I've got just the very basic functionality from the Data Selfie app. I've stripped away P5, the webcam, images, a lot of stuff. The page just loads and shows my latitude and longitude. When I click check-in, it's saving that current latitude and longitude and the timestamp to the database. And when I go to view check-ins, I see a log of all of my recent check-ins at this latitude and longitude and time. So the very first thing that I want to do in this series now is add weather. I want to be able to display on this page information about the current temperature outside at this latitude and longitude. Now I have to figure out where am I going to get the weather information from. So I don't really feel so inclined to build my own set of sensors and my own weather station. So most likely I can find some type of API service that I can make a request to and get the data back, maybe even in JSON format. This is very similar to what we did when we looked at the International Space Station latitude and longitude from an external API. And there are many weather APIs. Google it. Google weather API, JSON data. You'll probably find a ton. One that I've used in previous video tutorials is Open Weather Map. That's one that you could look into using. The National Weather Service. Probably there are other governmental organizations or public institutions that have public weather data that you could use that have APIs that you request data from. I'm somewhat arbitrarily picking an API called Dark Sky. One of the things I look for when trying to pick an API is does it have good documentation? Are the examples easy to follow? Can I get up and running with it fairly quickly? And looking at Dark Sky, I find that to be true. The documentation is pretty easy to follow and I can get up and running with it quickly. And it offers the data in JSON format. It also, while it's not entirely a free service, it lets you do a thousand API calls per day free. And that's for demonstration purposes. That's pretty much all I need. A risk here, of course, is that by the time you're watching this video, the Dark Sky API won't exist anymore or the way that it works will have completely changed. But that's just a fact of life. So really what you should be taking away from this video is less the specifics of the Dark Sky API, but what you need to do when you find an API. How to get your API key. How to make the request. How to get the data and then present the data. And hopefully, you know, maybe follow this video along but use a completely different weather API while you're following. So unlike the International Space Station API that we looked at in a previous video, the Dark Sky API requires you to authenticate. It's pretty simple to authenticate. All you need is a single API key. Other APIs can have a much more involved process. But if you're going to follow along and use this, you're going to need to first go to darksky.net and click sign up. You're going to want to register with your email address and make up a password. Now I've already done that. So I'm just going to go straight to logging in. Once you're logged in, you'll arrive exactly to this page. And you can see this is really important. This is my API key. Now there's a little bit of irony here that I'm in this public video on YouTube showing you my API key right here. I will, by the time you're watching this, I'm going to have regenerated my API key and this one won't be valid. So don't try typing this one in. You're going to need to get your own. But while I'm making this video, this is the one that I'm going to use. The other thing that I love about this is already, right, I need to read the documentation. But even without reading the documentation, right here I can see a URL for making an API call. So if I want to get the forecast, all I need is api.darksky.net slash forecast. That's the endpoint. We've learned about endpoints now. My API key and then slash latitude comma longitude. So I can actually just click on this, open it in a new tab, and we can see, look, this is weather for, that's a latitude and longitude for Los Angeles. I'm getting a summary. I'm getting near storm distance. All sorts of information. I can use any of this in my application. So let's assume what I want to do is now request this API endpoint in my client side JavaScript. That's a thing that we've done before. We did that with International Space Station. So I'm going to grab this URL. So right here, once I geolocated, then I can say I can make an API URL, which is equal to exactly that. But instead of, I'm going to make this a string literal because instead of hard coding in the latitude and longitude, I might as well say latitude comma longitude. And then now I can say this is all stuff we've done before. I can fetch, make a get request to that API URL. So I can say the response equals await fetch API URL. Now, since I'm using the keyword await, I need to add the async keyword up here to this callback function. Then I can say JSON equals await response dot JSON. And then I can console log the data. So in theory now, the feature that I've added here, in addition to geolocating, I'm going to take that geolocation, send it to the darksky.net API, and get the weather information back. Let's try giving that a run. Going here to here, hitting refresh. Ah! I'm the only person in the entire world that's really excited to see the dreaded CORS error. CORS stands for cross-origin resource sharing. And it's the way that if it's enabled or disabled. If it's enabled, it's saying, like, hey, I want you as a separate server from a different origin to be able to share my resources. Now, the thing that's sort of crucial here, if CORS is disabled, it's not that the API is saying you can't have access to my data. It's just requiring that you do it from your own server. And this is something that's explained in the darksky API's FAQ. If you scroll down, you'll find the question, why do I get the error no access control allow origin? And it's because they explain that it's for security reasons. Because the API key is part of that request, they want you to enforce that you can't make that request from client-side code. You can only do it from server-side code. So this is a nice demonstration of how we're going to make that request from Node itself. So, in fact, what I want to do is take this code itself and put it in the server. So go to index.js, and I'm just going to paste it in the bottom. But where do I want to call this? I want to make a new endpoint in my server that receives the latitude and longitude, then makes a call out to darksky.net, and then returns that back. So that I could actually have this still in my client. I don't want to actually remove this. What I want is to change this URL maybe to just a local path, weather slash latitude longitude, weather being the endpoint that I'm going to create, and then console.log it here. So I'm going to go into the server, I'm going to make a new endpoint for a get request, I'll call that weather. This is now a function that gets closed off like this. And now, okay, I'm getting some errors here. What's the issue? Okay, well, a couple things. One is I shouldn't, the argument to the function is called response, so I really shouldn't call that response here. So I'm just going to call this fetch response, and then say fetch response dot JSON. But there's a missing piece here, actually. Number one is this needs to be an async function, because I'm using await. And then, instead of console.logging, I want to say response dot JSON, that JSON. So I'm going to make the API call from within here, and then send it back. This is what's known as a proxy server. It's basically the server is a proxy for darksky.net. I can't make the call to darksky.net directly in the client, so I just send off the latitude and longitude, receive it here, and make that request. Ah, but wait a second. How do I have these variables latitude, longitude? Oh, boy. This is opening up a can of worms about passing parameters within API. Here I am in the client-side code. I want to send to my new weather endpoint the latitude and longitude that I've gotten from the client-side code. Then, somehow in the server, I need to pass, I need to receive those and put them in here when I send the dark sky. Now, I need to show you how this is going to work. But for right now, let's just make sure this is actually working. Let's just hard code in the latitude and longitude. So I'm going to go back to this particular latitude and longitude that I know will work. I'm going to go to my server. I'm going to comment this out, and I'm going to paste in a hard coded latitude and longitude. So now when I go to that endpoint, I don't need to pass in a latitude and longitude. I am just going to get exactly the weather for Los Angeles. I'm also going to do the same thing in the client. I'm going to just temporarily comment this out and then get rid of the latitude and longitude. And I think for the paths to be correct, I should have included a slash here. Okay, so let's restart the server. Let's go to the client and hit refresh. Ah, wait, it's only valid in async function. Sketch.js. I forgot to put my async function in here. Okay. Hmm. Ah, right. Let's check the server. Ah-ha, of course. So up here it's going to give me a nice error that says fetch is not defined. Fetch is not defined. I forgot about that. Fetch, the web fetch API, is part of the client side browser API. If I want to use it from within Node, I can, but I need to install a Node package for that. The package I can use to do that is called Node-fetch. So I'm going to go over back here and say npm install Node-fetch. If I go to my package.json, I can see that that's in there now. And then most likely what I need to also do is say const fetch equals require Node-fetch. So that's going to pull the fetch function from Node-fetch. So I can add that up here at the top. Fetch equals require Node-fetch. Rerun the server. Give it one more refresh here. And there we go. I'm done with that. I now have the weather from Los Angeles right over there. The last step here, I know this has been a bit of a longer video than usual, but I just want to finish off this one last step. And this last step is sending from the client the latitude and longitude to the server so that the server can send that latitude and longitude to dark sky, get the weather, and then send the weather back to the client. The way that I'm going to do that is with route parameters. Now we learned about routes. If I have a get request or a post request, I set up a route, a path, an endpoint for that particular request. Route parameters are extra parts of that path that you can name and capture as variables essentially with data that's sent from the client. Another way to do this is with something called a URL query string, which I cover in another video. And so either way would work here, but I'm going to go with route parameters. So here on the express documentation, we can see that a route parameter is specified with a colon. So the route is users, and then I might say users slash Daniel or users slash Shiffman, and that will come in as a user ID parameter. So to add that, I'm going to go back to the server. I can remove this hard-coded lat long in and put back in the one that has the lat long latitude and longitude variables. So now I need to add the route parameters. So one thing I could do is I could do slash colon lat slash colon long, so I could have two parameters coming in. I don't know. I think I'm going to just make it one. I'll call it lat long, and then I'll send it in with a comma. And those, you can see I haven't used this request argument yet. This is finally a chance to use that request object. Inside of the request object is a property called params, and inside that params object are all of the parameters. In this case, there's just one parameter, something called lat long. So I could type in lat long, or I could also put that in brackets in quotes. So either way this will work. I'm going to just go with the dot syntax, and what I'm going to do is I'm going to put that in another variable. So I'm going to say constant lat long equals that, and then I will say actually what I'm going to do is I'm going to do dot split, and I'll split with a comma, and then the latitude is the lat long index 0, and the longitude is lat long index 1. So in theory, as long as I send in as the route parameter, the latitude and longitude separated by a comma, I can pull it out of request.params, split it by comma into an array, and put them in each one of these variables. So I probably should have done this more incrementally and console logged some stuff, but let's just hope that this works, and I'm going to add some console logs to debug just so I see in case something goes wrong. Then I'm going to go back to the client. Now I need to go back to the client code, and here I can go back to this, right, because this is exactly what I'm sending in. I'm going to the weather route with the parameters latitude comma longitude. All right, I already set that up. Okay, let me add one more console log, request.params, so we can see the raw request params, and let's hope that this works. Go back to the browser, hit refresh, and there we go. I have got the correct latitude and longitude and the weather now from New York, the actual latitude and longitude that I sent to the server. Let's check the server's logs, and you can see there we go. So this is the request parameters that came in. There was just one called lat long. Then I used split to turn it into an array, and then I took the zero index of the array and the index number one of the array. So luckily I wrote the correct code, and it actually worked. The next step here would be to present that information. I mean there's several next steps here. I need to save stuff in the database and all sorts of other things, but the small immediate next step would be to display the weather information here in the DOM itself. So I'm going to leave that for you as an exercise. I will do that at the beginning of the next video, and then I'm going to continue on and make a request to open air quality, the open AQ API to get both the weather information and the air quality information for a single latitude and longitude. Microsoft Mechanics www.microsoft.com.com",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:29.012916Z",
  "started_at": "2023-09-26T21:11:35.593298Z",
  "completed_at": "2023-09-26T21:15:27.567079Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=ZtLVbJk7KcM",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 231.973781
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/iq3dv5rbnn5o76bsmpso4f2kqe/cancel",
    "get": "https://api.replicate.com/v1/predictions/iq3dv5rbnn5o76bsmpso4f2kqe"
  }
}