{
  "id": "fc6is3rbdhuebaavts4bepv7lu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/4hJykkzjXYY.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/62635 [00:00<?, ?frames/s]\n  5%|▍         | 2908/62635 [00:07<02:40, 372.16frames/s]\n  9%|▉         | 5810/62635 [00:15<02:34, 366.63frames/s]\n 14%|█▍        | 8672/62635 [00:25<02:47, 322.58frames/s]\n 18%|█▊        | 11298/62635 [00:34<02:44, 313.00frames/s]\n 23%|██▎       | 14240/62635 [00:42<02:25, 331.74frames/s]\n 27%|██▋       | 16890/62635 [00:49<02:10, 351.39frames/s]\n 32%|███▏      | 19868/62635 [00:56<01:56, 365.62frames/s]\n 36%|███▋      | 22842/62635 [01:05<01:49, 361.99frames/s]\n 41%|████▏     | 25842/62635 [01:12<01:36, 380.91frames/s]\n 45%|████▌     | 28492/62635 [01:18<01:27, 388.69frames/s]\n 50%|████▉     | 31026/62635 [01:25<01:20, 390.85frames/s]\n 54%|█████▍    | 33834/62635 [01:29<01:04, 445.74frames/s]\n 58%|█████▊    | 36512/62635 [01:36<01:01, 427.50frames/s]\n 63%|██████▎   | 39490/62635 [01:44<00:57, 402.09frames/s]\n 68%|██████▊   | 42288/62635 [01:52<00:52, 384.35frames/s]\n 72%|███████▏  | 45246/62635 [01:58<00:41, 417.84frames/s]\n 77%|███████▋  | 47992/62635 [02:07<00:38, 381.62frames/s]\n 81%|████████▏ | 50902/62635 [02:15<00:31, 374.08frames/s]\n 85%|████████▍ | 53134/62635 [02:22<00:27, 350.93frames/s]\n 90%|████████▉ | 56080/62635 [02:25<00:14, 456.80frames/s]\n 94%|█████████▍| 58866/62635 [02:32<00:08, 424.73frames/s]\n 98%|█████████▊| 61604/62635 [02:40<00:02, 401.12frames/s]\n100%|██████████| 62635/62635 [02:53<00:00, 256.81frames/s]\n100%|██████████| 62635/62635 [02:53<00:00, 361.06frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 5,
        "id": 0,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, all right, I'm still working with Mastodon",
        "tokens": [
          50364,
          2425,
          11,
          439,
          558,
          11,
          286,
          478,
          920,
          1364,
          365,
          376,
          525,
          378,
          266,
          50614
        ]
      },
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 8.98,
        "id": 1,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 6.24,
        "temperature": 0,
        "text": " and what I'm going to do in this video now",
        "tokens": [
          50676,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          341,
          960,
          586,
          50813
        ]
      },
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 12.6,
        "id": 2,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 8.98,
        "temperature": 0,
        "text": " is I'm going to take the sample bot that I made",
        "tokens": [
          50813,
          307,
          286,
          478,
          516,
          281,
          747,
          264,
          6889,
          10592,
          300,
          286,
          1027,
          50994
        ]
      },
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 15.38,
        "id": 3,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 12.6,
        "temperature": 0,
        "text": " and instead of just on a timer every 24 hours,",
        "tokens": [
          50994,
          293,
          2602,
          295,
          445,
          322,
          257,
          19247,
          633,
          4022,
          2496,
          11,
          51133
        ]
      },
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 18.82,
        "id": 4,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 15.38,
        "temperature": 0,
        "text": " every 60 minutes, I happen to post something, I toot,",
        "tokens": [
          51133,
          633,
          4060,
          2077,
          11,
          286,
          1051,
          281,
          2183,
          746,
          11,
          286,
          281,
          310,
          11,
          51305
        ]
      },
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 22.26,
        "id": 5,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 18.82,
        "temperature": 0,
        "text": " what I'm going to do is I'm going to use the streaming API.",
        "tokens": [
          51305,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          764,
          264,
          11791,
          9362,
          13,
          51477
        ]
      },
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 25.8,
        "id": 6,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 22.26,
        "temperature": 0,
        "text": " The streaming API is a way for me to, in real time,",
        "tokens": [
          51477,
          440,
          11791,
          9362,
          307,
          257,
          636,
          337,
          385,
          281,
          11,
          294,
          957,
          565,
          11,
          51654
        ]
      },
      {
        "avg_logprob": -0.23759244069331834,
        "compression_ratio": 1.7234042553191489,
        "end": 29.080000000000002,
        "id": 7,
        "no_speech_prob": 0.003944428637623787,
        "seek": 0,
        "start": 25.8,
        "temperature": 0,
        "text": " listen for events and the particular kind of events",
        "tokens": [
          51654,
          2140,
          337,
          3931,
          293,
          264,
          1729,
          733,
          295,
          3931,
          51818
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 31.82,
        "id": 8,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 29.08,
        "temperature": 0,
        "text": " that I'm going to listen for are what's known",
        "tokens": [
          50364,
          300,
          286,
          478,
          516,
          281,
          2140,
          337,
          366,
          437,
          311,
          2570,
          50501
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 33.3,
        "id": 9,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 31.82,
        "temperature": 0,
        "text": " as user events.",
        "tokens": [
          50501,
          382,
          4195,
          3931,
          13,
          50575
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 35.54,
        "id": 10,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 33.3,
        "temperature": 0,
        "text": " So a user event, and we'll see all the different kinds,",
        "tokens": [
          50575,
          407,
          257,
          4195,
          2280,
          11,
          293,
          321,
          603,
          536,
          439,
          264,
          819,
          3685,
          11,
          50687
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 37.58,
        "id": 11,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 35.54,
        "temperature": 0,
        "text": " is any time that I might get a notification",
        "tokens": [
          50687,
          307,
          604,
          565,
          300,
          286,
          1062,
          483,
          257,
          11554,
          50789
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 39.94,
        "id": 12,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 37.58,
        "temperature": 0,
        "text": " or somebody that I follow might post something",
        "tokens": [
          50789,
          420,
          2618,
          300,
          286,
          1524,
          1062,
          2183,
          746,
          50907
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 41.739999999999995,
        "id": 13,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 39.94,
        "temperature": 0,
        "text": " or any time that I might get, anyway,",
        "tokens": [
          50907,
          420,
          604,
          565,
          300,
          286,
          1062,
          483,
          11,
          4033,
          11,
          50997
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 44,
        "id": 14,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 41.739999999999995,
        "temperature": 0,
        "text": " there's lots of things that come in, user events,",
        "tokens": [
          50997,
          456,
          311,
          3195,
          295,
          721,
          300,
          808,
          294,
          11,
          4195,
          3931,
          11,
          51110
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 45.78,
        "id": 15,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 44,
        "temperature": 0,
        "text": " and these are the good ones to use",
        "tokens": [
          51110,
          293,
          613,
          366,
          264,
          665,
          2306,
          281,
          764,
          51199
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 48.14,
        "id": 16,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 45.78,
        "temperature": 0,
        "text": " because if you're using your user event as a bot,",
        "tokens": [
          51199,
          570,
          498,
          291,
          434,
          1228,
          428,
          4195,
          2280,
          382,
          257,
          10592,
          11,
          51317
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 50.68,
        "id": 17,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 48.14,
        "temperature": 0,
        "text": " you're sort of making sure that your bot only engages",
        "tokens": [
          51317,
          291,
          434,
          1333,
          295,
          1455,
          988,
          300,
          428,
          10592,
          787,
          45576,
          51444
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 52.94,
        "id": 18,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 50.68,
        "temperature": 0,
        "text": " with people who are opting in, and this is pretty important.",
        "tokens": [
          51444,
          365,
          561,
          567,
          366,
          2427,
          278,
          294,
          11,
          293,
          341,
          307,
          1238,
          1021,
          13,
          51557
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 55.14,
        "id": 19,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 52.94,
        "temperature": 0,
        "text": " You don't want your bot just randomly spamming people",
        "tokens": [
          51557,
          509,
          500,
          380,
          528,
          428,
          10592,
          445,
          16979,
          24028,
          2810,
          561,
          51667
        ]
      },
      {
        "avg_logprob": -0.21851175694377875,
        "compression_ratio": 1.8823529411764706,
        "end": 58.099999999999994,
        "id": 20,
        "no_speech_prob": 0.000003340533339724061,
        "seek": 2908,
        "start": 55.14,
        "temperature": 0,
        "text": " and favoriting random things or replying to random people",
        "tokens": [
          51667,
          293,
          2294,
          1748,
          4974,
          721,
          420,
          1085,
          7310,
          281,
          4974,
          561,
          51815
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 60.120000000000005,
        "id": 21,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 58.120000000000005,
        "temperature": 0,
        "text": " who haven't really asked to engage with your bot.",
        "tokens": [
          50365,
          567,
          2378,
          380,
          534,
          2351,
          281,
          4683,
          365,
          428,
          10592,
          13,
          50465
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 61.84,
        "id": 22,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 60.120000000000005,
        "temperature": 0,
        "text": " So you're going to want to make sure that your bot",
        "tokens": [
          50465,
          407,
          291,
          434,
          516,
          281,
          528,
          281,
          652,
          988,
          300,
          428,
          10592,
          50551
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 64.72,
        "id": 23,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 61.84,
        "temperature": 0,
        "text": " follows the code of conduct in the terms of service",
        "tokens": [
          50551,
          10002,
          264,
          3089,
          295,
          6018,
          294,
          264,
          2115,
          295,
          2643,
          50695
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 67.52,
        "id": 24,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 64.72,
        "temperature": 0,
        "text": " of bots in space, I'll show you where you can find that,",
        "tokens": [
          50695,
          295,
          35410,
          294,
          1901,
          11,
          286,
          603,
          855,
          291,
          689,
          291,
          393,
          915,
          300,
          11,
          50835
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 69.8,
        "id": 25,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 67.52,
        "temperature": 0,
        "text": " but typically, a good way to think about it is just like,",
        "tokens": [
          50835,
          457,
          5850,
          11,
          257,
          665,
          636,
          281,
          519,
          466,
          309,
          307,
          445,
          411,
          11,
          50949
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 71.44,
        "id": 26,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 69.8,
        "temperature": 0,
        "text": " if somebody is at mentioning the bot,",
        "tokens": [
          50949,
          498,
          2618,
          307,
          412,
          18315,
          264,
          10592,
          11,
          51031
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 73.1,
        "id": 27,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 71.44,
        "temperature": 0,
        "text": " then you're welcome to reply to them.",
        "tokens": [
          51031,
          550,
          291,
          434,
          2928,
          281,
          16972,
          281,
          552,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 75.16,
        "id": 28,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 73.1,
        "temperature": 0,
        "text": " If somebody follows you, then you're also welcome",
        "tokens": [
          51114,
          759,
          2618,
          10002,
          291,
          11,
          550,
          291,
          434,
          611,
          2928,
          51217
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 78.08,
        "id": 29,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 75.16,
        "temperature": 0,
        "text": " to engage with that person as the bot programmer.",
        "tokens": [
          51217,
          281,
          4683,
          365,
          300,
          954,
          382,
          264,
          10592,
          32116,
          13,
          51363
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 80.54,
        "id": 30,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 78.08,
        "temperature": 0,
        "text": " Okay, so let's go over and look at the streaming API.",
        "tokens": [
          51363,
          1033,
          11,
          370,
          718,
          311,
          352,
          670,
          293,
          574,
          412,
          264,
          11791,
          9362,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 83.88,
        "id": 31,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 80.54,
        "temperature": 0,
        "text": " So before I start using the streaming API,",
        "tokens": [
          51486,
          407,
          949,
          286,
          722,
          1228,
          264,
          11791,
          9362,
          11,
          51653
        ]
      },
      {
        "avg_logprob": -0.20930200890649722,
        "compression_ratio": 1.8073394495412844,
        "end": 86.72,
        "id": 32,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 5810,
        "start": 83.88,
        "temperature": 0,
        "text": " let me just point out to read the information page",
        "tokens": [
          51653,
          718,
          385,
          445,
          935,
          484,
          281,
          1401,
          264,
          1589,
          3028,
          51795
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 89.5,
        "id": 33,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 86.86,
        "temperature": 0,
        "text": " with the code of conduct and also the terms of service",
        "tokens": [
          50371,
          365,
          264,
          3089,
          295,
          6018,
          293,
          611,
          264,
          2115,
          295,
          2643,
          50503
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 92.46,
        "id": 34,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 89.5,
        "temperature": 0,
        "text": " if you're choosing to host your bot on bots in dot space,",
        "tokens": [
          50503,
          498,
          291,
          434,
          10875,
          281,
          3975,
          428,
          10592,
          322,
          35410,
          294,
          5893,
          1901,
          11,
          50651
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 94.1,
        "id": 35,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 92.46,
        "temperature": 0,
        "text": " you're going to want to make sure you follow",
        "tokens": [
          50651,
          291,
          434,
          516,
          281,
          528,
          281,
          652,
          988,
          291,
          1524,
          50733
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 95.74,
        "id": 36,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 94.1,
        "temperature": 0,
        "text": " the rules of the space.",
        "tokens": [
          50733,
          264,
          4474,
          295,
          264,
          1901,
          13,
          50815
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 99.84,
        "id": 37,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 95.74,
        "temperature": 0,
        "text": " Okay, now, what I'm going to do is I am going to start",
        "tokens": [
          50815,
          1033,
          11,
          586,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          669,
          516,
          281,
          722,
          51020
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 101.14,
        "id": 38,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 99.84,
        "temperature": 0,
        "text": " using the streaming API.",
        "tokens": [
          51020,
          1228,
          264,
          11791,
          9362,
          13,
          51085
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 103.53999999999999,
        "id": 39,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 101.14,
        "temperature": 0,
        "text": " So the way that I do that, and we can find it here,",
        "tokens": [
          51085,
          407,
          264,
          636,
          300,
          286,
          360,
          300,
          11,
          293,
          321,
          393,
          915,
          309,
          510,
          11,
          51205
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 105.38,
        "id": 40,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 103.53999999999999,
        "temperature": 0,
        "text": " remember, this is the node package that I'm using,",
        "tokens": [
          51205,
          1604,
          11,
          341,
          307,
          264,
          9984,
          7372,
          300,
          286,
          478,
          1228,
          11,
          51297
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 108.9,
        "id": 41,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 105.38,
        "temperature": 0,
        "text": " mastodon-api, and this is basically what I want to do.",
        "tokens": [
          51297,
          27055,
          378,
          266,
          12,
          35891,
          11,
          293,
          341,
          307,
          1936,
          437,
          286,
          528,
          281,
          360,
          13,
          51473
        ]
      },
      {
        "avg_logprob": -0.21587510790143694,
        "compression_ratio": 1.7647058823529411,
        "end": 112.98,
        "id": 42,
        "no_speech_prob": 0.000023552596758236177,
        "seek": 8672,
        "start": 108.9,
        "temperature": 0,
        "text": " I want to create a listener, and whenever there is a message",
        "tokens": [
          51473,
          286,
          528,
          281,
          1884,
          257,
          31569,
          11,
          293,
          5699,
          456,
          307,
          257,
          3636,
          51677
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 116.12,
        "id": 43,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 113.98,
        "temperature": 0,
        "text": " I want to take a look at it and do stuff,",
        "tokens": [
          50414,
          286,
          528,
          281,
          747,
          257,
          574,
          412,
          309,
          293,
          360,
          1507,
          11,
          50521
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 117.4,
        "id": 44,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 116.12,
        "temperature": 0,
        "text": " act upon that message.",
        "tokens": [
          50521,
          605,
          3564,
          300,
          3636,
          13,
          50585
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 119.08,
        "id": 45,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 117.4,
        "temperature": 0,
        "text": " So let's actually do exactly this.",
        "tokens": [
          50585,
          407,
          718,
          311,
          767,
          360,
          2293,
          341,
          13,
          50669
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 120.82000000000001,
        "id": 46,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 119.08,
        "temperature": 0,
        "text": " I'm going to keep the error one in here as well.",
        "tokens": [
          50669,
          286,
          478,
          516,
          281,
          1066,
          264,
          6713,
          472,
          294,
          510,
          382,
          731,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 125.24000000000001,
        "id": 47,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 120.82000000000001,
        "temperature": 0,
        "text": " I'm just going to copy paste this into my code.",
        "tokens": [
          50756,
          286,
          478,
          445,
          516,
          281,
          5055,
          9163,
          341,
          666,
          452,
          3089,
          13,
          50977
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 130.92000000000002,
        "id": 48,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 127.88000000000001,
        "temperature": 0,
        "text": " I'm going to comment out this auto posting thing",
        "tokens": [
          51109,
          286,
          478,
          516,
          281,
          2871,
          484,
          341,
          8399,
          15978,
          551,
          51261
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 133.08,
        "id": 49,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 130.92000000000002,
        "temperature": 0,
        "text": " that I had before about the meaning of life.",
        "tokens": [
          51261,
          300,
          286,
          632,
          949,
          466,
          264,
          3620,
          295,
          993,
          13,
          51369
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 134.68,
        "id": 50,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 133.08,
        "temperature": 0,
        "text": " I'm just going to put this here.",
        "tokens": [
          51369,
          286,
          478,
          445,
          516,
          281,
          829,
          341,
          510,
          13,
          51449
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 138.16,
        "id": 51,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 135.6,
        "temperature": 0,
        "text": " And actually what I want to do now is I want to use",
        "tokens": [
          51495,
          400,
          767,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          286,
          528,
          281,
          764,
          51623
        ]
      },
      {
        "avg_logprob": -0.24727598571777343,
        "compression_ratio": 1.8091286307053942,
        "end": 142.4,
        "id": 52,
        "no_speech_prob": 0.000002561280780355446,
        "seek": 11298,
        "start": 138.16,
        "temperature": 0,
        "text": " my little trick, instead of just console logging the message",
        "tokens": [
          51623,
          452,
          707,
          4282,
          11,
          2602,
          295,
          445,
          11076,
          27991,
          264,
          3636,
          51835
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 143.9,
        "id": 53,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 142.42000000000002,
        "temperature": 0,
        "text": " if you remember a little trick that I did",
        "tokens": [
          50365,
          498,
          291,
          1604,
          257,
          707,
          4282,
          300,
          286,
          630,
          50439
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 148.9,
        "id": 54,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 143.9,
        "temperature": 0,
        "text": " in a previous video is I used write file.",
        "tokens": [
          50439,
          294,
          257,
          3894,
          960,
          307,
          286,
          1143,
          2464,
          3991,
          13,
          50689
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 153.34,
        "id": 55,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 150.34,
        "temperature": 0,
        "text": " So I want to write files out so I can look at what kind",
        "tokens": [
          50761,
          407,
          286,
          528,
          281,
          2464,
          7098,
          484,
          370,
          286,
          393,
          574,
          412,
          437,
          733,
          50911
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 155.42000000000002,
        "id": 56,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 153.34,
        "temperature": 0,
        "text": " of messages I'm getting.",
        "tokens": [
          50911,
          295,
          7897,
          286,
          478,
          1242,
          13,
          51015
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 157.22,
        "id": 57,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 155.42000000000002,
        "temperature": 0,
        "text": " Whoops, ah, where have I gone?",
        "tokens": [
          51015,
          45263,
          11,
          3716,
          11,
          689,
          362,
          286,
          2780,
          30,
          51105
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 161.54000000000002,
        "id": 58,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 158.26000000000002,
        "temperature": 0,
        "text": " And so let me uncomment this out, and I do want to",
        "tokens": [
          51157,
          400,
          370,
          718,
          385,
          8585,
          518,
          341,
          484,
          11,
          293,
          286,
          360,
          528,
          281,
          51321
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 165.46,
        "id": 59,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 162.82,
        "temperature": 0,
        "text": " put like a timestamp also here.",
        "tokens": [
          51385,
          829,
          411,
          257,
          49108,
          1215,
          611,
          510,
          13,
          51517
        ]
      },
      {
        "avg_logprob": -0.2744118309020996,
        "compression_ratio": 1.5305164319248827,
        "end": 168.9,
        "id": 60,
        "no_speech_prob": 0.0000030894925657776184,
        "seek": 14240,
        "start": 165.46,
        "temperature": 0,
        "text": " So it would make sense for me to say like data,",
        "tokens": [
          51517,
          407,
          309,
          576,
          652,
          2020,
          337,
          385,
          281,
          584,
          411,
          1412,
          11,
          51689
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 173.28,
        "id": 61,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 168.92000000000002,
        "temperature": 0,
        "text": " and then actually the message probably has a timestamp",
        "tokens": [
          50365,
          293,
          550,
          767,
          264,
          3636,
          1391,
          575,
          257,
          49108,
          1215,
          50583
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 178.28,
        "id": 62,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 173.28,
        "temperature": 0,
        "text": " built into it, but I can also like JavaScript timestamp.",
        "tokens": [
          50583,
          3094,
          666,
          309,
          11,
          457,
          286,
          393,
          611,
          411,
          15778,
          49108,
          1215,
          13,
          50833
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 181.64000000000001,
        "id": 63,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 178.48000000000002,
        "temperature": 0,
        "text": " I think it's just like new date, get time, yeah.",
        "tokens": [
          50843,
          286,
          519,
          309,
          311,
          445,
          411,
          777,
          4002,
          11,
          483,
          565,
          11,
          1338,
          13,
          51001
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 186.64000000000001,
        "id": 64,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 181.64000000000001,
        "temperature": 0,
        "text": " So I can say new date, get time.",
        "tokens": [
          51001,
          407,
          286,
          393,
          584,
          777,
          4002,
          11,
          483,
          565,
          13,
          51251
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 188,
        "id": 65,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 186.68,
        "temperature": 0,
        "text": " I think this is right.",
        "tokens": [
          51253,
          286,
          519,
          341,
          307,
          558,
          13,
          51319
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 191.12,
        "id": 66,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 188,
        "temperature": 0,
        "text": " So again, you can put with template literals,",
        "tokens": [
          51319,
          407,
          797,
          11,
          291,
          393,
          829,
          365,
          12379,
          2733,
          1124,
          11,
          51475
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 194,
        "id": 67,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 191.12,
        "temperature": 0,
        "text": " I can put a whole string to evaluate, a whole line of code",
        "tokens": [
          51475,
          286,
          393,
          829,
          257,
          1379,
          6798,
          281,
          13059,
          11,
          257,
          1379,
          1622,
          295,
          3089,
          51619
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 196.56,
        "id": 68,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 194,
        "temperature": 0,
        "text": " to evaluate in essence inside that area.",
        "tokens": [
          51619,
          281,
          13059,
          294,
          12801,
          1854,
          300,
          1859,
          13,
          51747
        ]
      },
      {
        "avg_logprob": -0.24571107995921168,
        "compression_ratio": 1.6995708154506437,
        "end": 198.68,
        "id": 69,
        "no_speech_prob": 0.000014064043170947116,
        "seek": 16890,
        "start": 196.56,
        "temperature": 0,
        "text": " Okay, so let's see if this works.",
        "tokens": [
          51747,
          1033,
          11,
          370,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          51853
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 200.56,
        "id": 70,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 199.46,
        "temperature": 0,
        "text": " What's going to happen?",
        "tokens": [
          50403,
          708,
          311,
          516,
          281,
          1051,
          30,
          50458
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 203.54000000000002,
        "id": 71,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 202.06,
        "temperature": 0,
        "text": " Let me see, am I in the right place?",
        "tokens": [
          50533,
          961,
          385,
          536,
          11,
          669,
          286,
          294,
          264,
          558,
          1081,
          30,
          50607
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 205.70000000000002,
        "id": 72,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 203.54000000000002,
        "temperature": 0,
        "text": " No, sorry, I made a new folder.",
        "tokens": [
          50607,
          883,
          11,
          2597,
          11,
          286,
          1027,
          257,
          777,
          10820,
          13,
          50715
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 208.20000000000002,
        "id": 73,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 205.70000000000002,
        "temperature": 0,
        "text": " So I'm going to release these examples separately.",
        "tokens": [
          50715,
          407,
          286,
          478,
          516,
          281,
          4374,
          613,
          5110,
          14759,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 210.4,
        "id": 74,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 209.1,
        "temperature": 0,
        "text": " I'm going to run this bot.",
        "tokens": [
          50885,
          286,
          478,
          516,
          281,
          1190,
          341,
          10592,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 213.94,
        "id": 75,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 211.22,
        "temperature": 0,
        "text": " And now, okay, so I don't know if it's working",
        "tokens": [
          50991,
          400,
          586,
          11,
          1392,
          11,
          370,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          1364,
          51127
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 215.62,
        "id": 76,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 213.94,
        "temperature": 0,
        "text": " because I don't know if I've gotten any notification.",
        "tokens": [
          51127,
          570,
          286,
          500,
          380,
          458,
          498,
          286,
          600,
          5768,
          604,
          11554,
          13,
          51211
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 218.02,
        "id": 77,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 215.62,
        "temperature": 0,
        "text": " Maybe somebody watching this live is going to favorite",
        "tokens": [
          51211,
          2704,
          2618,
          1976,
          341,
          1621,
          307,
          516,
          281,
          2954,
          51331
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 220.5,
        "id": 78,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 218.02,
        "temperature": 0,
        "text": " something or at mention my bot.",
        "tokens": [
          51331,
          746,
          420,
          412,
          2152,
          452,
          10592,
          13,
          51455
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 221.70000000000002,
        "id": 79,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 220.5,
        "temperature": 0,
        "text": " That would be nice, right?",
        "tokens": [
          51455,
          663,
          576,
          312,
          1481,
          11,
          558,
          30,
          51515
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 223.78,
        "id": 80,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 221.70000000000002,
        "temperature": 0,
        "text": " And then something would come in through here.",
        "tokens": [
          51515,
          400,
          550,
          746,
          576,
          808,
          294,
          807,
          510,
          13,
          51619
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 225.66,
        "id": 81,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 223.78,
        "temperature": 0,
        "text": " Oh, I did get a message from somebody,",
        "tokens": [
          51619,
          876,
          11,
          286,
          630,
          483,
          257,
          3636,
          490,
          2618,
          11,
          51713
        ]
      },
      {
        "avg_logprob": -0.25437166866840133,
        "compression_ratio": 1.691275167785235,
        "end": 228.42000000000002,
        "id": 82,
        "no_speech_prob": 0.000027108750145998783,
        "seek": 19868,
        "start": 225.66,
        "temperature": 0,
        "text": " but I made some sort of mistake.",
        "tokens": [
          51713,
          457,
          286,
          1027,
          512,
          1333,
          295,
          6146,
          13,
          51851
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 230.48,
        "id": 83,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 229.16,
        "temperature": 0,
        "text": " Data is not defined.",
        "tokens": [
          50401,
          11888,
          307,
          406,
          7642,
          13,
          50467
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 235.23999999999998,
        "id": 84,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 230.48,
        "temperature": 0,
        "text": " Ah, okay, because, oh yes, it's called,",
        "tokens": [
          50467,
          2438,
          11,
          1392,
          11,
          570,
          11,
          1954,
          2086,
          11,
          309,
          311,
          1219,
          11,
          50705
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 237.88,
        "id": 85,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 235.23999999999998,
        "temperature": 0,
        "text": " the variable name is MSG for message,",
        "tokens": [
          50705,
          264,
          7006,
          1315,
          307,
          7395,
          38,
          337,
          3636,
          11,
          50837
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 240.23999999999998,
        "id": 86,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 237.88,
        "temperature": 0,
        "text": " which is why I was thinking that, I guess.",
        "tokens": [
          50837,
          597,
          307,
          983,
          286,
          390,
          1953,
          300,
          11,
          286,
          2041,
          13,
          50955
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 241.83999999999997,
        "id": 87,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 240.23999999999998,
        "temperature": 0,
        "text": " So it should be MSG here.",
        "tokens": [
          50955,
          407,
          309,
          820,
          312,
          7395,
          38,
          510,
          13,
          51035
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 243.23999999999998,
        "id": 88,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 241.83999999999997,
        "temperature": 0,
        "text": " Okay, let's try this again.",
        "tokens": [
          51035,
          1033,
          11,
          718,
          311,
          853,
          341,
          797,
          13,
          51105
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 247.35999999999999,
        "id": 89,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 244.35999999999999,
        "temperature": 0,
        "text": " And actually, I'm just going to take this out",
        "tokens": [
          51161,
          400,
          767,
          11,
          286,
          478,
          445,
          516,
          281,
          747,
          341,
          484,
          51311
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 252.35999999999999,
        "id": 90,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 247.35999999999999,
        "temperature": 0,
        "text": " and I'm just going to write console.log user event.",
        "tokens": [
          51311,
          293,
          286,
          478,
          445,
          516,
          281,
          2464,
          11076,
          13,
          4987,
          4195,
          2280,
          13,
          51561
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 255,
        "id": 91,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 253.51999999999998,
        "temperature": 0,
        "text": " All right, everybody, are you watching?",
        "tokens": [
          51619,
          1057,
          558,
          11,
          2201,
          11,
          366,
          291,
          1976,
          30,
          51693
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 256.8,
        "id": 92,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 255,
        "temperature": 0,
        "text": " Are you giving me some user events?",
        "tokens": [
          51693,
          2014,
          291,
          2902,
          385,
          512,
          4195,
          3931,
          30,
          51783
        ]
      },
      {
        "avg_logprob": -0.2515752823626409,
        "compression_ratio": 1.5301204819277108,
        "end": 257.7,
        "id": 93,
        "no_speech_prob": 0.000006240924449230079,
        "seek": 22842,
        "start": 256.8,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51783,
          1692,
          321,
          352,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 263.04,
        "id": 94,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 259.04,
        "temperature": 0,
        "text": " Waiting for my user events.",
        "tokens": [
          50395,
          37291,
          337,
          452,
          4195,
          3931,
          13,
          50595
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 268.04,
        "id": 95,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 263.04,
        "temperature": 0,
        "text": " Okay, I think that was enough user events.",
        "tokens": [
          50595,
          1033,
          11,
          286,
          519,
          300,
          390,
          1547,
          4195,
          3931,
          13,
          50845
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 270.6,
        "id": 96,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 269.36,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          50911,
          1044,
          291,
          588,
          709,
          13,
          50973
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 273.24,
        "id": 97,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 270.6,
        "temperature": 0,
        "text": " Let's go back and we can see here",
        "tokens": [
          50973,
          961,
          311,
          352,
          646,
          293,
          321,
          393,
          536,
          510,
          51105
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 275.76,
        "id": 98,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 273.24,
        "temperature": 0,
        "text": " that I have all of these data.json files",
        "tokens": [
          51105,
          300,
          286,
          362,
          439,
          295,
          613,
          1412,
          13,
          73,
          3015,
          7098,
          51231
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 276.92,
        "id": 99,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 275.76,
        "temperature": 0,
        "text": " for all of these events.",
        "tokens": [
          51231,
          337,
          439,
          295,
          613,
          3931,
          13,
          51289
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 277.88,
        "id": 100,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 276.92,
        "temperature": 0,
        "text": " So I can kind of click through them",
        "tokens": [
          51289,
          407,
          286,
          393,
          733,
          295,
          2052,
          807,
          552,
          51337
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 279,
        "id": 101,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 277.88,
        "temperature": 0,
        "text": " and see what kind of events.",
        "tokens": [
          51337,
          293,
          536,
          437,
          733,
          295,
          3931,
          13,
          51393
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 281.64,
        "id": 102,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 279,
        "temperature": 0,
        "text": " I'm hoping that the kind people of the internet",
        "tokens": [
          51393,
          286,
          478,
          7159,
          300,
          264,
          733,
          561,
          295,
          264,
          4705,
          51525
        ]
      },
      {
        "avg_logprob": -0.2716440367467195,
        "compression_ratio": 1.624413145539906,
        "end": 284.92,
        "id": 103,
        "no_speech_prob": 0.000018342841940466315,
        "seek": 25842,
        "start": 281.64,
        "temperature": 0,
        "text": " are not spamming me with horrible things.",
        "tokens": [
          51525,
          366,
          406,
          24028,
          2810,
          385,
          365,
          9263,
          721,
          13,
          51689
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 288.7,
        "id": 104,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 284.94,
        "temperature": 0,
        "text": " So the first kind of event we got here is a follow event.",
        "tokens": [
          50365,
          407,
          264,
          700,
          733,
          295,
          2280,
          321,
          658,
          510,
          307,
          257,
          1524,
          2280,
          13,
          50553
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 291.78000000000003,
        "id": 105,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 288.7,
        "temperature": 0,
        "text": " So if the event is a notification of type follow,",
        "tokens": [
          50553,
          407,
          498,
          264,
          2280,
          307,
          257,
          11554,
          295,
          2010,
          1524,
          11,
          50707
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 292.82,
        "id": 106,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 291.78000000000003,
        "temperature": 0,
        "text": " we could act on that.",
        "tokens": [
          50707,
          321,
          727,
          605,
          322,
          300,
          13,
          50759
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 294.42,
        "id": 107,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 292.82,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          50759,
          407,
          718,
          311,
          360,
          300,
          13,
          50839
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 297.46000000000004,
        "id": 108,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 294.42,
        "temperature": 0,
        "text": " Let's say, let's go back to our code.",
        "tokens": [
          50839,
          961,
          311,
          584,
          11,
          718,
          311,
          352,
          646,
          281,
          527,
          3089,
          13,
          50991
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 300.70000000000005,
        "id": 109,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 297.46000000000004,
        "temperature": 0,
        "text": " And I'm going to say, right here,",
        "tokens": [
          50991,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          558,
          510,
          11,
          51153
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 302.76,
        "id": 110,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 300.70000000000005,
        "temperature": 0,
        "text": " I'm going to not write these out anymore.",
        "tokens": [
          51153,
          286,
          478,
          516,
          281,
          406,
          2464,
          613,
          484,
          3602,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.2490763372304488,
        "compression_ratio": 1.6054054054054054,
        "end": 310.26,
        "id": 111,
        "no_speech_prob": 0.0000024824785214150324,
        "seek": 28492,
        "start": 305.26,
        "temperature": 0,
        "text": " If, if message., what was it again?",
        "tokens": [
          51381,
          759,
          11,
          498,
          3636,
          13,
          11,
          437,
          390,
          309,
          797,
          30,
          51631
        ]
      },
      {
        "avg_logprob": -0.2878402225554936,
        "compression_ratio": 1.4513888888888888,
        "end": 316.24,
        "id": 112,
        "no_speech_prob": 0.00020988208416383713,
        "seek": 31026,
        "start": 311.24,
        "temperature": 0,
        "text": " Message.event equals notification.",
        "tokens": [
          50413,
          45947,
          13,
          68,
          2475,
          6915,
          11554,
          13,
          50663
        ]
      },
      {
        "avg_logprob": -0.2878402225554936,
        "compression_ratio": 1.4513888888888888,
        "end": 321.59999999999997,
        "id": 113,
        "no_speech_prob": 0.00020988208416383713,
        "seek": 31026,
        "start": 320.32,
        "temperature": 0,
        "text": " And I think there's going to be",
        "tokens": [
          50867,
          400,
          286,
          519,
          456,
          311,
          516,
          281,
          312,
          50931
        ]
      },
      {
        "avg_logprob": -0.2878402225554936,
        "compression_ratio": 1.4513888888888888,
        "end": 322.96,
        "id": 114,
        "no_speech_prob": 0.00020988208416383713,
        "seek": 31026,
        "start": 321.59999999999997,
        "temperature": 0,
        "text": " different kinds of notifications.",
        "tokens": [
          50931,
          819,
          3685,
          295,
          13426,
          13,
          50999
        ]
      },
      {
        "avg_logprob": -0.2878402225554936,
        "compression_ratio": 1.4513888888888888,
        "end": 327.96,
        "id": 115,
        "no_speech_prob": 0.00020988208416383713,
        "seek": 31026,
        "start": 322.96,
        "temperature": 0,
        "text": " So I'm going to say then if message.data.type follow,",
        "tokens": [
          50999,
          407,
          286,
          478,
          516,
          281,
          584,
          550,
          498,
          3636,
          13,
          67,
          3274,
          13,
          20467,
          1524,
          11,
          51249
        ]
      },
      {
        "avg_logprob": -0.2878402225554936,
        "compression_ratio": 1.4513888888888888,
        "end": 338.34,
        "id": 116,
        "no_speech_prob": 0.00020988208416383713,
        "seek": 31026,
        "start": 334.56,
        "temperature": 0,
        "text": " then what I want to do is I want to get the user name.",
        "tokens": [
          51579,
          550,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          483,
          264,
          4195,
          1315,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 342.4,
        "id": 117,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 338.34,
        "temperature": 0,
        "text": " So let me get the user name.",
        "tokens": [
          50364,
          407,
          718,
          385,
          483,
          264,
          4195,
          1315,
          13,
          50567
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 345.02,
        "id": 118,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 342.4,
        "temperature": 0,
        "text": " And that would be where?",
        "tokens": [
          50567,
          400,
          300,
          576,
          312,
          689,
          30,
          50698
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 346.64,
        "id": 119,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 345.02,
        "temperature": 0,
        "text": " It would be, ah, right there.",
        "tokens": [
          50698,
          467,
          576,
          312,
          11,
          3716,
          11,
          558,
          456,
          13,
          50779
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 348.11999999999995,
        "id": 120,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 346.64,
        "temperature": 0,
        "text": " And actually, I want the account.",
        "tokens": [
          50779,
          400,
          767,
          11,
          286,
          528,
          264,
          2696,
          13,
          50853
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 350.35999999999996,
        "id": 121,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 348.11999999999995,
        "temperature": 0,
        "text": " The user name is useful, but you always on mastodon",
        "tokens": [
          50853,
          440,
          4195,
          1315,
          307,
          4420,
          11,
          457,
          291,
          1009,
          322,
          27055,
          378,
          266,
          50965
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 353.35999999999996,
        "id": 122,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 350.35999999999996,
        "temperature": 0,
        "text": " need both the user name and the instance,",
        "tokens": [
          50965,
          643,
          1293,
          264,
          4195,
          1315,
          293,
          264,
          5197,
          11,
          51115
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 355.35999999999996,
        "id": 123,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 353.35999999999996,
        "temperature": 0,
        "text": " the address of the instance, the host name.",
        "tokens": [
          51115,
          264,
          2985,
          295,
          264,
          5197,
          11,
          264,
          3975,
          1315,
          13,
          51215
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 360.35999999999996,
        "id": 124,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 355.35999999999996,
        "temperature": 0,
        "text": " So let me grab account equals message.data.account.",
        "tokens": [
          51215,
          407,
          718,
          385,
          4444,
          2696,
          6915,
          3636,
          13,
          67,
          3274,
          13,
          8476,
          792,
          13,
          51465
        ]
      },
      {
        "avg_logprob": -0.24057987248786142,
        "compression_ratio": 1.7389162561576355,
        "end": 365.12,
        "id": 125,
        "no_speech_prob": 0.0000037266354411258362,
        "seek": 33834,
        "start": 363.55999999999995,
        "temperature": 0,
        "text": " And then the other thing that I'm pretty sure",
        "tokens": [
          51625,
          400,
          550,
          264,
          661,
          551,
          300,
          286,
          478,
          1238,
          988,
          51703
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 367.54,
        "id": 126,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 365.14,
        "temperature": 0,
        "text": " that I need is the ID, maybe.",
        "tokens": [
          50365,
          300,
          286,
          643,
          307,
          264,
          7348,
          11,
          1310,
          13,
          50485
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 370.3,
        "id": 127,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 367.54,
        "temperature": 0,
        "text": " 7670, that's the account ID.",
        "tokens": [
          50485,
          24733,
          5867,
          11,
          300,
          311,
          264,
          2696,
          7348,
          13,
          50623
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 371.42,
        "id": 128,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 370.3,
        "temperature": 0,
        "text": " This is the, I don't know what,",
        "tokens": [
          50623,
          639,
          307,
          264,
          11,
          286,
          500,
          380,
          458,
          437,
          11,
          50679
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 373.66,
        "id": 129,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 371.42,
        "temperature": 0,
        "text": " this is the ID of the event, I guess.",
        "tokens": [
          50679,
          341,
          307,
          264,
          7348,
          295,
          264,
          2280,
          11,
          286,
          2041,
          13,
          50791
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 375.22,
        "id": 130,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 373.66,
        "temperature": 0,
        "text": " So I want that account ID.",
        "tokens": [
          50791,
          407,
          286,
          528,
          300,
          2696,
          7348,
          13,
          50869
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 379.54,
        "id": 131,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 375.22,
        "temperature": 0,
        "text": " So I'm going to say constant ID equals message.data.id.",
        "tokens": [
          50869,
          407,
          286,
          478,
          516,
          281,
          584,
          5754,
          7348,
          6915,
          3636,
          13,
          67,
          3274,
          13,
          327,
          13,
          51085
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 382.98,
        "id": 132,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 381.02,
        "temperature": 0,
        "text": " Oh,.account, I forgot about account.",
        "tokens": [
          51159,
          876,
          11,
          2411,
          8476,
          792,
          11,
          286,
          5298,
          466,
          2696,
          13,
          51257
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 386.42,
        "id": 133,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 382.98,
        "temperature": 0,
        "text": " I'm also message.data.account.id.",
        "tokens": [
          51257,
          286,
          478,
          611,
          3636,
          13,
          67,
          3274,
          13,
          8476,
          792,
          13,
          327,
          13,
          51429
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 391.42,
        "id": 134,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 386.42,
        "temperature": 0,
        "text": ".account.account, and then.account.id.",
        "tokens": [
          51429,
          2411,
          8476,
          792,
          13,
          8476,
          792,
          11,
          293,
          550,
          2411,
          8476,
          792,
          13,
          327,
          13,
          51679
        ]
      },
      {
        "avg_logprob": -0.25232072310014203,
        "compression_ratio": 1.8112244897959184,
        "end": 394.9,
        "id": 135,
        "no_speech_prob": 0.0008167365449480712,
        "seek": 36512,
        "start": 392.14,
        "temperature": 0,
        "text": " And then I want to send a message.",
        "tokens": [
          51715,
          400,
          550,
          286,
          528,
          281,
          2845,
          257,
          3636,
          13,
          51853
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 396.41999999999996,
        "id": 136,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 395.58,
        "temperature": 0,
        "text": " So how do I do that?",
        "tokens": [
          50398,
          407,
          577,
          360,
          286,
          360,
          300,
          30,
          50440
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 399.08,
        "id": 137,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 396.41999999999996,
        "temperature": 0,
        "text": " Just with this nice m.post.",
        "tokens": [
          50440,
          1449,
          365,
          341,
          1481,
          275,
          13,
          23744,
          13,
          50573
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 399.91999999999996,
        "id": 138,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 399.08,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50573,
          407,
          510,
          311,
          264,
          551,
          13,
          50615
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 403.28,
        "id": 139,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 399.91999999999996,
        "temperature": 0,
        "text": " Maybe I want to make this quote unquote",
        "tokens": [
          50615,
          2704,
          286,
          528,
          281,
          652,
          341,
          6513,
          37557,
          50783
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 405.59999999999997,
        "id": 140,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 403.28,
        "temperature": 0,
        "text": " to to function a bit more generic.",
        "tokens": [
          50783,
          281,
          281,
          2445,
          257,
          857,
          544,
          19577,
          13,
          50899
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 407.32,
        "id": 141,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 405.59999999999997,
        "temperature": 0,
        "text": " And I'm just going to give it a,",
        "tokens": [
          50899,
          400,
          286,
          478,
          445,
          516,
          281,
          976,
          309,
          257,
          11,
          50985
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 410.23999999999995,
        "id": 142,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 408.12,
        "temperature": 0,
        "text": " I'm going to pass in a status.",
        "tokens": [
          51025,
          286,
          478,
          516,
          281,
          1320,
          294,
          257,
          6558,
          13,
          51131
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 412.76,
        "id": 143,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 411.15999999999997,
        "temperature": 0,
        "text": " So I'm going to get rid of the random number stuff,",
        "tokens": [
          51177,
          407,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          4974,
          1230,
          1507,
          11,
          51257
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 414.28,
        "id": 144,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 412.76,
        "temperature": 0,
        "text": " which was from before.",
        "tokens": [
          51257,
          597,
          390,
          490,
          949,
          13,
          51333
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 417.79999999999995,
        "id": 145,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 414.28,
        "temperature": 0,
        "text": " And then I'm going to just put,",
        "tokens": [
          51333,
          400,
          550,
          286,
          478,
          516,
          281,
          445,
          829,
          11,
          51509
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 420.84,
        "id": 146,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 420,
        "temperature": 0,
        "text": " this is a little confusing,",
        "tokens": [
          51619,
          341,
          307,
          257,
          707,
          13181,
          11,
          51661
        ]
      },
      {
        "avg_logprob": -0.2544644976419116,
        "compression_ratio": 1.6666666666666667,
        "end": 422.88,
        "id": 147,
        "no_speech_prob": 0.000004222821644361829,
        "seek": 39490,
        "start": 420.84,
        "temperature": 0,
        "text": " but I'm going to take whatever I pass in,",
        "tokens": [
          51661,
          457,
          286,
          478,
          516,
          281,
          747,
          2035,
          286,
          1320,
          294,
          11,
          51763
        ]
      },
      {
        "avg_logprob": -0.29695951527562636,
        "compression_ratio": 1.5644171779141105,
        "end": 426.98,
        "id": 148,
        "no_speech_prob": 0.000002368795094298548,
        "seek": 42288,
        "start": 422.88,
        "temperature": 0,
        "text": " and then here is, and then I'm going to post that.",
        "tokens": [
          50364,
          293,
          550,
          510,
          307,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          2183,
          300,
          13,
          50569
        ]
      },
      {
        "avg_logprob": -0.29695951527562636,
        "compression_ratio": 1.5644171779141105,
        "end": 430.1,
        "id": 149,
        "no_speech_prob": 0.000002368795094298548,
        "seek": 42288,
        "start": 426.98,
        "temperature": 0,
        "text": " So now I have a function that I can basically say,",
        "tokens": [
          50569,
          407,
          586,
          286,
          362,
          257,
          2445,
          300,
          286,
          393,
          1936,
          584,
          11,
          50725
        ]
      },
      {
        "avg_logprob": -0.29695951527562636,
        "compression_ratio": 1.5644171779141105,
        "end": 435.9,
        "id": 150,
        "no_speech_prob": 0.000002368795094298548,
        "seek": 42288,
        "start": 431,
        "temperature": 0,
        "text": " toot, and I can say,",
        "tokens": [
          50770,
          281,
          310,
          11,
          293,
          286,
          393,
          584,
          11,
          51015
        ]
      },
      {
        "avg_logprob": -0.29695951527562636,
        "compression_ratio": 1.5644171779141105,
        "end": 438.62,
        "id": 151,
        "no_speech_prob": 0.000002368795094298548,
        "seek": 42288,
        "start": 437.46,
        "temperature": 0,
        "text": " I'm going to use at,",
        "tokens": [
          51093,
          286,
          478,
          516,
          281,
          764,
          412,
          11,
          51151
        ]
      },
      {
        "avg_logprob": -0.29695951527562636,
        "compression_ratio": 1.5644171779141105,
        "end": 444.38,
        "id": 152,
        "no_speech_prob": 0.000002368795094298548,
        "seek": 42288,
        "start": 440.86,
        "temperature": 0,
        "text": " data.message.data.account, right?",
        "tokens": [
          51263,
          1412,
          13,
          76,
          442,
          609,
          13,
          67,
          3274,
          13,
          8476,
          792,
          11,
          558,
          30,
          51439
        ]
      },
      {
        "avg_logprob": -0.29695951527562636,
        "compression_ratio": 1.5644171779141105,
        "end": 447.65999999999997,
        "id": 153,
        "no_speech_prob": 0.000002368795094298548,
        "seek": 42288,
        "start": 444.38,
        "temperature": 0,
        "text": " This is me referencing the person that followed me.",
        "tokens": [
          51439,
          639,
          307,
          385,
          40582,
          264,
          954,
          300,
          6263,
          385,
          13,
          51603
        ]
      },
      {
        "avg_logprob": -0.29695951527562636,
        "compression_ratio": 1.5644171779141105,
        "end": 452.46,
        "id": 154,
        "no_speech_prob": 0.000002368795094298548,
        "seek": 42288,
        "start": 450.21999999999997,
        "temperature": 0,
        "text": " Thank you for the follow.",
        "tokens": [
          51731,
          1044,
          291,
          337,
          264,
          1524,
          13,
          51843
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 455.44,
        "id": 155,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 453.08,
        "temperature": 0,
        "text": " I'll just say, choo choo, welcome aboard.",
        "tokens": [
          50395,
          286,
          603,
          445,
          584,
          11,
          1586,
          78,
          1586,
          78,
          11,
          2928,
          27488,
          13,
          50513
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 457.64,
        "id": 156,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 455.44,
        "temperature": 0,
        "text": " Huh, that's a train theme, welcome aboard.",
        "tokens": [
          50513,
          8063,
          11,
          300,
          311,
          257,
          3847,
          6314,
          11,
          2928,
          27488,
          13,
          50623
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 460.56,
        "id": 157,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 458.79999999999995,
        "temperature": 0,
        "text": " Okay, so we can see it'll say, welcome aboard.",
        "tokens": [
          50681,
          1033,
          11,
          370,
          321,
          393,
          536,
          309,
          603,
          584,
          11,
          2928,
          27488,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 461.7,
        "id": 158,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 460.56,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          50769,
          823,
          510,
          311,
          264,
          551,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 468.35999999999996,
        "id": 159,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 464.08,
        "temperature": 0,
        "text": " I really should also, if I go back to the API,",
        "tokens": [
          50945,
          286,
          534,
          820,
          611,
          11,
          498,
          286,
          352,
          646,
          281,
          264,
          9362,
          11,
          51159
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 471.76,
        "id": 160,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 468.35999999999996,
        "temperature": 0,
        "text": " this one, I should probably say in,",
        "tokens": [
          51159,
          341,
          472,
          11,
          286,
          820,
          1391,
          584,
          294,
          11,
          51329
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 472.59999999999997,
        "id": 161,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 471.76,
        "temperature": 0,
        "text": " and that's a reply to this,",
        "tokens": [
          51329,
          293,
          300,
          311,
          257,
          16972,
          281,
          341,
          11,
          51371
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 474.17999999999995,
        "id": 162,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 472.59999999999997,
        "temperature": 0,
        "text": " because I don't need,",
        "tokens": [
          51371,
          570,
          286,
          500,
          380,
          643,
          11,
          51450
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 476.15999999999997,
        "id": 163,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 474.17999999999995,
        "temperature": 0,
        "text": " it's not in reply to a specific status,",
        "tokens": [
          51450,
          309,
          311,
          406,
          294,
          16972,
          281,
          257,
          2685,
          6558,
          11,
          51549
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 477.28,
        "id": 164,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 476.15999999999997,
        "temperature": 0,
        "text": " so this is actually fine.",
        "tokens": [
          51549,
          370,
          341,
          307,
          767,
          2489,
          13,
          51605
        ]
      },
      {
        "avg_logprob": -0.30932850624198344,
        "compression_ratio": 1.6945606694560669,
        "end": 479.91999999999996,
        "id": 165,
        "no_speech_prob": 0.00003169322371832095,
        "seek": 45246,
        "start": 477.28,
        "temperature": 0,
        "text": " I think as long as I just at mention that, I'm done.",
        "tokens": [
          51605,
          286,
          519,
          382,
          938,
          382,
          286,
          445,
          412,
          2152,
          300,
          11,
          286,
          478,
          1096,
          13,
          51737
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 483.06,
        "id": 166,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 479.94,
        "temperature": 0,
        "text": " So let me go, I've lost my code.",
        "tokens": [
          50365,
          407,
          718,
          385,
          352,
          11,
          286,
          600,
          2731,
          452,
          3089,
          13,
          50521
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 484.34000000000003,
        "id": 167,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 483.06,
        "temperature": 0,
        "text": " Let me go back, I think I'm good.",
        "tokens": [
          50521,
          961,
          385,
          352,
          646,
          11,
          286,
          519,
          286,
          478,
          665,
          13,
          50585
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 488.82,
        "id": 168,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 484.34000000000003,
        "temperature": 0,
        "text": " So now, I think that I have everything I want.",
        "tokens": [
          50585,
          407,
          586,
          11,
          286,
          519,
          300,
          286,
          362,
          1203,
          286,
          528,
          13,
          50809
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 493.18,
        "id": 169,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 488.82,
        "temperature": 0,
        "text": " So I am, let me just put the listened on error up here.",
        "tokens": [
          50809,
          407,
          286,
          669,
          11,
          718,
          385,
          445,
          829,
          264,
          13207,
          322,
          6713,
          493,
          510,
          13,
          51027
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 494.86,
        "id": 170,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 493.18,
        "temperature": 0,
        "text": " So I'm listening for a message.",
        "tokens": [
          51027,
          407,
          286,
          478,
          4764,
          337,
          257,
          3636,
          13,
          51111
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 497.86,
        "id": 171,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 494.86,
        "temperature": 0,
        "text": " If the message is a notification of a follow,",
        "tokens": [
          51111,
          759,
          264,
          3636,
          307,
          257,
          11554,
          295,
          257,
          1524,
          11,
          51261
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 500.46000000000004,
        "id": 172,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 497.86,
        "temperature": 0,
        "text": " then I will toot back to the person,",
        "tokens": [
          51261,
          550,
          286,
          486,
          281,
          310,
          646,
          281,
          264,
          954,
          11,
          51391
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 503.70000000000005,
        "id": 173,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 500.46000000000004,
        "temperature": 0,
        "text": " their account name, and say, welcome aboard.",
        "tokens": [
          51391,
          641,
          2696,
          1315,
          11,
          293,
          584,
          11,
          2928,
          27488,
          13,
          51553
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 504.90000000000003,
        "id": 174,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 503.70000000000005,
        "temperature": 0,
        "text": " Let's see how this goes.",
        "tokens": [
          51553,
          961,
          311,
          536,
          577,
          341,
          1709,
          13,
          51613
        ]
      },
      {
        "avg_logprob": -0.22135433959960937,
        "compression_ratio": 1.651063829787234,
        "end": 509.02000000000004,
        "id": 175,
        "no_speech_prob": 0.000019223158233216964,
        "seek": 47992,
        "start": 506.14,
        "temperature": 0,
        "text": " I look forward to all of you now.",
        "tokens": [
          51675,
          286,
          574,
          2128,
          281,
          439,
          295,
          291,
          586,
          13,
          51819
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 511.28,
        "id": 176,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 509.03999999999996,
        "temperature": 0,
        "text": " You can unfollow and follow if you already followed,",
        "tokens": [
          50365,
          509,
          393,
          3971,
          49082,
          293,
          1524,
          498,
          291,
          1217,
          6263,
          11,
          50477
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 512.84,
        "id": 177,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 511.28,
        "temperature": 0,
        "text": " but let me run it first.",
        "tokens": [
          50477,
          457,
          718,
          385,
          1190,
          309,
          700,
          13,
          50555
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 514.5,
        "id": 178,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 512.84,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          50555,
          400,
          510,
          321,
          352,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 516.96,
        "id": 179,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 514.5,
        "temperature": 0,
        "text": " Oh, okay, I have a status status.",
        "tokens": [
          50638,
          876,
          11,
          1392,
          11,
          286,
          362,
          257,
          6558,
          6558,
          13,
          50761
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 518.52,
        "id": 180,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 516.96,
        "temperature": 0,
        "text": " I have a mistake here.",
        "tokens": [
          50761,
          286,
          362,
          257,
          6146,
          510,
          13,
          50839
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 523.18,
        "id": 181,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 519.92,
        "temperature": 0,
        "text": " I'm just going to change this variable name to like txt,",
        "tokens": [
          50909,
          286,
          478,
          445,
          516,
          281,
          1319,
          341,
          7006,
          1315,
          281,
          411,
          256,
          734,
          11,
          51072
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 525.24,
        "id": 182,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 523.18,
        "temperature": 0,
        "text": " or content, let me make it content,",
        "tokens": [
          51072,
          420,
          2701,
          11,
          718,
          385,
          652,
          309,
          2701,
          11,
          51175
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 527.56,
        "id": 183,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 525.24,
        "temperature": 0,
        "text": " because I don't like having the same name everywhere.",
        "tokens": [
          51175,
          570,
          286,
          500,
          380,
          411,
          1419,
          264,
          912,
          1315,
          5315,
          13,
          51291
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 529.68,
        "id": 184,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 527.56,
        "temperature": 0,
        "text": " It's confusing, but there should be no semicolon",
        "tokens": [
          51291,
          467,
          311,
          13181,
          11,
          457,
          456,
          820,
          312,
          572,
          27515,
          38780,
          51397
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 530.52,
        "id": 185,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 529.68,
        "temperature": 0,
        "text": " after there.",
        "tokens": [
          51397,
          934,
          456,
          13,
          51439
        ]
      },
      {
        "avg_logprob": -0.27020633730114013,
        "compression_ratio": 1.6905829596412556,
        "end": 531.34,
        "id": 186,
        "no_speech_prob": 0.000009818316357268486,
        "seek": 50902,
        "start": 530.52,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          51439,
          1033,
          11,
          510,
          321,
          352,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.7754619261797737,
        "compression_ratio": 1.467741935483871,
        "end": 532.1800000000001,
        "id": 187,
        "no_speech_prob": 0.000028856933568022214,
        "seek": 53134,
        "start": 531.34,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.7754619261797737,
        "compression_ratio": 1.467741935483871,
        "end": 536.9200000000001,
        "id": 188,
        "no_speech_prob": 0.000028856933568022214,
        "seek": 53134,
        "start": 535.6800000000001,
        "temperature": 0,
        "text": " Welcome aboard.",
        "tokens": [
          50581,
          4027,
          27488,
          13,
          50643
        ]
      },
      {
        "avg_logprob": -0.7754619261797737,
        "compression_ratio": 1.467741935483871,
        "end": 547.2,
        "id": 189,
        "no_speech_prob": 0.000028856933568022214,
        "seek": 53134,
        "start": 546.36,
        "temperature": 0,
        "text": " Welcome aboard.",
        "tokens": [
          51115,
          4027,
          27488,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.7754619261797737,
        "compression_ratio": 1.467741935483871,
        "end": 550.1600000000001,
        "id": 190,
        "no_speech_prob": 0.000028856933568022214,
        "seek": 53134,
        "start": 549.32,
        "temperature": 0,
        "text": " Welcome aboard.",
        "tokens": [
          51263,
          4027,
          27488,
          13,
          51305
        ]
      },
      {
        "avg_logprob": -0.7754619261797737,
        "compression_ratio": 1.467741935483871,
        "end": 560.8000000000001,
        "id": 191,
        "no_speech_prob": 0.000028856933568022214,
        "seek": 53134,
        "start": 558.64,
        "temperature": 0,
        "text": " Okay, so you can see a bunch came in,",
        "tokens": [
          51729,
          1033,
          11,
          370,
          291,
          393,
          536,
          257,
          3840,
          1361,
          294,
          11,
          51837
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 563.62,
        "id": 192,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 561.14,
        "temperature": 0,
        "text": " and now I can go back here,",
        "tokens": [
          50381,
          293,
          586,
          286,
          393,
          352,
          646,
          510,
          11,
          50505
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 566.16,
        "id": 193,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 563.62,
        "temperature": 0,
        "text": " and I can go to here,",
        "tokens": [
          50505,
          293,
          286,
          393,
          352,
          281,
          510,
          11,
          50632
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 567.0999999999999,
        "id": 194,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 566.16,
        "temperature": 0,
        "text": " and we can see, look at this.",
        "tokens": [
          50632,
          293,
          321,
          393,
          536,
          11,
          574,
          412,
          341,
          13,
          50679
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 569.4399999999999,
        "id": 195,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 567.0999999999999,
        "temperature": 0,
        "text": " These are all the people who have now,",
        "tokens": [
          50679,
          1981,
          366,
          439,
          264,
          561,
          567,
          362,
          586,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 572.8599999999999,
        "id": 196,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 569.4399999999999,
        "temperature": 0,
        "text": " and if I click there, we can see where it's showing me",
        "tokens": [
          50796,
          293,
          498,
          286,
          2052,
          456,
          11,
          321,
          393,
          536,
          689,
          309,
          311,
          4099,
          385,
          50967
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 574.64,
        "id": 197,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 572.8599999999999,
        "temperature": 0,
        "text": " and going to these people's accounts.",
        "tokens": [
          50967,
          293,
          516,
          281,
          613,
          561,
          311,
          9402,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 575.8599999999999,
        "id": 198,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 574.64,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          51056,
          13268,
          0,
          51117
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 579.7199999999999,
        "id": 199,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 575.8599999999999,
        "temperature": 0,
        "text": " So we now have a bot that responds to follows.",
        "tokens": [
          51117,
          407,
          321,
          586,
          362,
          257,
          10592,
          300,
          27331,
          281,
          10002,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 582.06,
        "id": 200,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 579.7199999999999,
        "temperature": 0,
        "text": " Alka from the chat pointed out something here.",
        "tokens": [
          51310,
          967,
          2330,
          490,
          264,
          5081,
          10932,
          484,
          746,
          510,
          13,
          51427
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 582.9,
        "id": 201,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 582.06,
        "temperature": 0,
        "text": " What did I do?",
        "tokens": [
          51427,
          708,
          630,
          286,
          360,
          30,
          51469
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 585.42,
        "id": 202,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 582.9,
        "temperature": 0,
        "text": " Oh, the whole point of me making this variable",
        "tokens": [
          51469,
          876,
          11,
          264,
          1379,
          935,
          295,
          385,
          1455,
          341,
          7006,
          51595
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 587.5,
        "id": 203,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 585.42,
        "temperature": 0,
        "text": " was so that I don't have to write this all out here.",
        "tokens": [
          51595,
          390,
          370,
          300,
          286,
          500,
          380,
          362,
          281,
          2464,
          341,
          439,
          484,
          510,
          13,
          51699
        ]
      },
      {
        "avg_logprob": -0.2035549216800266,
        "compression_ratio": 1.726235741444867,
        "end": 588.66,
        "id": 204,
        "no_speech_prob": 0.00012931528908666223,
        "seek": 56080,
        "start": 587.5,
        "temperature": 0,
        "text": " I don't know why I did that.",
        "tokens": [
          51699,
          286,
          500,
          380,
          458,
          983,
          286,
          630,
          300,
          13,
          51757
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 590.6,
        "id": 205,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 588.66,
        "temperature": 0,
        "text": " So I can just do this.",
        "tokens": [
          50364,
          407,
          286,
          393,
          445,
          360,
          341,
          13,
          50461
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 591.92,
        "id": 206,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 590.6,
        "temperature": 0,
        "text": " This will make it much more readable.",
        "tokens": [
          50461,
          639,
          486,
          652,
          309,
          709,
          544,
          49857,
          13,
          50527
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 594.3199999999999,
        "id": 207,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 591.92,
        "temperature": 0,
        "text": " I actually don't need the ID, so I can take that out.",
        "tokens": [
          50527,
          286,
          767,
          500,
          380,
          643,
          264,
          7348,
          11,
          370,
          286,
          393,
          747,
          300,
          484,
          13,
          50647
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 595.36,
        "id": 208,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 594.3199999999999,
        "temperature": 0,
        "text": " So this is all I need.",
        "tokens": [
          50647,
          407,
          341,
          307,
          439,
          286,
          643,
          13,
          50699
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 596.1999999999999,
        "id": 209,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 595.36,
        "temperature": 0,
        "text": " So we are done.",
        "tokens": [
          50699,
          407,
          321,
          366,
          1096,
          13,
          50741
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 598.28,
        "id": 210,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 596.1999999999999,
        "temperature": 0,
        "text": " All right, so this is follow.",
        "tokens": [
          50741,
          1057,
          558,
          11,
          370,
          341,
          307,
          1524,
          13,
          50845
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 602.92,
        "id": 211,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 598.28,
        "temperature": 0,
        "text": " Now, I'm going to show you something in the next video.",
        "tokens": [
          50845,
          823,
          11,
          286,
          478,
          516,
          281,
          855,
          291,
          746,
          294,
          264,
          958,
          960,
          13,
          51077
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 604.52,
        "id": 212,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 602.92,
        "temperature": 0,
        "text": " I think I'm going to take a break,",
        "tokens": [
          51077,
          286,
          519,
          286,
          478,
          516,
          281,
          747,
          257,
          1821,
          11,
          51157
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 608.1,
        "id": 213,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 604.52,
        "temperature": 0,
        "text": " and in the next video, I'm going to look for messages",
        "tokens": [
          51157,
          293,
          294,
          264,
          958,
          960,
          11,
          286,
          478,
          516,
          281,
          574,
          337,
          7897,
          51336
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 609.56,
        "id": 214,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 608.1,
        "temperature": 0,
        "text": " that at mention the bot,",
        "tokens": [
          51336,
          300,
          412,
          2152,
          264,
          10592,
          11,
          51409
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 611.64,
        "id": 215,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 609.56,
        "temperature": 0,
        "text": " and then I'm going to have that bot act on those,",
        "tokens": [
          51409,
          293,
          550,
          286,
          478,
          516,
          281,
          362,
          300,
          10592,
          605,
          322,
          729,
          11,
          51513
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 614.0799999999999,
        "id": 216,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 611.64,
        "temperature": 0,
        "text": " either reply to them or favorite or do something like that.",
        "tokens": [
          51513,
          2139,
          16972,
          281,
          552,
          420,
          2954,
          420,
          360,
          746,
          411,
          300,
          13,
          51635
        ]
      },
      {
        "avg_logprob": -0.21557430051407725,
        "compression_ratio": 1.84,
        "end": 616.04,
        "id": 217,
        "no_speech_prob": 0.000010289507372363005,
        "seek": 58866,
        "start": 614.0799999999999,
        "temperature": 0,
        "text": " Okay, so that's what I'm going to do next.",
        "tokens": [
          51635,
          1033,
          11,
          370,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          958,
          13,
          51733
        ]
      },
      {
        "avg_logprob": -0.775913458604079,
        "compression_ratio": 0.6428571428571429,
        "end": 619.48,
        "id": 218,
        "no_speech_prob": 0.3691346347332001,
        "seek": 61604,
        "start": 616.04,
        "temperature": 0.4,
        "text": " ♪♪♪",
        "tokens": [
          50411,
          220,
          158,
          247,
          103,
          158,
          247,
          103,
          158,
          247,
          103,
          50536
        ]
      }
    ],
    "transcription": " Hello, all right, I'm still working with Mastodon and what I'm going to do in this video now is I'm going to take the sample bot that I made and instead of just on a timer every 24 hours, every 60 minutes, I happen to post something, I toot, what I'm going to do is I'm going to use the streaming API. The streaming API is a way for me to, in real time, listen for events and the particular kind of events that I'm going to listen for are what's known as user events. So a user event, and we'll see all the different kinds, is any time that I might get a notification or somebody that I follow might post something or any time that I might get, anyway, there's lots of things that come in, user events, and these are the good ones to use because if you're using your user event as a bot, you're sort of making sure that your bot only engages with people who are opting in, and this is pretty important. You don't want your bot just randomly spamming people and favoriting random things or replying to random people who haven't really asked to engage with your bot. So you're going to want to make sure that your bot follows the code of conduct in the terms of service of bots in space, I'll show you where you can find that, but typically, a good way to think about it is just like, if somebody is at mentioning the bot, then you're welcome to reply to them. If somebody follows you, then you're also welcome to engage with that person as the bot programmer. Okay, so let's go over and look at the streaming API. So before I start using the streaming API, let me just point out to read the information page with the code of conduct and also the terms of service if you're choosing to host your bot on bots in dot space, you're going to want to make sure you follow the rules of the space. Okay, now, what I'm going to do is I am going to start using the streaming API. So the way that I do that, and we can find it here, remember, this is the node package that I'm using, mastodon-api, and this is basically what I want to do. I want to create a listener, and whenever there is a message I want to take a look at it and do stuff, act upon that message. So let's actually do exactly this. I'm going to keep the error one in here as well. I'm just going to copy paste this into my code. I'm going to comment out this auto posting thing that I had before about the meaning of life. I'm just going to put this here. And actually what I want to do now is I want to use my little trick, instead of just console logging the message if you remember a little trick that I did in a previous video is I used write file. So I want to write files out so I can look at what kind of messages I'm getting. Whoops, ah, where have I gone? And so let me uncomment this out, and I do want to put like a timestamp also here. So it would make sense for me to say like data, and then actually the message probably has a timestamp built into it, but I can also like JavaScript timestamp. I think it's just like new date, get time, yeah. So I can say new date, get time. I think this is right. So again, you can put with template literals, I can put a whole string to evaluate, a whole line of code to evaluate in essence inside that area. Okay, so let's see if this works. What's going to happen? Let me see, am I in the right place? No, sorry, I made a new folder. So I'm going to release these examples separately. I'm going to run this bot. And now, okay, so I don't know if it's working because I don't know if I've gotten any notification. Maybe somebody watching this live is going to favorite something or at mention my bot. That would be nice, right? And then something would come in through here. Oh, I did get a message from somebody, but I made some sort of mistake. Data is not defined. Ah, okay, because, oh yes, it's called, the variable name is MSG for message, which is why I was thinking that, I guess. So it should be MSG here. Okay, let's try this again. And actually, I'm just going to take this out and I'm just going to write console.log user event. All right, everybody, are you watching? Are you giving me some user events? Here we go. Waiting for my user events. Okay, I think that was enough user events. Thank you very much. Let's go back and we can see here that I have all of these data.json files for all of these events. So I can kind of click through them and see what kind of events. I'm hoping that the kind people of the internet are not spamming me with horrible things. So the first kind of event we got here is a follow event. So if the event is a notification of type follow, we could act on that. So let's do that. Let's say, let's go back to our code. And I'm going to say, right here, I'm going to not write these out anymore. If, if message., what was it again? Message.event equals notification. And I think there's going to be different kinds of notifications. So I'm going to say then if message.data.type follow, then what I want to do is I want to get the user name. So let me get the user name. And that would be where? It would be, ah, right there. And actually, I want the account. The user name is useful, but you always on mastodon need both the user name and the instance, the address of the instance, the host name. So let me grab account equals message.data.account. And then the other thing that I'm pretty sure that I need is the ID, maybe. 7670, that's the account ID. This is the, I don't know what, this is the ID of the event, I guess. So I want that account ID. So I'm going to say constant ID equals message.data.id. Oh,.account, I forgot about account. I'm also message.data.account.id..account.account, and then.account.id. And then I want to send a message. So how do I do that? Just with this nice m.post. So here's the thing. Maybe I want to make this quote unquote to to function a bit more generic. And I'm just going to give it a, I'm going to pass in a status. So I'm going to get rid of the random number stuff, which was from before. And then I'm going to just put, this is a little confusing, but I'm going to take whatever I pass in, and then here is, and then I'm going to post that. So now I have a function that I can basically say, toot, and I can say, I'm going to use at, data.message.data.account, right? This is me referencing the person that followed me. Thank you for the follow. I'll just say, choo choo, welcome aboard. Huh, that's a train theme, welcome aboard. Okay, so we can see it'll say, welcome aboard. Now here's the thing. I really should also, if I go back to the API, this one, I should probably say in, and that's a reply to this, because I don't need, it's not in reply to a specific status, so this is actually fine. I think as long as I just at mention that, I'm done. So let me go, I've lost my code. Let me go back, I think I'm good. So now, I think that I have everything I want. So I am, let me just put the listened on error up here. So I'm listening for a message. If the message is a notification of a follow, then I will toot back to the person, their account name, and say, welcome aboard. Let's see how this goes. I look forward to all of you now. You can unfollow and follow if you already followed, but let me run it first. And here we go. Oh, okay, I have a status status. I have a mistake here. I'm just going to change this variable name to like txt, or content, let me make it content, because I don't like having the same name everywhere. It's confusing, but there should be no semicolon after there. Okay, here we go. Okay. Welcome aboard. Welcome aboard. Welcome aboard. Okay, so you can see a bunch came in, and now I can go back here, and I can go to here, and we can see, look at this. These are all the people who have now, and if I click there, we can see where it's showing me and going to these people's accounts. Yay! So we now have a bot that responds to follows. Alka from the chat pointed out something here. What did I do? Oh, the whole point of me making this variable was so that I don't have to write this all out here. I don't know why I did that. So I can just do this. This will make it much more readable. I actually don't need the ID, so I can take that out. So this is all I need. So we are done. All right, so this is follow. Now, I'm going to show you something in the next video. I think I'm going to take a break, and in the next video, I'm going to look for messages that at mention the bot, and then I'm going to have that bot act on those, either reply to them or favorite or do something like that. Okay, so that's what I'm going to do next. ♪♪♪",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:39.06457Z",
  "started_at": "2023-09-26T21:16:05.325084Z",
  "completed_at": "2023-09-26T21:19:03.474057Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=4hJykkzjXYY",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 178.148973
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/fc6is3rbdhuebaavts4bepv7lu/cancel",
    "get": "https://api.replicate.com/v1/predictions/fc6is3rbdhuebaavts4bepv7lu"
  }
}