{
  "id": "3bvdq2bbh4sz2nf5f25akhv3ri",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/ttz05d8DSOs.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/85407 [00:00<?, ?frames/s]\n  3%|▎         | 2876/85407 [00:09<04:36, 298.74frames/s]\n  7%|▋         | 5808/85407 [00:18<04:06, 322.38frames/s]\n 10%|█         | 8804/85407 [00:25<03:39, 349.32frames/s]\n 14%|█▎        | 11584/85407 [00:31<03:09, 388.82frames/s]\n 17%|█▋        | 14100/85407 [00:37<02:54, 409.72frames/s]\n 20%|█▉        | 16992/85407 [00:44<02:49, 404.37frames/s]\n 23%|██▎       | 19544/85407 [00:50<02:42, 404.36frames/s]\n 26%|██▋       | 22480/85407 [00:56<02:21, 444.92frames/s]\n 30%|██▉       | 25376/85407 [01:03<02:17, 438.09frames/s]\n 33%|███▎      | 28252/85407 [01:11<02:24, 394.91frames/s]\n 36%|███▌      | 30936/85407 [01:18<02:15, 402.62frames/s]\n 40%|███▉      | 33862/85407 [01:26<02:13, 386.56frames/s]\n 43%|████▎     | 36830/85407 [01:35<02:13, 363.14frames/s]\n 46%|████▋     | 39654/85407 [01:43<02:07, 357.53frames/s]\n 50%|████▉     | 42582/85407 [01:51<01:57, 364.15frames/s]\n 53%|█████▎    | 45306/85407 [01:58<01:46, 375.31frames/s]\n 57%|█████▋    | 48278/85407 [02:06<01:40, 368.76frames/s]\n 60%|█████▉    | 50954/85407 [02:13<01:32, 372.34frames/s]\n 63%|██████▎   | 53666/85407 [02:19<01:21, 391.32frames/s]\n 66%|██████▋   | 56622/85407 [02:26<01:09, 412.21frames/s]\n 70%|██████▉   | 59502/85407 [02:34<01:05, 394.81frames/s]\n 73%|███████▎  | 62470/85407 [02:40<00:56, 405.85frames/s]\n 76%|███████▌  | 65118/85407 [02:46<00:48, 416.74frames/s]\n 80%|███████▉  | 68006/85407 [02:53<00:40, 424.88frames/s]\n 83%|████████▎ | 70474/85407 [03:00<00:37, 398.96frames/s]\n 86%|████████▌ | 73186/85407 [03:06<00:29, 408.07frames/s]\n 89%|████████▉ | 75970/85407 [03:15<00:24, 381.04frames/s]\n 92%|█████████▏| 78782/85407 [03:25<00:19, 343.49frames/s]\n 96%|█████████▌| 81594/85407 [03:33<00:11, 343.53frames/s]\n 99%|█████████▉| 84450/85407 [03:39<00:02, 368.26frames/s]\n 99%|█████████▉| 84450/85407 [03:50<00:02, 368.26frames/s]\n100%|██████████| 85407/85407 [03:51<00:00, 253.35frames/s]\n100%|██████████| 85407/85407 [03:51<00:00, 368.43frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 1.28,
        "id": 0,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50364,
          2425,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 4.68,
        "id": 1,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 1.28,
        "temperature": 0,
        "text": " Welcome to another video in Nature of Code, Chapter 1",
        "tokens": [
          50428,
          4027,
          281,
          1071,
          960,
          294,
          20159,
          295,
          15549,
          11,
          18874,
          502,
          50598
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 6.04,
        "id": 2,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 4.68,
        "temperature": 0,
        "text": " Vectors series.",
        "tokens": [
          50598,
          691,
          557,
          830,
          2638,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 7.88,
        "id": 3,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 6.04,
        "temperature": 0,
        "text": " I really thought that in this video,",
        "tokens": [
          50666,
          286,
          534,
          1194,
          300,
          294,
          341,
          960,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 9.58,
        "id": 4,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 7.88,
        "temperature": 0,
        "text": " I was going to start making this example.",
        "tokens": [
          50758,
          286,
          390,
          516,
          281,
          722,
          1455,
          341,
          1365,
          13,
          50843
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 12.6,
        "id": 5,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 9.58,
        "temperature": 0,
        "text": " I almost have arrived there, where this mover object is",
        "tokens": [
          50843,
          286,
          1920,
          362,
          6678,
          456,
          11,
          689,
          341,
          39945,
          2657,
          307,
          50994
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 14.040000000000001,
        "id": 6,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 12.6,
        "temperature": 0,
        "text": " accelerating towards the mouse.",
        "tokens": [
          50994,
          34391,
          3030,
          264,
          9719,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 16.4,
        "id": 7,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 14.040000000000001,
        "temperature": 0,
        "text": " But there's a particular math function",
        "tokens": [
          51066,
          583,
          456,
          311,
          257,
          1729,
          5221,
          2445,
          51184
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 18.400000000000002,
        "id": 8,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 16.4,
        "temperature": 0,
        "text": " that I'm going to need for this example",
        "tokens": [
          51184,
          300,
          286,
          478,
          516,
          281,
          643,
          337,
          341,
          1365,
          51284
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 20.28,
        "id": 9,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 18.400000000000002,
        "temperature": 0,
        "text": " that I want to cover in a separate video.",
        "tokens": [
          51284,
          300,
          286,
          528,
          281,
          2060,
          294,
          257,
          4994,
          960,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 21.66,
        "id": 10,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 20.28,
        "temperature": 0,
        "text": " And that's the normalize function.",
        "tokens": [
          51378,
          400,
          300,
          311,
          264,
          2710,
          1125,
          2445,
          13,
          51447
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 24.8,
        "id": 11,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 21.66,
        "temperature": 0,
        "text": " I want to look at how I deal with and calculate",
        "tokens": [
          51447,
          286,
          528,
          281,
          574,
          412,
          577,
          286,
          2028,
          365,
          293,
          8873,
          51604
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 27.560000000000002,
        "id": 12,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 24.8,
        "temperature": 0,
        "text": " the magnitude of a vector, how I normalize a vector, what",
        "tokens": [
          51604,
          264,
          15668,
          295,
          257,
          8062,
          11,
          577,
          286,
          2710,
          1125,
          257,
          8062,
          11,
          437,
          51742
        ]
      },
      {
        "avg_logprob": -0.2622358124831627,
        "compression_ratio": 1.7591973244147157,
        "end": 28.76,
        "id": 13,
        "no_speech_prob": 0.0033763216342777014,
        "seek": 0,
        "start": 27.560000000000002,
        "temperature": 0,
        "text": " does that even mean.",
        "tokens": [
          51742,
          775,
          300,
          754,
          914,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 31.340000000000003,
        "id": 14,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 28.76,
        "temperature": 0,
        "text": " And the way that I'm going to do this",
        "tokens": [
          50364,
          400,
          264,
          636,
          300,
          286,
          478,
          516,
          281,
          360,
          341,
          50493
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 34.56,
        "id": 15,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 31.340000000000003,
        "temperature": 0,
        "text": " is look at creating a vector between the mouse",
        "tokens": [
          50493,
          307,
          574,
          412,
          4084,
          257,
          8062,
          1296,
          264,
          9719,
          50654
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 37.52,
        "id": 16,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 34.56,
        "temperature": 0,
        "text": " and the center of the canvas itself.",
        "tokens": [
          50654,
          293,
          264,
          3056,
          295,
          264,
          16267,
          2564,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 40.400000000000006,
        "id": 17,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 37.52,
        "temperature": 0,
        "text": " The scenario I want to look at is as follows.",
        "tokens": [
          50802,
          440,
          9005,
          286,
          528,
          281,
          574,
          412,
          307,
          382,
          10002,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 41,
        "id": 18,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 40.400000000000006,
        "temperature": 0,
        "text": " I have a canvas.",
        "tokens": [
          50946,
          286,
          362,
          257,
          16267,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 47.6,
        "id": 19,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 44.94,
        "temperature": 0,
        "text": " And I have some mover on the canvas, a particle somewhere.",
        "tokens": [
          51173,
          400,
          286,
          362,
          512,
          39945,
          322,
          264,
          16267,
          11,
          257,
          12359,
          4079,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 49.68000000000001,
        "id": 20,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 47.6,
        "temperature": 0,
        "text": " Let's just position it in the center.",
        "tokens": [
          51306,
          961,
          311,
          445,
          2535,
          309,
          294,
          264,
          3056,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 52.56,
        "id": 21,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 49.68000000000001,
        "temperature": 0,
        "text": " Let's say this is 600 by 400.",
        "tokens": [
          51410,
          961,
          311,
          584,
          341,
          307,
          11849,
          538,
          8423,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 54.68000000000001,
        "id": 22,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 52.56,
        "temperature": 0,
        "text": " It's not exactly drawn to scale, but close enough.",
        "tokens": [
          51554,
          467,
          311,
          406,
          2293,
          10117,
          281,
          4373,
          11,
          457,
          1998,
          1547,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 57,
        "id": 23,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 54.68000000000001,
        "temperature": 0,
        "text": " So this is 300 comma 200.",
        "tokens": [
          51660,
          407,
          341,
          307,
          6641,
          22117,
          2331,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.197800349413864,
        "compression_ratio": 1.657258064516129,
        "end": 58.08,
        "id": 24,
        "no_speech_prob": 0.000003966980330005754,
        "seek": 2876,
        "start": 57,
        "temperature": 0,
        "text": " Then I have the mouse.",
        "tokens": [
          51776,
          1396,
          286,
          362,
          264,
          9719,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 59.879999999999995,
        "id": 25,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 58.08,
        "temperature": 0,
        "text": " I'm moving my mouse around somewhere.",
        "tokens": [
          50364,
          286,
          478,
          2684,
          452,
          9719,
          926,
          4079,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 61.879999999999995,
        "id": 26,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 59.879999999999995,
        "temperature": 0,
        "text": " And let's say I have the mouse over here.",
        "tokens": [
          50454,
          400,
          718,
          311,
          584,
          286,
          362,
          264,
          9719,
          670,
          510,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 65.48,
        "id": 27,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 61.879999999999995,
        "temperature": 0,
        "text": " I'm going to try to draw a mouse arrow.",
        "tokens": [
          50554,
          286,
          478,
          516,
          281,
          853,
          281,
          2642,
          257,
          9719,
          11610,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 72.48,
        "id": 28,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 65.48,
        "temperature": 0,
        "text": " And we'll call this location 580 comma 20.",
        "tokens": [
          50734,
          400,
          321,
          603,
          818,
          341,
          4914,
          1025,
          4702,
          22117,
          945,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 74.64,
        "id": 29,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 72.48,
        "temperature": 0,
        "text": " What I'm looking to do is figure out",
        "tokens": [
          51084,
          708,
          286,
          478,
          1237,
          281,
          360,
          307,
          2573,
          484,
          51192
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 78,
        "id": 30,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 74.64,
        "temperature": 0,
        "text": " how do I calculate, if I know this position",
        "tokens": [
          51192,
          577,
          360,
          286,
          8873,
          11,
          498,
          286,
          458,
          341,
          2535,
          51360
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 82.12,
        "id": 31,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 78,
        "temperature": 0,
        "text": " and this position, a vector that points from one to the other.",
        "tokens": [
          51360,
          293,
          341,
          2535,
          11,
          257,
          8062,
          300,
          2793,
          490,
          472,
          281,
          264,
          661,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 84.16,
        "id": 32,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 82.12,
        "temperature": 0,
        "text": " If I want this particular particle",
        "tokens": [
          51566,
          759,
          286,
          528,
          341,
          1729,
          12359,
          51668
        ]
      },
      {
        "avg_logprob": -0.20130262642263252,
        "compression_ratio": 1.6434782608695653,
        "end": 88.03999999999999,
        "id": 33,
        "no_speech_prob": 0.000036478490073932335,
        "seek": 5808,
        "start": 84.16,
        "temperature": 0,
        "text": " to accelerate towards the mouse, how",
        "tokens": [
          51668,
          281,
          21341,
          3030,
          264,
          9719,
          11,
          577,
          51862
        ]
      },
      {
        "avg_logprob": -0.1953738530476888,
        "compression_ratio": 1.548780487804878,
        "end": 90.28,
        "id": 34,
        "no_speech_prob": 0.00009610229608369991,
        "seek": 8804,
        "start": 88.04,
        "temperature": 0,
        "text": " do I calculate this particular vector?",
        "tokens": [
          50364,
          360,
          286,
          8873,
          341,
          1729,
          8062,
          30,
          50476
        ]
      },
      {
        "avg_logprob": -0.1953738530476888,
        "compression_ratio": 1.548780487804878,
        "end": 95.68,
        "id": 35,
        "no_speech_prob": 0.00009610229608369991,
        "seek": 8804,
        "start": 90.28,
        "temperature": 0,
        "text": " Call it v. Well, when I say calculate the vector, what",
        "tokens": [
          50476,
          7807,
          309,
          371,
          13,
          1042,
          11,
          562,
          286,
          584,
          8873,
          264,
          8062,
          11,
          437,
          50746
        ]
      },
      {
        "avg_logprob": -0.1953738530476888,
        "compression_ratio": 1.548780487804878,
        "end": 99.88000000000001,
        "id": 36,
        "no_speech_prob": 0.00009610229608369991,
        "seek": 8804,
        "start": 95.68,
        "temperature": 0,
        "text": " I'm really looking for is the x component and the y component.",
        "tokens": [
          50746,
          286,
          478,
          534,
          1237,
          337,
          307,
          264,
          2031,
          6542,
          293,
          264,
          288,
          6542,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.1953738530476888,
        "compression_ratio": 1.548780487804878,
        "end": 104.84,
        "id": 37,
        "no_speech_prob": 0.00009610229608369991,
        "seek": 8804,
        "start": 99.88000000000001,
        "temperature": 0,
        "text": " So v dot x equals what?",
        "tokens": [
          50956,
          407,
          371,
          5893,
          2031,
          6915,
          437,
          30,
          51204
        ]
      },
      {
        "avg_logprob": -0.1953738530476888,
        "compression_ratio": 1.548780487804878,
        "end": 108.16000000000001,
        "id": 38,
        "no_speech_prob": 0.00009610229608369991,
        "seek": 8804,
        "start": 104.84,
        "temperature": 0,
        "text": " 580 minus 300.",
        "tokens": [
          51204,
          1025,
          4702,
          3175,
          6641,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.1953738530476888,
        "compression_ratio": 1.548780487804878,
        "end": 111.92,
        "id": 39,
        "no_speech_prob": 0.00009610229608369991,
        "seek": 8804,
        "start": 108.16000000000001,
        "temperature": 0,
        "text": " So 580 minus 300, that's 280.",
        "tokens": [
          51370,
          407,
          1025,
          4702,
          3175,
          6641,
          11,
          300,
          311,
          41229,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.1953738530476888,
        "compression_ratio": 1.548780487804878,
        "end": 115.84,
        "id": 40,
        "no_speech_prob": 0.00009610229608369991,
        "seek": 8804,
        "start": 111.92,
        "temperature": 0,
        "text": " v dot y equals 200 minus 20.",
        "tokens": [
          51558,
          371,
          5893,
          288,
          6915,
          2331,
          3175,
          945,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.17362789991425304,
        "compression_ratio": 1.658682634730539,
        "end": 119.28,
        "id": 41,
        "no_speech_prob": 0.000015446303223143332,
        "seek": 11584,
        "start": 115.84,
        "temperature": 0,
        "text": " This length is 180.",
        "tokens": [
          50364,
          639,
          4641,
          307,
          11971,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.17362789991425304,
        "compression_ratio": 1.658682634730539,
        "end": 124.44,
        "id": 42,
        "no_speech_prob": 0.000015446303223143332,
        "seek": 11584,
        "start": 119.28,
        "temperature": 0,
        "text": " So this vector is 280 comma 180.",
        "tokens": [
          50536,
          407,
          341,
          8062,
          307,
          41229,
          22117,
          11971,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.17362789991425304,
        "compression_ratio": 1.658682634730539,
        "end": 128.08,
        "id": 43,
        "no_speech_prob": 0.000015446303223143332,
        "seek": 11584,
        "start": 124.44,
        "temperature": 0,
        "text": " What mathematical operation did I just do here?",
        "tokens": [
          50794,
          708,
          18894,
          6916,
          630,
          286,
          445,
          360,
          510,
          30,
          50976
        ]
      },
      {
        "avg_logprob": -0.17362789991425304,
        "compression_ratio": 1.658682634730539,
        "end": 129.92000000000002,
        "id": 44,
        "no_speech_prob": 0.000015446303223143332,
        "seek": 11584,
        "start": 128.08,
        "temperature": 0,
        "text": " I have two vectors, really.",
        "tokens": [
          50976,
          286,
          362,
          732,
          18875,
          11,
          534,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.17362789991425304,
        "compression_ratio": 1.658682634730539,
        "end": 133,
        "id": 45,
        "no_speech_prob": 0.000015446303223143332,
        "seek": 11584,
        "start": 129.92000000000002,
        "temperature": 0,
        "text": " I have this vector, which I'll call position.",
        "tokens": [
          51068,
          286,
          362,
          341,
          8062,
          11,
          597,
          286,
          603,
          818,
          2535,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.17362789991425304,
        "compression_ratio": 1.658682634730539,
        "end": 135.88,
        "id": 46,
        "no_speech_prob": 0.000015446303223143332,
        "seek": 11584,
        "start": 133,
        "temperature": 0,
        "text": " And I have this vector, which I'll call mouse.",
        "tokens": [
          51222,
          400,
          286,
          362,
          341,
          8062,
          11,
          597,
          286,
          603,
          818,
          9719,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.17362789991425304,
        "compression_ratio": 1.658682634730539,
        "end": 141,
        "id": 47,
        "no_speech_prob": 0.000015446303223143332,
        "seek": 11584,
        "start": 135.88,
        "temperature": 0,
        "text": " What I did is I said mouse minus position gives me v. v",
        "tokens": [
          51366,
          708,
          286,
          630,
          307,
          286,
          848,
          9719,
          3175,
          2535,
          2709,
          385,
          371,
          13,
          371,
          51622
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 150.44,
        "id": 48,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 141,
        "temperature": 0,
        "text": " equals mouse minus position.",
        "tokens": [
          50364,
          6915,
          9719,
          3175,
          2535,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 153,
        "id": 49,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 150.44,
        "temperature": 0,
        "text": " Let's confirm that this really works, the subtract operation",
        "tokens": [
          50836,
          961,
          311,
          9064,
          300,
          341,
          534,
          1985,
          11,
          264,
          16390,
          6916,
          50964
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 154.16,
        "id": 50,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 153,
        "temperature": 0,
        "text": " by diagramming this.",
        "tokens": [
          50964,
          538,
          10686,
          2810,
          341,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 156.52,
        "id": 51,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 154.16,
        "temperature": 0,
        "text": " So if I take this mouse vector that's",
        "tokens": [
          51022,
          407,
          498,
          286,
          747,
          341,
          9719,
          8062,
          300,
          311,
          51140
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 160.2,
        "id": 52,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 156.52,
        "temperature": 0,
        "text": " pointing from 0 to this location 580 comma 200,",
        "tokens": [
          51140,
          12166,
          490,
          1958,
          281,
          341,
          4914,
          1025,
          4702,
          22117,
          2331,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 163.6,
        "id": 53,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 160.2,
        "temperature": 0,
        "text": " and I kind of draw that down here, it's not exactly right,",
        "tokens": [
          51324,
          293,
          286,
          733,
          295,
          2642,
          300,
          760,
          510,
          11,
          309,
          311,
          406,
          2293,
          558,
          11,
          51494
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 165.2,
        "id": 54,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 163.6,
        "temperature": 0,
        "text": " but I just sort of duplicate this here.",
        "tokens": [
          51494,
          457,
          286,
          445,
          1333,
          295,
          23976,
          341,
          510,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 168.16,
        "id": 55,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 165.2,
        "temperature": 0,
        "text": " If I were to add, if I were to say plus position,",
        "tokens": [
          51574,
          759,
          286,
          645,
          281,
          909,
          11,
          498,
          286,
          645,
          281,
          584,
          1804,
          2535,
          11,
          51722
        ]
      },
      {
        "avg_logprob": -0.25351158777872723,
        "compression_ratio": 1.5892116182572613,
        "end": 169.92000000000002,
        "id": 56,
        "no_speech_prob": 0.000043319014366716146,
        "seek": 14100,
        "start": 168.16,
        "temperature": 0,
        "text": " I would put these vectors end to end.",
        "tokens": [
          51722,
          286,
          576,
          829,
          613,
          18875,
          917,
          281,
          917,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 172.28,
        "id": 57,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 169.92,
        "temperature": 0,
        "text": " So I would take this vector and put it like over here.",
        "tokens": [
          50364,
          407,
          286,
          576,
          747,
          341,
          8062,
          293,
          829,
          309,
          411,
          670,
          510,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 174.64,
        "id": 58,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 172.28,
        "temperature": 0,
        "text": " I'm about to go out of your range of view,",
        "tokens": [
          50482,
          286,
          478,
          466,
          281,
          352,
          484,
          295,
          428,
          3613,
          295,
          1910,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 176.39999999999998,
        "id": 59,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 174.64,
        "temperature": 0,
        "text": " so I'll just draw it a little bit shorter.",
        "tokens": [
          50600,
          370,
          286,
          603,
          445,
          2642,
          309,
          257,
          707,
          857,
          11639,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 177.56,
        "id": 60,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 176.39999999999998,
        "temperature": 0,
        "text": " But this is the idea.",
        "tokens": [
          50688,
          583,
          341,
          307,
          264,
          1558,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 181.64,
        "id": 61,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 177.56,
        "temperature": 0,
        "text": " Mouse plus position would give me this vector,",
        "tokens": [
          50746,
          29383,
          1804,
          2535,
          576,
          976,
          385,
          341,
          8062,
          11,
          50950
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 183.39999999999998,
        "id": 62,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 181.64,
        "temperature": 0,
        "text": " mouse plus position.",
        "tokens": [
          50950,
          9719,
          1804,
          2535,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 186.32,
        "id": 63,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 183.39999999999998,
        "temperature": 0,
        "text": " But I want to say mouse minus position,",
        "tokens": [
          51038,
          583,
          286,
          528,
          281,
          584,
          9719,
          3175,
          2535,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 189,
        "id": 64,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 186.32,
        "temperature": 0,
        "text": " so that's taking this position vector",
        "tokens": [
          51184,
          370,
          300,
          311,
          1940,
          341,
          2535,
          8062,
          51318
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 192.11999999999998,
        "id": 65,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 189,
        "temperature": 0,
        "text": " and pointing it in the opposite direction.",
        "tokens": [
          51318,
          293,
          12166,
          309,
          294,
          264,
          6182,
          3513,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.21674226364999447,
        "compression_ratio": 1.7688679245283019,
        "end": 195.44,
        "id": 66,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 16992,
        "start": 192.11999999999998,
        "temperature": 0,
        "text": " This is minus position.",
        "tokens": [
          51474,
          639,
          307,
          3175,
          2535,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.26875039088873215,
        "compression_ratio": 1.5913978494623655,
        "end": 202.32,
        "id": 67,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 19544,
        "start": 195.44,
        "temperature": 0,
        "text": " So mouse minus position is this vector v right here,",
        "tokens": [
          50364,
          407,
          9719,
          3175,
          2535,
          307,
          341,
          8062,
          371,
          558,
          510,
          11,
          50708
        ]
      },
      {
        "avg_logprob": -0.26875039088873215,
        "compression_ratio": 1.5913978494623655,
        "end": 205.2,
        "id": 68,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 19544,
        "start": 202.32,
        "temperature": 0,
        "text": " and you can see that matches up with that.",
        "tokens": [
          50708,
          293,
          291,
          393,
          536,
          300,
          10676,
          493,
          365,
          300,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.26875039088873215,
        "compression_ratio": 1.5913978494623655,
        "end": 214.52,
        "id": 69,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 19544,
        "start": 212.24,
        "temperature": 0,
        "text": " So this example is drawing random vectors",
        "tokens": [
          51204,
          407,
          341,
          1365,
          307,
          6316,
          4974,
          18875,
          51318
        ]
      },
      {
        "avg_logprob": -0.26875039088873215,
        "compression_ratio": 1.5913978494623655,
        "end": 215.8,
        "id": 70,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 19544,
        "start": 214.52,
        "temperature": 0,
        "text": " that emanate from the center.",
        "tokens": [
          51318,
          300,
          28211,
          473,
          490,
          264,
          3056,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.26875039088873215,
        "compression_ratio": 1.5913978494623655,
        "end": 217.96,
        "id": 71,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 19544,
        "start": 215.8,
        "temperature": 0,
        "text": " Let's try that math operation.",
        "tokens": [
          51382,
          961,
          311,
          853,
          300,
          5221,
          6916,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.26875039088873215,
        "compression_ratio": 1.5913978494623655,
        "end": 220.28,
        "id": 72,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 19544,
        "start": 217.96,
        "temperature": 0,
        "text": " So I'm going to actually get rid of all this,",
        "tokens": [
          51490,
          407,
          286,
          478,
          516,
          281,
          767,
          483,
          3973,
          295,
          439,
          341,
          11,
          51606
        ]
      },
      {
        "avg_logprob": -0.26875039088873215,
        "compression_ratio": 1.5913978494623655,
        "end": 224.8,
        "id": 73,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 19544,
        "start": 220.28,
        "temperature": 0,
        "text": " and I'm going to say position equals create vector,",
        "tokens": [
          51606,
          293,
          286,
          478,
          516,
          281,
          584,
          2535,
          6915,
          1884,
          8062,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 229.04000000000002,
        "id": 74,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 224.8,
        "temperature": 0,
        "text": " the center 200, 200, mouse equals create vector,",
        "tokens": [
          50364,
          264,
          3056,
          2331,
          11,
          2331,
          11,
          9719,
          6915,
          1884,
          8062,
          11,
          50576
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 231.96,
        "id": 75,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 229.04000000000002,
        "temperature": 0,
        "text": " mouse x, mouse y.",
        "tokens": [
          50576,
          9719,
          2031,
          11,
          9719,
          288,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 237.76000000000002,
        "id": 76,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 231.96,
        "temperature": 0,
        "text": " And then v is, and to do this subtraction,",
        "tokens": [
          50722,
          400,
          550,
          371,
          307,
          11,
          293,
          281,
          360,
          341,
          16390,
          313,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 240.12,
        "id": 77,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 237.76000000000002,
        "temperature": 0,
        "text": " mouse minus position and store it in a new vector,",
        "tokens": [
          51012,
          9719,
          3175,
          2535,
          293,
          3531,
          309,
          294,
          257,
          777,
          8062,
          11,
          51130
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 243.20000000000002,
        "id": 78,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 240.12,
        "temperature": 0,
        "text": " I need a static function.",
        "tokens": [
          51130,
          286,
          643,
          257,
          13437,
          2445,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 245.12,
        "id": 79,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 243.20000000000002,
        "temperature": 0,
        "text": " That's what the previous video was about.",
        "tokens": [
          51284,
          663,
          311,
          437,
          264,
          3894,
          960,
          390,
          466,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 251.04000000000002,
        "id": 80,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 245.12,
        "temperature": 0,
        "text": " So I can say p5.vector.subtract mouse minus position.",
        "tokens": [
          51380,
          407,
          286,
          393,
          584,
          280,
          20,
          13,
          303,
          1672,
          13,
          30131,
          83,
          1897,
          9719,
          3175,
          2535,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.24650943756103516,
        "compression_ratio": 1.64321608040201,
        "end": 253.76000000000002,
        "id": 81,
        "no_speech_prob": 0.00007602474215673283,
        "seek": 22480,
        "start": 251.04000000000002,
        "temperature": 0,
        "text": " And actually, let me put the translate back,",
        "tokens": [
          51676,
          400,
          767,
          11,
          718,
          385,
          829,
          264,
          13799,
          646,
          11,
          51812
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 255.2,
        "id": 82,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 253.76,
        "temperature": 0,
        "text": " because I want to draw everything",
        "tokens": [
          50364,
          570,
          286,
          528,
          281,
          2642,
          1203,
          50436
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 257.52,
        "id": 83,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 255.2,
        "temperature": 0,
        "text": " relative to the center.",
        "tokens": [
          50436,
          4972,
          281,
          264,
          3056,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 258.24,
        "id": 84,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 257.52,
        "temperature": 0,
        "text": " Oh, look at that.",
        "tokens": [
          50552,
          876,
          11,
          574,
          412,
          300,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 259.64,
        "id": 85,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 258.24,
        "temperature": 0,
        "text": " I still have the funny background",
        "tokens": [
          50588,
          286,
          920,
          362,
          264,
          4074,
          3678,
          50658
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 260.56,
        "id": 86,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 259.64,
        "temperature": 0,
        "text": " thing, which I'll keep.",
        "tokens": [
          50658,
          551,
          11,
          597,
          286,
          603,
          1066,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 262.28,
        "id": 87,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 260.56,
        "temperature": 0,
        "text": " So no matter where I move the mouse,",
        "tokens": [
          50704,
          407,
          572,
          1871,
          689,
          286,
          1286,
          264,
          9719,
          11,
          50790
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 264.8,
        "id": 88,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 262.28,
        "temperature": 0,
        "text": " I now have a vector that points from the center",
        "tokens": [
          50790,
          286,
          586,
          362,
          257,
          8062,
          300,
          2793,
          490,
          264,
          3056,
          50916
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 265.8,
        "id": 89,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 264.8,
        "temperature": 0,
        "text": " to where the mouse is.",
        "tokens": [
          50916,
          281,
          689,
          264,
          9719,
          307,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 267.36,
        "id": 90,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 265.8,
        "temperature": 0,
        "text": " Now, certainly, this visualization",
        "tokens": [
          50966,
          823,
          11,
          3297,
          11,
          341,
          25801,
          51044
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 269.8,
        "id": 91,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 267.36,
        "temperature": 0,
        "text": " could have been created just by calling the line function",
        "tokens": [
          51044,
          727,
          362,
          668,
          2942,
          445,
          538,
          5141,
          264,
          1622,
          2445,
          51166
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 273.59999999999997,
        "id": 92,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 269.8,
        "temperature": 0,
        "text": " and saying line 200, 200, mouse x, mouse y.",
        "tokens": [
          51166,
          293,
          1566,
          1622,
          2331,
          11,
          2331,
          11,
          9719,
          2031,
          11,
          9719,
          288,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 275.8,
        "id": 93,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 273.59999999999997,
        "temperature": 0,
        "text": " But the reason why I'm doing it this way",
        "tokens": [
          51356,
          583,
          264,
          1778,
          983,
          286,
          478,
          884,
          309,
          341,
          636,
          51466
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 278.92,
        "id": 94,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 275.8,
        "temperature": 0,
        "text": " through vector subtraction is to show you",
        "tokens": [
          51466,
          807,
          8062,
          16390,
          313,
          307,
          281,
          855,
          291,
          51622
        ]
      },
      {
        "avg_logprob": -0.21945647118796766,
        "compression_ratio": 1.7043189368770764,
        "end": 282.52,
        "id": 95,
        "no_speech_prob": 0.000018342887415201403,
        "seek": 25376,
        "start": 278.92,
        "temperature": 0,
        "text": " about the normalize function and what kind of power",
        "tokens": [
          51622,
          466,
          264,
          2710,
          1125,
          2445,
          293,
          437,
          733,
          295,
          1347,
          51802
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 284.15999999999997,
        "id": 96,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 282.56,
        "temperature": 0,
        "text": " that unlocks.",
        "tokens": [
          50366,
          300,
          517,
          34896,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 286.44,
        "id": 97,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 284.15999999999997,
        "temperature": 0,
        "text": " Let's say that I have a collection of vectors.",
        "tokens": [
          50446,
          961,
          311,
          584,
          300,
          286,
          362,
          257,
          5765,
          295,
          18875,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 289.2,
        "id": 98,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 286.44,
        "temperature": 0,
        "text": " I'm going to draw five of them.",
        "tokens": [
          50560,
          286,
          478,
          516,
          281,
          2642,
          1732,
          295,
          552,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 294.03999999999996,
        "id": 99,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 289.2,
        "temperature": 0,
        "text": " All random directions, all varying lengths.",
        "tokens": [
          50698,
          1057,
          4974,
          11095,
          11,
          439,
          22984,
          26329,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 295.84,
        "id": 100,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 294.03999999999996,
        "temperature": 0,
        "text": " Those are my five vectors.",
        "tokens": [
          50940,
          3950,
          366,
          452,
          1732,
          18875,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 299.14,
        "id": 101,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 295.84,
        "temperature": 0,
        "text": " The process of normalization, which",
        "tokens": [
          51030,
          440,
          1399,
          295,
          2710,
          2144,
          11,
          597,
          51195
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 302.76,
        "id": 102,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 299.14,
        "temperature": 0,
        "text": " is executed with the normalize function in p5.js,",
        "tokens": [
          51195,
          307,
          17577,
          365,
          264,
          2710,
          1125,
          2445,
          294,
          280,
          20,
          13,
          25530,
          11,
          51376
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 306.94,
        "id": 103,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 302.76,
        "temperature": 0,
        "text": " is to take any vector of any length in any direction",
        "tokens": [
          51376,
          307,
          281,
          747,
          604,
          8062,
          295,
          604,
          4641,
          294,
          604,
          3513,
          51585
        ]
      },
      {
        "avg_logprob": -0.20604192596120932,
        "compression_ratio": 1.5904761904761904,
        "end": 309.35999999999996,
        "id": 104,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 28252,
        "start": 306.94,
        "temperature": 0,
        "text": " and make it into a unit vector.",
        "tokens": [
          51585,
          293,
          652,
          309,
          666,
          257,
          4985,
          8062,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 315.40000000000003,
        "id": 105,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 309.36,
        "temperature": 0,
        "text": " A unit vector is one where the magnitude, the length, is 1.",
        "tokens": [
          50364,
          316,
          4985,
          8062,
          307,
          472,
          689,
          264,
          15668,
          11,
          264,
          4641,
          11,
          307,
          502,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 319.76,
        "id": 106,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 315.40000000000003,
        "temperature": 0,
        "text": " So let's just establish that this is approximately",
        "tokens": [
          50666,
          407,
          718,
          311,
          445,
          8327,
          300,
          341,
          307,
          10447,
          50884
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 323.08000000000004,
        "id": 107,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 319.76,
        "temperature": 0,
        "text": " length 1 in terms of this arbitrary two-dimensional space",
        "tokens": [
          50884,
          4641,
          502,
          294,
          2115,
          295,
          341,
          23211,
          732,
          12,
          18759,
          1901,
          51050
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 323.88,
        "id": 108,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 323.08000000000004,
        "temperature": 0,
        "text": " I'm working with.",
        "tokens": [
          51050,
          286,
          478,
          1364,
          365,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 327.52000000000004,
        "id": 109,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 323.88,
        "temperature": 0,
        "text": " So this vector normalized would be this vector.",
        "tokens": [
          51090,
          407,
          341,
          8062,
          48704,
          576,
          312,
          341,
          8062,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 329.92,
        "id": 110,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 327.52000000000004,
        "temperature": 0,
        "text": " This vector normalized would be this vector.",
        "tokens": [
          51272,
          639,
          8062,
          48704,
          576,
          312,
          341,
          8062,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 332,
        "id": 111,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 329.92,
        "temperature": 0,
        "text": " This vector, oh, it's less than 1.",
        "tokens": [
          51392,
          639,
          8062,
          11,
          1954,
          11,
          309,
          311,
          1570,
          813,
          502,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 334.16,
        "id": 112,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 332,
        "temperature": 0,
        "text": " So normalizing it would actually be to grow it,",
        "tokens": [
          51496,
          407,
          2710,
          3319,
          309,
          576,
          767,
          312,
          281,
          1852,
          309,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 335.44,
        "id": 113,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 334.16,
        "temperature": 0,
        "text": " would be this vector.",
        "tokens": [
          51604,
          576,
          312,
          341,
          8062,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 337.08000000000004,
        "id": 114,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 335.44,
        "temperature": 0,
        "text": " This vector would be this vector.",
        "tokens": [
          51668,
          639,
          8062,
          576,
          312,
          341,
          8062,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.2189267011192756,
        "compression_ratio": 2.0821917808219177,
        "end": 338.62,
        "id": 115,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 30936,
        "start": 337.08000000000004,
        "temperature": 0,
        "text": " And this vector would be this vector.",
        "tokens": [
          51750,
          400,
          341,
          8062,
          576,
          312,
          341,
          8062,
          13,
          51827
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 340.74,
        "id": 116,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 338.62,
        "temperature": 0,
        "text": " Now, of course, I haven't drawn these exactly right,",
        "tokens": [
          50364,
          823,
          11,
          295,
          1164,
          11,
          286,
          2378,
          380,
          10117,
          613,
          2293,
          558,
          11,
          50470
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 341.62,
        "id": 117,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 340.74,
        "temperature": 0,
        "text": " but this is the idea.",
        "tokens": [
          50470,
          457,
          341,
          307,
          264,
          1558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 344.98,
        "id": 118,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 341.62,
        "temperature": 0,
        "text": " All of these are normalized versions of these.",
        "tokens": [
          50514,
          1057,
          295,
          613,
          366,
          48704,
          9606,
          295,
          613,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 346.9,
        "id": 119,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 344.98,
        "temperature": 0,
        "text": " And you can think of the term normalize",
        "tokens": [
          50682,
          400,
          291,
          393,
          519,
          295,
          264,
          1433,
          2710,
          1125,
          50778
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 349.78000000000003,
        "id": 120,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 346.9,
        "temperature": 0,
        "text": " as making all these vectors into a normal vector.",
        "tokens": [
          50778,
          382,
          1455,
          439,
          613,
          18875,
          666,
          257,
          2710,
          8062,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 352.26,
        "id": 121,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 349.78000000000003,
        "temperature": 0,
        "text": " Normal being, well, a normal vector is length 1.",
        "tokens": [
          50922,
          21277,
          885,
          11,
          731,
          11,
          257,
          2710,
          8062,
          307,
          4641,
          502,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 354.74,
        "id": 122,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 352.26,
        "temperature": 0,
        "text": " Otherwise, it's some wacky, crazy, insane vector",
        "tokens": [
          51046,
          10328,
          11,
          309,
          311,
          512,
          42138,
          88,
          11,
          3219,
          11,
          10838,
          8062,
          51170
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 356.26,
        "id": 123,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 354.74,
        "temperature": 0,
        "text": " with a much longer length.",
        "tokens": [
          51170,
          365,
          257,
          709,
          2854,
          4641,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 358.86,
        "id": 124,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 356.26,
        "temperature": 0,
        "text": " It's basically having a standard.",
        "tokens": [
          51246,
          467,
          311,
          1936,
          1419,
          257,
          3832,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 362.2,
        "id": 125,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 358.86,
        "temperature": 0,
        "text": " By the way, in vector notation, a vector",
        "tokens": [
          51376,
          3146,
          264,
          636,
          11,
          294,
          8062,
          24657,
          11,
          257,
          8062,
          51543
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 365.22,
        "id": 126,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 362.2,
        "temperature": 0,
        "text": " is typically written like vector v with an arrow on top.",
        "tokens": [
          51543,
          307,
          5850,
          3720,
          411,
          8062,
          371,
          365,
          364,
          11610,
          322,
          1192,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.22178483516611952,
        "compression_ratio": 1.7937062937062938,
        "end": 368.3,
        "id": 127,
        "no_speech_prob": 0.00010071389988297597,
        "seek": 33862,
        "start": 365.22,
        "temperature": 0,
        "text": " The unit vector is often written as vector v",
        "tokens": [
          51694,
          440,
          4985,
          8062,
          307,
          2049,
          3720,
          382,
          8062,
          371,
          51848
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 370.46000000000004,
        "id": 128,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 368.38,
        "temperature": 0,
        "text": " with the hat or caret on top.",
        "tokens": [
          50368,
          365,
          264,
          2385,
          420,
          1127,
          83,
          322,
          1192,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 374.46000000000004,
        "id": 129,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 370.46000000000004,
        "temperature": 0,
        "text": " So this would be a unit vector v or any given vector v.",
        "tokens": [
          50472,
          407,
          341,
          576,
          312,
          257,
          4985,
          8062,
          371,
          420,
          604,
          2212,
          8062,
          371,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 376.86,
        "id": 130,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 374.46000000000004,
        "temperature": 0,
        "text": " So if I come back to this example here,",
        "tokens": [
          50672,
          407,
          498,
          286,
          808,
          646,
          281,
          341,
          1365,
          510,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 381.78000000000003,
        "id": 131,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 376.86,
        "temperature": 0,
        "text": " one of the things we could look at is I could say v.normalize.",
        "tokens": [
          50792,
          472,
          295,
          264,
          721,
          321,
          727,
          574,
          412,
          307,
          286,
          727,
          584,
          371,
          13,
          23157,
          1125,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 385.06,
        "id": 132,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 381.78000000000003,
        "temperature": 0,
        "text": " What does that do?",
        "tokens": [
          51038,
          708,
          775,
          300,
          360,
          30,
          51202
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 385.98,
        "id": 133,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 385.06,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          51202,
          8239,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 387.98,
        "id": 134,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 385.98,
        "temperature": 0,
        "text": " Well, it makes the vector length 1.",
        "tokens": [
          51248,
          1042,
          11,
          309,
          1669,
          264,
          8062,
          4641,
          502,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 389.5,
        "id": 135,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 387.98,
        "temperature": 0,
        "text": " So I can just keep zooming into this.",
        "tokens": [
          51348,
          407,
          286,
          393,
          445,
          1066,
          48226,
          666,
          341,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 391.86,
        "id": 136,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 389.5,
        "temperature": 0,
        "text": " I'm drawing something of pixel length 1.",
        "tokens": [
          51424,
          286,
          478,
          6316,
          746,
          295,
          19261,
          4641,
          502,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 394.18,
        "id": 137,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 391.86,
        "temperature": 0,
        "text": " So how does the math for normalize work?",
        "tokens": [
          51542,
          407,
          577,
          775,
          264,
          5221,
          337,
          2710,
          1125,
          589,
          30,
          51658
        ]
      },
      {
        "avg_logprob": -0.2500781434955019,
        "compression_ratio": 1.6867469879518073,
        "end": 396.54,
        "id": 138,
        "no_speech_prob": 0.0000037266377148625907,
        "seek": 36830,
        "start": 394.18,
        "temperature": 0,
        "text": " Luckily for us, we could just call normalize in p5.",
        "tokens": [
          51658,
          19726,
          337,
          505,
          11,
          321,
          727,
          445,
          818,
          2710,
          1125,
          294,
          280,
          20,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 398.54,
        "id": 139,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 396.54,
        "temperature": 0,
        "text": " But this is a moment for us to take a little time",
        "tokens": [
          50364,
          583,
          341,
          307,
          257,
          1623,
          337,
          505,
          281,
          747,
          257,
          707,
          565,
          50464
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 401.54,
        "id": 140,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 398.54,
        "temperature": 0,
        "text": " to look at the math for that.",
        "tokens": [
          50464,
          281,
          574,
          412,
          264,
          5221,
          337,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 403.78000000000003,
        "id": 141,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 401.54,
        "temperature": 0,
        "text": " Well, before we can look at the math for normalize,",
        "tokens": [
          50614,
          1042,
          11,
          949,
          321,
          393,
          574,
          412,
          264,
          5221,
          337,
          2710,
          1125,
          11,
          50726
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 407.54,
        "id": 142,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 403.78000000000003,
        "temperature": 0,
        "text": " we actually should look for the math at another function",
        "tokens": [
          50726,
          321,
          767,
          820,
          574,
          337,
          264,
          5221,
          412,
          1071,
          2445,
          50914
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 408.98,
        "id": 143,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 407.54,
        "temperature": 0,
        "text": " called mag.",
        "tokens": [
          50914,
          1219,
          2258,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 410.86,
        "id": 144,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 408.98,
        "temperature": 0,
        "text": " And mag is a function that returns",
        "tokens": [
          50986,
          400,
          2258,
          307,
          257,
          2445,
          300,
          11247,
          51080
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 412.66,
        "id": 145,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 410.86,
        "temperature": 0,
        "text": " the magnitude of a vector.",
        "tokens": [
          51080,
          264,
          15668,
          295,
          257,
          8062,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 417.34000000000003,
        "id": 146,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 412.66,
        "temperature": 0,
        "text": " So it returns the scalar length of any given vector,",
        "tokens": [
          51170,
          407,
          309,
          11247,
          264,
          39684,
          4641,
          295,
          604,
          2212,
          8062,
          11,
          51404
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 419.18,
        "id": 147,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 417.34000000000003,
        "temperature": 0,
        "text": " that magnitude itself.",
        "tokens": [
          51404,
          300,
          15668,
          2564,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 420.52000000000004,
        "id": 148,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 419.18,
        "temperature": 0,
        "text": " So one thing that I could do here",
        "tokens": [
          51496,
          407,
          472,
          551,
          300,
          286,
          727,
          360,
          510,
          51563
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 423.18,
        "id": 149,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 420.52000000000004,
        "temperature": 0,
        "text": " that could demonstrate this is let me take the background",
        "tokens": [
          51563,
          300,
          727,
          11698,
          341,
          307,
          718,
          385,
          747,
          264,
          3678,
          51696
        ]
      },
      {
        "avg_logprob": -0.21941101935602003,
        "compression_ratio": 1.8408163265306123,
        "end": 425.82000000000005,
        "id": 150,
        "no_speech_prob": 0.000026688525395002216,
        "seek": 39654,
        "start": 423.18,
        "temperature": 0,
        "text": " and draw it in draw.",
        "tokens": [
          51696,
          293,
          2642,
          309,
          294,
          2642,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 426.5,
        "id": 151,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 425.82,
        "temperature": 0,
        "text": " Run this again.",
        "tokens": [
          50364,
          8950,
          341,
          797,
          13,
          50398
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 430.65999999999997,
        "id": 152,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 426.5,
        "temperature": 0,
        "text": " Oh, and I guess I will make this much brighter.",
        "tokens": [
          50398,
          876,
          11,
          293,
          286,
          2041,
          286,
          486,
          652,
          341,
          709,
          19764,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 433.58,
        "id": 153,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 430.65999999999997,
        "temperature": 0,
        "text": " So now I've just got this line pointing to the mouse.",
        "tokens": [
          50606,
          407,
          586,
          286,
          600,
          445,
          658,
          341,
          1622,
          12166,
          281,
          264,
          9719,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 437.9,
        "id": 154,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 433.58,
        "temperature": 0,
        "text": " And I'm going to ask for the magnitude.",
        "tokens": [
          50752,
          400,
          286,
          478,
          516,
          281,
          1029,
          337,
          264,
          15668,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 441.62,
        "id": 155,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 437.9,
        "temperature": 0,
        "text": " So that is now getting the magnitude of that.",
        "tokens": [
          50968,
          407,
          300,
          307,
          586,
          1242,
          264,
          15668,
          295,
          300,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 444.34,
        "id": 156,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 441.62,
        "temperature": 0,
        "text": " And actually, let's just console log it.",
        "tokens": [
          51154,
          400,
          767,
          11,
          718,
          311,
          445,
          11076,
          3565,
          309,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 447.3,
        "id": 157,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 444.34,
        "temperature": 0,
        "text": " So you can see this console log down here",
        "tokens": [
          51290,
          407,
          291,
          393,
          536,
          341,
          11076,
          3565,
          760,
          510,
          51438
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 450.14,
        "id": 158,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 447.3,
        "temperature": 0,
        "text": " is giving me the magnitude of the vector",
        "tokens": [
          51438,
          307,
          2902,
          385,
          264,
          15668,
          295,
          264,
          8062,
          51580
        ]
      },
      {
        "avg_logprob": -0.22402356941009235,
        "compression_ratio": 1.724770642201835,
        "end": 453.06,
        "id": 159,
        "no_speech_prob": 0.0000736858492018655,
        "seek": 42582,
        "start": 450.14,
        "temperature": 0,
        "text": " itself as I move the mouse closer to the center.",
        "tokens": [
          51580,
          2564,
          382,
          286,
          1286,
          264,
          9719,
          4966,
          281,
          264,
          3056,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 455.78000000000003,
        "id": 160,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 453.06,
        "temperature": 0,
        "text": " And you can see it's always a positive number",
        "tokens": [
          50364,
          400,
          291,
          393,
          536,
          309,
          311,
          1009,
          257,
          3353,
          1230,
          50500
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 458.1,
        "id": 161,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 455.78000000000003,
        "temperature": 0,
        "text": " because it's the length of it, no matter what",
        "tokens": [
          50500,
          570,
          309,
          311,
          264,
          4641,
          295,
          309,
          11,
          572,
          1871,
          437,
          50616
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 459.94,
        "id": 162,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 458.1,
        "temperature": 0,
        "text": " direction it's pointing in.",
        "tokens": [
          50616,
          3513,
          309,
          311,
          12166,
          294,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 461.34,
        "id": 163,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 459.94,
        "temperature": 0,
        "text": " I could try something interesting.",
        "tokens": [
          50708,
          286,
          727,
          853,
          746,
          1880,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 463.56,
        "id": 164,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 461.34,
        "temperature": 0,
        "text": " Like I could say, oh, let's make the background color",
        "tokens": [
          50778,
          1743,
          286,
          727,
          584,
          11,
          1954,
          11,
          718,
          311,
          652,
          264,
          3678,
          2017,
          50889
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 465.1,
        "id": 165,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 463.56,
        "temperature": 0,
        "text": " associated with the magnitude.",
        "tokens": [
          50889,
          6615,
          365,
          264,
          15668,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 468.38,
        "id": 166,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 465.1,
        "temperature": 0,
        "text": " So now you can see the closer the mouse gets to the center,",
        "tokens": [
          50966,
          407,
          586,
          291,
          393,
          536,
          264,
          4966,
          264,
          9719,
          2170,
          281,
          264,
          3056,
          11,
          51130
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 472.26,
        "id": 167,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 468.38,
        "temperature": 0,
        "text": " the brighter the background is.",
        "tokens": [
          51130,
          264,
          19764,
          264,
          3678,
          307,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 473.74,
        "id": 168,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 472.26,
        "temperature": 0,
        "text": " Sort of an interesting interaction",
        "tokens": [
          51324,
          26149,
          295,
          364,
          1880,
          9285,
          51398
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 475.3,
        "id": 169,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 473.74,
        "temperature": 0,
        "text": " that you could play with.",
        "tokens": [
          51398,
          300,
          291,
          727,
          862,
          365,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 478.14,
        "id": 170,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 475.3,
        "temperature": 0,
        "text": " And the reason why this magnitude value is so important",
        "tokens": [
          51476,
          400,
          264,
          1778,
          983,
          341,
          15668,
          2158,
          307,
          370,
          1021,
          51618
        ]
      },
      {
        "avg_logprob": -0.2292737160020202,
        "compression_ratio": 1.7465753424657535,
        "end": 482.78,
        "id": 171,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 45306,
        "start": 478.14,
        "temperature": 0,
        "text": " is it plays a fundamental role in how a vector is normalized.",
        "tokens": [
          51618,
          307,
          309,
          5749,
          257,
          8088,
          3090,
          294,
          577,
          257,
          8062,
          307,
          48704,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 485.94,
        "id": 172,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 482.78,
        "temperature": 0,
        "text": " Let's say I take this vector.",
        "tokens": [
          50364,
          961,
          311,
          584,
          286,
          747,
          341,
          8062,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 488.14,
        "id": 173,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 485.94,
        "temperature": 0,
        "text": " And this is the magnitude m.",
        "tokens": [
          50522,
          400,
          341,
          307,
          264,
          15668,
          275,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 490.65999999999997,
        "id": 174,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 488.14,
        "temperature": 0,
        "text": " And this is the x component and the y component.",
        "tokens": [
          50632,
          400,
          341,
          307,
          264,
          2031,
          6542,
          293,
          264,
          288,
          6542,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 494.78,
        "id": 175,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 490.65999999999997,
        "temperature": 0,
        "text": " Well, another way I could draw this diagram",
        "tokens": [
          50758,
          1042,
          11,
          1071,
          636,
          286,
          727,
          2642,
          341,
          10686,
          50964
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 498.7,
        "id": 176,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 494.78,
        "temperature": 0,
        "text": " is like this, a right triangle with a, b, and c.",
        "tokens": [
          50964,
          307,
          411,
          341,
          11,
          257,
          558,
          13369,
          365,
          257,
          11,
          272,
          11,
          293,
          269,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 501.26,
        "id": 177,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 498.7,
        "temperature": 0,
        "text": " And if you've ever seen this kind of diagram in a geometry",
        "tokens": [
          51160,
          400,
          498,
          291,
          600,
          1562,
          1612,
          341,
          733,
          295,
          10686,
          294,
          257,
          18426,
          51288
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 503.9,
        "id": 178,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 501.26,
        "temperature": 0,
        "text": " context, you might have seen it paired with something called",
        "tokens": [
          51288,
          4319,
          11,
          291,
          1062,
          362,
          1612,
          309,
          25699,
          365,
          746,
          1219,
          51420
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 505.53999999999996,
        "id": 179,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 503.9,
        "temperature": 0,
        "text": " the Pythagorean theorem.",
        "tokens": [
          51420,
          264,
          9953,
          392,
          559,
          25885,
          20904,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.20381790294981839,
        "compression_ratio": 1.742489270386266,
        "end": 509.53999999999996,
        "id": 180,
        "no_speech_prob": 4.520940706242982e-7,
        "seek": 48278,
        "start": 505.53999999999996,
        "temperature": 0,
        "text": " The Pythagorean theorem states that a squared plus b squared",
        "tokens": [
          51502,
          440,
          9953,
          392,
          559,
          25885,
          20904,
          4368,
          300,
          257,
          8889,
          1804,
          272,
          8889,
          51702
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 515.9,
        "id": 181,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 509.54,
        "temperature": 0,
        "text": " equals c squared, or c equals the square root of a squared",
        "tokens": [
          50364,
          6915,
          269,
          8889,
          11,
          420,
          269,
          6915,
          264,
          3732,
          5593,
          295,
          257,
          8889,
          50682
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 516.94,
        "id": 182,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 515.9,
        "temperature": 0,
        "text": " plus b squared.",
        "tokens": [
          50682,
          1804,
          272,
          8889,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 521.34,
        "id": 183,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 516.94,
        "temperature": 0,
        "text": " And in fact, that is exactly how the magnitude is calculated.",
        "tokens": [
          50734,
          400,
          294,
          1186,
          11,
          300,
          307,
          2293,
          577,
          264,
          15668,
          307,
          15598,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 523.94,
        "id": 184,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 521.34,
        "temperature": 0,
        "text": " So when magnitude, the mag function",
        "tokens": [
          50954,
          407,
          562,
          15668,
          11,
          264,
          2258,
          2445,
          51084
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 527.74,
        "id": 185,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 523.94,
        "temperature": 0,
        "text": " is called on a vector, v.mag, it takes",
        "tokens": [
          51084,
          307,
          1219,
          322,
          257,
          8062,
          11,
          371,
          13,
          37941,
          11,
          309,
          2516,
          51274
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 530.14,
        "id": 186,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 527.74,
        "temperature": 0,
        "text": " the square root of the x component squared",
        "tokens": [
          51274,
          264,
          3732,
          5593,
          295,
          264,
          2031,
          6542,
          8889,
          51394
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 531.44,
        "id": 187,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 530.14,
        "temperature": 0,
        "text": " plus the y component squared.",
        "tokens": [
          51394,
          1804,
          264,
          288,
          6542,
          8889,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 533.78,
        "id": 188,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 531.44,
        "temperature": 0,
        "text": " And that gives you that magnitude.",
        "tokens": [
          51459,
          400,
          300,
          2709,
          291,
          300,
          15668,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.23116649280894885,
        "compression_ratio": 1.9371727748691099,
        "end": 536.66,
        "id": 189,
        "no_speech_prob": 0.000031201903766486794,
        "seek": 50954,
        "start": 533.78,
        "temperature": 0,
        "text": " Now that I understand how magnitude is calculated,",
        "tokens": [
          51576,
          823,
          300,
          286,
          1223,
          577,
          15668,
          307,
          15598,
          11,
          51720
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 541.5799999999999,
        "id": 190,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 536.66,
        "temperature": 0,
        "text": " I'm ready to look at how normalization works.",
        "tokens": [
          50364,
          286,
          478,
          1919,
          281,
          574,
          412,
          577,
          2710,
          2144,
          1985,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 545.02,
        "id": 191,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 541.5799999999999,
        "temperature": 0,
        "text": " Let's use the 3, 4, 5 triangle as our starting point.",
        "tokens": [
          50610,
          961,
          311,
          764,
          264,
          805,
          11,
          1017,
          11,
          1025,
          13369,
          382,
          527,
          2891,
          935,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 547.78,
        "id": 192,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 545.02,
        "temperature": 0,
        "text": " So let's say I have a vector.",
        "tokens": [
          50782,
          407,
          718,
          311,
          584,
          286,
          362,
          257,
          8062,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 552.06,
        "id": 193,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 547.78,
        "temperature": 0,
        "text": " Its components are 4 and 3.",
        "tokens": [
          50920,
          6953,
          6677,
          366,
          1017,
          293,
          805,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 554.62,
        "id": 194,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 552.06,
        "temperature": 0,
        "text": " We know that the magnitude now equals",
        "tokens": [
          51134,
          492,
          458,
          300,
          264,
          15668,
          586,
          6915,
          51262
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 558.8199999999999,
        "id": 195,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 554.62,
        "temperature": 0,
        "text": " the square root of 4 squared plus 3 squared, which",
        "tokens": [
          51262,
          264,
          3732,
          5593,
          295,
          1017,
          8889,
          1804,
          805,
          8889,
          11,
          597,
          51472
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 564.06,
        "id": 196,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 558.8199999999999,
        "temperature": 0,
        "text": " is 16 plus 9, which is 25, the square root of which is 5.",
        "tokens": [
          51472,
          307,
          3165,
          1804,
          1722,
          11,
          597,
          307,
          3552,
          11,
          264,
          3732,
          5593,
          295,
          597,
          307,
          1025,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.15644951622084816,
        "compression_ratio": 1.5951219512195123,
        "end": 566.22,
        "id": 197,
        "no_speech_prob": 0.000002260323299196898,
        "seek": 53666,
        "start": 564.06,
        "temperature": 0,
        "text": " So the magnitude is 5.",
        "tokens": [
          51734,
          407,
          264,
          15668,
          307,
          1025,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 569.0600000000001,
        "id": 198,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 566.28,
        "temperature": 0,
        "text": " You can see how this math for calculating the magnitude now",
        "tokens": [
          50367,
          509,
          393,
          536,
          577,
          341,
          5221,
          337,
          28258,
          264,
          15668,
          586,
          50506
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 569.86,
        "id": 199,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 569.0600000000001,
        "temperature": 0,
        "text": " works out.",
        "tokens": [
          50506,
          1985,
          484,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 572.14,
        "id": 200,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 569.86,
        "temperature": 0,
        "text": " If I wanted to normalize this vector,",
        "tokens": [
          50546,
          759,
          286,
          1415,
          281,
          2710,
          1125,
          341,
          8062,
          11,
          50660
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 577.0600000000001,
        "id": 201,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 572.14,
        "temperature": 0,
        "text": " that means I want to shrink this length, which is 5, down to 1.",
        "tokens": [
          50660,
          300,
          1355,
          286,
          528,
          281,
          23060,
          341,
          4641,
          11,
          597,
          307,
          1025,
          11,
          760,
          281,
          502,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 579.3000000000001,
        "id": 202,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 577.0600000000001,
        "temperature": 0,
        "text": " So it turns out if I'm taking a vector",
        "tokens": [
          50906,
          407,
          309,
          4523,
          484,
          498,
          286,
          478,
          1940,
          257,
          8062,
          51018
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 582.6600000000001,
        "id": 203,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 579.3000000000001,
        "temperature": 0,
        "text": " and normalizing its length down to 1 or up to 1,",
        "tokens": [
          51018,
          293,
          2710,
          3319,
          1080,
          4641,
          760,
          281,
          502,
          420,
          493,
          281,
          502,
          11,
          51186
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 584.58,
        "id": 204,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 582.6600000000001,
        "temperature": 0,
        "text": " 5 divided by 5 is 1.",
        "tokens": [
          51186,
          1025,
          6666,
          538,
          1025,
          307,
          502,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 587.22,
        "id": 205,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 584.58,
        "temperature": 0,
        "text": " I can actually just take the components, the x and y",
        "tokens": [
          51282,
          286,
          393,
          767,
          445,
          747,
          264,
          6677,
          11,
          264,
          2031,
          293,
          288,
          51414
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 589.4200000000001,
        "id": 206,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 587.22,
        "temperature": 0,
        "text": " components, and divide by the magnitude.",
        "tokens": [
          51414,
          6677,
          11,
          293,
          9845,
          538,
          264,
          15668,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 592.3000000000001,
        "id": 207,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 589.4200000000001,
        "temperature": 0,
        "text": " So this length right here is actually 3 fifths.",
        "tokens": [
          51524,
          407,
          341,
          4641,
          558,
          510,
          307,
          767,
          805,
          9266,
          82,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.18197013350094066,
        "compression_ratio": 1.858267716535433,
        "end": 595.02,
        "id": 208,
        "no_speech_prob": 0.0000019947297005273867,
        "seek": 56622,
        "start": 592.3000000000001,
        "temperature": 0,
        "text": " And this length right here is actually 4 fifths.",
        "tokens": [
          51668,
          400,
          341,
          4641,
          558,
          510,
          307,
          767,
          1017,
          9266,
          82,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 596.74,
        "id": 209,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 595.02,
        "temperature": 0,
        "text": " And that's how you normalize a vector,",
        "tokens": [
          50364,
          400,
          300,
          311,
          577,
          291,
          2710,
          1125,
          257,
          8062,
          11,
          50450
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 599.26,
        "id": 210,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 596.74,
        "temperature": 0,
        "text": " by dividing it by its magnitude.",
        "tokens": [
          50450,
          538,
          26764,
          309,
          538,
          1080,
          15668,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 603.46,
        "id": 211,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 599.26,
        "temperature": 0,
        "text": " So removing this background little digression,",
        "tokens": [
          50576,
          407,
          12720,
          341,
          3678,
          707,
          2528,
          2775,
          11,
          50786
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 609.26,
        "id": 212,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 603.46,
        "temperature": 0,
        "text": " I can now actually normalize v by saying v.div,",
        "tokens": [
          50786,
          286,
          393,
          586,
          767,
          2710,
          1125,
          371,
          538,
          1566,
          371,
          13,
          67,
          592,
          11,
          51076
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 613.22,
        "id": 213,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 609.26,
        "temperature": 0,
        "text": " D-I-V for divide a vector by its magnitude.",
        "tokens": [
          51076,
          413,
          12,
          40,
          12,
          53,
          337,
          9845,
          257,
          8062,
          538,
          1080,
          15668,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 616.22,
        "id": 214,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 613.22,
        "temperature": 0,
        "text": " So if I do that, oh, wait a second.",
        "tokens": [
          51274,
          407,
          498,
          286,
          360,
          300,
          11,
          1954,
          11,
          1699,
          257,
          1150,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 617.02,
        "id": 215,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 616.22,
        "temperature": 0,
        "text": " Well, there it is.",
        "tokens": [
          51424,
          1042,
          11,
          456,
          309,
          307,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 618.9399999999999,
        "id": 216,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 617.02,
        "temperature": 0,
        "text": " You can see no matter where I put the mouse,",
        "tokens": [
          51464,
          509,
          393,
          536,
          572,
          1871,
          689,
          286,
          829,
          264,
          9719,
          11,
          51560
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 621.9399999999999,
        "id": 217,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 618.9399999999999,
        "temperature": 0,
        "text": " I have this nice vector of length 1.",
        "tokens": [
          51560,
          286,
          362,
          341,
          1481,
          8062,
          295,
          4641,
          502,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.19519590362300718,
        "compression_ratio": 1.6016260162601625,
        "end": 624.6999999999999,
        "id": 218,
        "no_speech_prob": 0.00000533815500602941,
        "seek": 59502,
        "start": 621.9399999999999,
        "temperature": 0,
        "text": " But maybe what I should do is then scale it up",
        "tokens": [
          51710,
          583,
          1310,
          437,
          286,
          820,
          360,
          307,
          550,
          4373,
          309,
          493,
          51848
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 628.5400000000001,
        "id": 219,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 624.7800000000001,
        "temperature": 0,
        "text": " by something like 50, multiplying it.",
        "tokens": [
          50368,
          538,
          746,
          411,
          2625,
          11,
          30955,
          309,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 629.3000000000001,
        "id": 220,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 628.5400000000001,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          50556,
          400,
          574,
          412,
          341,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 632.62,
        "id": 221,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 629.3000000000001,
        "temperature": 0,
        "text": " So now I have this multi-step process",
        "tokens": [
          50594,
          407,
          586,
          286,
          362,
          341,
          4825,
          12,
          16792,
          1399,
          50760
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 635.46,
        "id": 222,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 632.62,
        "temperature": 0,
        "text": " to make a vector that points at a given direction",
        "tokens": [
          50760,
          281,
          652,
          257,
          8062,
          300,
          2793,
          412,
          257,
          2212,
          3513,
          50902
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 636.7800000000001,
        "id": 223,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 635.46,
        "temperature": 0,
        "text": " with a fixed length.",
        "tokens": [
          50902,
          365,
          257,
          6806,
          4641,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 639.5400000000001,
        "id": 224,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 636.7800000000001,
        "temperature": 0,
        "text": " I have some vector that I've calculated.",
        "tokens": [
          50968,
          286,
          362,
          512,
          8062,
          300,
          286,
          600,
          15598,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 641.7800000000001,
        "id": 225,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 639.5400000000001,
        "temperature": 0,
        "text": " Call it v. And the first thing I do",
        "tokens": [
          51106,
          7807,
          309,
          371,
          13,
          400,
          264,
          700,
          551,
          286,
          360,
          51218
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 645.4200000000001,
        "id": 226,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 641.7800000000001,
        "temperature": 0,
        "text": " is I call v.mag, which gives me the magnitude.",
        "tokens": [
          51218,
          307,
          286,
          818,
          371,
          13,
          37941,
          11,
          597,
          2709,
          385,
          264,
          15668,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 646.7800000000001,
        "id": 227,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 645.4200000000001,
        "temperature": 0,
        "text": " Maybe it's 100.",
        "tokens": [
          51400,
          2704,
          309,
          311,
          2319,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 648.5,
        "id": 228,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 646.7800000000001,
        "temperature": 0,
        "text": " So the length is 100.",
        "tokens": [
          51468,
          407,
          264,
          4641,
          307,
          2319,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.20238458699193493,
        "compression_ratio": 1.5847457627118644,
        "end": 651.1800000000001,
        "id": 229,
        "no_speech_prob": 0.0000316932491841726,
        "seek": 62470,
        "start": 648.5,
        "temperature": 0,
        "text": " Then what I want to do is normalize the vector.",
        "tokens": [
          51554,
          1396,
          437,
          286,
          528,
          281,
          360,
          307,
          2710,
          1125,
          264,
          8062,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 655.54,
        "id": 230,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 651.2199999999999,
        "temperature": 0,
        "text": " I want the vector to be that same vector, but of length 1.",
        "tokens": [
          50366,
          286,
          528,
          264,
          8062,
          281,
          312,
          300,
          912,
          8062,
          11,
          457,
          295,
          4641,
          502,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 660.3399999999999,
        "id": 231,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 655.54,
        "temperature": 0,
        "text": " So I can say v.div by that magnitude, or 100.",
        "tokens": [
          50582,
          407,
          286,
          393,
          584,
          371,
          13,
          67,
          592,
          538,
          300,
          15668,
          11,
          420,
          2319,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 663.2199999999999,
        "id": 232,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 660.3399999999999,
        "temperature": 0,
        "text": " That takes this vector and shrinks it down to here.",
        "tokens": [
          50822,
          663,
          2516,
          341,
          8062,
          293,
          9884,
          16431,
          309,
          760,
          281,
          510,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 669.42,
        "id": 233,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 663.2199999999999,
        "temperature": 0,
        "text": " Then I want to scale it up by some amount like 50.",
        "tokens": [
          50966,
          1396,
          286,
          528,
          281,
          4373,
          309,
          493,
          538,
          512,
          2372,
          411,
          2625,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 673.18,
        "id": 234,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 669.42,
        "temperature": 0,
        "text": " And that will then scale it back up to a higher length of 50.",
        "tokens": [
          51276,
          400,
          300,
          486,
          550,
          4373,
          309,
          646,
          493,
          281,
          257,
          2946,
          4641,
          295,
          2625,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 675.14,
        "id": 235,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 673.18,
        "temperature": 0,
        "text": " So this is my multi-step process.",
        "tokens": [
          51464,
          407,
          341,
          307,
          452,
          4825,
          12,
          16792,
          1399,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 677.06,
        "id": 236,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 675.14,
        "temperature": 0,
        "text": " But this is with all of this math.",
        "tokens": [
          51562,
          583,
          341,
          307,
          365,
          439,
          295,
          341,
          5221,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.1744283095650051,
        "compression_ratio": 1.6302521008403361,
        "end": 680.06,
        "id": 237,
        "no_speech_prob": 0.00007254358206409961,
        "seek": 65118,
        "start": 677.06,
        "temperature": 0,
        "text": " And in fact, instead of calculating the magnitude",
        "tokens": [
          51658,
          400,
          294,
          1186,
          11,
          2602,
          295,
          28258,
          264,
          15668,
          51808
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 684.7399999999999,
        "id": 238,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 680.06,
        "temperature": 0,
        "text": " and dividing by the magnitude, I can just instead call,",
        "tokens": [
          50364,
          293,
          26764,
          538,
          264,
          15668,
          11,
          286,
          393,
          445,
          2602,
          818,
          11,
          50598
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 687.9399999999999,
        "id": 239,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 684.7399999999999,
        "temperature": 0,
        "text": " it's such a common operation, I could just",
        "tokens": [
          50598,
          309,
          311,
          1270,
          257,
          2689,
          6916,
          11,
          286,
          727,
          445,
          50758
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 689.9399999999999,
        "id": 240,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 687.9399999999999,
        "temperature": 0,
        "text": " instead call v.normalize.",
        "tokens": [
          50758,
          2602,
          818,
          371,
          13,
          23157,
          1125,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 692.7399999999999,
        "id": 241,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 689.9399999999999,
        "temperature": 0,
        "text": " So v.normalize is the act of taking any vector",
        "tokens": [
          50858,
          407,
          371,
          13,
          23157,
          1125,
          307,
          264,
          605,
          295,
          1940,
          604,
          8062,
          50998
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 694.0999999999999,
        "id": 242,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 692.7399999999999,
        "temperature": 0,
        "text": " and shrinking it to length 1.",
        "tokens": [
          50998,
          293,
          41684,
          309,
          281,
          4641,
          502,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 696.9399999999999,
        "id": 243,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 694.0999999999999,
        "temperature": 0,
        "text": " I did a terrible job of drawing these in the same direction.",
        "tokens": [
          51066,
          286,
          630,
          257,
          6237,
          1691,
          295,
          6316,
          613,
          294,
          264,
          912,
          3513,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 698.6199999999999,
        "id": 244,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 696.9399999999999,
        "temperature": 0,
        "text": " But hopefully you get the idea.",
        "tokens": [
          51208,
          583,
          4696,
          291,
          483,
          264,
          1558,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 702.9,
        "id": 245,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 698.6199999999999,
        "temperature": 0,
        "text": " So now I can simplify this by commenting these out and just",
        "tokens": [
          51292,
          407,
          586,
          286,
          393,
          20460,
          341,
          538,
          29590,
          613,
          484,
          293,
          445,
          51506
        ]
      },
      {
        "avg_logprob": -0.21216694513956705,
        "compression_ratio": 1.6695652173913043,
        "end": 704.7399999999999,
        "id": 246,
        "no_speech_prob": 0.000004785094461112749,
        "seek": 68006,
        "start": 702.9,
        "temperature": 0,
        "text": " changing this to v.normalize.",
        "tokens": [
          51506,
          4473,
          341,
          281,
          371,
          13,
          23157,
          1125,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.36206693147358143,
        "compression_ratio": 1.4928909952606635,
        "end": 709.82,
        "id": 247,
        "no_speech_prob": 0.00009461252193432301,
        "seek": 70474,
        "start": 705.66,
        "temperature": 0,
        "text": " And we've got the same exact result. But guess what?",
        "tokens": [
          50410,
          400,
          321,
          600,
          658,
          264,
          912,
          1900,
          1874,
          13,
          583,
          2041,
          437,
          30,
          50618
        ]
      },
      {
        "avg_logprob": -0.36206693147358143,
        "compression_ratio": 1.4928909952606635,
        "end": 715.1800000000001,
        "id": 248,
        "no_speech_prob": 0.00009461252193432301,
        "seek": 70474,
        "start": 709.82,
        "temperature": 0,
        "text": " v.normalize, v.multiply times 50 is also such a common operation.",
        "tokens": [
          50618,
          371,
          13,
          23157,
          1125,
          11,
          371,
          13,
          76,
          723,
          647,
          356,
          1413,
          2625,
          307,
          611,
          1270,
          257,
          2689,
          6916,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.36206693147358143,
        "compression_ratio": 1.4928909952606635,
        "end": 718.3,
        "id": 249,
        "no_speech_prob": 0.00009461252193432301,
        "seek": 70474,
        "start": 715.1800000000001,
        "temperature": 0,
        "text": " Like I want this vector in this direction,",
        "tokens": [
          50886,
          1743,
          286,
          528,
          341,
          8062,
          294,
          341,
          3513,
          11,
          51042
        ]
      },
      {
        "avg_logprob": -0.36206693147358143,
        "compression_ratio": 1.4928909952606635,
        "end": 720.9,
        "id": 250,
        "no_speech_prob": 0.00009461252193432301,
        "seek": 70474,
        "start": 718.3,
        "temperature": 0,
        "text": " but I just want it to be this magnitude.",
        "tokens": [
          51042,
          457,
          286,
          445,
          528,
          309,
          281,
          312,
          341,
          15668,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.36206693147358143,
        "compression_ratio": 1.4928909952606635,
        "end": 728.38,
        "id": 251,
        "no_speech_prob": 0.00009461252193432301,
        "seek": 70474,
        "start": 720.9,
        "temperature": 0,
        "text": " That in fact, I can even take these and just call v.setmag50.",
        "tokens": [
          51172,
          663,
          294,
          1186,
          11,
          286,
          393,
          754,
          747,
          613,
          293,
          445,
          818,
          371,
          13,
          3854,
          37941,
          2803,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.36206693147358143,
        "compression_ratio": 1.4928909952606635,
        "end": 731.86,
        "id": 252,
        "no_speech_prob": 0.00009461252193432301,
        "seek": 70474,
        "start": 728.38,
        "temperature": 0,
        "text": " So this function v.set the magnitude of the vector",
        "tokens": [
          51546,
          407,
          341,
          2445,
          371,
          13,
          3854,
          264,
          15668,
          295,
          264,
          8062,
          51720
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 735.62,
        "id": 253,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 732.5,
        "temperature": 0,
        "text": " is the process of normalizing it down to length 1",
        "tokens": [
          50396,
          307,
          264,
          1399,
          295,
          2710,
          3319,
          309,
          760,
          281,
          4641,
          502,
          50552
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 738.3000000000001,
        "id": 254,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 735.62,
        "temperature": 0,
        "text": " and then scaling it to a particular magnitude,",
        "tokens": [
          50552,
          293,
          550,
          21589,
          309,
          281,
          257,
          1729,
          15668,
          11,
          50686
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 740.42,
        "id": 255,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 738.3000000000001,
        "temperature": 0,
        "text": " in this case, arbitrarily 50.",
        "tokens": [
          50686,
          294,
          341,
          1389,
          11,
          19071,
          3289,
          2625,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 743.26,
        "id": 256,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 740.42,
        "temperature": 0,
        "text": " And the process of normalizing is calculating the magnitude",
        "tokens": [
          50792,
          400,
          264,
          1399,
          295,
          2710,
          3319,
          307,
          28258,
          264,
          15668,
          50934
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 745.34,
        "id": 257,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 743.26,
        "temperature": 0,
        "text": " and dividing by that magnitude.",
        "tokens": [
          50934,
          293,
          26764,
          538,
          300,
          15668,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 748.42,
        "id": 258,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 745.34,
        "temperature": 0,
        "text": " And we should see this is the same result.",
        "tokens": [
          51038,
          400,
          321,
          820,
          536,
          341,
          307,
          264,
          912,
          1874,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 750.0600000000001,
        "id": 259,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 748.42,
        "temperature": 0,
        "text": " Incidentally, it's worth pointing out",
        "tokens": [
          51192,
          7779,
          36578,
          11,
          309,
          311,
          3163,
          12166,
          484,
          51274
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 752.1800000000001,
        "id": 260,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 750.0600000000001,
        "temperature": 0,
        "text": " that I can actually go and confirm this",
        "tokens": [
          51274,
          300,
          286,
          393,
          767,
          352,
          293,
          9064,
          341,
          51380
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 754.42,
        "id": 261,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 752.1800000000001,
        "temperature": 0,
        "text": " by looking in the p5 source code itself.",
        "tokens": [
          51380,
          538,
          1237,
          294,
          264,
          280,
          20,
          4009,
          3089,
          2564,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 757.94,
        "id": 262,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 754.42,
        "temperature": 0,
        "text": " So this is the source code for the p5 vector object itself.",
        "tokens": [
          51492,
          407,
          341,
          307,
          264,
          4009,
          3089,
          337,
          264,
          280,
          20,
          8062,
          2657,
          2564,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.3187931090828002,
        "compression_ratio": 1.8250950570342206,
        "end": 759.7,
        "id": 263,
        "no_speech_prob": 0.0020507366862148046,
        "seek": 73186,
        "start": 757.94,
        "temperature": 0,
        "text": " And there's a normalize function, which",
        "tokens": [
          51668,
          400,
          456,
          311,
          257,
          2710,
          1125,
          2445,
          11,
          597,
          51756
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 761.7800000000001,
        "id": 264,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 759.82,
        "temperature": 0,
        "text": " And as long as the magnitude isn't 0, right,",
        "tokens": [
          50370,
          400,
          382,
          938,
          382,
          264,
          15668,
          1943,
          380,
          1958,
          11,
          558,
          11,
          50468
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 763.7800000000001,
        "id": 265,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 761.7800000000001,
        "temperature": 0,
        "text": " because you can't divide by 0, then",
        "tokens": [
          50468,
          570,
          291,
          393,
          380,
          9845,
          538,
          1958,
          11,
          550,
          50568
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 766.5400000000001,
        "id": 266,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 763.7800000000001,
        "temperature": 0,
        "text": " it multiplies by 1 divided by length, which is",
        "tokens": [
          50568,
          309,
          12788,
          530,
          538,
          502,
          6666,
          538,
          4641,
          11,
          597,
          307,
          50706
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 768.1800000000001,
        "id": 267,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 766.5400000000001,
        "temperature": 0,
        "text": " the same as dividing by length.",
        "tokens": [
          50706,
          264,
          912,
          382,
          26764,
          538,
          4641,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 770.5,
        "id": 268,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 768.1800000000001,
        "temperature": 0,
        "text": " So that is the normalize function.",
        "tokens": [
          50788,
          407,
          300,
          307,
          264,
          2710,
          1125,
          2445,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 772.7,
        "id": 269,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 770.5,
        "temperature": 0,
        "text": " I could even look at the set magnitude function",
        "tokens": [
          50904,
          286,
          727,
          754,
          574,
          412,
          264,
          992,
          15668,
          2445,
          51014
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 774.94,
        "id": 270,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 772.7,
        "temperature": 0,
        "text": " and see that it's, oh, normalize the vector",
        "tokens": [
          51014,
          293,
          536,
          300,
          309,
          311,
          11,
          1954,
          11,
          2710,
          1125,
          264,
          8062,
          51126
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 777.62,
        "id": 271,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 774.94,
        "temperature": 0,
        "text": " and then multiply it by some quantity n.",
        "tokens": [
          51126,
          293,
          550,
          12972,
          309,
          538,
          512,
          11275,
          297,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 779.5,
        "id": 272,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 777.62,
        "temperature": 0,
        "text": " And in fact, you can see here that something",
        "tokens": [
          51260,
          400,
          294,
          1186,
          11,
          291,
          393,
          536,
          510,
          300,
          746,
          51354
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 781.98,
        "id": 273,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 779.5,
        "temperature": 0,
        "text": " that I'm not doing is chaining.",
        "tokens": [
          51354,
          300,
          286,
          478,
          406,
          884,
          307,
          417,
          3686,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 784.22,
        "id": 274,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 781.98,
        "temperature": 0,
        "text": " So a lot of these math operations on vectors",
        "tokens": [
          51478,
          407,
          257,
          688,
          295,
          613,
          5221,
          7705,
          322,
          18875,
          51590
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 786.6600000000001,
        "id": 275,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 784.22,
        "temperature": 0,
        "text": " can be chained to a set of numbers.",
        "tokens": [
          51590,
          393,
          312,
          417,
          3563,
          281,
          257,
          992,
          295,
          3547,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.4727521769205729,
        "compression_ratio": 1.7874564459930313,
        "end": 787.82,
        "id": 276,
        "no_speech_prob": 0.015906138345599174,
        "seek": 75970,
        "start": 786.6600000000001,
        "temperature": 0,
        "text": " And I can actually do that.",
        "tokens": [
          51712,
          400,
          286,
          393,
          767,
          360,
          300,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 789.86,
        "id": 277,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 787.9000000000001,
        "temperature": 0,
        "text": " So a lot of these operations on vectors can be chained,",
        "tokens": [
          50368,
          407,
          257,
          688,
          295,
          613,
          7705,
          322,
          18875,
          393,
          312,
          417,
          3563,
          11,
          50466
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 792.58,
        "id": 278,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 789.86,
        "temperature": 0,
        "text": " meaning I can say normalize multiply.",
        "tokens": [
          50466,
          3620,
          286,
          393,
          584,
          2710,
          1125,
          12972,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 796.0200000000001,
        "id": 279,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 792.58,
        "temperature": 0,
        "text": " And by that, I mean these two operations, v.normalize,",
        "tokens": [
          50602,
          400,
          538,
          300,
          11,
          286,
          914,
          613,
          732,
          7705,
          11,
          371,
          13,
          23157,
          1125,
          11,
          50774
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 802.1800000000001,
        "id": 280,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 796.0200000000001,
        "temperature": 0,
        "text": " v.multiply, could be written as v.normalize.multiply 50.",
        "tokens": [
          50774,
          371,
          13,
          76,
          723,
          647,
          356,
          11,
          727,
          312,
          3720,
          382,
          371,
          13,
          23157,
          1125,
          13,
          76,
          723,
          647,
          356,
          2625,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 805.86,
        "id": 281,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 802.1800000000001,
        "temperature": 0,
        "text": " So once again, we now see there are so many different ways",
        "tokens": [
          51082,
          407,
          1564,
          797,
          11,
          321,
          586,
          536,
          456,
          366,
          370,
          867,
          819,
          2098,
          51266
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 807.5,
        "id": 282,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 805.86,
        "temperature": 0,
        "text": " to do the same exact thing.",
        "tokens": [
          51266,
          281,
          360,
          264,
          912,
          1900,
          551,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 809.46,
        "id": 283,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 807.5,
        "temperature": 0,
        "text": " But hopefully, this is giving you",
        "tokens": [
          51348,
          583,
          4696,
          11,
          341,
          307,
          2902,
          291,
          51446
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 813.6600000000001,
        "id": 284,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 809.46,
        "temperature": 0,
        "text": " a better picture of what vector math operations do,",
        "tokens": [
          51446,
          257,
          1101,
          3036,
          295,
          437,
          8062,
          5221,
          7705,
          360,
          11,
          51656
        ]
      },
      {
        "avg_logprob": -0.2249483754557948,
        "compression_ratio": 1.6653386454183268,
        "end": 815.94,
        "id": 285,
        "no_speech_prob": 0.012053619138896465,
        "seek": 78782,
        "start": 813.6600000000001,
        "temperature": 0,
        "text": " how they work, and how you might choose",
        "tokens": [
          51656,
          577,
          436,
          589,
          11,
          293,
          577,
          291,
          1062,
          2826,
          51770
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 819.6600000000001,
        "id": 286,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 815.98,
        "temperature": 0,
        "text": " between static functions versus instance functions,",
        "tokens": [
          50366,
          1296,
          13437,
          6828,
          5717,
          5197,
          6828,
          11,
          50550
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 821.98,
        "id": 287,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 819.6600000000001,
        "temperature": 0,
        "text": " and how you might manipulate vectors by using",
        "tokens": [
          50550,
          293,
          577,
          291,
          1062,
          20459,
          18875,
          538,
          1228,
          50666
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 823.9000000000001,
        "id": 288,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 821.98,
        "temperature": 0,
        "text": " these mathematical operations.",
        "tokens": [
          50666,
          613,
          18894,
          7705,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 826.62,
        "id": 289,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 823.9000000000001,
        "temperature": 0,
        "text": " So I think this truly is the penultimate video",
        "tokens": [
          50762,
          407,
          286,
          519,
          341,
          4908,
          307,
          264,
          3435,
          723,
          2905,
          960,
          50898
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 829.58,
        "id": 290,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 826.62,
        "temperature": 0,
        "text": " in the chapter on vectors, because we're now",
        "tokens": [
          50898,
          294,
          264,
          7187,
          322,
          18875,
          11,
          570,
          321,
          434,
          586,
          51046
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 833.22,
        "id": 291,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 829.58,
        "temperature": 0,
        "text": " ready to take this idea of calculating a vector that",
        "tokens": [
          51046,
          1919,
          281,
          747,
          341,
          1558,
          295,
          28258,
          257,
          8062,
          300,
          51228
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 838.62,
        "id": 292,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 833.22,
        "temperature": 0,
        "text": " points to the mouse and apply it as an acceleration to an object",
        "tokens": [
          51228,
          2793,
          281,
          264,
          9719,
          293,
          3079,
          309,
          382,
          364,
          17162,
          281,
          364,
          2657,
          51498
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 841.22,
        "id": 293,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 838.62,
        "temperature": 0,
        "text": " and see what happens.",
        "tokens": [
          51498,
          293,
          536,
          437,
          2314,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 843.1,
        "id": 294,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 841.22,
        "temperature": 0,
        "text": " So that's coming in the next video.",
        "tokens": [
          51628,
          407,
          300,
          311,
          1348,
          294,
          264,
          958,
          960,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.25232629868590717,
        "compression_ratio": 1.691358024691358,
        "end": 844.5,
        "id": 295,
        "no_speech_prob": 0.00001568954212416429,
        "seek": 81594,
        "start": 843.1,
        "temperature": 0,
        "text": " See you there.",
        "tokens": [
          51722,
          3008,
          291,
          456,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 846.34,
        "id": 296,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 845.26,
        "temperature": 1,
        "text": " BEEP",
        "tokens": [
          50402,
          363,
          32810,
          50456
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 847.14,
        "id": 297,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 846.34,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50456,
          879,
          595,
          50496
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 847.94,
        "id": 298,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 847.14,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50496,
          879,
          595,
          50536
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 848.66,
        "id": 299,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 847.94,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50536,
          879,
          595,
          50572
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 849.46,
        "id": 300,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 848.66,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50572,
          879,
          595,
          50612
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 850.3,
        "id": 301,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 849.46,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50612,
          879,
          595,
          50654
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 851.26,
        "id": 302,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 850.3,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50654,
          879,
          595,
          50702
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 852.18,
        "id": 303,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 851.26,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50702,
          879,
          595,
          50748
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 853.02,
        "id": 304,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 852.18,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50748,
          879,
          595,
          50790
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 857.02,
        "id": 305,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 856.06,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          50942,
          879,
          595,
          50990
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 861.34,
        "id": 306,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 860.46,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          51162,
          879,
          595,
          51206
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 870.5,
        "id": 307,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 869.66,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          51622,
          879,
          595,
          51664
        ]
      },
      {
        "avg_logprob": -1.588963490612102,
        "compression_ratio": 3.3684210526315788,
        "end": 873.94,
        "id": 308,
        "no_speech_prob": 0.4520963430404663,
        "seek": 84450,
        "start": 873.18,
        "temperature": 1,
        "text": " Beep",
        "tokens": [
          51798,
          879,
          595,
          51836
        ]
      }
    ],
    "transcription": " Hello. Welcome to another video in Nature of Code, Chapter 1 Vectors series. I really thought that in this video, I was going to start making this example. I almost have arrived there, where this mover object is accelerating towards the mouse. But there's a particular math function that I'm going to need for this example that I want to cover in a separate video. And that's the normalize function. I want to look at how I deal with and calculate the magnitude of a vector, how I normalize a vector, what does that even mean. And the way that I'm going to do this is look at creating a vector between the mouse and the center of the canvas itself. The scenario I want to look at is as follows. I have a canvas. And I have some mover on the canvas, a particle somewhere. Let's just position it in the center. Let's say this is 600 by 400. It's not exactly drawn to scale, but close enough. So this is 300 comma 200. Then I have the mouse. I'm moving my mouse around somewhere. And let's say I have the mouse over here. I'm going to try to draw a mouse arrow. And we'll call this location 580 comma 20. What I'm looking to do is figure out how do I calculate, if I know this position and this position, a vector that points from one to the other. If I want this particular particle to accelerate towards the mouse, how do I calculate this particular vector? Call it v. Well, when I say calculate the vector, what I'm really looking for is the x component and the y component. So v dot x equals what? 580 minus 300. So 580 minus 300, that's 280. v dot y equals 200 minus 20. This length is 180. So this vector is 280 comma 180. What mathematical operation did I just do here? I have two vectors, really. I have this vector, which I'll call position. And I have this vector, which I'll call mouse. What I did is I said mouse minus position gives me v. v equals mouse minus position. Let's confirm that this really works, the subtract operation by diagramming this. So if I take this mouse vector that's pointing from 0 to this location 580 comma 200, and I kind of draw that down here, it's not exactly right, but I just sort of duplicate this here. If I were to add, if I were to say plus position, I would put these vectors end to end. So I would take this vector and put it like over here. I'm about to go out of your range of view, so I'll just draw it a little bit shorter. But this is the idea. Mouse plus position would give me this vector, mouse plus position. But I want to say mouse minus position, so that's taking this position vector and pointing it in the opposite direction. This is minus position. So mouse minus position is this vector v right here, and you can see that matches up with that. So this example is drawing random vectors that emanate from the center. Let's try that math operation. So I'm going to actually get rid of all this, and I'm going to say position equals create vector, the center 200, 200, mouse equals create vector, mouse x, mouse y. And then v is, and to do this subtraction, mouse minus position and store it in a new vector, I need a static function. That's what the previous video was about. So I can say p5.vector.subtract mouse minus position. And actually, let me put the translate back, because I want to draw everything relative to the center. Oh, look at that. I still have the funny background thing, which I'll keep. So no matter where I move the mouse, I now have a vector that points from the center to where the mouse is. Now, certainly, this visualization could have been created just by calling the line function and saying line 200, 200, mouse x, mouse y. But the reason why I'm doing it this way through vector subtraction is to show you about the normalize function and what kind of power that unlocks. Let's say that I have a collection of vectors. I'm going to draw five of them. All random directions, all varying lengths. Those are my five vectors. The process of normalization, which is executed with the normalize function in p5.js, is to take any vector of any length in any direction and make it into a unit vector. A unit vector is one where the magnitude, the length, is 1. So let's just establish that this is approximately length 1 in terms of this arbitrary two-dimensional space I'm working with. So this vector normalized would be this vector. This vector normalized would be this vector. This vector, oh, it's less than 1. So normalizing it would actually be to grow it, would be this vector. This vector would be this vector. And this vector would be this vector. Now, of course, I haven't drawn these exactly right, but this is the idea. All of these are normalized versions of these. And you can think of the term normalize as making all these vectors into a normal vector. Normal being, well, a normal vector is length 1. Otherwise, it's some wacky, crazy, insane vector with a much longer length. It's basically having a standard. By the way, in vector notation, a vector is typically written like vector v with an arrow on top. The unit vector is often written as vector v with the hat or caret on top. So this would be a unit vector v or any given vector v. So if I come back to this example here, one of the things we could look at is I could say v.normalize. What does that do? Hmm. Well, it makes the vector length 1. So I can just keep zooming into this. I'm drawing something of pixel length 1. So how does the math for normalize work? Luckily for us, we could just call normalize in p5. But this is a moment for us to take a little time to look at the math for that. Well, before we can look at the math for normalize, we actually should look for the math at another function called mag. And mag is a function that returns the magnitude of a vector. So it returns the scalar length of any given vector, that magnitude itself. So one thing that I could do here that could demonstrate this is let me take the background and draw it in draw. Run this again. Oh, and I guess I will make this much brighter. So now I've just got this line pointing to the mouse. And I'm going to ask for the magnitude. So that is now getting the magnitude of that. And actually, let's just console log it. So you can see this console log down here is giving me the magnitude of the vector itself as I move the mouse closer to the center. And you can see it's always a positive number because it's the length of it, no matter what direction it's pointing in. I could try something interesting. Like I could say, oh, let's make the background color associated with the magnitude. So now you can see the closer the mouse gets to the center, the brighter the background is. Sort of an interesting interaction that you could play with. And the reason why this magnitude value is so important is it plays a fundamental role in how a vector is normalized. Let's say I take this vector. And this is the magnitude m. And this is the x component and the y component. Well, another way I could draw this diagram is like this, a right triangle with a, b, and c. And if you've ever seen this kind of diagram in a geometry context, you might have seen it paired with something called the Pythagorean theorem. The Pythagorean theorem states that a squared plus b squared equals c squared, or c equals the square root of a squared plus b squared. And in fact, that is exactly how the magnitude is calculated. So when magnitude, the mag function is called on a vector, v.mag, it takes the square root of the x component squared plus the y component squared. And that gives you that magnitude. Now that I understand how magnitude is calculated, I'm ready to look at how normalization works. Let's use the 3, 4, 5 triangle as our starting point. So let's say I have a vector. Its components are 4 and 3. We know that the magnitude now equals the square root of 4 squared plus 3 squared, which is 16 plus 9, which is 25, the square root of which is 5. So the magnitude is 5. You can see how this math for calculating the magnitude now works out. If I wanted to normalize this vector, that means I want to shrink this length, which is 5, down to 1. So it turns out if I'm taking a vector and normalizing its length down to 1 or up to 1, 5 divided by 5 is 1. I can actually just take the components, the x and y components, and divide by the magnitude. So this length right here is actually 3 fifths. And this length right here is actually 4 fifths. And that's how you normalize a vector, by dividing it by its magnitude. So removing this background little digression, I can now actually normalize v by saying v.div, D-I-V for divide a vector by its magnitude. So if I do that, oh, wait a second. Well, there it is. You can see no matter where I put the mouse, I have this nice vector of length 1. But maybe what I should do is then scale it up by something like 50, multiplying it. And look at this. So now I have this multi-step process to make a vector that points at a given direction with a fixed length. I have some vector that I've calculated. Call it v. And the first thing I do is I call v.mag, which gives me the magnitude. Maybe it's 100. So the length is 100. Then what I want to do is normalize the vector. I want the vector to be that same vector, but of length 1. So I can say v.div by that magnitude, or 100. That takes this vector and shrinks it down to here. Then I want to scale it up by some amount like 50. And that will then scale it back up to a higher length of 50. So this is my multi-step process. But this is with all of this math. And in fact, instead of calculating the magnitude and dividing by the magnitude, I can just instead call, it's such a common operation, I could just instead call v.normalize. So v.normalize is the act of taking any vector and shrinking it to length 1. I did a terrible job of drawing these in the same direction. But hopefully you get the idea. So now I can simplify this by commenting these out and just changing this to v.normalize. And we've got the same exact result. But guess what? v.normalize, v.multiply times 50 is also such a common operation. Like I want this vector in this direction, but I just want it to be this magnitude. That in fact, I can even take these and just call v.setmag50. So this function v.set the magnitude of the vector is the process of normalizing it down to length 1 and then scaling it to a particular magnitude, in this case, arbitrarily 50. And the process of normalizing is calculating the magnitude and dividing by that magnitude. And we should see this is the same result. Incidentally, it's worth pointing out that I can actually go and confirm this by looking in the p5 source code itself. So this is the source code for the p5 vector object itself. And there's a normalize function, which And as long as the magnitude isn't 0, right, because you can't divide by 0, then it multiplies by 1 divided by length, which is the same as dividing by length. So that is the normalize function. I could even look at the set magnitude function and see that it's, oh, normalize the vector and then multiply it by some quantity n. And in fact, you can see here that something that I'm not doing is chaining. So a lot of these math operations on vectors can be chained to a set of numbers. And I can actually do that. So a lot of these operations on vectors can be chained, meaning I can say normalize multiply. And by that, I mean these two operations, v.normalize, v.multiply, could be written as v.normalize.multiply 50. So once again, we now see there are so many different ways to do the same exact thing. But hopefully, this is giving you a better picture of what vector math operations do, how they work, and how you might choose between static functions versus instance functions, and how you might manipulate vectors by using these mathematical operations. So I think this truly is the penultimate video in the chapter on vectors, because we're now ready to take this idea of calculating a vector that points to the mouse and apply it as an acceleration to an object and see what happens. So that's coming in the next video. See you there. BEEP Beep Beep Beep Beep Beep Beep Beep Beep Beep Beep Beep Beep",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:25.617166Z",
  "started_at": "2023-09-26T21:08:27.023041Z",
  "completed_at": "2023-09-26T21:12:23.803516Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=ttz05d8DSOs",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 236.780475
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/3bvdq2bbh4sz2nf5f25akhv3ri/cancel",
    "get": "https://api.replicate.com/v1/predictions/3bvdq2bbh4sz2nf5f25akhv3ri"
  }
}