{
  "id": "fyuxudzbm6giyadjqrn7yqomzu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/Xrhrn8HaFPI.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/103663 [00:00<?, ?frames/s]\n  3%|▎         | 2892/103663 [00:07<04:25, 379.47frames/s]\n  6%|▌         | 5812/103663 [00:17<04:56, 330.14frames/s]\n  8%|▊         | 8640/103663 [00:26<04:51, 326.43frames/s]\n 11%|█         | 11500/103663 [00:33<04:31, 338.92frames/s]\n 13%|█▎        | 13880/103663 [00:40<04:16, 349.52frames/s]\n 16%|█▌        | 16800/103663 [00:47<03:51, 374.88frames/s]\n 19%|█▉        | 19708/103663 [00:54<03:38, 384.03frames/s]\n 22%|██▏       | 22616/103663 [01:03<03:45, 358.95frames/s]\n 25%|██▍       | 25404/103663 [01:11<03:38, 357.62frames/s]\n 27%|██▋       | 28352/103663 [01:20<03:39, 343.23frames/s]\n 30%|██▉       | 31080/103663 [01:30<03:46, 320.14frames/s]\n 33%|███▎      | 34072/103663 [01:40<03:43, 311.62frames/s]\n 36%|███▌      | 37000/103663 [01:48<03:25, 323.88frames/s]\n 38%|███▊      | 39884/103663 [01:58<03:22, 314.82frames/s]\n 41%|████      | 42708/103663 [02:06<03:05, 328.55frames/s]\n 44%|████▍     | 45628/103663 [02:14<02:52, 336.20frames/s]\n 47%|████▋     | 48312/103663 [02:21<02:37, 352.40frames/s]\n 49%|████▉     | 51020/103663 [02:26<02:16, 386.28frames/s]\n 52%|█████▏    | 53956/103663 [02:34<02:07, 388.68frames/s]\n 55%|█████▍    | 56680/103663 [02:42<02:06, 370.40frames/s]\n 58%|█████▊    | 59680/103663 [02:50<02:00, 366.26frames/s]\n 60%|██████    | 62324/103663 [02:56<01:45, 391.19frames/s]\n 63%|██████▎   | 65320/103663 [03:02<01:31, 419.64frames/s]\n 65%|██████▌   | 67856/103663 [03:08<01:26, 414.53frames/s]\n 68%|██████▊   | 70116/103663 [03:13<01:18, 427.87frames/s]\n 70%|███████   | 72956/103663 [03:18<01:06, 459.49frames/s]\n 73%|███████▎  | 75748/103663 [03:23<00:57, 488.54frames/s]\n 76%|███████▌  | 78608/103663 [03:32<00:58, 424.94frames/s]\n 78%|███████▊  | 81312/103663 [03:35<00:45, 487.18frames/s]\n 81%|████████  | 83756/103663 [03:39<00:38, 514.88frames/s]\n 84%|████████▎ | 86688/103663 [03:47<00:35, 476.85frames/s]\n 86%|████████▋ | 89664/103663 [03:54<00:31, 451.14frames/s]\n 89%|████████▉ | 92376/103663 [03:59<00:24, 461.27frames/s]\n 92%|█████████▏| 95124/103663 [04:05<00:18, 461.99frames/s]\n 94%|█████████▍| 97948/103663 [04:12<00:12, 459.19frames/s]\n 97%|█████████▋| 100904/103663 [04:21<00:06, 402.42frames/s]\n 99%|█████████▉| 102684/103663 [04:28<00:02, 355.09frames/s]\n100%|██████████| 103663/103663 [04:29<00:00, 396.10frames/s]\n100%|██████████| 103663/103663 [04:29<00:00, 384.74frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 0.96,
        "id": 0,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50364,
          2425,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 7.640000000000001,
        "id": 1,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 0.96,
        "temperature": 0,
        "text": " Welcome to the third video in my build a classifier with p5.js",
        "tokens": [
          50412,
          4027,
          281,
          264,
          2636,
          960,
          294,
          452,
          1322,
          257,
          1508,
          9902,
          365,
          280,
          20,
          13,
          25530,
          50746
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 8.64,
        "id": 2,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 7.640000000000001,
        "temperature": 0,
        "text": " and TensorFlow.js.",
        "tokens": [
          50746,
          293,
          37624,
          13,
          25530,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 10.24,
        "id": 3,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 8.64,
        "temperature": 0,
        "text": " And there's a neural network in there.",
        "tokens": [
          50796,
          400,
          456,
          311,
          257,
          18161,
          3209,
          294,
          456,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 12.44,
        "id": 4,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 10.24,
        "temperature": 0,
        "text": " So I'm really exploring this machine learning library",
        "tokens": [
          50876,
          407,
          286,
          478,
          534,
          12736,
          341,
          3479,
          2539,
          6405,
          50986
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 13.280000000000001,
        "id": 5,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 12.44,
        "temperature": 0,
        "text": " TensorFlow.js.",
        "tokens": [
          50986,
          37624,
          13,
          25530,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 16.92,
        "id": 6,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 13.280000000000001,
        "temperature": 0,
        "text": " And I wanted to come up with a creative example that",
        "tokens": [
          51028,
          400,
          286,
          1415,
          281,
          808,
          493,
          365,
          257,
          5880,
          1365,
          300,
          51210
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 20.6,
        "id": 7,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 16.92,
        "temperature": 0,
        "text": " shows the full classification process from collecting data,",
        "tokens": [
          51210,
          3110,
          264,
          1577,
          21538,
          1399,
          490,
          12510,
          1412,
          11,
          51394
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 23.64,
        "id": 8,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 20.6,
        "temperature": 0,
        "text": " training, and then deploying a machine learning model.",
        "tokens": [
          51394,
          3097,
          11,
          293,
          550,
          34198,
          257,
          3479,
          2539,
          2316,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 27.04,
        "id": 9,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 23.64,
        "temperature": 0,
        "text": " And so the example that I'm working with",
        "tokens": [
          51546,
          400,
          370,
          264,
          1365,
          300,
          286,
          478,
          1364,
          365,
          51716
        ]
      },
      {
        "avg_logprob": -0.2625501715618631,
        "compression_ratio": 1.73046875,
        "end": 28.92,
        "id": 10,
        "no_speech_prob": 0.014499054290354252,
        "seek": 0,
        "start": 27.04,
        "temperature": 0,
        "text": " is this idea of color classification.",
        "tokens": [
          51716,
          307,
          341,
          1558,
          295,
          2017,
          21538,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 32.760000000000005,
        "id": 11,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 28.92,
        "temperature": 0,
        "text": " So I'm crowdsourcing this data from you, the viewing audience.",
        "tokens": [
          50364,
          407,
          286,
          478,
          26070,
          41849,
          341,
          1412,
          490,
          291,
          11,
          264,
          17480,
          4034,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 35.120000000000005,
        "id": 12,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 32.760000000000005,
        "temperature": 0,
        "text": " And if I look at this, so you might remember,",
        "tokens": [
          50556,
          400,
          498,
          286,
          574,
          412,
          341,
          11,
          370,
          291,
          1062,
          1604,
          11,
          50674
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 39.72,
        "id": 13,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 35.120000000000005,
        "temperature": 0,
        "text": " I built this little web app in the previous video, I think.",
        "tokens": [
          50674,
          286,
          3094,
          341,
          707,
          3670,
          724,
          294,
          264,
          3894,
          960,
          11,
          286,
          519,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 40.72,
        "id": 14,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 39.72,
        "temperature": 0,
        "text": " That was yesterday.",
        "tokens": [
          50904,
          663,
          390,
          5186,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 43,
        "id": 15,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 40.72,
        "temperature": 0,
        "text": " And then now it's today, 24 hours later.",
        "tokens": [
          50954,
          400,
          550,
          586,
          309,
          311,
          965,
          11,
          4022,
          2496,
          1780,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 44.120000000000005,
        "id": 16,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 43,
        "temperature": 0,
        "text": " It's been improved.",
        "tokens": [
          51068,
          467,
          311,
          668,
          9689,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 46.480000000000004,
        "id": 17,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 44.120000000000005,
        "temperature": 0,
        "text": " Thank you to the internet, the wonderful people",
        "tokens": [
          51124,
          1044,
          291,
          281,
          264,
          4705,
          11,
          264,
          3715,
          561,
          51242
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 49.36,
        "id": 18,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 46.480000000000004,
        "temperature": 0,
        "text": " who have pull requested various design fixes and updates.",
        "tokens": [
          51242,
          567,
          362,
          2235,
          16436,
          3683,
          1715,
          32539,
          293,
          9205,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 51.120000000000005,
        "id": 19,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 49.36,
        "temperature": 0,
        "text": " You can check all that out on GitHub",
        "tokens": [
          51386,
          509,
          393,
          1520,
          439,
          300,
          484,
          322,
          23331,
          51474
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 52.52,
        "id": 20,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 51.120000000000005,
        "temperature": 0,
        "text": " to see who the contributors were.",
        "tokens": [
          51474,
          281,
          536,
          567,
          264,
          45627,
          645,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 55.72,
        "id": 21,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 52.52,
        "temperature": 0,
        "text": " Now, let me add a few things here.",
        "tokens": [
          51544,
          823,
          11,
          718,
          385,
          909,
          257,
          1326,
          721,
          510,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.22977509705916696,
        "compression_ratio": 1.5806451612903225,
        "end": 58.120000000000005,
        "id": 22,
        "no_speech_prob": 0.00008219078154070303,
        "seek": 2892,
        "start": 55.72,
        "temperature": 0,
        "text": " Brown, that's kind of brown.",
        "tokens": [
          51704,
          8030,
          11,
          300,
          311,
          733,
          295,
          6292,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 60.16,
        "id": 23,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 58.12,
        "temperature": 0,
        "text": " That's purplish.",
        "tokens": [
          50364,
          663,
          311,
          1864,
          564,
          742,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 60.8,
        "id": 24,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 60.16,
        "temperature": 0,
        "text": " That's bluish.",
        "tokens": [
          50466,
          663,
          311,
          888,
          33786,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 63.44,
        "id": 25,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 60.8,
        "temperature": 0,
        "text": " Now, one thing I will mention, thank you",
        "tokens": [
          50498,
          823,
          11,
          472,
          551,
          286,
          486,
          2152,
          11,
          1309,
          291,
          50630
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 68.6,
        "id": 26,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 63.44,
        "temperature": 0,
        "text": " to Bruno, who brought this up in the patron Slack channel.",
        "tokens": [
          50630,
          281,
          23046,
          11,
          567,
          3038,
          341,
          493,
          294,
          264,
          21843,
          37211,
          2269,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 71.72,
        "id": 27,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 68.6,
        "temperature": 0,
        "text": " I sort of said yesterday, I just want to pick a trivial data set.",
        "tokens": [
          50888,
          286,
          1333,
          295,
          848,
          5186,
          11,
          286,
          445,
          528,
          281,
          1888,
          257,
          26703,
          1412,
          992,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 74.92,
        "id": 28,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 71.72,
        "temperature": 0,
        "text": " I want to make something that has very little sort",
        "tokens": [
          51044,
          286,
          528,
          281,
          652,
          746,
          300,
          575,
          588,
          707,
          1333,
          51204
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 78.12,
        "id": 29,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 74.92,
        "temperature": 0,
        "text": " of meaningfulness to it, just to sort of demonstrate",
        "tokens": [
          51204,
          295,
          10995,
          1287,
          281,
          309,
          11,
          445,
          281,
          1333,
          295,
          11698,
          51364
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 79.24,
        "id": 30,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 78.12,
        "temperature": 0,
        "text": " the whole process.",
        "tokens": [
          51364,
          264,
          1379,
          1399,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 82.6,
        "id": 31,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 79.24,
        "temperature": 0,
        "text": " But there is something kind of interesting going on here",
        "tokens": [
          51420,
          583,
          456,
          307,
          746,
          733,
          295,
          1880,
          516,
          322,
          510,
          51588
        ]
      },
      {
        "avg_logprob": -0.26494606335957843,
        "compression_ratio": 1.6428571428571428,
        "end": 86.4,
        "id": 32,
        "no_speech_prob": 0.0000961004407145083,
        "seek": 5812,
        "start": 82.6,
        "temperature": 0,
        "text": " in theory, which is that we're looking at human perception.",
        "tokens": [
          51588,
          294,
          5261,
          11,
          597,
          307,
          300,
          321,
          434,
          1237,
          412,
          1952,
          12860,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 92.16000000000001,
        "id": 33,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 86.4,
        "temperature": 0,
        "text": " And I'm not mathematically labeling a color",
        "tokens": [
          50364,
          400,
          286,
          478,
          406,
          44003,
          40244,
          257,
          2017,
          50652
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 93.84,
        "id": 34,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 92.16000000000001,
        "temperature": 0,
        "text": " according to the RGB values.",
        "tokens": [
          50652,
          4650,
          281,
          264,
          31231,
          4190,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 95.84,
        "id": 35,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 93.84,
        "temperature": 0,
        "text": " I'm asking you, the viewers, to tell me",
        "tokens": [
          50736,
          286,
          478,
          3365,
          291,
          11,
          264,
          8499,
          11,
          281,
          980,
          385,
          50836
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 96.96000000000001,
        "id": 36,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 95.84,
        "temperature": 0,
        "text": " what you think a color is.",
        "tokens": [
          50836,
          437,
          291,
          519,
          257,
          2017,
          307,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 99.80000000000001,
        "id": 37,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 96.96000000000001,
        "temperature": 0,
        "text": " And so there is a lot of interesting scientific research",
        "tokens": [
          50892,
          400,
          370,
          456,
          307,
          257,
          688,
          295,
          1880,
          8134,
          2132,
          51034
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 100.36000000000001,
        "id": 38,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 99.80000000000001,
        "temperature": 0,
        "text": " in this area.",
        "tokens": [
          51034,
          294,
          341,
          1859,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 103.4,
        "id": 39,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 100.36000000000001,
        "temperature": 0,
        "text": " And I'll reference this video that",
        "tokens": [
          51062,
          400,
          286,
          603,
          6408,
          341,
          960,
          300,
          51214
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 107.12,
        "id": 40,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 103.4,
        "temperature": 0,
        "text": " talks about Berkeley researchers and other research",
        "tokens": [
          51214,
          6686,
          466,
          23684,
          10309,
          293,
          661,
          2132,
          51400
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 108.92,
        "id": 41,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 107.12,
        "temperature": 0,
        "text": " around the surprising pattern behind color",
        "tokens": [
          51400,
          926,
          264,
          8830,
          5102,
          2261,
          2017,
          51490
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 109.88000000000001,
        "id": 42,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 108.92,
        "temperature": 0,
        "text": " names around the world.",
        "tokens": [
          51490,
          5288,
          926,
          264,
          1002,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 112.04,
        "id": 43,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 109.88000000000001,
        "temperature": 0,
        "text": " So there's a lot there that you could dig into.",
        "tokens": [
          51538,
          407,
          456,
          311,
          257,
          688,
          456,
          300,
          291,
          727,
          2528,
          666,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.23376208393513656,
        "compression_ratio": 1.753787878787879,
        "end": 115,
        "id": 44,
        "no_speech_prob": 0.00007254130468936637,
        "seek": 8640,
        "start": 112.04,
        "temperature": 0,
        "text": " So maybe there's more here than I might originally",
        "tokens": [
          51646,
          407,
          1310,
          456,
          311,
          544,
          510,
          813,
          286,
          1062,
          7993,
          51794
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 116.64,
        "id": 45,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 115.04,
        "temperature": 0,
        "text": " have thought.",
        "tokens": [
          50366,
          362,
          1194,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 120.32,
        "id": 46,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 116.64,
        "temperature": 0,
        "text": " The problem with what I built over here",
        "tokens": [
          50446,
          440,
          1154,
          365,
          437,
          286,
          3094,
          670,
          510,
          50630
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 123.16,
        "id": 47,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 120.32,
        "temperature": 0,
        "text": " is that you're wonderful.",
        "tokens": [
          50630,
          307,
          300,
          291,
          434,
          3715,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 125.24,
        "id": 48,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 123.16,
        "temperature": 0,
        "text": " I love all of you who watch these videos",
        "tokens": [
          50772,
          286,
          959,
          439,
          295,
          291,
          567,
          1159,
          613,
          2145,
          50876
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 127.52,
        "id": 49,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 125.24,
        "temperature": 0,
        "text": " and leave me nice feedback, leave me critical feedback,",
        "tokens": [
          50876,
          293,
          1856,
          385,
          1481,
          5824,
          11,
          1856,
          385,
          4924,
          5824,
          11,
          50990
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 128.72,
        "id": 50,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 127.52,
        "temperature": 0,
        "text": " and all that sort of stuff.",
        "tokens": [
          50990,
          293,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 131.84,
        "id": 51,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 128.72,
        "temperature": 0,
        "text": " But the database is a little bit off the rails,",
        "tokens": [
          51050,
          583,
          264,
          8149,
          307,
          257,
          707,
          857,
          766,
          264,
          27649,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 134.56,
        "id": 52,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 131.84,
        "temperature": 0,
        "text": " because I just left the rules wide open.",
        "tokens": [
          51206,
          570,
          286,
          445,
          1411,
          264,
          4474,
          4874,
          1269,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.2514016032218933,
        "compression_ratio": 1.627906976744186,
        "end": 138.8,
        "id": 53,
        "no_speech_prob": 0.00015355889627244323,
        "seek": 11500,
        "start": 134.56,
        "temperature": 0,
        "text": " Anybody can write, and anybody can read to the database.",
        "tokens": [
          51342,
          19082,
          393,
          2464,
          11,
          293,
          4472,
          393,
          1401,
          281,
          264,
          8149,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 148.32000000000002,
        "id": 54,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 138.8,
        "temperature": 0,
        "text": " And so thankfully, Panzer on GitHub",
        "tokens": [
          50364,
          400,
          370,
          27352,
          11,
          45932,
          260,
          322,
          23331,
          50840
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 150.76000000000002,
        "id": 55,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 148.32000000000002,
        "temperature": 0,
        "text": " left a pull request analyzing the data",
        "tokens": [
          50840,
          1411,
          257,
          2235,
          5308,
          23663,
          264,
          1412,
          50962
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 152.88000000000002,
        "id": 56,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 150.76000000000002,
        "temperature": 0,
        "text": " and looking at, OK, well, there's",
        "tokens": [
          50962,
          293,
          1237,
          412,
          11,
          2264,
          11,
          731,
          11,
          456,
          311,
          51068
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 154.44,
        "id": 57,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 152.88000000000002,
        "temperature": 0,
        "text": " a lot of stuff here that looks wrong.",
        "tokens": [
          51068,
          257,
          688,
          295,
          1507,
          510,
          300,
          1542,
          2085,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 158.28,
        "id": 58,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 154.44,
        "temperature": 0,
        "text": " Maybe there were some bots that started classifying colors.",
        "tokens": [
          51146,
          2704,
          456,
          645,
          512,
          35410,
          300,
          1409,
          1508,
          5489,
          4577,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 160.36,
        "id": 59,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 158.28,
        "temperature": 0,
        "text": " And so I wrote all these functions",
        "tokens": [
          51338,
          400,
          370,
          286,
          4114,
          439,
          613,
          6828,
          51442
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 161.92000000000002,
        "id": 60,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 160.36,
        "temperature": 0,
        "text": " to analyze and filter the data.",
        "tokens": [
          51442,
          281,
          12477,
          293,
          6608,
          264,
          1412,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 165.92000000000002,
        "id": 61,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 161.92000000000002,
        "temperature": 0,
        "text": " So I encourage you to check out this wonderful pull request.",
        "tokens": [
          51520,
          407,
          286,
          5373,
          291,
          281,
          1520,
          484,
          341,
          3715,
          2235,
          5308,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.2467657221425878,
        "compression_ratio": 1.5958333333333334,
        "end": 168,
        "id": 62,
        "no_speech_prob": 0.0008693472482264042,
        "seek": 13880,
        "start": 165.92000000000002,
        "temperature": 0,
        "text": " This pull request is now part of the repository.",
        "tokens": [
          51720,
          639,
          2235,
          5308,
          307,
          586,
          644,
          295,
          264,
          25841,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 172.72,
        "id": 63,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 168,
        "temperature": 0,
        "text": " However, I took a slightly different approach,",
        "tokens": [
          50364,
          2908,
          11,
          286,
          1890,
          257,
          4748,
          819,
          3109,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 176.04,
        "id": 64,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 172.72,
        "temperature": 0,
        "text": " and thanks to meiamsome, who helped me with this,",
        "tokens": [
          50600,
          293,
          3231,
          281,
          385,
          2918,
          82,
          423,
          11,
          567,
          4254,
          385,
          365,
          341,
          11,
          50766
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 179.22,
        "id": 65,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 176.04,
        "temperature": 0,
        "text": " which is that I changed the rules.",
        "tokens": [
          50766,
          597,
          307,
          300,
          286,
          3105,
          264,
          4474,
          13,
          50925
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 183.8,
        "id": 66,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 179.22,
        "temperature": 0,
        "text": " So the rules yesterday were just basically read true,",
        "tokens": [
          50925,
          407,
          264,
          4474,
          5186,
          645,
          445,
          1936,
          1401,
          2074,
          11,
          51154
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 184.5,
        "id": 67,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 183.8,
        "temperature": 0,
        "text": " write true.",
        "tokens": [
          51154,
          2464,
          2074,
          13,
          51189
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 186.48,
        "id": 68,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 184.5,
        "temperature": 0,
        "text": " These are the Firebase rules.",
        "tokens": [
          51189,
          1981,
          366,
          264,
          35173,
          4474,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 189.2,
        "id": 69,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 186.48,
        "temperature": 0,
        "text": " And meiamsome helped me look into how",
        "tokens": [
          51288,
          400,
          385,
          2918,
          82,
          423,
          4254,
          385,
          574,
          666,
          577,
          51424
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 190.92000000000002,
        "id": 70,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 189.2,
        "temperature": 0,
        "text": " you could customize the rules.",
        "tokens": [
          51424,
          291,
          727,
          19734,
          264,
          4474,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 193.24,
        "id": 71,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 190.92000000000002,
        "temperature": 0,
        "text": " And the things that have been added to the rules now",
        "tokens": [
          51510,
          400,
          264,
          721,
          300,
          362,
          668,
          3869,
          281,
          264,
          4474,
          586,
          51626
        ]
      },
      {
        "avg_logprob": -0.2716385283560123,
        "compression_ratio": 1.7035398230088497,
        "end": 197.08,
        "id": 72,
        "no_speech_prob": 0.00012730986054521054,
        "seek": 16800,
        "start": 193.24,
        "temperature": 0,
        "text": " are we have some things to validate",
        "tokens": [
          51626,
          366,
          321,
          362,
          512,
          721,
          281,
          29562,
          51818
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 200.16000000000003,
        "id": 73,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 197.12,
        "temperature": 0,
        "text": " to make sure the RGB values being put in the database",
        "tokens": [
          50366,
          281,
          652,
          988,
          264,
          31231,
          4190,
          885,
          829,
          294,
          264,
          8149,
          50518
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 201.96,
        "id": 74,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 200.16000000000003,
        "temperature": 0,
        "text": " are actually numbers.",
        "tokens": [
          50518,
          366,
          767,
          3547,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 203.42000000000002,
        "id": 75,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 201.96,
        "temperature": 0,
        "text": " So you can see how this looks here.",
        "tokens": [
          50608,
          407,
          291,
          393,
          536,
          577,
          341,
          1542,
          510,
          13,
          50681
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 206.64000000000001,
        "id": 76,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 203.42000000000002,
        "temperature": 0,
        "text": " New data is a number, and it's between 0 and 255.",
        "tokens": [
          50681,
          1873,
          1412,
          307,
          257,
          1230,
          11,
          293,
          309,
          311,
          1296,
          1958,
          293,
          3552,
          20,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 209.08,
        "id": 77,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 206.64000000000001,
        "temperature": 0,
        "text": " We have something to validate that the label, one of the",
        "tokens": [
          50842,
          492,
          362,
          746,
          281,
          29562,
          300,
          264,
          7645,
          11,
          472,
          295,
          264,
          50964
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 210.84,
        "id": 78,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 209.08,
        "temperature": 0,
        "text": " things that people put other words that",
        "tokens": [
          50964,
          721,
          300,
          561,
          829,
          661,
          2283,
          300,
          51052
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 213.72000000000003,
        "id": 79,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 210.84,
        "temperature": 0,
        "text": " weren't part of my set of classification labels",
        "tokens": [
          51052,
          4999,
          380,
          644,
          295,
          452,
          992,
          295,
          21538,
          16949,
          51196
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 214.92000000000002,
        "id": 80,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 213.72000000000003,
        "temperature": 0,
        "text": " into the database.",
        "tokens": [
          51196,
          666,
          264,
          8149,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 216.56,
        "id": 81,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 214.92000000000002,
        "temperature": 0,
        "text": " So I have to check that it's a string",
        "tokens": [
          51256,
          407,
          286,
          362,
          281,
          1520,
          300,
          309,
          311,
          257,
          6798,
          51338
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 218.94,
        "id": 82,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 216.56,
        "temperature": 0,
        "text": " and that the actual data's value matches",
        "tokens": [
          51338,
          293,
          300,
          264,
          3539,
          1412,
          311,
          2158,
          10676,
          51457
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 220.04000000000002,
        "id": 83,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 218.94,
        "temperature": 0,
        "text": " this regular expression.",
        "tokens": [
          51457,
          341,
          3890,
          6114,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 222.20000000000002,
        "id": 84,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 220.04000000000002,
        "temperature": 0,
        "text": " So if you've never seen regular expressions before,",
        "tokens": [
          51512,
          407,
          498,
          291,
          600,
          1128,
          1612,
          3890,
          15277,
          949,
          11,
          51620
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 225.12,
        "id": 85,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 222.20000000000002,
        "temperature": 0,
        "text": " I do happen to have a video series about that",
        "tokens": [
          51620,
          286,
          360,
          1051,
          281,
          362,
          257,
          960,
          2638,
          466,
          300,
          51766
        ]
      },
      {
        "avg_logprob": -0.24439498082103345,
        "compression_ratio": 1.7468354430379747,
        "end": 226.16000000000003,
        "id": 86,
        "no_speech_prob": 0.004264560993760824,
        "seek": 19708,
        "start": 225.12,
        "temperature": 0,
        "text": " that you could go watch.",
        "tokens": [
          51766,
          300,
          291,
          727,
          352,
          1159,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 229.28,
        "id": 87,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 226.16,
        "temperature": 0,
        "text": " But this, you can see that it matches any of these dash-ish.",
        "tokens": [
          50364,
          583,
          341,
          11,
          291,
          393,
          536,
          300,
          309,
          10676,
          604,
          295,
          613,
          8240,
          12,
          742,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 230.16,
        "id": 88,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 229.28,
        "temperature": 0,
        "text": " So that's protecting.",
        "tokens": [
          50520,
          407,
          300,
          311,
          12316,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 234.12,
        "id": 89,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 230.16,
        "temperature": 0,
        "text": " And then authentication was turned on.",
        "tokens": [
          50564,
          400,
          550,
          26643,
          390,
          3574,
          322,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 237.32,
        "id": 90,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 234.12,
        "temperature": 0,
        "text": " So what you don't see is that it's anonymous authentication,",
        "tokens": [
          50762,
          407,
          437,
          291,
          500,
          380,
          536,
          307,
          300,
          309,
          311,
          24932,
          26643,
          11,
          50922
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 240.76,
        "id": 91,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 237.32,
        "temperature": 0,
        "text": " but you can only write if you've been authenticated.",
        "tokens": [
          50922,
          457,
          291,
          393,
          787,
          2464,
          498,
          291,
          600,
          668,
          9214,
          3587,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 242.68,
        "id": 92,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 240.76,
        "temperature": 0,
        "text": " This way, it's anonymous.",
        "tokens": [
          51094,
          639,
          636,
          11,
          309,
          311,
          24932,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 245.88,
        "id": 93,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 242.68,
        "temperature": 0,
        "text": " I can track every person or every entry.",
        "tokens": [
          51190,
          286,
          393,
          2837,
          633,
          954,
          420,
          633,
          8729,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 248.8,
        "id": 94,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 245.88,
        "temperature": 0,
        "text": " It's not necessarily a person, but every entry",
        "tokens": [
          51350,
          467,
          311,
          406,
          4725,
          257,
          954,
          11,
          457,
          633,
          8729,
          51496
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 251.16,
        "id": 95,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 248.8,
        "temperature": 0,
        "text": " from a particular IP address into the database",
        "tokens": [
          51496,
          490,
          257,
          1729,
          8671,
          2985,
          666,
          264,
          8149,
          51614
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 252.32,
        "id": 96,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 251.16,
        "temperature": 0,
        "text": " with a unique ID.",
        "tokens": [
          51614,
          365,
          257,
          3845,
          7348,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.25682178139686584,
        "compression_ratio": 1.78125,
        "end": 254.04,
        "id": 97,
        "no_speech_prob": 0.00013551551091950387,
        "seek": 22616,
        "start": 252.32,
        "temperature": 0,
        "text": " So if I can see that there's a bot that's",
        "tokens": [
          51672,
          407,
          498,
          286,
          393,
          536,
          300,
          456,
          311,
          257,
          10592,
          300,
          311,
          51758
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 256.44,
        "id": 98,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 254.04,
        "temperature": 0,
        "text": " just flooding the database, I could either block it",
        "tokens": [
          50364,
          445,
          24132,
          264,
          8149,
          11,
          286,
          727,
          2139,
          3461,
          309,
          50484
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 258.71999999999997,
        "id": 99,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 256.44,
        "temperature": 0,
        "text": " or just clean that data out of it.",
        "tokens": [
          50484,
          420,
          445,
          2541,
          300,
          1412,
          484,
          295,
          309,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 260.96,
        "id": 100,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 258.71999999999997,
        "temperature": 0,
        "text": " So that's what I'm going to do in this video.",
        "tokens": [
          50598,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          341,
          960,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 265.64,
        "id": 101,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 260.96,
        "temperature": 0,
        "text": " I'm going to use a similar approach to this pull request.",
        "tokens": [
          50710,
          286,
          478,
          516,
          281,
          764,
          257,
          2531,
          3109,
          281,
          341,
          2235,
          5308,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 268.24,
        "id": 102,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 265.64,
        "temperature": 0,
        "text": " I'm going to actually read the data from the database.",
        "tokens": [
          50944,
          286,
          478,
          516,
          281,
          767,
          1401,
          264,
          1412,
          490,
          264,
          8149,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 270.84,
        "id": 103,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 268.24,
        "temperature": 0,
        "text": " And then I'm going to analyze it and delete stuff",
        "tokens": [
          51074,
          400,
          550,
          286,
          478,
          516,
          281,
          12477,
          309,
          293,
          12097,
          1507,
          51204
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 274.92,
        "id": 104,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 270.84,
        "temperature": 0,
        "text": " if it seems like it's no good, and then download a JSON file",
        "tokens": [
          51204,
          498,
          309,
          2544,
          411,
          309,
          311,
          572,
          665,
          11,
          293,
          550,
          5484,
          257,
          31828,
          3991,
          51408
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 278.28,
        "id": 105,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 274.92,
        "temperature": 0,
        "text": " that I'll then use in the TensorFlow.js example",
        "tokens": [
          51408,
          300,
          286,
          603,
          550,
          764,
          294,
          264,
          37624,
          13,
          25530,
          1365,
          51576
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 279.28,
        "id": 106,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 278.28,
        "temperature": 0,
        "text": " that I'm going to build.",
        "tokens": [
          51576,
          300,
          286,
          478,
          516,
          281,
          1322,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 282.68,
        "id": 107,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 279.28,
        "temperature": 0,
        "text": " Did I just spend the whole video introducing this topic?",
        "tokens": [
          51626,
          2589,
          286,
          445,
          3496,
          264,
          1379,
          960,
          15424,
          341,
          4829,
          30,
          51796
        ]
      },
      {
        "avg_logprob": -0.2107107269931847,
        "compression_ratio": 1.745704467353952,
        "end": 283.52,
        "id": 108,
        "no_speech_prob": 0.0007793608820065856,
        "seek": 25404,
        "start": 282.68,
        "temperature": 0,
        "text": " I think I might have.",
        "tokens": [
          51796,
          286,
          519,
          286,
          1062,
          362,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 285.79999999999995,
        "id": 109,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 283.52,
        "temperature": 0,
        "text": " But I'm going to move on and keep going anyway.",
        "tokens": [
          50364,
          583,
          286,
          478,
          516,
          281,
          1286,
          322,
          293,
          1066,
          516,
          4033,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 287.79999999999995,
        "id": 110,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 285.79999999999995,
        "temperature": 0,
        "text": " Before I dig into the code, let me just reference",
        "tokens": [
          50478,
          4546,
          286,
          2528,
          666,
          264,
          3089,
          11,
          718,
          385,
          445,
          6408,
          50578
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 289.08,
        "id": 111,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 287.79999999999995,
        "temperature": 0,
        "text": " one more web page to you.",
        "tokens": [
          50578,
          472,
          544,
          3670,
          3028,
          281,
          291,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 290.91999999999996,
        "id": 112,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 289.08,
        "temperature": 0,
        "text": " I want to show you this is a project that's",
        "tokens": [
          50642,
          286,
          528,
          281,
          855,
          291,
          341,
          307,
          257,
          1716,
          300,
          311,
          50734
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 292.15999999999997,
        "id": 113,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 290.91999999999996,
        "temperature": 0,
        "text": " at the time of this recording.",
        "tokens": [
          50734,
          412,
          264,
          565,
          295,
          341,
          6613,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 293.84,
        "id": 114,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 292.15999999999997,
        "temperature": 0,
        "text": " It hasn't technically been released yet,",
        "tokens": [
          50796,
          467,
          6132,
          380,
          12120,
          668,
          4736,
          1939,
          11,
          50880
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 295.76,
        "id": 115,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 293.84,
        "temperature": 0,
        "text": " although you can find it at ml5js.org.",
        "tokens": [
          50880,
          4878,
          291,
          393,
          915,
          309,
          412,
          23271,
          20,
          25530,
          13,
          4646,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 298.41999999999996,
        "id": 116,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 295.76,
        "temperature": 0,
        "text": " And it probably is released now that you're watching this video.",
        "tokens": [
          50976,
          400,
          309,
          1391,
          307,
          4736,
          586,
          300,
          291,
          434,
          1976,
          341,
          960,
          13,
          51109
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 301.44,
        "id": 117,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 298.41999999999996,
        "temperature": 0,
        "text": " But ml5 is a machine learning library",
        "tokens": [
          51109,
          583,
          23271,
          20,
          307,
          257,
          3479,
          2539,
          6405,
          51260
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 304.79999999999995,
        "id": 118,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 301.44,
        "temperature": 0,
        "text": " built on top of TensorFlow.js that I and other folks at ITP",
        "tokens": [
          51260,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          300,
          286,
          293,
          661,
          4024,
          412,
          6783,
          47,
          51428
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 306,
        "id": 119,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 304.79999999999995,
        "temperature": 0,
        "text": " have been working on.",
        "tokens": [
          51428,
          362,
          668,
          1364,
          322,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 308.03999999999996,
        "id": 120,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 306,
        "temperature": 0,
        "text": " And I just want to reference Hannah Davis, who's",
        "tokens": [
          51488,
          400,
          286,
          445,
          528,
          281,
          6408,
          21754,
          15658,
          11,
          567,
          311,
          51590
        ]
      },
      {
        "avg_logprob": -0.2521923542022705,
        "compression_ratio": 1.661764705882353,
        "end": 310.79999999999995,
        "id": 121,
        "no_speech_prob": 0.004754892084747553,
        "seek": 28352,
        "start": 308.03999999999996,
        "temperature": 0,
        "text": " an artist and researcher who's a contributor to ml5,",
        "tokens": [
          51590,
          364,
          5748,
          293,
          21751,
          567,
          311,
          257,
          42859,
          281,
          23271,
          20,
          11,
          51728
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 313.16,
        "id": 122,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 310.8,
        "temperature": 0,
        "text": " wrote this wonderful tutorial about making your own data",
        "tokens": [
          50364,
          4114,
          341,
          3715,
          7073,
          466,
          1455,
          428,
          1065,
          1412,
          50482
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 314.88,
        "id": 123,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 313.16,
        "temperature": 0,
        "text": " sets and thinking about questions",
        "tokens": [
          50482,
          6352,
          293,
          1953,
          466,
          1651,
          50568
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 318.04,
        "id": 124,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 314.88,
        "temperature": 0,
        "text": " to ask, in particular about responsible data collection",
        "tokens": [
          50568,
          281,
          1029,
          11,
          294,
          1729,
          466,
          6250,
          1412,
          5765,
          50726
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 319.40000000000003,
        "id": 125,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 318.04,
        "temperature": 0,
        "text": " and tagging and crowdsourcing.",
        "tokens": [
          50726,
          293,
          6162,
          3249,
          293,
          26070,
          41849,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 322.04,
        "id": 126,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 319.40000000000003,
        "temperature": 0,
        "text": " So hopefully, we'll come back to this topic again and again",
        "tokens": [
          50794,
          407,
          4696,
          11,
          321,
          603,
          808,
          646,
          281,
          341,
          4829,
          797,
          293,
          797,
          50926
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 323.04,
        "id": 127,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 322.04,
        "temperature": 0,
        "text": " in my video tutorials.",
        "tokens": [
          50926,
          294,
          452,
          960,
          17616,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 324.36,
        "id": 128,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 323.04,
        "temperature": 0,
        "text": " But I would encourage you to check this out",
        "tokens": [
          50976,
          583,
          286,
          576,
          5373,
          291,
          281,
          1520,
          341,
          484,
          51042
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 325,
        "id": 129,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 324.36,
        "temperature": 0,
        "text": " and really think about it.",
        "tokens": [
          51042,
          293,
          534,
          519,
          466,
          309,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 328.08000000000004,
        "id": 130,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 325,
        "temperature": 0,
        "text": " I mean, one thing we could think about here is, number one,",
        "tokens": [
          51074,
          286,
          914,
          11,
          472,
          551,
          321,
          727,
          519,
          466,
          510,
          307,
          11,
          1230,
          472,
          11,
          51228
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 330.96000000000004,
        "id": 131,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 328.08000000000004,
        "temperature": 0,
        "text": " I'm building an example that requires",
        "tokens": [
          51228,
          286,
          478,
          2390,
          364,
          1365,
          300,
          7029,
          51372
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 332.36,
        "id": 132,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 330.96000000000004,
        "temperature": 0,
        "text": " people to see the colors.",
        "tokens": [
          51372,
          561,
          281,
          536,
          264,
          4577,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 335.04,
        "id": 133,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 332.36,
        "temperature": 0,
        "text": " So what about people who are colorblind, low vision,",
        "tokens": [
          51442,
          407,
          437,
          466,
          561,
          567,
          366,
          2017,
          47494,
          11,
          2295,
          5201,
          11,
          51576
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 335.96000000000004,
        "id": 134,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 335.04,
        "temperature": 0,
        "text": " or blind?",
        "tokens": [
          51576,
          420,
          6865,
          30,
          51622
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 338.12,
        "id": 135,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 335.96000000000004,
        "temperature": 0,
        "text": " That's something I really should be thoughtful about",
        "tokens": [
          51622,
          663,
          311,
          746,
          286,
          534,
          820,
          312,
          21566,
          466,
          51730
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 338.88,
        "id": 136,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 338.12,
        "temperature": 0,
        "text": " in this example.",
        "tokens": [
          51730,
          294,
          341,
          1365,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.24531730315970174,
        "compression_ratio": 1.7768115942028986,
        "end": 340.72,
        "id": 137,
        "no_speech_prob": 0.007815498858690262,
        "seek": 31080,
        "start": 338.88,
        "temperature": 0,
        "text": " How can I approach that?",
        "tokens": [
          51768,
          1012,
          393,
          286,
          3109,
          300,
          30,
          51860
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 345.84000000000003,
        "id": 138,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 341.52000000000004,
        "temperature": 0,
        "text": " Who's really able to participate in tagging and submitting data?",
        "tokens": [
          50404,
          2102,
          311,
          534,
          1075,
          281,
          8197,
          294,
          6162,
          3249,
          293,
          31836,
          1412,
          30,
          50620
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 347.12,
        "id": 139,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 345.84000000000003,
        "temperature": 0,
        "text": " Who's being left out?",
        "tokens": [
          50620,
          2102,
          311,
          885,
          1411,
          484,
          30,
          50684
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 349.28000000000003,
        "id": 140,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 347.12,
        "temperature": 0,
        "text": " So I think the good news for me is",
        "tokens": [
          50684,
          407,
          286,
          519,
          264,
          665,
          2583,
          337,
          385,
          307,
          50792
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 351.6,
        "id": 141,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 349.28000000000003,
        "temperature": 0,
        "text": " that this is meant to be somewhat of a generic tutorial.",
        "tokens": [
          50792,
          300,
          341,
          307,
          4140,
          281,
          312,
          8344,
          295,
          257,
          19577,
          7073,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 354.88000000000005,
        "id": 142,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 351.6,
        "temperature": 0,
        "text": " And the data, wow, doesn't matter so much",
        "tokens": [
          50908,
          400,
          264,
          1412,
          11,
          6076,
          11,
          1177,
          380,
          1871,
          370,
          709,
          51072
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 356.92,
        "id": 143,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 354.88000000000005,
        "temperature": 0,
        "text": " if it's perfect, because I just want",
        "tokens": [
          51072,
          498,
          309,
          311,
          2176,
          11,
          570,
          286,
          445,
          528,
          51174
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 358.48,
        "id": 144,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 356.92,
        "temperature": 0,
        "text": " to show that whole process.",
        "tokens": [
          51174,
          281,
          855,
          300,
          1379,
          1399,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 360.40000000000003,
        "id": 145,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 358.48,
        "temperature": 0,
        "text": " But you then actually being a person",
        "tokens": [
          51252,
          583,
          291,
          550,
          767,
          885,
          257,
          954,
          51348
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 363.76000000000005,
        "id": 146,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 360.40000000000003,
        "temperature": 0,
        "text": " who might work with machine learning out in the real world,",
        "tokens": [
          51348,
          567,
          1062,
          589,
          365,
          3479,
          2539,
          484,
          294,
          264,
          957,
          1002,
          11,
          51516
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 367.04,
        "id": 147,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 363.76000000000005,
        "temperature": 0,
        "text": " you really want to be thoughtful about that data.",
        "tokens": [
          51516,
          291,
          534,
          528,
          281,
          312,
          21566,
          466,
          300,
          1412,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.22917721289714785,
        "compression_ratio": 1.6769759450171822,
        "end": 370,
        "id": 148,
        "no_speech_prob": 0.00003024164652742911,
        "seek": 34072,
        "start": 367.04,
        "temperature": 0,
        "text": " And I hope that I can link to more resources about that",
        "tokens": [
          51680,
          400,
          286,
          1454,
          300,
          286,
          393,
          2113,
          281,
          544,
          3593,
          466,
          300,
          51828
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 371.96,
        "id": 149,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 370,
        "temperature": 0,
        "text": " and cover that more on this channel as well.",
        "tokens": [
          50364,
          293,
          2060,
          300,
          544,
          322,
          341,
          2269,
          382,
          731,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 376.12,
        "id": 150,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 371.96,
        "temperature": 0,
        "text": " So all that aside, now I'm ready to dig in and look at the data",
        "tokens": [
          50462,
          407,
          439,
          300,
          7359,
          11,
          586,
          286,
          478,
          1919,
          281,
          2528,
          294,
          293,
          574,
          412,
          264,
          1412,
          50670
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 379.04,
        "id": 151,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 376.12,
        "temperature": 0,
        "text": " and do the thing that's probably going to take me the next 24",
        "tokens": [
          50670,
          293,
          360,
          264,
          551,
          300,
          311,
          1391,
          516,
          281,
          747,
          385,
          264,
          958,
          4022,
          50816
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 380.72,
        "id": 152,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 379.04,
        "temperature": 0,
        "text": " hours, or three days, or three weeks,",
        "tokens": [
          50816,
          2496,
          11,
          420,
          1045,
          1708,
          11,
          420,
          1045,
          3259,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 382.72,
        "id": 153,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 380.72,
        "temperature": 0,
        "text": " try to clean the data and make it usable for me.",
        "tokens": [
          50900,
          853,
          281,
          2541,
          264,
          1412,
          293,
          652,
          309,
          29975,
          337,
          385,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 386.96,
        "id": 154,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 382.72,
        "temperature": 0,
        "text": " So yeah, that's what I'm going to do.",
        "tokens": [
          51000,
          407,
          1338,
          11,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 389.96,
        "id": 155,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 386.96,
        "temperature": 0,
        "text": " OK, so I have a client.",
        "tokens": [
          51212,
          2264,
          11,
          370,
          286,
          362,
          257,
          6423,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 391.24,
        "id": 156,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 389.96,
        "temperature": 0,
        "text": " I mean, I could do this.",
        "tokens": [
          51362,
          286,
          914,
          11,
          286,
          727,
          360,
          341,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 393.4,
        "id": 157,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 391.24,
        "temperature": 0,
        "text": " I could download the data directly from Firebase",
        "tokens": [
          51426,
          286,
          727,
          5484,
          264,
          1412,
          3838,
          490,
          35173,
          51534
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 395.44,
        "id": 158,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 393.4,
        "temperature": 0,
        "text": " and just put it in a Google Sheet to look at it.",
        "tokens": [
          51534,
          293,
          445,
          829,
          309,
          294,
          257,
          3329,
          1240,
          302,
          281,
          574,
          412,
          309,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 397.08,
        "id": 159,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 395.44,
        "temperature": 0,
        "text": " That might be useful.",
        "tokens": [
          51636,
          663,
          1062,
          312,
          4420,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.2048446778328188,
        "compression_ratio": 1.7517482517482517,
        "end": 398.84,
        "id": 160,
        "no_speech_prob": 0.0012644048547372222,
        "seek": 37000,
        "start": 397.08,
        "temperature": 0,
        "text": " But what I'm going to do is I'm just",
        "tokens": [
          51718,
          583,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          51806
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 400.67999999999995,
        "id": 161,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 398.84,
        "temperature": 0,
        "text": " going to actually write a p5 sketch, or just",
        "tokens": [
          50364,
          516,
          281,
          767,
          2464,
          257,
          280,
          20,
          12325,
          11,
          420,
          445,
          50456
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 403.71999999999997,
        "id": 162,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 400.67999999999995,
        "temperature": 0,
        "text": " a JavaScript program, to look at the data first.",
        "tokens": [
          50456,
          257,
          15778,
          1461,
          11,
          281,
          574,
          412,
          264,
          1412,
          700,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 405.91999999999996,
        "id": 163,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 403.71999999999997,
        "temperature": 0,
        "text": " So I have this sketch.",
        "tokens": [
          50608,
          407,
          286,
          362,
          341,
          12325,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 408.52,
        "id": 164,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 405.91999999999996,
        "temperature": 0,
        "text": " All that's in it so far is just that connect to Firebase",
        "tokens": [
          50718,
          1057,
          300,
          311,
          294,
          309,
          370,
          1400,
          307,
          445,
          300,
          1745,
          281,
          35173,
          50848
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 409.84,
        "id": 165,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 408.52,
        "temperature": 0,
        "text": " and authenticate.",
        "tokens": [
          50848,
          293,
          9214,
          8700,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 412.71999999999997,
        "id": 166,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 409.84,
        "temperature": 0,
        "text": " So what I want to do is to retrieve data.",
        "tokens": [
          50914,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          281,
          30254,
          1412,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 418.64,
        "id": 167,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 412.71999999999997,
        "temperature": 0,
        "text": " I think I say something like database once, value.",
        "tokens": [
          51058,
          286,
          519,
          286,
          584,
          746,
          411,
          8149,
          1564,
          11,
          2158,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 421.88,
        "id": 168,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 418.64,
        "temperature": 0,
        "text": " And then I have a callback like got data.",
        "tokens": [
          51354,
          400,
          550,
          286,
          362,
          257,
          818,
          3207,
          411,
          658,
          1412,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 424.64,
        "id": 169,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 421.88,
        "temperature": 0,
        "text": " I don't know if this is right.",
        "tokens": [
          51516,
          286,
          500,
          380,
          458,
          498,
          341,
          307,
          558,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.2541036605834961,
        "compression_ratio": 1.625,
        "end": 427.08,
        "id": 170,
        "no_speech_prob": 0.002287176437675953,
        "seek": 39884,
        "start": 424.64,
        "temperature": 0,
        "text": " And by the way, I've learned that the JavaScript recently,",
        "tokens": [
          51654,
          400,
          538,
          264,
          636,
          11,
          286,
          600,
          3264,
          300,
          264,
          15778,
          3938,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 430.35999999999996,
        "id": 171,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 427.08,
        "temperature": 0,
        "text": " the JavaScript convention, which is not how p5 necessarily",
        "tokens": [
          50364,
          264,
          15778,
          10286,
          11,
          597,
          307,
          406,
          577,
          280,
          20,
          4725,
          50528
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 434.64,
        "id": 172,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 430.35999999999996,
        "temperature": 0,
        "text": " works, is often the error is first as callback arguments.",
        "tokens": [
          50528,
          1985,
          11,
          307,
          2049,
          264,
          6713,
          307,
          700,
          382,
          818,
          3207,
          12869,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 437.28,
        "id": 173,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 434.64,
        "temperature": 0,
        "text": " And then the results is second.",
        "tokens": [
          50742,
          400,
          550,
          264,
          3542,
          307,
          1150,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 438.08,
        "id": 174,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 437.28,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50874,
          286,
          500,
          380,
          458,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 441.64,
        "id": 175,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 438.08,
        "temperature": 0,
        "text": " I'm just speculating what the Firebase API might be like.",
        "tokens": [
          50914,
          286,
          478,
          445,
          1608,
          12162,
          437,
          264,
          35173,
          9362,
          1062,
          312,
          411,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 442.68,
        "id": 176,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 441.64,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51092,
          961,
          311,
          536,
          437,
          2314,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 444.32,
        "id": 177,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 442.68,
        "temperature": 0,
        "text": " Database once is not a function.",
        "tokens": [
          51144,
          40461,
          651,
          1564,
          307,
          406,
          257,
          2445,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 445.84,
        "id": 178,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 444.32,
        "temperature": 0,
        "text": " I probably need.ref.",
        "tokens": [
          51226,
          286,
          1391,
          643,
          2411,
          33115,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 449.15999999999997,
        "id": 179,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 445.84,
        "temperature": 0,
        "text": " And then I probably need colors or something, right?",
        "tokens": [
          51302,
          400,
          550,
          286,
          1391,
          643,
          4577,
          420,
          746,
          11,
          558,
          30,
          51468
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 451.68,
        "id": 180,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 449.15999999999997,
        "temperature": 0,
        "text": " Probably something like this.",
        "tokens": [
          51468,
          9210,
          746,
          411,
          341,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 454.03999999999996,
        "id": 181,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 451.68,
        "temperature": 0,
        "text": " I could just go and look on the documentation.",
        "tokens": [
          51594,
          286,
          727,
          445,
          352,
          293,
          574,
          322,
          264,
          14333,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.2455320656299591,
        "compression_ratio": 1.6512455516014235,
        "end": 456.28,
        "id": 182,
        "no_speech_prob": 0.0006361682899296284,
        "seek": 42708,
        "start": 454.03999999999996,
        "temperature": 0,
        "text": " I also have this Firebase tutorial.",
        "tokens": [
          51712,
          286,
          611,
          362,
          341,
          35173,
          7073,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 459.47999999999996,
        "id": 183,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 456.28,
        "temperature": 0,
        "text": " Oh, yeah, I need the database reference.",
        "tokens": [
          50364,
          876,
          11,
          1338,
          11,
          286,
          643,
          264,
          8149,
          6408,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 463.35999999999996,
        "id": 184,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 459.47999999999996,
        "temperature": 0,
        "text": " And then in my tutorial, I say.on, but really, oh,",
        "tokens": [
          50524,
          400,
          550,
          294,
          452,
          7073,
          11,
          286,
          584,
          2411,
          266,
          11,
          457,
          534,
          11,
          1954,
          11,
          50718
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 464.91999999999996,
        "id": 185,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 463.35999999999996,
        "temperature": 0,
        "text": " got one and got error data.",
        "tokens": [
          50718,
          658,
          472,
          293,
          658,
          6713,
          1412,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 466.15999999999997,
        "id": 186,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 464.91999999999996,
        "temperature": 0,
        "text": " So maybe there's two callbacks.",
        "tokens": [
          50796,
          407,
          1310,
          456,
          311,
          732,
          818,
          17758,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 466.91999999999996,
        "id": 187,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 466.15999999999997,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50858,
          2102,
          3255,
          30,
          50896
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 468.23999999999995,
        "id": 188,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 466.91999999999996,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50896,
          2102,
          3255,
          30,
          50962
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 472.35999999999996,
        "id": 189,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 468.23999999999995,
        "temperature": 0,
        "text": " Let's say, let's do this.",
        "tokens": [
          50962,
          961,
          311,
          584,
          11,
          718,
          311,
          360,
          341,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 477.28,
        "id": 190,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 472.35999999999996,
        "temperature": 0,
        "text": " Let ref equal database ref colors.",
        "tokens": [
          51168,
          961,
          1895,
          2681,
          8149,
          1895,
          4577,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 481.4,
        "id": 191,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 477.28,
        "temperature": 0,
        "text": " And then let's say ref once value got data.",
        "tokens": [
          51414,
          400,
          550,
          718,
          311,
          584,
          1895,
          1564,
          2158,
          658,
          1412,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.27090990318442293,
        "compression_ratio": 1.606060606060606,
        "end": 483.11999999999995,
        "id": 192,
        "no_speech_prob": 0.000073685085226316,
        "seek": 45628,
        "start": 481.4,
        "temperature": 0,
        "text": " And let's look and see what comes back.",
        "tokens": [
          51620,
          400,
          718,
          311,
          574,
          293,
          536,
          437,
          1487,
          646,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 486.2,
        "id": 193,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 483.96,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50406,
          1057,
          558,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 488.48,
        "id": 194,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 486.2,
        "temperature": 0,
        "text": " Let's go back to here.",
        "tokens": [
          50518,
          961,
          311,
          352,
          646,
          281,
          510,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 492.36,
        "id": 195,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 488.48,
        "temperature": 0,
        "text": " All right, something came back.",
        "tokens": [
          50632,
          1057,
          558,
          11,
          746,
          1361,
          646,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 493.32,
        "id": 196,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 492.36,
        "temperature": 0,
        "text": " No, nothing came back.",
        "tokens": [
          50826,
          883,
          11,
          1825,
          1361,
          646,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 495.36,
        "id": 197,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 493.32,
        "temperature": 0,
        "text": " 19.",
        "tokens": [
          50874,
          1294,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 497.52,
        "id": 198,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 495.36,
        "temperature": 0,
        "text": " All right, what's going on here?",
        "tokens": [
          50976,
          1057,
          558,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          51084
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 500.6,
        "id": 199,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 497.52,
        "temperature": 0,
        "text": " Maybe I should go back and look at my actual example.",
        "tokens": [
          51084,
          2704,
          286,
          820,
          352,
          646,
          293,
          574,
          412,
          452,
          3539,
          1365,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 502.36,
        "id": 200,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 500.6,
        "temperature": 0,
        "text": " Got one, error data.",
        "tokens": [
          51238,
          5803,
          472,
          11,
          6713,
          1412,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 506.4,
        "id": 201,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 502.36,
        "temperature": 0,
        "text": " So let's, oh, that's a pointer to the data.",
        "tokens": [
          51326,
          407,
          718,
          311,
          11,
          1954,
          11,
          300,
          311,
          257,
          23918,
          281,
          264,
          1412,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 507.16,
        "id": 202,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 506.4,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51528,
          1779,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.2894676132957534,
        "compression_ratio": 1.6420454545454546,
        "end": 510.2,
        "id": 203,
        "no_speech_prob": 0.00006302741530817002,
        "seek": 48312,
        "start": 507.16,
        "temperature": 0,
        "text": " So actually, the data, so it actually",
        "tokens": [
          51566,
          407,
          767,
          11,
          264,
          1412,
          11,
          370,
          309,
          767,
          51718
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 515.52,
        "id": 204,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 510.2,
        "temperature": 0,
        "text": " is a separate callback for error, looks like.",
        "tokens": [
          50364,
          307,
          257,
          4994,
          818,
          3207,
          337,
          6713,
          11,
          1542,
          411,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 518.48,
        "id": 205,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 515.52,
        "temperature": 0,
        "text": " So I'm going to not worry about the error callback right now.",
        "tokens": [
          50630,
          407,
          286,
          478,
          516,
          281,
          406,
          3292,
          466,
          264,
          6713,
          818,
          3207,
          558,
          586,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 520.4,
        "id": 206,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 518.48,
        "temperature": 0,
        "text": " I'm going to use got data.",
        "tokens": [
          50778,
          286,
          478,
          516,
          281,
          764,
          658,
          1412,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 523.28,
        "id": 207,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 520.4,
        "temperature": 0,
        "text": " And then let's look at the results.",
        "tokens": [
          50874,
          400,
          550,
          718,
          311,
          574,
          412,
          264,
          3542,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 526.96,
        "id": 208,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 525.68,
        "temperature": 0,
        "text": " And so, yeah, this looks weird.",
        "tokens": [
          51138,
          400,
          370,
          11,
          1338,
          11,
          341,
          1542,
          3657,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 528.36,
        "id": 209,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 526.96,
        "temperature": 0,
        "text": " Like, how could I possibly use this?",
        "tokens": [
          51202,
          1743,
          11,
          577,
          727,
          286,
          6264,
          764,
          341,
          30,
          51272
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 529.72,
        "id": 210,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 528.36,
        "temperature": 0,
        "text": " So what you're actually getting back",
        "tokens": [
          51272,
          407,
          437,
          291,
          434,
          767,
          1242,
          646,
          51340
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 531.12,
        "id": 211,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 529.72,
        "temperature": 0,
        "text": " is this pointer to the data.",
        "tokens": [
          51340,
          307,
          341,
          23918,
          281,
          264,
          1412,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 532.24,
        "id": 212,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 531.12,
        "temperature": 0,
        "text": " You've got to call functions on it",
        "tokens": [
          51410,
          509,
          600,
          658,
          281,
          818,
          6828,
          322,
          309,
          51466
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 533.8,
        "id": 213,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 532.24,
        "temperature": 0,
        "text": " to actually look at what's there.",
        "tokens": [
          51466,
          281,
          767,
          574,
          412,
          437,
          311,
          456,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 537.04,
        "id": 214,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 533.8,
        "temperature": 0,
        "text": " So presumably, something like results.value",
        "tokens": [
          51544,
          407,
          26742,
          11,
          746,
          411,
          3542,
          13,
          29155,
          51706
        ]
      },
      {
        "avg_logprob": -0.24843345988880505,
        "compression_ratio": 1.7126436781609196,
        "end": 539.56,
        "id": 215,
        "no_speech_prob": 0.004538404289633036,
        "seek": 51020,
        "start": 537.04,
        "temperature": 0,
        "text": " is probably what the API is.",
        "tokens": [
          51706,
          307,
          1391,
          437,
          264,
          9362,
          307,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 541.8,
        "id": 216,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 539.56,
        "temperature": 0,
        "text": " No, it's not a function.",
        "tokens": [
          50364,
          883,
          11,
          309,
          311,
          406,
          257,
          2445,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 544.4,
        "id": 217,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 541.8,
        "temperature": 0,
        "text": " So I have to go back and look at my tutorial..val.",
        "tokens": [
          50476,
          407,
          286,
          362,
          281,
          352,
          646,
          293,
          574,
          412,
          452,
          7073,
          13,
          13,
          3337,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 547.16,
        "id": 218,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 544.4,
        "temperature": 0,
        "text": " Let's try that.",
        "tokens": [
          50606,
          961,
          311,
          853,
          300,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 547.88,
        "id": 219,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 547.16,
        "temperature": 0,
        "text": " Let's try.val.",
        "tokens": [
          50744,
          961,
          311,
          853,
          2411,
          3337,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 553.0799999999999,
        "id": 220,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 552.4399999999999,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51008,
          400,
          456,
          321,
          352,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 554.28,
        "id": 221,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 553.0799999999999,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51040,
          2053,
          412,
          341,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 555.52,
        "id": 222,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 554.28,
        "temperature": 0,
        "text": " Oh, it's a lot of data.",
        "tokens": [
          51100,
          876,
          11,
          309,
          311,
          257,
          688,
          295,
          1412,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 558.64,
        "id": 223,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 555.52,
        "temperature": 0,
        "text": " Boy, the console is not able to render this.",
        "tokens": [
          51162,
          9486,
          11,
          264,
          11076,
          307,
          406,
          1075,
          281,
          15529,
          341,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 560.92,
        "id": 224,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 558.64,
        "temperature": 0,
        "text": " So now, is this actually an array?",
        "tokens": [
          51318,
          407,
          586,
          11,
          307,
          341,
          767,
          364,
          10225,
          30,
          51432
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 564.52,
        "id": 225,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 560.92,
        "temperature": 0,
        "text": " Ah, it's just actually an object with all the data in it.",
        "tokens": [
          51432,
          2438,
          11,
          309,
          311,
          445,
          767,
          364,
          2657,
          365,
          439,
          264,
          1412,
          294,
          309,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2464975561977418,
        "compression_ratio": 1.6359223300970873,
        "end": 566.8,
        "id": 226,
        "no_speech_prob": 0.000033214088034583256,
        "seek": 53956,
        "start": 564.52,
        "temperature": 0,
        "text": " So I need to turn that into an array.",
        "tokens": [
          51612,
          407,
          286,
          643,
          281,
          1261,
          300,
          666,
          364,
          10225,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 569.68,
        "id": 227,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 566.8,
        "temperature": 0,
        "text": " Because I kind of want to loop through it.",
        "tokens": [
          50364,
          1436,
          286,
          733,
          295,
          528,
          281,
          6367,
          807,
          309,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 571.88,
        "id": 228,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 569.68,
        "temperature": 0,
        "text": " I wonder what the, oh, you know what I'll do.",
        "tokens": [
          50508,
          286,
          2441,
          437,
          264,
          11,
          1954,
          11,
          291,
          458,
          437,
          286,
          603,
          360,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 574.16,
        "id": 229,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 571.88,
        "temperature": 0,
        "text": " This is what I'm going to do.",
        "tokens": [
          50618,
          639,
          307,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 577.92,
        "id": 230,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 574.16,
        "temperature": 0,
        "text": " I am going to, so now I'm going to process the data.",
        "tokens": [
          50732,
          286,
          669,
          516,
          281,
          11,
          370,
          586,
          286,
          478,
          516,
          281,
          1399,
          264,
          1412,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 580.64,
        "id": 231,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 577.92,
        "temperature": 0,
        "text": " So first, let me just get all the keys.",
        "tokens": [
          50920,
          407,
          700,
          11,
          718,
          385,
          445,
          483,
          439,
          264,
          9317,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 582.56,
        "id": 232,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 580.64,
        "temperature": 0,
        "text": " So I can say object.keys.",
        "tokens": [
          51056,
          407,
          286,
          393,
          584,
          2657,
          13,
          18847,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 587.28,
        "id": 233,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 582.56,
        "temperature": 0,
        "text": " So let me just say let data equal results.val.",
        "tokens": [
          51152,
          407,
          718,
          385,
          445,
          584,
          718,
          1412,
          2681,
          3542,
          13,
          3337,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 589.76,
        "id": 234,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 587.28,
        "temperature": 0,
        "text": " Let's not console log that.",
        "tokens": [
          51388,
          961,
          311,
          406,
          11076,
          3565,
          300,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 592.12,
        "id": 235,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 589.76,
        "temperature": 0,
        "text": " Object.keys data.",
        "tokens": [
          51512,
          24753,
          13,
          18847,
          1412,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.2489435968320232,
        "compression_ratio": 1.6470588235294117,
        "end": 594.4399999999999,
        "id": 236,
        "no_speech_prob": 0.00005829051588079892,
        "seek": 56680,
        "start": 592.12,
        "temperature": 0,
        "text": " And then console.log keys.length.",
        "tokens": [
          51630,
          400,
          550,
          11076,
          13,
          4987,
          9317,
          13,
          45390,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 600.88,
        "id": 237,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 597.68,
        "temperature": 0,
        "text": " And I don't need this page anymore.",
        "tokens": [
          50408,
          400,
          286,
          500,
          380,
          643,
          341,
          3028,
          3602,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 604.0799999999999,
        "id": 238,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 600.88,
        "temperature": 0,
        "text": " I'm going back to here, clean data.",
        "tokens": [
          50568,
          286,
          478,
          516,
          646,
          281,
          510,
          11,
          2541,
          1412,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 609.12,
        "id": 239,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 604.0799999999999,
        "temperature": 0,
        "text": " So there's 5,902 entries into the database.",
        "tokens": [
          50728,
          407,
          456,
          311,
          1025,
          11,
          7771,
          17,
          23041,
          666,
          264,
          8149,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 610.4,
        "id": 240,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 609.12,
        "temperature": 0,
        "text": " This is never going to change.",
        "tokens": [
          50980,
          639,
          307,
          1128,
          516,
          281,
          1319,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 612.28,
        "id": 241,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 610.4,
        "temperature": 0,
        "text": " Because just while I'm recording this video,",
        "tokens": [
          51044,
          1436,
          445,
          1339,
          286,
          478,
          6613,
          341,
          960,
          11,
          51138
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 616.3199999999999,
        "id": 242,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 612.28,
        "temperature": 0,
        "text": " I shut off the ability to write to the database.",
        "tokens": [
          51138,
          286,
          5309,
          766,
          264,
          3485,
          281,
          2464,
          281,
          264,
          8149,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 620.4799999999999,
        "id": 243,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 616.3199999999999,
        "temperature": 0,
        "text": " So what we can actually start to do now is I could say for let",
        "tokens": [
          51340,
          407,
          437,
          321,
          393,
          767,
          722,
          281,
          360,
          586,
          307,
          286,
          727,
          584,
          337,
          718,
          51548
        ]
      },
      {
        "avg_logprob": -0.2653239601536801,
        "compression_ratio": 1.490566037735849,
        "end": 623.24,
        "id": 244,
        "no_speech_prob": 0.000057387060223845765,
        "seek": 59680,
        "start": 620.4799999999999,
        "temperature": 0,
        "text": " key of keys.",
        "tokens": [
          51548,
          2141,
          295,
          9317,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 630.8,
        "id": 245,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 623.24,
        "temperature": 0,
        "text": " And I could say let record equals data key.",
        "tokens": [
          50364,
          400,
          286,
          727,
          584,
          718,
          2136,
          6915,
          1412,
          2141,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 633.6,
        "id": 246,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 630.8,
        "temperature": 0,
        "text": " And I could say console.log record.",
        "tokens": [
          50742,
          400,
          286,
          727,
          584,
          11076,
          13,
          4987,
          2136,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 635.84,
        "id": 247,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 633.6,
        "temperature": 0,
        "text": " So this is going to log all 5,000 of those one",
        "tokens": [
          50882,
          407,
          341,
          307,
          516,
          281,
          3565,
          439,
          1025,
          11,
          1360,
          295,
          729,
          472,
          50994
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 637.92,
        "id": 248,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 635.84,
        "temperature": 0,
        "text": " at a time, I think.",
        "tokens": [
          50994,
          412,
          257,
          565,
          11,
          286,
          519,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 640.8,
        "id": 249,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 637.92,
        "temperature": 0,
        "text": " So I can see these are all just logging every single data",
        "tokens": [
          51098,
          407,
          286,
          393,
          536,
          613,
          366,
          439,
          445,
          27991,
          633,
          2167,
          1412,
          51242
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 641.5600000000001,
        "id": 250,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 640.8,
        "temperature": 0,
        "text": " point.",
        "tokens": [
          51242,
          935,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 643.88,
        "id": 251,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 641.5600000000001,
        "temperature": 0,
        "text": " And we can see that for every single one,",
        "tokens": [
          51280,
          400,
          321,
          393,
          536,
          300,
          337,
          633,
          2167,
          472,
          11,
          51396
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 647.92,
        "id": 252,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 643.88,
        "temperature": 0,
        "text": " there's an R, a G, and a B, the label, and then this user ID.",
        "tokens": [
          51396,
          456,
          311,
          364,
          497,
          11,
          257,
          460,
          11,
          293,
          257,
          363,
          11,
          264,
          7645,
          11,
          293,
          550,
          341,
          4195,
          7348,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 652.44,
        "id": 253,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 647.92,
        "temperature": 0,
        "text": " So now I think there was, I'm watching the database",
        "tokens": [
          51598,
          407,
          586,
          286,
          519,
          456,
          390,
          11,
          286,
          478,
          1976,
          264,
          8149,
          51824
        ]
      },
      {
        "avg_logprob": -0.214661937114621,
        "compression_ratio": 1.6710526315789473,
        "end": 653.2,
        "id": 254,
        "no_speech_prob": 0.00030061337747611105,
        "seek": 62324,
        "start": 652.44,
        "temperature": 0,
        "text": " this morning.",
        "tokens": [
          51824,
          341,
          2446,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 656.08,
        "id": 255,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 654.1600000000001,
        "temperature": 0,
        "text": " I think there was a bot that was posting to it.",
        "tokens": [
          50412,
          286,
          519,
          456,
          390,
          257,
          10592,
          300,
          390,
          15978,
          281,
          309,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 658.36,
        "id": 256,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 656.08,
        "temperature": 0,
        "text": " So now it's possible it could be that there's just",
        "tokens": [
          50508,
          407,
          586,
          309,
          311,
          1944,
          309,
          727,
          312,
          300,
          456,
          311,
          445,
          50622
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 661.48,
        "id": 257,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 658.36,
        "temperature": 0,
        "text": " one person who actually clicked a lot of times.",
        "tokens": [
          50622,
          472,
          954,
          567,
          767,
          23370,
          257,
          688,
          295,
          1413,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 663.1600000000001,
        "id": 258,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 661.48,
        "temperature": 0,
        "text": " But so what I'm going to do right now",
        "tokens": [
          50778,
          583,
          370,
          437,
          286,
          478,
          516,
          281,
          360,
          558,
          586,
          50862
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 665.32,
        "id": 259,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 663.1600000000001,
        "temperature": 0,
        "text": " to just examine the data a little bit",
        "tokens": [
          50862,
          281,
          445,
          17496,
          264,
          1412,
          257,
          707,
          857,
          50970
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 672.6400000000001,
        "id": 260,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 665.32,
        "temperature": 0,
        "text": " is I am going to look at the user by user ID",
        "tokens": [
          50970,
          307,
          286,
          669,
          516,
          281,
          574,
          412,
          264,
          4195,
          538,
          4195,
          7348,
          51336
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 674.9200000000001,
        "id": 261,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 672.6400000000001,
        "temperature": 0,
        "text": " and count up how many entries for each user ID.",
        "tokens": [
          51336,
          293,
          1207,
          493,
          577,
          867,
          23041,
          337,
          1184,
          4195,
          7348,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.21137359907042305,
        "compression_ratio": 1.6200873362445414,
        "end": 678.5600000000001,
        "id": 262,
        "no_speech_prob": 0.00005562159640248865,
        "seek": 65320,
        "start": 674.9200000000001,
        "temperature": 0,
        "text": " So I basically need to do something like a concordance.",
        "tokens": [
          51450,
          407,
          286,
          1936,
          643,
          281,
          360,
          746,
          411,
          257,
          1588,
          765,
          719,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.21361771751852596,
        "compression_ratio": 1.4028776978417266,
        "end": 686.4399999999999,
        "id": 263,
        "no_speech_prob": 0.000030241844797274098,
        "seek": 67856,
        "start": 678.56,
        "temperature": 0,
        "text": " So if I say UID, if I look at that,",
        "tokens": [
          50364,
          407,
          498,
          286,
          584,
          624,
          2777,
          11,
          498,
          286,
          574,
          412,
          300,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.21361771751852596,
        "compression_ratio": 1.4028776978417266,
        "end": 689.28,
        "id": 264,
        "no_speech_prob": 0.000030241844797274098,
        "seek": 67856,
        "start": 686.4399999999999,
        "temperature": 0,
        "text": " we can see there's all the user IDs.",
        "tokens": [
          50758,
          321,
          393,
          536,
          456,
          311,
          439,
          264,
          4195,
          48212,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.21361771751852596,
        "compression_ratio": 1.4028776978417266,
        "end": 691.88,
        "id": 265,
        "no_speech_prob": 0.000030241844797274098,
        "seek": 67856,
        "start": 689.28,
        "temperature": 0,
        "text": " And what I want to do now is just associate.",
        "tokens": [
          50900,
          400,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          445,
          14644,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.21361771751852596,
        "compression_ratio": 1.4028776978417266,
        "end": 697.6199999999999,
        "id": 266,
        "no_speech_prob": 0.000030241844797274098,
        "seek": 67856,
        "start": 691.88,
        "temperature": 0,
        "text": " So I'm going to just say user ID by count.",
        "tokens": [
          51030,
          407,
          286,
          478,
          516,
          281,
          445,
          584,
          4195,
          7348,
          538,
          1207,
          13,
          51317
        ]
      },
      {
        "avg_logprob": -0.21361771751852596,
        "compression_ratio": 1.4028776978417266,
        "end": 701.16,
        "id": 267,
        "no_speech_prob": 0.000030241844797274098,
        "seek": 67856,
        "start": 697.6199999999999,
        "temperature": 0,
        "text": " And I'm going to say is an object.",
        "tokens": [
          51317,
          400,
          286,
          478,
          516,
          281,
          584,
          307,
          364,
          2657,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.43578022404720906,
        "compression_ratio": 1.606060606060606,
        "end": 703.76,
        "id": 268,
        "no_speech_prob": 0.0005792889278382063,
        "seek": 70116,
        "start": 701.8,
        "temperature": 0,
        "text": " OK, so what I want to do is I want",
        "tokens": [
          50396,
          2264,
          11,
          370,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          50494
        ]
      },
      {
        "avg_logprob": -0.43578022404720906,
        "compression_ratio": 1.606060606060606,
        "end": 712.64,
        "id": 269,
        "no_speech_prob": 0.0005792889278382063,
        "seek": 70116,
        "start": 703.76,
        "temperature": 0,
        "text": " to say if user ID by count of that, OK, so I need the ID,",
        "tokens": [
          50494,
          281,
          584,
          498,
          4195,
          7348,
          538,
          1207,
          295,
          300,
          11,
          2264,
          11,
          370,
          286,
          643,
          264,
          7348,
          11,
          50938
        ]
      },
      {
        "avg_logprob": -0.43578022404720906,
        "compression_ratio": 1.606060606060606,
        "end": 715.4399999999999,
        "id": 270,
        "no_speech_prob": 0.0005792889278382063,
        "seek": 70116,
        "start": 712.64,
        "temperature": 0,
        "text": " which is this.",
        "tokens": [
          50938,
          597,
          307,
          341,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.43578022404720906,
        "compression_ratio": 1.606060606060606,
        "end": 720.64,
        "id": 271,
        "no_speech_prob": 0.0005792889278382063,
        "seek": 70116,
        "start": 715.4399999999999,
        "temperature": 0,
        "text": " If user ID by count ID, it does not exist,",
        "tokens": [
          51078,
          759,
          4195,
          7348,
          538,
          1207,
          7348,
          11,
          309,
          775,
          406,
          2514,
          11,
          51338
        ]
      },
      {
        "avg_logprob": -0.43578022404720906,
        "compression_ratio": 1.606060606060606,
        "end": 725.24,
        "id": 272,
        "no_speech_prob": 0.0005792889278382063,
        "seek": 70116,
        "start": 720.64,
        "temperature": 0,
        "text": " then I want to set it to 1.",
        "tokens": [
          51338,
          550,
          286,
          528,
          281,
          992,
          309,
          281,
          502,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.43578022404720906,
        "compression_ratio": 1.606060606060606,
        "end": 729.56,
        "id": 273,
        "no_speech_prob": 0.0005792889278382063,
        "seek": 70116,
        "start": 725.24,
        "temperature": 0,
        "text": " Otherwise, I want to increase it.",
        "tokens": [
          51568,
          10328,
          11,
          286,
          528,
          281,
          3488,
          309,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.27129659518389637,
        "compression_ratio": 1.355263157894737,
        "end": 730.92,
        "id": 274,
        "no_speech_prob": 0.0005614666151814163,
        "seek": 72956,
        "start": 729.56,
        "temperature": 0,
        "text": " I want to increase it.",
        "tokens": [
          50364,
          286,
          528,
          281,
          3488,
          309,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.27129659518389637,
        "compression_ratio": 1.355263157894737,
        "end": 737.52,
        "id": 275,
        "no_speech_prob": 0.0005614666151814163,
        "seek": 72956,
        "start": 733.88,
        "temperature": 0,
        "text": " And then I want to console log that.",
        "tokens": [
          50580,
          400,
          550,
          286,
          528,
          281,
          11076,
          3565,
          300,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.27129659518389637,
        "compression_ratio": 1.355263157894737,
        "end": 743.8,
        "id": 276,
        "no_speech_prob": 0.0005614666151814163,
        "seek": 72956,
        "start": 737.52,
        "temperature": 0,
        "text": " So let's look at this should give me all the user IDs",
        "tokens": [
          50762,
          407,
          718,
          311,
          574,
          412,
          341,
          820,
          976,
          385,
          439,
          264,
          4195,
          48212,
          51076
        ]
      },
      {
        "avg_logprob": -0.27129659518389637,
        "compression_ratio": 1.355263157894737,
        "end": 748.2399999999999,
        "id": 277,
        "no_speech_prob": 0.0005614666151814163,
        "seek": 72956,
        "start": 743.8,
        "temperature": 0,
        "text": " by how many people, by how many entries they have.",
        "tokens": [
          51076,
          538,
          577,
          867,
          561,
          11,
          538,
          577,
          867,
          23041,
          436,
          362,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.27129659518389637,
        "compression_ratio": 1.355263157894737,
        "end": 757.4799999999999,
        "id": 278,
        "no_speech_prob": 0.0005614666151814163,
        "seek": 72956,
        "start": 748.2399999999999,
        "temperature": 0,
        "text": " So we can look 35, 33, 78, 147, 208, 189.",
        "tokens": [
          51298,
          407,
          321,
          393,
          574,
          6976,
          11,
          11816,
          11,
          26369,
          11,
          3499,
          22,
          11,
          945,
          23,
          11,
          2443,
          24,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 758.76,
        "id": 279,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 757.48,
        "temperature": 0,
        "text": " What's the record here?",
        "tokens": [
          50364,
          708,
          311,
          264,
          2136,
          510,
          30,
          50428
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 760.2,
        "id": 280,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 758.76,
        "temperature": 0,
        "text": " 201.",
        "tokens": [
          50428,
          1525,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 763.9200000000001,
        "id": 281,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 760.2,
        "temperature": 0,
        "text": " There was something I've already forgot, 236.",
        "tokens": [
          50500,
          821,
          390,
          746,
          286,
          600,
          1217,
          5298,
          11,
          6673,
          21,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 766.08,
        "id": 282,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 763.9200000000001,
        "temperature": 0,
        "text": " So is there anything suspicious here?",
        "tokens": [
          50686,
          407,
          307,
          456,
          1340,
          17931,
          510,
          30,
          50794
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 767.88,
        "id": 283,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 766.08,
        "temperature": 0,
        "text": " That's the question.",
        "tokens": [
          50794,
          663,
          311,
          264,
          1168,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 769.88,
        "id": 284,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 767.88,
        "temperature": 0,
        "text": " All right, it's probably worth me sorting this.",
        "tokens": [
          50884,
          1057,
          558,
          11,
          309,
          311,
          1391,
          3163,
          385,
          32411,
          341,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 772.48,
        "id": 285,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 769.88,
        "temperature": 0,
        "text": " This is why I should just put everything into a spreadsheet.",
        "tokens": [
          50984,
          639,
          307,
          983,
          286,
          820,
          445,
          829,
          1203,
          666,
          257,
          27733,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 774.88,
        "id": 286,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 772.48,
        "temperature": 0,
        "text": " But I'm just going to sort it myself.",
        "tokens": [
          51114,
          583,
          286,
          478,
          445,
          516,
          281,
          1333,
          309,
          2059,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 778.28,
        "id": 287,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 774.88,
        "temperature": 0,
        "text": " So in order to sort it, I want users.",
        "tokens": [
          51234,
          407,
          294,
          1668,
          281,
          1333,
          309,
          11,
          286,
          528,
          5022,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 780.94,
        "id": 288,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 778.28,
        "temperature": 0,
        "text": " I'm also going to have an array that I'm going to sort.",
        "tokens": [
          51404,
          286,
          478,
          611,
          516,
          281,
          362,
          364,
          10225,
          300,
          286,
          478,
          516,
          281,
          1333,
          13,
          51537
        ]
      },
      {
        "avg_logprob": -0.2276279216504279,
        "compression_ratio": 1.6311787072243347,
        "end": 786.08,
        "id": 289,
        "no_speech_prob": 0.00014425920380745083,
        "seek": 75748,
        "start": 780.94,
        "temperature": 0,
        "text": " And so if I find a new ID, I'll put that in the array.",
        "tokens": [
          51537,
          400,
          370,
          498,
          286,
          915,
          257,
          777,
          7348,
          11,
          286,
          603,
          829,
          300,
          294,
          264,
          10225,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.21138089497884113,
        "compression_ratio": 1.4126984126984128,
        "end": 790.9200000000001,
        "id": 290,
        "no_speech_prob": 0.0000036688611544377636,
        "seek": 78608,
        "start": 786.08,
        "temperature": 0,
        "text": " And then I want to say users.sort.",
        "tokens": [
          50364,
          400,
          550,
          286,
          528,
          281,
          584,
          5022,
          13,
          82,
          477,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.21138089497884113,
        "compression_ratio": 1.4126984126984128,
        "end": 794.24,
        "id": 291,
        "no_speech_prob": 0.0000036688611544377636,
        "seek": 78608,
        "start": 790.9200000000001,
        "temperature": 0,
        "text": " And now I need a comparing function",
        "tokens": [
          50606,
          400,
          586,
          286,
          643,
          257,
          15763,
          2445,
          50772
        ]
      },
      {
        "avg_logprob": -0.21138089497884113,
        "compression_ratio": 1.4126984126984128,
        "end": 798.96,
        "id": 292,
        "no_speech_prob": 0.0000036688611544377636,
        "seek": 78608,
        "start": 794.24,
        "temperature": 0,
        "text": " to compare two of them, A, B. And I'm just",
        "tokens": [
          50772,
          281,
          6794,
          732,
          295,
          552,
          11,
          316,
          11,
          363,
          13,
          400,
          286,
          478,
          445,
          51008
        ]
      },
      {
        "avg_logprob": -0.21138089497884113,
        "compression_ratio": 1.4126984126984128,
        "end": 811.0400000000001,
        "id": 293,
        "no_speech_prob": 0.0000036688611544377636,
        "seek": 78608,
        "start": 798.96,
        "temperature": 0,
        "text": " going to say return user ID by count A minus user ID",
        "tokens": [
          51008,
          516,
          281,
          584,
          2736,
          4195,
          7348,
          538,
          1207,
          316,
          3175,
          4195,
          7348,
          51612
        ]
      },
      {
        "avg_logprob": -0.21138089497884113,
        "compression_ratio": 1.4126984126984128,
        "end": 813.12,
        "id": 294,
        "no_speech_prob": 0.0000036688611544377636,
        "seek": 78608,
        "start": 811.0400000000001,
        "temperature": 0,
        "text": " by count B.",
        "tokens": [
          51612,
          538,
          1207,
          363,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.2803054150239921,
        "compression_ratio": 1.6582278481012658,
        "end": 814.76,
        "id": 295,
        "no_speech_prob": 0.000012805455298803281,
        "seek": 81312,
        "start": 813.12,
        "temperature": 0,
        "text": " So that'll sort the array.",
        "tokens": [
          50364,
          407,
          300,
          603,
          1333,
          264,
          10225,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2803054150239921,
        "compression_ratio": 1.6582278481012658,
        "end": 821.84,
        "id": 296,
        "no_speech_prob": 0.000012805455298803281,
        "seek": 81312,
        "start": 817.92,
        "temperature": 0,
        "text": " And sorting probably makes a new array, I think.",
        "tokens": [
          50604,
          400,
          32411,
          1391,
          1669,
          257,
          777,
          10225,
          11,
          286,
          519,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.2803054150239921,
        "compression_ratio": 1.6582278481012658,
        "end": 822.5600000000001,
        "id": 297,
        "no_speech_prob": 0.000012805455298803281,
        "seek": 81312,
        "start": 821.84,
        "temperature": 0,
        "text": " I can't remember.",
        "tokens": [
          50800,
          286,
          393,
          380,
          1604,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2803054150239921,
        "compression_ratio": 1.6582278481012658,
        "end": 825.08,
        "id": 298,
        "no_speech_prob": 0.000012805455298803281,
        "seek": 81312,
        "start": 822.5600000000001,
        "temperature": 0,
        "text": " Does it change the array or make a new array?",
        "tokens": [
          50836,
          4402,
          309,
          1319,
          264,
          10225,
          420,
          652,
          257,
          777,
          10225,
          30,
          50962
        ]
      },
      {
        "avg_logprob": -0.2803054150239921,
        "compression_ratio": 1.6582278481012658,
        "end": 827.84,
        "id": 299,
        "no_speech_prob": 0.000012805455298803281,
        "seek": 81312,
        "start": 825.08,
        "temperature": 0,
        "text": " So I want to sort the users array.",
        "tokens": [
          50962,
          407,
          286,
          528,
          281,
          1333,
          264,
          5022,
          10225,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2803054150239921,
        "compression_ratio": 1.6582278481012658,
        "end": 835.76,
        "id": 300,
        "no_speech_prob": 0.000012805455298803281,
        "seek": 81312,
        "start": 827.84,
        "temperature": 0,
        "text": " And then I'm just going to do let ID of users.",
        "tokens": [
          51100,
          400,
          550,
          286,
          478,
          445,
          516,
          281,
          360,
          718,
          7348,
          295,
          5022,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2803054150239921,
        "compression_ratio": 1.6582278481012658,
        "end": 837.5600000000001,
        "id": 301,
        "no_speech_prob": 0.000012805455298803281,
        "seek": 81312,
        "start": 835.76,
        "temperature": 0,
        "text": " I'm just going to iterate over the array",
        "tokens": [
          51496,
          286,
          478,
          445,
          516,
          281,
          44497,
          670,
          264,
          10225,
          51586
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 849.88,
        "id": 302,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 837.56,
        "temperature": 0,
        "text": " and console.log user ID plus user ID by count for that one.",
        "tokens": [
          50364,
          293,
          11076,
          13,
          4987,
          4195,
          7348,
          1804,
          4195,
          7348,
          538,
          1207,
          337,
          300,
          472,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 852.56,
        "id": 303,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 849.88,
        "temperature": 0,
        "text": " So I know I'm kind of like, whoops.",
        "tokens": [
          50980,
          407,
          286,
          458,
          286,
          478,
          733,
          295,
          411,
          11,
          567,
          3370,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 854.88,
        "id": 304,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 852.56,
        "temperature": 0,
        "text": " This would be a good time for me to use those new string",
        "tokens": [
          51114,
          639,
          576,
          312,
          257,
          665,
          565,
          337,
          385,
          281,
          764,
          729,
          777,
          6798,
          51230
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 856,
        "id": 305,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 854.88,
        "temperature": 0,
        "text": " literals.",
        "tokens": [
          51230,
          2733,
          1124,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 858.16,
        "id": 306,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 856,
        "temperature": 0,
        "text": " Someday I'll get to that.",
        "tokens": [
          51286,
          12297,
          16826,
          286,
          603,
          483,
          281,
          300,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 859.3199999999999,
        "id": 307,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 858.16,
        "temperature": 0,
        "text": " So let's take a look at this.",
        "tokens": [
          51394,
          407,
          718,
          311,
          747,
          257,
          574,
          412,
          341,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 862.04,
        "id": 308,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 859.3199999999999,
        "temperature": 0,
        "text": " What did I get wrong?",
        "tokens": [
          51452,
          708,
          630,
          286,
          483,
          2085,
          30,
          51588
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 862.7199999999999,
        "id": 309,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 862.04,
        "temperature": 0,
        "text": " Looks like I did.",
        "tokens": [
          51588,
          10027,
          411,
          286,
          630,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 863.52,
        "id": 310,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 862.7199999999999,
        "temperature": 0,
        "text": " That worked.",
        "tokens": [
          51622,
          663,
          2732,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 865.04,
        "id": 311,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 863.52,
        "temperature": 0,
        "text": " Amazingly, that worked.",
        "tokens": [
          51662,
          14165,
          356,
          11,
          300,
          2732,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.26624652558723383,
        "compression_ratio": 1.509090909090909,
        "end": 866.88,
        "id": 312,
        "no_speech_prob": 0.0000748460297472775,
        "seek": 83756,
        "start": 865.04,
        "temperature": 0,
        "text": " So we can see somebody just did one.",
        "tokens": [
          51738,
          407,
          321,
          393,
          536,
          2618,
          445,
          630,
          472,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 867.72,
        "id": 313,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 866.88,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50364,
          1044,
          291,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 872.04,
        "id": 314,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 867.72,
        "temperature": 0,
        "text": " Thank you, Noah, who did one.",
        "tokens": [
          50406,
          1044,
          291,
          11,
          20895,
          11,
          567,
          630,
          472,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 876.24,
        "id": 315,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 872.04,
        "temperature": 0,
        "text": " And then we can see here 236 entries",
        "tokens": [
          50622,
          400,
          550,
          321,
          393,
          536,
          510,
          6673,
          21,
          23041,
          50832
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 879.08,
        "id": 316,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 876.24,
        "temperature": 0,
        "text": " from this particular user.",
        "tokens": [
          50832,
          490,
          341,
          1729,
          4195,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 882.24,
        "id": 317,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 879.08,
        "temperature": 0,
        "text": " All right, these, by the way, are called template literals,",
        "tokens": [
          50974,
          1057,
          558,
          11,
          613,
          11,
          538,
          264,
          636,
          11,
          366,
          1219,
          12379,
          2733,
          1124,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 882.92,
        "id": 318,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 882.24,
        "temperature": 0,
        "text": " is what I meant.",
        "tokens": [
          51132,
          307,
          437,
          286,
          4140,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 885.24,
        "id": 319,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 882.92,
        "temperature": 0,
        "text": " By the way, since I mentioned it, let's actually use it.",
        "tokens": [
          51166,
          3146,
          264,
          636,
          11,
          1670,
          286,
          2835,
          309,
          11,
          718,
          311,
          767,
          764,
          309,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 887.04,
        "id": 320,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 885.24,
        "temperature": 0,
        "text": " This is a new feature of ES6.",
        "tokens": [
          51282,
          639,
          307,
          257,
          777,
          4111,
          295,
          12564,
          21,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 887.56,
        "id": 321,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 887.04,
        "temperature": 0,
        "text": " I'm here.",
        "tokens": [
          51372,
          286,
          478,
          510,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 888.6,
        "id": 322,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 887.56,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51398,
          1545,
          406,
          30,
          51450
        ]
      },
      {
        "avg_logprob": -0.2724362406237372,
        "compression_ratio": 1.463519313304721,
        "end": 896.64,
        "id": 323,
        "no_speech_prob": 0.00010229918552795425,
        "seek": 86688,
        "start": 888.6,
        "temperature": 0,
        "text": " Where if I use backtick, I can create a string that's",
        "tokens": [
          51450,
          2305,
          498,
          286,
          764,
          646,
          83,
          618,
          11,
          286,
          393,
          1884,
          257,
          6798,
          300,
          311,
          51852
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 901.64,
        "id": 324,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 897.4,
        "temperature": 0,
        "text": " just with variables with this syntax, I believe.",
        "tokens": [
          50402,
          445,
          365,
          9102,
          365,
          341,
          28431,
          11,
          286,
          1697,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 902.56,
        "id": 325,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 901.64,
        "temperature": 0,
        "text": " Does this go out here?",
        "tokens": [
          50614,
          4402,
          341,
          352,
          484,
          510,
          30,
          50660
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 904.08,
        "id": 326,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 902.56,
        "temperature": 0,
        "text": " Yes, that goes there.",
        "tokens": [
          50660,
          1079,
          11,
          300,
          1709,
          456,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 909,
        "id": 327,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 904.08,
        "temperature": 0,
        "text": " So what this does is, in other words,",
        "tokens": [
          50736,
          407,
          437,
          341,
          775,
          307,
          11,
          294,
          661,
          2283,
          11,
          50982
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 914.16,
        "id": 328,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 909,
        "temperature": 0,
        "text": " I could say user submitted.",
        "tokens": [
          50982,
          286,
          727,
          584,
          4195,
          14405,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 916.8,
        "id": 329,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 914.16,
        "temperature": 0,
        "text": " So I can just write a full string.",
        "tokens": [
          51240,
          407,
          286,
          393,
          445,
          2464,
          257,
          1577,
          6798,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 918.3199999999999,
        "id": 330,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 916.8,
        "temperature": 0,
        "text": " And then basically, anything that's",
        "tokens": [
          51372,
          400,
          550,
          1936,
          11,
          1340,
          300,
          311,
          51448
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 921.08,
        "id": 331,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 918.3199999999999,
        "temperature": 0,
        "text": " in between these dollar sign and curly brackets",
        "tokens": [
          51448,
          294,
          1296,
          613,
          7241,
          1465,
          293,
          32066,
          26179,
          51586
        ]
      },
      {
        "avg_logprob": -0.2536702959725026,
        "compression_ratio": 1.5170731707317073,
        "end": 923.76,
        "id": 332,
        "no_speech_prob": 0.00001952586171682924,
        "seek": 89664,
        "start": 921.08,
        "temperature": 0,
        "text": " is rendered as a variable value.",
        "tokens": [
          51586,
          307,
          28748,
          382,
          257,
          7006,
          2158,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.2509968426762795,
        "compression_ratio": 1.5330188679245282,
        "end": 931.36,
        "id": 333,
        "no_speech_prob": 0.0000772210187278688,
        "seek": 92376,
        "start": 923.76,
        "temperature": 0,
        "text": " So now if I run this again, I don't know why that didn't.",
        "tokens": [
          50364,
          407,
          586,
          498,
          286,
          1190,
          341,
          797,
          11,
          286,
          500,
          380,
          458,
          983,
          300,
          994,
          380,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2509968426762795,
        "compression_ratio": 1.5330188679245282,
        "end": 933.72,
        "id": 334,
        "no_speech_prob": 0.0000772210187278688,
        "seek": 92376,
        "start": 931.36,
        "temperature": 0,
        "text": " Yes, you can see now it has that full.",
        "tokens": [
          50744,
          1079,
          11,
          291,
          393,
          536,
          586,
          309,
          575,
          300,
          1577,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2509968426762795,
        "compression_ratio": 1.5330188679245282,
        "end": 936.56,
        "id": 335,
        "no_speech_prob": 0.0000772210187278688,
        "seek": 92376,
        "start": 933.72,
        "temperature": 0,
        "text": " And I kind of don't want all this extra stuff.",
        "tokens": [
          50862,
          400,
          286,
          733,
          295,
          500,
          380,
          528,
          439,
          341,
          2857,
          1507,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.2509968426762795,
        "compression_ratio": 1.5330188679245282,
        "end": 939.3199999999999,
        "id": 336,
        "no_speech_prob": 0.0000772210187278688,
        "seek": 92376,
        "start": 936.56,
        "temperature": 0,
        "text": " But I was just showing you that you can put together a string.",
        "tokens": [
          51004,
          583,
          286,
          390,
          445,
          4099,
          291,
          300,
          291,
          393,
          829,
          1214,
          257,
          6798,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.2509968426762795,
        "compression_ratio": 1.5330188679245282,
        "end": 942.6,
        "id": 337,
        "no_speech_prob": 0.0000772210187278688,
        "seek": 92376,
        "start": 939.3199999999999,
        "temperature": 0,
        "text": " And so, OK, so I happen to know, based",
        "tokens": [
          51142,
          400,
          370,
          11,
          2264,
          11,
          370,
          286,
          1051,
          281,
          458,
          11,
          2361,
          51306
        ]
      },
      {
        "avg_logprob": -0.2509968426762795,
        "compression_ratio": 1.5330188679245282,
        "end": 946.04,
        "id": 338,
        "no_speech_prob": 0.0000772210187278688,
        "seek": 92376,
        "start": 942.6,
        "temperature": 0,
        "text": " on earlier research of the day and watching",
        "tokens": [
          51306,
          322,
          3071,
          2132,
          295,
          264,
          786,
          293,
          1976,
          51478
        ]
      },
      {
        "avg_logprob": -0.2509968426762795,
        "compression_ratio": 1.5330188679245282,
        "end": 951.24,
        "id": 339,
        "no_speech_prob": 0.0000772210187278688,
        "seek": 92376,
        "start": 946.04,
        "temperature": 0,
        "text": " that this particular user is a bot.",
        "tokens": [
          51478,
          300,
          341,
          1729,
          4195,
          307,
          257,
          10592,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 953.84,
        "id": 340,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 951.24,
        "temperature": 0,
        "text": " But I am getting the suggestion from the chat",
        "tokens": [
          50364,
          583,
          286,
          669,
          1242,
          264,
          16541,
          490,
          264,
          5081,
          50494
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 958.96,
        "id": 341,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 953.84,
        "temperature": 0,
        "text": " to just discard anything that's over 100.",
        "tokens": [
          50494,
          281,
          445,
          31597,
          1340,
          300,
          311,
          670,
          2319,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 960.36,
        "id": 342,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 958.96,
        "temperature": 0,
        "text": " So it looks like this.",
        "tokens": [
          50750,
          407,
          309,
          1542,
          411,
          341,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 964,
        "id": 343,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 960.36,
        "temperature": 0,
        "text": " So those are ways that I can do this.",
        "tokens": [
          50820,
          407,
          729,
          366,
          2098,
          300,
          286,
          393,
          360,
          341,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 965.92,
        "id": 344,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 964,
        "temperature": 0,
        "text": " Another correction I just got is that I",
        "tokens": [
          51002,
          3996,
          19984,
          286,
          445,
          658,
          307,
          300,
          286,
          51098
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 970.72,
        "id": 345,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 965.92,
        "temperature": 0,
        "text": " believe users.sort actually changes the array.",
        "tokens": [
          51098,
          1697,
          5022,
          13,
          82,
          477,
          767,
          2962,
          264,
          10225,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 974.12,
        "id": 346,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 970.72,
        "temperature": 0,
        "text": " And since I've started using arrow syntax,",
        "tokens": [
          51338,
          400,
          1670,
          286,
          600,
          1409,
          1228,
          11610,
          28431,
          11,
          51508
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 977.36,
        "id": 347,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 974.12,
        "temperature": 0,
        "text": " I could write it this way, which is perhaps a bit more readable.",
        "tokens": [
          51508,
          286,
          727,
          2464,
          309,
          341,
          636,
          11,
          597,
          307,
          4317,
          257,
          857,
          544,
          49857,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 978.6,
        "id": 348,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 977.36,
        "temperature": 0,
        "text": " But who knows?",
        "tokens": [
          51670,
          583,
          567,
          3255,
          30,
          51732
        ]
      },
      {
        "avg_logprob": -0.2475419411292443,
        "compression_ratio": 1.5210084033613445,
        "end": 979.48,
        "id": 349,
        "no_speech_prob": 0.000037636298657162115,
        "seek": 95124,
        "start": 978.6,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51732,
          2264,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 983.2,
        "id": 350,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 979.48,
        "temperature": 0,
        "text": " All right, so the question here really is what to do next.",
        "tokens": [
          50364,
          1057,
          558,
          11,
          370,
          264,
          1168,
          510,
          534,
          307,
          437,
          281,
          360,
          958,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 986.12,
        "id": 351,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 983.2,
        "temperature": 0,
        "text": " I know that this, from my analysis earlier,",
        "tokens": [
          50550,
          286,
          458,
          300,
          341,
          11,
          490,
          452,
          5215,
          3071,
          11,
          50696
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 989.08,
        "id": 352,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 986.12,
        "temperature": 0,
        "text": " looking at the things being added to the database,",
        "tokens": [
          50696,
          1237,
          412,
          264,
          721,
          885,
          3869,
          281,
          264,
          8149,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 991.72,
        "id": 353,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 989.08,
        "temperature": 0,
        "text": " that this appeared to be a bot.",
        "tokens": [
          50844,
          300,
          341,
          8516,
          281,
          312,
          257,
          10592,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 996.24,
        "id": 354,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 991.72,
        "temperature": 0,
        "text": " I also could, the chat suggested I could just remove everything",
        "tokens": [
          50976,
          286,
          611,
          727,
          11,
          264,
          5081,
          10945,
          286,
          727,
          445,
          4159,
          1203,
          51202
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 997.64,
        "id": 355,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 996.24,
        "temperature": 0,
        "text": " that's 100 or more.",
        "tokens": [
          51202,
          300,
          311,
          2319,
          420,
          544,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 999.52,
        "id": 356,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 997.64,
        "temperature": 0,
        "text": " I'm actually going to stop this tutorial.",
        "tokens": [
          51272,
          286,
          478,
          767,
          516,
          281,
          1590,
          341,
          7073,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 1000.76,
        "id": 357,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 999.52,
        "temperature": 0,
        "text": " This was sort of like getting to actually",
        "tokens": [
          51366,
          639,
          390,
          1333,
          295,
          411,
          1242,
          281,
          767,
          51428
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 1002.0600000000001,
        "id": 358,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 1000.76,
        "temperature": 0,
        "text": " being able to look at the data.",
        "tokens": [
          51428,
          885,
          1075,
          281,
          574,
          412,
          264,
          1412,
          13,
          51493
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 1003.84,
        "id": 359,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 1002.0600000000001,
        "temperature": 0,
        "text": " And I'm going to do a whole next video,",
        "tokens": [
          51493,
          400,
          286,
          478,
          516,
          281,
          360,
          257,
          1379,
          958,
          960,
          11,
          51582
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 1005.36,
        "id": 360,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 1003.84,
        "temperature": 0,
        "text": " because what I think might be useful",
        "tokens": [
          51582,
          570,
          437,
          286,
          519,
          1062,
          312,
          4420,
          51658
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 1006.72,
        "id": 361,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 1005.36,
        "temperature": 0,
        "text": " is actually just look at the data.",
        "tokens": [
          51658,
          307,
          767,
          445,
          574,
          412,
          264,
          1412,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.24669237201716623,
        "compression_ratio": 1.7828947368421053,
        "end": 1009.04,
        "id": 362,
        "no_speech_prob": 0.00017400398792233318,
        "seek": 97948,
        "start": 1006.72,
        "temperature": 0,
        "text": " Because this is information I can visualize.",
        "tokens": [
          51726,
          1436,
          341,
          307,
          1589,
          286,
          393,
          23273,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1011.0799999999999,
        "id": 363,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1009.12,
        "temperature": 0,
        "text": " I could say, show me everything that's pinkish.",
        "tokens": [
          50368,
          286,
          727,
          584,
          11,
          855,
          385,
          1203,
          300,
          311,
          7022,
          742,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1012.56,
        "id": 364,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1011.0799999999999,
        "temperature": 0,
        "text": " Show me everything that's bluish.",
        "tokens": [
          50466,
          6895,
          385,
          1203,
          300,
          311,
          888,
          33786,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1014.28,
        "id": 365,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1012.56,
        "temperature": 0,
        "text": " And I could also say, ignore this.",
        "tokens": [
          50540,
          400,
          286,
          727,
          611,
          584,
          11,
          11200,
          341,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1017.24,
        "id": 366,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1014.28,
        "temperature": 0,
        "text": " I could see by user what they, I could actually",
        "tokens": [
          50626,
          286,
          727,
          536,
          538,
          4195,
          437,
          436,
          11,
          286,
          727,
          767,
          50774
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1018.68,
        "id": 367,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1017.24,
        "temperature": 0,
        "text": " look at what they assigned.",
        "tokens": [
          50774,
          574,
          412,
          437,
          436,
          13279,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1020.76,
        "id": 368,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1018.68,
        "temperature": 0,
        "text": " So I could try to see is something really just way",
        "tokens": [
          50846,
          407,
          286,
          727,
          853,
          281,
          536,
          307,
          746,
          534,
          445,
          636,
          50950
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1022.68,
        "id": 369,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1020.76,
        "temperature": 0,
        "text": " out there that maybe I shouldn't include.",
        "tokens": [
          50950,
          484,
          456,
          300,
          1310,
          286,
          4659,
          380,
          4090,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1024.72,
        "id": 370,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1022.68,
        "temperature": 0,
        "text": " So that's what I'm going to do in the next video.",
        "tokens": [
          51046,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          264,
          958,
          960,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.2935788631439209,
        "compression_ratio": 1.812206572769953,
        "end": 1026.84,
        "id": 371,
        "no_speech_prob": 0.00023050306481309235,
        "seek": 100904,
        "start": 1024.72,
        "temperature": 0,
        "text": " I'm going to add some tools to visualize the data.",
        "tokens": [
          51148,
          286,
          478,
          516,
          281,
          909,
          512,
          3873,
          281,
          23273,
          264,
          1412,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.9237004915873209,
        "compression_ratio": 0.5555555555555556,
        "end": 1028.6,
        "id": 372,
        "no_speech_prob": 0.5827977061271667,
        "seek": 102684,
        "start": 1026.84,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50374,
          1044,
          291,
          13,
          50452
        ]
      }
    ],
    "transcription": " Hello. Welcome to the third video in my build a classifier with p5.js and TensorFlow.js. And there's a neural network in there. So I'm really exploring this machine learning library TensorFlow.js. And I wanted to come up with a creative example that shows the full classification process from collecting data, training, and then deploying a machine learning model. And so the example that I'm working with is this idea of color classification. So I'm crowdsourcing this data from you, the viewing audience. And if I look at this, so you might remember, I built this little web app in the previous video, I think. That was yesterday. And then now it's today, 24 hours later. It's been improved. Thank you to the internet, the wonderful people who have pull requested various design fixes and updates. You can check all that out on GitHub to see who the contributors were. Now, let me add a few things here. Brown, that's kind of brown. That's purplish. That's bluish. Now, one thing I will mention, thank you to Bruno, who brought this up in the patron Slack channel. I sort of said yesterday, I just want to pick a trivial data set. I want to make something that has very little sort of meaningfulness to it, just to sort of demonstrate the whole process. But there is something kind of interesting going on here in theory, which is that we're looking at human perception. And I'm not mathematically labeling a color according to the RGB values. I'm asking you, the viewers, to tell me what you think a color is. And so there is a lot of interesting scientific research in this area. And I'll reference this video that talks about Berkeley researchers and other research around the surprising pattern behind color names around the world. So there's a lot there that you could dig into. So maybe there's more here than I might originally have thought. The problem with what I built over here is that you're wonderful. I love all of you who watch these videos and leave me nice feedback, leave me critical feedback, and all that sort of stuff. But the database is a little bit off the rails, because I just left the rules wide open. Anybody can write, and anybody can read to the database. And so thankfully, Panzer on GitHub left a pull request analyzing the data and looking at, OK, well, there's a lot of stuff here that looks wrong. Maybe there were some bots that started classifying colors. And so I wrote all these functions to analyze and filter the data. So I encourage you to check out this wonderful pull request. This pull request is now part of the repository. However, I took a slightly different approach, and thanks to meiamsome, who helped me with this, which is that I changed the rules. So the rules yesterday were just basically read true, write true. These are the Firebase rules. And meiamsome helped me look into how you could customize the rules. And the things that have been added to the rules now are we have some things to validate to make sure the RGB values being put in the database are actually numbers. So you can see how this looks here. New data is a number, and it's between 0 and 255. We have something to validate that the label, one of the things that people put other words that weren't part of my set of classification labels into the database. So I have to check that it's a string and that the actual data's value matches this regular expression. So if you've never seen regular expressions before, I do happen to have a video series about that that you could go watch. But this, you can see that it matches any of these dash-ish. So that's protecting. And then authentication was turned on. So what you don't see is that it's anonymous authentication, but you can only write if you've been authenticated. This way, it's anonymous. I can track every person or every entry. It's not necessarily a person, but every entry from a particular IP address into the database with a unique ID. So if I can see that there's a bot that's just flooding the database, I could either block it or just clean that data out of it. So that's what I'm going to do in this video. I'm going to use a similar approach to this pull request. I'm going to actually read the data from the database. And then I'm going to analyze it and delete stuff if it seems like it's no good, and then download a JSON file that I'll then use in the TensorFlow.js example that I'm going to build. Did I just spend the whole video introducing this topic? I think I might have. But I'm going to move on and keep going anyway. Before I dig into the code, let me just reference one more web page to you. I want to show you this is a project that's at the time of this recording. It hasn't technically been released yet, although you can find it at ml5js.org. And it probably is released now that you're watching this video. But ml5 is a machine learning library built on top of TensorFlow.js that I and other folks at ITP have been working on. And I just want to reference Hannah Davis, who's an artist and researcher who's a contributor to ml5, wrote this wonderful tutorial about making your own data sets and thinking about questions to ask, in particular about responsible data collection and tagging and crowdsourcing. So hopefully, we'll come back to this topic again and again in my video tutorials. But I would encourage you to check this out and really think about it. I mean, one thing we could think about here is, number one, I'm building an example that requires people to see the colors. So what about people who are colorblind, low vision, or blind? That's something I really should be thoughtful about in this example. How can I approach that? Who's really able to participate in tagging and submitting data? Who's being left out? So I think the good news for me is that this is meant to be somewhat of a generic tutorial. And the data, wow, doesn't matter so much if it's perfect, because I just want to show that whole process. But you then actually being a person who might work with machine learning out in the real world, you really want to be thoughtful about that data. And I hope that I can link to more resources about that and cover that more on this channel as well. So all that aside, now I'm ready to dig in and look at the data and do the thing that's probably going to take me the next 24 hours, or three days, or three weeks, try to clean the data and make it usable for me. So yeah, that's what I'm going to do. OK, so I have a client. I mean, I could do this. I could download the data directly from Firebase and just put it in a Google Sheet to look at it. That might be useful. But what I'm going to do is I'm just going to actually write a p5 sketch, or just a JavaScript program, to look at the data first. So I have this sketch. All that's in it so far is just that connect to Firebase and authenticate. So what I want to do is to retrieve data. I think I say something like database once, value. And then I have a callback like got data. I don't know if this is right. And by the way, I've learned that the JavaScript recently, the JavaScript convention, which is not how p5 necessarily works, is often the error is first as callback arguments. And then the results is second. I don't know. I'm just speculating what the Firebase API might be like. Let's see what happens. Database once is not a function. I probably need.ref. And then I probably need colors or something, right? Probably something like this. I could just go and look on the documentation. I also have this Firebase tutorial. Oh, yeah, I need the database reference. And then in my tutorial, I say.on, but really, oh, got one and got error data. So maybe there's two callbacks. Who knows? Who knows? Let's say, let's do this. Let ref equal database ref colors. And then let's say ref once value got data. And let's look and see what comes back. All right. Let's go back to here. All right, something came back. No, nothing came back. 19. All right, what's going on here? Maybe I should go back and look at my actual example. Got one, error data. So let's, oh, that's a pointer to the data. Right. So actually, the data, so it actually is a separate callback for error, looks like. So I'm going to not worry about the error callback right now. I'm going to use got data. And then let's look at the results. And so, yeah, this looks weird. Like, how could I possibly use this? So what you're actually getting back is this pointer to the data. You've got to call functions on it to actually look at what's there. So presumably, something like results.value is probably what the API is. No, it's not a function. So I have to go back and look at my tutorial..val. Let's try that. Let's try.val. And there we go. Look at this. Oh, it's a lot of data. Boy, the console is not able to render this. So now, is this actually an array? Ah, it's just actually an object with all the data in it. So I need to turn that into an array. Because I kind of want to loop through it. I wonder what the, oh, you know what I'll do. This is what I'm going to do. I am going to, so now I'm going to process the data. So first, let me just get all the keys. So I can say object.keys. So let me just say let data equal results.val. Let's not console log that. Object.keys data. And then console.log keys.length. And I don't need this page anymore. I'm going back to here, clean data. So there's 5,902 entries into the database. This is never going to change. Because just while I'm recording this video, I shut off the ability to write to the database. So what we can actually start to do now is I could say for let key of keys. And I could say let record equals data key. And I could say console.log record. So this is going to log all 5,000 of those one at a time, I think. So I can see these are all just logging every single data point. And we can see that for every single one, there's an R, a G, and a B, the label, and then this user ID. So now I think there was, I'm watching the database this morning. I think there was a bot that was posting to it. So now it's possible it could be that there's just one person who actually clicked a lot of times. But so what I'm going to do right now to just examine the data a little bit is I am going to look at the user by user ID and count up how many entries for each user ID. So I basically need to do something like a concordance. So if I say UID, if I look at that, we can see there's all the user IDs. And what I want to do now is just associate. So I'm going to just say user ID by count. And I'm going to say is an object. OK, so what I want to do is I want to say if user ID by count of that, OK, so I need the ID, which is this. If user ID by count ID, it does not exist, then I want to set it to 1. Otherwise, I want to increase it. I want to increase it. And then I want to console log that. So let's look at this should give me all the user IDs by how many people, by how many entries they have. So we can look 35, 33, 78, 147, 208, 189. What's the record here? 201. There was something I've already forgot, 236. So is there anything suspicious here? That's the question. All right, it's probably worth me sorting this. This is why I should just put everything into a spreadsheet. But I'm just going to sort it myself. So in order to sort it, I want users. I'm also going to have an array that I'm going to sort. And so if I find a new ID, I'll put that in the array. And then I want to say users.sort. And now I need a comparing function to compare two of them, A, B. And I'm just going to say return user ID by count A minus user ID by count B. So that'll sort the array. And sorting probably makes a new array, I think. I can't remember. Does it change the array or make a new array? So I want to sort the users array. And then I'm just going to do let ID of users. I'm just going to iterate over the array and console.log user ID plus user ID by count for that one. So I know I'm kind of like, whoops. This would be a good time for me to use those new string literals. Someday I'll get to that. So let's take a look at this. What did I get wrong? Looks like I did. That worked. Amazingly, that worked. So we can see somebody just did one. Thank you. Thank you, Noah, who did one. And then we can see here 236 entries from this particular user. All right, these, by the way, are called template literals, is what I meant. By the way, since I mentioned it, let's actually use it. This is a new feature of ES6. I'm here. Why not? Where if I use backtick, I can create a string that's just with variables with this syntax, I believe. Does this go out here? Yes, that goes there. So what this does is, in other words, I could say user submitted. So I can just write a full string. And then basically, anything that's in between these dollar sign and curly brackets is rendered as a variable value. So now if I run this again, I don't know why that didn't. Yes, you can see now it has that full. And I kind of don't want all this extra stuff. But I was just showing you that you can put together a string. And so, OK, so I happen to know, based on earlier research of the day and watching that this particular user is a bot. But I am getting the suggestion from the chat to just discard anything that's over 100. So it looks like this. So those are ways that I can do this. Another correction I just got is that I believe users.sort actually changes the array. And since I've started using arrow syntax, I could write it this way, which is perhaps a bit more readable. But who knows? OK. All right, so the question here really is what to do next. I know that this, from my analysis earlier, looking at the things being added to the database, that this appeared to be a bot. I also could, the chat suggested I could just remove everything that's 100 or more. I'm actually going to stop this tutorial. This was sort of like getting to actually being able to look at the data. And I'm going to do a whole next video, because what I think might be useful is actually just look at the data. Because this is information I can visualize. I could say, show me everything that's pinkish. Show me everything that's bluish. And I could also say, ignore this. I could see by user what they, I could actually look at what they assigned. So I could try to see is something really just way out there that maybe I shouldn't include. So that's what I'm going to do in the next video. I'm going to add some tools to visualize the data. Thank you.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:46.98181Z",
  "started_at": "2023-09-26T21:17:20.465265Z",
  "completed_at": "2023-09-26T21:21:56.200535Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=Xrhrn8HaFPI",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 275.73527
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/fyuxudzbm6giyadjqrn7yqomzu/cancel",
    "get": "https://api.replicate.com/v1/predictions/fyuxudzbm6giyadjqrn7yqomzu"
  }
}