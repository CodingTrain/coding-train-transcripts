{
  "id": "bnnqufrb3alibm35ypbtk4jzyy",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/ASnCXW6pPSY.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/550352 [00:00<?, ?frames/s]\n  0%|          | 2736/550352 [00:29<1:37:42, 93.41frames/s]\n  1%|          | 5716/550352 [00:34<48:06, 188.69frames/s] \n  2%|▏         | 8456/550352 [00:41<35:51, 251.84frames/s]\n  2%|▏         | 11326/550352 [00:48<31:05, 288.91frames/s]\n  3%|▎         | 13782/550352 [00:54<27:30, 325.04frames/s]\n  3%|▎         | 16562/550352 [00:57<20:56, 424.84frames/s]\n  4%|▎         | 19390/550352 [01:02<19:04, 463.88frames/s]\n  4%|▍         | 21974/550352 [01:09<20:48, 423.23frames/s]\n  5%|▍         | 24970/550352 [01:16<20:56, 418.23frames/s]\n  5%|▌         | 27522/550352 [01:22<20:53, 417.18frames/s]\n  5%|▌         | 29252/550352 [01:26<20:05, 432.24frames/s]\n  6%|▌         | 32236/550352 [01:32<19:36, 440.47frames/s]\n  6%|▋         | 35052/550352 [01:41<21:11, 405.27frames/s]\n  7%|▋         | 37596/550352 [01:45<19:39, 434.58frames/s]\n  7%|▋         | 40596/550352 [01:51<17:55, 474.13frames/s]\n  8%|▊         | 43308/550352 [01:56<17:06, 493.73frames/s]\n  8%|▊         | 46308/550352 [02:00<15:30, 541.49frames/s]\n  9%|▉         | 48948/550352 [02:03<14:00, 596.27frames/s]\n  9%|▉         | 51804/550352 [02:07<13:17, 625.43frames/s]\n 10%|▉         | 54804/550352 [02:13<13:53, 594.78frames/s]\n 10%|█         | 57716/550352 [02:21<16:51, 486.98frames/s]\n 11%|█         | 60716/550352 [02:27<16:33, 492.85frames/s]\n 11%|█▏        | 62780/550352 [02:32<16:52, 481.63frames/s]\n 12%|█▏        | 65284/550352 [02:37<16:46, 481.95frames/s]\n 12%|█▏        | 67732/550352 [02:43<17:46, 452.72frames/s]\n 13%|█▎        | 70396/550352 [02:50<18:28, 433.14frames/s]\n 13%|█▎        | 72564/550352 [02:55<17:52, 445.48frames/s]\n 14%|█▎        | 75076/550352 [02:58<15:39, 506.13frames/s]\n 14%|█▍        | 78076/550352 [03:03<15:10, 518.48frames/s]\n 15%|█▍        | 80980/550352 [03:09<14:42, 531.95frames/s]\n 15%|█▌        | 83236/550352 [03:13<14:47, 526.41frames/s]\n 16%|█▌        | 85476/550352 [03:19<16:01, 483.39frames/s]\n 16%|█▌        | 87908/550352 [03:23<15:26, 499.24frames/s]\n 16%|█▋        | 90076/550352 [03:27<15:17, 501.88frames/s]\n 17%|█▋        | 93076/550352 [03:30<12:15, 621.56frames/s]\n 17%|█▋        | 95604/550352 [03:33<11:00, 688.21frames/s]\n 18%|█▊        | 97684/550352 [03:36<11:06, 678.70frames/s]\n 18%|█▊        | 100684/550352 [03:40<10:32, 711.17frames/s]\n 19%|█▉        | 103684/550352 [03:45<11:14, 661.83frames/s]\n 19%|█▉        | 104812/550352 [03:47<11:38, 637.57frames/s]\n 19%|█▉        | 107060/550352 [04:00<20:49, 354.81frames/s]\n 20%|█▉        | 109992/550352 [04:02<15:01, 488.52frames/s]\n 20%|██        | 112556/550352 [04:05<13:19, 547.81frames/s]\n 21%|██        | 115100/550352 [04:11<14:01, 517.11frames/s]\n 21%|██▏       | 117592/550352 [04:17<14:54, 483.58frames/s]\n 22%|██▏       | 120188/550352 [04:22<14:57, 479.09frames/s]\n 22%|██▏       | 122480/550352 [04:28<15:32, 458.82frames/s]\n 23%|██▎       | 124952/550352 [04:34<16:00, 442.84frames/s]\n 23%|██▎       | 127952/550352 [04:42<16:44, 420.71frames/s]\n 24%|██▍       | 130952/550352 [04:46<14:33, 480.06frames/s]\n 24%|██▍       | 133192/550352 [04:51<14:29, 479.68frames/s]\n 25%|██▍       | 135480/550352 [04:55<14:06, 489.95frames/s]\n 25%|██▌       | 138040/550352 [04:59<13:04, 525.74frames/s]\n 26%|██▌       | 140832/550352 [05:05<13:13, 516.16frames/s]\n 26%|██▌       | 143744/550352 [05:13<14:50, 456.69frames/s]\n 27%|██▋       | 146704/550352 [05:19<14:04, 478.00frames/s]\n 27%|██▋       | 149168/550352 [05:23<13:28, 496.25frames/s]\n 28%|██▊       | 151648/550352 [05:28<13:21, 497.62frames/s]\n 28%|██▊       | 154480/550352 [05:34<13:19, 494.86frames/s]\n 29%|██▊       | 156920/550352 [05:39<13:36, 481.74frames/s]\n 29%|██▉       | 159512/550352 [05:46<14:13, 457.83frames/s]\n 29%|██▉       | 162184/550352 [05:52<14:20, 451.28frames/s]\n 30%|██▉       | 164592/550352 [06:00<16:17, 394.71frames/s]\n 30%|███       | 167432/550352 [06:07<16:16, 392.27frames/s]\n 31%|███       | 170336/550352 [06:15<16:20, 387.75frames/s]\n 31%|███▏      | 172632/550352 [06:19<14:43, 427.66frames/s]\n 32%|███▏      | 175424/550352 [06:23<12:52, 485.61frames/s]\n 32%|███▏      | 177760/550352 [06:28<13:16, 467.89frames/s]\n 33%|███▎      | 180584/550352 [06:34<12:58, 475.01frames/s]\n 33%|███▎      | 183248/550352 [06:37<11:20, 539.32frames/s]\n 34%|███▎      | 185656/550352 [06:43<12:02, 504.66frames/s]\n 34%|███▍      | 188160/550352 [06:49<12:39, 477.19frames/s]\n 34%|███▍      | 188160/550352 [07:03<12:39, 477.19frames/s]\n 35%|███▍      | 190848/550352 [07:09<22:32, 265.74frames/s]\n 35%|███▌      | 193544/550352 [07:16<20:39, 287.87frames/s]\n 36%|███▌      | 196200/550352 [07:23<18:58, 311.10frames/s]\n 36%|███▌      | 199160/550352 [07:30<17:10, 340.69frames/s]\n 37%|███▋      | 202160/550352 [07:35<14:44, 393.82frames/s]\n 37%|███▋      | 205160/550352 [07:42<13:57, 412.36frames/s]\n 38%|███▊      | 207776/550352 [07:50<15:09, 376.63frames/s]\n 38%|███▊      | 210648/550352 [07:55<13:11, 429.24frames/s]\n 39%|███▉      | 213560/550352 [08:00<11:46, 476.47frames/s]\n 39%|███▉      | 216472/550352 [08:05<11:15, 494.15frames/s]\n 40%|███▉      | 219248/550352 [08:08<09:47, 563.81frames/s]\n 40%|████      | 222128/550352 [08:13<09:29, 576.56frames/s]\n 41%|████      | 225032/550352 [08:22<11:31, 470.59frames/s]\n 41%|████▏     | 227432/550352 [08:29<12:32, 429.24frames/s]\n 42%|████▏     | 230408/550352 [08:36<12:25, 429.26frames/s]\n 42%|████▏     | 233400/550352 [08:42<11:50, 446.22frames/s]\n 43%|████▎     | 236096/550352 [08:51<13:24, 390.38frames/s]\n 43%|████▎     | 238880/550352 [08:59<14:02, 369.67frames/s]\n 44%|████▍     | 241672/550352 [09:07<13:50, 371.48frames/s]\n 44%|████▍     | 244464/550352 [09:14<13:51, 367.69frames/s]\n 45%|████▍     | 247464/550352 [09:24<14:28, 348.87frames/s]\n 45%|████▌     | 250240/550352 [09:30<13:28, 371.01frames/s]\n 46%|████▌     | 252912/550352 [09:37<13:04, 379.11frames/s]\n 46%|████▋     | 255760/550352 [09:45<13:21, 367.73frames/s]\n 47%|████▋     | 258744/550352 [09:55<14:15, 340.92frames/s]\n 48%|████▊     | 261712/550352 [10:04<13:54, 345.92frames/s]\n 48%|████▊     | 264616/550352 [10:13<14:04, 338.41frames/s]\n 49%|████▊     | 267616/550352 [10:17<11:44, 401.41frames/s]\n 49%|████▉     | 270560/550352 [10:26<12:32, 371.99frames/s]\n 50%|████▉     | 273560/550352 [10:33<11:32, 399.80frames/s]\n 50%|█████     | 276432/550352 [10:39<11:04, 412.04frames/s]\n 51%|█████     | 279152/550352 [10:45<10:52, 415.72frames/s]\n 51%|█████     | 281840/550352 [10:52<10:44, 416.54frames/s]\n 52%|█████▏    | 284456/550352 [11:00<11:32, 384.08frames/s]\n 52%|█████▏    | 287376/550352 [11:08<11:30, 380.85frames/s]\n 53%|█████▎    | 290144/550352 [11:13<10:16, 421.89frames/s]\n 53%|█████▎    | 293144/550352 [11:20<10:10, 421.63frames/s]\n 54%|█████▍    | 295952/550352 [11:25<09:19, 455.06frames/s]\n 54%|█████▍    | 298728/550352 [11:28<07:47, 537.70frames/s]\n 55%|█████▍    | 301728/550352 [11:33<07:32, 549.88frames/s]\n 55%|█████▌    | 304584/550352 [11:41<08:33, 478.53frames/s]\n 56%|█████▌    | 307584/550352 [11:49<09:16, 436.58frames/s]\n 56%|█████▋    | 310584/550352 [11:58<10:02, 397.79frames/s]\n 57%|█████▋    | 313256/550352 [12:06<10:17, 383.91frames/s]\n 57%|█████▋    | 316056/550352 [12:10<08:54, 438.23frames/s]\n 58%|█████▊    | 319056/550352 [12:15<08:04, 477.16frames/s]\n 59%|█████▊    | 322056/550352 [12:20<07:33, 503.79frames/s]\n 59%|█████▉    | 324728/550352 [12:25<07:25, 505.90frames/s]\n 60%|█████▉    | 327608/550352 [12:34<08:42, 426.59frames/s]\n 60%|██████    | 330520/550352 [12:44<09:37, 380.61frames/s]\n 61%|██████    | 333448/550352 [12:53<10:00, 361.24frames/s]\n 61%|██████    | 336432/550352 [13:04<10:44, 332.14frames/s]\n 62%|██████▏   | 339080/550352 [13:11<10:18, 341.58frames/s]\n 62%|██████▏   | 341944/550352 [13:18<09:40, 359.26frames/s]\n 63%|██████▎   | 344568/550352 [13:23<08:46, 391.06frames/s]\n 63%|██████▎   | 347400/550352 [13:30<08:24, 402.12frames/s]\n 64%|██████▎   | 350224/550352 [13:39<09:12, 362.42frames/s]\n 64%|██████▍   | 353088/550352 [13:48<09:29, 346.12frames/s]\n 65%|██████▍   | 356064/550352 [13:57<09:22, 345.27frames/s]\n 65%|██████▌   | 358752/550352 [14:05<09:15, 345.09frames/s]\n 66%|██████▌   | 361512/550352 [14:11<08:20, 377.50frames/s]\n 66%|██████▌   | 364168/550352 [14:15<07:30, 413.69frames/s]\n 67%|██████▋   | 366720/550352 [14:22<07:24, 413.36frames/s]\n 67%|██████▋   | 369648/550352 [14:27<06:40, 450.68frames/s]\n 68%|██████▊   | 372240/550352 [14:33<06:36, 449.64frames/s]\n 68%|██████▊   | 375240/550352 [14:38<06:10, 472.67frames/s]\n 69%|██████▊   | 377880/550352 [14:43<05:51, 490.41frames/s]\n 69%|██████▉   | 380560/550352 [14:53<07:13, 392.07frames/s]\n 70%|██████▉   | 383560/550352 [15:01<07:07, 389.97frames/s]\n 70%|███████   | 386560/550352 [15:09<07:02, 387.88frames/s]\n 71%|███████   | 389560/550352 [15:14<06:13, 430.42frames/s]\n 71%|███████▏  | 392560/550352 [15:21<06:11, 424.74frames/s]\n 72%|███████▏  | 395416/550352 [15:28<06:01, 428.15frames/s]\n 72%|███████▏  | 398384/550352 [15:36<06:17, 403.00frames/s]\n 73%|███████▎  | 401344/550352 [15:44<06:08, 403.88frames/s]\n 73%|███████▎  | 404168/550352 [15:53<06:31, 373.34frames/s]\n 74%|███████▍  | 407000/550352 [16:00<06:15, 382.25frames/s]\n 74%|███████▍  | 409792/550352 [16:06<05:56, 394.03frames/s]\n 75%|███████▍  | 412560/550352 [16:14<06:01, 381.40frames/s]\n 76%|███████▌  | 415544/550352 [16:22<05:55, 378.68frames/s]\n 76%|███████▌  | 418544/550352 [16:31<06:09, 356.86frames/s]\n 77%|███████▋  | 421304/550352 [16:41<06:27, 332.96frames/s]\n 77%|███████▋  | 423912/550352 [16:48<06:06, 345.06frames/s]\n 78%|███████▊  | 426776/550352 [16:54<05:28, 376.11frames/s]\n 78%|███████▊  | 429672/550352 [17:01<05:07, 392.08frames/s]\n 79%|███████▊  | 432408/550352 [17:06<04:39, 421.64frames/s]\n 79%|███████▉  | 435376/550352 [17:11<04:09, 461.57frames/s]\n 80%|███████▉  | 438064/550352 [17:17<04:00, 466.75frames/s]\n 80%|████████  | 440864/550352 [17:23<03:59, 456.86frames/s]\n 81%|████████  | 443648/550352 [17:31<04:13, 420.77frames/s]\n 81%|████████  | 446456/550352 [17:41<04:39, 371.79frames/s]\n 81%|████████  | 446456/550352 [17:53<04:39, 371.79frames/s]\n 82%|████████▏ | 449216/550352 [18:18<09:57, 169.21frames/s]\n 82%|████████▏ | 452128/550352 [18:28<08:25, 194.32frames/s]\n 83%|████████▎ | 455056/550352 [18:36<07:01, 226.24frames/s]\n 83%|████████▎ | 457968/550352 [18:46<06:19, 243.63frames/s]\n 84%|████████▎ | 460896/550352 [18:56<05:45, 258.80frames/s]\n 84%|████████▍ | 463848/550352 [19:05<05:16, 273.70frames/s]\n 85%|████████▍ | 465760/550352 [19:09<04:43, 298.62frames/s]\n 85%|████████▍ | 467728/550352 [19:13<04:05, 337.21frames/s]\n 85%|████████▍ | 467728/550352 [19:23<04:05, 337.21frames/s]\n 86%|████████▌ | 470632/550352 [19:45<07:34, 175.51frames/s]\n 86%|████████▌ | 473312/550352 [19:51<05:59, 214.58frames/s]\n 87%|████████▋ | 476080/550352 [19:59<05:07, 241.79frames/s]\n 87%|████████▋ | 478824/550352 [20:05<04:14, 281.51frames/s]\n 87%|████████▋ | 481512/550352 [20:14<03:52, 295.73frames/s]\n 88%|████████▊ | 484088/550352 [20:19<03:20, 329.95frames/s]\n 88%|████████▊ | 486688/550352 [20:22<02:39, 397.91frames/s]\n 89%|████████▉ | 489480/550352 [20:27<02:17, 441.65frames/s]\n 89%|████████▉ | 492152/550352 [20:35<02:22, 407.01frames/s]\n 90%|████████▉ | 494624/550352 [20:40<02:10, 427.63frames/s]\n 90%|█████████ | 497544/550352 [20:46<01:57, 450.72frames/s]\n 91%|█████████ | 500104/550352 [20:52<01:52, 445.38frames/s]\n 91%|█████████▏| 502984/550352 [20:58<01:46, 443.92frames/s]\n 92%|█████████▏| 505984/550352 [21:07<01:49, 406.17frames/s]\n 92%|█████████▏| 508968/550352 [21:13<01:38, 421.10frames/s]\n 93%|█████████▎| 511904/550352 [21:21<01:33, 409.66frames/s]\n 93%|█████████▎| 514032/550352 [21:25<01:24, 429.66frames/s]\n 94%|█████████▍| 516464/550352 [21:28<01:07, 501.30frames/s]\n 94%|█████████▍| 519264/550352 [21:31<00:54, 574.33frames/s]\n 95%|█████████▍| 521592/550352 [21:36<00:53, 538.81frames/s]\n 95%|█████████▌| 524312/550352 [21:42<00:49, 521.99frames/s]\n 96%|█████████▌| 527312/550352 [21:49<00:46, 492.99frames/s]\n 96%|█████████▋| 530136/550352 [21:57<00:45, 442.54frames/s]\n 97%|█████████▋| 532992/550352 [22:04<00:40, 429.13frames/s]\n 97%|█████████▋| 535992/550352 [22:12<00:35, 402.25frames/s]\n 98%|█████████▊| 538944/550352 [22:21<00:29, 386.72frames/s]\n 98%|█████████▊| 541600/550352 [22:28<00:23, 377.65frames/s]\n 99%|█████████▉| 544544/550352 [22:37<00:15, 366.95frames/s]\n 99%|█████████▉| 547376/550352 [22:40<00:06, 435.71frames/s]\n100%|██████████| 550352/550352 [22:49<00:00, 405.20frames/s]\n100%|██████████| 550352/550352 [22:49<00:00, 401.97frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.4817660808563232,
        "compression_ratio": 1.4063926940639269,
        "end": 9.8,
        "id": 0,
        "no_speech_prob": 0.11260402202606201,
        "seek": 0,
        "start": 0,
        "temperature": 0.4,
        "text": " Hello, good afternoon. Welcome to part 2 of today's Coding Training Live Stream Internet",
        "tokens": [
          50364,
          2425,
          11,
          665,
          6499,
          13,
          4027,
          281,
          644,
          568,
          295,
          965,
          311,
          383,
          8616,
          20620,
          10385,
          24904,
          7703,
          50854
        ]
      },
      {
        "avg_logprob": -0.4817660808563232,
        "compression_ratio": 1.4063926940639269,
        "end": 18.72,
        "id": 1,
        "no_speech_prob": 0.11260402202606201,
        "seek": 0,
        "start": 9.8,
        "temperature": 0.4,
        "text": " Coding Show Episode... thing. My name is Dan and I will be here with you for the next approximately",
        "tokens": [
          50854,
          383,
          8616,
          6895,
          19882,
          485,
          551,
          13,
          1222,
          1315,
          307,
          3394,
          293,
          286,
          486,
          312,
          510,
          365,
          291,
          337,
          264,
          958,
          10447,
          51300
        ]
      },
      {
        "avg_logprob": -0.4817660808563232,
        "compression_ratio": 1.4063926940639269,
        "end": 24.3,
        "id": 2,
        "no_speech_prob": 0.11260402202606201,
        "seek": 0,
        "start": 18.72,
        "temperature": 0.4,
        "text": " one hour and thirty minutes. I don't have the YouTube chat going, I just realized, so",
        "tokens": [
          51300,
          472,
          1773,
          293,
          11790,
          2077,
          13,
          286,
          500,
          380,
          362,
          264,
          3088,
          5081,
          516,
          11,
          286,
          445,
          5334,
          11,
          370,
          51579
        ]
      },
      {
        "avg_logprob": -0.4817660808563232,
        "compression_ratio": 1.4063926940639269,
        "end": 27.36,
        "id": 3,
        "no_speech_prob": 0.11260402202606201,
        "seek": 0,
        "start": 24.3,
        "temperature": 0.4,
        "text": " let me see if I can pull that up.",
        "tokens": [
          51579,
          718,
          385,
          536,
          498,
          286,
          393,
          2235,
          300,
          493,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.34234603409914627,
        "compression_ratio": 1.5502183406113537,
        "end": 34.36,
        "id": 4,
        "no_speech_prob": 0.005384440533816814,
        "seek": 2736,
        "start": 27.36,
        "temperature": 0,
        "text": " Alright. I don't see anybody say anything, like you see me and you hear me, but I assume",
        "tokens": [
          50364,
          2798,
          13,
          286,
          500,
          380,
          536,
          4472,
          584,
          1340,
          11,
          411,
          291,
          536,
          385,
          293,
          291,
          1568,
          385,
          11,
          457,
          286,
          6552,
          50714
        ]
      },
      {
        "avg_logprob": -0.34234603409914627,
        "compression_ratio": 1.5502183406113537,
        "end": 39.12,
        "id": 5,
        "no_speech_prob": 0.005384440533816814,
        "seek": 2736,
        "start": 34.36,
        "temperature": 0,
        "text": " that I am live streaming. So what's going to happen? So first of all, welcome. I think",
        "tokens": [
          50714,
          300,
          286,
          669,
          1621,
          11791,
          13,
          407,
          437,
          311,
          516,
          281,
          1051,
          30,
          407,
          700,
          295,
          439,
          11,
          2928,
          13,
          286,
          519,
          50952
        ]
      },
      {
        "avg_logprob": -0.34234603409914627,
        "compression_ratio": 1.5502183406113537,
        "end": 47.260000000000005,
        "id": 6,
        "no_speech_prob": 0.005384440533816814,
        "seek": 2736,
        "start": 39.12,
        "temperature": 0,
        "text": " I already said that. Okay, yes, I see that there are people in the chat. This morning",
        "tokens": [
          50952,
          286,
          1217,
          848,
          300,
          13,
          1033,
          11,
          2086,
          11,
          286,
          536,
          300,
          456,
          366,
          561,
          294,
          264,
          5081,
          13,
          639,
          2446,
          51359
        ]
      },
      {
        "avg_logprob": -0.34234603409914627,
        "compression_ratio": 1.5502183406113537,
        "end": 57.16,
        "id": 7,
        "no_speech_prob": 0.005384440533816814,
        "seek": 2736,
        "start": 47.260000000000005,
        "temperature": 0,
        "text": " I spent some time talking about my new favorite subject, linting. Universal sign for linting.",
        "tokens": [
          51359,
          286,
          4418,
          512,
          565,
          1417,
          466,
          452,
          777,
          2954,
          3983,
          11,
          287,
          686,
          278,
          13,
          22617,
          1465,
          337,
          287,
          686,
          278,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.3352389842905897,
        "compression_ratio": 1.6621004566210045,
        "end": 66.12,
        "id": 8,
        "no_speech_prob": 0.0007208242896012962,
        "seek": 5716,
        "start": 57.16,
        "temperature": 0,
        "text": " My phone is... notification. YouTube notification. YouTube notification. Watch now! The Coding",
        "tokens": [
          50364,
          1222,
          2593,
          307,
          485,
          11554,
          13,
          3088,
          11554,
          13,
          3088,
          11554,
          13,
          7277,
          586,
          0,
          440,
          383,
          8616,
          50812
        ]
      },
      {
        "avg_logprob": -0.3352389842905897,
        "compression_ratio": 1.6621004566210045,
        "end": 72.96,
        "id": 9,
        "no_speech_prob": 0.0007208242896012962,
        "seek": 5716,
        "start": 66.12,
        "temperature": 0,
        "text": " Train is live! I got a notification. I probably always get that, I don't notice. So this morning",
        "tokens": [
          50812,
          28029,
          307,
          1621,
          0,
          286,
          658,
          257,
          11554,
          13,
          286,
          1391,
          1009,
          483,
          300,
          11,
          286,
          500,
          380,
          3449,
          13,
          407,
          341,
          2446,
          51154
        ]
      },
      {
        "avg_logprob": -0.3352389842905897,
        "compression_ratio": 1.6621004566210045,
        "end": 76.84,
        "id": 10,
        "no_speech_prob": 0.0007208242896012962,
        "seek": 5716,
        "start": 72.96,
        "temperature": 0,
        "text": " I talked a little bit about linting, which is kind of new. I did a little video about",
        "tokens": [
          51154,
          286,
          2825,
          257,
          707,
          857,
          466,
          287,
          686,
          278,
          11,
          597,
          307,
          733,
          295,
          777,
          13,
          286,
          630,
          257,
          707,
          960,
          466,
          51348
        ]
      },
      {
        "avg_logprob": -0.3352389842905897,
        "compression_ratio": 1.6621004566210045,
        "end": 84.56,
        "id": 11,
        "no_speech_prob": 0.0007208242896012962,
        "seek": 5716,
        "start": 76.84,
        "temperature": 0,
        "text": " GitHub, not GitHub, sorry, Gitremotes, one of which can be a GitHub repository and you",
        "tokens": [
          51348,
          23331,
          11,
          406,
          23331,
          11,
          2597,
          11,
          16939,
          2579,
          17251,
          11,
          472,
          295,
          597,
          393,
          312,
          257,
          23331,
          25841,
          293,
          291,
          51734
        ]
      },
      {
        "avg_logprob": -0.31634130397764576,
        "compression_ratio": 1.748062015503876,
        "end": 90.44,
        "id": 12,
        "no_speech_prob": 0.2146766185760498,
        "seek": 8456,
        "start": 84.56,
        "temperature": 0,
        "text": " can have multiple different... the same repository as part of different accounts on GitHub as",
        "tokens": [
          50364,
          393,
          362,
          3866,
          819,
          485,
          264,
          912,
          25841,
          382,
          644,
          295,
          819,
          9402,
          322,
          23331,
          382,
          50658
        ]
      },
      {
        "avg_logprob": -0.31634130397764576,
        "compression_ratio": 1.748062015503876,
        "end": 95.72,
        "id": 13,
        "no_speech_prob": 0.2146766185760498,
        "seek": 8456,
        "start": 90.44,
        "temperature": 0,
        "text": " different remotes. Boy, that was like, it was like a thrilling topic, the crowd was",
        "tokens": [
          50658,
          819,
          890,
          17251,
          13,
          9486,
          11,
          300,
          390,
          411,
          11,
          309,
          390,
          411,
          257,
          39347,
          4829,
          11,
          264,
          6919,
          390,
          50922
        ]
      },
      {
        "avg_logprob": -0.31634130397764576,
        "compression_ratio": 1.748062015503876,
        "end": 100.72,
        "id": 14,
        "no_speech_prob": 0.2146766185760498,
        "seek": 8456,
        "start": 95.72,
        "temperature": 0,
        "text": " in front of me, they were standing, they were cheering, it was suspenseful, they were crying,",
        "tokens": [
          50922,
          294,
          1868,
          295,
          385,
          11,
          436,
          645,
          4877,
          11,
          436,
          645,
          11060,
          11,
          309,
          390,
          6535,
          30398,
          11,
          436,
          645,
          8554,
          11,
          51172
        ]
      },
      {
        "avg_logprob": -0.31634130397764576,
        "compression_ratio": 1.748062015503876,
        "end": 105.72,
        "id": 15,
        "no_speech_prob": 0.2146766185760498,
        "seek": 8456,
        "start": 100.72,
        "temperature": 0,
        "text": " there were tears. And no, it was me with the terminal typing like, Gitremote ad. But, you",
        "tokens": [
          51172,
          456,
          645,
          10462,
          13,
          400,
          572,
          11,
          309,
          390,
          385,
          365,
          264,
          14709,
          18444,
          411,
          11,
          16939,
          2579,
          1370,
          614,
          13,
          583,
          11,
          291,
          51422
        ]
      },
      {
        "avg_logprob": -0.31634130397764576,
        "compression_ratio": 1.748062015503876,
        "end": 113.26,
        "id": 16,
        "no_speech_prob": 0.2146766185760498,
        "seek": 8456,
        "start": 105.72,
        "temperature": 0,
        "text": " know, someday we can all dream, can't we? That I'll be here with my tuxedo and the masses",
        "tokens": [
          51422,
          458,
          11,
          19412,
          321,
          393,
          439,
          3055,
          11,
          393,
          380,
          321,
          30,
          663,
          286,
          603,
          312,
          510,
          365,
          452,
          256,
          2449,
          26351,
          293,
          264,
          23935,
          51799
        ]
      },
      {
        "avg_logprob": -0.2803597990999517,
        "compression_ratio": 1.5411255411255411,
        "end": 118.7,
        "id": 17,
        "no_speech_prob": 0.01243128627538681,
        "seek": 11326,
        "start": 113.26,
        "temperature": 0,
        "text": " out there will be with their laptops coding along, tears, because they're so moved by",
        "tokens": [
          50364,
          484,
          456,
          486,
          312,
          365,
          641,
          27642,
          17720,
          2051,
          11,
          10462,
          11,
          570,
          436,
          434,
          370,
          4259,
          538,
          50636
        ]
      },
      {
        "avg_logprob": -0.2803597990999517,
        "compression_ratio": 1.5411255411255411,
        "end": 129.06,
        "id": 18,
        "no_speech_prob": 0.01243128627538681,
        "seek": 11326,
        "start": 118.7,
        "temperature": 0,
        "text": " the Coding Train. No, no, yeah, very unlikely. Now, I'm really not sure, I think I better",
        "tokens": [
          50636,
          264,
          383,
          8616,
          28029,
          13,
          883,
          11,
          572,
          11,
          1338,
          11,
          588,
          17518,
          13,
          823,
          11,
          286,
          478,
          534,
          406,
          988,
          11,
          286,
          519,
          286,
          1101,
          51154
        ]
      },
      {
        "avg_logprob": -0.2803597990999517,
        "compression_ratio": 1.5411255411255411,
        "end": 133.42000000000002,
        "id": 19,
        "no_speech_prob": 0.01243128627538681,
        "seek": 11326,
        "start": 129.06,
        "temperature": 0,
        "text": " stick to what I said I was going to do because I know that'll be disappointing, but I'm a",
        "tokens": [
          51154,
          2897,
          281,
          437,
          286,
          848,
          286,
          390,
          516,
          281,
          360,
          570,
          286,
          458,
          300,
          603,
          312,
          25054,
          11,
          457,
          286,
          478,
          257,
          51372
        ]
      },
      {
        "avg_logprob": -0.2803597990999517,
        "compression_ratio": 1.5411255411255411,
        "end": 137.82,
        "id": 20,
        "no_speech_prob": 0.01243128627538681,
        "seek": 11326,
        "start": 133.42000000000002,
        "temperature": 0,
        "text": " little bit concerned with the smallish amount of time that I have, so I'd like to just get",
        "tokens": [
          51372,
          707,
          857,
          5922,
          365,
          264,
          1359,
          742,
          2372,
          295,
          565,
          300,
          286,
          362,
          11,
          370,
          286,
          1116,
          411,
          281,
          445,
          483,
          51592
        ]
      },
      {
        "avg_logprob": -0.2835987091064453,
        "compression_ratio": 1.3565891472868217,
        "end": 149.78,
        "id": 21,
        "no_speech_prob": 0.3775179386138916,
        "seek": 13782,
        "start": 137.82,
        "temperature": 0,
        "text": " started. But, let me make an announcement. There will be no, this is the bad news, there",
        "tokens": [
          50364,
          1409,
          13,
          583,
          11,
          718,
          385,
          652,
          364,
          12847,
          13,
          821,
          486,
          312,
          572,
          11,
          341,
          307,
          264,
          1578,
          2583,
          11,
          456,
          50962
        ]
      },
      {
        "avg_logprob": -0.2835987091064453,
        "compression_ratio": 1.3565891472868217,
        "end": 165.62,
        "id": 22,
        "no_speech_prob": 0.3775179386138916,
        "seek": 13782,
        "start": 149.78,
        "temperature": 0,
        "text": " will be no Coding Train next Friday, March 16th. However, the good news is, there will",
        "tokens": [
          50962,
          486,
          312,
          572,
          383,
          8616,
          28029,
          958,
          6984,
          11,
          6129,
          3165,
          392,
          13,
          2908,
          11,
          264,
          665,
          2583,
          307,
          11,
          456,
          486,
          51754
        ]
      },
      {
        "avg_logprob": -0.2612511396408081,
        "compression_ratio": 1.5297619047619047,
        "end": 180.02,
        "id": 23,
        "no_speech_prob": 0.24796704947948456,
        "seek": 16562,
        "start": 165.62,
        "temperature": 0,
        "text": " be a Coding Train next Wednesday, March 14th, which as you may know is Pi Day 3.14. So,",
        "tokens": [
          50364,
          312,
          257,
          383,
          8616,
          28029,
          958,
          10579,
          11,
          6129,
          3499,
          392,
          11,
          597,
          382,
          291,
          815,
          458,
          307,
          17741,
          5226,
          805,
          13,
          7271,
          13,
          407,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.2612511396408081,
        "compression_ratio": 1.5297619047619047,
        "end": 187.26,
        "id": 24,
        "no_speech_prob": 0.24796704947948456,
        "seek": 16562,
        "start": 180.02,
        "temperature": 0,
        "text": " I'm going to be out of town on Friday, I'm not available. Scratch that, I'm not going",
        "tokens": [
          51084,
          286,
          478,
          516,
          281,
          312,
          484,
          295,
          3954,
          322,
          6984,
          11,
          286,
          478,
          406,
          2435,
          13,
          34944,
          852,
          300,
          11,
          286,
          478,
          406,
          516,
          51446
        ]
      },
      {
        "avg_logprob": -0.2612511396408081,
        "compression_ratio": 1.5297619047619047,
        "end": 193.9,
        "id": 25,
        "no_speech_prob": 0.24796704947948456,
        "seek": 16562,
        "start": 187.26,
        "temperature": 0,
        "text": " to be available on Friday. Edit that out, never mind. I'm going dark on Friday. I'm",
        "tokens": [
          51446,
          281,
          312,
          2435,
          322,
          6984,
          13,
          33241,
          300,
          484,
          11,
          1128,
          1575,
          13,
          286,
          478,
          516,
          2877,
          322,
          6984,
          13,
          286,
          478,
          51778
        ]
      },
      {
        "avg_logprob": -0.28387576191365216,
        "compression_ratio": 1.6926070038910506,
        "end": 203.54000000000002,
        "id": 26,
        "no_speech_prob": 0.377472460269928,
        "seek": 19390,
        "start": 193.9,
        "temperature": 0,
        "text": " not available on Friday, but I will be, what am I, what am I saying here? Yes, but I will",
        "tokens": [
          50364,
          406,
          2435,
          322,
          6984,
          11,
          457,
          286,
          486,
          312,
          11,
          437,
          669,
          286,
          11,
          437,
          669,
          286,
          1566,
          510,
          30,
          1079,
          11,
          457,
          286,
          486,
          50846
        ]
      },
      {
        "avg_logprob": -0.28387576191365216,
        "compression_ratio": 1.6926070038910506,
        "end": 208.42000000000002,
        "id": 27,
        "no_speech_prob": 0.377472460269928,
        "seek": 19390,
        "start": 203.54000000000002,
        "temperature": 0,
        "text": " be on Wednesday, and since it's Pi Day, I thought what I would do is do some Pi themed",
        "tokens": [
          50846,
          312,
          322,
          10579,
          11,
          293,
          1670,
          309,
          311,
          17741,
          5226,
          11,
          286,
          1194,
          437,
          286,
          576,
          360,
          307,
          360,
          512,
          17741,
          33920,
          51090
        ]
      },
      {
        "avg_logprob": -0.28387576191365216,
        "compression_ratio": 1.6926070038910506,
        "end": 212.18,
        "id": 28,
        "no_speech_prob": 0.377472460269928,
        "seek": 19390,
        "start": 208.42000000000002,
        "temperature": 0,
        "text": " coding challenges. I was hoping that maybe I could also have somebody, I'll come here",
        "tokens": [
          51090,
          17720,
          4759,
          13,
          286,
          390,
          7159,
          300,
          1310,
          286,
          727,
          611,
          362,
          2618,
          11,
          286,
          603,
          808,
          510,
          51278
        ]
      },
      {
        "avg_logprob": -0.28387576191365216,
        "compression_ratio": 1.6926070038910506,
        "end": 215.58,
        "id": 29,
        "no_speech_prob": 0.377472460269928,
        "seek": 19390,
        "start": 212.18,
        "temperature": 0,
        "text": " with like an actual Pi, and I could open the door and I could get like the sort of the",
        "tokens": [
          51278,
          365,
          411,
          364,
          3539,
          17741,
          11,
          293,
          286,
          727,
          1269,
          264,
          2853,
          293,
          286,
          727,
          483,
          411,
          264,
          1333,
          295,
          264,
          51448
        ]
      },
      {
        "avg_logprob": -0.28387576191365216,
        "compression_ratio": 1.6926070038910506,
        "end": 219.74,
        "id": 30,
        "no_speech_prob": 0.377472460269928,
        "seek": 19390,
        "start": 215.58,
        "temperature": 0,
        "text": " Pi in the face thing. Anybody knows a way for me to make that happen? I think that'll",
        "tokens": [
          51448,
          17741,
          294,
          264,
          1851,
          551,
          13,
          19082,
          3255,
          257,
          636,
          337,
          385,
          281,
          652,
          300,
          1051,
          30,
          286,
          519,
          300,
          603,
          51656
        ]
      },
      {
        "avg_logprob": -0.3872654155149298,
        "compression_ratio": 1.6167883211678833,
        "end": 225.5,
        "id": 31,
        "no_speech_prob": 0.5271954536437988,
        "seek": 21974,
        "start": 219.74,
        "temperature": 0,
        "text": " be an excellent thing to do on Elias Dream on Pi Day. But I'm looking for, what I'm looking",
        "tokens": [
          50364,
          312,
          364,
          7103,
          551,
          281,
          360,
          322,
          16943,
          296,
          12105,
          322,
          17741,
          5226,
          13,
          583,
          286,
          478,
          1237,
          337,
          11,
          437,
          286,
          478,
          1237,
          50652
        ]
      },
      {
        "avg_logprob": -0.3872654155149298,
        "compression_ratio": 1.6167883211678833,
        "end": 232.5,
        "id": 32,
        "no_speech_prob": 0.5271954536437988,
        "seek": 21974,
        "start": 225.5,
        "temperature": 0,
        "text": " for are suggestions for things that are simple, like phylotaxis is a good example of that.",
        "tokens": [
          50652,
          337,
          366,
          13396,
          337,
          721,
          300,
          366,
          2199,
          11,
          411,
          903,
          88,
          752,
          1328,
          39637,
          307,
          257,
          665,
          1365,
          295,
          300,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.3872654155149298,
        "compression_ratio": 1.6167883211678833,
        "end": 239.5,
        "id": 33,
        "no_speech_prob": 0.5271954536437988,
        "seek": 21974,
        "start": 232.5,
        "temperature": 0,
        "text": " It's a little algorithm, it's kind of got Pi in it. Blueberry Pi, my favorite kind of",
        "tokens": [
          51002,
          467,
          311,
          257,
          707,
          9284,
          11,
          309,
          311,
          733,
          295,
          658,
          17741,
          294,
          309,
          13,
          8510,
          9099,
          17741,
          11,
          452,
          2954,
          733,
          295,
          51352
        ]
      },
      {
        "avg_logprob": -0.3872654155149298,
        "compression_ratio": 1.6167883211678833,
        "end": 244.94,
        "id": 34,
        "no_speech_prob": 0.5271954536437988,
        "seek": 21974,
        "start": 239.5,
        "temperature": 0,
        "text": " Pi. And so some things that I might, I know that Stand Up Maths, the YouTube channel,",
        "tokens": [
          51352,
          17741,
          13,
          400,
          370,
          512,
          721,
          300,
          286,
          1062,
          11,
          286,
          458,
          300,
          9133,
          5858,
          15776,
          82,
          11,
          264,
          3088,
          2269,
          11,
          51624
        ]
      },
      {
        "avg_logprob": -0.3872654155149298,
        "compression_ratio": 1.6167883211678833,
        "end": 249.70000000000002,
        "id": 35,
        "no_speech_prob": 0.5271954536437988,
        "seek": 21974,
        "start": 244.94,
        "temperature": 0,
        "text": " Matt Parker did an interesting video I think last year about calculating all the digital",
        "tokens": [
          51624,
          7397,
          20155,
          630,
          364,
          1880,
          960,
          286,
          519,
          1036,
          1064,
          466,
          28258,
          439,
          264,
          4562,
          51862
        ]
      },
      {
        "avg_logprob": -0.2632806155146385,
        "compression_ratio": 1.5859030837004404,
        "end": 253.89999999999998,
        "id": 36,
        "no_speech_prob": 0.01224103756248951,
        "seek": 24970,
        "start": 249.7,
        "temperature": 0,
        "text": " digits of Pi. Maybe I could make a piece of code that does that and displays them in",
        "tokens": [
          50364,
          27011,
          295,
          17741,
          13,
          2704,
          286,
          727,
          652,
          257,
          2522,
          295,
          3089,
          300,
          775,
          300,
          293,
          20119,
          552,
          294,
          50574
        ]
      },
      {
        "avg_logprob": -0.2632806155146385,
        "compression_ratio": 1.5859030837004404,
        "end": 265.9,
        "id": 37,
        "no_speech_prob": 0.01224103756248951,
        "seek": 24970,
        "start": 253.89999999999998,
        "temperature": 0,
        "text": " the browser. So, so I am, yeah, maybe do Python, no. That does not count. Python does not count",
        "tokens": [
          50574,
          264,
          11185,
          13,
          407,
          11,
          370,
          286,
          669,
          11,
          1338,
          11,
          1310,
          360,
          15329,
          11,
          572,
          13,
          663,
          775,
          406,
          1207,
          13,
          15329,
          775,
          406,
          1207,
          51174
        ]
      },
      {
        "avg_logprob": -0.2632806155146385,
        "compression_ratio": 1.5859030837004404,
        "end": 270.78,
        "id": 38,
        "no_speech_prob": 0.01224103756248951,
        "seek": 24970,
        "start": 265.9,
        "temperature": 0,
        "text": " as something for Pi Day, especially because I, I mean actually it does, it totally does,",
        "tokens": [
          51174,
          382,
          746,
          337,
          17741,
          5226,
          11,
          2318,
          570,
          286,
          11,
          286,
          914,
          767,
          309,
          775,
          11,
          309,
          3879,
          775,
          11,
          51418
        ]
      },
      {
        "avg_logprob": -0.2632806155146385,
        "compression_ratio": 1.5859030837004404,
        "end": 275.21999999999997,
        "id": 39,
        "no_speech_prob": 0.01224103756248951,
        "seek": 24970,
        "start": 270.78,
        "temperature": 0,
        "text": " but I don't know if that's going to happen. But, so I would like to take your suggestions.",
        "tokens": [
          51418,
          457,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          516,
          281,
          1051,
          13,
          583,
          11,
          370,
          286,
          576,
          411,
          281,
          747,
          428,
          13396,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.22989765167236328,
        "compression_ratio": 1.2797202797202798,
        "end": 286.66,
        "id": 40,
        "no_speech_prob": 0.12591145932674408,
        "seek": 27522,
        "start": 275.22,
        "temperature": 0,
        "text": " So where can you leave your suggestions for, let's do this for now. Rainbow Topics. I probably",
        "tokens": [
          50364,
          407,
          689,
          393,
          291,
          1856,
          428,
          13396,
          337,
          11,
          718,
          311,
          360,
          341,
          337,
          586,
          13,
          29477,
          8840,
          1167,
          13,
          286,
          1391,
          50936
        ]
      },
      {
        "avg_logprob": -0.22989765167236328,
        "compression_ratio": 1.2797202797202798,
        "end": 292.52000000000004,
        "id": 41,
        "no_speech_prob": 0.12591145932674408,
        "seek": 27522,
        "start": 286.66,
        "temperature": 0,
        "text": " should come up with a better system, but I am going to create a new issue, Pi Day Coding",
        "tokens": [
          50936,
          820,
          808,
          493,
          365,
          257,
          1101,
          1185,
          11,
          457,
          286,
          669,
          516,
          281,
          1884,
          257,
          777,
          2734,
          11,
          17741,
          5226,
          383,
          8616,
          51229
        ]
      },
      {
        "avg_logprob": -0.2777107352077371,
        "compression_ratio": 1.5769230769230769,
        "end": 307.35999999999996,
        "id": 42,
        "no_speech_prob": 0.43005838990211487,
        "seek": 29252,
        "start": 292.52,
        "temperature": 0,
        "text": " Challenge Suggestions. Please add your suggestions for a Pi Day Coding Challenge in the comments",
        "tokens": [
          50364,
          17517,
          39131,
          2629,
          626,
          13,
          2555,
          909,
          428,
          13396,
          337,
          257,
          17741,
          5226,
          383,
          8616,
          17517,
          294,
          264,
          3053,
          51106
        ]
      },
      {
        "avg_logprob": -0.2777107352077371,
        "compression_ratio": 1.5769230769230769,
        "end": 312.32,
        "id": 43,
        "no_speech_prob": 0.43005838990211487,
        "seek": 29252,
        "start": 307.35999999999996,
        "temperature": 0,
        "text": " below. And, you know, maybe we can do some kind of like, I guess I could do like a, maybe",
        "tokens": [
          51106,
          2507,
          13,
          400,
          11,
          291,
          458,
          11,
          1310,
          321,
          393,
          360,
          512,
          733,
          295,
          411,
          11,
          286,
          2041,
          286,
          727,
          360,
          411,
          257,
          11,
          1310,
          51354
        ]
      },
      {
        "avg_logprob": -0.2777107352077371,
        "compression_ratio": 1.5769230769230769,
        "end": 317.03999999999996,
        "id": 44,
        "no_speech_prob": 0.43005838990211487,
        "seek": 29252,
        "start": 312.32,
        "temperature": 0,
        "text": " I should do a Reddit, subreddit thread, because there is a Coding Train Reddit. Should we",
        "tokens": [
          51354,
          286,
          820,
          360,
          257,
          32210,
          11,
          1422,
          986,
          17975,
          7207,
          11,
          570,
          456,
          307,
          257,
          383,
          8616,
          28029,
          32210,
          13,
          6454,
          321,
          51590
        ]
      },
      {
        "avg_logprob": -0.2777107352077371,
        "compression_ratio": 1.5769230769230769,
        "end": 322.35999999999996,
        "id": 45,
        "no_speech_prob": 0.43005838990211487,
        "seek": 29252,
        "start": 317.03999999999996,
        "temperature": 0,
        "text": " try that? I don't know, I'm so used to GitHub. I'll close this and move it there if somebody",
        "tokens": [
          51590,
          853,
          300,
          30,
          286,
          500,
          380,
          458,
          11,
          286,
          478,
          370,
          1143,
          281,
          23331,
          13,
          286,
          603,
          1998,
          341,
          293,
          1286,
          309,
          456,
          498,
          2618,
          51856
        ]
      },
      {
        "avg_logprob": -0.21670527536360945,
        "compression_ratio": 1.7192307692307693,
        "end": 328.04,
        "id": 46,
        "no_speech_prob": 0.10970115661621094,
        "seek": 32236,
        "start": 322.36,
        "temperature": 0,
        "text": " has a better suggestion. But I'd like to, let me just do this right now. So you could",
        "tokens": [
          50364,
          575,
          257,
          1101,
          16541,
          13,
          583,
          286,
          1116,
          411,
          281,
          11,
          718,
          385,
          445,
          360,
          341,
          558,
          586,
          13,
          407,
          291,
          727,
          50648
        ]
      },
      {
        "avg_logprob": -0.21670527536360945,
        "compression_ratio": 1.7192307692307693,
        "end": 333.56,
        "id": 47,
        "no_speech_prob": 0.10970115661621094,
        "seek": 32236,
        "start": 328.04,
        "temperature": 0,
        "text": " add your suggestion here on GitHub and then people can like, thumbs up the ones that they",
        "tokens": [
          50648,
          909,
          428,
          16541,
          510,
          322,
          23331,
          293,
          550,
          561,
          393,
          411,
          11,
          8838,
          493,
          264,
          2306,
          300,
          436,
          50924
        ]
      },
      {
        "avg_logprob": -0.21670527536360945,
        "compression_ratio": 1.7192307692307693,
        "end": 337.48,
        "id": 48,
        "no_speech_prob": 0.10970115661621094,
        "seek": 32236,
        "start": 333.56,
        "temperature": 0,
        "text": " like and I can kind of look through and pick them that way. You could do a tag on the GitHub",
        "tokens": [
          50924,
          411,
          293,
          286,
          393,
          733,
          295,
          574,
          807,
          293,
          1888,
          552,
          300,
          636,
          13,
          509,
          727,
          360,
          257,
          6162,
          322,
          264,
          23331,
          51120
        ]
      },
      {
        "avg_logprob": -0.21670527536360945,
        "compression_ratio": 1.7192307692307693,
        "end": 342.12,
        "id": 49,
        "no_speech_prob": 0.10970115661621094,
        "seek": 32236,
        "start": 337.48,
        "temperature": 0,
        "text": " topics. I could also do that. That might be better for me to just do a label. Yeah, let's",
        "tokens": [
          51120,
          8378,
          13,
          286,
          727,
          611,
          360,
          300,
          13,
          663,
          1062,
          312,
          1101,
          337,
          385,
          281,
          445,
          360,
          257,
          7645,
          13,
          865,
          11,
          718,
          311,
          51352
        ]
      },
      {
        "avg_logprob": -0.21670527536360945,
        "compression_ratio": 1.7192307692307693,
        "end": 350.52000000000004,
        "id": 50,
        "no_speech_prob": 0.10970115661621094,
        "seek": 32236,
        "start": 342.12,
        "temperature": 0,
        "text": " not do it in the comments. Let's close this issue. Never mind. Let's use a label. I just",
        "tokens": [
          51352,
          406,
          360,
          309,
          294,
          264,
          3053,
          13,
          961,
          311,
          1998,
          341,
          2734,
          13,
          7344,
          1575,
          13,
          961,
          311,
          764,
          257,
          7645,
          13,
          286,
          445,
          51772
        ]
      },
      {
        "avg_logprob": -0.27884706309143925,
        "compression_ratio": 1.5257142857142858,
        "end": 353,
        "id": 51,
        "no_speech_prob": 0.6757320761680603,
        "seek": 35052,
        "start": 350.52,
        "temperature": 0,
        "text": " thought it might be nice to be able to see them all in one place, but with labels you",
        "tokens": [
          50364,
          1194,
          309,
          1062,
          312,
          1481,
          281,
          312,
          1075,
          281,
          536,
          552,
          439,
          294,
          472,
          1081,
          11,
          457,
          365,
          16949,
          291,
          50488
        ]
      },
      {
        "avg_logprob": -0.27884706309143925,
        "compression_ratio": 1.5257142857142858,
        "end": 367.71999999999997,
        "id": 52,
        "no_speech_prob": 0.6757320761680603,
        "seek": 35052,
        "start": 353,
        "temperature": 0,
        "text": " can do that. Let's use a label instead. All right, the trolls are out in full form today.",
        "tokens": [
          50488,
          393,
          360,
          300,
          13,
          961,
          311,
          764,
          257,
          7645,
          2602,
          13,
          1057,
          558,
          11,
          264,
          47749,
          366,
          484,
          294,
          1577,
          1254,
          965,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.27884706309143925,
        "compression_ratio": 1.5257142857142858,
        "end": 375.96,
        "id": 53,
        "no_speech_prob": 0.6757320761680603,
        "seek": 35052,
        "start": 367.71999999999997,
        "temperature": 0,
        "text": " Let's quickly, quickly lock this conversation. It's too heated. It's definitely too heated.",
        "tokens": [
          51224,
          961,
          311,
          2661,
          11,
          2661,
          4017,
          341,
          3761,
          13,
          467,
          311,
          886,
          18806,
          13,
          467,
          311,
          2138,
          886,
          18806,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.27421428061820363,
        "compression_ratio": 1.5286624203821657,
        "end": 388.91999999999996,
        "id": 54,
        "no_speech_prob": 0.053401872515678406,
        "seek": 37596,
        "start": 376.68,
        "temperature": 0,
        "text": " And let's add a label. Oh, let's go to issues, labels, new label, Pi Day.",
        "tokens": [
          50400,
          400,
          718,
          311,
          909,
          257,
          7645,
          13,
          876,
          11,
          718,
          311,
          352,
          281,
          2663,
          11,
          16949,
          11,
          777,
          7645,
          11,
          17741,
          5226,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.27421428061820363,
        "compression_ratio": 1.5286624203821657,
        "end": 398.84,
        "id": 55,
        "no_speech_prob": 0.053401872515678406,
        "seek": 37596,
        "start": 390.44,
        "temperature": 0,
        "text": " Challenge for three. I'm going to do this because this is the kind of person I am.",
        "tokens": [
          51088,
          17517,
          337,
          1045,
          13,
          286,
          478,
          516,
          281,
          360,
          341,
          570,
          341,
          307,
          264,
          733,
          295,
          954,
          286,
          669,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.27421428061820363,
        "compression_ratio": 1.5286624203821657,
        "end": 404.2,
        "id": 56,
        "no_speech_prob": 0.053401872515678406,
        "seek": 37596,
        "start": 399.47999999999996,
        "temperature": 0,
        "text": " I'm going to put my date with the day, then the month. That's what I'm going to do.",
        "tokens": [
          51540,
          286,
          478,
          516,
          281,
          829,
          452,
          4002,
          365,
          264,
          786,
          11,
          550,
          264,
          1618,
          13,
          663,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.24543573886533326,
        "compression_ratio": 1.4318181818181819,
        "end": 409.15999999999997,
        "id": 57,
        "no_speech_prob": 0.0003250316367484629,
        "seek": 40596,
        "start": 406.03999999999996,
        "temperature": 0,
        "text": " And I'm going to, let's get a color here. Oh, that's perfect.",
        "tokens": [
          50368,
          400,
          286,
          478,
          516,
          281,
          11,
          718,
          311,
          483,
          257,
          2017,
          510,
          13,
          876,
          11,
          300,
          311,
          2176,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.24543573886533326,
        "compression_ratio": 1.4318181818181819,
        "end": 423.24,
        "id": 58,
        "no_speech_prob": 0.0003250316367484629,
        "seek": 40596,
        "start": 410.91999999999996,
        "temperature": 0,
        "text": " Okay, so now you can file an issue and I will label it as Pi Day, like this. Okay, so send me",
        "tokens": [
          50612,
          1033,
          11,
          370,
          586,
          291,
          393,
          3991,
          364,
          2734,
          293,
          286,
          486,
          7645,
          309,
          382,
          17741,
          5226,
          11,
          411,
          341,
          13,
          1033,
          11,
          370,
          2845,
          385,
          51228
        ]
      },
      {
        "avg_logprob": -0.24543573886533326,
        "compression_ratio": 1.4318181818181819,
        "end": 433.08,
        "id": 59,
        "no_speech_prob": 0.0003250316367484629,
        "seek": 40596,
        "start": 423.24,
        "temperature": 0,
        "text": " your, now, next up, moving right along. Let's see, am I in the correct directory? Let's just see",
        "tokens": [
          51228,
          428,
          11,
          586,
          11,
          958,
          493,
          11,
          2684,
          558,
          2051,
          13,
          961,
          311,
          536,
          11,
          669,
          286,
          294,
          264,
          3006,
          21120,
          30,
          961,
          311,
          445,
          536,
          51720
        ]
      },
      {
        "avg_logprob": -0.34125638562579486,
        "compression_ratio": 1.5126903553299493,
        "end": 437.24,
        "id": 60,
        "no_speech_prob": 0.009708363562822342,
        "seek": 43308,
        "start": 433.08,
        "temperature": 0,
        "text": " what's been merged. Thank you again to Miyamasa-mi, who's been merging some, oh,",
        "tokens": [
          50364,
          437,
          311,
          668,
          36427,
          13,
          1044,
          291,
          797,
          281,
          26195,
          335,
          9994,
          12,
          3057,
          11,
          567,
          311,
          668,
          44559,
          512,
          11,
          1954,
          11,
          50572
        ]
      },
      {
        "avg_logprob": -0.34125638562579486,
        "compression_ratio": 1.5126903553299493,
        "end": 446.2,
        "id": 61,
        "no_speech_prob": 0.009708363562822342,
        "seek": 43308,
        "start": 439,
        "temperature": 0,
        "text": " merging some of these Flappy Bird pull requests, pull GitHub master.",
        "tokens": [
          50660,
          44559,
          512,
          295,
          613,
          479,
          875,
          7966,
          15931,
          2235,
          12475,
          11,
          2235,
          23331,
          4505,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.34125638562579486,
        "compression_ratio": 1.5126903553299493,
        "end": 451.08,
        "id": 62,
        "no_speech_prob": 0.009708363562822342,
        "seek": 43308,
        "start": 447.24,
        "temperature": 0,
        "text": " And we got some stuff. I think we have some unicorn horn pipes.",
        "tokens": [
          51072,
          400,
          321,
          658,
          512,
          1507,
          13,
          286,
          519,
          321,
          362,
          512,
          28122,
          13482,
          21882,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.34125638562579486,
        "compression_ratio": 1.5126903553299493,
        "end": 461.4,
        "id": 63,
        "no_speech_prob": 0.009708363562822342,
        "seek": 43308,
        "start": 453.32,
        "temperature": 0,
        "text": " Loading, loading, loading. Horn filled flipped.png. Looks like we're missing a file.",
        "tokens": [
          51376,
          6130,
          8166,
          11,
          15114,
          11,
          15114,
          13,
          31792,
          6412,
          932,
          72,
          3320,
          13,
          79,
          872,
          13,
          10027,
          411,
          321,
          434,
          5361,
          257,
          3991,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.22996772281707278,
        "compression_ratio": 1.7560975609756098,
        "end": 465.8,
        "id": 64,
        "no_speech_prob": 0.00007141894457163289,
        "seek": 46308,
        "start": 463.64,
        "temperature": 0,
        "text": " Let's see what I can figure out there.",
        "tokens": [
          50392,
          961,
          311,
          536,
          437,
          286,
          393,
          2573,
          484,
          456,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.22996772281707278,
        "compression_ratio": 1.7560975609756098,
        "end": 481.32,
        "id": 65,
        "no_speech_prob": 0.00007141894457163289,
        "seek": 46308,
        "start": 472.03999999999996,
        "temperature": 0,
        "text": " Graphics, horn body filled, horn tip filled, horn body filled, horn tip filled, ooh,",
        "tokens": [
          50812,
          21884,
          1167,
          11,
          13482,
          1772,
          6412,
          11,
          13482,
          4125,
          6412,
          11,
          13482,
          1772,
          6412,
          11,
          13482,
          4125,
          6412,
          11,
          17024,
          11,
          51276
        ]
      },
      {
        "avg_logprob": -0.22996772281707278,
        "compression_ratio": 1.7560975609756098,
        "end": 489.47999999999996,
        "id": 66,
        "no_speech_prob": 0.00007141894457163289,
        "seek": 46308,
        "start": 481.32,
        "temperature": 0,
        "text": " horn tip filled flipped. Do I need that one? Paint pant dot, ooh, horn tip filled, horn tip,",
        "tokens": [
          51276,
          13482,
          4125,
          6412,
          26273,
          13,
          1144,
          286,
          643,
          300,
          472,
          30,
          34865,
          14869,
          5893,
          11,
          17024,
          11,
          13482,
          4125,
          6412,
          11,
          13482,
          4125,
          11,
          51684
        ]
      },
      {
        "avg_logprob": -0.2591768980026245,
        "compression_ratio": 1.5224719101123596,
        "end": 494.36,
        "id": 67,
        "no_speech_prob": 0.000527476251590997,
        "seek": 48948,
        "start": 489.48,
        "temperature": 0,
        "text": " oh, those are like, I don't know what that is, paint dot net. These were made by a GitHub user.",
        "tokens": [
          50364,
          1954,
          11,
          729,
          366,
          411,
          11,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          11,
          4225,
          5893,
          2533,
          13,
          1981,
          645,
          1027,
          538,
          257,
          23331,
          4195,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.2591768980026245,
        "compression_ratio": 1.5224719101123596,
        "end": 509.96000000000004,
        "id": 68,
        "no_speech_prob": 0.000527476251590997,
        "seek": 48948,
        "start": 496.44,
        "temperature": 0,
        "text": " These were made by GitHub user. Just want to, K1J Julian, K1G Julian, King Julian.",
        "tokens": [
          50712,
          1981,
          645,
          1027,
          538,
          23331,
          4195,
          13,
          1449,
          528,
          281,
          11,
          591,
          16,
          41,
          25151,
          11,
          591,
          16,
          38,
          25151,
          11,
          3819,
          25151,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2591768980026245,
        "compression_ratio": 1.5224719101123596,
        "end": 518.04,
        "id": 69,
        "no_speech_prob": 0.000527476251590997,
        "seek": 48948,
        "start": 511,
        "temperature": 0,
        "text": " And we can see them here, these lovely unicorn horns. So I'm a little bit concerned. I might",
        "tokens": [
          51440,
          400,
          321,
          393,
          536,
          552,
          510,
          11,
          613,
          7496,
          28122,
          28818,
          13,
          407,
          286,
          478,
          257,
          707,
          857,
          5922,
          13,
          286,
          1062,
          51792
        ]
      },
      {
        "avg_logprob": -0.27205748558044435,
        "compression_ratio": 1.5980392156862746,
        "end": 522.1999999999999,
        "id": 70,
        "no_speech_prob": 0.003324376419186592,
        "seek": 51804,
        "start": 518.04,
        "temperature": 0,
        "text": " really actually just want to replace these with just like drawn rectangles, mostly because I'm a",
        "tokens": [
          50364,
          534,
          767,
          445,
          528,
          281,
          7406,
          613,
          365,
          445,
          411,
          10117,
          24077,
          904,
          11,
          5240,
          570,
          286,
          478,
          257,
          50572
        ]
      },
      {
        "avg_logprob": -0.27205748558044435,
        "compression_ratio": 1.5980392156862746,
        "end": 526.76,
        "id": 71,
        "no_speech_prob": 0.003324376419186592,
        "seek": 51804,
        "start": 522.1999999999999,
        "temperature": 0,
        "text": " little concerned about having the collision. I don't want to introduce extra complexity with",
        "tokens": [
          50572,
          707,
          5922,
          466,
          1419,
          264,
          24644,
          13,
          286,
          500,
          380,
          528,
          281,
          5366,
          2857,
          14024,
          365,
          50800
        ]
      },
      {
        "avg_logprob": -0.27205748558044435,
        "compression_ratio": 1.5980392156862746,
        "end": 531.88,
        "id": 72,
        "no_speech_prob": 0.003324376419186592,
        "seek": 51804,
        "start": 526.76,
        "temperature": 0,
        "text": " the collision detection. Maybe Miyamasa-mi, maybe.",
        "tokens": [
          50800,
          264,
          24644,
          17784,
          13,
          2704,
          26195,
          335,
          9994,
          12,
          3057,
          11,
          1310,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.27205748558044435,
        "compression_ratio": 1.5980392156862746,
        "end": 543.8,
        "id": 73,
        "no_speech_prob": 0.003324376419186592,
        "seek": 51804,
        "start": 539.0799999999999,
        "temperature": 0,
        "text": " Whoops, git pull, git pull. I can't, like I almost can't do it without saying origin.",
        "tokens": [
          51416,
          45263,
          11,
          18331,
          2235,
          11,
          18331,
          2235,
          13,
          286,
          393,
          380,
          11,
          411,
          286,
          1920,
          393,
          380,
          360,
          309,
          1553,
          1566,
          4957,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2490399304558249,
        "compression_ratio": 1.801498127340824,
        "end": 555.48,
        "id": 74,
        "no_speech_prob": 0.00021995214046910405,
        "seek": 54804,
        "start": 548.1999999999999,
        "temperature": 0,
        "text": " I just keep, until somebody fixes it, why do I just keep doing this? I'm just kidding, just kidding.",
        "tokens": [
          50372,
          286,
          445,
          1066,
          11,
          1826,
          2618,
          32539,
          309,
          11,
          983,
          360,
          286,
          445,
          1066,
          884,
          341,
          30,
          286,
          478,
          445,
          9287,
          11,
          445,
          9287,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2490399304558249,
        "compression_ratio": 1.801498127340824,
        "end": 562.12,
        "id": 75,
        "no_speech_prob": 0.00021995214046910405,
        "seek": 54804,
        "start": 555.48,
        "temperature": 0,
        "text": " Let's take a look here. Let's look at the pipe. Where is it being drawn? Draw, oh boy, this became",
        "tokens": [
          50736,
          961,
          311,
          747,
          257,
          574,
          510,
          13,
          961,
          311,
          574,
          412,
          264,
          11240,
          13,
          2305,
          307,
          309,
          885,
          10117,
          30,
          20386,
          11,
          1954,
          3237,
          11,
          341,
          3062,
          51068
        ]
      },
      {
        "avg_logprob": -0.2490399304558249,
        "compression_ratio": 1.801498127340824,
        "end": 565.7199999999999,
        "id": 76,
        "no_speech_prob": 0.00021995214046910405,
        "seek": 54804,
        "start": 562.12,
        "temperature": 0,
        "text": " incredible, this became very complicated. The good news is I was okay with all this becoming",
        "tokens": [
          51068,
          4651,
          11,
          341,
          3062,
          588,
          6179,
          13,
          440,
          665,
          2583,
          307,
          286,
          390,
          1392,
          365,
          439,
          341,
          5617,
          51248
        ]
      },
      {
        "avg_logprob": -0.2490399304558249,
        "compression_ratio": 1.801498127340824,
        "end": 571.9599999999999,
        "id": 77,
        "no_speech_prob": 0.00021995214046910405,
        "seek": 54804,
        "start": 565.7199999999999,
        "temperature": 0,
        "text": " complicated because it's all just in the pipe class and I actually don't really mind if the",
        "tokens": [
          51248,
          6179,
          570,
          309,
          311,
          439,
          445,
          294,
          264,
          11240,
          1508,
          293,
          286,
          767,
          500,
          380,
          534,
          1575,
          498,
          264,
          51560
        ]
      },
      {
        "avg_logprob": -0.2490399304558249,
        "compression_ratio": 1.801498127340824,
        "end": 577.16,
        "id": 78,
        "no_speech_prob": 0.00021995214046910405,
        "seek": 54804,
        "start": 571.9599999999999,
        "temperature": 0,
        "text": " pipe class is the super complicated thing because what I need to demonstrate will happen, can be",
        "tokens": [
          51560,
          11240,
          1508,
          307,
          264,
          1687,
          6179,
          551,
          570,
          437,
          286,
          643,
          281,
          11698,
          486,
          1051,
          11,
          393,
          312,
          51820
        ]
      },
      {
        "avg_logprob": -0.2237871846845073,
        "compression_ratio": 1.541062801932367,
        "end": 580.28,
        "id": 79,
        "no_speech_prob": 0.0001088965218514204,
        "seek": 57716,
        "start": 577.16,
        "temperature": 0,
        "text": " applied to any game whether the code is very simple or complicated.",
        "tokens": [
          50364,
          6456,
          281,
          604,
          1216,
          1968,
          264,
          3089,
          307,
          588,
          2199,
          420,
          6179,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.2237871846845073,
        "compression_ratio": 1.541062801932367,
        "end": 586.1999999999999,
        "id": 80,
        "no_speech_prob": 0.0001088965218514204,
        "seek": 57716,
        "start": 583.16,
        "temperature": 0,
        "text": " So let me see here, what is the image that's missing?",
        "tokens": [
          50664,
          407,
          718,
          385,
          536,
          510,
          11,
          437,
          307,
          264,
          3256,
          300,
          311,
          5361,
          30,
          50816
        ]
      },
      {
        "avg_logprob": -0.2237871846845073,
        "compression_ratio": 1.541062801932367,
        "end": 596.04,
        "id": 81,
        "no_speech_prob": 0.0001088965218514204,
        "seek": 57716,
        "start": 589.64,
        "temperature": 0,
        "text": " I'm sure there's a crack team of coders working, okay now it's fixed. Okay, thank you Miyamasa-mi.",
        "tokens": [
          50988,
          286,
          478,
          988,
          456,
          311,
          257,
          6226,
          1469,
          295,
          17656,
          433,
          1364,
          11,
          1392,
          586,
          309,
          311,
          6806,
          13,
          1033,
          11,
          1309,
          291,
          26195,
          335,
          9994,
          12,
          3057,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2237871846845073,
        "compression_ratio": 1.541062801932367,
        "end": 606.36,
        "id": 82,
        "no_speech_prob": 0.0001088965218514204,
        "seek": 57716,
        "start": 597.88,
        "temperature": 0,
        "text": " Let's, there we go. Looks like we've got that fixed. Let's go here and there we go. So now we have",
        "tokens": [
          51400,
          961,
          311,
          11,
          456,
          321,
          352,
          13,
          10027,
          411,
          321,
          600,
          658,
          300,
          6806,
          13,
          961,
          311,
          352,
          510,
          293,
          456,
          321,
          352,
          13,
          407,
          586,
          321,
          362,
          51824
        ]
      },
      {
        "avg_logprob": -0.252920869467915,
        "compression_ratio": 1.535031847133758,
        "end": 613.0799999999999,
        "id": 83,
        "no_speech_prob": 0.00006205038516782224,
        "seek": 60716,
        "start": 607.88,
        "temperature": 0,
        "text": " our beautiful Flappy Bird game so slow on my machine.",
        "tokens": [
          50400,
          527,
          2238,
          479,
          875,
          7966,
          15931,
          1216,
          370,
          2964,
          322,
          452,
          3479,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.252920869467915,
        "compression_ratio": 1.535031847133758,
        "end": 620.6,
        "id": 84,
        "no_speech_prob": 0.00006205038516782224,
        "seek": 60716,
        "start": 615.0799999999999,
        "temperature": 0,
        "text": " And so let's see about this collision stuff. Yeah, that makes sense but let's see, let's see, let's see.",
        "tokens": [
          50760,
          400,
          370,
          718,
          311,
          536,
          466,
          341,
          24644,
          1507,
          13,
          865,
          11,
          300,
          1669,
          2020,
          457,
          718,
          311,
          536,
          11,
          718,
          311,
          536,
          11,
          718,
          311,
          536,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.252920869467915,
        "compression_ratio": 1.535031847133758,
        "end": 627.8,
        "id": 85,
        "no_speech_prob": 0.00006205038516782224,
        "seek": 60716,
        "start": 623.3199999999999,
        "temperature": 0,
        "text": " Yeah, so it's using the rectangle up to the height of the tip of the unicorn horn.",
        "tokens": [
          51172,
          865,
          11,
          370,
          309,
          311,
          1228,
          264,
          21930,
          493,
          281,
          264,
          6681,
          295,
          264,
          4125,
          295,
          264,
          28122,
          13482,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.22772157014305913,
        "compression_ratio": 1.3865030674846626,
        "end": 632.3599999999999,
        "id": 86,
        "no_speech_prob": 0.0029810022097080946,
        "seek": 62780,
        "start": 628.76,
        "temperature": 0,
        "text": " Almost look like candy here but",
        "tokens": [
          50412,
          12627,
          574,
          411,
          11237,
          510,
          457,
          50592
        ]
      },
      {
        "avg_logprob": -0.22772157014305913,
        "compression_ratio": 1.3865030674846626,
        "end": 642.8399999999999,
        "id": 87,
        "no_speech_prob": 0.0029810022097080946,
        "seek": 62780,
        "start": 635.8,
        "temperature": 0,
        "text": " yeah, I'm going to change these to rectangles. I can't tolerate it. I'm sorry everybody. This is,",
        "tokens": [
          50764,
          1338,
          11,
          286,
          478,
          516,
          281,
          1319,
          613,
          281,
          24077,
          904,
          13,
          286,
          393,
          380,
          25773,
          309,
          13,
          286,
          478,
          2597,
          2201,
          13,
          639,
          307,
          11,
          51116
        ]
      },
      {
        "avg_logprob": -0.22772157014305913,
        "compression_ratio": 1.3865030674846626,
        "end": 652.8399999999999,
        "id": 88,
        "no_speech_prob": 0.0029810022097080946,
        "seek": 62780,
        "start": 642.8399999999999,
        "temperature": 0,
        "text": " I really like these designs and I will maybe come back to them. If, I don't know if Miyamasa-mi,",
        "tokens": [
          51116,
          286,
          534,
          411,
          613,
          11347,
          293,
          286,
          486,
          1310,
          808,
          646,
          281,
          552,
          13,
          759,
          11,
          286,
          500,
          380,
          458,
          498,
          26195,
          335,
          9994,
          12,
          3057,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.23026119189315966,
        "compression_ratio": 1.537117903930131,
        "end": 658.12,
        "id": 89,
        "no_speech_prob": 0.00008750259439693764,
        "seek": 65284,
        "start": 652.84,
        "temperature": 0,
        "text": " while you're watching, if you, while I'm kind of getting, I'm going to explain the GitHub,",
        "tokens": [
          50364,
          1339,
          291,
          434,
          1976,
          11,
          498,
          291,
          11,
          1339,
          286,
          478,
          733,
          295,
          1242,
          11,
          286,
          478,
          516,
          281,
          2903,
          264,
          23331,
          11,
          50628
        ]
      },
      {
        "avg_logprob": -0.23026119189315966,
        "compression_ratio": 1.537117903930131,
        "end": 664.84,
        "id": 90,
        "no_speech_prob": 0.00008750259439693764,
        "seek": 65284,
        "start": 659.5600000000001,
        "temperature": 0,
        "text": " maybe make it a separate branch or just like push these unicorn horns into another branch.",
        "tokens": [
          50700,
          1310,
          652,
          309,
          257,
          4994,
          9819,
          420,
          445,
          411,
          2944,
          613,
          28122,
          28818,
          666,
          1071,
          9819,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23026119189315966,
        "compression_ratio": 1.537117903930131,
        "end": 670.44,
        "id": 91,
        "no_speech_prob": 0.00008750259439693764,
        "seek": 65284,
        "start": 664.84,
        "temperature": 0,
        "text": " But let's just make these a nice purple, green, blue, rainbow colored rectangles.",
        "tokens": [
          50964,
          583,
          718,
          311,
          445,
          652,
          613,
          257,
          1481,
          9656,
          11,
          3092,
          11,
          3344,
          11,
          18526,
          14332,
          24077,
          904,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.23026119189315966,
        "compression_ratio": 1.537117903930131,
        "end": 677.32,
        "id": 92,
        "no_speech_prob": 0.00008750259439693764,
        "seek": 65284,
        "start": 671.32,
        "temperature": 0,
        "text": " There's also something that's running really slow and I don't know why because it's not,",
        "tokens": [
          51288,
          821,
          311,
          611,
          746,
          300,
          311,
          2614,
          534,
          2964,
          293,
          286,
          500,
          380,
          458,
          983,
          570,
          309,
          311,
          406,
          11,
          51588
        ]
      },
      {
        "avg_logprob": -0.301489537305171,
        "compression_ratio": 1.6008583690987124,
        "end": 684.7600000000001,
        "id": 93,
        "no_speech_prob": 0.00009761524415807799,
        "seek": 67732,
        "start": 678.0400000000001,
        "temperature": 0,
        "text": " yeah, it's running at 30 frames per second which is reasonable. So let's do that. If anybody can",
        "tokens": [
          50400,
          1338,
          11,
          309,
          311,
          2614,
          412,
          2217,
          12083,
          680,
          1150,
          597,
          307,
          10585,
          13,
          407,
          718,
          311,
          360,
          300,
          13,
          759,
          4472,
          393,
          50736
        ]
      },
      {
        "avg_logprob": -0.301489537305171,
        "compression_ratio": 1.6008583690987124,
        "end": 693,
        "id": 94,
        "no_speech_prob": 0.00009761524415807799,
        "seek": 67732,
        "start": 684.7600000000001,
        "temperature": 0,
        "text": " do a pull request, so because I think these are a problem. They're lovely, beautiful",
        "tokens": [
          50736,
          360,
          257,
          2235,
          5308,
          11,
          370,
          570,
          286,
          519,
          613,
          366,
          257,
          1154,
          13,
          814,
          434,
          7496,
          11,
          2238,
          51148
        ]
      },
      {
        "avg_logprob": -0.301489537305171,
        "compression_ratio": 1.6008583690987124,
        "end": 700.36,
        "id": 95,
        "no_speech_prob": 0.00009761524415807799,
        "seek": 67732,
        "start": 693,
        "temperature": 0,
        "text": " unicorn horns but I think the collision stuff and yeah, they kind of, they resemble the poop emoji",
        "tokens": [
          51148,
          28122,
          28818,
          457,
          286,
          519,
          264,
          24644,
          1507,
          293,
          1338,
          11,
          436,
          733,
          295,
          11,
          436,
          36870,
          264,
          17153,
          31595,
          51516
        ]
      },
      {
        "avg_logprob": -0.301489537305171,
        "compression_ratio": 1.6008583690987124,
        "end": 703.96,
        "id": 96,
        "no_speech_prob": 0.00009761524415807799,
        "seek": 67732,
        "start": 700.36,
        "temperature": 0,
        "text": " but they're pink. There's, you know, there's a lot of, there's a lot of, it's just going to,",
        "tokens": [
          51516,
          457,
          436,
          434,
          7022,
          13,
          821,
          311,
          11,
          291,
          458,
          11,
          456,
          311,
          257,
          688,
          295,
          11,
          456,
          311,
          257,
          688,
          295,
          11,
          309,
          311,
          445,
          516,
          281,
          11,
          51696
        ]
      },
      {
        "avg_logprob": -0.30969492594401044,
        "compression_ratio": 1.4791666666666667,
        "end": 708.6,
        "id": 97,
        "no_speech_prob": 0.00045830701128579676,
        "seek": 70396,
        "start": 703.96,
        "temperature": 0,
        "text": " I'm just going to be uncomfortable the entire time. Okay.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          312,
          10532,
          264,
          2302,
          565,
          13,
          1033,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.30969492594401044,
        "compression_ratio": 1.4791666666666667,
        "end": 721.8000000000001,
        "id": 98,
        "no_speech_prob": 0.00045830701128579676,
        "seek": 70396,
        "start": 715.48,
        "temperature": 0,
        "text": " Use Vim instead of Atom. Okay, let's get, let me, let's go over to the whiteboard for a minute here",
        "tokens": [
          50940,
          8278,
          691,
          332,
          2602,
          295,
          1711,
          298,
          13,
          1033,
          11,
          718,
          311,
          483,
          11,
          718,
          385,
          11,
          718,
          311,
          352,
          670,
          281,
          264,
          2418,
          3787,
          337,
          257,
          3456,
          510,
          51256
        ]
      },
      {
        "avg_logprob": -0.30969492594401044,
        "compression_ratio": 1.4791666666666667,
        "end": 725.64,
        "id": 99,
        "no_speech_prob": 0.00045830701128579676,
        "seek": 70396,
        "start": 722.9200000000001,
        "temperature": 0,
        "text": " and let's do some erasing or let's not do some erasing.",
        "tokens": [
          51312,
          293,
          718,
          311,
          360,
          512,
          1189,
          3349,
          420,
          718,
          311,
          406,
          360,
          512,
          1189,
          3349,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.34251312414805096,
        "compression_ratio": 1.6238532110091743,
        "end": 729.64,
        "id": 100,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 72564,
        "start": 725.64,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50364,
          8239,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.34251312414805096,
        "compression_ratio": 1.6238532110091743,
        "end": 743.3199999999999,
        "id": 101,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 72564,
        "start": 734.36,
        "temperature": 0,
        "text": " I'm thinking. So I want to talk about neuro, I want to talk about neuro evolution",
        "tokens": [
          50800,
          286,
          478,
          1953,
          13,
          407,
          286,
          528,
          281,
          751,
          466,
          16499,
          11,
          286,
          528,
          281,
          751,
          466,
          16499,
          9303,
          51248
        ]
      },
      {
        "avg_logprob": -0.34251312414805096,
        "compression_ratio": 1.6238532110091743,
        "end": 750.76,
        "id": 102,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 72564,
        "start": 746.28,
        "temperature": 0,
        "text": " and I think that to start talking about neuro evolution, it wouldn't be the worst thing in",
        "tokens": [
          51396,
          293,
          286,
          519,
          300,
          281,
          722,
          1417,
          466,
          16499,
          9303,
          11,
          309,
          2759,
          380,
          312,
          264,
          5855,
          551,
          294,
          51620
        ]
      },
      {
        "avg_logprob": -0.23450267605665254,
        "compression_ratio": 1.5462962962962963,
        "end": 756.68,
        "id": 103,
        "no_speech_prob": 0.000032192314392887056,
        "seek": 75076,
        "start": 750.76,
        "temperature": 0,
        "text": " the world for me to have my leftover ending diagram from the doodle classification",
        "tokens": [
          50364,
          264,
          1002,
          337,
          385,
          281,
          362,
          452,
          27373,
          8121,
          10686,
          490,
          264,
          360,
          30013,
          21538,
          50660
        ]
      },
      {
        "avg_logprob": -0.23450267605665254,
        "compression_ratio": 1.5462962962962963,
        "end": 765.16,
        "id": 104,
        "no_speech_prob": 0.000032192314392887056,
        "seek": 75076,
        "start": 758.12,
        "temperature": 0,
        "text": " example because one of the key things I want to talk about is the difference between,",
        "tokens": [
          50732,
          1365,
          570,
          472,
          295,
          264,
          2141,
          721,
          286,
          528,
          281,
          751,
          466,
          307,
          264,
          2649,
          1296,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.23450267605665254,
        "compression_ratio": 1.5462962962962963,
        "end": 771.96,
        "id": 105,
        "no_speech_prob": 0.000032192314392887056,
        "seek": 75076,
        "start": 766.2,
        "temperature": 0,
        "text": " train whistle? What about like a train whistle for the pipe? Here, somebody can like,",
        "tokens": [
          51136,
          3847,
          23470,
          30,
          708,
          466,
          411,
          257,
          3847,
          23470,
          337,
          264,
          11240,
          30,
          1692,
          11,
          2618,
          393,
          411,
          11,
          51424
        ]
      },
      {
        "avg_logprob": -0.23450267605665254,
        "compression_ratio": 1.5462962962962963,
        "end": 778.28,
        "id": 106,
        "no_speech_prob": 0.000032192314392887056,
        "seek": 75076,
        "start": 773.16,
        "temperature": 0,
        "text": " right, I don't know, just make it a, just a rectangle, a plain rectangle. Okay.",
        "tokens": [
          51484,
          558,
          11,
          286,
          500,
          380,
          458,
          11,
          445,
          652,
          309,
          257,
          11,
          445,
          257,
          21930,
          11,
          257,
          11121,
          21930,
          13,
          1033,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.21493352086920486,
        "compression_ratio": 1.5,
        "end": 782.68,
        "id": 107,
        "no_speech_prob": 0.000009080442396225408,
        "seek": 78076,
        "start": 780.84,
        "temperature": 0,
        "text": " Is the chat going on in here? Okay.",
        "tokens": [
          50368,
          1119,
          264,
          5081,
          516,
          322,
          294,
          510,
          30,
          1033,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.21493352086920486,
        "compression_ratio": 1.5,
        "end": 793.96,
        "id": 108,
        "no_speech_prob": 0.000009080442396225408,
        "seek": 78076,
        "start": 785.8,
        "temperature": 0,
        "text": " So what I want to talk about is how back propagation and gradient descent, while the sort of",
        "tokens": [
          50616,
          407,
          437,
          286,
          528,
          281,
          751,
          466,
          307,
          577,
          646,
          38377,
          293,
          16235,
          23475,
          11,
          1339,
          264,
          1333,
          295,
          51024
        ]
      },
      {
        "avg_logprob": -0.21493352086920486,
        "compression_ratio": 1.5,
        "end": 802.52,
        "id": 109,
        "no_speech_prob": 0.000009080442396225408,
        "seek": 78076,
        "start": 795.56,
        "temperature": 0,
        "text": " standard or probably most well-known technique for training the weights of a neural network",
        "tokens": [
          51104,
          3832,
          420,
          1391,
          881,
          731,
          12,
          6861,
          6532,
          337,
          3097,
          264,
          17443,
          295,
          257,
          18161,
          3209,
          51452
        ]
      },
      {
        "avg_logprob": -0.21493352086920486,
        "compression_ratio": 1.5,
        "end": 809.8,
        "id": 110,
        "no_speech_prob": 0.000009080442396225408,
        "seek": 78076,
        "start": 803.56,
        "temperature": 0,
        "text": " is not the only technique. And so having this as a reference is good and then I need to,",
        "tokens": [
          51504,
          307,
          406,
          264,
          787,
          6532,
          13,
          400,
          370,
          1419,
          341,
          382,
          257,
          6408,
          307,
          665,
          293,
          550,
          286,
          643,
          281,
          11,
          51816
        ]
      },
      {
        "avg_logprob": -0.19256173647367036,
        "compression_ratio": 1.4099378881987579,
        "end": 818.4399999999999,
        "id": 111,
        "no_speech_prob": 0.000001459368945688766,
        "seek": 80980,
        "start": 809.88,
        "temperature": 0,
        "text": " I'm just going to, and then what I'll do is erase this and diagram out how a genetic algorithm can",
        "tokens": [
          50368,
          286,
          478,
          445,
          516,
          281,
          11,
          293,
          550,
          437,
          286,
          603,
          360,
          307,
          23525,
          341,
          293,
          10686,
          484,
          577,
          257,
          12462,
          9284,
          393,
          50796
        ]
      },
      {
        "avg_logprob": -0.19256173647367036,
        "compression_ratio": 1.4099378881987579,
        "end": 825.24,
        "id": 112,
        "no_speech_prob": 0.000001459368945688766,
        "seek": 80980,
        "start": 818.4399999999999,
        "temperature": 0,
        "text": " be used to train a neural network. Okay. So I think I'm going to get started with this right now.",
        "tokens": [
          50796,
          312,
          1143,
          281,
          3847,
          257,
          18161,
          3209,
          13,
          1033,
          13,
          407,
          286,
          519,
          286,
          478,
          516,
          281,
          483,
          1409,
          365,
          341,
          558,
          586,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.19256173647367036,
        "compression_ratio": 1.4099378881987579,
        "end": 832.3599999999999,
        "id": 113,
        "no_speech_prob": 0.000001459368945688766,
        "seek": 80980,
        "start": 830.4399999999999,
        "temperature": 0,
        "text": " Let's, let's take a look here.",
        "tokens": [
          51396,
          961,
          311,
          11,
          718,
          311,
          747,
          257,
          574,
          510,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.21972686124135213,
        "compression_ratio": 1.5932203389830508,
        "end": 843,
        "id": 114,
        "no_speech_prob": 0.00235962588340044,
        "seek": 83236,
        "start": 833.32,
        "temperature": 0,
        "text": " Oh, let's look at Simon's pull request. So here's the thing. This is very useful. Thank you,",
        "tokens": [
          50412,
          876,
          11,
          718,
          311,
          574,
          412,
          13193,
          311,
          2235,
          5308,
          13,
          407,
          510,
          311,
          264,
          551,
          13,
          639,
          307,
          588,
          4420,
          13,
          1044,
          291,
          11,
          50896
        ]
      },
      {
        "avg_logprob": -0.21972686124135213,
        "compression_ratio": 1.5932203389830508,
        "end": 850.2,
        "id": 115,
        "no_speech_prob": 0.00235962588340044,
        "seek": 83236,
        "start": 843,
        "temperature": 0,
        "text": " Simon, for this. I'm going to not, oh, I'm going to not merge this right now because I want to,",
        "tokens": [
          50896,
          13193,
          11,
          337,
          341,
          13,
          286,
          478,
          516,
          281,
          406,
          11,
          1954,
          11,
          286,
          478,
          516,
          281,
          406,
          22183,
          341,
          558,
          586,
          570,
          286,
          528,
          281,
          11,
          51256
        ]
      },
      {
        "avg_logprob": -0.21972686124135213,
        "compression_ratio": 1.5932203389830508,
        "end": 854.76,
        "id": 116,
        "no_speech_prob": 0.00235962588340044,
        "seek": 83236,
        "start": 851.4,
        "temperature": 0,
        "text": " I'm going to have to sort of like, the mechanics of the way the game works once I'm doing the",
        "tokens": [
          51316,
          286,
          478,
          516,
          281,
          362,
          281,
          1333,
          295,
          411,
          11,
          264,
          12939,
          295,
          264,
          636,
          264,
          1216,
          1985,
          1564,
          286,
          478,
          884,
          264,
          51484
        ]
      },
      {
        "avg_logprob": -0.2546013961603612,
        "compression_ratio": 1.507936507936508,
        "end": 862.6,
        "id": 117,
        "no_speech_prob": 0.10087073594331741,
        "seek": 85476,
        "start": 854.76,
        "temperature": 0,
        "text": " evolution thing is going to be pretty different. Okay. Okay. Just push to change back to pipes.",
        "tokens": [
          50364,
          9303,
          551,
          307,
          516,
          281,
          312,
          1238,
          819,
          13,
          1033,
          13,
          1033,
          13,
          1449,
          2944,
          281,
          1319,
          646,
          281,
          21882,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2546013961603612,
        "compression_ratio": 1.507936507936508,
        "end": 868.36,
        "id": 118,
        "no_speech_prob": 0.10087073594331741,
        "seek": 85476,
        "start": 862.6,
        "temperature": 0,
        "text": " Great. Thank you. So now I'm going to do this, get pull origin master, get pull. I just rename",
        "tokens": [
          50756,
          3769,
          13,
          1044,
          291,
          13,
          407,
          586,
          286,
          478,
          516,
          281,
          360,
          341,
          11,
          483,
          2235,
          4957,
          4505,
          11,
          483,
          2235,
          13,
          286,
          445,
          36741,
          51044
        ]
      },
      {
        "avg_logprob": -0.2546013961603612,
        "compression_ratio": 1.507936507936508,
        "end": 879.08,
        "id": 119,
        "no_speech_prob": 0.10087073594331741,
        "seek": 85476,
        "start": 868.36,
        "temperature": 0,
        "text": " it back to origin. And let's go here. There we go. Oh, look at those green pipes. Perfect. Oh,",
        "tokens": [
          51044,
          309,
          646,
          281,
          4957,
          13,
          400,
          718,
          311,
          352,
          510,
          13,
          821,
          321,
          352,
          13,
          876,
          11,
          574,
          412,
          729,
          3092,
          21882,
          13,
          10246,
          13,
          876,
          11,
          51580
        ]
      },
      {
        "avg_logprob": -0.25851150512695314,
        "compression_ratio": 1.425414364640884,
        "end": 881.88,
        "id": 120,
        "no_speech_prob": 0.000056497668992960826,
        "seek": 87908,
        "start": 879.72,
        "temperature": 0,
        "text": " green pipes. Everything is right with the world.",
        "tokens": [
          50396,
          3092,
          21882,
          13,
          5471,
          307,
          558,
          365,
          264,
          1002,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.25851150512695314,
        "compression_ratio": 1.425414364640884,
        "end": 892.12,
        "id": 121,
        "no_speech_prob": 0.000056497668992960826,
        "seek": 87908,
        "start": 886.2,
        "temperature": 0,
        "text": " This is very, quite a hard to play, but I'm also probably in the end going to change this",
        "tokens": [
          50720,
          639,
          307,
          588,
          11,
          1596,
          257,
          1152,
          281,
          862,
          11,
          457,
          286,
          478,
          611,
          1391,
          294,
          264,
          917,
          516,
          281,
          1319,
          341,
          51016
        ]
      },
      {
        "avg_logprob": -0.25851150512695314,
        "compression_ratio": 1.425414364640884,
        "end": 895.5600000000001,
        "id": 122,
        "no_speech_prob": 0.000056497668992960826,
        "seek": 87908,
        "start": 892.12,
        "temperature": 0,
        "text": " into circles, but okay. So that's good. I also, let me just see something here.",
        "tokens": [
          51016,
          666,
          13040,
          11,
          457,
          1392,
          13,
          407,
          300,
          311,
          665,
          13,
          286,
          611,
          11,
          718,
          385,
          445,
          536,
          746,
          510,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.25851150512695314,
        "compression_ratio": 1.425414364640884,
        "end": 900.76,
        "id": 123,
        "no_speech_prob": 0.000056497668992960826,
        "seek": 87908,
        "start": 899.1600000000001,
        "temperature": 0,
        "text": " Yeah, no, this is great. Okay. Perfect.",
        "tokens": [
          51368,
          865,
          11,
          572,
          11,
          341,
          307,
          869,
          13,
          1033,
          13,
          10246,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.24112989902496337,
        "compression_ratio": 1.12,
        "end": 908.6,
        "id": 124,
        "no_speech_prob": 0.0007672600331716239,
        "seek": 90076,
        "start": 901.24,
        "temperature": 0,
        "text": " Okay. Thank you for that. Now let us begin.",
        "tokens": [
          50388,
          1033,
          13,
          1044,
          291,
          337,
          300,
          13,
          823,
          718,
          505,
          1841,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.24112989902496337,
        "compression_ratio": 1.12,
        "end": 918.28,
        "id": 125,
        "no_speech_prob": 0.0007672600331716239,
        "seek": 90076,
        "start": 916.36,
        "temperature": 0,
        "text": " I'm trying to think if I want to,",
        "tokens": [
          51144,
          286,
          478,
          1382,
          281,
          519,
          498,
          286,
          528,
          281,
          11,
          51240
        ]
      },
      {
        "avg_logprob": -0.24112989902496337,
        "compression_ratio": 1.12,
        "end": 925.4,
        "id": 126,
        "no_speech_prob": 0.0007672600331716239,
        "seek": 90076,
        "start": 922.68,
        "temperature": 0,
        "text": " what am I doing here? Let's go to,",
        "tokens": [
          51460,
          437,
          669,
          286,
          884,
          510,
          30,
          961,
          311,
          352,
          281,
          11,
          51596
        ]
      },
      {
        "avg_logprob": -0.2825407743453979,
        "compression_ratio": 1.1296296296296295,
        "end": 935.4,
        "id": 127,
        "no_speech_prob": 0.0010321018053218722,
        "seek": 93076,
        "start": 931.72,
        "temperature": 0,
        "text": " so I'm going to go away from flappy bird for a second.",
        "tokens": [
          50412,
          370,
          286,
          478,
          516,
          281,
          352,
          1314,
          490,
          46338,
          7966,
          5255,
          337,
          257,
          1150,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.2825407743453979,
        "compression_ratio": 1.1296296296296295,
        "end": 956.04,
        "id": 128,
        "no_speech_prob": 0.0010321018053218722,
        "seek": 93076,
        "start": 946.36,
        "temperature": 0,
        "text": " Let's get rid of this. Come on, computer. Terminate you. Okay. Then",
        "tokens": [
          51144,
          961,
          311,
          483,
          3973,
          295,
          341,
          13,
          2492,
          322,
          11,
          3820,
          13,
          19835,
          13923,
          291,
          13,
          1033,
          13,
          1396,
          51628
        ]
      },
      {
        "avg_logprob": -0.29548752307891846,
        "compression_ratio": 1.236220472440945,
        "end": 959.88,
        "id": 129,
        "no_speech_prob": 0.004467364400625229,
        "seek": 95604,
        "start": 956.04,
        "temperature": 0,
        "text": " I want to open this up and Adam.",
        "tokens": [
          50364,
          286,
          528,
          281,
          1269,
          341,
          493,
          293,
          7938,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.29548752307891846,
        "compression_ratio": 1.236220472440945,
        "end": 967.16,
        "id": 130,
        "no_speech_prob": 0.004467364400625229,
        "seek": 95604,
        "start": 964.1999999999999,
        "temperature": 0,
        "text": " What's going on in here? I guess I changed some stuff at one point.",
        "tokens": [
          50772,
          708,
          311,
          516,
          322,
          294,
          510,
          30,
          286,
          2041,
          286,
          3105,
          512,
          1507,
          412,
          472,
          935,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.29548752307891846,
        "compression_ratio": 1.236220472440945,
        "end": 976.8399999999999,
        "id": 131,
        "no_speech_prob": 0.004467364400625229,
        "seek": 95604,
        "start": 971.7199999999999,
        "temperature": 0,
        "text": " And I need the neural network library and let's get XOR.",
        "tokens": [
          51148,
          400,
          286,
          643,
          264,
          18161,
          3209,
          6405,
          293,
          718,
          311,
          483,
          1783,
          2483,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.43516585610129616,
        "compression_ratio": 1.550387596899225,
        "end": 983.08,
        "id": 132,
        "no_speech_prob": 0.06186836212873459,
        "seek": 97684,
        "start": 977.48,
        "temperature": 0,
        "text": " So desktop neural network coding train. Am I in the wrong? I've been in the wrong",
        "tokens": [
          50396,
          407,
          14502,
          18161,
          3209,
          17720,
          3847,
          13,
          2012,
          286,
          294,
          264,
          2085,
          30,
          286,
          600,
          668,
          294,
          264,
          2085,
          50676
        ]
      },
      {
        "avg_logprob": -0.43516585610129616,
        "compression_ratio": 1.550387596899225,
        "end": 986.6800000000001,
        "id": 133,
        "no_speech_prob": 0.06186836212873459,
        "seek": 97684,
        "start": 983.08,
        "temperature": 0,
        "text": " camera screen all this time again, as I always am. Sorry, everybody.",
        "tokens": [
          50676,
          2799,
          2568,
          439,
          341,
          565,
          797,
          11,
          382,
          286,
          1009,
          669,
          13,
          4919,
          11,
          2201,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.43516585610129616,
        "compression_ratio": 1.550387596899225,
        "end": 1003.64,
        "id": 134,
        "no_speech_prob": 0.06186836212873459,
        "seek": 97684,
        "start": 996.6800000000001,
        "temperature": 0,
        "text": " Sorry, everybody. Sorry, everybody. I don't know.",
        "tokens": [
          51356,
          4919,
          11,
          2201,
          13,
          4919,
          11,
          2201,
          13,
          286,
          500,
          380,
          458,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.2325261015641062,
        "compression_ratio": 1.490566037735849,
        "end": 1013.64,
        "id": 135,
        "no_speech_prob": 0.000019833190890494734,
        "seek": 100684,
        "start": 1006.9200000000001,
        "temperature": 0,
        "text": " I'm doing my best. I'm doing my best. Okay. Let's see. What do I need now?",
        "tokens": [
          50368,
          286,
          478,
          884,
          452,
          1151,
          13,
          286,
          478,
          884,
          452,
          1151,
          13,
          1033,
          13,
          961,
          311,
          536,
          13,
          708,
          360,
          286,
          643,
          586,
          30,
          50704
        ]
      },
      {
        "avg_logprob": -0.2325261015641062,
        "compression_ratio": 1.490566037735849,
        "end": 1023.72,
        "id": 136,
        "no_speech_prob": 0.000019833190890494734,
        "seek": 100684,
        "start": 1014.84,
        "temperature": 0,
        "text": " Examples XOR. Let's copy paste that and let's just do, let's call neuro evolution.",
        "tokens": [
          50764,
          48591,
          1783,
          2483,
          13,
          961,
          311,
          5055,
          9163,
          300,
          293,
          718,
          311,
          445,
          360,
          11,
          718,
          311,
          818,
          16499,
          9303,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2325261015641062,
        "compression_ratio": 1.490566037735849,
        "end": 1032.8400000000001,
        "id": 137,
        "no_speech_prob": 0.000019833190890494734,
        "seek": 100684,
        "start": 1026.76,
        "temperature": 0,
        "text": " So I'm going to have an example and I'm going to, I want to do it with XOR, but",
        "tokens": [
          51360,
          407,
          286,
          478,
          516,
          281,
          362,
          364,
          1365,
          293,
          286,
          478,
          516,
          281,
          11,
          286,
          528,
          281,
          360,
          309,
          365,
          1783,
          2483,
          11,
          457,
          51664
        ]
      },
      {
        "avg_logprob": -0.3861456623783818,
        "compression_ratio": 1.0506329113924051,
        "end": 1048.12,
        "id": 138,
        "no_speech_prob": 0.0007672130595892668,
        "seek": 103684,
        "start": 1037.8,
        "temperature": 0,
        "text": " but let's leave that out for right now. Okay. All right. And so now I also want to,",
        "tokens": [
          50412,
          457,
          718,
          311,
          1856,
          300,
          484,
          337,
          558,
          586,
          13,
          1033,
          13,
          1057,
          558,
          13,
          400,
          370,
          586,
          286,
          611,
          528,
          281,
          11,
          50928
        ]
      },
      {
        "avg_logprob": -0.5803419610728389,
        "compression_ratio": 0.9605263157894737,
        "end": 1070.6,
        "id": 139,
        "no_speech_prob": 0.19186148047447205,
        "seek": 104812,
        "start": 1048.12,
        "temperature": 1,
        "text": " I want to, whoa. Yeah. No kidding. Examples, doodle classification. Oops.",
        "tokens": [
          50364,
          286,
          528,
          281,
          11,
          13310,
          13,
          865,
          13,
          883,
          9287,
          13,
          48591,
          11,
          360,
          30013,
          21538,
          13,
          21726,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.41872732455913836,
        "compression_ratio": 1.105263157894737,
        "end": 1099.9199999999998,
        "id": 140,
        "no_speech_prob": 0.6146124601364136,
        "seek": 107060,
        "start": 1070.6,
        "temperature": 0,
        "text": " Train. All right. All right. Test. Pretty good. Let's look at the rainbow here. Here",
        "tokens": [
          50364,
          28029,
          13,
          1057,
          558,
          13,
          1057,
          558,
          13,
          9279,
          13,
          10693,
          665,
          13,
          961,
          311,
          574,
          412,
          264,
          18526,
          510,
          13,
          1692,
          51830
        ]
      },
      {
        "avg_logprob": -0.33533963970109526,
        "compression_ratio": 1.373015873015873,
        "end": 1119.64,
        "id": 141,
        "no_speech_prob": 0.022285353392362595,
        "seek": 109992,
        "start": 1099.92,
        "temperature": 0,
        "text": " we go. All right. So that's going to be, okay. So this is weirdly, not you for when you",
        "tokens": [
          50364,
          321,
          352,
          13,
          1057,
          558,
          13,
          407,
          300,
          311,
          516,
          281,
          312,
          11,
          1392,
          13,
          407,
          341,
          307,
          48931,
          11,
          406,
          291,
          337,
          562,
          291,
          51350
        ]
      },
      {
        "avg_logprob": -0.33533963970109526,
        "compression_ratio": 1.373015873015873,
        "end": 1125.5600000000002,
        "id": 142,
        "no_speech_prob": 0.022285353392362595,
        "seek": 109992,
        "start": 1119.64,
        "temperature": 0,
        "text": " and everybody watching. This is weird. This is a new chapter that I, so the nature of",
        "tokens": [
          51350,
          293,
          2201,
          1976,
          13,
          639,
          307,
          3657,
          13,
          639,
          307,
          257,
          777,
          7187,
          300,
          286,
          11,
          370,
          264,
          3687,
          295,
          51646
        ]
      },
      {
        "avg_logprob": -0.281613119717302,
        "compression_ratio": 1.6515837104072397,
        "end": 1134,
        "id": 143,
        "no_speech_prob": 0.014281640760600567,
        "seek": 112556,
        "start": 1125.56,
        "temperature": 0,
        "text": " code book, if I go to the book's website, I'm currently working on a, the chapter nine",
        "tokens": [
          50364,
          3089,
          1446,
          11,
          498,
          286,
          352,
          281,
          264,
          1446,
          311,
          3144,
          11,
          286,
          478,
          4362,
          1364,
          322,
          257,
          11,
          264,
          7187,
          4949,
          50786
        ]
      },
      {
        "avg_logprob": -0.281613119717302,
        "compression_ratio": 1.6515837104072397,
        "end": 1139.3999999999999,
        "id": 144,
        "no_speech_prob": 0.014281640760600567,
        "seek": 112556,
        "start": 1134,
        "temperature": 0,
        "text": " is all about genetic algorithms and I have a video tutorial series about genetic algorithms.",
        "tokens": [
          50786,
          307,
          439,
          466,
          12462,
          14642,
          293,
          286,
          362,
          257,
          960,
          7073,
          2638,
          466,
          12462,
          14642,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.281613119717302,
        "compression_ratio": 1.6515837104072397,
        "end": 1144.84,
        "id": 145,
        "no_speech_prob": 0.014281640760600567,
        "seek": 112556,
        "start": 1139.3999999999999,
        "temperature": 0,
        "text": " Chapter 10 is about the basics of neural networks and the content that's currently in the book",
        "tokens": [
          51056,
          18874,
          1266,
          307,
          466,
          264,
          14688,
          295,
          18161,
          9590,
          293,
          264,
          2701,
          300,
          311,
          4362,
          294,
          264,
          1446,
          51328
        ]
      },
      {
        "avg_logprob": -0.281613119717302,
        "compression_ratio": 1.6515837104072397,
        "end": 1151,
        "id": 146,
        "no_speech_prob": 0.014281640760600567,
        "seek": 112556,
        "start": 1144.84,
        "temperature": 0,
        "text": " at the moment is pretty, it's from 2012. A lot's happened in the field of machine learning",
        "tokens": [
          51328,
          412,
          264,
          1623,
          307,
          1238,
          11,
          309,
          311,
          490,
          9125,
          13,
          316,
          688,
          311,
          2011,
          294,
          264,
          2519,
          295,
          3479,
          2539,
          51636
        ]
      },
      {
        "avg_logprob": -0.308338040890901,
        "compression_ratio": 1.5862068965517242,
        "end": 1161.76,
        "id": 147,
        "no_speech_prob": 0.04208381846547127,
        "seek": 115100,
        "start": 1151,
        "temperature": 0,
        "text": " since then, you might've noticed. And so I'm trying to rewrite this chapter and I've been",
        "tokens": [
          50364,
          1670,
          550,
          11,
          291,
          1062,
          600,
          5694,
          13,
          400,
          370,
          286,
          478,
          1382,
          281,
          28132,
          341,
          7187,
          293,
          286,
          600,
          668,
          50902
        ]
      },
      {
        "avg_logprob": -0.308338040890901,
        "compression_ratio": 1.5862068965517242,
        "end": 1165.52,
        "id": 148,
        "no_speech_prob": 0.04208381846547127,
        "seek": 115100,
        "start": 1161.76,
        "temperature": 0,
        "text": " making these video tutorials and examples in this neural network library and working on this",
        "tokens": [
          50902,
          1455,
          613,
          960,
          17616,
          293,
          5110,
          294,
          341,
          18161,
          3209,
          6405,
          293,
          1364,
          322,
          341,
          51090
        ]
      },
      {
        "avg_logprob": -0.308338040890901,
        "compression_ratio": 1.5862068965517242,
        "end": 1170.56,
        "id": 149,
        "no_speech_prob": 0.04208381846547127,
        "seek": 115100,
        "start": 1165.52,
        "temperature": 0,
        "text": " other thing called ML5, which is built on top of DeepLearn JS, all of which I am trying to get",
        "tokens": [
          51090,
          661,
          551,
          1219,
          21601,
          20,
          11,
          597,
          307,
          3094,
          322,
          1192,
          295,
          14895,
          11020,
          1083,
          33063,
          11,
          439,
          295,
          597,
          286,
          669,
          1382,
          281,
          483,
          51342
        ]
      },
      {
        "avg_logprob": -0.308338040890901,
        "compression_ratio": 1.5862068965517242,
        "end": 1175.92,
        "id": 150,
        "no_speech_prob": 0.04208381846547127,
        "seek": 115100,
        "start": 1170.56,
        "temperature": 0,
        "text": " through and to do more and more stuff with. That I'm currently working on as part of a new",
        "tokens": [
          51342,
          807,
          293,
          281,
          360,
          544,
          293,
          544,
          1507,
          365,
          13,
          663,
          286,
          478,
          4362,
          1364,
          322,
          382,
          644,
          295,
          257,
          777,
          51610
        ]
      },
      {
        "avg_logprob": -0.3287837164742606,
        "compression_ratio": 1.7942583732057416,
        "end": 1182.6000000000001,
        "id": 151,
        "no_speech_prob": 0.03732524439692497,
        "seek": 117592,
        "start": 1175.92,
        "temperature": 0,
        "text": " chapter 10 and now. So chapter nine being about genetic algorithms, I think calling it the",
        "tokens": [
          50364,
          7187,
          1266,
          293,
          586,
          13,
          407,
          7187,
          4949,
          885,
          466,
          12462,
          14642,
          11,
          286,
          519,
          5141,
          309,
          264,
          50698
        ]
      },
      {
        "avg_logprob": -0.3287837164742606,
        "compression_ratio": 1.7942583732057416,
        "end": 1186.04,
        "id": 152,
        "no_speech_prob": 0.03732524439692497,
        "seek": 117592,
        "start": 1182.6000000000001,
        "temperature": 0,
        "text": " evolution of code is sort of silly and I should just call it evolutionary computing or genetic",
        "tokens": [
          50698,
          9303,
          295,
          3089,
          307,
          1333,
          295,
          11774,
          293,
          286,
          820,
          445,
          818,
          309,
          27567,
          15866,
          420,
          12462,
          50870
        ]
      },
      {
        "avg_logprob": -0.3287837164742606,
        "compression_ratio": 1.7942583732057416,
        "end": 1193.0800000000002,
        "id": 153,
        "no_speech_prob": 0.03732524439692497,
        "seek": 117592,
        "start": 1186.04,
        "temperature": 0,
        "text": " algorithms, but that aside, chapter 10 about neural networks, chapter 11, which does not exist,",
        "tokens": [
          50870,
          14642,
          11,
          457,
          300,
          7359,
          11,
          7187,
          1266,
          466,
          18161,
          9590,
          11,
          7187,
          2975,
          11,
          597,
          775,
          406,
          2514,
          11,
          51222
        ]
      },
      {
        "avg_logprob": -0.3287837164742606,
        "compression_ratio": 1.7942583732057416,
        "end": 1201.88,
        "id": 154,
        "no_speech_prob": 0.03732524439692497,
        "seek": 117592,
        "start": 1193.0800000000002,
        "temperature": 0,
        "text": " is going to be about using genetic algorithms with neural networks. So I'm about to start the",
        "tokens": [
          51222,
          307,
          516,
          281,
          312,
          466,
          1228,
          12462,
          14642,
          365,
          18161,
          9590,
          13,
          407,
          286,
          478,
          466,
          281,
          722,
          264,
          51662
        ]
      },
      {
        "avg_logprob": -0.302035561923323,
        "compression_ratio": 1.6563876651982379,
        "end": 1207.6000000000001,
        "id": 155,
        "no_speech_prob": 0.1871052086353302,
        "seek": 120188,
        "start": 1201.88,
        "temperature": 0,
        "text": " first video for chapter 11 and repeat exactly what I just said because I think that would be",
        "tokens": [
          50364,
          700,
          960,
          337,
          7187,
          2975,
          293,
          7149,
          2293,
          437,
          286,
          445,
          848,
          570,
          286,
          519,
          300,
          576,
          312,
          50650
        ]
      },
      {
        "avg_logprob": -0.302035561923323,
        "compression_ratio": 1.6563876651982379,
        "end": 1214.92,
        "id": 156,
        "no_speech_prob": 0.1871052086353302,
        "seek": 120188,
        "start": 1207.6000000000001,
        "temperature": 0,
        "text": " useful just for part of the context. Because weirdly, typically in the past, for all my other",
        "tokens": [
          50650,
          4420,
          445,
          337,
          644,
          295,
          264,
          4319,
          13,
          1436,
          48931,
          11,
          5850,
          294,
          264,
          1791,
          11,
          337,
          439,
          452,
          661,
          51016
        ]
      },
      {
        "avg_logprob": -0.302035561923323,
        "compression_ratio": 1.6563876651982379,
        "end": 1220.3600000000001,
        "id": 157,
        "no_speech_prob": 0.1871052086353302,
        "seek": 120188,
        "start": 1214.92,
        "temperature": 0,
        "text": " nature of code content, the book came first and the videos came after the fact. And this is a",
        "tokens": [
          51016,
          3687,
          295,
          3089,
          2701,
          11,
          264,
          1446,
          1361,
          700,
          293,
          264,
          2145,
          1361,
          934,
          264,
          1186,
          13,
          400,
          341,
          307,
          257,
          51288
        ]
      },
      {
        "avg_logprob": -0.302035561923323,
        "compression_ratio": 1.6563876651982379,
        "end": 1224.8000000000002,
        "id": 158,
        "no_speech_prob": 0.1871052086353302,
        "seek": 120188,
        "start": 1220.3600000000001,
        "temperature": 0,
        "text": " little bit strange that I'm going to make the videos and then hopefully write that content into",
        "tokens": [
          51288,
          707,
          857,
          5861,
          300,
          286,
          478,
          516,
          281,
          652,
          264,
          2145,
          293,
          550,
          4696,
          2464,
          300,
          2701,
          666,
          51510
        ]
      },
      {
        "avg_logprob": -0.26308493711510483,
        "compression_ratio": 1.5932203389830508,
        "end": 1232.56,
        "id": 159,
        "no_speech_prob": 0.5734646320343018,
        "seek": 122480,
        "start": 1224.8,
        "temperature": 0,
        "text": " the book. All right, so I'm about to get started and I will get started. I'm just looking at my",
        "tokens": [
          50364,
          264,
          1446,
          13,
          1057,
          558,
          11,
          370,
          286,
          478,
          466,
          281,
          483,
          1409,
          293,
          286,
          486,
          483,
          1409,
          13,
          286,
          478,
          445,
          1237,
          412,
          452,
          50752
        ]
      },
      {
        "avg_logprob": -0.26308493711510483,
        "compression_ratio": 1.5932203389830508,
        "end": 1238.8,
        "id": 160,
        "no_speech_prob": 0.5734646320343018,
        "seek": 122480,
        "start": 1232.56,
        "temperature": 0,
        "text": " phone because, ah, because as I mentioned, I have a very exciting guest video that will be",
        "tokens": [
          50752,
          2593,
          570,
          11,
          3716,
          11,
          570,
          382,
          286,
          2835,
          11,
          286,
          362,
          257,
          588,
          4670,
          8341,
          960,
          300,
          486,
          312,
          51064
        ]
      },
      {
        "avg_logprob": -0.26308493711510483,
        "compression_ratio": 1.5932203389830508,
        "end": 1244.56,
        "id": 161,
        "no_speech_prob": 0.5734646320343018,
        "seek": 122480,
        "start": 1239.32,
        "temperature": 0,
        "text": " released to this channel hopefully next week sometime, but certainly sometime in the next week",
        "tokens": [
          51090,
          4736,
          281,
          341,
          2269,
          4696,
          958,
          1243,
          15053,
          11,
          457,
          3297,
          15053,
          294,
          264,
          958,
          1243,
          51352
        ]
      },
      {
        "avg_logprob": -0.26308493711510483,
        "compression_ratio": 1.5932203389830508,
        "end": 1249.52,
        "id": 162,
        "no_speech_prob": 0.5734646320343018,
        "seek": 122480,
        "start": 1244.56,
        "temperature": 0,
        "text": " or two. And that guest is coming to record at around 5 p.m. today. So I've got to finish up by",
        "tokens": [
          51352,
          420,
          732,
          13,
          400,
          300,
          8341,
          307,
          1348,
          281,
          2136,
          412,
          926,
          1025,
          280,
          13,
          76,
          13,
          965,
          13,
          407,
          286,
          600,
          658,
          281,
          2413,
          493,
          538,
          51600
        ]
      },
      {
        "avg_logprob": -0.24227279424667358,
        "compression_ratio": 1.710801393728223,
        "end": 1255.52,
        "id": 163,
        "no_speech_prob": 0.21199296414852142,
        "seek": 124952,
        "start": 1249.52,
        "temperature": 0,
        "text": " then. And just in case you were on the fence whether you wanted to be a patron of the Coding",
        "tokens": [
          50364,
          550,
          13,
          400,
          445,
          294,
          1389,
          291,
          645,
          322,
          264,
          15422,
          1968,
          291,
          1415,
          281,
          312,
          257,
          21843,
          295,
          264,
          383,
          8616,
          50664
        ]
      },
      {
        "avg_logprob": -0.24227279424667358,
        "compression_ratio": 1.710801393728223,
        "end": 1260.8,
        "id": 164,
        "no_speech_prob": 0.21199296414852142,
        "seek": 124952,
        "start": 1255.52,
        "temperature": 0,
        "text": " Train, sometimes, especially when I have guests, I'll keep a live stream going just to get a backup",
        "tokens": [
          50664,
          28029,
          11,
          2171,
          11,
          2318,
          562,
          286,
          362,
          9804,
          11,
          286,
          603,
          1066,
          257,
          1621,
          4309,
          516,
          445,
          281,
          483,
          257,
          14807,
          50928
        ]
      },
      {
        "avg_logprob": -0.24227279424667358,
        "compression_ratio": 1.710801393728223,
        "end": 1265.28,
        "id": 165,
        "no_speech_prob": 0.21199296414852142,
        "seek": 124952,
        "start": 1260.8,
        "temperature": 0,
        "text": " onto YouTube and I'll let people in the patron group kind of listen in on that as well. But don't",
        "tokens": [
          50928,
          3911,
          3088,
          293,
          286,
          603,
          718,
          561,
          294,
          264,
          21843,
          1594,
          733,
          295,
          2140,
          294,
          322,
          300,
          382,
          731,
          13,
          583,
          500,
          380,
          51152
        ]
      },
      {
        "avg_logprob": -0.24227279424667358,
        "compression_ratio": 1.710801393728223,
        "end": 1269.92,
        "id": 166,
        "no_speech_prob": 0.21199296414852142,
        "seek": 124952,
        "start": 1265.28,
        "temperature": 0,
        "text": " worry, there's no need to be a patron of the Coding Train. The video will be released. But if you like",
        "tokens": [
          51152,
          3292,
          11,
          456,
          311,
          572,
          643,
          281,
          312,
          257,
          21843,
          295,
          264,
          383,
          8616,
          28029,
          13,
          440,
          960,
          486,
          312,
          4736,
          13,
          583,
          498,
          291,
          411,
          51384
        ]
      },
      {
        "avg_logprob": -0.24227279424667358,
        "compression_ratio": 1.710801393728223,
        "end": 1278.16,
        "id": 167,
        "no_speech_prob": 0.21199296414852142,
        "seek": 124952,
        "start": 1269.92,
        "temperature": 0,
        "text": " a little advanced stuff, water. No, I don't have any water. This liquid beverage will have to do.",
        "tokens": [
          51384,
          257,
          707,
          7339,
          1507,
          11,
          1281,
          13,
          883,
          11,
          286,
          500,
          380,
          362,
          604,
          1281,
          13,
          639,
          6553,
          35519,
          486,
          362,
          281,
          360,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.3595382064136107,
        "compression_ratio": 1.3867403314917126,
        "end": 1286.16,
        "id": 168,
        "no_speech_prob": 0.00028681516414508224,
        "seek": 127952,
        "start": 1280.48,
        "temperature": 0,
        "text": " It's so slurpy. Can you hear that? That's like terrible.",
        "tokens": [
          50412,
          467,
          311,
          370,
          1061,
          374,
          8200,
          13,
          1664,
          291,
          1568,
          300,
          30,
          663,
          311,
          411,
          6237,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.3595382064136107,
        "compression_ratio": 1.3867403314917126,
        "end": 1298.24,
        "id": 169,
        "no_speech_prob": 0.00028681516414508224,
        "seek": 127952,
        "start": 1292.16,
        "temperature": 0,
        "text": " Coding Train brought to you by anonymous cup of coffee. I usually don't drink coffee while I'm",
        "tokens": [
          50996,
          383,
          8616,
          28029,
          3038,
          281,
          291,
          538,
          24932,
          4414,
          295,
          4982,
          13,
          286,
          2673,
          500,
          380,
          2822,
          4982,
          1339,
          286,
          478,
          51300
        ]
      },
      {
        "avg_logprob": -0.3595382064136107,
        "compression_ratio": 1.3867403314917126,
        "end": 1303.68,
        "id": 170,
        "no_speech_prob": 0.00028681516414508224,
        "seek": 127952,
        "start": 1298.24,
        "temperature": 0,
        "text": " live streaming because it only leads to bad things. But every once in a while, it's just necessary.",
        "tokens": [
          51300,
          1621,
          11791,
          570,
          309,
          787,
          6689,
          281,
          1578,
          721,
          13,
          583,
          633,
          1564,
          294,
          257,
          1339,
          11,
          309,
          311,
          445,
          4818,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.20843309595964957,
        "compression_ratio": 1.4473684210526316,
        "end": 1319.12,
        "id": 171,
        "no_speech_prob": 0.000319995335303247,
        "seek": 130952,
        "start": 1310.4,
        "temperature": 0,
        "text": " All right. So let's close this out. Let's leave.",
        "tokens": [
          50408,
          1057,
          558,
          13,
          407,
          718,
          311,
          1998,
          341,
          484,
          13,
          961,
          311,
          1856,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.20843309595964957,
        "compression_ratio": 1.4473684210526316,
        "end": 1326.16,
        "id": 172,
        "no_speech_prob": 0.000319995335303247,
        "seek": 130952,
        "start": 1320.72,
        "temperature": 0,
        "text": " Whoops. What did I do? No, I don't want you to move anything. Let's leave this here.",
        "tokens": [
          50924,
          45263,
          13,
          708,
          630,
          286,
          360,
          30,
          883,
          11,
          286,
          500,
          380,
          528,
          291,
          281,
          1286,
          1340,
          13,
          961,
          311,
          1856,
          341,
          510,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20843309595964957,
        "compression_ratio": 1.4473684210526316,
        "end": 1331.92,
        "id": 173,
        "no_speech_prob": 0.000319995335303247,
        "seek": 130952,
        "start": 1326.72,
        "temperature": 0,
        "text": " Move this out here. I'm just getting everything ready. Come on. Come on, Adam. Behave.",
        "tokens": [
          51224,
          10475,
          341,
          484,
          510,
          13,
          286,
          478,
          445,
          1242,
          1203,
          1919,
          13,
          2492,
          322,
          13,
          2492,
          322,
          11,
          7938,
          13,
          13068,
          946,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.44252651929855347,
        "compression_ratio": 1.344,
        "end": 1333.44,
        "id": 174,
        "no_speech_prob": 0.0011694979621097445,
        "seek": 133192,
        "start": 1332.4,
        "temperature": 0,
        "text": " I'll do this.",
        "tokens": [
          50388,
          286,
          603,
          360,
          341,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.44252651929855347,
        "compression_ratio": 1.344,
        "end": 1339.3000000000002,
        "id": 175,
        "no_speech_prob": 0.0011694979621097445,
        "seek": 133192,
        "start": 1338.8000000000002,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50708,
          1033,
          13,
          50733
        ]
      },
      {
        "avg_logprob": -0.44252651929855347,
        "compression_ratio": 1.344,
        "end": 1350.64,
        "id": 176,
        "no_speech_prob": 0.0011694979621097445,
        "seek": 133192,
        "start": 1345.8400000000001,
        "temperature": 0,
        "text": " All right. Here we go. Oh, yeah. It's fine. It's fine. I don't have a marker, but I will.",
        "tokens": [
          51060,
          1057,
          558,
          13,
          1692,
          321,
          352,
          13,
          876,
          11,
          1338,
          13,
          467,
          311,
          2489,
          13,
          467,
          311,
          2489,
          13,
          286,
          500,
          380,
          362,
          257,
          15247,
          11,
          457,
          286,
          486,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.44252651929855347,
        "compression_ratio": 1.344,
        "end": 1354.8000000000002,
        "id": 177,
        "no_speech_prob": 0.0011694979621097445,
        "seek": 133192,
        "start": 1352.4,
        "temperature": 0,
        "text": " I don't know if I need one this second, but it's like a...",
        "tokens": [
          51388,
          286,
          500,
          380,
          458,
          498,
          286,
          643,
          472,
          341,
          1150,
          11,
          457,
          309,
          311,
          411,
          257,
          485,
          51508
        ]
      },
      {
        "avg_logprob": -0.36595557717715993,
        "compression_ratio": 1.439306358381503,
        "end": 1360.08,
        "id": 178,
        "no_speech_prob": 0.0020507085137069225,
        "seek": 135480,
        "start": 1355.04,
        "temperature": 0,
        "text": " Some people have like a lovey or a teddy bear. That's their comfort object. It helps them sleep",
        "tokens": [
          50376,
          2188,
          561,
          362,
          411,
          257,
          959,
          88,
          420,
          257,
          45116,
          6155,
          13,
          663,
          311,
          641,
          3400,
          2657,
          13,
          467,
          3665,
          552,
          2817,
          50628
        ]
      },
      {
        "avg_logprob": -0.36595557717715993,
        "compression_ratio": 1.439306358381503,
        "end": 1370.1599999999999,
        "id": 179,
        "no_speech_prob": 0.0020507085137069225,
        "seek": 135480,
        "start": 1360.08,
        "temperature": 0,
        "text": " at night. I have a whiteboard marker. It's my comfort object.",
        "tokens": [
          50628,
          412,
          1818,
          13,
          286,
          362,
          257,
          2418,
          3787,
          15247,
          13,
          467,
          311,
          452,
          3400,
          2657,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.36595557717715993,
        "compression_ratio": 1.439306358381503,
        "end": 1380.3999999999999,
        "id": 180,
        "no_speech_prob": 0.0020507085137069225,
        "seek": 135480,
        "start": 1374.48,
        "temperature": 0,
        "text": " Hello. Welcome to the first video in a new chapter of the book, Nature of Code, chapter 11.",
        "tokens": [
          51348,
          2425,
          13,
          4027,
          281,
          264,
          700,
          960,
          294,
          257,
          777,
          7187,
          295,
          264,
          1446,
          11,
          20159,
          295,
          15549,
          11,
          7187,
          2975,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.3807590886166221,
        "compression_ratio": 1.6618705035971224,
        "end": 1386.48,
        "id": 181,
        "no_speech_prob": 0.006097426638007164,
        "seek": 138040,
        "start": 1381.3600000000001,
        "temperature": 0,
        "text": " Only strangely, chapter 11 does not exist. So I'm doing something a little different here,",
        "tokens": [
          50412,
          5686,
          39851,
          11,
          7187,
          2975,
          775,
          406,
          2514,
          13,
          407,
          286,
          478,
          884,
          746,
          257,
          707,
          819,
          510,
          11,
          50668
        ]
      },
      {
        "avg_logprob": -0.3807590886166221,
        "compression_ratio": 1.6618705035971224,
        "end": 1391.0400000000002,
        "id": 182,
        "no_speech_prob": 0.006097426638007164,
        "seek": 138040,
        "start": 1386.48,
        "temperature": 0,
        "text": " where all my previous other Nature of Code videos that go along with this Nature of Code book,",
        "tokens": [
          50668,
          689,
          439,
          452,
          3894,
          661,
          20159,
          295,
          15549,
          2145,
          300,
          352,
          2051,
          365,
          341,
          20159,
          295,
          15549,
          1446,
          11,
          50896
        ]
      },
      {
        "avg_logprob": -0.3807590886166221,
        "compression_ratio": 1.6618705035971224,
        "end": 1400.0800000000002,
        "id": 183,
        "no_speech_prob": 0.006097426638007164,
        "seek": 138040,
        "start": 1391.0400000000002,
        "temperature": 0,
        "text": " the book was written first, came out in 2012. And this is the current version of it. And then",
        "tokens": [
          50896,
          264,
          1446,
          390,
          3720,
          700,
          11,
          1361,
          484,
          294,
          9125,
          13,
          400,
          341,
          307,
          264,
          2190,
          3037,
          295,
          309,
          13,
          400,
          550,
          51348
        ]
      },
      {
        "avg_logprob": -0.3807590886166221,
        "compression_ratio": 1.6618705035971224,
        "end": 1404.88,
        "id": 184,
        "no_speech_prob": 0.006097426638007164,
        "seek": 138040,
        "start": 1400.0800000000002,
        "temperature": 0,
        "text": " I made videos after the fact. Now, what I'm going to do, I want... So chapter 9 is about genetic",
        "tokens": [
          51348,
          286,
          1027,
          2145,
          934,
          264,
          1186,
          13,
          823,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          286,
          528,
          485,
          407,
          7187,
          1722,
          307,
          466,
          12462,
          51588
        ]
      },
      {
        "avg_logprob": -0.3807590886166221,
        "compression_ratio": 1.6618705035971224,
        "end": 1408.3200000000002,
        "id": 185,
        "no_speech_prob": 0.006097426638007164,
        "seek": 138040,
        "start": 1404.88,
        "temperature": 0,
        "text": " algorithms and chapter 10 is about neural networks. And I have a bunch of videos that",
        "tokens": [
          51588,
          14642,
          293,
          7187,
          1266,
          307,
          466,
          18161,
          9590,
          13,
          400,
          286,
          362,
          257,
          3840,
          295,
          2145,
          300,
          51760
        ]
      },
      {
        "avg_logprob": -0.3661350250244141,
        "compression_ratio": 1.6979166666666667,
        "end": 1413.4399999999998,
        "id": 186,
        "no_speech_prob": 0.051076099276542664,
        "seek": 140832,
        "start": 1408.3999999999999,
        "temperature": 0,
        "text": " go along with both of those chapters. Today, I'm going to start talking about something that I want",
        "tokens": [
          50368,
          352,
          2051,
          365,
          1293,
          295,
          729,
          20013,
          13,
          2692,
          11,
          286,
          478,
          516,
          281,
          722,
          1417,
          466,
          746,
          300,
          286,
          528,
          50620
        ]
      },
      {
        "avg_logprob": -0.3661350250244141,
        "compression_ratio": 1.6979166666666667,
        "end": 1419.28,
        "id": 187,
        "no_speech_prob": 0.051076099276542664,
        "seek": 140832,
        "start": 1413.4399999999998,
        "temperature": 0,
        "text": " to be in the next edition of the Nature of Code in chapter 11 called neuroevolution. So I want to",
        "tokens": [
          50620,
          281,
          312,
          294,
          264,
          958,
          11377,
          295,
          264,
          20159,
          295,
          15549,
          294,
          7187,
          2975,
          1219,
          16499,
          13379,
          3386,
          13,
          407,
          286,
          528,
          281,
          50912
        ]
      },
      {
        "avg_logprob": -0.3661350250244141,
        "compression_ratio": 1.6979166666666667,
        "end": 1425.4399999999998,
        "id": 188,
        "no_speech_prob": 0.051076099276542664,
        "seek": 140832,
        "start": 1419.28,
        "temperature": 0,
        "text": " take the idea of a genetic algorithm and a neural network and use them together in a magical way",
        "tokens": [
          50912,
          747,
          264,
          1558,
          295,
          257,
          12462,
          9284,
          293,
          257,
          18161,
          3209,
          293,
          764,
          552,
          1214,
          294,
          257,
          12066,
          636,
          51220
        ]
      },
      {
        "avg_logprob": -0.3661350250244141,
        "compression_ratio": 1.6979166666666667,
        "end": 1431.36,
        "id": 189,
        "no_speech_prob": 0.051076099276542664,
        "seek": 140832,
        "start": 1425.4399999999998,
        "temperature": 0,
        "text": " to make wonderful things happen on the screen. Or it doesn't have to even be on a screen in some",
        "tokens": [
          51220,
          281,
          652,
          3715,
          721,
          1051,
          322,
          264,
          2568,
          13,
          1610,
          309,
          1177,
          380,
          362,
          281,
          754,
          312,
          322,
          257,
          2568,
          294,
          512,
          51516
        ]
      },
      {
        "avg_logprob": -0.3661350250244141,
        "compression_ratio": 1.6979166666666667,
        "end": 1437.4399999999998,
        "id": 190,
        "no_speech_prob": 0.051076099276542664,
        "seek": 140832,
        "start": 1431.36,
        "temperature": 0,
        "text": " other capacity that I can't even imagine right now. So what is neuroevolution? It's a very simple",
        "tokens": [
          51516,
          661,
          6042,
          300,
          286,
          393,
          380,
          754,
          3811,
          558,
          586,
          13,
          407,
          437,
          307,
          16499,
          13379,
          3386,
          30,
          467,
          311,
          257,
          588,
          2199,
          51820
        ]
      },
      {
        "avg_logprob": -0.23527153751306368,
        "compression_ratio": 1.6937269372693726,
        "end": 1444.0800000000002,
        "id": 191,
        "no_speech_prob": 0.00000880105380929308,
        "seek": 143744,
        "start": 1437.8400000000001,
        "temperature": 0,
        "text": " question. So what is it that I am going to do? So first of all, okay, so if you... wrong keyboard.",
        "tokens": [
          50384,
          1168,
          13,
          407,
          437,
          307,
          309,
          300,
          286,
          669,
          516,
          281,
          360,
          30,
          407,
          700,
          295,
          439,
          11,
          1392,
          11,
          370,
          498,
          291,
          485,
          2085,
          10186,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.23527153751306368,
        "compression_ratio": 1.6937269372693726,
        "end": 1451.6000000000001,
        "id": 192,
        "no_speech_prob": 0.00000880105380929308,
        "seek": 143744,
        "start": 1444.64,
        "temperature": 0,
        "text": " If you have watched some of my other neural network tutorials, the most recent thing before",
        "tokens": [
          50724,
          759,
          291,
          362,
          6337,
          512,
          295,
          452,
          661,
          18161,
          3209,
          17616,
          11,
          264,
          881,
          5162,
          551,
          949,
          51072
        ]
      },
      {
        "avg_logprob": -0.23527153751306368,
        "compression_ratio": 1.6937269372693726,
        "end": 1457.52,
        "id": 193,
        "no_speech_prob": 0.00000880105380929308,
        "seek": 143744,
        "start": 1451.6000000000001,
        "temperature": 0,
        "text": " the recording of this video that I made was a doodle classifier. It's kind of the classic",
        "tokens": [
          51072,
          264,
          6613,
          295,
          341,
          960,
          300,
          286,
          1027,
          390,
          257,
          360,
          30013,
          1508,
          9902,
          13,
          467,
          311,
          733,
          295,
          264,
          7230,
          51368
        ]
      },
      {
        "avg_logprob": -0.23527153751306368,
        "compression_ratio": 1.6937269372693726,
        "end": 1463.04,
        "id": 194,
        "no_speech_prob": 0.00000880105380929308,
        "seek": 143744,
        "start": 1457.52,
        "temperature": 0,
        "text": " machine learning classification example. I have some images, maybe they're handwritten digits,",
        "tokens": [
          51368,
          3479,
          2539,
          21538,
          1365,
          13,
          286,
          362,
          512,
          5267,
          11,
          1310,
          436,
          434,
          1011,
          26859,
          27011,
          11,
          51644
        ]
      },
      {
        "avg_logprob": -0.23527153751306368,
        "compression_ratio": 1.6937269372693726,
        "end": 1467.04,
        "id": 195,
        "no_speech_prob": 0.00000880105380929308,
        "seek": 143744,
        "start": 1463.04,
        "temperature": 0,
        "text": " maybe they're doodles of cats and rainbows and unicorns and all that sort of stuff.",
        "tokens": [
          51644,
          1310,
          436,
          434,
          360,
          35192,
          295,
          11111,
          293,
          4830,
          21118,
          293,
          28122,
          82,
          293,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.21880460920787992,
        "compression_ratio": 1.7207207207207207,
        "end": 1472.24,
        "id": 196,
        "no_speech_prob": 0.0000312018564727623,
        "seek": 146704,
        "start": 1467.2,
        "temperature": 0,
        "text": " I want to feed those things into a neural network and I want the neural network to classify them.",
        "tokens": [
          50372,
          286,
          528,
          281,
          3154,
          729,
          721,
          666,
          257,
          18161,
          3209,
          293,
          286,
          528,
          264,
          18161,
          3209,
          281,
          33872,
          552,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.21880460920787992,
        "compression_ratio": 1.7207207207207207,
        "end": 1477.84,
        "id": 197,
        "no_speech_prob": 0.0000312018564727623,
        "seek": 146704,
        "start": 1472.24,
        "temperature": 0,
        "text": " And if you've watched those videos, you might have noticed that there's this whole elaborate",
        "tokens": [
          50624,
          400,
          498,
          291,
          600,
          6337,
          729,
          2145,
          11,
          291,
          1062,
          362,
          5694,
          300,
          456,
          311,
          341,
          1379,
          20945,
          50904
        ]
      },
      {
        "avg_logprob": -0.21880460920787992,
        "compression_ratio": 1.7207207207207207,
        "end": 1486.3999999999999,
        "id": 198,
        "no_speech_prob": 0.0000312018564727623,
        "seek": 146704,
        "start": 1477.84,
        "temperature": 0,
        "text": " training process. The training process involves making that guess, having some labeled correct",
        "tokens": [
          50904,
          3097,
          1399,
          13,
          440,
          3097,
          1399,
          11626,
          1455,
          300,
          2041,
          11,
          1419,
          512,
          21335,
          3006,
          51332
        ]
      },
      {
        "avg_logprob": -0.21880460920787992,
        "compression_ratio": 1.7207207207207207,
        "end": 1491.68,
        "id": 199,
        "no_speech_prob": 0.0000312018564727623,
        "seek": 146704,
        "start": 1486.3999999999999,
        "temperature": 0,
        "text": " data, and then feeding that and then looking at the error, like what is it supposed to be versus",
        "tokens": [
          51332,
          1412,
          11,
          293,
          550,
          12919,
          300,
          293,
          550,
          1237,
          412,
          264,
          6713,
          11,
          411,
          437,
          307,
          309,
          3442,
          281,
          312,
          5717,
          51596
        ]
      },
      {
        "avg_logprob": -0.3254954285091824,
        "compression_ratio": 1.5706521739130435,
        "end": 1496.96,
        "id": 200,
        "no_speech_prob": 0.1441354751586914,
        "seek": 149168,
        "start": 1491.68,
        "temperature": 0,
        "text": " what it guessed and feeding that error back through the neural network. Just time out for a second.",
        "tokens": [
          50364,
          437,
          309,
          21852,
          293,
          12919,
          300,
          6713,
          646,
          807,
          264,
          18161,
          3209,
          13,
          1449,
          565,
          484,
          337,
          257,
          1150,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.3254954285091824,
        "compression_ratio": 1.5706521739130435,
        "end": 1509.04,
        "id": 201,
        "no_speech_prob": 0.1441354751586914,
        "seek": 149168,
        "start": 1501.3600000000001,
        "temperature": 0,
        "text": " Okay, these messages, I really take seriously the at messages to my watch. So little notes to me.",
        "tokens": [
          50848,
          1033,
          11,
          613,
          7897,
          11,
          286,
          534,
          747,
          6638,
          264,
          412,
          7897,
          281,
          452,
          1159,
          13,
          407,
          707,
          5570,
          281,
          385,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.3254954285091824,
        "compression_ratio": 1.5706521739130435,
        "end": 1516.48,
        "id": 202,
        "no_speech_prob": 0.1441354751586914,
        "seek": 149168,
        "start": 1510.48,
        "temperature": 0,
        "text": " Don't little... thank you for the kind comments. Okay, come back, come back to my momentum.",
        "tokens": [
          51304,
          1468,
          380,
          707,
          485,
          1309,
          291,
          337,
          264,
          733,
          3053,
          13,
          1033,
          11,
          808,
          646,
          11,
          808,
          646,
          281,
          452,
          11244,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.25824869246709914,
        "compression_ratio": 1.6578947368421053,
        "end": 1524.88,
        "id": 203,
        "no_speech_prob": 0.00017952610505744815,
        "seek": 151648,
        "start": 1517.3600000000001,
        "temperature": 0,
        "text": " So try not to direct message me during the live stream. I probably should set up a separate",
        "tokens": [
          50408,
          407,
          853,
          406,
          281,
          2047,
          3636,
          385,
          1830,
          264,
          1621,
          4309,
          13,
          286,
          1391,
          820,
          992,
          493,
          257,
          4994,
          50784
        ]
      },
      {
        "avg_logprob": -0.25824869246709914,
        "compression_ratio": 1.6578947368421053,
        "end": 1529.6,
        "id": 204,
        "no_speech_prob": 0.00017952610505744815,
        "seek": 151648,
        "start": 1524.88,
        "temperature": 0,
        "text": " Slack user that just sends the notifications so that regular other messages don't get here.",
        "tokens": [
          50784,
          37211,
          4195,
          300,
          445,
          14790,
          264,
          13426,
          370,
          300,
          3890,
          661,
          7897,
          500,
          380,
          483,
          510,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.25824869246709914,
        "compression_ratio": 1.6578947368421053,
        "end": 1539.84,
        "id": 205,
        "no_speech_prob": 0.00017952610505744815,
        "seek": 151648,
        "start": 1529.6,
        "temperature": 0,
        "text": " All right, all right, all right. Let's see here. Looking at the guess output versus the correct",
        "tokens": [
          51020,
          1057,
          558,
          11,
          439,
          558,
          11,
          439,
          558,
          13,
          961,
          311,
          536,
          510,
          13,
          11053,
          412,
          264,
          2041,
          5598,
          5717,
          264,
          3006,
          51532
        ]
      },
      {
        "avg_logprob": -0.25824869246709914,
        "compression_ratio": 1.6578947368421053,
        "end": 1544.8,
        "id": 206,
        "no_speech_prob": 0.00017952610505744815,
        "seek": 151648,
        "start": 1539.84,
        "temperature": 0,
        "text": " label, calculating an error and setting that error backwards through the network through a process",
        "tokens": [
          51532,
          7645,
          11,
          28258,
          364,
          6713,
          293,
          3287,
          300,
          6713,
          12204,
          807,
          264,
          3209,
          807,
          257,
          1399,
          51780
        ]
      },
      {
        "avg_logprob": -0.21592343937266956,
        "compression_ratio": 1.7012987012987013,
        "end": 1551.12,
        "id": 207,
        "no_speech_prob": 0.0000433188361057546,
        "seek": 154480,
        "start": 1544.8,
        "temperature": 0,
        "text": " known as back propagation, where all of the weights are tuned and changed. So while this is the",
        "tokens": [
          50364,
          2570,
          382,
          646,
          38377,
          11,
          689,
          439,
          295,
          264,
          17443,
          366,
          10870,
          293,
          3105,
          13,
          407,
          1339,
          341,
          307,
          264,
          50680
        ]
      },
      {
        "avg_logprob": -0.21592343937266956,
        "compression_ratio": 1.7012987012987013,
        "end": 1557.36,
        "id": 208,
        "no_speech_prob": 0.0000433188361057546,
        "seek": 154480,
        "start": 1551.84,
        "temperature": 0,
        "text": " most well known and probably most common and sort of standard technique for training a neural network,",
        "tokens": [
          50716,
          881,
          731,
          2570,
          293,
          1391,
          881,
          2689,
          293,
          1333,
          295,
          3832,
          6532,
          337,
          3097,
          257,
          18161,
          3209,
          11,
          50992
        ]
      },
      {
        "avg_logprob": -0.21592343937266956,
        "compression_ratio": 1.7012987012987013,
        "end": 1563.2,
        "id": 209,
        "no_speech_prob": 0.0000433188361057546,
        "seek": 154480,
        "start": 1557.9199999999998,
        "temperature": 0,
        "text": " back propagation with gradient descent, very fancy sounding, there are many other ways. I mean,",
        "tokens": [
          51020,
          646,
          38377,
          365,
          16235,
          23475,
          11,
          588,
          10247,
          24931,
          11,
          456,
          366,
          867,
          661,
          2098,
          13,
          286,
          914,
          11,
          51284
        ]
      },
      {
        "avg_logprob": -0.21592343937266956,
        "compression_ratio": 1.7012987012987013,
        "end": 1569.2,
        "id": 210,
        "no_speech_prob": 0.0000433188361057546,
        "seek": 154480,
        "start": 1563.2,
        "temperature": 0,
        "text": " there's other ways that you can train a neural network, one of which is using a genetic algorithm.",
        "tokens": [
          51284,
          456,
          311,
          661,
          2098,
          300,
          291,
          393,
          3847,
          257,
          18161,
          3209,
          11,
          472,
          295,
          597,
          307,
          1228,
          257,
          12462,
          9284,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.2028983487921246,
        "compression_ratio": 1.75,
        "end": 1574.4,
        "id": 211,
        "no_speech_prob": 0.00005307485116645694,
        "seek": 156920,
        "start": 1569.2,
        "temperature": 0,
        "text": " So what if we just threw away all of that calculus math and all of this sort of like",
        "tokens": [
          50364,
          407,
          437,
          498,
          321,
          445,
          11918,
          1314,
          439,
          295,
          300,
          33400,
          5221,
          293,
          439,
          295,
          341,
          1333,
          295,
          411,
          50624
        ]
      },
      {
        "avg_logprob": -0.2028983487921246,
        "compression_ratio": 1.75,
        "end": 1580,
        "id": 212,
        "no_speech_prob": 0.00005307485116645694,
        "seek": 156920,
        "start": 1574.4,
        "temperature": 0,
        "text": " error this, error that, and back propagation this, and we just said, hey, I've got an idea.",
        "tokens": [
          50624,
          6713,
          341,
          11,
          6713,
          300,
          11,
          293,
          646,
          38377,
          341,
          11,
          293,
          321,
          445,
          848,
          11,
          4177,
          11,
          286,
          600,
          658,
          364,
          1558,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2028983487921246,
        "compression_ratio": 1.75,
        "end": 1584.88,
        "id": 213,
        "no_speech_prob": 0.00005307485116645694,
        "seek": 156920,
        "start": 1580.72,
        "temperature": 0,
        "text": " Why don't I make, instead of having one neural network, why don't I make a thousand of them,",
        "tokens": [
          50940,
          1545,
          500,
          380,
          286,
          652,
          11,
          2602,
          295,
          1419,
          472,
          18161,
          3209,
          11,
          983,
          500,
          380,
          286,
          652,
          257,
          4714,
          295,
          552,
          11,
          51148
        ]
      },
      {
        "avg_logprob": -0.2028983487921246,
        "compression_ratio": 1.75,
        "end": 1589.28,
        "id": 214,
        "no_speech_prob": 0.00005307485116645694,
        "seek": 156920,
        "start": 1584.88,
        "temperature": 0,
        "text": " and I'll try them all. Maybe some of them will classify image, maybe one will classify images",
        "tokens": [
          51148,
          293,
          286,
          603,
          853,
          552,
          439,
          13,
          2704,
          512,
          295,
          552,
          486,
          33872,
          3256,
          11,
          1310,
          472,
          486,
          33872,
          5267,
          51368
        ]
      },
      {
        "avg_logprob": -0.2028983487921246,
        "compression_ratio": 1.75,
        "end": 1595.1200000000001,
        "id": 215,
        "no_speech_prob": 0.00005307485116645694,
        "seek": 156920,
        "start": 1589.28,
        "temperature": 0,
        "text": " better than another one does. Maybe I'll keep that one. And one just gets everything wrong,",
        "tokens": [
          51368,
          1101,
          813,
          1071,
          472,
          775,
          13,
          2704,
          286,
          603,
          1066,
          300,
          472,
          13,
          400,
          472,
          445,
          2170,
          1203,
          2085,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.17704995473225912,
        "compression_ratio": 1.7961538461538462,
        "end": 1601.6,
        "id": 216,
        "no_speech_prob": 0.0007793493568897247,
        "seek": 159512,
        "start": 1595.12,
        "temperature": 0,
        "text": " maybe I won't keep that one at all. And maybe I'll pick from the ones that kind of do well,",
        "tokens": [
          50364,
          1310,
          286,
          1582,
          380,
          1066,
          300,
          472,
          412,
          439,
          13,
          400,
          1310,
          286,
          603,
          1888,
          490,
          264,
          2306,
          300,
          733,
          295,
          360,
          731,
          11,
          50688
        ]
      },
      {
        "avg_logprob": -0.17704995473225912,
        "compression_ratio": 1.7961538461538462,
        "end": 1605.9199999999998,
        "id": 217,
        "no_speech_prob": 0.0007793493568897247,
        "seek": 159512,
        "start": 1601.6,
        "temperature": 0,
        "text": " and take those and duplicate them or mix them up to make a new population of neural networks",
        "tokens": [
          50688,
          293,
          747,
          729,
          293,
          23976,
          552,
          420,
          2890,
          552,
          493,
          281,
          652,
          257,
          777,
          4415,
          295,
          18161,
          9590,
          50904
        ]
      },
      {
        "avg_logprob": -0.17704995473225912,
        "compression_ratio": 1.7961538461538462,
        "end": 1612.32,
        "id": 218,
        "no_speech_prob": 0.0007793493568897247,
        "seek": 159512,
        "start": 1605.9199999999998,
        "temperature": 0,
        "text": " and see how those do. And this is the central idea of a genetic algorithm. Now, I might suggest",
        "tokens": [
          50904,
          293,
          536,
          577,
          729,
          360,
          13,
          400,
          341,
          307,
          264,
          5777,
          1558,
          295,
          257,
          12462,
          9284,
          13,
          823,
          11,
          286,
          1062,
          3402,
          51224
        ]
      },
      {
        "avg_logprob": -0.17704995473225912,
        "compression_ratio": 1.7961538461538462,
        "end": 1617.52,
        "id": 219,
        "no_speech_prob": 0.0007793493568897247,
        "seek": 159512,
        "start": 1612.32,
        "temperature": 0,
        "text": " if you want to, if genetic algorithms are totally new to you, you might want to pause this video",
        "tokens": [
          51224,
          498,
          291,
          528,
          281,
          11,
          498,
          12462,
          14642,
          366,
          3879,
          777,
          281,
          291,
          11,
          291,
          1062,
          528,
          281,
          10465,
          341,
          960,
          51484
        ]
      },
      {
        "avg_logprob": -0.17704995473225912,
        "compression_ratio": 1.7961538461538462,
        "end": 1621.84,
        "id": 220,
        "no_speech_prob": 0.0007793493568897247,
        "seek": 159512,
        "start": 1617.52,
        "temperature": 0,
        "text": " right now and go watch my genetic algorithm tutorials. If the concept of a neural network",
        "tokens": [
          51484,
          558,
          586,
          293,
          352,
          1159,
          452,
          12462,
          9284,
          17616,
          13,
          759,
          264,
          3410,
          295,
          257,
          18161,
          3209,
          51700
        ]
      },
      {
        "avg_logprob": -0.21887564255019365,
        "compression_ratio": 1.730909090909091,
        "end": 1626,
        "id": 221,
        "no_speech_prob": 0.013427753932774067,
        "seek": 162184,
        "start": 1621.84,
        "temperature": 0,
        "text": " is totally new to you, you could pause and go watch those tutorials, but you could probably",
        "tokens": [
          50364,
          307,
          3879,
          777,
          281,
          291,
          11,
          291,
          727,
          10465,
          293,
          352,
          1159,
          729,
          17616,
          11,
          457,
          291,
          727,
          1391,
          50572
        ]
      },
      {
        "avg_logprob": -0.21887564255019365,
        "compression_ratio": 1.730909090909091,
        "end": 1631.6,
        "id": 222,
        "no_speech_prob": 0.013427753932774067,
        "seek": 162184,
        "start": 1626,
        "temperature": 0,
        "text": " also just keep going because I'm going to cover almost all of this stuff anyway, kind of as I try",
        "tokens": [
          50572,
          611,
          445,
          1066,
          516,
          570,
          286,
          478,
          516,
          281,
          2060,
          1920,
          439,
          295,
          341,
          1507,
          4033,
          11,
          733,
          295,
          382,
          286,
          853,
          50852
        ]
      },
      {
        "avg_logprob": -0.21887564255019365,
        "compression_ratio": 1.730909090909091,
        "end": 1635.52,
        "id": 223,
        "no_speech_prob": 0.013427753932774067,
        "seek": 162184,
        "start": 1631.6,
        "temperature": 0,
        "text": " to sort this out. So I'm going to take a break for a minute. I'm going to erase this whiteboard",
        "tokens": [
          50852,
          281,
          1333,
          341,
          484,
          13,
          407,
          286,
          478,
          516,
          281,
          747,
          257,
          1821,
          337,
          257,
          3456,
          13,
          286,
          478,
          516,
          281,
          23525,
          341,
          2418,
          3787,
          51048
        ]
      },
      {
        "avg_logprob": -0.21887564255019365,
        "compression_ratio": 1.730909090909091,
        "end": 1639.04,
        "id": 224,
        "no_speech_prob": 0.013427753932774067,
        "seek": 162184,
        "start": 1635.52,
        "temperature": 0,
        "text": " here, what's there right now, left over from the doodle classification, and then I'm going to",
        "tokens": [
          51048,
          510,
          11,
          437,
          311,
          456,
          558,
          586,
          11,
          1411,
          670,
          490,
          264,
          360,
          30013,
          21538,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          51224
        ]
      },
      {
        "avg_logprob": -0.21887564255019365,
        "compression_ratio": 1.730909090909091,
        "end": 1645.9199999999998,
        "id": 225,
        "no_speech_prob": 0.013427753932774067,
        "seek": 162184,
        "start": 1639.04,
        "temperature": 0,
        "text": " diagram out how a neural network can be trained using a genetic algorithm, and then through that",
        "tokens": [
          51224,
          10686,
          484,
          577,
          257,
          18161,
          3209,
          393,
          312,
          8895,
          1228,
          257,
          12462,
          9284,
          11,
          293,
          550,
          807,
          300,
          51568
        ]
      },
      {
        "avg_logprob": -0.20906958807082404,
        "compression_ratio": 1.5532786885245902,
        "end": 1651.76,
        "id": 226,
        "no_speech_prob": 0.0006986716762185097,
        "seek": 164592,
        "start": 1645.92,
        "temperature": 0,
        "text": " diagram, I will discover things I need to add to my neural network code base. And at some point,",
        "tokens": [
          50364,
          10686,
          11,
          286,
          486,
          4411,
          721,
          286,
          643,
          281,
          909,
          281,
          452,
          18161,
          3209,
          3089,
          3096,
          13,
          400,
          412,
          512,
          935,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.20906958807082404,
        "compression_ratio": 1.5532786885245902,
        "end": 1659.8400000000001,
        "id": 227,
        "no_speech_prob": 0.0006986716762185097,
        "seek": 164592,
        "start": 1652.4,
        "temperature": 0,
        "text": " if all goes according to plan, you know, I have this particular, this was the doodle classifier",
        "tokens": [
          50688,
          498,
          439,
          1709,
          4650,
          281,
          1393,
          11,
          291,
          458,
          11,
          286,
          362,
          341,
          1729,
          11,
          341,
          390,
          264,
          360,
          30013,
          1508,
          9902,
          51060
        ]
      },
      {
        "avg_logprob": -0.20906958807082404,
        "compression_ratio": 1.5532786885245902,
        "end": 1666.48,
        "id": 228,
        "no_speech_prob": 0.0006986716762185097,
        "seek": 164592,
        "start": 1659.8400000000001,
        "temperature": 0,
        "text": " example, which you see here, it's classifying my rainbow. But what I want to do is take this",
        "tokens": [
          51060,
          1365,
          11,
          597,
          291,
          536,
          510,
          11,
          309,
          311,
          1508,
          5489,
          452,
          18526,
          13,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          747,
          341,
          51392
        ]
      },
      {
        "avg_logprob": -0.20906958807082404,
        "compression_ratio": 1.5532786885245902,
        "end": 1674.3200000000002,
        "id": 229,
        "no_speech_prob": 0.0006986716762185097,
        "seek": 164592,
        "start": 1667.3600000000001,
        "temperature": 0,
        "text": " version of the game, Flappy Coding Train, it's not very flappy, I guess, and see if I can use",
        "tokens": [
          51436,
          3037,
          295,
          264,
          1216,
          11,
          479,
          875,
          7966,
          383,
          8616,
          28029,
          11,
          309,
          311,
          406,
          588,
          46338,
          7966,
          11,
          286,
          2041,
          11,
          293,
          536,
          498,
          286,
          393,
          764,
          51784
        ]
      },
      {
        "avg_logprob": -0.23028368949890138,
        "compression_ratio": 1.7481203007518797,
        "end": 1680.96,
        "id": 230,
        "no_speech_prob": 0.000698670104611665,
        "seek": 167432,
        "start": 1674.32,
        "temperature": 0,
        "text": " a neural network that evolves to play this particular game. So that's going to be the goal",
        "tokens": [
          50364,
          257,
          18161,
          3209,
          300,
          43737,
          281,
          862,
          341,
          1729,
          1216,
          13,
          407,
          300,
          311,
          516,
          281,
          312,
          264,
          3387,
          50696
        ]
      },
      {
        "avg_logprob": -0.23028368949890138,
        "compression_ratio": 1.7481203007518797,
        "end": 1685.4399999999998,
        "id": 231,
        "no_speech_prob": 0.000698670104611665,
        "seek": 167432,
        "start": 1680.96,
        "temperature": 0,
        "text": " of this series, and then I have all sorts of other ideas for other types of neuroevolution",
        "tokens": [
          50696,
          295,
          341,
          2638,
          11,
          293,
          550,
          286,
          362,
          439,
          7527,
          295,
          661,
          3487,
          337,
          661,
          3467,
          295,
          16499,
          13379,
          3386,
          50920
        ]
      },
      {
        "avg_logprob": -0.23028368949890138,
        "compression_ratio": 1.7481203007518797,
        "end": 1693.28,
        "id": 232,
        "no_speech_prob": 0.000698670104611665,
        "seek": 167432,
        "start": 1686.08,
        "temperature": 0,
        "text": " tutorials. I believe this is often also referred to as NEET. NEET algorithm, because it's NEET,",
        "tokens": [
          50952,
          17616,
          13,
          286,
          1697,
          341,
          307,
          2049,
          611,
          10839,
          281,
          382,
          12384,
          4850,
          13,
          12384,
          4850,
          9284,
          11,
          570,
          309,
          311,
          12384,
          4850,
          11,
          51312
        ]
      },
      {
        "avg_logprob": -0.23028368949890138,
        "compression_ratio": 1.7481203007518797,
        "end": 1698.8799999999999,
        "id": 233,
        "no_speech_prob": 0.000698670104611665,
        "seek": 167432,
        "start": 1693.28,
        "temperature": 0,
        "text": " neuroevolution of, and see, here's the thing, I was just saying neuroevolution, and all the while,",
        "tokens": [
          51312,
          16499,
          13379,
          3386,
          295,
          11,
          293,
          536,
          11,
          510,
          311,
          264,
          551,
          11,
          286,
          390,
          445,
          1566,
          16499,
          13379,
          3386,
          11,
          293,
          439,
          264,
          1339,
          11,
          51592
        ]
      },
      {
        "avg_logprob": -0.23028368949890138,
        "compression_ratio": 1.7481203007518797,
        "end": 1703.36,
        "id": 234,
        "no_speech_prob": 0.000698670104611665,
        "seek": 167432,
        "start": 1698.8799999999999,
        "temperature": 0,
        "text": " it could sound so much smarter by saying neuroevolution of augmenting topologies. That's",
        "tokens": [
          51592,
          309,
          727,
          1626,
          370,
          709,
          20294,
          538,
          1566,
          16499,
          13379,
          3386,
          295,
          29919,
          278,
          1192,
          6204,
          13,
          663,
          311,
          51816
        ]
      },
      {
        "avg_logprob": -0.18064239568877638,
        "compression_ratio": 1.2816901408450705,
        "end": 1716.6399999999999,
        "id": 235,
        "no_speech_prob": 0.0007436907035298645,
        "seek": 170336,
        "start": 1703.36,
        "temperature": 0,
        "text": " totally NEET. All right, be back in a minute. Okay, I'm looking at the chat, everything seems",
        "tokens": [
          50364,
          3879,
          12384,
          4850,
          13,
          1057,
          558,
          11,
          312,
          646,
          294,
          257,
          3456,
          13,
          1033,
          11,
          286,
          478,
          1237,
          412,
          264,
          5081,
          11,
          1203,
          2544,
          51028
        ]
      },
      {
        "avg_logprob": -0.18064239568877638,
        "compression_ratio": 1.2816901408450705,
        "end": 1726.32,
        "id": 236,
        "no_speech_prob": 0.0007436907035298645,
        "seek": 170336,
        "start": 1716.6399999999999,
        "temperature": 0,
        "text": " okay. So now what I need to do is go erase this. Man, this copy is so slurpy. All right,",
        "tokens": [
          51028,
          1392,
          13,
          407,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          352,
          23525,
          341,
          13,
          2458,
          11,
          341,
          5055,
          307,
          370,
          1061,
          374,
          8200,
          13,
          1057,
          558,
          11,
          51512
        ]
      },
      {
        "avg_logprob": -0.25210393269856773,
        "compression_ratio": 1.4285714285714286,
        "end": 1730.6399999999999,
        "id": 237,
        "no_speech_prob": 0.0017545645823702216,
        "seek": 172632,
        "start": 1726.32,
        "temperature": 0,
        "text": " so let's do some erasing. If anyone has any questions.",
        "tokens": [
          50364,
          370,
          718,
          311,
          360,
          512,
          1189,
          3349,
          13,
          759,
          2878,
          575,
          604,
          1651,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.25210393269856773,
        "compression_ratio": 1.4285714285714286,
        "end": 1741.9199999999998,
        "id": 238,
        "no_speech_prob": 0.0017545645823702216,
        "seek": 172632,
        "start": 1738.3999999999999,
        "temperature": 0,
        "text": " I knew there was a reason why I didn't erase this whiteboard for like two weeks.",
        "tokens": [
          50968,
          286,
          2586,
          456,
          390,
          257,
          1778,
          983,
          286,
          994,
          380,
          23525,
          341,
          2418,
          3787,
          337,
          411,
          732,
          3259,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.25210393269856773,
        "compression_ratio": 1.4285714285714286,
        "end": 1754.24,
        "id": 239,
        "no_speech_prob": 0.0017545645823702216,
        "seek": 172632,
        "start": 1750,
        "temperature": 0,
        "text": " Should I mute my microphone? Is this like some horrible scratching sound that I'm making into?",
        "tokens": [
          51548,
          6454,
          286,
          24523,
          452,
          10952,
          30,
          1119,
          341,
          411,
          512,
          9263,
          29699,
          1626,
          300,
          286,
          478,
          1455,
          666,
          30,
          51760
        ]
      },
      {
        "avg_logprob": -0.3711040450865964,
        "compression_ratio": 1.4607843137254901,
        "end": 1757.84,
        "id": 240,
        "no_speech_prob": 0.000011659498341032304,
        "seek": 175424,
        "start": 1754.64,
        "temperature": 0,
        "text": " It's really better if I erase it immediately after I use it.",
        "tokens": [
          50384,
          467,
          311,
          534,
          1101,
          498,
          286,
          23525,
          309,
          4258,
          934,
          286,
          764,
          309,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.3711040450865964,
        "compression_ratio": 1.4607843137254901,
        "end": 1760.8,
        "id": 241,
        "no_speech_prob": 0.000011659498341032304,
        "seek": 175424,
        "start": 1759.28,
        "temperature": 0,
        "text": " Look at all this. Oh, it's so...",
        "tokens": [
          50616,
          2053,
          412,
          439,
          341,
          13,
          876,
          11,
          309,
          311,
          370,
          485,
          50692
        ]
      },
      {
        "avg_logprob": -0.3711040450865964,
        "compression_ratio": 1.4607843137254901,
        "end": 1766.8,
        "id": 242,
        "no_speech_prob": 0.000011659498341032304,
        "seek": 175424,
        "start": 1762.16,
        "temperature": 0,
        "text": " Anybody has any suggestions? Maybe there's like a squeegee company I could hire to come in here",
        "tokens": [
          50760,
          19082,
          575,
          604,
          13396,
          30,
          2704,
          456,
          311,
          411,
          257,
          8447,
          2828,
          68,
          2237,
          286,
          727,
          11158,
          281,
          808,
          294,
          510,
          50992
        ]
      },
      {
        "avg_logprob": -0.3711040450865964,
        "compression_ratio": 1.4607843137254901,
        "end": 1771.52,
        "id": 243,
        "no_speech_prob": 0.000011659498341032304,
        "seek": 175424,
        "start": 1767.52,
        "temperature": 0,
        "text": " and just like make this shiny and new spick and span.",
        "tokens": [
          51028,
          293,
          445,
          411,
          652,
          341,
          16997,
          293,
          777,
          637,
          618,
          293,
          16174,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.3711040450865964,
        "compression_ratio": 1.4607843137254901,
        "end": 1777.6,
        "id": 244,
        "no_speech_prob": 0.000011659498341032304,
        "seek": 175424,
        "start": 1774.4,
        "temperature": 0,
        "text": " You know, I said earlier today that my passion in life",
        "tokens": [
          51372,
          509,
          458,
          11,
          286,
          848,
          3071,
          965,
          300,
          452,
          5418,
          294,
          993,
          51532
        ]
      },
      {
        "avg_logprob": -0.3525938770987771,
        "compression_ratio": 1.5944700460829493,
        "end": 1784.48,
        "id": 245,
        "no_speech_prob": 0.0018101406749337912,
        "seek": 177760,
        "start": 1778.56,
        "temperature": 0,
        "text": " is indentation and spacing. And this is why linting, this idea of linting your coat is",
        "tokens": [
          50412,
          307,
          44494,
          399,
          293,
          27739,
          13,
          400,
          341,
          307,
          983,
          287,
          686,
          278,
          11,
          341,
          1558,
          295,
          287,
          686,
          278,
          428,
          10690,
          307,
          50708
        ]
      },
      {
        "avg_logprob": -0.3525938770987771,
        "compression_ratio": 1.5944700460829493,
        "end": 1791.28,
        "id": 246,
        "no_speech_prob": 0.0018101406749337912,
        "seek": 177760,
        "start": 1784.48,
        "temperature": 0,
        "text": " bringing such joy and happiness to me. And yet, in this moment right now, I think I might have",
        "tokens": [
          50708,
          5062,
          1270,
          6258,
          293,
          8324,
          281,
          385,
          13,
          400,
          1939,
          11,
          294,
          341,
          1623,
          558,
          586,
          11,
          286,
          519,
          286,
          1062,
          362,
          51048
        ]
      },
      {
        "avg_logprob": -0.3525938770987771,
        "compression_ratio": 1.5944700460829493,
        "end": 1799.1999999999998,
        "id": 247,
        "no_speech_prob": 0.0018101406749337912,
        "seek": 177760,
        "start": 1791.28,
        "temperature": 0,
        "text": " discovered that my true passion is whiteboard erasing. There's nothing more soothing and",
        "tokens": [
          51048,
          6941,
          300,
          452,
          2074,
          5418,
          307,
          2418,
          3787,
          1189,
          3349,
          13,
          821,
          311,
          1825,
          544,
          40704,
          293,
          51444
        ]
      },
      {
        "avg_logprob": -0.3525938770987771,
        "compression_ratio": 1.5944700460829493,
        "end": 1805.84,
        "id": 248,
        "no_speech_prob": 0.0018101406749337912,
        "seek": 177760,
        "start": 1799.1999999999998,
        "temperature": 0,
        "text": " meditative and relaxing than just a little cleaner. Look at the whiteboard.",
        "tokens": [
          51444,
          1205,
          14275,
          293,
          20103,
          813,
          445,
          257,
          707,
          16532,
          13,
          2053,
          412,
          264,
          2418,
          3787,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.25465198516845705,
        "compression_ratio": 1.3430656934306568,
        "end": 1811.52,
        "id": 249,
        "no_speech_prob": 0.00007141865353332832,
        "seek": 180584,
        "start": 1806,
        "temperature": 0,
        "text": " Look at the whiteboard. It's a good exercise. It's good physical therapy for my",
        "tokens": [
          50372,
          2053,
          412,
          264,
          2418,
          3787,
          13,
          467,
          311,
          257,
          665,
          5380,
          13,
          467,
          311,
          665,
          4001,
          9492,
          337,
          452,
          50648
        ]
      },
      {
        "avg_logprob": -0.25465198516845705,
        "compression_ratio": 1.3430656934306568,
        "end": 1816.8799999999999,
        "id": 250,
        "no_speech_prob": 0.00007141865353332832,
        "seek": 180584,
        "start": 1811.52,
        "temperature": 0,
        "text": " broken elbow that has pretty much healed all the way. Almost there.",
        "tokens": [
          50648,
          5463,
          18507,
          300,
          575,
          1238,
          709,
          20482,
          439,
          264,
          636,
          13,
          12627,
          456,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.25465198516845705,
        "compression_ratio": 1.3430656934306568,
        "end": 1832.48,
        "id": 251,
        "no_speech_prob": 0.00007141865353332832,
        "seek": 180584,
        "start": 1829.6,
        "temperature": 0,
        "text": " Just water. Make my hair look nicer.",
        "tokens": [
          51552,
          1449,
          1281,
          13,
          4387,
          452,
          2578,
          574,
          22842,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.3660420236133394,
        "compression_ratio": 1.5217391304347827,
        "end": 1838,
        "id": 252,
        "no_speech_prob": 0.00009170147677650675,
        "seek": 183248,
        "start": 1832.8,
        "temperature": 0,
        "text": " No nasty chemicals. No cleaning anything. Just a little water and a paper towel.",
        "tokens": [
          50380,
          883,
          17923,
          16152,
          13,
          883,
          8924,
          1340,
          13,
          1449,
          257,
          707,
          1281,
          293,
          257,
          3035,
          15755,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.3660420236133394,
        "compression_ratio": 1.5217391304347827,
        "end": 1843.1200000000001,
        "id": 253,
        "no_speech_prob": 0.00009170147677650675,
        "seek": 183248,
        "start": 1838.88,
        "temperature": 0,
        "text": " Paper towel isn't so good for the earth, but I guess the earth will have to survive using",
        "tokens": [
          50684,
          24990,
          15755,
          1943,
          380,
          370,
          665,
          337,
          264,
          4120,
          11,
          457,
          286,
          2041,
          264,
          4120,
          486,
          362,
          281,
          7867,
          1228,
          50896
        ]
      },
      {
        "avg_logprob": -0.3660420236133394,
        "compression_ratio": 1.5217391304347827,
        "end": 1849.52,
        "id": 254,
        "no_speech_prob": 0.00009170147677650675,
        "seek": 183248,
        "start": 1843.1200000000001,
        "temperature": 0,
        "text": " some paper towels. Maybe I can get a nice cloth or rag that's more reusable.",
        "tokens": [
          50896,
          512,
          3035,
          32819,
          13,
          2704,
          286,
          393,
          483,
          257,
          1481,
          13619,
          420,
          17539,
          300,
          311,
          544,
          41807,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.3660420236133394,
        "compression_ratio": 1.5217391304347827,
        "end": 1856.56,
        "id": 255,
        "no_speech_prob": 0.00009170147677650675,
        "seek": 183248,
        "start": 1852.48,
        "temperature": 0,
        "text": " How am I doing? How's this whiteboard look to you? Is it all clear?",
        "tokens": [
          51364,
          1012,
          669,
          286,
          884,
          30,
          1012,
          311,
          341,
          2418,
          3787,
          574,
          281,
          291,
          30,
          1119,
          309,
          439,
          1850,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.3872417449951172,
        "compression_ratio": 1.5522388059701493,
        "end": 1858.32,
        "id": 256,
        "no_speech_prob": 0.0003459568542893976,
        "seek": 185656,
        "start": 1856.6399999999999,
        "temperature": 0,
        "text": " It's pretty dirty, to be honest with you.",
        "tokens": [
          50368,
          467,
          311,
          1238,
          9360,
          11,
          281,
          312,
          3245,
          365,
          291,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.3872417449951172,
        "compression_ratio": 1.5522388059701493,
        "end": 1863.12,
        "id": 257,
        "no_speech_prob": 0.0003459568542893976,
        "seek": 185656,
        "start": 1859.84,
        "temperature": 0,
        "text": " I don't know what it looks like. Yeah, you can see all those smudges and things.",
        "tokens": [
          50528,
          286,
          500,
          380,
          458,
          437,
          309,
          1542,
          411,
          13,
          865,
          11,
          291,
          393,
          536,
          439,
          729,
          899,
          532,
          2880,
          293,
          721,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.3872417449951172,
        "compression_ratio": 1.5522388059701493,
        "end": 1873.6,
        "id": 258,
        "no_speech_prob": 0.0003459568542893976,
        "seek": 185656,
        "start": 1869.6,
        "temperature": 0,
        "text": " I'm sure you'll want to edit a highlight reel of me erasing the whiteboard.",
        "tokens": [
          51016,
          286,
          478,
          988,
          291,
          603,
          528,
          281,
          8129,
          257,
          5078,
          34973,
          295,
          385,
          1189,
          3349,
          264,
          2418,
          3787,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.3872417449951172,
        "compression_ratio": 1.5522388059701493,
        "end": 1879.44,
        "id": 259,
        "no_speech_prob": 0.0003459568542893976,
        "seek": 185656,
        "start": 1876.08,
        "temperature": 0,
        "text": " You can do one of those things in the video where you do it really,",
        "tokens": [
          51340,
          509,
          393,
          360,
          472,
          295,
          729,
          721,
          294,
          264,
          960,
          689,
          291,
          360,
          309,
          534,
          11,
          51508
        ]
      },
      {
        "avg_logprob": -0.3872417449951172,
        "compression_ratio": 1.5522388059701493,
        "end": 1881.6,
        "id": 260,
        "no_speech_prob": 0.0003459568542893976,
        "seek": 185656,
        "start": 1879.44,
        "temperature": 0,
        "text": " really fast instead of just doing a jump cut.",
        "tokens": [
          51508,
          534,
          2370,
          2602,
          295,
          445,
          884,
          257,
          3012,
          1723,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.7271826344151651,
        "compression_ratio": 2.080952380952381,
        "end": 1885.4399999999998,
        "id": 261,
        "no_speech_prob": 0.04145986586809158,
        "seek": 188160,
        "start": 1882.3999999999999,
        "temperature": 0.2,
        "text": " We got to up our coding train game here.",
        "tokens": [
          50404,
          492,
          658,
          281,
          493,
          527,
          17720,
          3847,
          1216,
          510,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.7271826344151651,
        "compression_ratio": 2.080952380952381,
        "end": 1895.6,
        "id": 262,
        "no_speech_prob": 0.04145986586809158,
        "seek": 188160,
        "start": 1890.6399999999999,
        "temperature": 0.2,
        "text": " I'm glad to see that the chat has moved on from discussing which coding language is the best to",
        "tokens": [
          50816,
          286,
          478,
          5404,
          281,
          536,
          300,
          264,
          5081,
          575,
          4259,
          322,
          490,
          10850,
          597,
          17720,
          2856,
          307,
          264,
          1151,
          281,
          51064
        ]
      },
      {
        "avg_logprob": -0.7271826344151651,
        "compression_ratio": 2.080952380952381,
        "end": 1898.7199999999998,
        "id": 263,
        "no_speech_prob": 0.04145986586809158,
        "seek": 188160,
        "start": 1895.6,
        "temperature": 0.2,
        "text": " how to effectively clean a whiteboard. The chat's actually not discussing that.",
        "tokens": [
          51064,
          577,
          281,
          8659,
          2541,
          257,
          2418,
          3787,
          13,
          440,
          5081,
          311,
          767,
          406,
          10850,
          300,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.7271826344151651,
        "compression_ratio": 2.080952380952381,
        "end": 1901.9199999999998,
        "id": 264,
        "no_speech_prob": 0.04145986586809158,
        "seek": 188160,
        "start": 1898.7199999999998,
        "temperature": 0.2,
        "text": " That's what I wish for. People are still like,",
        "tokens": [
          51220,
          663,
          311,
          437,
          286,
          3172,
          337,
          13,
          3432,
          366,
          920,
          411,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.7271826344151651,
        "compression_ratio": 2.080952380952381,
        "end": 1904.48,
        "id": 265,
        "no_speech_prob": 0.04145986586809158,
        "seek": 188160,
        "start": 1901.9199999999998,
        "temperature": 0.2,
        "text": " I'm not sure what I'm doing. I'm just trying to get it right.",
        "tokens": [
          51380,
          286,
          478,
          406,
          988,
          437,
          286,
          478,
          884,
          13,
          286,
          478,
          445,
          1382,
          281,
          483,
          309,
          558,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.7271826344151651,
        "compression_ratio": 2.080952380952381,
        "end": 1906.48,
        "id": 266,
        "no_speech_prob": 0.04145986586809158,
        "seek": 188160,
        "start": 1904.48,
        "temperature": 0.2,
        "text": " I'm trying to get it right. I'm trying to get it right.",
        "tokens": [
          51508,
          286,
          478,
          1382,
          281,
          483,
          309,
          558,
          13,
          286,
          478,
          1382,
          281,
          483,
          309,
          558,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.7271826344151651,
        "compression_ratio": 2.080952380952381,
        "end": 1908.48,
        "id": 267,
        "no_speech_prob": 0.04145986586809158,
        "seek": 188160,
        "start": 1906.48,
        "temperature": 0.2,
        "text": " I'm trying to get it right. I'm trying to get it right.",
        "tokens": [
          51608,
          286,
          478,
          1382,
          281,
          483,
          309,
          558,
          13,
          286,
          478,
          1382,
          281,
          483,
          309,
          558,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.24473867416381836,
        "compression_ratio": 1.5729537366548043,
        "end": 1910.96,
        "id": 268,
        "no_speech_prob": 0.17552532255649567,
        "seek": 190848,
        "start": 1908.56,
        "temperature": 0,
        "text": " I wish for. People are still like,",
        "tokens": [
          50368,
          286,
          3172,
          337,
          13,
          3432,
          366,
          920,
          411,
          11,
          50488
        ]
      },
      {
        "avg_logprob": -0.24473867416381836,
        "compression_ratio": 1.5729537366548043,
        "end": 1915.2,
        "id": 269,
        "no_speech_prob": 0.17552532255649567,
        "seek": 190848,
        "start": 1912.16,
        "temperature": 0,
        "text": " discussing MATLAB versus Pascal versus Java.",
        "tokens": [
          50548,
          10850,
          5904,
          11435,
          33,
          5717,
          41723,
          5717,
          10745,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.24473867416381836,
        "compression_ratio": 1.5729537366548043,
        "end": 1920.96,
        "id": 270,
        "no_speech_prob": 0.17552532255649567,
        "seek": 190848,
        "start": 1917.28,
        "temperature": 0,
        "text": " And yes, do you think I could have a YouTube channel where I just clean stuff",
        "tokens": [
          50804,
          400,
          2086,
          11,
          360,
          291,
          519,
          286,
          727,
          362,
          257,
          3088,
          2269,
          689,
          286,
          445,
          2541,
          1507,
          50988
        ]
      },
      {
        "avg_logprob": -0.24473867416381836,
        "compression_ratio": 1.5729537366548043,
        "end": 1923.84,
        "id": 271,
        "no_speech_prob": 0.17552532255649567,
        "seek": 190848,
        "start": 1920.96,
        "temperature": 0,
        "text": " and I'm like happy about it all the time? I would really like that.",
        "tokens": [
          50988,
          293,
          286,
          478,
          411,
          2055,
          466,
          309,
          439,
          264,
          565,
          30,
          286,
          576,
          534,
          411,
          300,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.24473867416381836,
        "compression_ratio": 1.5729537366548043,
        "end": 1928.48,
        "id": 272,
        "no_speech_prob": 0.17552532255649567,
        "seek": 190848,
        "start": 1923.84,
        "temperature": 0,
        "text": " I've been thinking of starting a gaming channel because I recently acquired a Nintendo Switch.",
        "tokens": [
          51132,
          286,
          600,
          668,
          1953,
          295,
          2891,
          257,
          9703,
          2269,
          570,
          286,
          3938,
          17554,
          257,
          11578,
          13893,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24473867416381836,
        "compression_ratio": 1.5729537366548043,
        "end": 1932.08,
        "id": 273,
        "no_speech_prob": 0.17552532255649567,
        "seek": 190848,
        "start": 1928.48,
        "temperature": 0,
        "text": " My kids and I, we play it a lot. And I was thinking, I don't know,",
        "tokens": [
          51364,
          1222,
          2301,
          293,
          286,
          11,
          321,
          862,
          309,
          257,
          688,
          13,
          400,
          286,
          390,
          1953,
          11,
          286,
          500,
          380,
          458,
          11,
          51544
        ]
      },
      {
        "avg_logprob": -0.24473867416381836,
        "compression_ratio": 1.5729537366548043,
        "end": 1935.44,
        "id": 274,
        "no_speech_prob": 0.17552532255649567,
        "seek": 190848,
        "start": 1932.08,
        "temperature": 0,
        "text": " maybe I'll make a gaming channel. That's all the rage.",
        "tokens": [
          51544,
          1310,
          286,
          603,
          652,
          257,
          9703,
          2269,
          13,
          663,
          311,
          439,
          264,
          20133,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.20048986417110834,
        "compression_ratio": 1.5236051502145922,
        "end": 1940.56,
        "id": 275,
        "no_speech_prob": 0.00046552380081266165,
        "seek": 193544,
        "start": 1935.44,
        "temperature": 0,
        "text": " I'm like a 44 year old human who can have a YouTube gaming channel.",
        "tokens": [
          50364,
          286,
          478,
          411,
          257,
          16408,
          1064,
          1331,
          1952,
          567,
          393,
          362,
          257,
          3088,
          9703,
          2269,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.20048986417110834,
        "compression_ratio": 1.5236051502145922,
        "end": 1943.8400000000001,
        "id": 276,
        "no_speech_prob": 0.00046552380081266165,
        "seek": 193544,
        "start": 1940.56,
        "temperature": 0,
        "text": " People might watch, probably not. That's a terrible idea.",
        "tokens": [
          50620,
          3432,
          1062,
          1159,
          11,
          1391,
          406,
          13,
          663,
          311,
          257,
          6237,
          1558,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.20048986417110834,
        "compression_ratio": 1.5236051502145922,
        "end": 1947.52,
        "id": 277,
        "no_speech_prob": 0.00046552380081266165,
        "seek": 193544,
        "start": 1943.8400000000001,
        "temperature": 0,
        "text": " Okay. I don't know how to set that up.",
        "tokens": [
          50784,
          1033,
          13,
          286,
          500,
          380,
          458,
          577,
          281,
          992,
          300,
          493,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.20048986417110834,
        "compression_ratio": 1.5236051502145922,
        "end": 1950.4,
        "id": 278,
        "no_speech_prob": 0.00046552380081266165,
        "seek": 193544,
        "start": 1947.52,
        "temperature": 0,
        "text": " I got to like get the output into the input to the output.",
        "tokens": [
          50968,
          286,
          658,
          281,
          411,
          483,
          264,
          5598,
          666,
          264,
          4846,
          281,
          264,
          5598,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.20048986417110834,
        "compression_ratio": 1.5236051502145922,
        "end": 1953.68,
        "id": 279,
        "no_speech_prob": 0.00046552380081266165,
        "seek": 193544,
        "start": 1951.52,
        "temperature": 0,
        "text": " This sort of thing. A Twitch channel.",
        "tokens": [
          51168,
          639,
          1333,
          295,
          551,
          13,
          316,
          22222,
          2269,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.20048986417110834,
        "compression_ratio": 1.5236051502145922,
        "end": 1957.92,
        "id": 280,
        "no_speech_prob": 0.00046552380081266165,
        "seek": 193544,
        "start": 1953.68,
        "temperature": 0,
        "text": " I'm a little bit afraid of Twitch, but I am a kind of a Twitchy person.",
        "tokens": [
          51276,
          286,
          478,
          257,
          707,
          857,
          4638,
          295,
          22222,
          11,
          457,
          286,
          669,
          257,
          733,
          295,
          257,
          22222,
          88,
          954,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.20048986417110834,
        "compression_ratio": 1.5236051502145922,
        "end": 1962,
        "id": 281,
        "no_speech_prob": 0.00046552380081266165,
        "seek": 193544,
        "start": 1959.68,
        "temperature": 0,
        "text": " All right. Let's see.",
        "tokens": [
          51576,
          1057,
          558,
          13,
          961,
          311,
          536,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1963.44,
        "id": 282,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1962.56,
        "temperature": 0,
        "text": " Take a second.",
        "tokens": [
          50392,
          3664,
          257,
          1150,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1968.24,
        "id": 283,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1965.92,
        "temperature": 0,
        "text": " I'm getting a very excellent suggestion in the chat.",
        "tokens": [
          50560,
          286,
          478,
          1242,
          257,
          588,
          7103,
          16541,
          294,
          264,
          5081,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1972.32,
        "id": 284,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1968.24,
        "temperature": 0,
        "text": " Take a second and mark the edges of the whiteboard so you don't draw off the camera.",
        "tokens": [
          50676,
          3664,
          257,
          1150,
          293,
          1491,
          264,
          8819,
          295,
          264,
          2418,
          3787,
          370,
          291,
          500,
          380,
          2642,
          766,
          264,
          2799,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1973.76,
        "id": 285,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1972.32,
        "temperature": 0,
        "text": " But what would be the fun in that?",
        "tokens": [
          50880,
          583,
          437,
          576,
          312,
          264,
          1019,
          294,
          300,
          30,
          50952
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1976.32,
        "id": 286,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1974.4,
        "temperature": 0,
        "text": " We should be living on the edge here, don't you think?",
        "tokens": [
          50984,
          492,
          820,
          312,
          2647,
          322,
          264,
          4691,
          510,
          11,
          500,
          380,
          291,
          519,
          30,
          51080
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1977.92,
        "id": 287,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1976.32,
        "temperature": 0,
        "text": " All right. Let's see. Let's make this happen.",
        "tokens": [
          51080,
          1057,
          558,
          13,
          961,
          311,
          536,
          13,
          961,
          311,
          652,
          341,
          1051,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1987.04,
        "id": 288,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1983.2,
        "temperature": 0,
        "text": " Yeah, I think I'm kind of all, for better or worse,",
        "tokens": [
          51424,
          865,
          11,
          286,
          519,
          286,
          478,
          733,
          295,
          439,
          11,
          337,
          1101,
          420,
          5324,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.21275874315682103,
        "compression_ratio": 1.6095617529880477,
        "end": 1991.6,
        "id": 289,
        "no_speech_prob": 0.008846917189657688,
        "seek": 196200,
        "start": 1987.84,
        "temperature": 0,
        "text": " I don't think that I can manage to like do different platforms.",
        "tokens": [
          51656,
          286,
          500,
          380,
          519,
          300,
          286,
          393,
          3067,
          281,
          411,
          360,
          819,
          9473,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 1994.56,
        "id": 290,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 1991.76,
        "temperature": 0,
        "text": " I've kind of got the YouTube thing going, so that's probably what I'm going to stick with.",
        "tokens": [
          50372,
          286,
          600,
          733,
          295,
          658,
          264,
          3088,
          551,
          516,
          11,
          370,
          300,
          311,
          1391,
          437,
          286,
          478,
          516,
          281,
          2897,
          365,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 1998.3999999999999,
        "id": 291,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 1996.08,
        "temperature": 0,
        "text": " I don't know. I'm always conflicted about this sort of thing.",
        "tokens": [
          50588,
          286,
          500,
          380,
          458,
          13,
          286,
          478,
          1009,
          6596,
          292,
          466,
          341,
          1333,
          295,
          551,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 2002.9599999999998,
        "id": 292,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 1998.3999999999999,
        "temperature": 0,
        "text": " Okay. Let me use a different color to mark the edges.",
        "tokens": [
          50704,
          1033,
          13,
          961,
          385,
          764,
          257,
          819,
          2017,
          281,
          1491,
          264,
          8819,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 2007.12,
        "id": 293,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 2005.4399999999998,
        "temperature": 0,
        "text": " This is actually already marked up here.",
        "tokens": [
          51056,
          639,
          307,
          767,
          1217,
          12658,
          493,
          510,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 2010.1599999999999,
        "id": 294,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 2008.1599999999999,
        "temperature": 0,
        "text": " I do actually have some markings already.",
        "tokens": [
          51192,
          286,
          360,
          767,
          362,
          512,
          39087,
          1217,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 2011.36,
        "id": 295,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 2010.1599999999999,
        "temperature": 0,
        "text": " This is marked here.",
        "tokens": [
          51292,
          639,
          307,
          12658,
          510,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 2015.9199999999998,
        "id": 296,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 2014.3999999999999,
        "temperature": 0,
        "text": " This is probably more correct.",
        "tokens": [
          51504,
          639,
          307,
          1391,
          544,
          3006,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 2020,
        "id": 297,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 2018.32,
        "temperature": 0,
        "text": " This is marked down here.",
        "tokens": [
          51700,
          639,
          307,
          12658,
          760,
          510,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.19500776986095392,
        "compression_ratio": 1.6754385964912282,
        "end": 2020.6399999999999,
        "id": 298,
        "no_speech_prob": 0.00002668797787919175,
        "seek": 199160,
        "start": 2020,
        "temperature": 0,
        "text": " Is that right?",
        "tokens": [
          51784,
          1119,
          300,
          558,
          30,
          51816
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2022.8799999999999,
        "id": 299,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2022.24,
        "temperature": 0,
        "text": " Let me see here.",
        "tokens": [
          50396,
          961,
          385,
          536,
          510,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2025.1999999999998,
        "id": 300,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2022.8799999999999,
        "temperature": 0,
        "text": " I promise I can't see my monitor.",
        "tokens": [
          50428,
          286,
          6228,
          286,
          393,
          380,
          536,
          452,
          6002,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2027.4399999999998,
        "id": 301,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2025.1999999999998,
        "temperature": 0,
        "text": " Down, down, down, down, down, down, down.",
        "tokens": [
          50544,
          9506,
          11,
          760,
          11,
          760,
          11,
          760,
          11,
          760,
          11,
          760,
          11,
          760,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2027.6799999999998,
        "id": 302,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2027.4399999999998,
        "temperature": 0,
        "text": " There.",
        "tokens": [
          50656,
          821,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2032.32,
        "id": 303,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2028.6399999999999,
        "temperature": 0,
        "text": " And over here, maybe.",
        "tokens": [
          50716,
          400,
          670,
          510,
          11,
          1310,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2034.8,
        "id": 304,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2033.84,
        "temperature": 0,
        "text": " Over here.",
        "tokens": [
          50976,
          4886,
          510,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2037.76,
        "id": 305,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2035.84,
        "temperature": 0,
        "text": " This is really the important one.",
        "tokens": [
          51076,
          639,
          307,
          534,
          264,
          1021,
          472,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2039.1999999999998,
        "id": 306,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2037.76,
        "temperature": 0,
        "text": " This is the one that I mess up all the time.",
        "tokens": [
          51172,
          639,
          307,
          264,
          472,
          300,
          286,
          2082,
          493,
          439,
          264,
          565,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2042,
        "id": 307,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2040.8799999999999,
        "temperature": 0,
        "text": " Can you see that line?",
        "tokens": [
          51328,
          1664,
          291,
          536,
          300,
          1622,
          30,
          51384
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2044.32,
        "id": 308,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2042.7199999999998,
        "temperature": 0,
        "text": " It should be where the tip of my finger is.",
        "tokens": [
          51420,
          467,
          820,
          312,
          689,
          264,
          4125,
          295,
          452,
          5984,
          307,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2045.28,
        "id": 309,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2044.32,
        "temperature": 0,
        "text": " I think I got it right.",
        "tokens": [
          51500,
          286,
          519,
          286,
          658,
          309,
          558,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.22214022097380265,
        "compression_ratio": 1.6292682926829267,
        "end": 2046.7199999999998,
        "id": 310,
        "no_speech_prob": 0.00015355668438132852,
        "seek": 202160,
        "start": 2045.28,
        "temperature": 0,
        "text": " Okay. Now that'll hopefully do.",
        "tokens": [
          51548,
          1033,
          13,
          823,
          300,
          603,
          4696,
          360,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2051.68,
        "id": 311,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2051.68,
        "temperature": 0,
        "text": "",
        "tokens": [],
        "words": []
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2053.2799999999997,
        "id": 312,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2051.68,
        "temperature": 0,
        "text": " So I'm just checking the chat.",
        "tokens": [
          50368,
          407,
          286,
          478,
          445,
          8568,
          264,
          5081,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2057.2799999999997,
        "id": 313,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2054.08,
        "temperature": 0,
        "text": " Doesn't your current streaming setup not take the output into the input?",
        "tokens": [
          50488,
          12955,
          380,
          428,
          2190,
          11791,
          8657,
          406,
          747,
          264,
          5598,
          666,
          264,
          4846,
          30,
          50648
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2058.08,
        "id": 314,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2057.2799999999997,
        "temperature": 0,
        "text": " It does.",
        "tokens": [
          50648,
          467,
          775,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2059.8399999999997,
        "id": 315,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2058.08,
        "temperature": 0,
        "text": " The output goes into the input here.",
        "tokens": [
          50688,
          440,
          5598,
          1709,
          666,
          264,
          4846,
          510,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2060.3199999999997,
        "id": 316,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2059.8399999999997,
        "temperature": 0,
        "text": " Uh-huh.",
        "tokens": [
          50776,
          4019,
          12,
          18710,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2060.64,
        "id": 317,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2060.3199999999997,
        "temperature": 0,
        "text": " It does.",
        "tokens": [
          50800,
          467,
          775,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2061.2799999999997,
        "id": 318,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2060.64,
        "temperature": 0,
        "text": " It totally does.",
        "tokens": [
          50816,
          467,
          3879,
          775,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2064.88,
        "id": 319,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2061.2799999999997,
        "temperature": 0,
        "text": " And then that input goes back to the output and back into a different input also.",
        "tokens": [
          50848,
          400,
          550,
          300,
          4846,
          1709,
          646,
          281,
          264,
          5598,
          293,
          646,
          666,
          257,
          819,
          4846,
          611,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2065.8399999999997,
        "id": 320,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2064.88,
        "temperature": 0,
        "text": " I'm really...",
        "tokens": [
          51028,
          286,
          478,
          534,
          485,
          51076
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2068.48,
        "id": 321,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2065.8399999999997,
        "temperature": 0,
        "text": " The input output thing is totally working.",
        "tokens": [
          51076,
          440,
          4846,
          5598,
          551,
          307,
          3879,
          1364,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2074.16,
        "id": 322,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2068.48,
        "temperature": 0,
        "text": " I have all the plugs going from one electronic machine to the other electronic machine,",
        "tokens": [
          51208,
          286,
          362,
          439,
          264,
          33899,
          516,
          490,
          472,
          10092,
          3479,
          281,
          264,
          661,
          10092,
          3479,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2076.08,
        "id": 323,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2074.16,
        "temperature": 0,
        "text": " and they're connected to the internet tube.",
        "tokens": [
          51492,
          293,
          436,
          434,
          4582,
          281,
          264,
          4705,
          9917,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.35436118858447974,
        "compression_ratio": 1.8389513108614233,
        "end": 2077.7599999999998,
        "id": 324,
        "no_speech_prob": 0.00018522536265663803,
        "seek": 205160,
        "start": 2076.88,
        "temperature": 0,
        "text": " That's how I'm live streaming.",
        "tokens": [
          51628,
          663,
          311,
          577,
          286,
          478,
          1621,
          11791,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2079.0400000000004,
        "id": 325,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2078.0800000000004,
        "temperature": 0,
        "text": " That's how I'm live streaming.",
        "tokens": [
          50380,
          663,
          311,
          577,
          286,
          478,
          1621,
          11791,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2085.2000000000003,
        "id": 326,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2079.0400000000004,
        "temperature": 0,
        "text": " So I could probably set that tube input output plug-based system up in my place of residence.",
        "tokens": [
          50428,
          407,
          286,
          727,
          1391,
          992,
          300,
          9917,
          4846,
          5598,
          5452,
          12,
          6032,
          1185,
          493,
          294,
          452,
          1081,
          295,
          19607,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2088.96,
        "id": 327,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2087.2000000000003,
        "temperature": 0,
        "text": " I should really get going with some content.",
        "tokens": [
          50836,
          286,
          820,
          534,
          483,
          516,
          365,
          512,
          2701,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2093.84,
        "id": 328,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2093.1200000000003,
        "temperature": 0,
        "text": " What time is it?",
        "tokens": [
          51132,
          708,
          565,
          307,
          309,
          30,
          51168
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2095.92,
        "id": 329,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2094.88,
        "temperature": 0,
        "text": " 3.55.",
        "tokens": [
          51220,
          805,
          13,
          13622,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2097.0400000000004,
        "id": 330,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2096.7200000000003,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51312,
          1033,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2097.92,
        "id": 331,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2097.6000000000004,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51356,
          1033,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2099.5200000000004,
        "id": 332,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2098.8,
        "temperature": 0,
        "text": " Okay, everyone.",
        "tokens": [
          51416,
          1033,
          11,
          1518,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2105.6800000000003,
        "id": 333,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2105.44,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51748,
          1033,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.20700008113209795,
        "compression_ratio": 1.3757225433526012,
        "end": 2106.48,
        "id": 334,
        "no_speech_prob": 0.00009028014028444886,
        "seek": 207776,
        "start": 2105.6800000000003,
        "temperature": 0,
        "text": " So let's...",
        "tokens": [
          51760,
          407,
          718,
          311,
          485,
          51800
        ]
      },
      {
        "avg_logprob": -0.19017580722240693,
        "compression_ratio": 1.7810945273631842,
        "end": 2106.8,
        "id": 335,
        "no_speech_prob": 0.00001428548785042949,
        "seek": 210648,
        "start": 2106.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50380
        ]
      },
      {
        "avg_logprob": -0.19017580722240693,
        "compression_ratio": 1.7810945273631842,
        "end": 2107.44,
        "id": 336,
        "no_speech_prob": 0.00001428548785042949,
        "seek": 210648,
        "start": 2106.8,
        "temperature": 0,
        "text": " Now that I have a...",
        "tokens": [
          50380,
          823,
          300,
          286,
          362,
          257,
          485,
          50412
        ]
      },
      {
        "avg_logprob": -0.19017580722240693,
        "compression_ratio": 1.7810945273631842,
        "end": 2111.6,
        "id": 337,
        "no_speech_prob": 0.00001428548785042949,
        "seek": 210648,
        "start": 2110,
        "temperature": 0,
        "text": " Now that I have a blank whiteboard,",
        "tokens": [
          50540,
          823,
          300,
          286,
          362,
          257,
          8247,
          2418,
          3787,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.19017580722240693,
        "compression_ratio": 1.7810945273631842,
        "end": 2118.48,
        "id": 338,
        "no_speech_prob": 0.00001428548785042949,
        "seek": 210648,
        "start": 2112.88,
        "temperature": 0,
        "text": " let me review the steps of a genetic algorithm and think of them in the context of a neural network.",
        "tokens": [
          50684,
          718,
          385,
          3131,
          264,
          4439,
          295,
          257,
          12462,
          9284,
          293,
          519,
          295,
          552,
          294,
          264,
          4319,
          295,
          257,
          18161,
          3209,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19017580722240693,
        "compression_ratio": 1.7810945273631842,
        "end": 2123.2,
        "id": 339,
        "no_speech_prob": 0.00001428548785042949,
        "seek": 210648,
        "start": 2118.48,
        "temperature": 0,
        "text": " So the first thing in a genetic algorithm that I need to do is create a population.",
        "tokens": [
          50964,
          407,
          264,
          700,
          551,
          294,
          257,
          12462,
          9284,
          300,
          286,
          643,
          281,
          360,
          307,
          1884,
          257,
          4415,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.19017580722240693,
        "compression_ratio": 1.7810945273631842,
        "end": 2132.88,
        "id": 340,
        "no_speech_prob": 0.00001428548785042949,
        "seek": 210648,
        "start": 2127.04,
        "temperature": 0,
        "text": " And the population is going to be a whole lot of neural networks.",
        "tokens": [
          51392,
          400,
          264,
          4415,
          307,
          516,
          281,
          312,
          257,
          1379,
          688,
          295,
          18161,
          9590,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.19017580722240693,
        "compression_ratio": 1.7810945273631842,
        "end": 2135.6,
        "id": 341,
        "no_speech_prob": 0.00001428548785042949,
        "seek": 210648,
        "start": 2132.88,
        "temperature": 0,
        "text": " Neural networks are the individual elements.",
        "tokens": [
          51684,
          1734,
          1807,
          9590,
          366,
          264,
          2609,
          4959,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2138.16,
        "id": 342,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2135.6,
        "temperature": 0,
        "text": " So maybe my population is 100 neural networks.",
        "tokens": [
          50364,
          407,
          1310,
          452,
          4415,
          307,
          2319,
          18161,
          9590,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2139.92,
        "id": 343,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2139.68,
        "temperature": 0,
        "text": " Two.",
        "tokens": [
          50568,
          4453,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2150,
        "id": 344,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2140.88,
        "temperature": 0,
        "text": " I need to evaluate fitness of neural networks.",
        "tokens": [
          50628,
          286,
          643,
          281,
          13059,
          15303,
          295,
          18161,
          9590,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2151.2799999999997,
        "id": 345,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2150.64,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51116,
          1033,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2152.48,
        "id": 346,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2151.2799999999997,
        "temperature": 0,
        "text": " So this is kind of like...",
        "tokens": [
          51148,
          407,
          341,
          307,
          733,
          295,
          411,
          485,
          51208
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2154.16,
        "id": 347,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2152.48,
        "temperature": 0,
        "text": " Again, this is kind of like the setup.",
        "tokens": [
          51208,
          3764,
          11,
          341,
          307,
          733,
          295,
          411,
          264,
          8657,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2156.48,
        "id": 348,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2154.72,
        "temperature": 0,
        "text": " I know that's kind of getting close to the top there.",
        "tokens": [
          51320,
          286,
          458,
          300,
          311,
          733,
          295,
          1242,
          1998,
          281,
          264,
          1192,
          456,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2159.2,
        "id": 349,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2156.48,
        "temperature": 0,
        "text": " It's the thing that I'm going to do once at the beginning of the program,",
        "tokens": [
          51408,
          467,
          311,
          264,
          551,
          300,
          286,
          478,
          516,
          281,
          360,
          1564,
          412,
          264,
          2863,
          295,
          264,
          1461,
          11,
          51544
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2160.96,
        "id": 350,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2159.2,
        "temperature": 0,
        "text": " my sort of initialization state.",
        "tokens": [
          51544,
          452,
          1333,
          295,
          5883,
          2144,
          1785,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.18285062020285087,
        "compression_ratio": 1.7477477477477477,
        "end": 2164.72,
        "id": 351,
        "no_speech_prob": 0.000006048878731235163,
        "seek": 213560,
        "start": 2162.08,
        "temperature": 0,
        "text": " Then this is this thing that I'm going to do for a loop.",
        "tokens": [
          51688,
          1396,
          341,
          307,
          341,
          551,
          300,
          286,
          478,
          516,
          281,
          360,
          337,
          257,
          6367,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.2781287299262153,
        "compression_ratio": 1.4691358024691359,
        "end": 2170.3199999999997,
        "id": 352,
        "no_speech_prob": 4.247017102443351e-7,
        "seek": 216472,
        "start": 2165.04,
        "temperature": 0,
        "text": " Generation after generation in p5, this might be called the draw loop.",
        "tokens": [
          50380,
          23898,
          934,
          5125,
          294,
          280,
          20,
          11,
          341,
          1062,
          312,
          1219,
          264,
          2642,
          6367,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2781287299262153,
        "compression_ratio": 1.4691358024691359,
        "end": 2173.6,
        "id": 353,
        "no_speech_prob": 4.247017102443351e-7,
        "seek": 216472,
        "start": 2171.12,
        "temperature": 0,
        "text": " I'm going to evaluate the fitness of all the neural networks.",
        "tokens": [
          50684,
          286,
          478,
          516,
          281,
          13059,
          264,
          15303,
          295,
          439,
          264,
          18161,
          9590,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.2781287299262153,
        "compression_ratio": 1.4691358024691359,
        "end": 2179.52,
        "id": 354,
        "no_speech_prob": 4.247017102443351e-7,
        "seek": 216472,
        "start": 2175.7599999999998,
        "temperature": 0,
        "text": " And then create a new population.",
        "tokens": [
          50916,
          400,
          550,
          1884,
          257,
          777,
          4415,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2781287299262153,
        "compression_ratio": 1.4691358024691359,
        "end": 2186.64,
        "id": 355,
        "no_speech_prob": 4.247017102443351e-7,
        "seek": 216472,
        "start": 2181.6,
        "temperature": 0,
        "text": " And the way I will do that is by pick",
        "tokens": [
          51208,
          400,
          264,
          636,
          286,
          486,
          360,
          300,
          307,
          538,
          1888,
          51460
        ]
      },
      {
        "avg_logprob": -0.2781287299262153,
        "compression_ratio": 1.4691358024691359,
        "end": 2192.48,
        "id": 356,
        "no_speech_prob": 4.247017102443351e-7,
        "seek": 216472,
        "start": 2189.2799999999997,
        "temperature": 0,
        "text": " quote unquote parents based on...",
        "tokens": [
          51592,
          6513,
          37557,
          3152,
          2361,
          322,
          485,
          51752
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2195.44,
        "id": 357,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2193.04,
        "temperature": 0,
        "text": " My handwriting is getting worse and worse over time.",
        "tokens": [
          50392,
          1222,
          39179,
          307,
          1242,
          5324,
          293,
          5324,
          670,
          565,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2196.64,
        "id": 358,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2195.44,
        "temperature": 0,
        "text": " Based on...",
        "tokens": [
          50512,
          18785,
          322,
          485,
          50572
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2201.2,
        "id": 359,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2198.4,
        "temperature": 0,
        "text": " Pick parents based on fitness scores.",
        "tokens": [
          50660,
          14129,
          3152,
          2361,
          322,
          15303,
          13444,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2205.52,
        "id": 360,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2204.32,
        "temperature": 0,
        "text": " Map to probability.",
        "tokens": [
          50956,
          22053,
          281,
          8482,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2208.96,
        "id": 361,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2207.04,
        "temperature": 0,
        "text": " I have so much room in this direction.",
        "tokens": [
          51092,
          286,
          362,
          370,
          709,
          1808,
          294,
          341,
          3513,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2209.92,
        "id": 362,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2208.96,
        "temperature": 0,
        "text": " Probability.",
        "tokens": [
          51188,
          8736,
          2310,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2214.88,
        "id": 363,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2210.48,
        "temperature": 0,
        "text": " And then I want to apply a crossover, which is a way...",
        "tokens": [
          51264,
          400,
          550,
          286,
          528,
          281,
          3079,
          257,
          33837,
          11,
          597,
          307,
          257,
          636,
          485,
          51484
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2217.28,
        "id": 364,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2214.88,
        "temperature": 0,
        "text": " If I pick two parents, for example,",
        "tokens": [
          51484,
          759,
          286,
          1888,
          732,
          3152,
          11,
          337,
          1365,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.419000728155977,
        "compression_ratio": 1.5,
        "end": 2221.28,
        "id": 365,
        "no_speech_prob": 0.0000217825872823596,
        "seek": 219248,
        "start": 2217.28,
        "temperature": 0,
        "text": " I can take half of their so-called digital DNA of one,",
        "tokens": [
          51604,
          286,
          393,
          747,
          1922,
          295,
          641,
          370,
          12,
          11880,
          4562,
          8272,
          295,
          472,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2224.48,
        "id": 366,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2221.36,
        "temperature": 0,
        "text": " half of the other, or some random amount of one, random amount of another,",
        "tokens": [
          50368,
          1922,
          295,
          264,
          661,
          11,
          420,
          512,
          4974,
          2372,
          295,
          472,
          11,
          4974,
          2372,
          295,
          1071,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2227.52,
        "id": 367,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2224.48,
        "temperature": 0,
        "text": " and combine them into a new entity.",
        "tokens": [
          50524,
          293,
          10432,
          552,
          666,
          257,
          777,
          13977,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2232.32,
        "id": 368,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2227.52,
        "temperature": 0,
        "text": " And then I can apply mutation, which would be...",
        "tokens": [
          50676,
          400,
          550,
          286,
          393,
          3079,
          27960,
          11,
          597,
          576,
          312,
          485,
          50916
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2234.6400000000003,
        "id": 369,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2232.32,
        "temperature": 0,
        "text": " Which is the step of saying, hey, let me look at the DNA.",
        "tokens": [
          50916,
          3013,
          307,
          264,
          1823,
          295,
          1566,
          11,
          4177,
          11,
          718,
          385,
          574,
          412,
          264,
          8272,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2237.84,
        "id": 370,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2234.6400000000003,
        "temperature": 0,
        "text": " Let me... I have this child DNA that is made from two parents.",
        "tokens": [
          51032,
          961,
          385,
          485,
          286,
          362,
          341,
          1440,
          8272,
          300,
          307,
          1027,
          490,
          732,
          3152,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2242.0800000000004,
        "id": 371,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2237.84,
        "temperature": 0,
        "text": " Let me randomly just change some of it up as if it's spontaneously mutating",
        "tokens": [
          51192,
          961,
          385,
          16979,
          445,
          1319,
          512,
          295,
          309,
          493,
          382,
          498,
          309,
          311,
          47632,
          5839,
          990,
          51404
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2244.5600000000004,
        "id": 372,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2242.0800000000004,
        "temperature": 0,
        "text": " to continue to have variation in the system.",
        "tokens": [
          51404,
          281,
          2354,
          281,
          362,
          12990,
          294,
          264,
          1185,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2247.36,
        "id": 373,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2244.5600000000004,
        "temperature": 0,
        "text": " So again, you could go watch my genetic algorithm tutorials",
        "tokens": [
          51528,
          407,
          797,
          11,
          291,
          727,
          352,
          1159,
          452,
          12462,
          9284,
          17616,
          51668
        ]
      },
      {
        "avg_logprob": -0.321558966565488,
        "compression_ratio": 1.6731391585760518,
        "end": 2250.32,
        "id": 374,
        "no_speech_prob": 0.00018813976203091443,
        "seek": 222128,
        "start": 2247.36,
        "temperature": 0,
        "text": " where I describe all this stuff in much greater detail.",
        "tokens": [
          51668,
          689,
          286,
          6786,
          439,
          341,
          1507,
          294,
          709,
          5044,
          2607,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2253.52,
        "id": 375,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2250.32,
        "temperature": 0,
        "text": " Much greater detail of different techniques and why and how.",
        "tokens": [
          50364,
          12313,
          5044,
          2607,
          295,
          819,
          7512,
          293,
          983,
          293,
          577,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2255.2000000000003,
        "id": 376,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2253.52,
        "temperature": 0,
        "text": " But this is the basic idea.",
        "tokens": [
          50524,
          583,
          341,
          307,
          264,
          3875,
          1558,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2258.2400000000002,
        "id": 377,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2255.2000000000003,
        "temperature": 0,
        "text": " But you might remember, if you did watch those tutorials,",
        "tokens": [
          50608,
          583,
          291,
          1062,
          1604,
          11,
          498,
          291,
          630,
          1159,
          729,
          17616,
          11,
          50760
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2260.8,
        "id": 378,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2258.2400000000002,
        "temperature": 0,
        "text": " that this is kind of like the algorithm.",
        "tokens": [
          50760,
          300,
          341,
          307,
          733,
          295,
          411,
          264,
          9284,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2261.36,
        "id": 379,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2260.8,
        "temperature": 0,
        "text": " And it...",
        "tokens": [
          50888,
          400,
          309,
          485,
          50916
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2263.44,
        "id": 380,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2261.36,
        "temperature": 0,
        "text": " Obviously, you can change it and be creative with it,",
        "tokens": [
          50916,
          7580,
          11,
          291,
          393,
          1319,
          309,
          293,
          312,
          5880,
          365,
          309,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2265.6000000000004,
        "id": 381,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2263.44,
        "temperature": 0,
        "text": " but it's kind of somewhat of a standard.",
        "tokens": [
          51020,
          457,
          309,
          311,
          733,
          295,
          8344,
          295,
          257,
          3832,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2270.88,
        "id": 382,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2265.6000000000004,
        "temperature": 0,
        "text": " The really tricky thing when you're making your own genetic algorithm",
        "tokens": [
          51128,
          440,
          534,
          12414,
          551,
          562,
          291,
          434,
          1455,
          428,
          1065,
          12462,
          9284,
          51392
        ]
      },
      {
        "avg_logprob": -0.21292012651390005,
        "compression_ratio": 1.61328125,
        "end": 2274.32,
        "id": 383,
        "no_speech_prob": 0.000003555983084879699,
        "seek": 225032,
        "start": 2270.88,
        "temperature": 0,
        "text": " and applying it to your own project is as follows.",
        "tokens": [
          51392,
          293,
          9275,
          309,
          281,
          428,
          1065,
          1716,
          307,
          382,
          10002,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2280.7200000000003,
        "id": 384,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2274.88,
        "temperature": 0,
        "text": " Number one is this idea of genotype versus phenotype.",
        "tokens": [
          50392,
          5118,
          472,
          307,
          341,
          1558,
          295,
          1049,
          13108,
          5717,
          7279,
          13108,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2285.6000000000004,
        "id": 385,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2282.4,
        "temperature": 0,
        "text": " What is that so-called digital DNA?",
        "tokens": [
          50768,
          708,
          307,
          300,
          370,
          12,
          11880,
          4562,
          8272,
          30,
          50928
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2287.1200000000003,
        "id": 386,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2286.2400000000002,
        "temperature": 0,
        "text": " The genotype.",
        "tokens": [
          50960,
          440,
          1049,
          13108,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2288.8,
        "id": 387,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2287.1200000000003,
        "temperature": 0,
        "text": " What is the data of that DNA?",
        "tokens": [
          51004,
          708,
          307,
          264,
          1412,
          295,
          300,
          8272,
          30,
          51088
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2290.96,
        "id": 388,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2289.36,
        "temperature": 0,
        "text": " And what does that data do?",
        "tokens": [
          51116,
          400,
          437,
          775,
          300,
          1412,
          360,
          30,
          51196
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2293.44,
        "id": 389,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2290.96,
        "temperature": 0,
        "text": " How does it express itself into a system?",
        "tokens": [
          51196,
          1012,
          775,
          309,
          5109,
          2564,
          666,
          257,
          1185,
          30,
          51320
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2295.44,
        "id": 390,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2293.44,
        "temperature": 0,
        "text": " So this is really key in thinking, okay,",
        "tokens": [
          51320,
          407,
          341,
          307,
          534,
          2141,
          294,
          1953,
          11,
          1392,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2297.92,
        "id": 391,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2295.44,
        "temperature": 0,
        "text": " well, the neural network is somehow the genotype.",
        "tokens": [
          51420,
          731,
          11,
          264,
          18161,
          3209,
          307,
          6063,
          264,
          1049,
          13108,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2300.4,
        "id": 392,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2298.6400000000003,
        "temperature": 0,
        "text": " What could be the data?",
        "tokens": [
          51580,
          708,
          727,
          312,
          264,
          1412,
          30,
          51668
        ]
      },
      {
        "avg_logprob": -0.16790950081565165,
        "compression_ratio": 1.728110599078341,
        "end": 2304.0800000000004,
        "id": 393,
        "no_speech_prob": 0.0021489388309419155,
        "seek": 227432,
        "start": 2300.4,
        "temperature": 0,
        "text": " So in fact, thinking back to my simplest neural network,",
        "tokens": [
          51668,
          407,
          294,
          1186,
          11,
          1953,
          646,
          281,
          452,
          22811,
          18161,
          3209,
          11,
          51852
        ]
      },
      {
        "avg_logprob": -0.23346569140752158,
        "compression_ratio": 1.787037037037037,
        "end": 2308.4,
        "id": 394,
        "no_speech_prob": 0.000008398063073400408,
        "seek": 230408,
        "start": 2304.7999999999997,
        "temperature": 0,
        "text": " just has two layers, really, a hidden layer and output layer.",
        "tokens": [
          50400,
          445,
          575,
          732,
          7914,
          11,
          534,
          11,
          257,
          7633,
          4583,
          293,
          5598,
          4583,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.23346569140752158,
        "compression_ratio": 1.787037037037037,
        "end": 2310.56,
        "id": 395,
        "no_speech_prob": 0.000008398063073400408,
        "seek": 230408,
        "start": 2308.4,
        "temperature": 0,
        "text": " The inputs come into the hidden layer.",
        "tokens": [
          50580,
          440,
          15743,
          808,
          666,
          264,
          7633,
          4583,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.23346569140752158,
        "compression_ratio": 1.787037037037037,
        "end": 2313.2799999999997,
        "id": 396,
        "no_speech_prob": 0.000008398063073400408,
        "seek": 230408,
        "start": 2310.56,
        "temperature": 0,
        "text": " They get processed from the hidden to the output.",
        "tokens": [
          50688,
          814,
          483,
          18846,
          490,
          264,
          7633,
          281,
          264,
          5598,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.23346569140752158,
        "compression_ratio": 1.787037037037037,
        "end": 2316.16,
        "id": 397,
        "no_speech_prob": 0.000008398063073400408,
        "seek": 230408,
        "start": 2313.2799999999997,
        "temperature": 0,
        "text": " They get processed, and then we have a final result.",
        "tokens": [
          50824,
          814,
          483,
          18846,
          11,
          293,
          550,
          321,
          362,
          257,
          2572,
          1874,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.23346569140752158,
        "compression_ratio": 1.787037037037037,
        "end": 2324.7999999999997,
        "id": 398,
        "no_speech_prob": 0.000008398063073400408,
        "seek": 230408,
        "start": 2316.72,
        "temperature": 0,
        "text": " So the core elements of those layers are weights and biases.",
        "tokens": [
          50996,
          407,
          264,
          4965,
          4959,
          295,
          729,
          7914,
          366,
          17443,
          293,
          32152,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.23346569140752158,
        "compression_ratio": 1.787037037037037,
        "end": 2329.6,
        "id": 399,
        "no_speech_prob": 0.000008398063073400408,
        "seek": 230408,
        "start": 2325.52,
        "temperature": 0,
        "text": " So all the weight matrices and the bias vectors,",
        "tokens": [
          51436,
          407,
          439,
          264,
          3364,
          32284,
          293,
          264,
          12577,
          18875,
          11,
          51640
        ]
      },
      {
        "avg_logprob": -0.23346569140752158,
        "compression_ratio": 1.787037037037037,
        "end": 2334,
        "id": 400,
        "no_speech_prob": 0.000008398063073400408,
        "seek": 230408,
        "start": 2330.16,
        "temperature": 0,
        "text": " those things, which I describe in detail in my neural network tutorials,",
        "tokens": [
          51668,
          729,
          721,
          11,
          597,
          286,
          6786,
          294,
          2607,
          294,
          452,
          18161,
          3209,
          17616,
          11,
          51860
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2338.4,
        "id": 401,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2334.48,
        "temperature": 0,
        "text": " make up the genotype of the neural network, the core aspect of it.",
        "tokens": [
          50388,
          652,
          493,
          264,
          1049,
          13108,
          295,
          264,
          18161,
          3209,
          11,
          264,
          4965,
          4171,
          295,
          309,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2340.16,
        "id": 402,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2338.4,
        "temperature": 0,
        "text": " Now, the phenotype is the expression.",
        "tokens": [
          50584,
          823,
          11,
          264,
          7279,
          13108,
          307,
          264,
          6114,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2343.28,
        "id": 403,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2340.16,
        "temperature": 0,
        "text": " It's really, really, what am I using the neural network for?",
        "tokens": [
          50672,
          467,
          311,
          534,
          11,
          534,
          11,
          437,
          669,
          286,
          1228,
          264,
          18161,
          3209,
          337,
          30,
          50828
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2346.88,
        "id": 404,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2343.28,
        "temperature": 0,
        "text": " So for example, the expression of the neural network",
        "tokens": [
          50828,
          407,
          337,
          1365,
          11,
          264,
          6114,
          295,
          264,
          18161,
          3209,
          51008
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2348.96,
        "id": 405,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2346.88,
        "temperature": 0,
        "text": " might be in the game Flappy Bird,",
        "tokens": [
          51008,
          1062,
          312,
          294,
          264,
          1216,
          479,
          875,
          7966,
          15931,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2351.52,
        "id": 406,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2348.96,
        "temperature": 0,
        "text": " the decision whether to jump or not jump.",
        "tokens": [
          51112,
          264,
          3537,
          1968,
          281,
          3012,
          420,
          406,
          3012,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2352.32,
        "id": 407,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2351.52,
        "temperature": 0,
        "text": " That's the expression.",
        "tokens": [
          51240,
          663,
          311,
          264,
          6114,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2355.44,
        "id": 408,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2352.32,
        "temperature": 0,
        "text": " That's how it's going to be used, applied in a given scenario.",
        "tokens": [
          51280,
          663,
          311,
          577,
          309,
          311,
          516,
          281,
          312,
          1143,
          11,
          6456,
          294,
          257,
          2212,
          9005,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2358.64,
        "id": 409,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2355.44,
        "temperature": 0,
        "text": " In a classification example, it could be it's classifying an image.",
        "tokens": [
          51436,
          682,
          257,
          21538,
          1365,
          11,
          309,
          727,
          312,
          309,
          311,
          1508,
          5489,
          364,
          3256,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.17678651742055906,
        "compression_ratio": 1.9922178988326849,
        "end": 2360.96,
        "id": 410,
        "no_speech_prob": 0.0000030894914289092412,
        "seek": 233400,
        "start": 2358.64,
        "temperature": 0,
        "text": " That's how the data from the neural network is going to be used",
        "tokens": [
          51596,
          663,
          311,
          577,
          264,
          1412,
          490,
          264,
          18161,
          3209,
          307,
          516,
          281,
          312,
          1143,
          51712
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2364.7200000000003,
        "id": 411,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2360.96,
        "temperature": 0,
        "text": " to make a guess based on this image and turn it into a string.",
        "tokens": [
          50364,
          281,
          652,
          257,
          2041,
          2361,
          322,
          341,
          3256,
          293,
          1261,
          309,
          666,
          257,
          6798,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2366.8,
        "id": 412,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2365.6,
        "temperature": 0,
        "text": " So that's aspect number one.",
        "tokens": [
          50596,
          407,
          300,
          311,
          4171,
          1230,
          472,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2367.6,
        "id": 413,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2366.8,
        "temperature": 0,
        "text": " We've got that.",
        "tokens": [
          50656,
          492,
          600,
          658,
          300,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2369.92,
        "id": 414,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2367.6,
        "temperature": 0,
        "text": " So what that means is when I write the code,",
        "tokens": [
          50696,
          407,
          437,
          300,
          1355,
          307,
          562,
          286,
          2464,
          264,
          3089,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2374.2400000000002,
        "id": 415,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2369.92,
        "temperature": 0,
        "text": " I need to somehow figure out how to do crossover and mutation",
        "tokens": [
          50812,
          286,
          643,
          281,
          6063,
          2573,
          484,
          577,
          281,
          360,
          33837,
          293,
          27960,
          51028
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2375.68,
        "id": 416,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2374.2400000000002,
        "temperature": 0,
        "text": " with weights and biases.",
        "tokens": [
          51028,
          365,
          17443,
          293,
          32152,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2380,
        "id": 417,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2376.7200000000003,
        "temperature": 0,
        "text": " I think I can create probably a population of random neural networks.",
        "tokens": [
          51152,
          286,
          519,
          286,
          393,
          1884,
          1391,
          257,
          4415,
          295,
          4974,
          18161,
          9590,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2381.36,
        "id": 418,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2380,
        "temperature": 0,
        "text": " That's just going to be like new neural network,",
        "tokens": [
          51316,
          663,
          311,
          445,
          516,
          281,
          312,
          411,
          777,
          18161,
          3209,
          11,
          51384
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2383.28,
        "id": 419,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2381.36,
        "temperature": 0,
        "text": " new neural network, new neural network.",
        "tokens": [
          51384,
          777,
          18161,
          3209,
          11,
          777,
          18161,
          3209,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2385.12,
        "id": 420,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2383.28,
        "temperature": 0,
        "text": " Evaluating the fitness I've got to get to,",
        "tokens": [
          51480,
          462,
          3337,
          32438,
          264,
          15303,
          286,
          600,
          658,
          281,
          483,
          281,
          11,
          51572
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2387.2,
        "id": 421,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2385.12,
        "temperature": 0,
        "text": " I can pick two random ones,",
        "tokens": [
          51572,
          286,
          393,
          1888,
          732,
          4974,
          2306,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.1737065315246582,
        "compression_ratio": 1.8049645390070923,
        "end": 2388.8,
        "id": 422,
        "no_speech_prob": 0.0002453685738146305,
        "seek": 236096,
        "start": 2387.2,
        "temperature": 0,
        "text": " but I need to apply crossover mutation.",
        "tokens": [
          51676,
          457,
          286,
          643,
          281,
          3079,
          33837,
          27960,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2392,
        "id": 423,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2388.8,
        "temperature": 0,
        "text": " And to be honest, what I might do at first in my first implementation",
        "tokens": [
          50364,
          400,
          281,
          312,
          3245,
          11,
          437,
          286,
          1062,
          360,
          412,
          700,
          294,
          452,
          700,
          11420,
          50524
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2393.76,
        "id": 424,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2392,
        "temperature": 0,
        "text": " is not even bother with crossover",
        "tokens": [
          50524,
          307,
          406,
          754,
          8677,
          365,
          33837,
          50612
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2395.92,
        "id": 425,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2393.76,
        "temperature": 0,
        "text": " and not even bother with picking more than one parent.",
        "tokens": [
          50612,
          293,
          406,
          754,
          8677,
          365,
          8867,
          544,
          813,
          472,
          2596,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2400.96,
        "id": 426,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2395.92,
        "temperature": 0,
        "text": " So one technique to simplify the genetic algorithm is just to make copies.",
        "tokens": [
          50720,
          407,
          472,
          6532,
          281,
          20460,
          264,
          12462,
          9284,
          307,
          445,
          281,
          652,
          14341,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2403.2000000000003,
        "id": 427,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2400.96,
        "temperature": 0,
        "text": " So I can pick the good ones and make copies of them,",
        "tokens": [
          50972,
          407,
          286,
          393,
          1888,
          264,
          665,
          2306,
          293,
          652,
          14341,
          295,
          552,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2404.48,
        "id": 428,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2403.2000000000003,
        "temperature": 0,
        "text": " mutate a little bit and keep going.",
        "tokens": [
          51084,
          5839,
          473,
          257,
          707,
          857,
          293,
          1066,
          516,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2407.28,
        "id": 429,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2404.48,
        "temperature": 0,
        "text": " It might not work as effectively as if I use crossover,",
        "tokens": [
          51148,
          467,
          1062,
          406,
          589,
          382,
          8659,
          382,
          498,
          286,
          764,
          33837,
          11,
          51288
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2409.36,
        "id": 430,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2407.28,
        "temperature": 0,
        "text": " but it'll certainly be easier to code.",
        "tokens": [
          51288,
          457,
          309,
          603,
          3297,
          312,
          3571,
          281,
          3089,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.18835848999023438,
        "compression_ratio": 1.7517482517482517,
        "end": 2416.7200000000003,
        "id": 431,
        "no_speech_prob": 0.00000595511255596648,
        "seek": 238880,
        "start": 2409.36,
        "temperature": 0,
        "text": " So the other thing that's tricky with when you're making your own genetic algorithm",
        "tokens": [
          51392,
          407,
          264,
          661,
          551,
          300,
          311,
          12414,
          365,
          562,
          291,
          434,
          1455,
          428,
          1065,
          12462,
          9284,
          51760
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2420,
        "id": 432,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2416.72,
        "temperature": 0,
        "text": " and applying it to your own project is the fitness function.",
        "tokens": [
          50364,
          293,
          9275,
          309,
          281,
          428,
          1065,
          1716,
          307,
          264,
          15303,
          2445,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2425.3599999999997,
        "id": 433,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2423.52,
        "temperature": 0,
        "text": " Question mark, question mark, question mark.",
        "tokens": [
          50704,
          14464,
          1491,
          11,
          1168,
          1491,
          11,
          1168,
          1491,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2426.64,
        "id": 434,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2425.3599999999997,
        "temperature": 0,
        "text": " So this is crucial.",
        "tokens": [
          50796,
          407,
          341,
          307,
          11462,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2428.48,
        "id": 435,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2426.64,
        "temperature": 0,
        "text": " If you don't have a good fitness function,",
        "tokens": [
          50860,
          759,
          291,
          500,
          380,
          362,
          257,
          665,
          15303,
          2445,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2430.72,
        "id": 436,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2428.48,
        "temperature": 0,
        "text": " this whole selection process,",
        "tokens": [
          50952,
          341,
          1379,
          9450,
          1399,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2432.08,
        "id": 437,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2430.72,
        "temperature": 0,
        "text": " this quote unquote natural slice,",
        "tokens": [
          51064,
          341,
          6513,
          37557,
          3303,
          13153,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2434.3199999999997,
        "id": 438,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2432.08,
        "temperature": 0,
        "text": " not very natural here, it's like digital selection.",
        "tokens": [
          51132,
          406,
          588,
          3303,
          510,
          11,
          309,
          311,
          411,
          4562,
          9450,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2437.12,
        "id": 439,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2435.04,
        "temperature": 0,
        "text": " I'm not going to be able to distinguish between",
        "tokens": [
          51280,
          286,
          478,
          406,
          516,
          281,
          312,
          1075,
          281,
          20206,
          1296,
          51384
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2440.16,
        "id": 440,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2437.9199999999996,
        "temperature": 0,
        "text": " members of the population that do really well",
        "tokens": [
          51424,
          2679,
          295,
          264,
          4415,
          300,
          360,
          534,
          731,
          51536
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2442.72,
        "id": 441,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2440.16,
        "temperature": 0,
        "text": " that should be that their digital DNA should be passed down",
        "tokens": [
          51536,
          300,
          820,
          312,
          300,
          641,
          4562,
          8272,
          820,
          312,
          4678,
          760,
          51664
        ]
      },
      {
        "avg_logprob": -0.20488180995972688,
        "compression_ratio": 1.7509025270758123,
        "end": 2444.64,
        "id": 442,
        "no_speech_prob": 0.00012339399836491793,
        "seek": 241672,
        "start": 2442.72,
        "temperature": 0,
        "text": " to the next generation versus ones that don't.",
        "tokens": [
          51664,
          281,
          264,
          958,
          5125,
          5717,
          2306,
          300,
          500,
          380,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2449.52,
        "id": 443,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2444.64,
        "temperature": 0,
        "text": " So I want a good fitness function that gives me a good range of probabilities.",
        "tokens": [
          50364,
          407,
          286,
          528,
          257,
          665,
          15303,
          2445,
          300,
          2709,
          385,
          257,
          665,
          3613,
          295,
          33783,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2452.08,
        "id": 444,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2449.52,
        "temperature": 0,
        "text": " And so in this case, we could think about the classification.",
        "tokens": [
          50608,
          400,
          370,
          294,
          341,
          1389,
          11,
          321,
          727,
          519,
          466,
          264,
          21538,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2453.7599999999998,
        "id": 445,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2452.08,
        "temperature": 0,
        "text": " It could be, okay, well, this neural network,",
        "tokens": [
          50736,
          467,
          727,
          312,
          11,
          1392,
          11,
          731,
          11,
          341,
          18161,
          3209,
          11,
          50820
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2455.44,
        "id": 446,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2453.7599999999998,
        "temperature": 0,
        "text": " give it 100 images,",
        "tokens": [
          50820,
          976,
          309,
          2319,
          5267,
          11,
          50904
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2458,
        "id": 447,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2455.44,
        "temperature": 0,
        "text": " its fitness is how many of those it classified correctly.",
        "tokens": [
          50904,
          1080,
          15303,
          307,
          577,
          867,
          295,
          729,
          309,
          20627,
          8944,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2462.56,
        "id": 448,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2458.8799999999997,
        "temperature": 0,
        "text": " We could even go into it deeper and somehow score the fitness",
        "tokens": [
          51076,
          492,
          727,
          754,
          352,
          666,
          309,
          7731,
          293,
          6063,
          6175,
          264,
          15303,
          51260
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2465.2799999999997,
        "id": 449,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2462.56,
        "temperature": 0,
        "text": " according to its confidence level about classifying them correctly.",
        "tokens": [
          51260,
          4650,
          281,
          1080,
          6687,
          1496,
          466,
          1508,
          5489,
          552,
          8944,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2468,
        "id": 450,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2465.2799999999997,
        "temperature": 0,
        "text": " But that might be flawed in some ways also.",
        "tokens": [
          51396,
          583,
          300,
          1062,
          312,
          38823,
          294,
          512,
          2098,
          611,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2468.96,
        "id": 451,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2468,
        "temperature": 0,
        "text": " So that's one thing.",
        "tokens": [
          51532,
          407,
          300,
          311,
          472,
          551,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2470.96,
        "id": 452,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2468.96,
        "temperature": 0,
        "text": " With the flappy bird scenario,",
        "tokens": [
          51580,
          2022,
          264,
          46338,
          7966,
          5255,
          9005,
          11,
          51680
        ]
      },
      {
        "avg_logprob": -0.18860466340008905,
        "compression_ratio": 1.7666666666666666,
        "end": 2472.8799999999997,
        "id": 453,
        "no_speech_prob": 0.000010783226571220439,
        "seek": 244464,
        "start": 2470.96,
        "temperature": 0,
        "text": " if we think about the flappy bird game,",
        "tokens": [
          51680,
          498,
          321,
          519,
          466,
          264,
          46338,
          7966,
          5255,
          1216,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2477.8399999999997,
        "id": 454,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2475.2,
        "temperature": 0,
        "text": " what is the fitness here?",
        "tokens": [
          50392,
          437,
          307,
          264,
          15303,
          510,
          30,
          50524
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2480.08,
        "id": 455,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2477.8399999999997,
        "temperature": 0,
        "text": " Well, the fitness would simply be the score.",
        "tokens": [
          50524,
          1042,
          11,
          264,
          15303,
          576,
          2935,
          312,
          264,
          6175,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2481.3599999999997,
        "id": 456,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2480.08,
        "temperature": 0,
        "text": " So I'm a neural network.",
        "tokens": [
          50636,
          407,
          286,
          478,
          257,
          18161,
          3209,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2485.7599999999998,
        "id": 457,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2481.3599999999997,
        "temperature": 0,
        "text": " I am a neural network playing flappy coding train now,",
        "tokens": [
          50700,
          286,
          669,
          257,
          18161,
          3209,
          2433,
          46338,
          7966,
          17720,
          3847,
          586,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2488.48,
        "id": 458,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2485.7599999999998,
        "temperature": 0,
        "text": " beep beep, boop boop, input, output, beep boop.",
        "tokens": [
          50920,
          28678,
          28678,
          11,
          748,
          404,
          748,
          404,
          11,
          4846,
          11,
          5598,
          11,
          28678,
          748,
          404,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2492.3199999999997,
        "id": 459,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2490,
        "temperature": 0,
        "text": " Am I still like recording a video tutorial?",
        "tokens": [
          51132,
          2012,
          286,
          920,
          411,
          6613,
          257,
          960,
          7073,
          30,
          51248
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2494.16,
        "id": 460,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2493.04,
        "temperature": 0,
        "text": " So it could just be like,",
        "tokens": [
          51284,
          407,
          309,
          727,
          445,
          312,
          411,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2497.7599999999998,
        "id": 461,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2494.16,
        "temperature": 0,
        "text": " how long am I able to go through this world",
        "tokens": [
          51340,
          577,
          938,
          669,
          286,
          1075,
          281,
          352,
          807,
          341,
          1002,
          51520
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2499.44,
        "id": 462,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2497.7599999999998,
        "temperature": 0,
        "text": " without running into a pipe?",
        "tokens": [
          51520,
          1553,
          2614,
          666,
          257,
          11240,
          30,
          51604
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2501.12,
        "id": 463,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2499.44,
        "temperature": 0,
        "text": " So that could be the fitness.",
        "tokens": [
          51604,
          407,
          300,
          727,
          312,
          264,
          15303,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.2548608858723286,
        "compression_ratio": 1.6824034334763949,
        "end": 2502.4,
        "id": 464,
        "no_speech_prob": 0.000008530309969501104,
        "seek": 247464,
        "start": 2501.12,
        "temperature": 0,
        "text": " So I could say, hey,",
        "tokens": [
          51688,
          407,
          286,
          727,
          584,
          11,
          4177,
          11,
          51752
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2504.56,
        "id": 465,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2502.4,
        "temperature": 0,
        "text": " why don't you 1,000 of you try playing this game?",
        "tokens": [
          50364,
          983,
          500,
          380,
          291,
          502,
          11,
          1360,
          295,
          291,
          853,
          2433,
          341,
          1216,
          30,
          50472
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2507.44,
        "id": 466,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2504.56,
        "temperature": 0,
        "text": " 1,000 of you electronic neural network magic machines",
        "tokens": [
          50472,
          502,
          11,
          1360,
          295,
          291,
          10092,
          18161,
          3209,
          5585,
          8379,
          50616
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2509.52,
        "id": 467,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2508.2400000000002,
        "temperature": 0,
        "text": " try playing this game",
        "tokens": [
          50656,
          853,
          2433,
          341,
          1216,
          50720
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2513.52,
        "id": 468,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2511.04,
        "temperature": 0,
        "text": " and your fitness is how long you last",
        "tokens": [
          50796,
          293,
          428,
          15303,
          307,
          577,
          938,
          291,
          1036,
          50920
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2514.96,
        "id": 469,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2513.52,
        "temperature": 0,
        "text": " before you run into a pipe.",
        "tokens": [
          50920,
          949,
          291,
          1190,
          666,
          257,
          11240,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2518.2400000000002,
        "id": 470,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2516.2400000000002,
        "temperature": 0,
        "text": " And so that is the fitness function.",
        "tokens": [
          51056,
          400,
          370,
          300,
          307,
          264,
          15303,
          2445,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2520,
        "id": 471,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2518.2400000000002,
        "temperature": 0,
        "text": " So we have all the pieces.",
        "tokens": [
          51156,
          407,
          321,
          362,
          439,
          264,
          3755,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2522.1600000000003,
        "id": 472,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2520,
        "temperature": 0,
        "text": " So what do I have already?",
        "tokens": [
          51244,
          407,
          437,
          360,
          286,
          362,
          1217,
          30,
          51352
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2524.8,
        "id": 473,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2522.1600000000003,
        "temperature": 0,
        "text": " Like if I'm going for this flappy bird example,",
        "tokens": [
          51352,
          1743,
          498,
          286,
          478,
          516,
          337,
          341,
          46338,
          7966,
          5255,
          1365,
          11,
          51484
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2526.64,
        "id": 474,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2524.8,
        "temperature": 0,
        "text": " I already have the flappy bird game.",
        "tokens": [
          51484,
          286,
          1217,
          362,
          264,
          46338,
          7966,
          5255,
          1216,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.16427363868521042,
        "compression_ratio": 1.75,
        "end": 2529.12,
        "id": 475,
        "no_speech_prob": 0.0000016280495174214593,
        "seek": 250240,
        "start": 2527.2000000000003,
        "temperature": 0,
        "text": " So I have the flappy bird code.",
        "tokens": [
          51604,
          407,
          286,
          362,
          264,
          46338,
          7966,
          5255,
          3089,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2531.52,
        "id": 476,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2529.44,
        "temperature": 0,
        "text": " I have my genetic algorithm examples,",
        "tokens": [
          50380,
          286,
          362,
          452,
          12462,
          9284,
          5110,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2533.3599999999997,
        "id": 477,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2531.52,
        "temperature": 0,
        "text": " but ultimately, there's not really,",
        "tokens": [
          50484,
          457,
          6284,
          11,
          456,
          311,
          406,
          534,
          11,
          50576
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2536.4,
        "id": 478,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2533.3599999999997,
        "temperature": 0,
        "text": " I don't really have a genetic algorithm library per se.",
        "tokens": [
          50576,
          286,
          500,
          380,
          534,
          362,
          257,
          12462,
          9284,
          6405,
          680,
          369,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2537.6,
        "id": 479,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2536.4,
        "temperature": 0,
        "text": " So I'm probably gonna have to build",
        "tokens": [
          50728,
          407,
          286,
          478,
          1391,
          799,
          362,
          281,
          1322,
          50788
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2539.68,
        "id": 480,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2537.6,
        "temperature": 0,
        "text": " the genetic algorithm stuff in the code.",
        "tokens": [
          50788,
          264,
          12462,
          9284,
          1507,
          294,
          264,
          3089,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2543.2,
        "id": 481,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2539.68,
        "temperature": 0,
        "text": " But I do have a neural network library.",
        "tokens": [
          50892,
          583,
          286,
          360,
          362,
          257,
          18161,
          3209,
          6405,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2546.56,
        "id": 482,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2545.44,
        "temperature": 0,
        "text": " So I don't have to write,",
        "tokens": [
          51180,
          407,
          286,
          500,
          380,
          362,
          281,
          2464,
          11,
          51236
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2548.08,
        "id": 483,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2546.56,
        "temperature": 0,
        "text": " I don't have to write the flappy bird game.",
        "tokens": [
          51236,
          286,
          500,
          380,
          362,
          281,
          2464,
          264,
          46338,
          7966,
          5255,
          1216,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2549.7599999999998,
        "id": 484,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2548.08,
        "temperature": 0,
        "text": " I don't have to write the neural network library.",
        "tokens": [
          51312,
          286,
          500,
          380,
          362,
          281,
          2464,
          264,
          18161,
          3209,
          6405,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2554.64,
        "id": 485,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2549.7599999999998,
        "temperature": 0,
        "text": " However, it might make sense for my neural network objects",
        "tokens": [
          51396,
          2908,
          11,
          309,
          1062,
          652,
          2020,
          337,
          452,
          18161,
          3209,
          6565,
          51640
        ]
      },
      {
        "avg_logprob": -0.23781646728515626,
        "compression_ratio": 1.9871244635193133,
        "end": 2557.6,
        "id": 486,
        "no_speech_prob": 0.000023552602215204388,
        "seek": 252912,
        "start": 2554.64,
        "temperature": 0,
        "text": " to know about crossover and mutation.",
        "tokens": [
          51640,
          281,
          458,
          466,
          33837,
          293,
          27960,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2560,
        "id": 487,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2557.92,
        "temperature": 0,
        "text": " That might be something that probably should go",
        "tokens": [
          50380,
          663,
          1062,
          312,
          746,
          300,
          1391,
          820,
          352,
          50484
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2561.36,
        "id": 488,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2560,
        "temperature": 0,
        "text": " into the neural network library",
        "tokens": [
          50484,
          666,
          264,
          18161,
          3209,
          6405,
          50552
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2563.12,
        "id": 489,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2561.36,
        "temperature": 0,
        "text": " so that at any moment I could say like,",
        "tokens": [
          50552,
          370,
          300,
          412,
          604,
          1623,
          286,
          727,
          584,
          411,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2564.96,
        "id": 490,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2563.12,
        "temperature": 0,
        "text": " hey, you neural network and you neural network,",
        "tokens": [
          50640,
          4177,
          11,
          291,
          18161,
          3209,
          293,
          291,
          18161,
          3209,
          11,
          50732
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2566.64,
        "id": 491,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2564.96,
        "temperature": 0,
        "text": " get together, make another one.",
        "tokens": [
          50732,
          483,
          1214,
          11,
          652,
          1071,
          472,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2568.88,
        "id": 492,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2566.64,
        "temperature": 0,
        "text": " Or hey, you neural network, mutate yourself.",
        "tokens": [
          50816,
          1610,
          4177,
          11,
          291,
          18161,
          3209,
          11,
          5839,
          473,
          1803,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2570.72,
        "id": 493,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2568.88,
        "temperature": 0,
        "text": " So I probably should, that's something,",
        "tokens": [
          50928,
          407,
          286,
          1391,
          820,
          11,
          300,
          311,
          746,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2572.48,
        "id": 494,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2570.72,
        "temperature": 0,
        "text": " so that's the first thing I think I'm gonna do",
        "tokens": [
          51020,
          370,
          300,
          311,
          264,
          700,
          551,
          286,
          519,
          286,
          478,
          799,
          360,
          51108
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2576.16,
        "id": 495,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2572.48,
        "temperature": 0,
        "text": " in the next video is add crossover and mutations",
        "tokens": [
          51108,
          294,
          264,
          958,
          960,
          307,
          909,
          33837,
          293,
          29243,
          51292
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2578,
        "id": 496,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2576.16,
        "temperature": 0,
        "text": " or maybe to start more simply,",
        "tokens": [
          51292,
          420,
          1310,
          281,
          722,
          544,
          2935,
          11,
          51384
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2580.64,
        "id": 497,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2578,
        "temperature": 0,
        "text": " I'm just gonna start with like a copy function",
        "tokens": [
          51384,
          286,
          478,
          445,
          799,
          722,
          365,
          411,
          257,
          5055,
          2445,
          51516
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2582.16,
        "id": 498,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2580.64,
        "temperature": 0,
        "text": " just to kind of get going here,",
        "tokens": [
          51516,
          445,
          281,
          733,
          295,
          483,
          516,
          510,
          11,
          51592
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2584.08,
        "id": 499,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2582.16,
        "temperature": 0,
        "text": " a copy function and mutation.",
        "tokens": [
          51592,
          257,
          5055,
          2445,
          293,
          27960,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.24270400502323325,
        "compression_ratio": 1.9965517241379311,
        "end": 2587.44,
        "id": 500,
        "no_speech_prob": 0.003765379311516881,
        "seek": 255760,
        "start": 2585.04,
        "temperature": 0,
        "text": " So those things need to go into the neural network library",
        "tokens": [
          51736,
          407,
          729,
          721,
          643,
          281,
          352,
          666,
          264,
          18161,
          3209,
          6405,
          51856
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2591.92,
        "id": 501,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2588.32,
        "temperature": 0,
        "text": " and then the third thing is I just need to apply the GA.",
        "tokens": [
          50408,
          293,
          550,
          264,
          2636,
          551,
          307,
          286,
          445,
          643,
          281,
          3079,
          264,
          22841,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2594.64,
        "id": 502,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2591.92,
        "temperature": 0,
        "text": " So this I really need to do a lot of work",
        "tokens": [
          50588,
          407,
          341,
          286,
          534,
          643,
          281,
          360,
          257,
          688,
          295,
          589,
          50724
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2596.48,
        "id": 503,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2594.64,
        "temperature": 0,
        "text": " to write the genetic algorithm code.",
        "tokens": [
          50724,
          281,
          2464,
          264,
          12462,
          9284,
          3089,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2598.64,
        "id": 504,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2596.48,
        "temperature": 0,
        "text": " So I'm gonna start with my flappy bird code,",
        "tokens": [
          50816,
          407,
          286,
          478,
          799,
          722,
          365,
          452,
          46338,
          7966,
          5255,
          3089,
          11,
          50924
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2600.56,
        "id": 505,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2598.64,
        "temperature": 0,
        "text": " import the neural network library,",
        "tokens": [
          50924,
          974,
          264,
          18161,
          3209,
          6405,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2603.52,
        "id": 506,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2600.56,
        "temperature": 0,
        "text": " add crossover slash copy mutation",
        "tokens": [
          51020,
          909,
          33837,
          17330,
          5055,
          27960,
          51168
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2606.32,
        "id": 507,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2603.52,
        "temperature": 0,
        "text": " and then start to implement the idea",
        "tokens": [
          51168,
          293,
          550,
          722,
          281,
          4445,
          264,
          1558,
          51308
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2608.8,
        "id": 508,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2606.32,
        "temperature": 0,
        "text": " of a genetic algorithm in this particular program",
        "tokens": [
          51308,
          295,
          257,
          12462,
          9284,
          294,
          341,
          1729,
          1461,
          51432
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2610.32,
        "id": 509,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2608.8,
        "temperature": 0,
        "text": " that started with the flappy bird code",
        "tokens": [
          51432,
          300,
          1409,
          365,
          264,
          46338,
          7966,
          5255,
          3089,
          51508
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2612,
        "id": 510,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2610.32,
        "temperature": 0,
        "text": " that imported the neural network library",
        "tokens": [
          51508,
          300,
          25524,
          264,
          18161,
          3209,
          6405,
          51592
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2614.56,
        "id": 511,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2612,
        "temperature": 0,
        "text": " that my father bought for two zoozy,",
        "tokens": [
          51592,
          300,
          452,
          3086,
          4243,
          337,
          732,
          710,
          1986,
          1229,
          11,
          51720
        ]
      },
      {
        "avg_logprob": -0.2193714678287506,
        "compression_ratio": 1.8352059925093633,
        "end": 2617.12,
        "id": 512,
        "no_speech_prob": 0.00006709204899379984,
        "seek": 258744,
        "start": 2614.56,
        "temperature": 0,
        "text": " anyway, nevermind, random reference.",
        "tokens": [
          51720,
          4033,
          11,
          1128,
          13733,
          11,
          4974,
          6408,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2619.12,
        "id": 513,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2617.44,
        "temperature": 0,
        "text": " Because it's like the flappy bird",
        "tokens": [
          50380,
          1436,
          309,
          311,
          411,
          264,
          46338,
          7966,
          5255,
          50464
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2621.04,
        "id": 514,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2619.12,
        "temperature": 0,
        "text": " that imported the neural network library",
        "tokens": [
          50464,
          300,
          25524,
          264,
          18161,
          3209,
          6405,
          50560
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2623.52,
        "id": 515,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2621.04,
        "temperature": 0,
        "text": " that added the genetic algorithm",
        "tokens": [
          50560,
          300,
          3869,
          264,
          12462,
          9284,
          50684
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2625.68,
        "id": 516,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2623.52,
        "temperature": 0,
        "text": " that there's a song going on there",
        "tokens": [
          50684,
          300,
          456,
          311,
          257,
          2153,
          516,
          322,
          456,
          50792
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2627.7599999999998,
        "id": 517,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2625.68,
        "temperature": 0,
        "text": " that somebody else will finish for me.",
        "tokens": [
          50792,
          300,
          2618,
          1646,
          486,
          2413,
          337,
          385,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2630.7999999999997,
        "id": 518,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2627.7599999999998,
        "temperature": 0,
        "text": " All right, Passover is coming up.",
        "tokens": [
          50896,
          1057,
          558,
          11,
          48016,
          307,
          1348,
          493,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2634.24,
        "id": 519,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2630.7999999999997,
        "temperature": 0,
        "text": " Okay, so that's that.",
        "tokens": [
          51048,
          1033,
          11,
          370,
          300,
          311,
          300,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2637.12,
        "id": 520,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2634.24,
        "temperature": 0,
        "text": " Okay, so you've made it to the end of this first video",
        "tokens": [
          51220,
          1033,
          11,
          370,
          291,
          600,
          1027,
          309,
          281,
          264,
          917,
          295,
          341,
          700,
          960,
          51364
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2639.12,
        "id": 521,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2637.12,
        "temperature": 0,
        "text": " for chapter 11 of the nature of code",
        "tokens": [
          51364,
          337,
          7187,
          2975,
          295,
          264,
          3687,
          295,
          3089,
          51464
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2640.24,
        "id": 522,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2639.12,
        "temperature": 0,
        "text": " which doesn't even exist yet",
        "tokens": [
          51464,
          597,
          1177,
          380,
          754,
          2514,
          1939,
          51520
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2641.8399999999997,
        "id": 523,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2640.24,
        "temperature": 0,
        "text": " but maybe by the time you're watching it,",
        "tokens": [
          51520,
          457,
          1310,
          538,
          264,
          565,
          291,
          434,
          1976,
          309,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2642.88,
        "id": 524,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2641.8399999999997,
        "temperature": 0,
        "text": " I'll be so happy if it exists",
        "tokens": [
          51600,
          286,
          603,
          312,
          370,
          2055,
          498,
          309,
          8198,
          51652
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2643.8399999999997,
        "id": 525,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2642.88,
        "temperature": 0,
        "text": " by the time you're watching this.",
        "tokens": [
          51652,
          538,
          264,
          565,
          291,
          434,
          1976,
          341,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.17178258151872783,
        "compression_ratio": 1.719298245614035,
        "end": 2646.16,
        "id": 526,
        "no_speech_prob": 0.00045831079478375614,
        "seek": 261712,
        "start": 2645.12,
        "temperature": 0,
        "text": " And so in the next video,",
        "tokens": [
          51764,
          400,
          370,
          294,
          264,
          958,
          960,
          11,
          51816
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2648.08,
        "id": 527,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2646.16,
        "temperature": 0,
        "text": " I'm going to revisit the neural network library",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          32676,
          264,
          18161,
          3209,
          6405,
          50460
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2650.48,
        "id": 528,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2648.08,
        "temperature": 0,
        "text": " and add functions for copy and mutation.",
        "tokens": [
          50460,
          293,
          909,
          6828,
          337,
          5055,
          293,
          27960,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2651.2,
        "id": 529,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2650.48,
        "temperature": 0,
        "text": " I'll see you there.",
        "tokens": [
          50580,
          286,
          603,
          536,
          291,
          456,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2657.2799999999997,
        "id": 530,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2654.56,
        "temperature": 0,
        "text": " All right, how we doing everybody?",
        "tokens": [
          50784,
          1057,
          558,
          11,
          577,
          321,
          884,
          2201,
          30,
          50920
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2670,
        "id": 531,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2669.2,
        "temperature": 0,
        "text": " Okay, everybody.",
        "tokens": [
          51516,
          1033,
          11,
          2201,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2672.56,
        "id": 532,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2672.08,
        "temperature": 0,
        "text": " Am I done?",
        "tokens": [
          51660,
          2012,
          286,
          1096,
          30,
          51684
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2673.3599999999997,
        "id": 533,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2672.56,
        "temperature": 0,
        "text": " Can I go home now?",
        "tokens": [
          51684,
          1664,
          286,
          352,
          1280,
          586,
          30,
          51724
        ]
      },
      {
        "avg_logprob": -0.2506783604621887,
        "compression_ratio": 1.3108108108108107,
        "end": 2674.3999999999996,
        "id": 534,
        "no_speech_prob": 0.0010321983136236668,
        "seek": 264616,
        "start": 2674.16,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51764,
          883,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2678.56,
        "id": 535,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2676.7999999999997,
        "temperature": 0,
        "text": " Echo34, hello Dan.",
        "tokens": [
          50396,
          31887,
          12249,
          11,
          7751,
          3394,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2681.2799999999997,
        "id": 536,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2678.56,
        "temperature": 0,
        "text": " Did you have a chance to check my firework program on Twitter?",
        "tokens": [
          50484,
          2589,
          291,
          362,
          257,
          2931,
          281,
          1520,
          452,
          2610,
          1902,
          1461,
          322,
          5794,
          30,
          50620
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2682.3999999999996,
        "id": 537,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2681.2799999999997,
        "temperature": 0,
        "text": " I think that I did.",
        "tokens": [
          50620,
          286,
          519,
          300,
          286,
          630,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2683.44,
        "id": 538,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2682.3999999999996,
        "temperature": 0,
        "text": " That was a couple weeks ago.",
        "tokens": [
          50676,
          663,
          390,
          257,
          1916,
          3259,
          2057,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2684.3199999999997,
        "id": 539,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2683.44,
        "temperature": 0,
        "text": " I remember seeing it.",
        "tokens": [
          50728,
          286,
          1604,
          2577,
          309,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2685.52,
        "id": 540,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2684.3199999999997,
        "temperature": 0,
        "text": " I remember it was beautiful.",
        "tokens": [
          50772,
          286,
          1604,
          309,
          390,
          2238,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2687.52,
        "id": 541,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2685.52,
        "temperature": 0,
        "text": " Send it to me again just in case I missed it.",
        "tokens": [
          50832,
          17908,
          309,
          281,
          385,
          797,
          445,
          294,
          1389,
          286,
          6721,
          309,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2689.12,
        "id": 542,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2687.52,
        "temperature": 0,
        "text": " I recognize your name though, Echo34.",
        "tokens": [
          50932,
          286,
          5521,
          428,
          1315,
          1673,
          11,
          31887,
          12249,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2690.96,
        "id": 543,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2689.12,
        "temperature": 0,
        "text": " You've made a lot of great contributions.",
        "tokens": [
          51012,
          509,
          600,
          1027,
          257,
          688,
          295,
          869,
          15725,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2691.2799999999997,
        "id": 544,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2690.96,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51104,
          1044,
          291,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2696.16,
        "id": 545,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2693.3599999999997,
        "temperature": 0,
        "text": " Dan, many questions about the ethics of neural nets.",
        "tokens": [
          51224,
          3394,
          11,
          867,
          1651,
          466,
          264,
          19769,
          295,
          18161,
          36170,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2699.3599999999997,
        "id": 546,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2697.04,
        "temperature": 0,
        "text": " Yes, I have many questions",
        "tokens": [
          51408,
          1079,
          11,
          286,
          362,
          867,
          1651,
          51524
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2701.7599999999998,
        "id": 547,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2699.3599999999997,
        "temperature": 0,
        "text": " about the ethics of neural networks itself.",
        "tokens": [
          51524,
          466,
          264,
          19769,
          295,
          18161,
          9590,
          2564,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.20837518100080818,
        "compression_ratio": 1.697594501718213,
        "end": 2705.6,
        "id": 548,
        "no_speech_prob": 0.0026316384319216013,
        "seek": 267616,
        "start": 2701.7599999999998,
        "temperature": 0,
        "text": " And I, but I, so I don't necessarily have questions",
        "tokens": [
          51644,
          400,
          286,
          11,
          457,
          286,
          11,
          370,
          286,
          500,
          380,
          4725,
          362,
          1651,
          51836
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2707.2,
        "id": 549,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2705.6,
        "temperature": 0,
        "text": " about the ethics of neural networks.",
        "tokens": [
          50364,
          466,
          264,
          19769,
          295,
          18161,
          9590,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2709.6,
        "id": 550,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2707.2,
        "temperature": 0,
        "text": " I have questions about the ethics of the people",
        "tokens": [
          50444,
          286,
          362,
          1651,
          466,
          264,
          19769,
          295,
          264,
          561,
          50564
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2712.96,
        "id": 551,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2709.6,
        "temperature": 0,
        "text": " who have access and the ability to program neural networks",
        "tokens": [
          50564,
          567,
          362,
          2105,
          293,
          264,
          3485,
          281,
          1461,
          18161,
          9590,
          50732
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2716.24,
        "id": 552,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2712.96,
        "temperature": 0,
        "text": " and how those programs are applied in society.",
        "tokens": [
          50732,
          293,
          577,
          729,
          4268,
          366,
          6456,
          294,
          4086,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2721.8399999999997,
        "id": 553,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2716.24,
        "temperature": 0,
        "text": " So hopefully, I hope, or that the work that I'm doing",
        "tokens": [
          50896,
          407,
          4696,
          11,
          286,
          1454,
          11,
          420,
          300,
          264,
          589,
          300,
          286,
          478,
          884,
          51176
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2725.12,
        "id": 554,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2721.8399999999997,
        "temperature": 0,
        "text": " to provide educational materials about neural networks",
        "tokens": [
          51176,
          281,
          2893,
          10189,
          5319,
          466,
          18161,
          9590,
          51340
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2729.7599999999998,
        "id": 555,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2725.12,
        "temperature": 0,
        "text": " will provoke that discussion and make it easier",
        "tokens": [
          51340,
          486,
          47015,
          300,
          5017,
          293,
          652,
          309,
          3571,
          51572
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2732.7999999999997,
        "id": 556,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2729.7599999999998,
        "temperature": 0,
        "text": " and more accessible for understanding of these algorithms",
        "tokens": [
          51572,
          293,
          544,
          9515,
          337,
          3701,
          295,
          613,
          14642,
          51724
        ]
      },
      {
        "avg_logprob": -0.19775094985961914,
        "compression_ratio": 1.8257261410788381,
        "end": 2734.72,
        "id": 557,
        "no_speech_prob": 0.0003150262637063861,
        "seek": 270560,
        "start": 2732.7999999999997,
        "temperature": 0,
        "text": " to be in the hands of more people.",
        "tokens": [
          51724,
          281,
          312,
          294,
          264,
          2377,
          295,
          544,
          561,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2739.7599999999998,
        "id": 558,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2736.3199999999997,
        "temperature": 0,
        "text": " And so that we can ask the right questions",
        "tokens": [
          50400,
          400,
          370,
          300,
          321,
          393,
          1029,
          264,
          558,
          1651,
          50572
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2743.2,
        "id": 559,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2739.7599999999998,
        "temperature": 0,
        "text": " and work together to make sure the power of these algorithms",
        "tokens": [
          50572,
          293,
          589,
          1214,
          281,
          652,
          988,
          264,
          1347,
          295,
          613,
          14642,
          50744
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2744.48,
        "id": 560,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2743.2,
        "temperature": 0,
        "text": " and the way that they can be applied",
        "tokens": [
          50744,
          293,
          264,
          636,
          300,
          436,
          393,
          312,
          6456,
          50808
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2747.2,
        "id": 561,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2744.48,
        "temperature": 0,
        "text": " and the data sets that can be used with them is not abused.",
        "tokens": [
          50808,
          293,
          264,
          1412,
          6352,
          300,
          393,
          312,
          1143,
          365,
          552,
          307,
          406,
          27075,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2749.04,
        "id": 562,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2747.8399999999997,
        "temperature": 0,
        "text": " That's what I have to say about that.",
        "tokens": [
          50976,
          663,
          311,
          437,
          286,
          362,
          281,
          584,
          466,
          300,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2751.7,
        "id": 563,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2751.2,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51144,
          1033,
          13,
          51169
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2755.04,
        "id": 564,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2753.04,
        "temperature": 0,
        "text": " I suggest you override the weights",
        "tokens": [
          51236,
          286,
          3402,
          291,
          42321,
          264,
          17443,
          51336
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2756.4,
        "id": 565,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2755.04,
        "temperature": 0,
        "text": " when you apply crossover.",
        "tokens": [
          51336,
          562,
          291,
          3079,
          33837,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2757.86,
        "id": 566,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2757.36,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51452,
          1057,
          558,
          13,
          51477
        ]
      },
      {
        "avg_logprob": -0.20255489939266874,
        "compression_ratio": 1.6267942583732058,
        "end": 2764.3199999999997,
        "id": 567,
        "no_speech_prob": 0.000001002984731712786,
        "seek": 273560,
        "start": 2763.2,
        "temperature": 0,
        "text": " So I think that's good.",
        "tokens": [
          51744,
          407,
          286,
          519,
          300,
          311,
          665,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2769.92,
        "id": 568,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2764.32,
        "temperature": 0,
        "text": " So anybody have any comments or questions before?",
        "tokens": [
          50364,
          407,
          4472,
          362,
          604,
          3053,
          420,
          1651,
          949,
          30,
          50644
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2771.6800000000003,
        "id": 569,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2769.92,
        "temperature": 0,
        "text": " Oh, this is not, this computer is not plugged in.",
        "tokens": [
          50644,
          876,
          11,
          341,
          307,
          406,
          11,
          341,
          3820,
          307,
          406,
          25679,
          294,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2779.6200000000003,
        "id": 570,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2779.1200000000003,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51104,
          1057,
          558,
          13,
          51129
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2782.48,
        "id": 571,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2781.6000000000004,
        "temperature": 0,
        "text": " Anybody have any questions?",
        "tokens": [
          51228,
          19082,
          362,
          604,
          1651,
          30,
          51272
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2785.92,
        "id": 572,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2782.48,
        "temperature": 0,
        "text": " So let me get set up, I guess, for the next video.",
        "tokens": [
          51272,
          407,
          718,
          385,
          483,
          992,
          493,
          11,
          286,
          2041,
          11,
          337,
          264,
          958,
          960,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2787.52,
        "id": 573,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2785.92,
        "temperature": 0,
        "text": " Again, I don't think we're gonna have,",
        "tokens": [
          51444,
          3764,
          11,
          286,
          500,
          380,
          519,
          321,
          434,
          799,
          362,
          11,
          51524
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2788.88,
        "id": 574,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2787.52,
        "temperature": 0,
        "text": " I just wanna be honest here.",
        "tokens": [
          51524,
          286,
          445,
          1948,
          312,
          3245,
          510,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2790.4,
        "id": 575,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2788.88,
        "temperature": 0,
        "text": " It seems very unlikely at this point",
        "tokens": [
          51592,
          467,
          2544,
          588,
          17518,
          412,
          341,
          935,
          51668
        ]
      },
      {
        "avg_logprob": -0.2022833086780666,
        "compression_ratio": 1.570048309178744,
        "end": 2791.52,
        "id": 576,
        "no_speech_prob": 0.00005738681284128688,
        "seek": 276432,
        "start": 2790.4,
        "temperature": 0,
        "text": " that I'm gonna have a finished",
        "tokens": [
          51668,
          300,
          286,
          478,
          799,
          362,
          257,
          4335,
          51724
        ]
      },
      {
        "avg_logprob": -0.2651404941204897,
        "compression_ratio": 1.490909090909091,
        "end": 2795.28,
        "id": 577,
        "no_speech_prob": 0.0006263252580538392,
        "seek": 279152,
        "start": 2792.24,
        "temperature": 0,
        "text": " Flappy Bird neuro evolution tutorial by the end of today.",
        "tokens": [
          50400,
          479,
          875,
          7966,
          15931,
          16499,
          9303,
          7073,
          538,
          264,
          917,
          295,
          965,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.2651404941204897,
        "compression_ratio": 1.490909090909091,
        "end": 2797.52,
        "id": 578,
        "no_speech_prob": 0.0006263252580538392,
        "seek": 279152,
        "start": 2795.92,
        "temperature": 0,
        "text": " But I certainly, this is a project",
        "tokens": [
          50584,
          583,
          286,
          3297,
          11,
          341,
          307,
          257,
          1716,
          50664
        ]
      },
      {
        "avg_logprob": -0.2651404941204897,
        "compression_ratio": 1.490909090909091,
        "end": 2799.28,
        "id": 579,
        "no_speech_prob": 0.0006263252580538392,
        "seek": 279152,
        "start": 2797.52,
        "temperature": 0,
        "text": " that I intend to complete.",
        "tokens": [
          50664,
          300,
          286,
          19759,
          281,
          3566,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2651404941204897,
        "compression_ratio": 1.490909090909091,
        "end": 2801.92,
        "id": 580,
        "no_speech_prob": 0.0006263252580538392,
        "seek": 279152,
        "start": 2799.28,
        "temperature": 0,
        "text": " I intend to write a chapter for the nature of code book about it.",
        "tokens": [
          50752,
          286,
          19759,
          281,
          2464,
          257,
          7187,
          337,
          264,
          3687,
          295,
          3089,
          1446,
          466,
          309,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2651404941204897,
        "compression_ratio": 1.490909090909091,
        "end": 2811.52,
        "id": 581,
        "no_speech_prob": 0.0006263252580538392,
        "seek": 279152,
        "start": 2802.72,
        "temperature": 0,
        "text": " And yes, so don't worry, even though I don't finish today,",
        "tokens": [
          50924,
          400,
          2086,
          11,
          370,
          500,
          380,
          3292,
          11,
          754,
          1673,
          286,
          500,
          380,
          2413,
          965,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2651404941204897,
        "compression_ratio": 1.490909090909091,
        "end": 2814.48,
        "id": 582,
        "no_speech_prob": 0.0006263252580538392,
        "seek": 279152,
        "start": 2811.52,
        "temperature": 0,
        "text": " I will also mention that if you go to github.com",
        "tokens": [
          51364,
          286,
          486,
          611,
          2152,
          300,
          498,
          291,
          352,
          281,
          290,
          355,
          836,
          13,
          1112,
          51512
        ]
      },
      {
        "avg_logprob": -0.2651404941204897,
        "compression_ratio": 1.490909090909091,
        "end": 2818.4,
        "id": 583,
        "no_speech_prob": 0.0006263252580538392,
        "seek": 279152,
        "start": 2814.48,
        "temperature": 0,
        "text": " slash Schiffman neural network p5.",
        "tokens": [
          51512,
          17330,
          2065,
          3661,
          1601,
          18161,
          3209,
          280,
          20,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2821.92,
        "id": 584,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2819.04,
        "temperature": 0,
        "text": " So you'll notice I have a repository",
        "tokens": [
          50396,
          407,
          291,
          603,
          3449,
          286,
          362,
          257,
          25841,
          50540
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2822.96,
        "id": 585,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2821.92,
        "temperature": 0,
        "text": " called neural network p5,",
        "tokens": [
          50540,
          1219,
          18161,
          3209,
          280,
          20,
          11,
          50592
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2825.12,
        "id": 586,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2822.96,
        "temperature": 0,
        "text": " which says this repository has been archived by the owner,",
        "tokens": [
          50592,
          597,
          1619,
          341,
          25841,
          575,
          668,
          3912,
          3194,
          538,
          264,
          7289,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2826.08,
        "id": 587,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2825.12,
        "temperature": 0,
        "text": " it is now read only.",
        "tokens": [
          50700,
          309,
          307,
          586,
          1401,
          787,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2828.4,
        "id": 588,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2826.96,
        "temperature": 0,
        "text": " And I wrote this has been deprecated",
        "tokens": [
          50792,
          400,
          286,
          4114,
          341,
          575,
          668,
          1367,
          13867,
          770,
          50864
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2831.12,
        "id": 589,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2828.4,
        "temperature": 0,
        "text": " and it links to the coding train neural network JS.",
        "tokens": [
          50864,
          293,
          309,
          6123,
          281,
          264,
          17720,
          3847,
          18161,
          3209,
          33063,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2832.1600000000003,
        "id": 590,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2831.12,
        "temperature": 0,
        "text": " The reason why I mentioned this",
        "tokens": [
          51000,
          440,
          1778,
          983,
          286,
          2835,
          341,
          51052
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2834.88,
        "id": 591,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2832.1600000000003,
        "temperature": 0,
        "text": " is I started doing this work last year",
        "tokens": [
          51052,
          307,
          286,
          1409,
          884,
          341,
          589,
          1036,
          1064,
          51188
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2836.96,
        "id": 592,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2834.88,
        "temperature": 0,
        "text": " and then decided I wanted to rebuild it again",
        "tokens": [
          51188,
          293,
          550,
          3047,
          286,
          1415,
          281,
          16877,
          309,
          797,
          51292
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2839.36,
        "id": 593,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2836.96,
        "temperature": 0,
        "text": " from scratch in video tutorial form.",
        "tokens": [
          51292,
          490,
          8459,
          294,
          960,
          7073,
          1254,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2840.8,
        "id": 594,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2839.36,
        "temperature": 0,
        "text": " But there are, for example,",
        "tokens": [
          51412,
          583,
          456,
          366,
          11,
          337,
          1365,
          11,
          51484
        ]
      },
      {
        "avg_logprob": -0.2911401871711977,
        "compression_ratio": 1.695970695970696,
        "end": 2844.56,
        "id": 595,
        "no_speech_prob": 0.002396500203758478,
        "seek": 281840,
        "start": 2841.76,
        "temperature": 0,
        "text": " there is a neuro evolution tutorial example here.",
        "tokens": [
          51532,
          456,
          307,
          257,
          16499,
          9303,
          7073,
          1365,
          510,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2845.52,
        "id": 596,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2844.7999999999997,
        "temperature": 0,
        "text": " Example here.",
        "tokens": [
          50376,
          24755,
          781,
          510,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2851.12,
        "id": 597,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2846.4,
        "temperature": 0,
        "text": " And let's see if I go to click this link,",
        "tokens": [
          50456,
          400,
          718,
          311,
          536,
          498,
          286,
          352,
          281,
          2052,
          341,
          2113,
          11,
          50692
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2855.12,
        "id": 598,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2852.16,
        "temperature": 0,
        "text": " this is actually running what I intend now to build.",
        "tokens": [
          50744,
          341,
          307,
          767,
          2614,
          437,
          286,
          19759,
          586,
          281,
          1322,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2857.7599999999998,
        "id": 599,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2856.88,
        "temperature": 0,
        "text": " So let's take a look at this.",
        "tokens": [
          50980,
          407,
          718,
          311,
          747,
          257,
          574,
          412,
          341,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2859.2799999999997,
        "id": 600,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2857.7599999999998,
        "temperature": 0,
        "text": " So and one thing that I built into this",
        "tokens": [
          51024,
          407,
          293,
          472,
          551,
          300,
          286,
          3094,
          666,
          341,
          51100
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2861.2799999999997,
        "id": 601,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2859.2799999999997,
        "temperature": 0,
        "text": " is I can like speed it up.",
        "tokens": [
          51100,
          307,
          286,
          393,
          411,
          3073,
          309,
          493,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2863.36,
        "id": 602,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2861.2799999999997,
        "temperature": 0,
        "text": " And by the way, I made it very easy to play.",
        "tokens": [
          51200,
          400,
          538,
          264,
          636,
          11,
          286,
          1027,
          309,
          588,
          1858,
          281,
          862,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2864,
        "id": 603,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2863.36,
        "temperature": 0,
        "text": " You notice that.",
        "tokens": [
          51304,
          509,
          3449,
          300,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2871.52,
        "id": 604,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2865.6,
        "temperature": 0,
        "text": " So this over time, we can see like the all time high score.",
        "tokens": [
          51416,
          407,
          341,
          670,
          565,
          11,
          321,
          393,
          536,
          411,
          264,
          439,
          565,
          1090,
          6175,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.24599854420807402,
        "compression_ratio": 1.6457399103139014,
        "end": 2873.7599999999998,
        "id": 605,
        "no_speech_prob": 0.00005920585317653604,
        "seek": 284456,
        "start": 2871.52,
        "temperature": 0,
        "text": " And what I can do now is I can also say",
        "tokens": [
          51712,
          400,
          437,
          286,
          393,
          360,
          586,
          307,
          286,
          393,
          611,
          584,
          51824
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2874.96,
        "id": 606,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2873.76,
        "temperature": 0,
        "text": " run best so far.",
        "tokens": [
          50364,
          1190,
          1151,
          370,
          1400,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2876.96,
        "id": 607,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2875.5200000000004,
        "temperature": 0,
        "text": " So this is now going to just show",
        "tokens": [
          50452,
          407,
          341,
          307,
          586,
          516,
          281,
          445,
          855,
          50524
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2878.96,
        "id": 608,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2876.96,
        "temperature": 0,
        "text": " this is the current member of the population",
        "tokens": [
          50524,
          341,
          307,
          264,
          2190,
          4006,
          295,
          264,
          4415,
          50624
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2882.88,
        "id": 609,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2879.5200000000004,
        "temperature": 0,
        "text": " that has the best neural network so far",
        "tokens": [
          50652,
          300,
          575,
          264,
          1151,
          18161,
          3209,
          370,
          1400,
          50820
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2884.4,
        "id": 610,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2882.88,
        "temperature": 0,
        "text": " to effectively play this game.",
        "tokens": [
          50820,
          281,
          8659,
          862,
          341,
          1216,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2885.92,
        "id": 611,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2884.4,
        "temperature": 0,
        "text": " So I probably should have shown this",
        "tokens": [
          50896,
          407,
          286,
          1391,
          820,
          362,
          4898,
          341,
          50972
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2890.1600000000003,
        "id": 612,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2886.6400000000003,
        "temperature": 0,
        "text": " in the video tutorial itself, but you know.",
        "tokens": [
          51008,
          294,
          264,
          960,
          7073,
          2564,
          11,
          457,
          291,
          458,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2897.76,
        "id": 613,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2892.8,
        "temperature": 0,
        "text": " Next come, easy come, easy go or something like that.",
        "tokens": [
          51316,
          3087,
          808,
          11,
          1858,
          808,
          11,
          1858,
          352,
          420,
          746,
          411,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2898.0800000000004,
        "id": 614,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2897.76,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51564,
          1057,
          558,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.2447104983859592,
        "compression_ratio": 1.5810810810810811,
        "end": 2901.44,
        "id": 615,
        "no_speech_prob": 0.00004611249823938124,
        "seek": 287376,
        "start": 2899.36,
        "temperature": 0,
        "text": " So you can look at this for reference.",
        "tokens": [
          51644,
          407,
          291,
          393,
          574,
          412,
          341,
          337,
          6408,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2903.92,
        "id": 616,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2901.44,
        "temperature": 0,
        "text": " I think there's flaws and mistakes and weirdness in here,",
        "tokens": [
          50364,
          286,
          519,
          456,
          311,
          27108,
          293,
          8038,
          293,
          3657,
          1287,
          294,
          510,
          11,
          50488
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2904.88,
        "id": 617,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2903.92,
        "temperature": 0,
        "text": " but it's something.",
        "tokens": [
          50488,
          457,
          309,
          311,
          746,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2906.88,
        "id": 618,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2904.88,
        "temperature": 0,
        "text": " Oh, I forgot to tweet that I was live streaming again.",
        "tokens": [
          50536,
          876,
          11,
          286,
          5298,
          281,
          15258,
          300,
          286,
          390,
          1621,
          11791,
          797,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2909.92,
        "id": 619,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2908.08,
        "temperature": 0,
        "text": " This is the worst thing that I do while live stream,",
        "tokens": [
          50696,
          639,
          307,
          264,
          5855,
          551,
          300,
          286,
          360,
          1339,
          1621,
          4309,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2912.4,
        "id": 620,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2909.92,
        "temperature": 0,
        "text": " which is that I look at my phone and notifications.",
        "tokens": [
          50788,
          597,
          307,
          300,
          286,
          574,
          412,
          452,
          2593,
          293,
          13426,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2915.52,
        "id": 621,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2912.4,
        "temperature": 0,
        "text": " But sometimes I just want to make sure that my guest,",
        "tokens": [
          50912,
          583,
          2171,
          286,
          445,
          528,
          281,
          652,
          988,
          300,
          452,
          8341,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2919.36,
        "id": 622,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2915.52,
        "temperature": 0,
        "text": " which I'm very excited about, is not lost",
        "tokens": [
          51068,
          597,
          286,
          478,
          588,
          2919,
          466,
          11,
          307,
          406,
          2731,
          51260
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2920.88,
        "id": 623,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2919.36,
        "temperature": 0,
        "text": " and figuring out where to go.",
        "tokens": [
          51260,
          293,
          15213,
          484,
          689,
          281,
          352,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2921.38,
        "id": 624,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2920.88,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51336,
          1033,
          13,
          51361
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2926.48,
        "id": 625,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2923.92,
        "temperature": 0,
        "text": " All right, so neat.",
        "tokens": [
          51488,
          1057,
          558,
          11,
          370,
          10654,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.20686413214458682,
        "compression_ratio": 1.6,
        "end": 2929.6,
        "id": 626,
        "no_speech_prob": 0.00028685308643616736,
        "seek": 290144,
        "start": 2927.28,
        "temperature": 0,
        "text": " Nature of code, doodle classifier.",
        "tokens": [
          51656,
          20159,
          295,
          3089,
          11,
          360,
          30013,
          1508,
          9902,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.4661677533929998,
        "compression_ratio": 1.5679611650485437,
        "end": 2939.6,
        "id": 627,
        "no_speech_prob": 0.000022827678549219854,
        "seek": 293144,
        "start": 2931.84,
        "temperature": 0,
        "text": " So let's go to the code here and go to this neuro evolution sketch",
        "tokens": [
          50384,
          407,
          718,
          311,
          352,
          281,
          264,
          3089,
          510,
          293,
          352,
          281,
          341,
          16499,
          9303,
          12325,
          50772
        ]
      },
      {
        "avg_logprob": -0.4661677533929998,
        "compression_ratio": 1.5679611650485437,
        "end": 2945.04,
        "id": 628,
        "no_speech_prob": 0.000022827678549219854,
        "seek": 293144,
        "start": 2939.6,
        "temperature": 0,
        "text": " and just make sure it's importing the neural network library",
        "tokens": [
          50772,
          293,
          445,
          652,
          988,
          309,
          311,
          43866,
          264,
          18161,
          3209,
          6405,
          51044
        ]
      },
      {
        "avg_logprob": -0.4661677533929998,
        "compression_ratio": 1.5679611650485437,
        "end": 2945.84,
        "id": 629,
        "no_speech_prob": 0.000022827678549219854,
        "seek": 293144,
        "start": 2945.04,
        "temperature": 0,
        "text": " and the matrix library.",
        "tokens": [
          51044,
          293,
          264,
          8141,
          6405,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.4661677533929998,
        "compression_ratio": 1.5679611650485437,
        "end": 2951.6,
        "id": 630,
        "no_speech_prob": 0.000022827678549219854,
        "seek": 293144,
        "start": 2946.4,
        "temperature": 0,
        "text": " And I also need to open up the, and let me do something here.",
        "tokens": [
          51112,
          400,
          286,
          611,
          643,
          281,
          1269,
          493,
          264,
          11,
          293,
          718,
          385,
          360,
          746,
          510,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.4661677533929998,
        "compression_ratio": 1.5679611650485437,
        "end": 2953.92,
        "id": 631,
        "no_speech_prob": 0.000022827678549219854,
        "seek": 293144,
        "start": 2952.88,
        "temperature": 0,
        "text": " What changes?",
        "tokens": [
          51436,
          708,
          2962,
          30,
          51488
        ]
      },
      {
        "avg_logprob": -0.4661677533929998,
        "compression_ratio": 1.5679611650485437,
        "end": 2956.88,
        "id": 632,
        "no_speech_prob": 0.000022827678549219854,
        "seek": 293144,
        "start": 2953.92,
        "temperature": 0,
        "text": " I just want to like do some git cleanup for a second",
        "tokens": [
          51488,
          286,
          445,
          528,
          281,
          411,
          360,
          512,
          18331,
          40991,
          337,
          257,
          1150,
          51636
        ]
      },
      {
        "avg_logprob": -0.4661677533929998,
        "compression_ratio": 1.5679611650485437,
        "end": 2959.52,
        "id": 633,
        "no_speech_prob": 0.000022827678549219854,
        "seek": 293144,
        "start": 2956.88,
        "temperature": 0,
        "text": " because this is going to go into the repo.",
        "tokens": [
          51636,
          570,
          341,
          307,
          516,
          281,
          352,
          666,
          264,
          49040,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.28780245780944824,
        "compression_ratio": 1.476923076923077,
        "end": 2963.44,
        "id": 634,
        "no_speech_prob": 0.000029772929337923415,
        "seek": 295952,
        "start": 2959.52,
        "temperature": 0,
        "text": " Into the repo, git status here.",
        "tokens": [
          50364,
          23373,
          264,
          49040,
          11,
          18331,
          6558,
          510,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.28780245780944824,
        "compression_ratio": 1.476923076923077,
        "end": 2965.6,
        "id": 635,
        "no_speech_prob": 0.000029772929337923415,
        "seek": 295952,
        "start": 2964.72,
        "temperature": 0,
        "text": " What did I change?",
        "tokens": [
          50624,
          708,
          630,
          286,
          1319,
          30,
          50668
        ]
      },
      {
        "avg_logprob": -0.28780245780944824,
        "compression_ratio": 1.476923076923077,
        "end": 2971.7599999999998,
        "id": 636,
        "no_speech_prob": 0.000029772929337923415,
        "seek": 295952,
        "start": 2965.6,
        "temperature": 0,
        "text": " So first let me add and commit the, let me add neuro evolution.",
        "tokens": [
          50668,
          407,
          700,
          718,
          385,
          909,
          293,
          5599,
          264,
          11,
          718,
          385,
          909,
          16499,
          9303,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.28780245780944824,
        "compression_ratio": 1.476923076923077,
        "end": 2983.7599999999998,
        "id": 637,
        "no_speech_prob": 0.000029772929337923415,
        "seek": 295952,
        "start": 2974.16,
        "temperature": 0,
        "text": " And let me say, adding new neuro evolution tutorial.",
        "tokens": [
          51096,
          400,
          718,
          385,
          584,
          11,
          5127,
          777,
          16499,
          9303,
          7073,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.28780245780944824,
        "compression_ratio": 1.476923076923077,
        "end": 2987.28,
        "id": 638,
        "no_speech_prob": 0.000029772929337923415,
        "seek": 295952,
        "start": 2985.7599999999998,
        "temperature": 0,
        "text": " Neuro evolution example.",
        "tokens": [
          51676,
          1734,
          7052,
          9303,
          1365,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 2989.92,
        "id": 639,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 2988.0800000000004,
        "temperature": 0,
        "text": " Nothing to see here yet.",
        "tokens": [
          50404,
          6693,
          281,
          536,
          510,
          1939,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 2995.2000000000003,
        "id": 640,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 2991.36,
        "temperature": 0,
        "text": " And, oops, escape.",
        "tokens": [
          50568,
          400,
          11,
          34166,
          11,
          7615,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 2996.5600000000004,
        "id": 641,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 2995.92,
        "temperature": 0,
        "text": " Oh my God.",
        "tokens": [
          50796,
          876,
          452,
          1265,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 2997.36,
        "id": 642,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 2996.5600000000004,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          50828,
          708,
          307,
          341,
          30,
          50868
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3001.44,
        "id": 643,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 2997.36,
        "temperature": 0,
        "text": " What is this dungeon that I am now in?",
        "tokens": [
          50868,
          708,
          307,
          341,
          27919,
          300,
          286,
          669,
          586,
          294,
          30,
          51072
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3002.48,
        "id": 644,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 3001.44,
        "temperature": 0,
        "text": " WQ.",
        "tokens": [
          51072,
          343,
          48,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3003.52,
        "id": 645,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 3002.48,
        "temperature": 0,
        "text": " What is this?",
        "tokens": [
          51124,
          708,
          307,
          341,
          30,
          51176
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3004.2400000000002,
        "id": 646,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 3003.52,
        "temperature": 0,
        "text": " Crazy.",
        "tokens": [
          51176,
          22509,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3004.8,
        "id": 647,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 3004.2400000000002,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51212,
          1057,
          558,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3008.6400000000003,
        "id": 648,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 3004.8,
        "temperature": 0,
        "text": " Now let me git push origin master this.",
        "tokens": [
          51240,
          823,
          718,
          385,
          18331,
          2944,
          4957,
          4505,
          341,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3012.5600000000004,
        "id": 649,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 3010.1600000000003,
        "temperature": 0,
        "text": " And now let me see what's going on here.",
        "tokens": [
          51508,
          400,
          586,
          718,
          385,
          536,
          437,
          311,
          516,
          322,
          510,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.5203819274902344,
        "compression_ratio": 1.5123456790123457,
        "end": 3015.0400000000004,
        "id": 650,
        "no_speech_prob": 0.001524653984233737,
        "seek": 298728,
        "start": 3013.76,
        "temperature": 0,
        "text": " Let me say git diff.",
        "tokens": [
          51688,
          961,
          385,
          584,
          18331,
          7593,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3018.6400000000003,
        "id": 651,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3017.52,
        "temperature": 0,
        "text": " There's some weirdness.",
        "tokens": [
          50376,
          821,
          311,
          512,
          3657,
          1287,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3022.0800000000004,
        "id": 652,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3018.6400000000003,
        "temperature": 0,
        "text": " I don't know what, I don't know what's going on here.",
        "tokens": [
          50432,
          286,
          500,
          380,
          458,
          437,
          11,
          286,
          500,
          380,
          458,
          437,
          311,
          516,
          322,
          510,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3027.1200000000003,
        "id": 653,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3022.0800000000004,
        "temperature": 0,
        "text": " I'm going to just stash this because I don't want to deal with that.",
        "tokens": [
          50604,
          286,
          478,
          516,
          281,
          445,
          342,
          1299,
          341,
          570,
          286,
          500,
          380,
          528,
          281,
          2028,
          365,
          300,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3030.1600000000003,
        "id": 654,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3027.76,
        "temperature": 0,
        "text": " And now I think I'm good.",
        "tokens": [
          50888,
          400,
          586,
          286,
          519,
          286,
          478,
          665,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3036.4,
        "id": 655,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3032.4,
        "temperature": 0,
        "text": " And I want to have the library code open neural network.",
        "tokens": [
          51120,
          400,
          286,
          528,
          281,
          362,
          264,
          6405,
          3089,
          1269,
          18161,
          3209,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3036.9,
        "id": 656,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3036.4,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51320,
          1033,
          13,
          51345
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3040.48,
        "id": 657,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3040.0800000000004,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          51504,
          7521,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3040.88,
        "id": 658,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3040.48,
        "temperature": 0,
        "text": " Oh, right.",
        "tokens": [
          51524,
          876,
          11,
          558,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3042.4,
        "id": 659,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3040.88,
        "temperature": 0,
        "text": " I have the activation function thing.",
        "tokens": [
          51544,
          286,
          362,
          264,
          24433,
          2445,
          551,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3044.0800000000004,
        "id": 660,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3042.4,
        "temperature": 0,
        "text": " This, I don't know.",
        "tokens": [
          51620,
          639,
          11,
          286,
          500,
          380,
          458,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.202256153369772,
        "compression_ratio": 1.6941747572815533,
        "end": 3045.84,
        "id": 661,
        "no_speech_prob": 0.00006605191447306424,
        "seek": 301728,
        "start": 3044.0800000000004,
        "temperature": 0,
        "text": " Semicolon there or no semicolon there.",
        "tokens": [
          51704,
          318,
          3438,
          38780,
          456,
          420,
          572,
          27515,
          38780,
          456,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3047.76,
        "id": 662,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3046.48,
        "temperature": 0,
        "text": " What to do about that?",
        "tokens": [
          50396,
          708,
          281,
          360,
          466,
          300,
          30,
          50460
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3050.48,
        "id": 663,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3048.88,
        "temperature": 0,
        "text": " Never, never decide.",
        "tokens": [
          50516,
          7344,
          11,
          1128,
          4536,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3052.32,
        "id": 664,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3050.48,
        "temperature": 0,
        "text": " I guess this is really should have a semicolon there.",
        "tokens": [
          50596,
          286,
          2041,
          341,
          307,
          534,
          820,
          362,
          257,
          27515,
          38780,
          456,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3053.44,
        "id": 665,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3052.32,
        "temperature": 0,
        "text": " Yeah, yeah, that should.",
        "tokens": [
          50688,
          865,
          11,
          1338,
          11,
          300,
          820,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3053.94,
        "id": 666,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3053.44,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50744,
          1057,
          558,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3058,
        "id": 667,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3055.6800000000003,
        "temperature": 0,
        "text": " Just want to see what the randomized function does.",
        "tokens": [
          50856,
          1449,
          528,
          281,
          536,
          437,
          264,
          38513,
          2445,
          775,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3060.08,
        "id": 668,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3058.56,
        "temperature": 0,
        "text": " Oh, that's in the matrix library.",
        "tokens": [
          51000,
          876,
          11,
          300,
          311,
          294,
          264,
          8141,
          6405,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3063.92,
        "id": 669,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3060.08,
        "temperature": 0,
        "text": " Oh, it's really the matrix library that I want to randomize.",
        "tokens": [
          51076,
          876,
          11,
          309,
          311,
          534,
          264,
          8141,
          6405,
          300,
          286,
          528,
          281,
          4974,
          1125,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3068.32,
        "id": 670,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3063.92,
        "temperature": 0,
        "text": " Ah, I really should change this to a Gaussian distribution.",
        "tokens": [
          51268,
          2438,
          11,
          286,
          534,
          820,
          1319,
          341,
          281,
          257,
          39148,
          7316,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3070.2400000000002,
        "id": 671,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3068.32,
        "temperature": 0,
        "text": " So at some point I need to do that.",
        "tokens": [
          51488,
          407,
          412,
          512,
          935,
          286,
          643,
          281,
          360,
          300,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.18969797894237486,
        "compression_ratio": 1.7113821138211383,
        "end": 3072.08,
        "id": 672,
        "no_speech_prob": 0.00004539781002677046,
        "seek": 304584,
        "start": 3070.2400000000002,
        "temperature": 0,
        "text": " I guess I will not worry about it right now.",
        "tokens": [
          51584,
          286,
          2041,
          286,
          486,
          406,
          3292,
          466,
          309,
          558,
          586,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3077.76,
        "id": 673,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3076,
        "temperature": 0,
        "text": " Boy, this has had some nice changes to it.",
        "tokens": [
          50372,
          9486,
          11,
          341,
          575,
          632,
          512,
          1481,
          2962,
          281,
          309,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3079.04,
        "id": 674,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3077.76,
        "temperature": 0,
        "text": " Oh, it has serialize in it.",
        "tokens": [
          50460,
          876,
          11,
          309,
          575,
          17436,
          1125,
          294,
          309,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3079.84,
        "id": 675,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3079.04,
        "temperature": 0,
        "text": " Wait a second here.",
        "tokens": [
          50524,
          3802,
          257,
          1150,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3082.1600000000003,
        "id": 676,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3080.56,
        "temperature": 0,
        "text": " I forgot that that was in there.",
        "tokens": [
          50600,
          286,
          5298,
          300,
          300,
          390,
          294,
          456,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3087.04,
        "id": 677,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3083.44,
        "temperature": 0,
        "text": " I've had some nice pull requests and also a lot of pull requests that I haven't had a chance to",
        "tokens": [
          50744,
          286,
          600,
          632,
          512,
          1481,
          2235,
          12475,
          293,
          611,
          257,
          688,
          295,
          2235,
          12475,
          300,
          286,
          2378,
          380,
          632,
          257,
          2931,
          281,
          50924
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3089.04,
        "id": 678,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3087.04,
        "temperature": 0,
        "text": " look over and figure out what to do about yet.",
        "tokens": [
          50924,
          574,
          670,
          293,
          2573,
          484,
          437,
          281,
          360,
          466,
          1939,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3089.76,
        "id": 679,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3089.04,
        "temperature": 0,
        "text": " Here's the thing.",
        "tokens": [
          51024,
          1692,
          311,
          264,
          551,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3092.7200000000003,
        "id": 680,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3091.44,
        "temperature": 0,
        "text": " Yeah, I'm up to date.",
        "tokens": [
          51144,
          865,
          11,
          286,
          478,
          493,
          281,
          4002,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3095.52,
        "id": 681,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3092.7200000000003,
        "temperature": 0,
        "text": " One of the reasons why I haven't merged some of the pull requests,",
        "tokens": [
          51208,
          1485,
          295,
          264,
          4112,
          983,
          286,
          2378,
          380,
          36427,
          512,
          295,
          264,
          2235,
          12475,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.1959056854248047,
        "compression_ratio": 1.8294573643410852,
        "end": 3105.28,
        "id": 682,
        "no_speech_prob": 0.0004655234224628657,
        "seek": 307584,
        "start": 3095.52,
        "temperature": 0,
        "text": " which are amazing pull requests, is that I feel like what I want to do with crossover and mutation",
        "tokens": [
          51348,
          597,
          366,
          2243,
          2235,
          12475,
          11,
          307,
          300,
          286,
          841,
          411,
          437,
          286,
          528,
          281,
          360,
          365,
          33837,
          293,
          27960,
          51836
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3110.7200000000003,
        "id": 683,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3105.92,
        "temperature": 0,
        "text": " is going to be much simpler to demonstrate with just a single hidden layer than if there",
        "tokens": [
          50368,
          307,
          516,
          281,
          312,
          709,
          18587,
          281,
          11698,
          365,
          445,
          257,
          2167,
          7633,
          4583,
          813,
          498,
          456,
          50608
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3112,
        "id": 684,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3110.7200000000003,
        "temperature": 0,
        "text": " were multiple hidden layers.",
        "tokens": [
          50608,
          645,
          3866,
          7633,
          7914,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3115.28,
        "id": 685,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3112,
        "temperature": 0,
        "text": " And to be honest, this sort of flappy bird scenario is so simple.",
        "tokens": [
          50672,
          400,
          281,
          312,
          3245,
          11,
          341,
          1333,
          295,
          46338,
          7966,
          5255,
          9005,
          307,
          370,
          2199,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3116.7200000000003,
        "id": 686,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3115.28,
        "temperature": 0,
        "text": " It's just a few inputs.",
        "tokens": [
          50836,
          467,
          311,
          445,
          257,
          1326,
          15743,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3119.6800000000003,
        "id": 687,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3116.7200000000003,
        "temperature": 0,
        "text": " I'm not going to do, I could do all the pixels as input.",
        "tokens": [
          50908,
          286,
          478,
          406,
          516,
          281,
          360,
          11,
          286,
          727,
          360,
          439,
          264,
          18668,
          382,
          4846,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3120.8,
        "id": 688,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3119.6800000000003,
        "temperature": 0,
        "text": " That would be interesting.",
        "tokens": [
          51056,
          663,
          576,
          312,
          1880,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3124.6400000000003,
        "id": 689,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3120.8,
        "temperature": 0,
        "text": " Actually, that would be really, I remember to mention that when I get to that.",
        "tokens": [
          51112,
          5135,
          11,
          300,
          576,
          312,
          534,
          11,
          286,
          1604,
          281,
          2152,
          300,
          562,
          286,
          483,
          281,
          300,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.1687875101643224,
        "compression_ratio": 1.8274509803921568,
        "end": 3132.56,
        "id": 690,
        "no_speech_prob": 0.000010783254765556194,
        "seek": 310584,
        "start": 3126.6400000000003,
        "temperature": 0,
        "text": " But I think it's going to be easier if there is just a single hidden layer and an output layer.",
        "tokens": [
          51404,
          583,
          286,
          519,
          309,
          311,
          516,
          281,
          312,
          3571,
          498,
          456,
          307,
          445,
          257,
          2167,
          7633,
          4583,
          293,
          364,
          5598,
          4583,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2677288577981191,
        "compression_ratio": 1.4259259259259258,
        "end": 3136.88,
        "id": 691,
        "no_speech_prob": 0.00002111232970491983,
        "seek": 313256,
        "start": 3132.56,
        "temperature": 0,
        "text": " Then I can just do the sort of copying and mutation stuff pretty manually.",
        "tokens": [
          50364,
          1396,
          286,
          393,
          445,
          360,
          264,
          1333,
          295,
          27976,
          293,
          27960,
          1507,
          1238,
          16945,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.2677288577981191,
        "compression_ratio": 1.4259259259259258,
        "end": 3139.52,
        "id": 692,
        "no_speech_prob": 0.00002111232970491983,
        "seek": 313256,
        "start": 3138.4,
        "temperature": 0,
        "text": " You know, I don't know.",
        "tokens": [
          50656,
          509,
          458,
          11,
          286,
          500,
          380,
          458,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.2677288577981191,
        "compression_ratio": 1.4259259259259258,
        "end": 3141.92,
        "id": 693,
        "no_speech_prob": 0.00002111232970491983,
        "seek": 313256,
        "start": 3139.52,
        "temperature": 0,
        "text": " But I like, I think that's a good decision.",
        "tokens": [
          50712,
          583,
          286,
          411,
          11,
          286,
          519,
          300,
          311,
          257,
          665,
          3537,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.2677288577981191,
        "compression_ratio": 1.4259259259259258,
        "end": 3143.36,
        "id": 694,
        "no_speech_prob": 0.00002111232970491983,
        "seek": 313256,
        "start": 3141.92,
        "temperature": 0,
        "text": " That's a decision I'm making right now.",
        "tokens": [
          50832,
          663,
          311,
          257,
          3537,
          286,
          478,
          1455,
          558,
          586,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2677288577981191,
        "compression_ratio": 1.4259259259259258,
        "end": 3153.6,
        "id": 695,
        "no_speech_prob": 0.00002111232970491983,
        "seek": 313256,
        "start": 3152.08,
        "temperature": 0,
        "text": " All right, sorry, I'm looking at the chat.",
        "tokens": [
          51340,
          1057,
          558,
          11,
          2597,
          11,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2677288577981191,
        "compression_ratio": 1.4259259259259258,
        "end": 3160.56,
        "id": 696,
        "no_speech_prob": 0.00002111232970491983,
        "seek": 313256,
        "start": 3160.24,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51748,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4383415065399588,
        "compression_ratio": 1.6935483870967742,
        "end": 3162.88,
        "id": 697,
        "no_speech_prob": 0.0011160030262544751,
        "seek": 316056,
        "start": 3160.96,
        "temperature": 0,
        "text": " Yeah, I can just, oh, I can just do map.",
        "tokens": [
          50384,
          865,
          11,
          286,
          393,
          445,
          11,
          1954,
          11,
          286,
          393,
          445,
          360,
          4471,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.4383415065399588,
        "compression_ratio": 1.6935483870967742,
        "end": 3163.92,
        "id": 698,
        "no_speech_prob": 0.0011160030262544751,
        "seek": 316056,
        "start": 3162.88,
        "temperature": 0,
        "text": " Right, right, right.",
        "tokens": [
          50480,
          1779,
          11,
          558,
          11,
          558,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.4383415065399588,
        "compression_ratio": 1.6935483870967742,
        "end": 3165.52,
        "id": 699,
        "no_speech_prob": 0.0011160030262544751,
        "seek": 316056,
        "start": 3163.92,
        "temperature": 0,
        "text": " All right, all right, all right, all right, all right, all right.",
        "tokens": [
          50532,
          1057,
          558,
          11,
          439,
          558,
          11,
          439,
          558,
          11,
          439,
          558,
          11,
          439,
          558,
          11,
          439,
          558,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.4383415065399588,
        "compression_ratio": 1.6935483870967742,
        "end": 3171.2799999999997,
        "id": 700,
        "no_speech_prob": 0.0011160030262544751,
        "seek": 316056,
        "start": 3170.96,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50884,
          1033,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.4383415065399588,
        "compression_ratio": 1.6935483870967742,
        "end": 3178.08,
        "id": 701,
        "no_speech_prob": 0.0011160030262544751,
        "seek": 316056,
        "start": 3172.4,
        "temperature": 0,
        "text": " So, so really what I want is some new stuff in the matrix class.",
        "tokens": [
          50956,
          407,
          11,
          370,
          534,
          437,
          286,
          528,
          307,
          512,
          777,
          1507,
          294,
          264,
          8141,
          1508,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.4383415065399588,
        "compression_ratio": 1.6935483870967742,
        "end": 3180.08,
        "id": 702,
        "no_speech_prob": 0.0011160030262544751,
        "seek": 316056,
        "start": 3178.64,
        "temperature": 0,
        "text": " Copy, okay.",
        "tokens": [
          51268,
          25653,
          11,
          1392,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.20429754892985025,
        "compression_ratio": 1.4879518072289157,
        "end": 3193.04,
        "id": 703,
        "no_speech_prob": 0.06560158729553223,
        "seek": 319056,
        "start": 3191.44,
        "temperature": 0,
        "text": " I found a wire on the floor.",
        "tokens": [
          50408,
          286,
          1352,
          257,
          6234,
          322,
          264,
          4123,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.20429754892985025,
        "compression_ratio": 1.4879518072289157,
        "end": 3195.6,
        "id": 704,
        "no_speech_prob": 0.06560158729553223,
        "seek": 319056,
        "start": 3194.48,
        "temperature": 0,
        "text": " Can you see this wire?",
        "tokens": [
          50560,
          1664,
          291,
          536,
          341,
          6234,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.20429754892985025,
        "compression_ratio": 1.4879518072289157,
        "end": 3200.88,
        "id": 705,
        "no_speech_prob": 0.06560158729553223,
        "seek": 319056,
        "start": 3196.72,
        "temperature": 0,
        "text": " Look, someone's been making some physical computing tutorials in this room.",
        "tokens": [
          50672,
          2053,
          11,
          1580,
          311,
          668,
          1455,
          512,
          4001,
          15866,
          17616,
          294,
          341,
          1808,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.20429754892985025,
        "compression_ratio": 1.4879518072289157,
        "end": 3203.2799999999997,
        "id": 706,
        "no_speech_prob": 0.06560158729553223,
        "seek": 319056,
        "start": 3201.52,
        "temperature": 0,
        "text": " That is, you can't even see it because of the focus.",
        "tokens": [
          50912,
          663,
          307,
          11,
          291,
          393,
          380,
          754,
          536,
          309,
          570,
          295,
          264,
          1879,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.20429754892985025,
        "compression_ratio": 1.4879518072289157,
        "end": 3205.44,
        "id": 707,
        "no_speech_prob": 0.06560158729553223,
        "seek": 319056,
        "start": 3203.92,
        "temperature": 0,
        "text": " There's a wire there.",
        "tokens": [
          51032,
          821,
          311,
          257,
          6234,
          456,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.20429754892985025,
        "compression_ratio": 1.4879518072289157,
        "end": 3206.72,
        "id": 708,
        "no_speech_prob": 0.06560158729553223,
        "seek": 319056,
        "start": 3205.44,
        "temperature": 0,
        "text": " How come you can't see that wire?",
        "tokens": [
          51108,
          1012,
          808,
          291,
          393,
          380,
          536,
          300,
          6234,
          30,
          51172
        ]
      },
      {
        "avg_logprob": -0.20429754892985025,
        "compression_ratio": 1.4879518072289157,
        "end": 3208.32,
        "id": 709,
        "no_speech_prob": 0.06560158729553223,
        "seek": 319056,
        "start": 3207.92,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51232,
          1057,
          558,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.4010799263097063,
        "compression_ratio": 1.507462686567164,
        "end": 3222,
        "id": 710,
        "no_speech_prob": 0.002396706026047468,
        "seek": 322056,
        "start": 3221.52,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50412,
          1057,
          558,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.4010799263097063,
        "compression_ratio": 1.507462686567164,
        "end": 3228.08,
        "id": 711,
        "no_speech_prob": 0.002396706026047468,
        "seek": 322056,
        "start": 3227.52,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50712,
          2425,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.4010799263097063,
        "compression_ratio": 1.507462686567164,
        "end": 3235.7599999999998,
        "id": 712,
        "no_speech_prob": 0.002396706026047468,
        "seek": 322056,
        "start": 3229.2,
        "temperature": 0,
        "text": " Welcome to part two of my neuroevolution series where I am attempting to look at how",
        "tokens": [
          50796,
          4027,
          281,
          644,
          732,
          295,
          452,
          16499,
          13379,
          3386,
          2638,
          689,
          286,
          669,
          22001,
          281,
          574,
          412,
          577,
          51124
        ]
      },
      {
        "avg_logprob": -0.4010799263097063,
        "compression_ratio": 1.507462686567164,
        "end": 3241.2,
        "id": 713,
        "no_speech_prob": 0.002396706026047468,
        "seek": 322056,
        "start": 3236.32,
        "temperature": 0,
        "text": " I can train a neural network, or more accurately, a population of neural networks",
        "tokens": [
          51152,
          286,
          393,
          3847,
          257,
          18161,
          3209,
          11,
          420,
          544,
          20095,
          11,
          257,
          4415,
          295,
          18161,
          9590,
          51396
        ]
      },
      {
        "avg_logprob": -0.4010799263097063,
        "compression_ratio": 1.507462686567164,
        "end": 3243.2,
        "id": 714,
        "no_speech_prob": 0.002396706026047468,
        "seek": 322056,
        "start": 3241.2,
        "temperature": 0,
        "text": " with a genetic algorithm.",
        "tokens": [
          51396,
          365,
          257,
          12462,
          9284,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.4010799263097063,
        "compression_ratio": 1.507462686567164,
        "end": 3247.2799999999997,
        "id": 715,
        "no_speech_prob": 0.002396706026047468,
        "seek": 322056,
        "start": 3243.2,
        "temperature": 0,
        "text": " I talked about this in the previous video, which you could go back and watch if you haven't.",
        "tokens": [
          51496,
          286,
          2825,
          466,
          341,
          294,
          264,
          3894,
          960,
          11,
          597,
          291,
          727,
          352,
          646,
          293,
          1159,
          498,
          291,
          2378,
          380,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3251.6000000000004,
        "id": 716,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3247.52,
        "temperature": 0,
        "text": " But the main thing that I want to do in this video is look at, okay, well, if I have a",
        "tokens": [
          50376,
          583,
          264,
          2135,
          551,
          300,
          286,
          528,
          281,
          360,
          294,
          341,
          960,
          307,
          574,
          412,
          11,
          1392,
          11,
          731,
          11,
          498,
          286,
          362,
          257,
          50580
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3258.4,
        "id": 717,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3251.6000000000004,
        "temperature": 0,
        "text": " neural network, if I have a neural network, how can I apply crossover and mutation to",
        "tokens": [
          50580,
          18161,
          3209,
          11,
          498,
          286,
          362,
          257,
          18161,
          3209,
          11,
          577,
          393,
          286,
          3079,
          33837,
          293,
          27960,
          281,
          50920
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3259.0400000000004,
        "id": 718,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3258.4,
        "temperature": 0,
        "text": " that neural network?",
        "tokens": [
          50920,
          300,
          18161,
          3209,
          30,
          50952
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3260.32,
        "id": 719,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3259.0400000000004,
        "temperature": 0,
        "text": " So that will be the focus of this video.",
        "tokens": [
          50952,
          407,
          300,
          486,
          312,
          264,
          1879,
          295,
          341,
          960,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3264.4,
        "id": 720,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3260.32,
        "temperature": 0,
        "text": " I do sort of remember, though, I did kind of remember that there's a lot of stuff that",
        "tokens": [
          51016,
          286,
          360,
          1333,
          295,
          1604,
          11,
          1673,
          11,
          286,
          630,
          733,
          295,
          1604,
          300,
          456,
          311,
          257,
          688,
          295,
          1507,
          300,
          51220
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3265.6000000000004,
        "id": 721,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3264.4,
        "temperature": 0,
        "text": " I haven't talked about yet.",
        "tokens": [
          51220,
          286,
          2378,
          380,
          2825,
          466,
          1939,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3269.6800000000003,
        "id": 722,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3265.6000000000004,
        "temperature": 0,
        "text": " Because one of the reasons why I use a neural network is to be able to give it some inputs",
        "tokens": [
          51280,
          1436,
          472,
          295,
          264,
          4112,
          983,
          286,
          764,
          257,
          18161,
          3209,
          307,
          281,
          312,
          1075,
          281,
          976,
          309,
          512,
          15743,
          51484
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3270.96,
        "id": 723,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3269.6800000000003,
        "temperature": 0,
        "text": " and to get some outputs.",
        "tokens": [
          51484,
          293,
          281,
          483,
          512,
          23930,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.27320991568013925,
        "compression_ratio": 1.84,
        "end": 3276.0800000000004,
        "id": 724,
        "no_speech_prob": 0.00793779082596302,
        "seek": 324728,
        "start": 3270.96,
        "temperature": 0,
        "text": " So that makes sense in the context of the doodle classification example, probably, but",
        "tokens": [
          51548,
          407,
          300,
          1669,
          2020,
          294,
          264,
          4319,
          295,
          264,
          360,
          30013,
          21538,
          1365,
          11,
          1391,
          11,
          457,
          51804
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3280.72,
        "id": 725,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3276.16,
        "temperature": 0,
        "text": " might not make sense to you immediately in terms of this idea of a flappy bird game.",
        "tokens": [
          50368,
          1062,
          406,
          652,
          2020,
          281,
          291,
          4258,
          294,
          2115,
          295,
          341,
          1558,
          295,
          257,
          46338,
          7966,
          5255,
          1216,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3282,
        "id": 726,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3280.72,
        "temperature": 0,
        "text": " So I will get to all that.",
        "tokens": [
          50596,
          407,
          286,
          486,
          483,
          281,
          439,
          300,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3285.2799999999997,
        "id": 727,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3282,
        "temperature": 0,
        "text": " But right now, I'm going to focus on saying new neural network.",
        "tokens": [
          50660,
          583,
          558,
          586,
          11,
          286,
          478,
          516,
          281,
          1879,
          322,
          1566,
          777,
          18161,
          3209,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3286.24,
        "id": 728,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3285.2799999999997,
        "temperature": 0,
        "text": " And you know what?",
        "tokens": [
          50824,
          400,
          291,
          458,
          437,
          30,
          50872
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3287.44,
        "id": 729,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3286.24,
        "temperature": 0,
        "text": " I'm going to stick with copy.",
        "tokens": [
          50872,
          286,
          478,
          516,
          281,
          2897,
          365,
          5055,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3289.84,
        "id": 730,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3287.44,
        "temperature": 0,
        "text": " Like I said, I'm going to get to crossover in a future video.",
        "tokens": [
          50932,
          1743,
          286,
          848,
          11,
          286,
          478,
          516,
          281,
          483,
          281,
          33837,
          294,
          257,
          2027,
          960,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3292.72,
        "id": 731,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3289.84,
        "temperature": 0,
        "text": " I'm going to stick with copy for simplicity and mutation.",
        "tokens": [
          51052,
          286,
          478,
          516,
          281,
          2897,
          365,
          5055,
          337,
          25632,
          293,
          27960,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3293.52,
        "id": 732,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3292.72,
        "temperature": 0,
        "text": " So let's go back.",
        "tokens": [
          51196,
          407,
          718,
          311,
          352,
          646,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3294.64,
        "id": 733,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3293.52,
        "temperature": 0,
        "text": " Let's go over to the code.",
        "tokens": [
          51236,
          961,
          311,
          352,
          670,
          281,
          264,
          3089,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3295.6,
        "id": 734,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3294.64,
        "temperature": 0,
        "text": " And let's take care of that.",
        "tokens": [
          51292,
          400,
          718,
          311,
          747,
          1127,
          295,
          300,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.3024125910129677,
        "compression_ratio": 1.7535714285714286,
        "end": 3305.2,
        "id": 735,
        "no_speech_prob": 0.0001376536238240078,
        "seek": 327608,
        "start": 3297.36,
        "temperature": 0,
        "text": " Now, let's start by having, I'm going to create a variable called break.",
        "tokens": [
          51428,
          823,
          11,
          718,
          311,
          722,
          538,
          1419,
          11,
          286,
          478,
          516,
          281,
          1884,
          257,
          7006,
          1219,
          1821,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3311.4399999999996,
        "id": 736,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3305.52,
        "temperature": 0,
        "text": " And I'm using the p5.js library, though what I'm going to do right now, it's totally unnecessary",
        "tokens": [
          50380,
          400,
          286,
          478,
          1228,
          264,
          280,
          20,
          13,
          25530,
          6405,
          11,
          1673,
          437,
          286,
          478,
          516,
          281,
          360,
          558,
          586,
          11,
          309,
          311,
          3879,
          19350,
          50676
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3315.6,
        "id": 737,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3311.4399999999996,
        "temperature": 0,
        "text": " for, but because the flappy bird game is programmed in p5, that's going to be helpful later.",
        "tokens": [
          50676,
          337,
          11,
          457,
          570,
          264,
          46338,
          7966,
          5255,
          1216,
          307,
          31092,
          294,
          280,
          20,
          11,
          300,
          311,
          516,
          281,
          312,
          4961,
          1780,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3316.7999999999997,
        "id": 738,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3315.6,
        "temperature": 0,
        "text": " Also, I use it all the time.",
        "tokens": [
          50884,
          2743,
          11,
          286,
          764,
          309,
          439,
          264,
          565,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3318.3199999999997,
        "id": 739,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3317.3599999999997,
        "temperature": 0,
        "text": " So I don't need a canvas.",
        "tokens": [
          50972,
          407,
          286,
          500,
          380,
          643,
          257,
          16267,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3319.9199999999996,
        "id": 740,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3318.3199999999997,
        "temperature": 0,
        "text": " I'm just going to say no canvas.",
        "tokens": [
          51020,
          286,
          478,
          445,
          516,
          281,
          584,
          572,
          16267,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3323.52,
        "id": 741,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3319.9199999999996,
        "temperature": 0,
        "text": " And I'm going to say brain equals new neural network.",
        "tokens": [
          51100,
          400,
          286,
          478,
          516,
          281,
          584,
          3567,
          6915,
          777,
          18161,
          3209,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3330.7999999999997,
        "id": 742,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3325.52,
        "temperature": 0,
        "text": " Now, when I create a new neural network object, if you remember the three arguments I need",
        "tokens": [
          51380,
          823,
          11,
          562,
          286,
          1884,
          257,
          777,
          18161,
          3209,
          2657,
          11,
          498,
          291,
          1604,
          264,
          1045,
          12869,
          286,
          643,
          51644
        ]
      },
      {
        "avg_logprob": -0.3427626381457691,
        "compression_ratio": 1.711340206185567,
        "end": 3334.48,
        "id": 743,
        "no_speech_prob": 0.0006361865089274943,
        "seek": 330520,
        "start": 3330.7999999999997,
        "temperature": 0,
        "text": " to give it, and this is just for this particular example, I'm going to say,",
        "tokens": [
          51644,
          281,
          976,
          309,
          11,
          293,
          341,
          307,
          445,
          337,
          341,
          1729,
          1365,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3339.28,
        "id": 744,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3334.48,
        "temperature": 0,
        "text": " this particular neural network implementation, it'll work differently if you're using, say,",
        "tokens": [
          50364,
          341,
          1729,
          18161,
          3209,
          11420,
          11,
          309,
          603,
          589,
          7614,
          498,
          291,
          434,
          1228,
          11,
          584,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3344.2400000000002,
        "id": 745,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3339.28,
        "temperature": 0,
        "text": " like a different machine learning framework like Keras or somebody else's neural network",
        "tokens": [
          50604,
          411,
          257,
          819,
          3479,
          2539,
          8388,
          411,
          591,
          6985,
          420,
          2618,
          1646,
          311,
          18161,
          3209,
          50852
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3345.04,
        "id": 746,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3344.2400000000002,
        "temperature": 0,
        "text": " library.",
        "tokens": [
          50852,
          6405,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3346.88,
        "id": 747,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3345.04,
        "temperature": 0,
        "text": " Maybe you might want to look at deeplearn.js.",
        "tokens": [
          50892,
          2704,
          291,
          1062,
          528,
          281,
          574,
          412,
          2452,
          306,
          1083,
          13,
          25530,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3348.64,
        "id": 748,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3346.88,
        "temperature": 0,
        "text": " I will come back to that in a future video.",
        "tokens": [
          50984,
          286,
          486,
          808,
          646,
          281,
          300,
          294,
          257,
          2027,
          960,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3352.64,
        "id": 749,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3349.92,
        "temperature": 0,
        "text": " So I need to give it a certain number of inputs.",
        "tokens": [
          51136,
          407,
          286,
          643,
          281,
          976,
          309,
          257,
          1629,
          1230,
          295,
          15743,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3355.28,
        "id": 750,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3352.64,
        "temperature": 0,
        "text": " Well, all of a sudden, now we're back to that question.",
        "tokens": [
          51272,
          1042,
          11,
          439,
          295,
          257,
          3990,
          11,
          586,
          321,
          434,
          646,
          281,
          300,
          1168,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3358.96,
        "id": 751,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3356.8,
        "temperature": 0,
        "text": " So let's actually not worry about that right now.",
        "tokens": [
          51480,
          407,
          718,
          311,
          767,
          406,
          3292,
          466,
          300,
          558,
          586,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3360.32,
        "id": 752,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3358.96,
        "temperature": 0,
        "text": " Let's not worry about that question.",
        "tokens": [
          51588,
          961,
          311,
          406,
          3292,
          466,
          300,
          1168,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3361.36,
        "id": 753,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3360.32,
        "temperature": 0,
        "text": " I'm going to go back to that question.",
        "tokens": [
          51656,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          300,
          1168,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3362.56,
        "id": 754,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3361.36,
        "temperature": 0,
        "text": " And I'm just going to make something up.",
        "tokens": [
          51708,
          400,
          286,
          478,
          445,
          516,
          281,
          652,
          746,
          493,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.1941330627825275,
        "compression_ratio": 1.8074534161490683,
        "end": 3364.32,
        "id": 755,
        "no_speech_prob": 0.00004757625356432982,
        "seek": 333448,
        "start": 3362.56,
        "temperature": 0,
        "text": " So let's take the xor example.",
        "tokens": [
          51768,
          407,
          718,
          311,
          747,
          264,
          2031,
          284,
          1365,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3367.36,
        "id": 756,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3364.7200000000003,
        "temperature": 0,
        "text": " A trivial example of, OK, it has two inputs.",
        "tokens": [
          50384,
          316,
          26703,
          1365,
          295,
          11,
          2264,
          11,
          309,
          575,
          732,
          15743,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3370.32,
        "id": 757,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3367.36,
        "temperature": 0,
        "text": " They're either true, true, true, false, false, true, false, false.",
        "tokens": [
          50516,
          814,
          434,
          2139,
          2074,
          11,
          2074,
          11,
          2074,
          11,
          7908,
          11,
          7908,
          11,
          2074,
          11,
          7908,
          11,
          7908,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3371.44,
        "id": 758,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3370.32,
        "temperature": 0,
        "text": " So there are going to be two inputs.",
        "tokens": [
          50664,
          407,
          456,
          366,
          516,
          281,
          312,
          732,
          15743,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3376.8,
        "id": 759,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3372.0800000000004,
        "temperature": 0,
        "text": " Let's just have a hidden layer with four nodes and one output.",
        "tokens": [
          50752,
          961,
          311,
          445,
          362,
          257,
          7633,
          4583,
          365,
          1451,
          13891,
          293,
          472,
          5598,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3379.28,
        "id": 760,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3376.8,
        "temperature": 0,
        "text": " So we can create some simple neural network.",
        "tokens": [
          50988,
          407,
          321,
          393,
          1884,
          512,
          2199,
          18161,
          3209,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3386,
        "id": 761,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3379.28,
        "temperature": 0,
        "text": " And what I want to be able to do is I want to say, let, I'll call it like child equal",
        "tokens": [
          51112,
          400,
          437,
          286,
          528,
          281,
          312,
          1075,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          11,
          718,
          11,
          286,
          603,
          818,
          309,
          411,
          1440,
          2681,
          51448
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3387.04,
        "id": 762,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3386,
        "temperature": 0,
        "text": " brain.copy.",
        "tokens": [
          51448,
          3567,
          13,
          13084,
          88,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.1697060465812683,
        "compression_ratio": 1.7551867219917012,
        "end": 3390.8,
        "id": 763,
        "no_speech_prob": 0.0000848108611535281,
        "seek": 336432,
        "start": 3387.6800000000003,
        "temperature": 0,
        "text": " I want to be able to say, let me make a copy of that neural network.",
        "tokens": [
          51532,
          286,
          528,
          281,
          312,
          1075,
          281,
          584,
          11,
          718,
          385,
          652,
          257,
          5055,
          295,
          300,
          18161,
          3209,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3394.7200000000003,
        "id": 764,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3391.36,
        "temperature": 0,
        "text": " And I also want to say something like child.mutate.",
        "tokens": [
          50392,
          400,
          286,
          611,
          528,
          281,
          584,
          746,
          411,
          1440,
          13,
          38326,
          473,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3399.04,
        "id": 765,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3394.7200000000003,
        "temperature": 0,
        "text": " So let me take that copy and apply a mutation in it.",
        "tokens": [
          50560,
          407,
          718,
          385,
          747,
          300,
          5055,
          293,
          3079,
          257,
          27960,
          294,
          309,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3402.88,
        "id": 766,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3399.04,
        "temperature": 0,
        "text": " Mutation, which is something I describe more in the genetic algorithm video series.",
        "tokens": [
          50776,
          376,
          11380,
          11,
          597,
          307,
          746,
          286,
          6786,
          544,
          294,
          264,
          12462,
          9284,
          960,
          2638,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3407.76,
        "id": 767,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3402.88,
        "temperature": 0,
        "text": " So what this means is this neural network class needs to have two new functions.",
        "tokens": [
          50968,
          407,
          437,
          341,
          1355,
          307,
          341,
          18161,
          3209,
          1508,
          2203,
          281,
          362,
          732,
          777,
          6828,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3409.2000000000003,
        "id": 768,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3407.76,
        "temperature": 0,
        "text": " It needs to have a copy function.",
        "tokens": [
          51212,
          467,
          2203,
          281,
          362,
          257,
          5055,
          2445,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3410.88,
        "id": 769,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3409.2000000000003,
        "temperature": 0,
        "text": " It needs to have a mutate function.",
        "tokens": [
          51284,
          467,
          2203,
          281,
          362,
          257,
          5839,
          473,
          2445,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3413.76,
        "id": 770,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3410.88,
        "temperature": 0,
        "text": " So let's go into the neural network library code.",
        "tokens": [
          51368,
          407,
          718,
          311,
          352,
          666,
          264,
          18161,
          3209,
          6405,
          3089,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3414.6400000000003,
        "id": 771,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3413.76,
        "temperature": 0,
        "text": " This is the class.",
        "tokens": [
          51512,
          639,
          307,
          264,
          1508,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3416,
        "id": 772,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3414.6400000000003,
        "temperature": 0,
        "text": " There's a lot of stuff in here.",
        "tokens": [
          51556,
          821,
          311,
          257,
          688,
          295,
          1507,
          294,
          510,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.1632918315147286,
        "compression_ratio": 1.8168498168498168,
        "end": 3419.44,
        "id": 773,
        "no_speech_prob": 0.0013885180233046412,
        "seek": 339080,
        "start": 3416,
        "temperature": 0,
        "text": " I have way too many videos going through all this code.",
        "tokens": [
          51624,
          286,
          362,
          636,
          886,
          867,
          2145,
          516,
          807,
          439,
          341,
          3089,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.17173472510443794,
        "compression_ratio": 1.5391705069124424,
        "end": 3421.68,
        "id": 774,
        "no_speech_prob": 0.0000217826382140629,
        "seek": 341944,
        "start": 3419.44,
        "temperature": 0,
        "text": " Luckily, we can kind of ignore all of this.",
        "tokens": [
          50364,
          19726,
          11,
          321,
          393,
          733,
          295,
          11200,
          439,
          295,
          341,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.17173472510443794,
        "compression_ratio": 1.5391705069124424,
        "end": 3423.76,
        "id": 775,
        "no_speech_prob": 0.0000217826382140629,
        "seek": 341944,
        "start": 3421.68,
        "temperature": 0,
        "text": " And I'm just going to go down to the bottom here.",
        "tokens": [
          50476,
          400,
          286,
          478,
          445,
          516,
          281,
          352,
          760,
          281,
          264,
          2767,
          510,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.17173472510443794,
        "compression_ratio": 1.5391705069124424,
        "end": 3430.96,
        "id": 776,
        "no_speech_prob": 0.0000217826382140629,
        "seek": 341944,
        "start": 3423.76,
        "temperature": 0,
        "text": " And I'm going to say something like adding functions for neuroevolution.",
        "tokens": [
          50580,
          400,
          286,
          478,
          516,
          281,
          584,
          746,
          411,
          5127,
          6828,
          337,
          16499,
          13379,
          3386,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.17173472510443794,
        "compression_ratio": 1.5391705069124424,
        "end": 3435.84,
        "id": 777,
        "no_speech_prob": 0.0000217826382140629,
        "seek": 341944,
        "start": 3432,
        "temperature": 0,
        "text": " Now, the truth of the matter is, what is it that I really want to copy?",
        "tokens": [
          50992,
          823,
          11,
          264,
          3494,
          295,
          264,
          1871,
          307,
          11,
          437,
          307,
          309,
          300,
          286,
          534,
          528,
          281,
          5055,
          30,
          51184
        ]
      },
      {
        "avg_logprob": -0.17173472510443794,
        "compression_ratio": 1.5391705069124424,
        "end": 3445.68,
        "id": 778,
        "no_speech_prob": 0.0000217826382140629,
        "seek": 341944,
        "start": 3436.48,
        "temperature": 0,
        "text": " Well, if you recall, the neural network structure is such that if there are two inputs and four",
        "tokens": [
          51216,
          1042,
          11,
          498,
          291,
          9901,
          11,
          264,
          18161,
          3209,
          3877,
          307,
          1270,
          300,
          498,
          456,
          366,
          732,
          15743,
          293,
          1451,
          51676
        ]
      },
      {
        "avg_logprob": -0.1957154028194467,
        "compression_ratio": 2.0954773869346734,
        "end": 3450.3199999999997,
        "id": 779,
        "no_speech_prob": 0.0018102022586390376,
        "seek": 344568,
        "start": 3445.7599999999998,
        "temperature": 0,
        "text": " hidden nodes and one output, the neural network looks like this.",
        "tokens": [
          50368,
          7633,
          13891,
          293,
          472,
          5598,
          11,
          264,
          18161,
          3209,
          1542,
          411,
          341,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.1957154028194467,
        "compression_ratio": 2.0954773869346734,
        "end": 3456.7999999999997,
        "id": 780,
        "no_speech_prob": 0.0018102022586390376,
        "seek": 344568,
        "start": 3451.04,
        "temperature": 0,
        "text": " It's connections between the inputs and the hidden layer and connections between the hidden",
        "tokens": [
          50632,
          467,
          311,
          9271,
          1296,
          264,
          15743,
          293,
          264,
          7633,
          4583,
          293,
          9271,
          1296,
          264,
          7633,
          50920
        ]
      },
      {
        "avg_logprob": -0.1957154028194467,
        "compression_ratio": 2.0954773869346734,
        "end": 3458.7999999999997,
        "id": 781,
        "no_speech_prob": 0.0018102022586390376,
        "seek": 344568,
        "start": 3456.7999999999997,
        "temperature": 0,
        "text": " layer and the output.",
        "tokens": [
          50920,
          4583,
          293,
          264,
          5598,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.1957154028194467,
        "compression_ratio": 2.0954773869346734,
        "end": 3464.3199999999997,
        "id": 782,
        "no_speech_prob": 0.0018102022586390376,
        "seek": 344568,
        "start": 3458.7999999999997,
        "temperature": 0,
        "text": " And these connections, the sort of dials of the neural network, the data of the neural",
        "tokens": [
          51020,
          400,
          613,
          9271,
          11,
          264,
          1333,
          295,
          5502,
          82,
          295,
          264,
          18161,
          3209,
          11,
          264,
          1412,
          295,
          264,
          18161,
          51296
        ]
      },
      {
        "avg_logprob": -0.1957154028194467,
        "compression_ratio": 2.0954773869346734,
        "end": 3469.3599999999997,
        "id": 783,
        "no_speech_prob": 0.0018102022586390376,
        "seek": 344568,
        "start": 3464.3199999999997,
        "temperature": 0,
        "text": " network, what controls how the information flows from the inputs and out through the",
        "tokens": [
          51296,
          3209,
          11,
          437,
          9003,
          577,
          264,
          1589,
          12867,
          490,
          264,
          15743,
          293,
          484,
          807,
          264,
          51548
        ]
      },
      {
        "avg_logprob": -0.1957154028194467,
        "compression_ratio": 2.0954773869346734,
        "end": 3471.52,
        "id": 784,
        "no_speech_prob": 0.0018102022586390376,
        "seek": 344568,
        "start": 3469.3599999999997,
        "temperature": 0,
        "text": " output are all of these weights.",
        "tokens": [
          51548,
          5598,
          366,
          439,
          295,
          613,
          17443,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1957154028194467,
        "compression_ratio": 2.0954773869346734,
        "end": 3474,
        "id": 785,
        "no_speech_prob": 0.0018102022586390376,
        "seek": 344568,
        "start": 3472.3199999999997,
        "temperature": 0,
        "text": " And these are stored in matrices.",
        "tokens": [
          51696,
          400,
          613,
          366,
          12187,
          294,
          32284,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3476,
        "id": 786,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3474,
        "temperature": 0,
        "text": " It's just a whole bunch of numbers.",
        "tokens": [
          50364,
          467,
          311,
          445,
          257,
          1379,
          3840,
          295,
          3547,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3481.2,
        "id": 787,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3476,
        "temperature": 0,
        "text": " So I have a weight matrix, which goes from input to hidden.",
        "tokens": [
          50464,
          407,
          286,
          362,
          257,
          3364,
          8141,
          11,
          597,
          1709,
          490,
          4846,
          281,
          7633,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3486.56,
        "id": 788,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3482.08,
        "temperature": 0,
        "text": " I have a weight matrix that goes from hidden to output.",
        "tokens": [
          50768,
          286,
          362,
          257,
          3364,
          8141,
          300,
          1709,
          490,
          7633,
          281,
          5598,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3489.92,
        "id": 789,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3486.56,
        "temperature": 0,
        "text": " And with each of these, I also have this thing called a bias.",
        "tokens": [
          50992,
          400,
          365,
          1184,
          295,
          613,
          11,
          286,
          611,
          362,
          341,
          551,
          1219,
          257,
          12577,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3494.88,
        "id": 790,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3489.92,
        "temperature": 0,
        "text": " And if you recall, the bias is something, really all I'm doing in the end is like, all",
        "tokens": [
          51160,
          400,
          498,
          291,
          9901,
          11,
          264,
          12577,
          307,
          746,
          11,
          534,
          439,
          286,
          478,
          884,
          294,
          264,
          917,
          307,
          411,
          11,
          439,
          51408
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3497.28,
        "id": 791,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3494.88,
        "temperature": 0,
        "text": " of this really boils down to like, hey, there's a whole bunch of points.",
        "tokens": [
          51408,
          295,
          341,
          534,
          35049,
          760,
          281,
          411,
          11,
          4177,
          11,
          456,
          311,
          257,
          1379,
          3840,
          295,
          2793,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3499.04,
        "id": 792,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3497.28,
        "temperature": 0,
        "text": " Could I just fit a line to those points?",
        "tokens": [
          51528,
          7497,
          286,
          445,
          3318,
          257,
          1622,
          281,
          729,
          2793,
          30,
          51616
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3501.76,
        "id": 793,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3499.04,
        "temperature": 0,
        "text": " And the bias is going to be like, move the line a little bit up, move the line a little",
        "tokens": [
          51616,
          400,
          264,
          12577,
          307,
          516,
          281,
          312,
          411,
          11,
          1286,
          264,
          1622,
          257,
          707,
          857,
          493,
          11,
          1286,
          264,
          1622,
          257,
          707,
          51752
        ]
      },
      {
        "avg_logprob": -0.1768840921336207,
        "compression_ratio": 1.946768060836502,
        "end": 3502.24,
        "id": 794,
        "no_speech_prob": 0.00011235305282752961,
        "seek": 347400,
        "start": 3501.76,
        "temperature": 0,
        "text": " bit down.",
        "tokens": [
          51752,
          857,
          760,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3505.7599999999998,
        "id": 795,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3502.24,
        "temperature": 0,
        "text": " So that's really, even though this all seems like fancy magic, ultimately, that's what",
        "tokens": [
          50364,
          407,
          300,
          311,
          534,
          11,
          754,
          1673,
          341,
          439,
          2544,
          411,
          10247,
          5585,
          11,
          6284,
          11,
          300,
          311,
          437,
          50540
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3507.7599999999998,
        "id": 796,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3505.7599999999998,
        "temperature": 0,
        "text": " it just boils down to in the end.",
        "tokens": [
          50540,
          309,
          445,
          35049,
          760,
          281,
          294,
          264,
          917,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3513.7599999999998,
        "id": 797,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3507.7599999999998,
        "temperature": 0,
        "text": " So I also have the bias for the hidden, and I have the bias for the output.",
        "tokens": [
          50640,
          407,
          286,
          611,
          362,
          264,
          12577,
          337,
          264,
          7633,
          11,
          293,
          286,
          362,
          264,
          12577,
          337,
          264,
          5598,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3514.3199999999997,
        "id": 798,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3513.7599999999998,
        "temperature": 0,
        "text": " And I don't know.",
        "tokens": [
          50940,
          400,
          286,
          500,
          380,
          458,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3516.72,
        "id": 799,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3514.3199999999997,
        "temperature": 0,
        "text": " I don't know what the best way to write the notation for this is.",
        "tokens": [
          50968,
          286,
          500,
          380,
          458,
          437,
          264,
          1151,
          636,
          281,
          2464,
          264,
          24657,
          337,
          341,
          307,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3519.12,
        "id": 800,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3518.4799999999996,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51176,
          865,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3523.6,
        "id": 801,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3519.12,
        "temperature": 0,
        "text": " So all of these things, when I want to copy the neural network, what I'm really saying",
        "tokens": [
          51208,
          407,
          439,
          295,
          613,
          721,
          11,
          562,
          286,
          528,
          281,
          5055,
          264,
          18161,
          3209,
          11,
          437,
          286,
          478,
          534,
          1566,
          51432
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3525.4399999999996,
        "id": 802,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3523.6,
        "temperature": 0,
        "text": " I want to do is copy all this stuff.",
        "tokens": [
          51432,
          286,
          528,
          281,
          360,
          307,
          5055,
          439,
          341,
          1507,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3527.52,
        "id": 803,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3526,
        "temperature": 0,
        "text": " So let me go ahead.",
        "tokens": [
          51552,
          407,
          718,
          385,
          352,
          2286,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.17786493435711928,
        "compression_ratio": 1.770909090909091,
        "end": 3530.8799999999997,
        "id": 804,
        "no_speech_prob": 0.0003682966926135123,
        "seek": 350224,
        "start": 3527.52,
        "temperature": 0,
        "text": " And so what I need probably is a function inside of all.",
        "tokens": [
          51628,
          400,
          370,
          437,
          286,
          643,
          1391,
          307,
          257,
          2445,
          1854,
          295,
          439,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3532.4,
        "id": 805,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3530.88,
        "temperature": 0,
        "text": " These are all matrix objects.",
        "tokens": [
          50364,
          1981,
          366,
          439,
          8141,
          6565,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3535.28,
        "id": 806,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3532.4,
        "temperature": 0,
        "text": " I need a function probably in the matrix class to say copy.",
        "tokens": [
          50440,
          286,
          643,
          257,
          2445,
          1391,
          294,
          264,
          8141,
          1508,
          281,
          584,
          5055,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3541.6800000000003,
        "id": 807,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3538.6400000000003,
        "temperature": 0,
        "text": " So let's start here and say copy.",
        "tokens": [
          50752,
          407,
          718,
          311,
          722,
          510,
          293,
          584,
          5055,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3544.8,
        "id": 808,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3542.8,
        "temperature": 0,
        "text": " And clone could be used.",
        "tokens": [
          50960,
          400,
          26506,
          727,
          312,
          1143,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3548.88,
        "id": 809,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3544.8,
        "temperature": 0,
        "text": " And I want to make a deep copy, I think, not a shallow copy.",
        "tokens": [
          51060,
          400,
          286,
          528,
          281,
          652,
          257,
          2452,
          5055,
          11,
          286,
          519,
          11,
          406,
          257,
          20488,
          5055,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3552.6400000000003,
        "id": 810,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3548.88,
        "temperature": 0,
        "text": " These terms get thrown around a lot in computer science, deep versus shallow.",
        "tokens": [
          51264,
          1981,
          2115,
          483,
          11732,
          926,
          257,
          688,
          294,
          3820,
          3497,
          11,
          2452,
          5717,
          20488,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3554.6400000000003,
        "id": 811,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3552.6400000000003,
        "temperature": 0,
        "text": " But I don't want to just point to the data.",
        "tokens": [
          51452,
          583,
          286,
          500,
          380,
          528,
          281,
          445,
          935,
          281,
          264,
          1412,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3558.48,
        "id": 812,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3554.6400000000003,
        "temperature": 0,
        "text": " I want just give me my own version of all of those numbers, because I'm going to mess",
        "tokens": [
          51552,
          286,
          528,
          445,
          976,
          385,
          452,
          1065,
          3037,
          295,
          439,
          295,
          729,
          3547,
          11,
          570,
          286,
          478,
          516,
          281,
          2082,
          51744
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3559.04,
        "id": 813,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3558.48,
        "temperature": 0,
        "text": " around with them.",
        "tokens": [
          51744,
          926,
          365,
          552,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.16987109363527225,
        "compression_ratio": 1.7163636363636363,
        "end": 3560.6400000000003,
        "id": 814,
        "no_speech_prob": 0.0004655253142118454,
        "seek": 353088,
        "start": 3559.04,
        "temperature": 0,
        "text": " And I want you to keep your numbers.",
        "tokens": [
          51772,
          400,
          286,
          528,
          291,
          281,
          1066,
          428,
          3547,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3561.92,
        "id": 815,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3560.64,
        "temperature": 0,
        "text": " I don't want to mess with your numbers.",
        "tokens": [
          50364,
          286,
          500,
          380,
          528,
          281,
          2082,
          365,
          428,
          3547,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3564.24,
        "id": 816,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3561.92,
        "temperature": 0,
        "text": " So instead of just saying, like, I'm a new neural network.",
        "tokens": [
          50428,
          407,
          2602,
          295,
          445,
          1566,
          11,
          411,
          11,
          286,
          478,
          257,
          777,
          18161,
          3209,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3565.7599999999998,
        "id": 817,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3564.24,
        "temperature": 0,
        "text": " Can I just point over to your numbers?",
        "tokens": [
          50544,
          1664,
          286,
          445,
          935,
          670,
          281,
          428,
          3547,
          30,
          50620
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3567.7599999999998,
        "id": 818,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3565.7599999999998,
        "temperature": 0,
        "text": " I really want a whole version of those.",
        "tokens": [
          50620,
          286,
          534,
          528,
          257,
          1379,
          3037,
          295,
          729,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3574.7999999999997,
        "id": 819,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3567.7599999999998,
        "temperature": 0,
        "text": " So and if we go back to here, so things that I need to do is I need to keep track of these",
        "tokens": [
          50720,
          407,
          293,
          498,
          321,
          352,
          646,
          281,
          510,
          11,
          370,
          721,
          300,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          1066,
          2837,
          295,
          613,
          51072
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3578.8799999999997,
        "id": 820,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3574.7999999999997,
        "temperature": 0,
        "text": " properties, input, output, the total input, output, and hidden nodes.",
        "tokens": [
          51072,
          7221,
          11,
          4846,
          11,
          5598,
          11,
          264,
          3217,
          4846,
          11,
          5598,
          11,
          293,
          7633,
          13891,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3582.16,
        "id": 821,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3579.7599999999998,
        "temperature": 0,
        "text": " So I want to say let's just put this in here.",
        "tokens": [
          51320,
          407,
          286,
          528,
          281,
          584,
          718,
          311,
          445,
          829,
          341,
          294,
          510,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.19829769432544708,
        "compression_ratio": 1.8089430894308942,
        "end": 3587.52,
        "id": 822,
        "no_speech_prob": 0.00006401967402780429,
        "seek": 356064,
        "start": 3582.16,
        "temperature": 0,
        "text": " So I want to say let input nodes equal this dot input nodes.",
        "tokens": [
          51440,
          407,
          286,
          528,
          281,
          584,
          718,
          4846,
          13891,
          2681,
          341,
          5893,
          4846,
          13891,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3591.2,
        "id": 823,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3587.52,
        "temperature": 0,
        "text": " Let hidden nodes equal this dot hidden nodes.",
        "tokens": [
          50364,
          961,
          7633,
          13891,
          2681,
          341,
          5893,
          7633,
          13891,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3596.4,
        "id": 824,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3592.72,
        "temperature": 0,
        "text": " And let output nodes equal this dot output.",
        "tokens": [
          50624,
          400,
          718,
          5598,
          13891,
          2681,
          341,
          5893,
          5598,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3596.96,
        "id": 825,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3596.4,
        "temperature": 0,
        "text": " And you know what?",
        "tokens": [
          50808,
          400,
          291,
          458,
          437,
          30,
          50836
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3600.48,
        "id": 826,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3598.88,
        "temperature": 0,
        "text": " This is very poorly named.",
        "tokens": [
          50932,
          639,
          307,
          588,
          22271,
          4926,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3603.28,
        "id": 827,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3600.48,
        "temperature": 0,
        "text": " This is sort of silly what I'm doing, but I'm going to do it anyway.",
        "tokens": [
          51012,
          639,
          307,
          1333,
          295,
          11774,
          437,
          286,
          478,
          884,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          309,
          4033,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3606.08,
        "id": 828,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3604.72,
        "temperature": 0,
        "text": " Input nodes.",
        "tokens": [
          51224,
          682,
          2582,
          13891,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3609.7599999999998,
        "id": 829,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3607.12,
        "temperature": 0,
        "text": " This is very, this is me, this is how I like to code.",
        "tokens": [
          51344,
          639,
          307,
          588,
          11,
          341,
          307,
          385,
          11,
          341,
          307,
          577,
          286,
          411,
          281,
          3089,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3614.08,
        "id": 830,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3609.7599999999998,
        "temperature": 0,
        "text": " I like to make things as long-winded as possible so that I can really think it through and",
        "tokens": [
          51476,
          286,
          411,
          281,
          652,
          721,
          382,
          938,
          12,
          12199,
          292,
          382,
          1944,
          370,
          300,
          286,
          393,
          534,
          519,
          309,
          807,
          293,
          51692
        ]
      },
      {
        "avg_logprob": -0.1860682794025966,
        "compression_ratio": 1.7641509433962264,
        "end": 3615.12,
        "id": 831,
        "no_speech_prob": 0.0023966641165316105,
        "seek": 358752,
        "start": 3614.08,
        "temperature": 0,
        "text": " explain it.",
        "tokens": [
          51692,
          2903,
          309,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.16190964242686395,
        "compression_ratio": 1.7826086956521738,
        "end": 3619.44,
        "id": 832,
        "no_speech_prob": 0.0005527769098989666,
        "seek": 361512,
        "start": 3615.2,
        "temperature": 0,
        "text": " All I'm doing right now is taking the properties of the neural network I want to copy and put",
        "tokens": [
          50368,
          1057,
          286,
          478,
          884,
          558,
          586,
          307,
          1940,
          264,
          7221,
          295,
          264,
          18161,
          3209,
          286,
          528,
          281,
          5055,
          293,
          829,
          50580
        ]
      },
      {
        "avg_logprob": -0.16190964242686395,
        "compression_ratio": 1.7826086956521738,
        "end": 3621.3599999999997,
        "id": 833,
        "no_speech_prob": 0.0005527769098989666,
        "seek": 361512,
        "start": 3619.44,
        "temperature": 0,
        "text": " them into local variables.",
        "tokens": [
          50580,
          552,
          666,
          2654,
          9102,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.16190964242686395,
        "compression_ratio": 1.7826086956521738,
        "end": 3621.92,
        "id": 834,
        "no_speech_prob": 0.0005527769098989666,
        "seek": 361512,
        "start": 3621.3599999999997,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50676,
          1545,
          30,
          50704
        ]
      },
      {
        "avg_logprob": -0.16190964242686395,
        "compression_ratio": 1.7826086956521738,
        "end": 3629.2799999999997,
        "id": 835,
        "no_speech_prob": 0.0005527769098989666,
        "seek": 361512,
        "start": 3621.92,
        "temperature": 0,
        "text": " Because I want to say neural network copy equals new neural network with what?",
        "tokens": [
          50704,
          1436,
          286,
          528,
          281,
          584,
          18161,
          3209,
          5055,
          6915,
          777,
          18161,
          3209,
          365,
          437,
          30,
          51072
        ]
      },
      {
        "avg_logprob": -0.16190964242686395,
        "compression_ratio": 1.7826086956521738,
        "end": 3634.64,
        "id": 836,
        "no_speech_prob": 0.0005527769098989666,
        "seek": 361512,
        "start": 3632.4,
        "temperature": 0,
        "text": " Oh, I have a better idea how to do this.",
        "tokens": [
          51228,
          876,
          11,
          286,
          362,
          257,
          1101,
          1558,
          577,
          281,
          360,
          341,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.16190964242686395,
        "compression_ratio": 1.7826086956521738,
        "end": 3636.3199999999997,
        "id": 837,
        "no_speech_prob": 0.0005527769098989666,
        "seek": 361512,
        "start": 3634.64,
        "temperature": 0,
        "text": " I have a better idea how to do this.",
        "tokens": [
          51340,
          286,
          362,
          257,
          1101,
          1558,
          577,
          281,
          360,
          341,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.16190964242686395,
        "compression_ratio": 1.7826086956521738,
        "end": 3641.68,
        "id": 838,
        "no_speech_prob": 0.0005527769098989666,
        "seek": 361512,
        "start": 3637.52,
        "temperature": 0,
        "text": " So this could work, but I have a better idea.",
        "tokens": [
          51484,
          407,
          341,
          727,
          589,
          11,
          457,
          286,
          362,
          257,
          1101,
          1558,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.21209572300766455,
        "compression_ratio": 1.6561085972850678,
        "end": 3645.9199999999996,
        "id": 839,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 364168,
        "start": 3641.68,
        "temperature": 0,
        "text": " So actually what I want to do is I kind of just want to say this.",
        "tokens": [
          50364,
          407,
          767,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          733,
          295,
          445,
          528,
          281,
          584,
          341,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.21209572300766455,
        "compression_ratio": 1.6561085972850678,
        "end": 3650.96,
        "id": 840,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 364168,
        "start": 3645.9199999999996,
        "temperature": 0,
        "text": " Return new neural network this.",
        "tokens": [
          50576,
          24350,
          777,
          18161,
          3209,
          341,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.21209572300766455,
        "compression_ratio": 1.6561085972850678,
        "end": 3655.12,
        "id": 841,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 364168,
        "start": 3652.3199999999997,
        "temperature": 0,
        "text": " Now you might be asking me, this isn't going to be bad.",
        "tokens": [
          50896,
          823,
          291,
          1062,
          312,
          3365,
          385,
          11,
          341,
          1943,
          380,
          516,
          281,
          312,
          1578,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.21209572300766455,
        "compression_ratio": 1.6561085972850678,
        "end": 3656.3199999999997,
        "id": 842,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 364168,
        "start": 3655.12,
        "temperature": 0,
        "text": " This isn't just going to work.",
        "tokens": [
          51036,
          639,
          1943,
          380,
          445,
          516,
          281,
          589,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.21209572300766455,
        "compression_ratio": 1.6561085972850678,
        "end": 3659.68,
        "id": 843,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 364168,
        "start": 3656.3199999999997,
        "temperature": 0,
        "text": " But what I'm sort of realizing here is maybe I don't want to copy everything here.",
        "tokens": [
          51096,
          583,
          437,
          286,
          478,
          1333,
          295,
          16734,
          510,
          307,
          1310,
          286,
          500,
          380,
          528,
          281,
          5055,
          1203,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21209572300766455,
        "compression_ratio": 1.6561085972850678,
        "end": 3667.2,
        "id": 844,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 364168,
        "start": 3660.24,
        "temperature": 0,
        "text": " What I actually want to do is call the constructor, but give it a reference to the existing neural",
        "tokens": [
          51292,
          708,
          286,
          767,
          528,
          281,
          360,
          307,
          818,
          264,
          47479,
          11,
          457,
          976,
          309,
          257,
          6408,
          281,
          264,
          6741,
          18161,
          51640
        ]
      },
      {
        "avg_logprob": -0.25237916105537006,
        "compression_ratio": 1.7522935779816513,
        "end": 3674.7999999999997,
        "id": 845,
        "no_speech_prob": 0.0024343631230294704,
        "seek": 366720,
        "start": 3667.2,
        "temperature": 0,
        "text": " network and then have that constructor instead of creating a new weight matrices that are",
        "tokens": [
          50364,
          3209,
          293,
          550,
          362,
          300,
          47479,
          2602,
          295,
          4084,
          257,
          777,
          3364,
          32284,
          300,
          366,
          50744
        ]
      },
      {
        "avg_logprob": -0.25237916105537006,
        "compression_ratio": 1.7522935779816513,
        "end": 3678.3999999999996,
        "id": 846,
        "no_speech_prob": 0.0024343631230294704,
        "seek": 366720,
        "start": 3674.7999999999997,
        "temperature": 0,
        "text": " random, it'll create weight matrices that are copies of the existing one.",
        "tokens": [
          50744,
          4974,
          11,
          309,
          603,
          1884,
          3364,
          32284,
          300,
          366,
          14341,
          295,
          264,
          6741,
          472,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.25237916105537006,
        "compression_ratio": 1.7522935779816513,
        "end": 3684.56,
        "id": 847,
        "no_speech_prob": 0.0024343631230294704,
        "seek": 366720,
        "start": 3678.3999999999996,
        "temperature": 0,
        "text": " In other words, let me go back up to the constructor and look at this.",
        "tokens": [
          50924,
          682,
          661,
          2283,
          11,
          718,
          385,
          352,
          646,
          493,
          281,
          264,
          47479,
          293,
          574,
          412,
          341,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.25237916105537006,
        "compression_ratio": 1.7522935779816513,
        "end": 3687.68,
        "id": 848,
        "no_speech_prob": 0.0024343631230294704,
        "seek": 366720,
        "start": 3684.56,
        "temperature": 0,
        "text": " So what if, so the constructor gets three things.",
        "tokens": [
          51232,
          407,
          437,
          498,
          11,
          370,
          264,
          47479,
          2170,
          1045,
          721,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.25237916105537006,
        "compression_ratio": 1.7522935779816513,
        "end": 3690.08,
        "id": 849,
        "no_speech_prob": 0.0024343631230294704,
        "seek": 366720,
        "start": 3689.8399999999997,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51496,
          1779,
          30,
          51508
        ]
      },
      {
        "avg_logprob": -0.25237916105537006,
        "compression_ratio": 1.7522935779816513,
        "end": 3696.48,
        "id": 850,
        "no_speech_prob": 0.0024343631230294704,
        "seek": 366720,
        "start": 3690.72,
        "temperature": 0,
        "text": " A, B, I could just like rename the parameters of the constructor function for a second and",
        "tokens": [
          51540,
          316,
          11,
          363,
          11,
          286,
          727,
          445,
          411,
          36741,
          264,
          9834,
          295,
          264,
          47479,
          2445,
          337,
          257,
          1150,
          293,
          51828
        ]
      },
      {
        "avg_logprob": -0.21582288520280704,
        "compression_ratio": 1.5485714285714285,
        "end": 3697.92,
        "id": 851,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 369648,
        "start": 3696.48,
        "temperature": 0,
        "text": " just call them A, B, C.",
        "tokens": [
          50364,
          445,
          818,
          552,
          316,
          11,
          363,
          11,
          383,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.21582288520280704,
        "compression_ratio": 1.5485714285714285,
        "end": 3698.56,
        "id": 852,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 369648,
        "start": 3697.92,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50436,
          1779,
          30,
          50468
        ]
      },
      {
        "avg_logprob": -0.21582288520280704,
        "compression_ratio": 1.5485714285714285,
        "end": 3702.8,
        "id": 853,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 369648,
        "start": 3698.56,
        "temperature": 0,
        "text": " A being the input nodes, B being the hidden nodes, C being the output nodes.",
        "tokens": [
          50468,
          316,
          885,
          264,
          4846,
          13891,
          11,
          363,
          885,
          264,
          7633,
          13891,
          11,
          383,
          885,
          264,
          5598,
          13891,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.21582288520280704,
        "compression_ratio": 1.5485714285714285,
        "end": 3710.64,
        "id": 854,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 369648,
        "start": 3702.8,
        "temperature": 0,
        "text": " But before I do that, what I actually want to say is, is A an instance of a neural network?",
        "tokens": [
          50680,
          583,
          949,
          286,
          360,
          300,
          11,
          437,
          286,
          767,
          528,
          281,
          584,
          307,
          11,
          307,
          316,
          364,
          5197,
          295,
          257,
          18161,
          3209,
          30,
          51072
        ]
      },
      {
        "avg_logprob": -0.21582288520280704,
        "compression_ratio": 1.5485714285714285,
        "end": 3714.2400000000002,
        "id": 855,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 369648,
        "start": 3713.92,
        "temperature": 0,
        "text": " Else.",
        "tokens": [
          51236,
          45472,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.21582288520280704,
        "compression_ratio": 1.5485714285714285,
        "end": 3722.4,
        "id": 856,
        "no_speech_prob": 0.00005225220957072452,
        "seek": 369648,
        "start": 3715.44,
        "temperature": 0,
        "text": " In other words, this is how I want to create, oh I turned, pause.",
        "tokens": [
          51312,
          682,
          661,
          2283,
          11,
          341,
          307,
          577,
          286,
          528,
          281,
          1884,
          11,
          1954,
          286,
          3574,
          11,
          10465,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.46409074883711965,
        "compression_ratio": 1.4012345679012346,
        "end": 3731.84,
        "id": 857,
        "no_speech_prob": 0.00010720862337620929,
        "seek": 372240,
        "start": 3723.12,
        "temperature": 0,
        "text": " I want to put a preference back that I turned off this morning and I got to check the time, 422.",
        "tokens": [
          50400,
          286,
          528,
          281,
          829,
          257,
          17502,
          646,
          300,
          286,
          3574,
          766,
          341,
          2446,
          293,
          286,
          658,
          281,
          1520,
          264,
          565,
          11,
          1017,
          7490,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.46409074883711965,
        "compression_ratio": 1.4012345679012346,
        "end": 3732.8,
        "id": 858,
        "no_speech_prob": 0.00010720862337620929,
        "seek": 372240,
        "start": 3731.84,
        "temperature": 0,
        "text": " It's 422.",
        "tokens": [
          50836,
          467,
          311,
          1017,
          7490,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.46409074883711965,
        "compression_ratio": 1.4012345679012346,
        "end": 3739.6800000000003,
        "id": 859,
        "no_speech_prob": 0.00010720862337620929,
        "seek": 372240,
        "start": 3736.8,
        "temperature": 0,
        "text": " Packages, beautify.",
        "tokens": [
          51084,
          18466,
          1660,
          11,
          1869,
          2505,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.46409074883711965,
        "compression_ratio": 1.4012345679012346,
        "end": 3746.08,
        "id": 860,
        "no_speech_prob": 0.00010720862337620929,
        "seek": 372240,
        "start": 3743.52,
        "temperature": 0,
        "text": " I just, I really like having it beautify on save.",
        "tokens": [
          51420,
          286,
          445,
          11,
          286,
          534,
          411,
          1419,
          309,
          1869,
          2505,
          322,
          3155,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.46409074883711965,
        "compression_ratio": 1.4012345679012346,
        "end": 3749.2000000000003,
        "id": 861,
        "no_speech_prob": 0.00010720862337620929,
        "seek": 372240,
        "start": 3747.6800000000003,
        "temperature": 0,
        "text": " I'm so used to that.",
        "tokens": [
          51628,
          286,
          478,
          370,
          1143,
          281,
          300,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.46409074883711965,
        "compression_ratio": 1.4012345679012346,
        "end": 3750.7200000000003,
        "id": 862,
        "no_speech_prob": 0.00010720862337620929,
        "seek": 372240,
        "start": 3749.2000000000003,
        "temperature": 0,
        "text": " So let me just put that back.",
        "tokens": [
          51704,
          407,
          718,
          385,
          445,
          829,
          300,
          646,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.26528780800955637,
        "compression_ratio": 1.5294117647058822,
        "end": 3755.36,
        "id": 863,
        "no_speech_prob": 0.00028240744723007083,
        "seek": 375240,
        "start": 3752.96,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50392,
          1033,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.26528780800955637,
        "compression_ratio": 1.5294117647058822,
        "end": 3758.4,
        "id": 864,
        "no_speech_prob": 0.00028240744723007083,
        "seek": 375240,
        "start": 3757.92,
        "temperature": 0,
        "text": " This here.",
        "tokens": [
          50640,
          639,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.26528780800955637,
        "compression_ratio": 1.5294117647058822,
        "end": 3768.96,
        "id": 865,
        "no_speech_prob": 0.00028240744723007083,
        "seek": 375240,
        "start": 3763.6,
        "temperature": 0,
        "text": " So what I want to do is if I'm being sent three integers,",
        "tokens": [
          50924,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          498,
          286,
          478,
          885,
          2279,
          1045,
          41674,
          11,
          51192
        ]
      },
      {
        "avg_logprob": -0.26528780800955637,
        "compression_ratio": 1.5294117647058822,
        "end": 3771.92,
        "id": 866,
        "no_speech_prob": 0.00028240744723007083,
        "seek": 375240,
        "start": 3768.96,
        "temperature": 0,
        "text": " then I want to make the neural network the way I always have.",
        "tokens": [
          51192,
          550,
          286,
          528,
          281,
          652,
          264,
          18161,
          3209,
          264,
          636,
          286,
          1009,
          362,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.26528780800955637,
        "compression_ratio": 1.5294117647058822,
        "end": 3778.8,
        "id": 867,
        "no_speech_prob": 0.00028240744723007083,
        "seek": 375240,
        "start": 3772.7200000000003,
        "temperature": 0,
        "text": " However, if I'm being sent the first argument, and this is kind of, this is known as overloading.",
        "tokens": [
          51380,
          2908,
          11,
          498,
          286,
          478,
          885,
          2279,
          264,
          700,
          6770,
          11,
          293,
          341,
          307,
          733,
          295,
          11,
          341,
          307,
          2570,
          382,
          28777,
          278,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3782.96,
        "id": 868,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3778.8,
        "temperature": 0,
        "text": " Typically in a programming language like Java, if I had to overload the constructor,",
        "tokens": [
          50364,
          23129,
          294,
          257,
          9410,
          2856,
          411,
          10745,
          11,
          498,
          286,
          632,
          281,
          28777,
          264,
          47479,
          11,
          50572
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3784.88,
        "id": 869,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3782.96,
        "temperature": 0,
        "text": " like there's two different ways I could call the constructor.",
        "tokens": [
          50572,
          411,
          456,
          311,
          732,
          819,
          2098,
          286,
          727,
          818,
          264,
          47479,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3787.52,
        "id": 870,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3784.88,
        "temperature": 0,
        "text": " I could give you three numbers to make a brand new neural network,",
        "tokens": [
          50668,
          286,
          727,
          976,
          291,
          1045,
          3547,
          281,
          652,
          257,
          3360,
          777,
          18161,
          3209,
          11,
          50800
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3790.32,
        "id": 871,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3787.52,
        "temperature": 0,
        "text": " or I could give you a neural network to make a copy of yourself.",
        "tokens": [
          50800,
          420,
          286,
          727,
          976,
          291,
          257,
          18161,
          3209,
          281,
          652,
          257,
          5055,
          295,
          1803,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3793.1200000000003,
        "id": 872,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3791.2000000000003,
        "temperature": 0,
        "text": " I would write two versions of the constructor.",
        "tokens": [
          50984,
          286,
          576,
          2464,
          732,
          9606,
          295,
          264,
          47479,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3795.84,
        "id": 873,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3793.1200000000003,
        "temperature": 0,
        "text": " But in JavaScript, you can only have one version of the constructor,",
        "tokens": [
          51080,
          583,
          294,
          15778,
          11,
          291,
          393,
          787,
          362,
          472,
          3037,
          295,
          264,
          47479,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3797.92,
        "id": 874,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3795.84,
        "temperature": 0,
        "text": " but you can kind of check what you're passing in.",
        "tokens": [
          51216,
          457,
          291,
          393,
          733,
          295,
          1520,
          437,
          291,
          434,
          8437,
          294,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3801.92,
        "id": 875,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3797.92,
        "temperature": 0,
        "text": " And just to be clear about this, let me just make sure this instance of thing is correct.",
        "tokens": [
          51320,
          400,
          445,
          281,
          312,
          1850,
          466,
          341,
          11,
          718,
          385,
          445,
          652,
          988,
          341,
          5197,
          295,
          551,
          307,
          3006,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.17569038494914568,
        "compression_ratio": 1.9150326797385622,
        "end": 3805.6000000000004,
        "id": 876,
        "no_speech_prob": 0.001810198649764061,
        "seek": 377880,
        "start": 3801.92,
        "temperature": 0,
        "text": " So if I were to say, let A be a new neural network.",
        "tokens": [
          51520,
          407,
          498,
          286,
          645,
          281,
          584,
          11,
          718,
          316,
          312,
          257,
          777,
          18161,
          3209,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3810,
        "id": 877,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3806.4,
        "temperature": 0,
        "text": " 4, 3, 2, just arbitrarily.",
        "tokens": [
          50404,
          1017,
          11,
          805,
          11,
          568,
          11,
          445,
          19071,
          3289,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3815.2799999999997,
        "id": 878,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3810,
        "temperature": 0,
        "text": " And I can say A instance of, it's without a capital, instance of a string.",
        "tokens": [
          50584,
          400,
          286,
          393,
          584,
          316,
          5197,
          295,
          11,
          309,
          311,
          1553,
          257,
          4238,
          11,
          5197,
          295,
          257,
          6798,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3817.7599999999998,
        "id": 879,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3816.64,
        "temperature": 0,
        "text": " I should get false.",
        "tokens": [
          50916,
          286,
          820,
          483,
          7908,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3820.88,
        "id": 880,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3817.7599999999998,
        "temperature": 0,
        "text": " Instance of a neural network, I should get true.",
        "tokens": [
          50972,
          2730,
          719,
          295,
          257,
          18161,
          3209,
          11,
          286,
          820,
          483,
          2074,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3822,
        "id": 881,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3820.88,
        "temperature": 0,
        "text": " Okay, so that's right.",
        "tokens": [
          51128,
          1033,
          11,
          370,
          300,
          311,
          558,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3824.3199999999997,
        "id": 882,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3822.72,
        "temperature": 0,
        "text": " This of should be lowercase though.",
        "tokens": [
          51220,
          639,
          295,
          820,
          312,
          3126,
          9765,
          1673,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3828,
        "id": 883,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3824.3199999999997,
        "temperature": 0,
        "text": " If A is an instance of a neural network, then what am I doing?",
        "tokens": [
          51300,
          759,
          316,
          307,
          364,
          5197,
          295,
          257,
          18161,
          3209,
          11,
          550,
          437,
          669,
          286,
          884,
          30,
          51484
        ]
      },
      {
        "avg_logprob": -0.3069095270974295,
        "compression_ratio": 1.671497584541063,
        "end": 3834.4,
        "id": 884,
        "no_speech_prob": 0.0009253792813979089,
        "seek": 380560,
        "start": 3828,
        "temperature": 0,
        "text": " Then I am saying this.inputNodes equals A.inputNodes.",
        "tokens": [
          51484,
          1396,
          286,
          669,
          1566,
          341,
          13,
          259,
          2582,
          45,
          4789,
          6915,
          316,
          13,
          259,
          2582,
          45,
          4789,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3840.08,
        "id": 885,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3835.8399999999997,
        "temperature": 0,
        "text": " Like I can start right here's where if it's not a neural network,",
        "tokens": [
          50376,
          1743,
          286,
          393,
          722,
          558,
          510,
          311,
          689,
          498,
          309,
          311,
          406,
          257,
          18161,
          3209,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3842.48,
        "id": 886,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3840.08,
        "temperature": 0,
        "text": " I'm actually assigning it the numbers that are coming in.",
        "tokens": [
          50588,
          286,
          478,
          767,
          49602,
          309,
          264,
          3547,
          300,
          366,
          1348,
          294,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3844.4,
        "id": 887,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3842.48,
        "temperature": 0,
        "text": " If it is, I can just keep going.",
        "tokens": [
          50708,
          759,
          309,
          307,
          11,
          286,
          393,
          445,
          1066,
          516,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3846.08,
        "id": 888,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3844.96,
        "temperature": 0,
        "text": " Oh, actually, what am I doing?",
        "tokens": [
          50832,
          876,
          11,
          767,
          11,
          437,
          669,
          286,
          884,
          30,
          50888
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3846.88,
        "id": 889,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3846.08,
        "temperature": 0,
        "text": " I can say this.",
        "tokens": [
          50888,
          286,
          393,
          584,
          341,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3850.16,
        "id": 890,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3849.04,
        "temperature": 0,
        "text": " And this should be hidden.",
        "tokens": [
          51036,
          400,
          341,
          820,
          312,
          7633,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3855.2,
        "id": 891,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3852.56,
        "temperature": 0,
        "text": " And now I can say this.",
        "tokens": [
          51212,
          400,
          586,
          286,
          393,
          584,
          341,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3859.2799999999997,
        "id": 892,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3855.92,
        "temperature": 0,
        "text": " Maybe I should, if somebody has a suggestion for how to name these in a better way,",
        "tokens": [
          51380,
          2704,
          286,
          820,
          11,
          498,
          2618,
          575,
          257,
          16541,
          337,
          577,
          281,
          1315,
          613,
          294,
          257,
          1101,
          636,
          11,
          51548
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3863.6,
        "id": 893,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3859.2799999999997,
        "temperature": 0,
        "text": " I just, I didn't want to name them hidden, input, hidden, output anymore",
        "tokens": [
          51548,
          286,
          445,
          11,
          286,
          994,
          380,
          528,
          281,
          1315,
          552,
          7633,
          11,
          4846,
          11,
          7633,
          11,
          5598,
          3602,
          51764
        ]
      },
      {
        "avg_logprob": -0.18712561058275629,
        "compression_ratio": 1.6940298507462686,
        "end": 3865.44,
        "id": 894,
        "no_speech_prob": 0.00006302753899944946,
        "seek": 383560,
        "start": 3863.6,
        "temperature": 0,
        "text": " because A could be either of those things.",
        "tokens": [
          51764,
          570,
          316,
          727,
          312,
          2139,
          295,
          729,
          721,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2474913180453106,
        "compression_ratio": 1.5093457943925233,
        "end": 3873.8399999999997,
        "id": 895,
        "no_speech_prob": 5.715003226214321e-7,
        "seek": 386560,
        "start": 3866.56,
        "temperature": 0,
        "text": " So, you know, this maybe like to do, document what A, B, C are.",
        "tokens": [
          50412,
          407,
          11,
          291,
          458,
          11,
          341,
          1310,
          411,
          281,
          360,
          11,
          4166,
          437,
          316,
          11,
          363,
          11,
          383,
          366,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.2474913180453106,
        "compression_ratio": 1.5093457943925233,
        "end": 3880.72,
        "id": 896,
        "no_speech_prob": 5.715003226214321e-7,
        "seek": 386560,
        "start": 3877.2,
        "temperature": 0,
        "text": " OutputNodes, that's a little note to myself that I don't like what I've written here.",
        "tokens": [
          50944,
          5925,
          2582,
          45,
          4789,
          11,
          300,
          311,
          257,
          707,
          3637,
          281,
          2059,
          300,
          286,
          500,
          380,
          411,
          437,
          286,
          600,
          3720,
          510,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.2474913180453106,
        "compression_ratio": 1.5093457943925233,
        "end": 3882.08,
        "id": 897,
        "no_speech_prob": 5.715003226214321e-7,
        "seek": 386560,
        "start": 3880.72,
        "temperature": 0,
        "text": " And then now let's look at these.",
        "tokens": [
          51120,
          400,
          550,
          586,
          718,
          311,
          574,
          412,
          613,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2474913180453106,
        "compression_ratio": 1.5093457943925233,
        "end": 3886.08,
        "id": 898,
        "no_speech_prob": 5.715003226214321e-7,
        "seek": 386560,
        "start": 3883.36,
        "temperature": 0,
        "text": " So I'm not going to need to randomize the weight matrices",
        "tokens": [
          51252,
          407,
          286,
          478,
          406,
          516,
          281,
          643,
          281,
          4974,
          1125,
          264,
          3364,
          32284,
          51388
        ]
      },
      {
        "avg_logprob": -0.2474913180453106,
        "compression_ratio": 1.5093457943925233,
        "end": 3890.72,
        "id": 899,
        "no_speech_prob": 5.715003226214321e-7,
        "seek": 386560,
        "start": 3886.08,
        "temperature": 0,
        "text": " because I'm just going to say equals, what am I going to do here?",
        "tokens": [
          51388,
          570,
          286,
          478,
          445,
          516,
          281,
          584,
          6915,
          11,
          437,
          669,
          286,
          516,
          281,
          360,
          510,
          30,
          51620
        ]
      },
      {
        "avg_logprob": -0.2474913180453106,
        "compression_ratio": 1.5093457943925233,
        "end": 3893.7599999999998,
        "id": 900,
        "no_speech_prob": 5.715003226214321e-7,
        "seek": 386560,
        "start": 3891.52,
        "temperature": 0,
        "text": " A.weights.copy.",
        "tokens": [
          51660,
          316,
          13,
          826,
          5761,
          13,
          13084,
          88,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3896.72,
        "id": 901,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3896.3199999999997,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50400,
          1779,
          30,
          50420
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3898.96,
        "id": 902,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3896.72,
        "temperature": 0,
        "text": " What I want to do is say, hey, my weights are your weights.",
        "tokens": [
          50420,
          708,
          286,
          528,
          281,
          360,
          307,
          584,
          11,
          4177,
          11,
          452,
          17443,
          366,
          428,
          17443,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3904.88,
        "id": 903,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3900.24,
        "temperature": 0,
        "text": " And now my input to hidden weights are your weights",
        "tokens": [
          50596,
          400,
          586,
          452,
          4846,
          281,
          7633,
          17443,
          366,
          428,
          17443,
          50828
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3907.2799999999997,
        "id": 904,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3904.88,
        "temperature": 0,
        "text": " and my hidden to output weights are your weights.",
        "tokens": [
          50828,
          293,
          452,
          7633,
          281,
          5598,
          17443,
          366,
          428,
          17443,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3908.64,
        "id": 905,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3907.2799999999997,
        "temperature": 0,
        "text": " Now, is this going to run?",
        "tokens": [
          50948,
          823,
          11,
          307,
          341,
          516,
          281,
          1190,
          30,
          51016
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3912.96,
        "id": 906,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3908.64,
        "temperature": 0,
        "text": " I don't think so because I probably have to add a copy method to the matrix object,",
        "tokens": [
          51016,
          286,
          500,
          380,
          519,
          370,
          570,
          286,
          1391,
          362,
          281,
          909,
          257,
          5055,
          3170,
          281,
          264,
          8141,
          2657,
          11,
          51232
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3914.64,
        "id": 907,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3912.96,
        "temperature": 0,
        "text": " but I'm getting somewhere.",
        "tokens": [
          51232,
          457,
          286,
          478,
          1242,
          4079,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3915.68,
        "id": 908,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3914.64,
        "temperature": 0,
        "text": " Now, what else do I need?",
        "tokens": [
          51316,
          823,
          11,
          437,
          1646,
          360,
          286,
          643,
          30,
          51368
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3916.72,
        "id": 909,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3915.68,
        "temperature": 0,
        "text": " I need the biases.",
        "tokens": [
          51368,
          286,
          643,
          264,
          32152,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3922,
        "id": 910,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3920,
        "temperature": 0,
        "text": " So I need to set the biases.",
        "tokens": [
          51584,
          407,
          286,
          643,
          281,
          992,
          264,
          32152,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.1770779609680176,
        "compression_ratio": 1.789237668161435,
        "end": 3923.2799999999997,
        "id": 911,
        "no_speech_prob": 0.000027969261282123625,
        "seek": 389560,
        "start": 3922,
        "temperature": 0,
        "text": " So the same thing.",
        "tokens": [
          51684,
          407,
          264,
          912,
          551,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.3257188712601113,
        "compression_ratio": 1.7215686274509805,
        "end": 3929.12,
        "id": 912,
        "no_speech_prob": 0.00003944235868402757,
        "seek": 392560,
        "start": 3926,
        "temperature": 0,
        "text": " I'm just doing a lot of little copy-paste stuff here.",
        "tokens": [
          50384,
          286,
          478,
          445,
          884,
          257,
          688,
          295,
          707,
          5055,
          12,
          79,
          9079,
          1507,
          510,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.3257188712601113,
        "compression_ratio": 1.7215686274509805,
        "end": 3932.88,
        "id": 913,
        "no_speech_prob": 0.00003944235868402757,
        "seek": 392560,
        "start": 3929.12,
        "temperature": 0,
        "text": " So I need to set the hidden bias values and the output bias values.",
        "tokens": [
          50540,
          407,
          286,
          643,
          281,
          992,
          264,
          7633,
          12577,
          4190,
          293,
          264,
          5598,
          12577,
          4190,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.3257188712601113,
        "compression_ratio": 1.7215686274509805,
        "end": 3936.96,
        "id": 914,
        "no_speech_prob": 0.00003944235868402757,
        "seek": 392560,
        "start": 3933.52,
        "temperature": 0,
        "text": " So this is me creating this new copy of a previous neural network.",
        "tokens": [
          50760,
          407,
          341,
          307,
          385,
          4084,
          341,
          777,
          5055,
          295,
          257,
          3894,
          18161,
          3209,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.3257188712601113,
        "compression_ratio": 1.7215686274509805,
        "end": 3942.48,
        "id": 915,
        "no_speech_prob": 0.00003944235868402757,
        "seek": 392560,
        "start": 3936.96,
        "temperature": 0,
        "text": " And then, you know, right now it looks like learning rate and activation function",
        "tokens": [
          50932,
          400,
          550,
          11,
          291,
          458,
          11,
          558,
          586,
          309,
          1542,
          411,
          2539,
          3314,
          293,
          24433,
          2445,
          51208
        ]
      },
      {
        "avg_logprob": -0.3257188712601113,
        "compression_ratio": 1.7215686274509805,
        "end": 3946.3199999999997,
        "id": 916,
        "no_speech_prob": 0.00003944235868402757,
        "seek": 392560,
        "start": 3942.48,
        "temperature": 0,
        "text": " are at the moment, even though I have different activation functions,",
        "tokens": [
          51208,
          366,
          412,
          264,
          1623,
          11,
          754,
          1673,
          286,
          362,
          819,
          24433,
          6828,
          11,
          51400
        ]
      },
      {
        "avg_logprob": -0.3257188712601113,
        "compression_ratio": 1.7215686274509805,
        "end": 3952.3199999999997,
        "id": 917,
        "no_speech_prob": 0.00003944235868402757,
        "seek": 392560,
        "start": 3949.52,
        "temperature": 0,
        "text": " I can kind of write is this default is getting set to sigma",
        "tokens": [
          51560,
          286,
          393,
          733,
          295,
          2464,
          307,
          341,
          7576,
          307,
          1242,
          992,
          281,
          12771,
          51700
        ]
      },
      {
        "avg_logprob": -0.3257188712601113,
        "compression_ratio": 1.7215686274509805,
        "end": 3954.16,
        "id": 918,
        "no_speech_prob": 0.00003944235868402757,
        "seek": 392560,
        "start": 3952.3199999999997,
        "temperature": 0,
        "text": " and its default is getting set to 0.1.",
        "tokens": [
          51700,
          293,
          1080,
          7576,
          307,
          1242,
          992,
          281,
          1958,
          13,
          16,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3957.6,
        "id": 919,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3954.96,
        "temperature": 0,
        "text": " So I probably should copy those as well.",
        "tokens": [
          50404,
          407,
          286,
          1391,
          820,
          5055,
          729,
          382,
          731,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3960.96,
        "id": 920,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3958.3999999999996,
        "temperature": 0,
        "text": " I'm just going to just be simple about this right now",
        "tokens": [
          50576,
          286,
          478,
          445,
          516,
          281,
          445,
          312,
          2199,
          466,
          341,
          558,
          586,
          50704
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3964.72,
        "id": 921,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3960.96,
        "temperature": 0,
        "text": " and just assume that my program is never going to change learning rate",
        "tokens": [
          50704,
          293,
          445,
          6552,
          300,
          452,
          1461,
          307,
          1128,
          516,
          281,
          1319,
          2539,
          3314,
          50892
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3965.92,
        "id": 922,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3964.72,
        "temperature": 0,
        "text": " or activation function.",
        "tokens": [
          50892,
          420,
          24433,
          2445,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3967.3599999999997,
        "id": 923,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3966.3199999999997,
        "temperature": 0,
        "text": " That should be a to do.",
        "tokens": [
          50972,
          663,
          820,
          312,
          257,
          281,
          360,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3973.68,
        "id": 924,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3970.3199999999997,
        "temperature": 0,
        "text": " To do copy these as well at some point.",
        "tokens": [
          51172,
          1407,
          360,
          5055,
          613,
          382,
          731,
          412,
          512,
          935,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3974.96,
        "id": 925,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3973.68,
        "temperature": 0,
        "text": " But I don't need to worry about that right now.",
        "tokens": [
          51340,
          583,
          286,
          500,
          380,
          643,
          281,
          3292,
          466,
          300,
          558,
          586,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3978.64,
        "id": 926,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3974.96,
        "temperature": 0,
        "text": " And to be honest, the learning rate isn't going to play a role anymore.",
        "tokens": [
          51404,
          400,
          281,
          312,
          3245,
          11,
          264,
          2539,
          3314,
          1943,
          380,
          516,
          281,
          862,
          257,
          3090,
          3602,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3980.24,
        "id": 927,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3978.64,
        "temperature": 0,
        "text": " The learning rate is completely irrelevant.",
        "tokens": [
          51588,
          440,
          2539,
          3314,
          307,
          2584,
          28682,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.18405450439453125,
        "compression_ratio": 1.8320895522388059,
        "end": 3983.8399999999997,
        "id": 928,
        "no_speech_prob": 0.0003514363488648087,
        "seek": 395416,
        "start": 3980.24,
        "temperature": 0,
        "text": " The learning rate is specifically tied to the gradient descent algorithm,",
        "tokens": [
          51668,
          440,
          2539,
          3314,
          307,
          4682,
          9601,
          281,
          264,
          16235,
          23475,
          9284,
          11,
          51848
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 3990,
        "id": 929,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3984.08,
        "temperature": 0,
        "text": " I'm no longer using with the genetic algorithm.",
        "tokens": [
          50376,
          286,
          478,
          572,
          2854,
          1228,
          365,
          264,
          12462,
          9284,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 3991.04,
        "id": 930,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3990,
        "temperature": 0,
        "text": " That's what I'm doing now.",
        "tokens": [
          50672,
          663,
          311,
          437,
          286,
          478,
          884,
          586,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 3992.2400000000002,
        "id": 931,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3991.04,
        "temperature": 0,
        "text": " OK, we're getting somewhere.",
        "tokens": [
          50724,
          2264,
          11,
          321,
          434,
          1242,
          4079,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 3992.56,
        "id": 932,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3992.2400000000002,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50784,
          1057,
          558,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 3996.32,
        "id": 933,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3993.1200000000003,
        "temperature": 0,
        "text": " So just out of curiosity, remember, this is the code.",
        "tokens": [
          50828,
          407,
          445,
          484,
          295,
          18769,
          11,
          1604,
          11,
          341,
          307,
          264,
          3089,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 3998,
        "id": 934,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3996.32,
        "temperature": 0,
        "text": " I'm making a new neural network.",
        "tokens": [
          50988,
          286,
          478,
          1455,
          257,
          777,
          18161,
          3209,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 3999.92,
        "id": 935,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3998,
        "temperature": 0,
        "text": " And I know I haven't done mutate yet.",
        "tokens": [
          51072,
          400,
          286,
          458,
          286,
          2378,
          380,
          1096,
          5839,
          473,
          1939,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 4001.36,
        "id": 936,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 3999.92,
        "temperature": 0,
        "text": " But is this even working?",
        "tokens": [
          51168,
          583,
          307,
          341,
          754,
          1364,
          30,
          51240
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 4008.56,
        "id": 937,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 4004.7200000000003,
        "temperature": 0,
        "text": " Is there was there by did I maybe in some other universe",
        "tokens": [
          51408,
          1119,
          456,
          390,
          456,
          538,
          630,
          286,
          1310,
          294,
          512,
          661,
          6445,
          51600
        ]
      },
      {
        "avg_logprob": -0.25328138896397184,
        "compression_ratio": 1.5098039215686274,
        "end": 4013.44,
        "id": 938,
        "no_speech_prob": 0.00035143629065714777,
        "seek": 398384,
        "start": 4008.56,
        "temperature": 0,
        "text": " happen to write a copy function already into the matrix class?",
        "tokens": [
          51600,
          1051,
          281,
          2464,
          257,
          5055,
          2445,
          1217,
          666,
          264,
          8141,
          1508,
          30,
          51844
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4014.16,
        "id": 939,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4013.44,
        "temperature": 0,
        "text": " Seriously doubt it.",
        "tokens": [
          50364,
          14063,
          6385,
          309,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4014.7200000000003,
        "id": 940,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4014.16,
        "temperature": 0,
        "text": " But let's see.",
        "tokens": [
          50400,
          583,
          718,
          311,
          536,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4017.2000000000003,
        "id": 941,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4015.44,
        "temperature": 0,
        "text": " Yeah, copy is not a function.",
        "tokens": [
          50464,
          865,
          11,
          5055,
          307,
          406,
          257,
          2445,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4021.52,
        "id": 942,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4017.2000000000003,
        "temperature": 0,
        "text": " So what this means is I need to also go into the matrix library.",
        "tokens": [
          50552,
          407,
          437,
          341,
          1355,
          307,
          286,
          643,
          281,
          611,
          352,
          666,
          264,
          8141,
          6405,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4025.04,
        "id": 943,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4021.52,
        "temperature": 0,
        "text": " And I think this I think is worth having in here.",
        "tokens": [
          50768,
          400,
          286,
          519,
          341,
          286,
          519,
          307,
          3163,
          1419,
          294,
          510,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4030.16,
        "id": 944,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4025.04,
        "temperature": 0,
        "text": " That's not just this isn't exclusive to genetic algorithms or neuro evolution.",
        "tokens": [
          50944,
          663,
          311,
          406,
          445,
          341,
          1943,
          380,
          13005,
          281,
          12462,
          14642,
          420,
          16499,
          9303,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4035.12,
        "id": 945,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4030.16,
        "temperature": 0,
        "text": " Like so I'm adding this stuff, you know, copy and mutate and crossover will be here",
        "tokens": [
          51200,
          1743,
          370,
          286,
          478,
          5127,
          341,
          1507,
          11,
          291,
          458,
          11,
          5055,
          293,
          5839,
          473,
          293,
          33837,
          486,
          312,
          510,
          51448
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4036.96,
        "id": 946,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4035.12,
        "temperature": 0,
        "text": " specifically because of genetic algorithm.",
        "tokens": [
          51448,
          4682,
          570,
          295,
          12462,
          9284,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4040.64,
        "id": 947,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4036.96,
        "temperature": 0,
        "text": " But the matrix I can the matrix objects, I can be a little less formal about this.",
        "tokens": [
          51540,
          583,
          264,
          8141,
          286,
          393,
          264,
          8141,
          6565,
          11,
          286,
          393,
          312,
          257,
          707,
          1570,
          9860,
          466,
          341,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.23334040570614942,
        "compression_ratio": 1.6711864406779662,
        "end": 4041.68,
        "id": 948,
        "no_speech_prob": 0.00017952724010683596,
        "seek": 401344,
        "start": 4040.64,
        "temperature": 0,
        "text": " So what do I want to do?",
        "tokens": [
          51724,
          407,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51776
        ]
      },
      {
        "avg_logprob": -0.1743748982747396,
        "compression_ratio": 1.6519823788546255,
        "end": 4043.3599999999997,
        "id": 949,
        "no_speech_prob": 0.0005527762696146965,
        "seek": 404168,
        "start": 4041.7599999999998,
        "temperature": 0,
        "text": " I want to write a function copy.",
        "tokens": [
          50368,
          286,
          528,
          281,
          2464,
          257,
          2445,
          5055,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.1743748982747396,
        "compression_ratio": 1.6519823788546255,
        "end": 4045.8399999999997,
        "id": 950,
        "no_speech_prob": 0.0005527762696146965,
        "seek": 404168,
        "start": 4044.48,
        "temperature": 0,
        "text": " And what do I do?",
        "tokens": [
          50504,
          400,
          437,
          360,
          286,
          360,
          30,
          50572
        ]
      },
      {
        "avg_logprob": -0.1743748982747396,
        "compression_ratio": 1.6519823788546255,
        "end": 4055.7599999999998,
        "id": 951,
        "no_speech_prob": 0.0005527762696146965,
        "seek": 404168,
        "start": 4045.8399999999997,
        "temperature": 0,
        "text": " I'm going to say let m equal a new matrix with this dot rows, this dot columns.",
        "tokens": [
          50572,
          286,
          478,
          516,
          281,
          584,
          718,
          275,
          2681,
          257,
          777,
          8141,
          365,
          341,
          5893,
          13241,
          11,
          341,
          5893,
          13766,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.1743748982747396,
        "compression_ratio": 1.6519823788546255,
        "end": 4060.08,
        "id": 952,
        "no_speech_prob": 0.0005527762696146965,
        "seek": 404168,
        "start": 4055.7599999999998,
        "temperature": 0,
        "text": " So I create a matrix object with the same number of rows and columns.",
        "tokens": [
          51068,
          407,
          286,
          1884,
          257,
          8141,
          2657,
          365,
          264,
          912,
          1230,
          295,
          13241,
          293,
          13766,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.1743748982747396,
        "compression_ratio": 1.6519823788546255,
        "end": 4065.3599999999997,
        "id": 953,
        "no_speech_prob": 0.0005527762696146965,
        "seek": 404168,
        "start": 4060.08,
        "temperature": 0,
        "text": " And somebody in the chat I know is going to tell me there's some very fancy way that I",
        "tokens": [
          51284,
          400,
          2618,
          294,
          264,
          5081,
          286,
          458,
          307,
          516,
          281,
          980,
          385,
          456,
          311,
          512,
          588,
          10247,
          636,
          300,
          286,
          51548
        ]
      },
      {
        "avg_logprob": -0.1743748982747396,
        "compression_ratio": 1.6519823788546255,
        "end": 4070,
        "id": 954,
        "no_speech_prob": 0.0005527762696146965,
        "seek": 404168,
        "start": 4065.3599999999997,
        "temperature": 0,
        "text": " could just instantly use some higher order array function to copy the whole thing over.",
        "tokens": [
          51548,
          727,
          445,
          13518,
          764,
          512,
          2946,
          1668,
          10225,
          2445,
          281,
          5055,
          264,
          1379,
          551,
          670,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.1750060995829474,
        "compression_ratio": 1.7202072538860103,
        "end": 4080,
        "id": 955,
        "no_speech_prob": 0.0006563720526173711,
        "seek": 407000,
        "start": 4070,
        "temperature": 0,
        "text": " But because I am who I am, I'm going to say I'm going to write a nice little nested loop,",
        "tokens": [
          50364,
          583,
          570,
          286,
          669,
          567,
          286,
          669,
          11,
          286,
          478,
          516,
          281,
          584,
          286,
          478,
          516,
          281,
          2464,
          257,
          1481,
          707,
          15646,
          292,
          6367,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1750060995829474,
        "compression_ratio": 1.7202072538860103,
        "end": 4083.68,
        "id": 956,
        "no_speech_prob": 0.0006563720526173711,
        "seek": 407000,
        "start": 4080,
        "temperature": 0,
        "text": " I can always refactor this later, I just know this is going to work.",
        "tokens": [
          50864,
          286,
          393,
          1009,
          1895,
          15104,
          341,
          1780,
          11,
          286,
          445,
          458,
          341,
          307,
          516,
          281,
          589,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.1750060995829474,
        "compression_ratio": 1.7202072538860103,
        "end": 4092.88,
        "id": 957,
        "no_speech_prob": 0.0006563720526173711,
        "seek": 407000,
        "start": 4083.68,
        "temperature": 0,
        "text": " And I'm going to say m dot data index i index j equals this, this dot data index i index j.",
        "tokens": [
          51048,
          400,
          286,
          478,
          516,
          281,
          584,
          275,
          5893,
          1412,
          8186,
          741,
          8186,
          361,
          6915,
          341,
          11,
          341,
          5893,
          1412,
          8186,
          741,
          8186,
          361,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.1750060995829474,
        "compression_ratio": 1.7202072538860103,
        "end": 4096.64,
        "id": 958,
        "no_speech_prob": 0.0006563720526173711,
        "seek": 407000,
        "start": 4092.88,
        "temperature": 0,
        "text": " So this is manually me looping through the entire matrix.",
        "tokens": [
          51508,
          407,
          341,
          307,
          16945,
          385,
          6367,
          278,
          807,
          264,
          2302,
          8141,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.1750060995829474,
        "compression_ratio": 1.7202072538860103,
        "end": 4097.92,
        "id": 959,
        "no_speech_prob": 0.0006563720526173711,
        "seek": 407000,
        "start": 4096.64,
        "temperature": 0,
        "text": " It's a grid of numbers.",
        "tokens": [
          51696,
          467,
          311,
          257,
          10748,
          295,
          3547,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4101.28,
        "id": 960,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4097.92,
        "temperature": 0,
        "text": " It's all the weights of the connection to the neural network and just manually",
        "tokens": [
          50364,
          467,
          311,
          439,
          264,
          17443,
          295,
          264,
          4984,
          281,
          264,
          18161,
          3209,
          293,
          445,
          16945,
          50532
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4103.28,
        "id": 961,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4101.28,
        "temperature": 0,
        "text": " copying them over one by one.",
        "tokens": [
          50532,
          27976,
          552,
          670,
          472,
          538,
          472,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4105.2,
        "id": 962,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4103.28,
        "temperature": 0,
        "text": " And I think this will work.",
        "tokens": [
          50632,
          400,
          286,
          519,
          341,
          486,
          589,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4114.4,
        "id": 963,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4111.2,
        "temperature": 0,
        "text": " I have some breaking news from the chat that I need to mention in a second,",
        "tokens": [
          51028,
          286,
          362,
          512,
          7697,
          2583,
          490,
          264,
          5081,
          300,
          286,
          643,
          281,
          2152,
          294,
          257,
          1150,
          11,
          51188
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4116,
        "id": 964,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4114.4,
        "temperature": 0,
        "text": " but it's not relevant to what I'm doing right now.",
        "tokens": [
          51188,
          457,
          309,
          311,
          406,
          7340,
          281,
          437,
          286,
          478,
          884,
          558,
          586,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4116.96,
        "id": 965,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4116,
        "temperature": 0,
        "text": " So I will come back to that.",
        "tokens": [
          51268,
          407,
          286,
          486,
          808,
          646,
          281,
          300,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4119.12,
        "id": 966,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4118.4,
        "temperature": 0,
        "text": " All right, so let's see.",
        "tokens": [
          51388,
          1057,
          558,
          11,
          370,
          718,
          311,
          536,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4120.24,
        "id": 967,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4119.12,
        "temperature": 0,
        "text": " Let me hit refresh.",
        "tokens": [
          51424,
          961,
          385,
          2045,
          15134,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4121.04,
        "id": 968,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4120.24,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51480,
          821,
          321,
          352,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4122.56,
        "id": 969,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4121.04,
        "temperature": 0,
        "text": " So does this work?",
        "tokens": [
          51520,
          407,
          775,
          341,
          589,
          30,
          51596
        ]
      },
      {
        "avg_logprob": -0.19567322931369813,
        "compression_ratio": 1.640495867768595,
        "end": 4125.6,
        "id": 970,
        "no_speech_prob": 0.02064552903175354,
        "seek": 409792,
        "start": 4122.56,
        "temperature": 0,
        "text": " I have two neural networks.",
        "tokens": [
          51596,
          286,
          362,
          732,
          18161,
          9590,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4129.6,
        "id": 971,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4125.6,
        "temperature": 0,
        "text": " They both seem to have 2, 4, 1, 2, 4, 1.",
        "tokens": [
          50364,
          814,
          1293,
          1643,
          281,
          362,
          568,
          11,
          1017,
          11,
          502,
          11,
          568,
          11,
          1017,
          11,
          502,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4133.4400000000005,
        "id": 972,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4130.320000000001,
        "temperature": 0,
        "text": " You know, I could go, let me look at one of these biases.",
        "tokens": [
          50600,
          509,
          458,
          11,
          286,
          727,
          352,
          11,
          718,
          385,
          574,
          412,
          472,
          295,
          613,
          32152,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4134.320000000001,
        "id": 973,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4133.4400000000005,
        "temperature": 0,
        "text": " Let me look at these values.",
        "tokens": [
          50756,
          961,
          385,
          574,
          412,
          613,
          4190,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4136.08,
        "id": 974,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4134.320000000001,
        "temperature": 0,
        "text": " So this is bias h.",
        "tokens": [
          50800,
          407,
          341,
          307,
          12577,
          276,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4137.04,
        "id": 975,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4136.08,
        "temperature": 0,
        "text": " These are the values.",
        "tokens": [
          50888,
          1981,
          366,
          264,
          4190,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4138,
        "id": 976,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4137.04,
        "temperature": 0,
        "text": " Can you memorize those?",
        "tokens": [
          50936,
          1664,
          291,
          27478,
          729,
          30,
          50984
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4139.200000000001,
        "id": 977,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4138,
        "temperature": 0,
        "text": " Can you remember them?",
        "tokens": [
          50984,
          1664,
          291,
          1604,
          552,
          30,
          51044
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4140.240000000001,
        "id": 978,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4139.200000000001,
        "temperature": 0,
        "text": " Let's go down here.",
        "tokens": [
          51044,
          961,
          311,
          352,
          760,
          510,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4144.56,
        "id": 979,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4141.360000000001,
        "temperature": 0,
        "text": " OK, nope, nope, something is wrong.",
        "tokens": [
          51152,
          2264,
          11,
          23444,
          11,
          23444,
          11,
          746,
          307,
          2085,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4146.64,
        "id": 980,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4144.56,
        "temperature": 0,
        "text": " So this stuff did not get copied.",
        "tokens": [
          51312,
          407,
          341,
          1507,
          630,
          406,
          483,
          25365,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4147.4400000000005,
        "id": 981,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4146.64,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          51416,
          17795,
          437,
          30,
          51456
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4148.400000000001,
        "id": 982,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4147.4400000000005,
        "temperature": 0,
        "text": " Guess what I forgot?",
        "tokens": [
          51456,
          17795,
          437,
          286,
          5298,
          30,
          51504
        ]
      },
      {
        "avg_logprob": -0.19828129565621924,
        "compression_ratio": 1.626086956521739,
        "end": 4155.4400000000005,
        "id": 983,
        "no_speech_prob": 0.00019110368157271296,
        "seek": 412560,
        "start": 4152.400000000001,
        "temperature": 0,
        "text": " I forgot something quite important.",
        "tokens": [
          51704,
          286,
          5298,
          746,
          1596,
          1021,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4159.679999999999,
        "id": 984,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4155.679999999999,
        "temperature": 0,
        "text": " In this function, I did not forget to return the thing that's new.",
        "tokens": [
          50376,
          682,
          341,
          2445,
          11,
          286,
          630,
          406,
          2870,
          281,
          2736,
          264,
          551,
          300,
          311,
          777,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4164,
        "id": 985,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4159.679999999999,
        "temperature": 0,
        "text": " But in the matrix, I forgot to say return n.",
        "tokens": [
          50576,
          583,
          294,
          264,
          8141,
          11,
          286,
          5298,
          281,
          584,
          2736,
          297,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4166.799999999999,
        "id": 986,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4164,
        "temperature": 0,
        "text": " So this new matrix that I'm making, I've got to actually return it.",
        "tokens": [
          50792,
          407,
          341,
          777,
          8141,
          300,
          286,
          478,
          1455,
          11,
          286,
          600,
          658,
          281,
          767,
          2736,
          309,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4167.919999999999,
        "id": 987,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4166.799999999999,
        "temperature": 0,
        "text": " I made the copy.",
        "tokens": [
          50932,
          286,
          1027,
          264,
          5055,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4169.2,
        "id": 988,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4167.919999999999,
        "temperature": 0,
        "text": " You can make the copy.",
        "tokens": [
          50988,
          509,
          393,
          652,
          264,
          5055,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4170.799999999999,
        "id": 989,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4169.2,
        "temperature": 0,
        "text": " You can take the reservation.",
        "tokens": [
          51052,
          509,
          393,
          747,
          264,
          28922,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4173.839999999999,
        "id": 990,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4170.799999999999,
        "temperature": 0,
        "text": " But you can't hold the return the copy.",
        "tokens": [
          51132,
          583,
          291,
          393,
          380,
          1797,
          264,
          2736,
          264,
          5055,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4175.679999999999,
        "id": 991,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4173.839999999999,
        "temperature": 0,
        "text": " I don't know, a little Seinfeld reference for all of you.",
        "tokens": [
          51284,
          286,
          500,
          380,
          458,
          11,
          257,
          707,
          1100,
          19920,
          5957,
          6408,
          337,
          439,
          295,
          291,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4176.48,
        "id": 992,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4175.679999999999,
        "temperature": 0,
        "text": " I probably shouldn't have said that.",
        "tokens": [
          51376,
          286,
          1391,
          4659,
          380,
          362,
          848,
          300,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4177.599999999999,
        "id": 993,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4176.48,
        "temperature": 0,
        "text": " It'd be more interesting if I didn't say that.",
        "tokens": [
          51416,
          467,
          1116,
          312,
          544,
          1880,
          498,
          286,
          994,
          380,
          584,
          300,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4182.719999999999,
        "id": 994,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4177.599999999999,
        "temperature": 0,
        "text": " OK, so now I can look here.",
        "tokens": [
          51472,
          2264,
          11,
          370,
          586,
          286,
          393,
          574,
          510,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.16538207561938795,
        "compression_ratio": 1.7892857142857144,
        "end": 4184.799999999999,
        "id": 995,
        "no_speech_prob": 0.00010720835416577756,
        "seek": 415544,
        "start": 4182.719999999999,
        "temperature": 0,
        "text": " And I can see, OK, look at these numbers.",
        "tokens": [
          51728,
          400,
          286,
          393,
          536,
          11,
          2264,
          11,
          574,
          412,
          613,
          3547,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4186.879999999999,
        "id": 996,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4185.5199999999995,
        "temperature": 0,
        "text": " Memorize these numbers.",
        "tokens": [
          50368,
          8731,
          284,
          1125,
          613,
          3547,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4188.639999999999,
        "id": 997,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4186.879999999999,
        "temperature": 0,
        "text": " This is the way, actually, let me look at,",
        "tokens": [
          50436,
          639,
          307,
          264,
          636,
          11,
          767,
          11,
          718,
          385,
          574,
          412,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4190.719999999999,
        "id": 998,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4189.28,
        "temperature": 0,
        "text": " I'm just going to look at one of the bias ones.",
        "tokens": [
          50556,
          286,
          478,
          445,
          516,
          281,
          574,
          412,
          472,
          295,
          264,
          12577,
          2306,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4191.679999999999,
        "id": 999,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4190.719999999999,
        "temperature": 0,
        "text": " This will be a little bit simpler.",
        "tokens": [
          50628,
          639,
          486,
          312,
          257,
          707,
          857,
          18587,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4193.599999999999,
        "id": 1000,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4192.32,
        "temperature": 0,
        "text": " So here's the bias.",
        "tokens": [
          50708,
          407,
          510,
          311,
          264,
          12577,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4195.28,
        "id": 1001,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4193.599999999999,
        "temperature": 0,
        "text": " Bias h has these values.",
        "tokens": [
          50772,
          363,
          4609,
          276,
          575,
          613,
          4190,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4196.799999999999,
        "id": 1002,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4195.28,
        "temperature": 0,
        "text": " Memorize them, memorize them.",
        "tokens": [
          50856,
          8731,
          284,
          1125,
          552,
          11,
          27478,
          552,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4200.32,
        "id": 1003,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4196.799999999999,
        "temperature": 0,
        "text": " I could write a nice unit test to actually see if this function worked.",
        "tokens": [
          50932,
          286,
          727,
          2464,
          257,
          1481,
          4985,
          1500,
          281,
          767,
          536,
          498,
          341,
          2445,
          2732,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4201.839999999999,
        "id": 1004,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4200.32,
        "temperature": 0,
        "text": " That would be much better.",
        "tokens": [
          51108,
          663,
          576,
          312,
          709,
          1101,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4203.2,
        "id": 1005,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4201.839999999999,
        "temperature": 0,
        "text": " But I'm going to eyeball it.",
        "tokens": [
          51184,
          583,
          286,
          478,
          516,
          281,
          38868,
          309,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4206.08,
        "id": 1006,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4204.639999999999,
        "temperature": 0,
        "text": " 0.208415.",
        "tokens": [
          51324,
          1958,
          13,
          2009,
          25494,
          5211,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4207.44,
        "id": 1007,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4206.08,
        "temperature": 0,
        "text": " Yep, these look like the same numbers.",
        "tokens": [
          51396,
          7010,
          11,
          613,
          574,
          411,
          264,
          912,
          3547,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4208.879999999999,
        "id": 1008,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4207.44,
        "temperature": 0,
        "text": " Same numbers, same numbers.",
        "tokens": [
          51464,
          10635,
          3547,
          11,
          912,
          3547,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.1957117227407602,
        "compression_ratio": 1.7857142857142858,
        "end": 4213.04,
        "id": 1009,
        "no_speech_prob": 0.000014064014067116659,
        "seek": 418544,
        "start": 4208.879999999999,
        "temperature": 0,
        "text": " So I'm going to just choose at the moment to believe that this worked.",
        "tokens": [
          51536,
          407,
          286,
          478,
          516,
          281,
          445,
          2826,
          412,
          264,
          1623,
          281,
          1697,
          300,
          341,
          2732,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4215.84,
        "id": 1010,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4213.36,
        "temperature": 0,
        "text": " This is probably a bad idea.",
        "tokens": [
          50380,
          639,
          307,
          1391,
          257,
          1578,
          1558,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4218.64,
        "id": 1011,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4215.84,
        "temperature": 0,
        "text": " But this is the reality of what I'm going to do.",
        "tokens": [
          50504,
          583,
          341,
          307,
          264,
          4103,
          295,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4220.8,
        "id": 1012,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4219.6,
        "temperature": 0,
        "text": " And I'm OK with that.",
        "tokens": [
          50692,
          400,
          286,
          478,
          2264,
          365,
          300,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4221.5199999999995,
        "id": 1013,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4220.8,
        "temperature": 0,
        "text": " So let's move on.",
        "tokens": [
          50752,
          407,
          718,
          311,
          1286,
          322,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4224,
        "id": 1014,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4221.5199999999995,
        "temperature": 0,
        "text": " So we have now implemented copy.",
        "tokens": [
          50788,
          407,
          321,
          362,
          586,
          12270,
          5055,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4227.92,
        "id": 1015,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4225.12,
        "temperature": 0,
        "text": " What I next need to do is implement mutation.",
        "tokens": [
          50968,
          708,
          286,
          958,
          643,
          281,
          360,
          307,
          4445,
          27960,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4231.6,
        "id": 1016,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4228.4,
        "temperature": 0,
        "text": " Now, I do need, in order to do mutation,",
        "tokens": [
          51132,
          823,
          11,
          286,
          360,
          643,
          11,
          294,
          1668,
          281,
          360,
          27960,
          11,
          51292
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4234.96,
        "id": 1017,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4231.6,
        "temperature": 0,
        "text": " I need to have something called a mutation rate.",
        "tokens": [
          51292,
          286,
          643,
          281,
          362,
          746,
          1219,
          257,
          27960,
          3314,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.23827318464006697,
        "compression_ratio": 1.6497695852534562,
        "end": 4239.12,
        "id": 1018,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 421304,
        "start": 4234.96,
        "temperature": 0,
        "text": " And that mutation rate is essentially a probability of how likely it is",
        "tokens": [
          51460,
          400,
          300,
          27960,
          3314,
          307,
          4476,
          257,
          8482,
          295,
          577,
          3700,
          309,
          307,
          51668
        ]
      },
      {
        "avg_logprob": -0.17437895658974337,
        "compression_ratio": 1.6651785714285714,
        "end": 4249.5199999999995,
        "id": 1019,
        "no_speech_prob": 0.0008295843144878745,
        "seek": 423912,
        "start": 4240.08,
        "temperature": 0,
        "text": " for each element of every sort of DNA to alter itself randomly",
        "tokens": [
          50412,
          337,
          1184,
          4478,
          295,
          633,
          1333,
          295,
          8272,
          281,
          11337,
          2564,
          16979,
          50884
        ]
      },
      {
        "avg_logprob": -0.17437895658974337,
        "compression_ratio": 1.6651785714285714,
        "end": 4251.04,
        "id": 1020,
        "no_speech_prob": 0.0008295843144878745,
        "seek": 423912,
        "start": 4249.5199999999995,
        "temperature": 0,
        "text": " when that child DNA is made.",
        "tokens": [
          50884,
          562,
          300,
          1440,
          8272,
          307,
          1027,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.17437895658974337,
        "compression_ratio": 1.6651785714285714,
        "end": 4255.92,
        "id": 1021,
        "no_speech_prob": 0.0008295843144878745,
        "seek": 423912,
        "start": 4251.04,
        "temperature": 0,
        "text": " So what that means in this context is for every single number that's a weight",
        "tokens": [
          50960,
          407,
          437,
          300,
          1355,
          294,
          341,
          4319,
          307,
          337,
          633,
          2167,
          1230,
          300,
          311,
          257,
          3364,
          51204
        ]
      },
      {
        "avg_logprob": -0.17437895658974337,
        "compression_ratio": 1.6651785714285714,
        "end": 4258.88,
        "id": 1022,
        "no_speech_prob": 0.0008295843144878745,
        "seek": 423912,
        "start": 4255.92,
        "temperature": 0,
        "text": " in these matrices, for every single number that's in the bias,",
        "tokens": [
          51204,
          294,
          613,
          32284,
          11,
          337,
          633,
          2167,
          1230,
          300,
          311,
          294,
          264,
          12577,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.17437895658974337,
        "compression_ratio": 1.6651785714285714,
        "end": 4263.5199999999995,
        "id": 1023,
        "no_speech_prob": 0.0008295843144878745,
        "seek": 423912,
        "start": 4258.88,
        "temperature": 0,
        "text": " there is a, say, 1% chance, 0.5% chance, 10% chance,",
        "tokens": [
          51352,
          456,
          307,
          257,
          11,
          584,
          11,
          502,
          4,
          2931,
          11,
          1958,
          13,
          20,
          4,
          2931,
          11,
          1266,
          4,
          2931,
          11,
          51584
        ]
      },
      {
        "avg_logprob": -0.17437895658974337,
        "compression_ratio": 1.6651785714285714,
        "end": 4265.12,
        "id": 1024,
        "no_speech_prob": 0.0008295843144878745,
        "seek": 423912,
        "start": 4263.5199999999995,
        "temperature": 0,
        "text": " then I'll pick a new random number.",
        "tokens": [
          51584,
          550,
          286,
          603,
          1888,
          257,
          777,
          4974,
          1230,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17437895658974337,
        "compression_ratio": 1.6651785714285714,
        "end": 4267.76,
        "id": 1025,
        "no_speech_prob": 0.0008295843144878745,
        "seek": 423912,
        "start": 4265.12,
        "temperature": 0,
        "text": " I could also, with mutation, like nudge the values.",
        "tokens": [
          51664,
          286,
          727,
          611,
          11,
          365,
          27960,
          11,
          411,
          297,
          16032,
          264,
          4190,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4269.76,
        "id": 1026,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4267.76,
        "temperature": 0,
        "text": " So instead of picking an entirely random number,",
        "tokens": [
          50364,
          407,
          2602,
          295,
          8867,
          364,
          7696,
          4974,
          1230,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4271.76,
        "id": 1027,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4269.76,
        "temperature": 0,
        "text": " I could push it a little higher, push it a little lower.",
        "tokens": [
          50464,
          286,
          727,
          2944,
          309,
          257,
          707,
          2946,
          11,
          2944,
          309,
          257,
          707,
          3126,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4275.2,
        "id": 1028,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4271.76,
        "temperature": 0,
        "text": " But for simplicity right now, let's just pick a new random number.",
        "tokens": [
          50564,
          583,
          337,
          25632,
          558,
          586,
          11,
          718,
          311,
          445,
          1888,
          257,
          777,
          4974,
          1230,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4277.280000000001,
        "id": 1029,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4275.2,
        "temperature": 0,
        "text": " So what do I need to do?",
        "tokens": [
          50736,
          407,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          50840
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4281.360000000001,
        "id": 1030,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4277.280000000001,
        "temperature": 0,
        "text": " I need to go back to neuralnetwork.js,",
        "tokens": [
          50840,
          286,
          643,
          281,
          352,
          646,
          281,
          18161,
          7129,
          1902,
          13,
          25530,
          11,
          51044
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4283.280000000001,
        "id": 1031,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4281.360000000001,
        "temperature": 0,
        "text": " and I'm going to add a function called mutate.",
        "tokens": [
          51044,
          293,
          286,
          478,
          516,
          281,
          909,
          257,
          2445,
          1219,
          5839,
          473,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4286.24,
        "id": 1032,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4284.72,
        "temperature": 0,
        "text": " And what am I going to do here?",
        "tokens": [
          51212,
          400,
          437,
          669,
          286,
          516,
          281,
          360,
          510,
          30,
          51288
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4291.2,
        "id": 1033,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4286.24,
        "temperature": 0,
        "text": " I'm going to say there are four things that I need to mutate.",
        "tokens": [
          51288,
          286,
          478,
          516,
          281,
          584,
          456,
          366,
          1451,
          721,
          300,
          286,
          643,
          281,
          5839,
          473,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4294.24,
        "id": 1034,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4291.2,
        "temperature": 0,
        "text": " So I'm going to say, let's think about this.",
        "tokens": [
          51536,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          718,
          311,
          519,
          466,
          341,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.1544031853223369,
        "compression_ratio": 1.795275590551181,
        "end": 4296.72,
        "id": 1035,
        "no_speech_prob": 0.00009915260307025164,
        "seek": 426776,
        "start": 4294.24,
        "temperature": 0,
        "text": " What are all those things called?",
        "tokens": [
          51688,
          708,
          366,
          439,
          729,
          721,
          1219,
          30,
          51812
        ]
      },
      {
        "avg_logprob": -0.25013332191957244,
        "compression_ratio": 1.646153846153846,
        "end": 4298.8,
        "id": 1036,
        "no_speech_prob": 0.000022474059733212925,
        "seek": 429672,
        "start": 4296.72,
        "temperature": 0,
        "text": " There's, I just got to go back up to here.",
        "tokens": [
          50364,
          821,
          311,
          11,
          286,
          445,
          658,
          281,
          352,
          646,
          493,
          281,
          510,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.25013332191957244,
        "compression_ratio": 1.646153846153846,
        "end": 4302.400000000001,
        "id": 1037,
        "no_speech_prob": 0.000022474059733212925,
        "seek": 429672,
        "start": 4298.8,
        "temperature": 0,
        "text": " There's weights i, h, weights h, o, bias h, bias o.",
        "tokens": [
          50468,
          821,
          311,
          17443,
          741,
          11,
          276,
          11,
          17443,
          276,
          11,
          277,
          11,
          12577,
          276,
          11,
          12577,
          277,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.25013332191957244,
        "compression_ratio": 1.646153846153846,
        "end": 4306.08,
        "id": 1038,
        "no_speech_prob": 0.000022474059733212925,
        "seek": 429672,
        "start": 4303.04,
        "temperature": 0,
        "text": " So I need to say, what I need to do is say,",
        "tokens": [
          50680,
          407,
          286,
          643,
          281,
          584,
          11,
          437,
          286,
          643,
          281,
          360,
          307,
          584,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.25013332191957244,
        "compression_ratio": 1.646153846153846,
        "end": 4310,
        "id": 1039,
        "no_speech_prob": 0.000022474059733212925,
        "seek": 429672,
        "start": 4306.72,
        "temperature": 0,
        "text": " weights, I'm going to map a mutation function.",
        "tokens": [
          50864,
          17443,
          11,
          286,
          478,
          516,
          281,
          4471,
          257,
          27960,
          2445,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.25013332191957244,
        "compression_ratio": 1.646153846153846,
        "end": 4315.52,
        "id": 1040,
        "no_speech_prob": 0.000022474059733212925,
        "seek": 429672,
        "start": 4311.84,
        "temperature": 0,
        "text": " So remember there's the, the, the,",
        "tokens": [
          51120,
          407,
          1604,
          456,
          311,
          264,
          11,
          264,
          11,
          264,
          11,
          51304
        ]
      },
      {
        "avg_logprob": -0.25013332191957244,
        "compression_ratio": 1.646153846153846,
        "end": 4321.12,
        "id": 1041,
        "no_speech_prob": 0.000022474059733212925,
        "seek": 429672,
        "start": 4317.6,
        "temperature": 0,
        "text": " sorry, I'm all of a sudden not able to type and talk at the same time.",
        "tokens": [
          51408,
          2597,
          11,
          286,
          478,
          439,
          295,
          257,
          3990,
          406,
          1075,
          281,
          2010,
          293,
          751,
          412,
          264,
          912,
          565,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.25013332191957244,
        "compression_ratio": 1.646153846153846,
        "end": 4324.08,
        "id": 1042,
        "no_speech_prob": 0.000022474059733212925,
        "seek": 429672,
        "start": 4321.12,
        "temperature": 0,
        "text": " So if you recall, the matrix,",
        "tokens": [
          51584,
          407,
          498,
          291,
          9901,
          11,
          264,
          8141,
          11,
          51732
        ]
      },
      {
        "avg_logprob": -0.18461066601323148,
        "compression_ratio": 1.8803827751196172,
        "end": 4328.08,
        "id": 1043,
        "no_speech_prob": 0.0004802947223652154,
        "seek": 432408,
        "start": 4324.8,
        "temperature": 0,
        "text": " the matrix library has a function called map.",
        "tokens": [
          50400,
          264,
          8141,
          6405,
          575,
          257,
          2445,
          1219,
          4471,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18461066601323148,
        "compression_ratio": 1.8803827751196172,
        "end": 4331.04,
        "id": 1044,
        "no_speech_prob": 0.0004802947223652154,
        "seek": 432408,
        "start": 4328.64,
        "temperature": 0,
        "text": " And what it allows you to do,",
        "tokens": [
          50592,
          400,
          437,
          309,
          4045,
          291,
          281,
          360,
          11,
          50712
        ]
      },
      {
        "avg_logprob": -0.18461066601323148,
        "compression_ratio": 1.8803827751196172,
        "end": 4337.68,
        "id": 1045,
        "no_speech_prob": 0.0004802947223652154,
        "seek": 432408,
        "start": 4333.36,
        "temperature": 0,
        "text": " it's a little unfortunate that there's also a JavaScript native function called map,",
        "tokens": [
          50828,
          309,
          311,
          257,
          707,
          17843,
          300,
          456,
          311,
          611,
          257,
          15778,
          8470,
          2445,
          1219,
          4471,
          11,
          51044
        ]
      },
      {
        "avg_logprob": -0.18461066601323148,
        "compression_ratio": 1.8803827751196172,
        "end": 4338.88,
        "id": 1046,
        "no_speech_prob": 0.0004802947223652154,
        "seek": 432408,
        "start": 4337.68,
        "temperature": 0,
        "text": " which I'm using everywhere.",
        "tokens": [
          51044,
          597,
          286,
          478,
          1228,
          5315,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.18461066601323148,
        "compression_ratio": 1.8803827751196172,
        "end": 4344.72,
        "id": 1047,
        "no_speech_prob": 0.0004802947223652154,
        "seek": 432408,
        "start": 4338.88,
        "temperature": 0,
        "text": " It allows you to apply a function to every single element of the array.",
        "tokens": [
          51104,
          467,
          4045,
          291,
          281,
          3079,
          257,
          2445,
          281,
          633,
          2167,
          4478,
          295,
          264,
          10225,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.18461066601323148,
        "compression_ratio": 1.8803827751196172,
        "end": 4348.96,
        "id": 1048,
        "no_speech_prob": 0.0004802947223652154,
        "seek": 432408,
        "start": 4345.36,
        "temperature": 0,
        "text": " So I can pass in a function and apply it to every single element of the array.",
        "tokens": [
          51428,
          407,
          286,
          393,
          1320,
          294,
          257,
          2445,
          293,
          3079,
          309,
          281,
          633,
          2167,
          4478,
          295,
          264,
          10225,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.18461066601323148,
        "compression_ratio": 1.8803827751196172,
        "end": 4353.76,
        "id": 1049,
        "no_speech_prob": 0.0004802947223652154,
        "seek": 432408,
        "start": 4348.96,
        "temperature": 0,
        "text": " And the function that I'm going to pass in is mutate.",
        "tokens": [
          51608,
          400,
          264,
          2445,
          300,
          286,
          478,
          516,
          281,
          1320,
          294,
          307,
          5839,
          473,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.16733474731445314,
        "compression_ratio": 1.71900826446281,
        "end": 4355.6,
        "id": 1050,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 435376,
        "start": 4353.76,
        "temperature": 0,
        "text": " So let's write this function now.",
        "tokens": [
          50364,
          407,
          718,
          311,
          2464,
          341,
          2445,
          586,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.16733474731445314,
        "compression_ratio": 1.71900826446281,
        "end": 4361.92,
        "id": 1051,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 435376,
        "start": 4358.24,
        "temperature": 0,
        "text": " And it's going to get, it receives a value, but to be honest,",
        "tokens": [
          50588,
          400,
          309,
          311,
          516,
          281,
          483,
          11,
          309,
          20717,
          257,
          2158,
          11,
          457,
          281,
          312,
          3245,
          11,
          50772
        ]
      },
      {
        "avg_logprob": -0.16733474731445314,
        "compression_ratio": 1.71900826446281,
        "end": 4365.84,
        "id": 1052,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 435376,
        "start": 4362.64,
        "temperature": 0,
        "text": " I don't care about, I do care about what the value is,",
        "tokens": [
          50808,
          286,
          500,
          380,
          1127,
          466,
          11,
          286,
          360,
          1127,
          466,
          437,
          264,
          2158,
          307,
          11,
          50968
        ]
      },
      {
        "avg_logprob": -0.16733474731445314,
        "compression_ratio": 1.71900826446281,
        "end": 4368.72,
        "id": 1053,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 435376,
        "start": 4365.84,
        "temperature": 0,
        "text": " if I were planning to nudge it higher and nudge it lower.",
        "tokens": [
          50968,
          498,
          286,
          645,
          5038,
          281,
          297,
          16032,
          309,
          2946,
          293,
          297,
          16032,
          309,
          3126,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.16733474731445314,
        "compression_ratio": 1.71900826446281,
        "end": 4373.4400000000005,
        "id": 1054,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 435376,
        "start": 4368.72,
        "temperature": 0,
        "text": " But what I'm going to do right now is I'm just going to return a random number.",
        "tokens": [
          51112,
          583,
          437,
          286,
          478,
          516,
          281,
          360,
          558,
          586,
          307,
          286,
          478,
          445,
          516,
          281,
          2736,
          257,
          4974,
          1230,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.16733474731445314,
        "compression_ratio": 1.71900826446281,
        "end": 4378.4800000000005,
        "id": 1055,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 435376,
        "start": 4374.400000000001,
        "temperature": 0,
        "text": " So let me actually, I sort of, I should probably link these better in some way.",
        "tokens": [
          51396,
          407,
          718,
          385,
          767,
          11,
          286,
          1333,
          295,
          11,
          286,
          820,
          1391,
          2113,
          613,
          1101,
          294,
          512,
          636,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.16733474731445314,
        "compression_ratio": 1.71900826446281,
        "end": 4380.64,
        "id": 1056,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 435376,
        "start": 4378.4800000000005,
        "temperature": 0,
        "text": " But when I have this function called randomize,",
        "tokens": [
          51600,
          583,
          562,
          286,
          362,
          341,
          2445,
          1219,
          4974,
          1125,
          11,
          51708
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4384.64,
        "id": 1057,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4381.280000000001,
        "temperature": 0,
        "text": " and this is the kind of random number that I'm asking for.",
        "tokens": [
          50396,
          293,
          341,
          307,
          264,
          733,
          295,
          4974,
          1230,
          300,
          286,
          478,
          3365,
          337,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4388.56,
        "id": 1058,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4385.360000000001,
        "temperature": 0,
        "text": " So I am going to just return this.",
        "tokens": [
          50600,
          407,
          286,
          669,
          516,
          281,
          445,
          2736,
          341,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4391.52,
        "id": 1059,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4388.56,
        "temperature": 0,
        "text": " Ah, but am I always going to, oh, I do need the val.",
        "tokens": [
          50760,
          2438,
          11,
          457,
          669,
          286,
          1009,
          516,
          281,
          11,
          1954,
          11,
          286,
          360,
          643,
          264,
          220,
          3337,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4392.160000000001,
        "id": 1060,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4391.52,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          50908,
          17795,
          437,
          30,
          50940
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4396.08,
        "id": 1061,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4392.160000000001,
        "temperature": 0,
        "text": " If I do this, it'll completely randomize every single element.",
        "tokens": [
          50940,
          759,
          286,
          360,
          341,
          11,
          309,
          603,
          2584,
          4974,
          1125,
          633,
          2167,
          4478,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4399.360000000001,
        "id": 1062,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4396.08,
        "temperature": 0,
        "text": " So this mutation function needs a mutation rate.",
        "tokens": [
          51136,
          407,
          341,
          27960,
          2445,
          2203,
          257,
          27960,
          3314,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4402.56,
        "id": 1063,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4400.160000000001,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going to pick a random number.",
        "tokens": [
          51340,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          1888,
          257,
          4974,
          1230,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.2908103219394026,
        "compression_ratio": 1.7048458149779735,
        "end": 4408.64,
        "id": 1064,
        "no_speech_prob": 0.000022474070647149347,
        "seek": 438064,
        "start": 4404,
        "temperature": 0,
        "text": " If math.random is greater than or less than the rate,",
        "tokens": [
          51532,
          759,
          5221,
          13,
          3699,
          298,
          307,
          5044,
          813,
          420,
          1570,
          813,
          264,
          3314,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4412.64,
        "id": 1065,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4408.64,
        "temperature": 0,
        "text": " so let's say math.random will give me a number between zero and one.",
        "tokens": [
          50364,
          370,
          718,
          311,
          584,
          5221,
          13,
          3699,
          298,
          486,
          976,
          385,
          257,
          1230,
          1296,
          4018,
          293,
          472,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4415.360000000001,
        "id": 1066,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4413.360000000001,
        "temperature": 0,
        "text": " So if the mutation rate is 0.1,",
        "tokens": [
          50600,
          407,
          498,
          264,
          27960,
          3314,
          307,
          1958,
          13,
          16,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4419.04,
        "id": 1067,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4415.360000000001,
        "temperature": 0,
        "text": " that random number between zero and one will be less than 0.1 10% of the time.",
        "tokens": [
          50700,
          300,
          4974,
          1230,
          1296,
          4018,
          293,
          472,
          486,
          312,
          1570,
          813,
          1958,
          13,
          16,
          1266,
          4,
          295,
          264,
          565,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4423.76,
        "id": 1068,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4419.84,
        "temperature": 0,
        "text": " Otherwise, stick with the same value.",
        "tokens": [
          50924,
          10328,
          11,
          2897,
          365,
          264,
          912,
          2158,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4426.64,
        "id": 1069,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4423.76,
        "temperature": 0,
        "text": " So this is now the function that I want to apply",
        "tokens": [
          51120,
          407,
          341,
          307,
          586,
          264,
          2445,
          300,
          286,
          528,
          281,
          3079,
          51264
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4430.64,
        "id": 1070,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4426.64,
        "temperature": 0,
        "text": " to every element of all of the weight matrices.",
        "tokens": [
          51264,
          281,
          633,
          4478,
          295,
          439,
          295,
          264,
          3364,
          32284,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4434.56,
        "id": 1071,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4430.64,
        "temperature": 0,
        "text": " I want to say, hey, mutate these weights, mutate these weights,",
        "tokens": [
          51464,
          286,
          528,
          281,
          584,
          11,
          4177,
          11,
          5839,
          473,
          613,
          17443,
          11,
          5839,
          473,
          613,
          17443,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.2656286583572138,
        "compression_ratio": 1.883408071748879,
        "end": 4436.4800000000005,
        "id": 1072,
        "no_speech_prob": 0.00021995285351295024,
        "seek": 440864,
        "start": 4434.56,
        "temperature": 0,
        "text": " mutate these biases, mutate these biases.",
        "tokens": [
          51660,
          5839,
          473,
          613,
          32152,
          11,
          5839,
          473,
          613,
          32152,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4438.4,
        "id": 1073,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4436.48,
        "temperature": 0,
        "text": " And perhaps there's a more elegant way to write this,",
        "tokens": [
          50364,
          400,
          4317,
          456,
          311,
          257,
          544,
          21117,
          636,
          281,
          2464,
          341,
          11,
          50460
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4440.24,
        "id": 1074,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4438.4,
        "temperature": 0,
        "text": " and I will consider that all in the future",
        "tokens": [
          50460,
          293,
          286,
          486,
          1949,
          300,
          439,
          294,
          264,
          2027,
          50552
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4442.959999999999,
        "id": 1075,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4440.24,
        "temperature": 0,
        "text": " with your many comments and pull requests and complaints.",
        "tokens": [
          50552,
          365,
          428,
          867,
          3053,
          293,
          2235,
          12475,
          293,
          19585,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4444.24,
        "id": 1076,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4442.959999999999,
        "temperature": 0,
        "text": " I look forward to them,",
        "tokens": [
          50688,
          286,
          574,
          2128,
          281,
          552,
          11,
          50752
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4445.919999999999,
        "id": 1077,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4444.24,
        "temperature": 0,
        "text": " but this is what I'm going to leave it at right now.",
        "tokens": [
          50752,
          457,
          341,
          307,
          437,
          286,
          478,
          516,
          281,
          1856,
          309,
          412,
          558,
          586,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4449.28,
        "id": 1078,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4445.919999999999,
        "temperature": 0,
        "text": " So let's see now if what I can do,",
        "tokens": [
          50836,
          407,
          718,
          311,
          536,
          586,
          498,
          437,
          286,
          393,
          360,
          11,
          51004
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4453.44,
        "id": 1079,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4449.28,
        "temperature": 0,
        "text": " if I go back to this particular program and I say child.",
        "tokens": [
          51004,
          498,
          286,
          352,
          646,
          281,
          341,
          1729,
          1461,
          293,
          286,
          584,
          1440,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4457.759999999999,
        "id": 1080,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4453.44,
        "temperature": 0,
        "text": " Now, just out of curiosity, I'm going to say child.mutate one.",
        "tokens": [
          51212,
          823,
          11,
          445,
          484,
          295,
          18769,
          11,
          286,
          478,
          516,
          281,
          584,
          1440,
          13,
          38326,
          473,
          472,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4459.839999999999,
        "id": 1081,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4457.759999999999,
        "temperature": 0,
        "text": " So I'm giving it a mutation rate of one,",
        "tokens": [
          51428,
          407,
          286,
          478,
          2902,
          309,
          257,
          27960,
          3314,
          295,
          472,
          11,
          51532
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4461.839999999999,
        "id": 1082,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4459.839999999999,
        "temperature": 0,
        "text": " which means everything should be completely random.",
        "tokens": [
          51532,
          597,
          1355,
          1203,
          820,
          312,
          2584,
          4974,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.27868939717610675,
        "compression_ratio": 1.744186046511628,
        "end": 4464.5599999999995,
        "id": 1083,
        "no_speech_prob": 0.04467751085758209,
        "seek": 443648,
        "start": 4463.04,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going to say,",
        "tokens": [
          51692,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          11,
          51768
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4466.88,
        "id": 1084,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4464.8,
        "temperature": 0.4,
        "text": " I'm going to say, I'm going to give it a mutation rate",
        "tokens": [
          50376,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          478,
          516,
          281,
          976,
          309,
          257,
          27960,
          3314,
          50480
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4470.240000000001,
        "id": 1085,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4466.88,
        "temperature": 0.4,
        "text": " of one, which means everything should be completely random.",
        "tokens": [
          50480,
          295,
          472,
          11,
          597,
          1355,
          1203,
          820,
          312,
          2584,
          4974,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4473.76,
        "id": 1086,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4470.240000000001,
        "temperature": 0.4,
        "text": " And what I'm going to do just as a way of testing,",
        "tokens": [
          50648,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          445,
          382,
          257,
          636,
          295,
          4997,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4476.160000000001,
        "id": 1087,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4473.76,
        "temperature": 0.4,
        "text": " actually, is I'm going to change this to,",
        "tokens": [
          50824,
          767,
          11,
          307,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          11,
          50944
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4478.8,
        "id": 1088,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4476.160000000001,
        "temperature": 0.4,
        "text": " I'm going to multiply it by 1,000,",
        "tokens": [
          50944,
          286,
          478,
          516,
          281,
          12972,
          309,
          538,
          502,
          11,
          1360,
          11,
          51076
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4481.76,
        "id": 1089,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4478.8,
        "temperature": 0.4,
        "text": " just because I want to see totally different numbers",
        "tokens": [
          51076,
          445,
          570,
          286,
          528,
          281,
          536,
          3879,
          819,
          3547,
          51224
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4483.360000000001,
        "id": 1090,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4481.76,
        "temperature": 0.4,
        "text": " to see that this is working.",
        "tokens": [
          51224,
          281,
          536,
          300,
          341,
          307,
          1364,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4486.320000000001,
        "id": 1091,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4483.360000000001,
        "temperature": 0.4,
        "text": " So I'm going to go back, and I'm going to refresh the code.",
        "tokens": [
          51304,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          11,
          293,
          286,
          478,
          516,
          281,
          15134,
          264,
          3089,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4488.320000000001,
        "id": 1092,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4486.320000000001,
        "temperature": 0.4,
        "text": " Weights i.h is not defined.",
        "tokens": [
          51452,
          492,
          5761,
          741,
          13,
          71,
          307,
          406,
          7642,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4490.160000000001,
        "id": 1093,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4488.320000000001,
        "temperature": 0.4,
        "text": " Oh, right, I forgot about the this.",
        "tokens": [
          51552,
          876,
          11,
          558,
          11,
          286,
          5298,
          466,
          264,
          341,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.4926734819804152,
        "compression_ratio": 1.7204301075268817,
        "end": 4492.160000000001,
        "id": 1094,
        "no_speech_prob": 0.0003982098132837564,
        "seek": 446456,
        "start": 4490.160000000001,
        "temperature": 0.4,
        "text": " That won't surprise any of you.",
        "tokens": [
          51644,
          663,
          1582,
          380,
          6365,
          604,
          295,
          291,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4492.96,
        "id": 1095,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4492.16,
        "temperature": 0,
        "text": " So let's take a look.",
        "tokens": [
          50364,
          407,
          718,
          311,
          747,
          257,
          574,
          13,
          50404
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4495.84,
        "id": 1096,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4492.96,
        "temperature": 0,
        "text": " So here we have, once again, the biases.",
        "tokens": [
          50404,
          407,
          510,
          321,
          362,
          11,
          1564,
          797,
          11,
          264,
          32152,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4499.04,
        "id": 1097,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4495.84,
        "temperature": 0,
        "text": " They're all reasonable numbers between negative one and one,",
        "tokens": [
          50548,
          814,
          434,
          439,
          10585,
          3547,
          1296,
          3671,
          472,
          293,
          472,
          11,
          50708
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4501.12,
        "id": 1098,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4499.04,
        "temperature": 0,
        "text": " which is how I started the neural network.",
        "tokens": [
          50708,
          597,
          307,
          577,
          286,
          1409,
          264,
          18161,
          3209,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4506.639999999999,
        "id": 1099,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4501.68,
        "temperature": 0,
        "text": " And now, if I look at the child neural network,",
        "tokens": [
          50840,
          400,
          586,
          11,
          498,
          286,
          574,
          412,
          264,
          1440,
          18161,
          3209,
          11,
          51088
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4509.84,
        "id": 1100,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4506.639999999999,
        "temperature": 0,
        "text": " and I look at the biases, we can see, yep, so that mutated.",
        "tokens": [
          51088,
          293,
          286,
          574,
          412,
          264,
          32152,
          11,
          321,
          393,
          536,
          11,
          18633,
          11,
          370,
          300,
          5839,
          770,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4511.92,
        "id": 1101,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4509.84,
        "temperature": 0,
        "text": " Now, let's change the mutation rate.",
        "tokens": [
          51248,
          823,
          11,
          718,
          311,
          1319,
          264,
          27960,
          3314,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4514.08,
        "id": 1102,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4511.92,
        "temperature": 0,
        "text": " Let's change it to 0.5.",
        "tokens": [
          51352,
          961,
          311,
          1319,
          309,
          281,
          1958,
          13,
          20,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4517.04,
        "id": 1103,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4514.08,
        "temperature": 0,
        "text": " So we have kind of, I mean, we're not going to get exactly 50%",
        "tokens": [
          51460,
          407,
          321,
          362,
          733,
          295,
          11,
          286,
          914,
          11,
          321,
          434,
          406,
          516,
          281,
          483,
          2293,
          2625,
          4,
          51608
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4518.5599999999995,
        "id": 1104,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4517.04,
        "temperature": 0,
        "text": " of them, because it's supposed to be random.",
        "tokens": [
          51608,
          295,
          552,
          11,
          570,
          309,
          311,
          3442,
          281,
          312,
          4974,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4520.24,
        "id": 1105,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4518.5599999999995,
        "temperature": 0,
        "text": " But we'll at least see some of them didn't mutate",
        "tokens": [
          51684,
          583,
          321,
          603,
          412,
          1935,
          536,
          512,
          295,
          552,
          994,
          380,
          5839,
          473,
          51768
        ]
      },
      {
        "avg_logprob": -0.15070993900299073,
        "compression_ratio": 1.734006734006734,
        "end": 4521.28,
        "id": 1106,
        "no_speech_prob": 0.00023782142670825124,
        "seek": 449216,
        "start": 4520.24,
        "temperature": 0,
        "text": " and some of them did.",
        "tokens": [
          51768,
          293,
          512,
          295,
          552,
          630,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4525.679999999999,
        "id": 1107,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4521.28,
        "temperature": 0,
        "text": " So let's change now the mutation rate to 0.5,",
        "tokens": [
          50364,
          407,
          718,
          311,
          1319,
          586,
          264,
          27960,
          3314,
          281,
          1958,
          13,
          20,
          11,
          50584
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4527.04,
        "id": 1108,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4525.679999999999,
        "temperature": 0,
        "text": " just to see that this is working.",
        "tokens": [
          50584,
          445,
          281,
          536,
          300,
          341,
          307,
          1364,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4528.96,
        "id": 1109,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4527.04,
        "temperature": 0,
        "text": " This is instead of me writing unit tests,",
        "tokens": [
          50652,
          639,
          307,
          2602,
          295,
          385,
          3579,
          4985,
          6921,
          11,
          50748
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4531.04,
        "id": 1110,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4529.92,
        "temperature": 0,
        "text": " manual unit testing.",
        "tokens": [
          50796,
          9688,
          4985,
          4997,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4532.719999999999,
        "id": 1111,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4531.759999999999,
        "temperature": 0,
        "text": " Let's look here.",
        "tokens": [
          50888,
          961,
          311,
          574,
          510,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4536,
        "id": 1112,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4532.719999999999,
        "temperature": 0,
        "text": " We can see, wonderful, here's some original values.",
        "tokens": [
          50936,
          492,
          393,
          536,
          11,
          3715,
          11,
          510,
          311,
          512,
          3380,
          4190,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4540.4,
        "id": 1113,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4536.5599999999995,
        "temperature": 0,
        "text": " And now, let's go down to here in the child object.",
        "tokens": [
          51128,
          400,
          586,
          11,
          718,
          311,
          352,
          760,
          281,
          510,
          294,
          264,
          1440,
          2657,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4543.679999999999,
        "id": 1114,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4541.44,
        "temperature": 0,
        "text": " And let's look at the biases again.",
        "tokens": [
          51372,
          400,
          718,
          311,
          574,
          412,
          264,
          32152,
          797,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4547.84,
        "id": 1115,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4543.679999999999,
        "temperature": 0,
        "text": " And we can see, hey, it actually worked out exactly as planned.",
        "tokens": [
          51484,
          400,
          321,
          393,
          536,
          11,
          4177,
          11,
          309,
          767,
          2732,
          484,
          2293,
          382,
          8589,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.1688639171539791,
        "compression_ratio": 1.6613545816733069,
        "end": 4550.5599999999995,
        "id": 1116,
        "no_speech_prob": 0.000025867360818665475,
        "seek": 452128,
        "start": 4547.84,
        "temperature": 0,
        "text": " It mutated two of them and didn't mutate two of them,",
        "tokens": [
          51692,
          467,
          5839,
          770,
          732,
          295,
          552,
          293,
          994,
          380,
          5839,
          473,
          732,
          295,
          552,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4554.320000000001,
        "id": 1117,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4550.56,
        "temperature": 0,
        "text": " which is what most commonly with a 50% probability",
        "tokens": [
          50364,
          597,
          307,
          437,
          881,
          12719,
          365,
          257,
          2625,
          4,
          8482,
          50552
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4555.120000000001,
        "id": 1118,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4554.320000000001,
        "temperature": 0,
        "text": " we're going to see.",
        "tokens": [
          50552,
          321,
          434,
          516,
          281,
          536,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4558.160000000001,
        "id": 1119,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4555.120000000001,
        "temperature": 0,
        "text": " And I suspect that if I go into the output bias,",
        "tokens": [
          50592,
          400,
          286,
          9091,
          300,
          498,
          286,
          352,
          666,
          264,
          5598,
          12577,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4561.04,
        "id": 1120,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4559.360000000001,
        "temperature": 0,
        "text": " oh, the output bias just has one value.",
        "tokens": [
          50804,
          1954,
          11,
          264,
          5598,
          12577,
          445,
          575,
          472,
          2158,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4562.400000000001,
        "id": 1121,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4561.04,
        "temperature": 0,
        "text": " It didn't get mutated, right?",
        "tokens": [
          50888,
          467,
          994,
          380,
          483,
          5839,
          770,
          11,
          558,
          30,
          50956
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4564,
        "id": 1122,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4562.400000000001,
        "temperature": 0,
        "text": " Because this is such a simple little neural network.",
        "tokens": [
          50956,
          1436,
          341,
          307,
          1270,
          257,
          2199,
          707,
          18161,
          3209,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4567.76,
        "id": 1123,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4564,
        "temperature": 0,
        "text": " If we go into these weights, we can see three out of four",
        "tokens": [
          51036,
          759,
          321,
          352,
          666,
          613,
          17443,
          11,
          321,
          393,
          536,
          1045,
          484,
          295,
          1451,
          51224
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4568.56,
        "id": 1124,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4567.76,
        "temperature": 0,
        "text": " got mutated.",
        "tokens": [
          51224,
          658,
          5839,
          770,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4569.360000000001,
        "id": 1125,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4568.56,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51264,
          286,
          519,
          309,
          311,
          1364,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4572.320000000001,
        "id": 1126,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4569.360000000001,
        "temperature": 0,
        "text": " So we are in good shape here.",
        "tokens": [
          51304,
          407,
          321,
          366,
          294,
          665,
          3909,
          510,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4576.320000000001,
        "id": 1127,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4573.280000000001,
        "temperature": 0,
        "text": " We now, and so I want to, probably the actual mutation rate",
        "tokens": [
          51500,
          492,
          586,
          11,
          293,
          370,
          286,
          528,
          281,
          11,
          1391,
          264,
          3539,
          27960,
          3314,
          51652
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4578.160000000001,
        "id": 1128,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4576.320000000001,
        "temperature": 0,
        "text": " I'm going to want to use is only like 1%,",
        "tokens": [
          51652,
          286,
          478,
          516,
          281,
          528,
          281,
          764,
          307,
          787,
          411,
          502,
          8923,
          51744
        ]
      },
      {
        "avg_logprob": -0.19707284475627698,
        "compression_ratio": 1.65359477124183,
        "end": 4579.68,
        "id": 1129,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 455056,
        "start": 4578.160000000001,
        "temperature": 0,
        "text": " because I want to do it pretty rarely.",
        "tokens": [
          51744,
          570,
          286,
          528,
          281,
          360,
          309,
          1238,
          13752,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4584.96,
        "id": 1130,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4579.68,
        "temperature": 0,
        "text": " But we now have the ability to both copy a neural network,",
        "tokens": [
          50364,
          583,
          321,
          586,
          362,
          264,
          3485,
          281,
          1293,
          5055,
          257,
          18161,
          3209,
          11,
          50628
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4587.280000000001,
        "id": 1131,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4584.96,
        "temperature": 0,
        "text": " again, as an exercise, if you're watching this",
        "tokens": [
          50628,
          797,
          11,
          382,
          364,
          5380,
          11,
          498,
          291,
          434,
          1976,
          341,
          50744
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4589.84,
        "id": 1132,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4587.280000000001,
        "temperature": 0,
        "text": " and the future videos of this tutorial aren't released yet,",
        "tokens": [
          50744,
          293,
          264,
          2027,
          2145,
          295,
          341,
          7073,
          3212,
          380,
          4736,
          1939,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4591.68,
        "id": 1133,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4589.84,
        "temperature": 0,
        "text": " or if you don't feel like watching them just yet,",
        "tokens": [
          50872,
          420,
          498,
          291,
          500,
          380,
          841,
          411,
          1976,
          552,
          445,
          1939,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4594.88,
        "id": 1134,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4591.68,
        "temperature": 0,
        "text": " try as an exercise for yourself, go and implement crossover.",
        "tokens": [
          50964,
          853,
          382,
          364,
          5380,
          337,
          1803,
          11,
          352,
          293,
          4445,
          33837,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4598.72,
        "id": 1135,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4594.88,
        "temperature": 0,
        "text": " How could instead of copy, could you create a new neural network",
        "tokens": [
          51124,
          1012,
          727,
          2602,
          295,
          5055,
          11,
          727,
          291,
          1884,
          257,
          777,
          18161,
          3209,
          51316
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4601.4400000000005,
        "id": 1136,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4598.72,
        "temperature": 0,
        "text": " that's a mixture of all of these weight matrices?",
        "tokens": [
          51316,
          300,
          311,
          257,
          9925,
          295,
          439,
          295,
          613,
          3364,
          32284,
          30,
          51452
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4602.96,
        "id": 1137,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4601.4400000000005,
        "temperature": 0,
        "text": " That would be a really interesting thing to try.",
        "tokens": [
          51452,
          663,
          576,
          312,
          257,
          534,
          1880,
          551,
          281,
          853,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4604.64,
        "id": 1138,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4602.96,
        "temperature": 0,
        "text": " I will do that, hopefully, in a future video.",
        "tokens": [
          51528,
          286,
          486,
          360,
          300,
          11,
          4696,
          11,
          294,
          257,
          2027,
          960,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4607.12,
        "id": 1139,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4605.360000000001,
        "temperature": 0,
        "text": " So I've got copy, I've got mutation,",
        "tokens": [
          51648,
          407,
          286,
          600,
          658,
          5055,
          11,
          286,
          600,
          658,
          27960,
          11,
          51736
        ]
      },
      {
        "avg_logprob": -0.1994601313273112,
        "compression_ratio": 1.7643312101910829,
        "end": 4608.96,
        "id": 1140,
        "no_speech_prob": 0.00003591289714677259,
        "seek": 457968,
        "start": 4607.12,
        "temperature": 0,
        "text": " I've got the floppy bird game,",
        "tokens": [
          51736,
          286,
          600,
          658,
          264,
          25343,
          8200,
          5255,
          1216,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4610.4800000000005,
        "id": 1141,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4608.96,
        "temperature": 0,
        "text": " I've got the neural network library,",
        "tokens": [
          50364,
          286,
          600,
          658,
          264,
          18161,
          3209,
          6405,
          11,
          50440
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4613.12,
        "id": 1142,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4610.4800000000005,
        "temperature": 0,
        "text": " I've added crossover mutation, so we're ready now.",
        "tokens": [
          50440,
          286,
          600,
          3869,
          33837,
          27960,
          11,
          370,
          321,
          434,
          1919,
          586,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4616.08,
        "id": 1143,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4613.12,
        "temperature": 0,
        "text": " We're actually ready to implement the genetic algorithm.",
        "tokens": [
          50572,
          492,
          434,
          767,
          1919,
          281,
          4445,
          264,
          12462,
          9284,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4617.04,
        "id": 1144,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4616.08,
        "temperature": 0,
        "text": " I'm going to say this twice.",
        "tokens": [
          50720,
          286,
          478,
          516,
          281,
          584,
          341,
          6091,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4621.36,
        "id": 1145,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4617.76,
        "temperature": 0,
        "text": " Someone in the chat pointed out that the NEAT algorithm,",
        "tokens": [
          50804,
          8734,
          294,
          264,
          5081,
          10932,
          484,
          300,
          264,
          12384,
          2218,
          9284,
          11,
          50984
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4623.44,
        "id": 1146,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4621.36,
        "temperature": 0,
        "text": " Neural Evolution Augmented Topology things,",
        "tokens": [
          50984,
          1734,
          1807,
          40800,
          6088,
          14684,
          8840,
          1793,
          721,
          11,
          51088
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4628.96,
        "id": 1147,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4624.24,
        "temperature": 0,
        "text": " refers to a very specific implementation of neural evolution",
        "tokens": [
          51128,
          14942,
          281,
          257,
          588,
          2685,
          11420,
          295,
          18161,
          9303,
          51364
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4630,
        "id": 1148,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4628.96,
        "temperature": 0,
        "text": " in a specific paper,",
        "tokens": [
          51364,
          294,
          257,
          2685,
          3035,
          11,
          51416
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4632.4,
        "id": 1149,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4630,
        "temperature": 0,
        "text": " and I'm obviously being much more informal about this here.",
        "tokens": [
          51416,
          293,
          286,
          478,
          2745,
          885,
          709,
          544,
          24342,
          466,
          341,
          510,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4634.88,
        "id": 1150,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4632.4,
        "temperature": 0,
        "text": " So technically, this probably isn't the NEAT algorithm.",
        "tokens": [
          51536,
          407,
          12120,
          11,
          341,
          1391,
          1943,
          380,
          264,
          12384,
          2218,
          9284,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4636.8,
        "id": 1151,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4634.88,
        "temperature": 0,
        "text": " And maybe I'll mention that at the beginning of the next video too,",
        "tokens": [
          51660,
          400,
          1310,
          286,
          603,
          2152,
          300,
          412,
          264,
          2863,
          295,
          264,
          958,
          960,
          886,
          11,
          51756
        ]
      },
      {
        "avg_logprob": -0.20318651852542408,
        "compression_ratio": 1.7207207207207207,
        "end": 4638.4800000000005,
        "id": 1152,
        "no_speech_prob": 0.0004512064915616065,
        "seek": 460896,
        "start": 4636.8,
        "temperature": 0,
        "text": " just to emphasize it a bit more.",
        "tokens": [
          51756,
          445,
          281,
          16078,
          309,
          257,
          857,
          544,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.233690549456884,
        "compression_ratio": 1.3175675675675675,
        "end": 4642.08,
        "id": 1153,
        "no_speech_prob": 0.000014285004908742849,
        "seek": 463848,
        "start": 4638.5599999999995,
        "temperature": 0,
        "text": " All right, thanks for watching, and I will see you when I continue.",
        "tokens": [
          50368,
          1057,
          558,
          11,
          3231,
          337,
          1976,
          11,
          293,
          286,
          486,
          536,
          291,
          562,
          286,
          2354,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.233690549456884,
        "compression_ratio": 1.3175675675675675,
        "end": 4651.04,
        "id": 1154,
        "no_speech_prob": 0.000014285004908742849,
        "seek": 463848,
        "start": 4649.44,
        "temperature": 0,
        "text": " All right, let me look at the time.",
        "tokens": [
          50912,
          1057,
          558,
          11,
          718,
          385,
          574,
          412,
          264,
          565,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.233690549456884,
        "compression_ratio": 1.3175675675675675,
        "end": 4653.44,
        "id": 1155,
        "no_speech_prob": 0.000014285004908742849,
        "seek": 463848,
        "start": 4652.5599999999995,
        "temperature": 0,
        "text": " Where are we time-wise?",
        "tokens": [
          51068,
          2305,
          366,
          321,
          565,
          12,
          3711,
          30,
          51112
        ]
      },
      {
        "avg_logprob": -0.233690549456884,
        "compression_ratio": 1.3175675675675675,
        "end": 4654.32,
        "id": 1156,
        "no_speech_prob": 0.000014285004908742849,
        "seek": 463848,
        "start": 4653.44,
        "temperature": 0,
        "text": " It's 4.40.",
        "tokens": [
          51112,
          467,
          311,
          1017,
          13,
          5254,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.233690549456884,
        "compression_ratio": 1.3175675675675675,
        "end": 4657.599999999999,
        "id": 1157,
        "no_speech_prob": 0.000014285004908742849,
        "seek": 463848,
        "start": 4654.32,
        "temperature": 0,
        "text": " I think I should stop because the next aspect of this...",
        "tokens": [
          51156,
          286,
          519,
          286,
          820,
          1590,
          570,
          264,
          958,
          4171,
          295,
          341,
          485,
          51320
        ]
      },
      {
        "avg_logprob": -0.5388045501708985,
        "compression_ratio": 1.2777777777777777,
        "end": 4664.4800000000005,
        "id": 1158,
        "no_speech_prob": 0.0021156577859073877,
        "seek": 465760,
        "start": 4657.68,
        "temperature": 0,
        "text": " I think I should stop because I don't have very much time left.",
        "tokens": [
          50368,
          286,
          519,
          286,
          820,
          1590,
          570,
          286,
          500,
          380,
          362,
          588,
          709,
          565,
          1411,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.5388045501708985,
        "compression_ratio": 1.2777777777777777,
        "end": 4672.64,
        "id": 1159,
        "no_speech_prob": 0.0021156577859073877,
        "seek": 465760,
        "start": 4665.92,
        "temperature": 0,
        "text": " And it's definitely going to take longer than 20 minutes",
        "tokens": [
          50780,
          400,
          309,
          311,
          2138,
          516,
          281,
          747,
          2854,
          813,
          945,
          2077,
          51116
        ]
      },
      {
        "avg_logprob": -0.5388045501708985,
        "compression_ratio": 1.2777777777777777,
        "end": 4675.200000000001,
        "id": 1160,
        "no_speech_prob": 0.0021156577859073877,
        "seek": 465760,
        "start": 4672.64,
        "temperature": 0,
        "text": " to finish Neural Evolution.",
        "tokens": [
          51116,
          281,
          2413,
          1734,
          1807,
          40800,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.5388045501708985,
        "compression_ratio": 1.2777777777777777,
        "end": 4677.280000000001,
        "id": 1161,
        "no_speech_prob": 0.0021156577859073877,
        "seek": 465760,
        "start": 4675.200000000001,
        "temperature": 0,
        "text": " Let me just check some things here.",
        "tokens": [
          51244,
          961,
          385,
          445,
          1520,
          512,
          721,
          510,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4680.4,
        "id": 1162,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4677.84,
        "temperature": 0.4,
        "text": " Let me just check some things here.",
        "tokens": [
          50392,
          961,
          385,
          445,
          1520,
          512,
          721,
          510,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4683.12,
        "id": 1163,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4680.4,
        "temperature": 0.4,
        "text": " I'm just looking to make sure I don't have any important messages",
        "tokens": [
          50520,
          286,
          478,
          445,
          1237,
          281,
          652,
          988,
          286,
          500,
          380,
          362,
          604,
          1021,
          7897,
          50656
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4687.04,
        "id": 1164,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4683.12,
        "temperature": 0.4,
        "text": " that I need to deal with right now, and I don't seem to.",
        "tokens": [
          50656,
          300,
          286,
          643,
          281,
          2028,
          365,
          558,
          586,
          11,
          293,
          286,
          500,
          380,
          1643,
          281,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4687.54,
        "id": 1165,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4687.04,
        "temperature": 0.4,
        "text": " Okay.",
        "tokens": [
          50852,
          1033,
          13,
          50877
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4689.84,
        "id": 1166,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4688.32,
        "temperature": 0.4,
        "text": " I do see that some people have suggested",
        "tokens": [
          50916,
          286,
          360,
          536,
          300,
          512,
          561,
          362,
          262,
          697,
          2629,
          292,
          50992
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4692.24,
        "id": 1167,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4689.84,
        "temperature": 0.4,
        "text": " Pi Day coding challenges, which I'm excited about.",
        "tokens": [
          50992,
          17741,
          5226,
          17720,
          4759,
          11,
          597,
          286,
          478,
          2919,
          466,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4695.2,
        "id": 1168,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4693.5199999999995,
        "temperature": 0.4,
        "text": " I'm going to say, I'm going to say,",
        "tokens": [
          51176,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4697.92,
        "id": 1169,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4695.2,
        "temperature": 0.4,
        "text": " Pi Day coding challenges is just a very simple thing.",
        "tokens": [
          51260,
          17741,
          5226,
          17720,
          4759,
          307,
          445,
          257,
          588,
          2199,
          551,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4699.84,
        "id": 1170,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4697.92,
        "temperature": 0.4,
        "text": " It's just a simple way to do a code.",
        "tokens": [
          51396,
          467,
          311,
          445,
          257,
          2199,
          636,
          220,
          1353,
          360,
          257,
          3089,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4701.28,
        "id": 1171,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4699.84,
        "temperature": 0.4,
        "text": " It's not a very complicated code,",
        "tokens": [
          51492,
          467,
          311,
          406,
          257,
          588,
          6179,
          3089,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4702.96,
        "id": 1172,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4701.28,
        "temperature": 0.4,
        "text": " but it's just a simple way to do a code.",
        "tokens": [
          51564,
          457,
          309,
          311,
          445,
          257,
          2199,
          636,
          281,
          360,
          257,
          3089,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4704.08,
        "id": 1173,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4702.96,
        "temperature": 0.4,
        "text": " So it's a very simple code,",
        "tokens": [
          51648,
          407,
          309,
          311,
          257,
          588,
          2199,
          3089,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.9409303211030506,
        "compression_ratio": 2.0036764705882355,
        "end": 4706.32,
        "id": 1174,
        "no_speech_prob": 0.009708124212920666,
        "seek": 467728,
        "start": 4704.08,
        "temperature": 0.4,
        "text": " and it's going to take a little bit more time than Pi Day.",
        "tokens": [
          51704,
          293,
          309,
          311,
          516,
          281,
          747,
          257,
          707,
          857,
          544,
          565,
          813,
          17741,
          5226,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2462776257441594,
        "compression_ratio": 1.608910891089109,
        "end": 4712.48,
        "id": 1175,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 470632,
        "start": 4706.88,
        "temperature": 0,
        "text": " Um, so, um, what have I done so far today?",
        "tokens": [
          50392,
          3301,
          11,
          370,
          11,
          1105,
          11,
          437,
          362,
          286,
          1096,
          370,
          1400,
          965,
          30,
          50672
        ]
      },
      {
        "avg_logprob": -0.2462776257441594,
        "compression_ratio": 1.608910891089109,
        "end": 4718,
        "id": 1176,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 470632,
        "start": 4713.44,
        "temperature": 0,
        "text": " I have done one video about linting, which needs a follow-up.",
        "tokens": [
          50720,
          286,
          362,
          1096,
          472,
          960,
          466,
          287,
          686,
          278,
          11,
          597,
          2203,
          257,
          1524,
          12,
          1010,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2462776257441594,
        "compression_ratio": 1.608910891089109,
        "end": 4720.32,
        "id": 1177,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 470632,
        "start": 4718,
        "temperature": 0,
        "text": " I have done one video about remote...",
        "tokens": [
          50948,
          286,
          362,
          1096,
          472,
          960,
          466,
          8607,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.2462776257441594,
        "compression_ratio": 1.608910891089109,
        "end": 4722.32,
        "id": 1178,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 470632,
        "start": 4720.32,
        "temperature": 0,
        "text": " Oh, oh, oh, oh, we don't have time for it.",
        "tokens": [
          51064,
          876,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          321,
          500,
          380,
          362,
          565,
          337,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2462776257441594,
        "compression_ratio": 1.608910891089109,
        "end": 4726.799999999999,
        "id": 1179,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 470632,
        "start": 4724.799999999999,
        "temperature": 0,
        "text": " Oh, maybe I could do my load bytes pull request.",
        "tokens": [
          51288,
          876,
          11,
          1310,
          286,
          727,
          360,
          452,
          3677,
          36088,
          2235,
          5308,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2462776257441594,
        "compression_ratio": 1.608910891089109,
        "end": 4729.04,
        "id": 1180,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 470632,
        "start": 4727.92,
        "temperature": 0,
        "text": " All right, this could fail.",
        "tokens": [
          51444,
          1057,
          558,
          11,
          341,
          727,
          3061,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2462776257441594,
        "compression_ratio": 1.608910891089109,
        "end": 4733.12,
        "id": 1181,
        "no_speech_prob": 0.000020145622329437174,
        "seek": 470632,
        "start": 4729.04,
        "temperature": 0,
        "text": " This is probably going to fail horribly because, I mean, yeah.",
        "tokens": [
          51500,
          639,
          307,
          1391,
          516,
          281,
          3061,
          45028,
          570,
          11,
          286,
          914,
          11,
          1338,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4735.68,
        "id": 1182,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4733.68,
        "temperature": 0,
        "text": " Eh, eh, mm.",
        "tokens": [
          50392,
          9663,
          11,
          7670,
          11,
          11169,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4739.68,
        "id": 1183,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4738.24,
        "temperature": 0,
        "text": " I should give myself more time for this.",
        "tokens": [
          50620,
          286,
          820,
          976,
          2059,
          544,
          565,
          337,
          341,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4742.48,
        "id": 1184,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4741.28,
        "temperature": 0,
        "text": " Yeah, it's a bad idea.",
        "tokens": [
          50772,
          865,
          11,
          309,
          311,
          257,
          1578,
          1558,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4745.76,
        "id": 1185,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4742.48,
        "temperature": 0,
        "text": " I want to, I, let me just say what I was thinking about doing.",
        "tokens": [
          50832,
          286,
          528,
          281,
          11,
          286,
          11,
          718,
          385,
          445,
          584,
          437,
          286,
          390,
          1953,
          466,
          884,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4746.8,
        "id": 1186,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4745.76,
        "temperature": 0,
        "text": " I think it's better for me to just,",
        "tokens": [
          50996,
          286,
          519,
          309,
          311,
          1101,
          337,
          385,
          281,
          445,
          11,
          51048
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4749.2,
        "id": 1187,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4748,
        "temperature": 0,
        "text": " it's not good for me to try to do something",
        "tokens": [
          51108,
          309,
          311,
          406,
          665,
          337,
          385,
          281,
          853,
          281,
          360,
          746,
          51168
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4751.04,
        "id": 1188,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4749.2,
        "temperature": 0,
        "text": " when I have a very limited amount of time,",
        "tokens": [
          51168,
          562,
          286,
          362,
          257,
          588,
          5567,
          2372,
          295,
          565,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4752.96,
        "id": 1189,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4751.04,
        "temperature": 0,
        "text": " especially anything that's complicated.",
        "tokens": [
          51260,
          2318,
          1340,
          300,
          311,
          6179,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4754.5599999999995,
        "id": 1190,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4752.96,
        "temperature": 0,
        "text": " This will be way more complicated,",
        "tokens": [
          51356,
          639,
          486,
          312,
          636,
          544,
          6179,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4758.64,
        "id": 1191,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4754.5599999999995,
        "temperature": 0,
        "text": " but I want to go to what I was thinking about doing",
        "tokens": [
          51436,
          457,
          286,
          528,
          281,
          352,
          281,
          437,
          286,
          390,
          1953,
          466,
          884,
          51640
        ]
      },
      {
        "avg_logprob": -0.29039705716646635,
        "compression_ratio": 1.7764227642276422,
        "end": 4760.8,
        "id": 1192,
        "no_speech_prob": 0.00008481067197863013,
        "seek": 473312,
        "start": 4758.64,
        "temperature": 0,
        "text": " that I think would make a useful video tutorial.",
        "tokens": [
          51640,
          300,
          286,
          519,
          576,
          652,
          257,
          4420,
          960,
          7073,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.355258042784943,
        "compression_ratio": 1.5854922279792747,
        "end": 4763.360000000001,
        "id": 1193,
        "no_speech_prob": 0.0001007133541861549,
        "seek": 476080,
        "start": 4761.28,
        "temperature": 0,
        "text": " So let me add a comment here about this at least.",
        "tokens": [
          50388,
          407,
          718,
          385,
          909,
          257,
          2871,
          510,
          466,
          341,
          412,
          1935,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.355258042784943,
        "compression_ratio": 1.5854922279792747,
        "end": 4765.360000000001,
        "id": 1194,
        "no_speech_prob": 0.0001007133541861549,
        "seek": 476080,
        "start": 4764.56,
        "temperature": 0,
        "text": " Load bytes.",
        "tokens": [
          50552,
          48408,
          36088,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.355258042784943,
        "compression_ratio": 1.5854922279792747,
        "end": 4775.52,
        "id": 1195,
        "no_speech_prob": 0.0001007133541861549,
        "seek": 476080,
        "start": 4770.8,
        "temperature": 0,
        "text": " So, so this, by the way, is a GitHub issue that I opened",
        "tokens": [
          50864,
          407,
          11,
          370,
          341,
          11,
          538,
          264,
          636,
          11,
          307,
          257,
          23331,
          2734,
          300,
          286,
          5625,
          51100
        ]
      },
      {
        "avg_logprob": -0.355258042784943,
        "compression_ratio": 1.5854922279792747,
        "end": 4778.4800000000005,
        "id": 1196,
        "no_speech_prob": 0.0001007133541861549,
        "seek": 476080,
        "start": 4775.52,
        "temperature": 0,
        "text": " for the open source project p5.js,",
        "tokens": [
          51100,
          337,
          264,
          1269,
          4009,
          1716,
          280,
          20,
          13,
          25530,
          11,
          51248
        ]
      },
      {
        "avg_logprob": -0.355258042784943,
        "compression_ratio": 1.5854922279792747,
        "end": 4781.12,
        "id": 1197,
        "no_speech_prob": 0.0001007133541861549,
        "seek": 476080,
        "start": 4778.4800000000005,
        "temperature": 0,
        "text": " which is a project that I'm very much involved with,",
        "tokens": [
          51248,
          597,
          307,
          257,
          1716,
          300,
          286,
          478,
          588,
          709,
          3288,
          365,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.355258042784943,
        "compression_ratio": 1.5854922279792747,
        "end": 4783.84,
        "id": 1198,
        "no_speech_prob": 0.0001007133541861549,
        "seek": 476080,
        "start": 4781.12,
        "temperature": 0,
        "text": " a wonderful community and open source project,",
        "tokens": [
          51380,
          257,
          3715,
          1768,
          293,
          1269,
          4009,
          1716,
          11,
          51516
        ]
      },
      {
        "avg_logprob": -0.355258042784943,
        "compression_ratio": 1.5854922279792747,
        "end": 4788.24,
        "id": 1199,
        "no_speech_prob": 0.0001007133541861549,
        "seek": 476080,
        "start": 4784.88,
        "temperature": 0,
        "text": " where I created a version of the load bytes function",
        "tokens": [
          51568,
          689,
          286,
          2942,
          257,
          3037,
          295,
          264,
          3677,
          36088,
          2445,
          51736
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4791.92,
        "id": 1200,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4789.2,
        "temperature": 0,
        "text": " to load a binary file to a JavaScript program",
        "tokens": [
          50412,
          281,
          3677,
          257,
          17434,
          3991,
          281,
          257,
          15778,
          1461,
          50548
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4794.96,
        "id": 1201,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4791.92,
        "temperature": 0,
        "text": " which doesn't at present exist,",
        "tokens": [
          50548,
          597,
          1177,
          380,
          412,
          1974,
          2514,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4800.48,
        "id": 1202,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4797.12,
        "temperature": 0,
        "text": " which doesn't at present, yeah,",
        "tokens": [
          50808,
          597,
          1177,
          380,
          412,
          1974,
          11,
          1338,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4803.44,
        "id": 1203,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4800.48,
        "temperature": 0,
        "text": " which doesn't at present exist in p5.",
        "tokens": [
          50976,
          597,
          1177,
          380,
          412,
          1974,
          2514,
          294,
          280,
          20,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4804.88,
        "id": 1204,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4803.44,
        "temperature": 0,
        "text": " If you go and look in the p5 source code,",
        "tokens": [
          51124,
          759,
          291,
          352,
          293,
          574,
          294,
          264,
          280,
          20,
          4009,
          3089,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4806.24,
        "id": 1205,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4804.88,
        "temperature": 0,
        "text": " it'll say to be implemented.",
        "tokens": [
          51196,
          309,
          603,
          584,
          281,
          312,
          12270,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4809.679999999999,
        "id": 1206,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4806.8,
        "temperature": 0,
        "text": " And so some people gave me some feedback here,",
        "tokens": [
          51292,
          400,
          370,
          512,
          561,
          2729,
          385,
          512,
          5824,
          510,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4812.08,
        "id": 1207,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4809.679999999999,
        "temperature": 0,
        "text": " and I just keep, it's been on my list every day,",
        "tokens": [
          51436,
          293,
          286,
          445,
          1066,
          11,
          309,
          311,
          668,
          322,
          452,
          1329,
          633,
          786,
          11,
          51556
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4813.28,
        "id": 1208,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4812.08,
        "temperature": 0,
        "text": " I'll let me pull request this,",
        "tokens": [
          51556,
          286,
          603,
          718,
          385,
          2235,
          5308,
          341,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.23432843159821073,
        "compression_ratio": 1.6796536796536796,
        "end": 4815.12,
        "id": 1209,
        "no_speech_prob": 0.00021654294687323272,
        "seek": 478824,
        "start": 4813.28,
        "temperature": 0,
        "text": " and then I thought, oh, it would be useful",
        "tokens": [
          51616,
          293,
          550,
          286,
          1194,
          11,
          1954,
          11,
          309,
          576,
          312,
          4420,
          51708
        ]
      },
      {
        "avg_logprob": -0.1832371756087902,
        "compression_ratio": 1.4973544973544974,
        "end": 4818,
        "id": 1210,
        "no_speech_prob": 0.0006070712115615606,
        "seek": 481512,
        "start": 4815.12,
        "temperature": 0,
        "text": " to actually make this contribution to p5.js",
        "tokens": [
          50364,
          281,
          767,
          652,
          341,
          13150,
          281,
          280,
          20,
          13,
          25530,
          50508
        ]
      },
      {
        "avg_logprob": -0.1832371756087902,
        "compression_ratio": 1.4973544973544974,
        "end": 4820.64,
        "id": 1211,
        "no_speech_prob": 0.0006070712115615606,
        "seek": 481512,
        "start": 4818,
        "temperature": 0,
        "text": " in a video tutorial, but I also feel like,",
        "tokens": [
          50508,
          294,
          257,
          960,
          7073,
          11,
          457,
          286,
          611,
          841,
          411,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.1832371756087902,
        "compression_ratio": 1.4973544973544974,
        "end": 4822.32,
        "id": 1212,
        "no_speech_prob": 0.0006070712115615606,
        "seek": 481512,
        "start": 4820.64,
        "temperature": 0,
        "text": " oh, when am I ever going to get to that?",
        "tokens": [
          50640,
          1954,
          11,
          562,
          669,
          286,
          1562,
          516,
          281,
          483,
          281,
          300,
          30,
          50724
        ]
      },
      {
        "avg_logprob": -0.1832371756087902,
        "compression_ratio": 1.4973544973544974,
        "end": 4823.76,
        "id": 1213,
        "no_speech_prob": 0.0006070712115615606,
        "seek": 481512,
        "start": 4822.32,
        "temperature": 0,
        "text": " So let me make a note here,",
        "tokens": [
          50724,
          407,
          718,
          385,
          652,
          257,
          3637,
          510,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.1832371756087902,
        "compression_ratio": 1.4973544973544974,
        "end": 4830.08,
        "id": 1214,
        "no_speech_prob": 0.0006070712115615606,
        "seek": 481512,
        "start": 4825.36,
        "temperature": 0,
        "text": " and just say, FYI, I am writing this while live streaming.",
        "tokens": [
          50876,
          293,
          445,
          584,
          11,
          42730,
          40,
          11,
          286,
          669,
          3579,
          341,
          1339,
          1621,
          11791,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.1832371756087902,
        "compression_ratio": 1.4973544973544974,
        "end": 4836.8,
        "id": 1215,
        "no_speech_prob": 0.0006070712115615606,
        "seek": 481512,
        "start": 4832.96,
        "temperature": 0,
        "text": " I would like to make a video tutorial",
        "tokens": [
          51256,
          286,
          576,
          411,
          281,
          652,
          257,
          960,
          7073,
          51448
        ]
      },
      {
        "avg_logprob": -0.1832371756087902,
        "compression_ratio": 1.4973544973544974,
        "end": 4840.88,
        "id": 1216,
        "no_speech_prob": 0.0006070712115615606,
        "seek": 481512,
        "start": 4836.8,
        "temperature": 0,
        "text": " where I walk through the steps",
        "tokens": [
          51448,
          689,
          286,
          1792,
          807,
          264,
          4439,
          51652
        ]
      },
      {
        "avg_logprob": -0.2546207955543031,
        "compression_ratio": 1.328,
        "end": 4848.96,
        "id": 1217,
        "no_speech_prob": 0.000300592218991369,
        "seek": 484088,
        "start": 4840.88,
        "temperature": 0,
        "text": " of how to contribute this enhancement,",
        "tokens": [
          50364,
          295,
          577,
          281,
          10586,
          341,
          40776,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.2546207955543031,
        "compression_ratio": 1.328,
        "end": 4853.12,
        "id": 1218,
        "no_speech_prob": 0.000300592218991369,
        "seek": 484088,
        "start": 4849.6,
        "temperature": 0,
        "text": " but I did not get to it today.",
        "tokens": [
          50800,
          457,
          286,
          630,
          406,
          483,
          281,
          309,
          965,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2546207955543031,
        "compression_ratio": 1.328,
        "end": 4856.64,
        "id": 1219,
        "no_speech_prob": 0.000300592218991369,
        "seek": 484088,
        "start": 4854.24,
        "temperature": 0,
        "text": " I think this would be useful.",
        "tokens": [
          51032,
          286,
          519,
          341,
          576,
          312,
          4420,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2546207955543031,
        "compression_ratio": 1.328,
        "end": 4864.16,
        "id": 1220,
        "no_speech_prob": 0.000300592218991369,
        "seek": 484088,
        "start": 4860.8,
        "temperature": 0,
        "text": " So I am holding off on submitting",
        "tokens": [
          51360,
          407,
          286,
          669,
          5061,
          766,
          322,
          31836,
          51528
        ]
      },
      {
        "avg_logprob": -0.2546207955543031,
        "compression_ratio": 1.328,
        "end": 4866.88,
        "id": 1221,
        "no_speech_prob": 0.000300592218991369,
        "seek": 484088,
        "start": 4864.16,
        "temperature": 0,
        "text": " until another recording session.",
        "tokens": [
          51528,
          1826,
          1071,
          6613,
          5481,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4868.32,
        "id": 1222,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4867.12,
        "temperature": 0,
        "text": " So this looks right.",
        "tokens": [
          50376,
          407,
          341,
          1542,
          558,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4879.36,
        "id": 1223,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4878.32,
        "temperature": 0,
        "text": " Okay, so wonderful.",
        "tokens": [
          50936,
          1033,
          11,
          370,
          3715,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4880.56,
        "id": 1224,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4879.36,
        "temperature": 0,
        "text": " So I added that note there.",
        "tokens": [
          50988,
          407,
          286,
          3869,
          300,
          3637,
          456,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4888.400000000001,
        "id": 1225,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4885.76,
        "temperature": 0,
        "text": " Thank you to everyone who has been",
        "tokens": [
          51308,
          1044,
          291,
          281,
          1518,
          567,
          575,
          668,
          51440
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4890.24,
        "id": 1226,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4888.400000000001,
        "temperature": 0,
        "text": " monitoring the YouTube chat today.",
        "tokens": [
          51440,
          11028,
          264,
          3088,
          5081,
          965,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4891.92,
        "id": 1227,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4890.24,
        "temperature": 0,
        "text": " That's not an easy thing to do,",
        "tokens": [
          51532,
          663,
          311,
          406,
          364,
          1858,
          551,
          281,
          360,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4893.68,
        "id": 1228,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4891.92,
        "temperature": 0,
        "text": " and I really appreciate it.",
        "tokens": [
          51616,
          293,
          286,
          534,
          4449,
          309,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.4777042388916016,
        "compression_ratio": 1.3888888888888888,
        "end": 4894.8,
        "id": 1229,
        "no_speech_prob": 0.00045120090362615883,
        "seek": 486688,
        "start": 4893.68,
        "temperature": 0,
        "text": " It's very important to me.",
        "tokens": [
          51704,
          467,
          311,
          588,
          1021,
          281,
          385,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4898.16,
        "id": 1230,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4894.88,
        "temperature": 0,
        "text": " It's very important to me that the community",
        "tokens": [
          50368,
          467,
          311,
          588,
          1021,
          281,
          385,
          300,
          264,
          1768,
          50532
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4899.52,
        "id": 1231,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4898.16,
        "temperature": 0,
        "text": " that participates in the channel",
        "tokens": [
          50532,
          300,
          3421,
          1024,
          294,
          264,
          2269,
          50600
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4902.88,
        "id": 1232,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4900.08,
        "temperature": 0,
        "text": " is kind and welcoming to everyone,",
        "tokens": [
          50628,
          307,
          733,
          293,
          17378,
          281,
          1518,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4906.8,
        "id": 1233,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4902.88,
        "temperature": 0,
        "text": " and so as always, if you're running into any issues",
        "tokens": [
          50768,
          293,
          370,
          382,
          1009,
          11,
          498,
          291,
          434,
          2614,
          666,
          604,
          2663,
          50964
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4908.64,
        "id": 1234,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4907.6,
        "temperature": 0,
        "text": " during any of the live streams,",
        "tokens": [
          51004,
          1830,
          604,
          295,
          264,
          1621,
          15842,
          11,
          51056
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4910.16,
        "id": 1235,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4908.64,
        "temperature": 0,
        "text": " please send me a tweet or an email.",
        "tokens": [
          51056,
          1767,
          2845,
          385,
          257,
          15258,
          420,
          364,
          3796,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4911.04,
        "id": 1236,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4910.16,
        "temperature": 0,
        "text": " You probably can figure out a way",
        "tokens": [
          51132,
          509,
          1391,
          393,
          2573,
          484,
          257,
          636,
          51176
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4912.24,
        "id": 1237,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4911.04,
        "temperature": 0,
        "text": " to get in contact with me.",
        "tokens": [
          51176,
          281,
          483,
          294,
          3385,
          365,
          385,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4913.84,
        "id": 1238,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4912.24,
        "temperature": 0,
        "text": " I'm happy to do anything I can to help.",
        "tokens": [
          51236,
          286,
          478,
          2055,
          281,
          360,
          1340,
          286,
          393,
          281,
          854,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4919.84,
        "id": 1239,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4915.4400000000005,
        "temperature": 0,
        "text": " So I think what I'll do is,",
        "tokens": [
          51396,
          407,
          286,
          519,
          437,
          286,
          603,
          360,
          307,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.20559076041229501,
        "compression_ratio": 1.5914396887159532,
        "end": 4921.52,
        "id": 1240,
        "no_speech_prob": 0.007815374992787838,
        "seek": 489480,
        "start": 4919.84,
        "temperature": 0,
        "text": " so I'm going to go in about five or 10 minutes.",
        "tokens": [
          51616,
          370,
          286,
          478,
          516,
          281,
          352,
          294,
          466,
          1732,
          420,
          1266,
          2077,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.22382264259534004,
        "compression_ratio": 1.4914285714285713,
        "end": 4927.68,
        "id": 1241,
        "no_speech_prob": 0.000677188509143889,
        "seek": 492152,
        "start": 4921.52,
        "temperature": 0,
        "text": " I'm happy to maybe take a few questions.",
        "tokens": [
          50364,
          286,
          478,
          2055,
          281,
          1310,
          747,
          257,
          1326,
          1651,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.22382264259534004,
        "compression_ratio": 1.4914285714285713,
        "end": 4930.88,
        "id": 1242,
        "no_speech_prob": 0.000677188509143889,
        "seek": 492152,
        "start": 4929.76,
        "temperature": 0,
        "text": " Let me actually also...",
        "tokens": [
          50776,
          961,
          385,
          767,
          611,
          485,
          50832
        ]
      },
      {
        "avg_logprob": -0.22382264259534004,
        "compression_ratio": 1.4914285714285713,
        "end": 4935.68,
        "id": 1243,
        "no_speech_prob": 0.000677188509143889,
        "seek": 492152,
        "start": 4933.76,
        "temperature": 0,
        "text": " I don't think anything that I've done",
        "tokens": [
          50976,
          286,
          500,
          380,
          519,
          1340,
          300,
          286,
          600,
          1096,
          51072
        ]
      },
      {
        "avg_logprob": -0.22382264259534004,
        "compression_ratio": 1.4914285714285713,
        "end": 4937.76,
        "id": 1244,
        "no_speech_prob": 0.000677188509143889,
        "seek": 492152,
        "start": 4935.68,
        "temperature": 0,
        "text": " has broken any of my existing examples.",
        "tokens": [
          51072,
          575,
          5463,
          604,
          295,
          452,
          6741,
          5110,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.22382264259534004,
        "compression_ratio": 1.4914285714285713,
        "end": 4939.92,
        "id": 1245,
        "no_speech_prob": 0.000677188509143889,
        "seek": 492152,
        "start": 4937.76,
        "temperature": 0,
        "text": " Wouldn't it be nice to have unit testing here?",
        "tokens": [
          51176,
          26291,
          380,
          309,
          312,
          1481,
          281,
          362,
          4985,
          4997,
          510,
          30,
          51284
        ]
      },
      {
        "avg_logprob": -0.22382264259534004,
        "compression_ratio": 1.4914285714285713,
        "end": 4942.4800000000005,
        "id": 1246,
        "no_speech_prob": 0.000677188509143889,
        "seek": 492152,
        "start": 4940.88,
        "temperature": 0,
        "text": " But I'm going to say git add.",
        "tokens": [
          51332,
          583,
          286,
          478,
          516,
          281,
          584,
          18331,
          909,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.22382264259534004,
        "compression_ratio": 1.4914285714285713,
        "end": 4946.240000000001,
        "id": 1247,
        "no_speech_prob": 0.000677188509143889,
        "seek": 492152,
        "start": 4944.64,
        "temperature": 0,
        "text": " And did I save everything that I've done?",
        "tokens": [
          51520,
          400,
          630,
          286,
          3155,
          1203,
          300,
          286,
          600,
          1096,
          30,
          51600
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4947.76,
        "id": 1248,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4946.96,
        "temperature": 0,
        "text": " I'm going to go in,",
        "tokens": [
          50400,
          286,
          478,
          516,
          281,
          352,
          294,
          11,
          50440
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4954.4,
        "id": 1249,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4951.76,
        "temperature": 0,
        "text": " and I'm going to say git commit.",
        "tokens": [
          50640,
          293,
          286,
          478,
          516,
          281,
          584,
          18331,
          5599,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4956.16,
        "id": 1250,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4955.44,
        "temperature": 0,
        "text": " Oh, let me do something.",
        "tokens": [
          50824,
          876,
          11,
          718,
          385,
          360,
          746,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4958.719999999999,
        "id": 1251,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4956.16,
        "temperature": 0,
        "text": " This is my new thing that I do, that I like.",
        "tokens": [
          50860,
          639,
          307,
          452,
          777,
          551,
          300,
          286,
          360,
          11,
          300,
          286,
          411,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4961.84,
        "id": 1252,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4959.5199999999995,
        "temperature": 0,
        "text": " Git commit and atom editor.",
        "tokens": [
          51028,
          16939,
          5599,
          293,
          12018,
          9839,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4965.28,
        "id": 1253,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4963.44,
        "temperature": 0,
        "text": " Wait, so let me do this.",
        "tokens": [
          51224,
          3802,
          11,
          370,
          718,
          385,
          360,
          341,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4967.36,
        "id": 1254,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4965.92,
        "temperature": 0,
        "text": " I want to make a video about this,",
        "tokens": [
          51348,
          286,
          528,
          281,
          652,
          257,
          960,
          466,
          341,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4972.08,
        "id": 1255,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4967.36,
        "temperature": 0,
        "text": " but yes, this is what I want.",
        "tokens": [
          51420,
          457,
          2086,
          11,
          341,
          307,
          437,
          286,
          528,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.4763820532596473,
        "compression_ratio": 1.6206896551724137,
        "end": 4975.44,
        "id": 1256,
        "no_speech_prob": 0.0004512071318458766,
        "seek": 494624,
        "start": 4972.639999999999,
        "temperature": 0,
        "text": " So what I'm doing is I'm associating atom",
        "tokens": [
          51684,
          407,
          437,
          286,
          478,
          884,
          307,
          286,
          478,
          4180,
          990,
          12018,
          51824
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4979.04,
        "id": 1257,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4975.5199999999995,
        "temperature": 0,
        "text": " with git, and so I'm going to do this.",
        "tokens": [
          50368,
          365,
          18331,
          11,
          293,
          370,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4982,
        "id": 1258,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4979.04,
        "temperature": 0,
        "text": " And the wait is there because when I say commit,",
        "tokens": [
          50544,
          400,
          264,
          1699,
          307,
          456,
          570,
          562,
          286,
          584,
          5599,
          11,
          50692
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4983.839999999999,
        "id": 1259,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4982,
        "temperature": 0,
        "text": " I want it to wait to make the commit",
        "tokens": [
          50692,
          286,
          528,
          309,
          281,
          1699,
          281,
          652,
          264,
          5599,
          50784
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4985.2,
        "id": 1260,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4983.839999999999,
        "temperature": 0,
        "text": " until I finish typing in atom.",
        "tokens": [
          50784,
          1826,
          286,
          2413,
          18444,
          294,
          12018,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4987.839999999999,
        "id": 1261,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4986.08,
        "temperature": 0,
        "text": " So now if I say git commit,",
        "tokens": [
          50896,
          407,
          586,
          498,
          286,
          584,
          18331,
          5599,
          11,
          50984
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4992,
        "id": 1262,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4989.5199999999995,
        "temperature": 0,
        "text": " it'll open up the message in atom.",
        "tokens": [
          51068,
          309,
          603,
          1269,
          493,
          264,
          3636,
          294,
          12018,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4996.08,
        "id": 1263,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4992,
        "temperature": 0,
        "text": " And actually, I'm going to do control C",
        "tokens": [
          51192,
          400,
          767,
          11,
          286,
          478,
          516,
          281,
          360,
          1969,
          383,
          51396
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 4998.4,
        "id": 1264,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4996.08,
        "temperature": 0,
        "text": " because what is the thing where I say dash v?",
        "tokens": [
          51396,
          570,
          437,
          307,
          264,
          551,
          689,
          286,
          584,
          8240,
          371,
          30,
          51512
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 5000.16,
        "id": 1265,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 4998.4,
        "temperature": 0,
        "text": " Is it dash v or verbose?",
        "tokens": [
          51512,
          1119,
          309,
          8240,
          371,
          420,
          9595,
          541,
          30,
          51600
        ]
      },
      {
        "avg_logprob": -0.22471044729421805,
        "compression_ratio": 1.6540284360189574,
        "end": 5001.04,
        "id": 1266,
        "no_speech_prob": 0.00002546634823374916,
        "seek": 497544,
        "start": 5000.16,
        "temperature": 0,
        "text": " Somebody must know.",
        "tokens": [
          51600,
          13463,
          1633,
          458,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5006.96,
        "id": 1267,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5002,
        "temperature": 0,
        "text": " Where it, I should really just make this a video right now.",
        "tokens": [
          50412,
          2305,
          309,
          11,
          286,
          820,
          534,
          445,
          652,
          341,
          257,
          960,
          558,
          586,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5011.68,
        "id": 1268,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5011.12,
        "temperature": 0,
        "text": " 15 minutes.",
        "tokens": [
          50868,
          2119,
          2077,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5015.36,
        "id": 1269,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5012.88,
        "temperature": 0,
        "text": " I just like when I have a nugget of something,",
        "tokens": [
          50956,
          286,
          445,
          411,
          562,
          286,
          362,
          257,
          30279,
          847,
          295,
          746,
          11,
          51080
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5018,
        "id": 1270,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5015.36,
        "temperature": 0,
        "text": " I think people find it better if it's in the right playlist",
        "tokens": [
          51080,
          286,
          519,
          561,
          915,
          309,
          1101,
          498,
          309,
          311,
          294,
          264,
          558,
          16788,
          51212
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5020.48,
        "id": 1271,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5018,
        "temperature": 0,
        "text": " and it's an edited chunk as opposed to a random thing.",
        "tokens": [
          51212,
          293,
          309,
          311,
          364,
          23016,
          16635,
          382,
          8851,
          281,
          257,
          4974,
          551,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5025.76,
        "id": 1272,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5022.8,
        "temperature": 0,
        "text": " Of course, all of this is a bad idea.",
        "tokens": [
          51452,
          2720,
          1164,
          11,
          439,
          295,
          341,
          307,
          257,
          1578,
          1558,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5028.32,
        "id": 1273,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5025.76,
        "temperature": 0,
        "text": " In the chat, I'm being told that using atom for this",
        "tokens": [
          51600,
          682,
          264,
          5081,
          11,
          286,
          478,
          885,
          1907,
          300,
          1228,
          12018,
          337,
          341,
          51728
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5029.12,
        "id": 1274,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5028.32,
        "temperature": 0,
        "text": " is a bad idea.",
        "tokens": [
          51728,
          307,
          257,
          1578,
          1558,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.20516044402790962,
        "compression_ratio": 1.5739910313901346,
        "end": 5029.84,
        "id": 1275,
        "no_speech_prob": 0.00047284967149607837,
        "seek": 500104,
        "start": 5029.12,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          51768,
          17795,
          437,
          30,
          51804
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5031.2,
        "id": 1276,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5029.84,
        "temperature": 0,
        "text": " It's all a bad idea.",
        "tokens": [
          50364,
          467,
          311,
          439,
          257,
          1578,
          1558,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5034,
        "id": 1277,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5031.2,
        "temperature": 0,
        "text": " We should all just go back, relax by the fire",
        "tokens": [
          50432,
          492,
          820,
          439,
          445,
          352,
          646,
          11,
          5789,
          538,
          264,
          2610,
          50572
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5036.4800000000005,
        "id": 1278,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5034,
        "temperature": 0,
        "text": " with our friends and read a book, frankly.",
        "tokens": [
          50572,
          365,
          527,
          1855,
          293,
          1401,
          257,
          1446,
          11,
          11939,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5038,
        "id": 1279,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5036.4800000000005,
        "temperature": 0,
        "text": " You know, playing the violin is something",
        "tokens": [
          50696,
          509,
          458,
          11,
          2433,
          264,
          22878,
          307,
          746,
          50772
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5039.04,
        "id": 1280,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5038,
        "temperature": 0,
        "text": " that I did for 12 years,",
        "tokens": [
          50772,
          300,
          286,
          630,
          337,
          2272,
          924,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5040.64,
        "id": 1281,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5039.04,
        "temperature": 0,
        "text": " and I probably should spend more time doing that.",
        "tokens": [
          50824,
          293,
          286,
          1391,
          820,
          3496,
          544,
          565,
          884,
          300,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5044.08,
        "id": 1282,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5043.2,
        "temperature": 0,
        "text": " What is it, verbose?",
        "tokens": [
          51032,
          708,
          307,
          309,
          11,
          9595,
          541,
          30,
          51076
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5045.360000000001,
        "id": 1283,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5044.08,
        "temperature": 0,
        "text": " Nobody's answered my question.",
        "tokens": [
          51076,
          9297,
          311,
          10103,
          452,
          1168,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5053.28,
        "id": 1284,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5050.56,
        "temperature": 0,
        "text": " Oh, Yardi is asking when is the next ITP show?",
        "tokens": [
          51400,
          876,
          11,
          398,
          38126,
          307,
          3365,
          562,
          307,
          264,
          958,
          6783,
          47,
          855,
          30,
          51536
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5054.88,
        "id": 1285,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5053.28,
        "temperature": 0,
        "text": " I think it's May 15th and 16th.",
        "tokens": [
          51536,
          286,
          519,
          309,
          311,
          1891,
          2119,
          392,
          293,
          3165,
          392,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5056.400000000001,
        "id": 1286,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5055.4400000000005,
        "temperature": 0,
        "text": " You should come to it in person,",
        "tokens": [
          51644,
          509,
          820,
          808,
          281,
          309,
          294,
          954,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.1975024425200302,
        "compression_ratio": 1.5310344827586206,
        "end": 5058.400000000001,
        "id": 1287,
        "no_speech_prob": 0.000032192241633310914,
        "seek": 502984,
        "start": 5056.400000000001,
        "temperature": 0,
        "text": " but I will plan on doing a live stream from it again.",
        "tokens": [
          51692,
          457,
          286,
          486,
          1393,
          322,
          884,
          257,
          1621,
          4309,
          490,
          309,
          797,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5061.2,
        "id": 1288,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5059.84,
        "temperature": 0,
        "text": " I guess I could just try dash V.",
        "tokens": [
          50364,
          286,
          2041,
          286,
          727,
          445,
          853,
          8240,
          691,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5066.16,
        "id": 1289,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5065.2,
        "temperature": 0,
        "text": " Yeah, that was it.",
        "tokens": [
          50632,
          865,
          11,
          300,
          390,
          309,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5067.4400000000005,
        "id": 1290,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5066.16,
        "temperature": 0,
        "text": " Shows me all the diffs.",
        "tokens": [
          50680,
          1160,
          1509,
          385,
          439,
          264,
          7593,
          82,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5068.24,
        "id": 1291,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5067.4400000000005,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          50744,
          2053,
          412,
          300,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5070.16,
        "id": 1292,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5069.28,
        "temperature": 0,
        "text": " Boom, boom, boom.",
        "tokens": [
          50836,
          15523,
          11,
          9351,
          11,
          9351,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5072.4800000000005,
        "id": 1293,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5071.52,
        "temperature": 0,
        "text": " I like that.",
        "tokens": [
          50948,
          286,
          411,
          300,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5072.96,
        "id": 1294,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5072.4800000000005,
        "temperature": 0,
        "text": " It's good.",
        "tokens": [
          50996,
          467,
          311,
          665,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5074.88,
        "id": 1295,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5072.96,
        "temperature": 0,
        "text": " Okay, so, all right, why not?",
        "tokens": [
          51020,
          1033,
          11,
          370,
          11,
          439,
          558,
          11,
          983,
          406,
          30,
          51116
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5082.88,
        "id": 1296,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5080.16,
        "temperature": 0,
        "text": " All right, use a sensible editor like VI.",
        "tokens": [
          51380,
          1057,
          558,
          11,
          764,
          257,
          25380,
          9839,
          411,
          27619,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2706964683532715,
        "compression_ratio": 1.4759036144578312,
        "end": 5089.68,
        "id": 1297,
        "no_speech_prob": 0.00009610217966837808,
        "seek": 505984,
        "start": 5084.96,
        "temperature": 0,
        "text": " But I, but, but, but, but, but, oh, nice.",
        "tokens": [
          51620,
          583,
          286,
          11,
          457,
          11,
          457,
          11,
          457,
          11,
          457,
          11,
          457,
          11,
          1954,
          11,
          1481,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5091.04,
        "id": 1298,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5090.240000000001,
        "temperature": 0,
        "text": " Nice lollipops.",
        "tokens": [
          50392,
          5490,
          450,
          285,
          647,
          3370,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5095.84,
        "id": 1299,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5094.88,
        "temperature": 0,
        "text": " You can't really do that.",
        "tokens": [
          50624,
          509,
          393,
          380,
          534,
          360,
          300,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5097.6,
        "id": 1300,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5095.84,
        "temperature": 0,
        "text": " It takes time and googling all your questions.",
        "tokens": [
          50672,
          467,
          2516,
          565,
          293,
          50061,
          1688,
          439,
          428,
          1651,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5099.04,
        "id": 1301,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5097.6,
        "temperature": 0,
        "text": " You need a violin coach.",
        "tokens": [
          50760,
          509,
          643,
          257,
          22878,
          6560,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5103.04,
        "id": 1302,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5099.04,
        "temperature": 0,
        "text": " Am I, you know, I can't tell whether I'm doing something.",
        "tokens": [
          50832,
          2012,
          286,
          11,
          291,
          458,
          11,
          286,
          393,
          380,
          980,
          1968,
          286,
          478,
          884,
          746,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5103.52,
        "id": 1303,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5103.04,
        "temperature": 0,
        "text": " All right, fine.",
        "tokens": [
          51032,
          1057,
          558,
          11,
          2489,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5105.52,
        "id": 1304,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5103.52,
        "temperature": 0,
        "text": " I'm not going to do my video about commit right now.",
        "tokens": [
          51056,
          286,
          478,
          406,
          516,
          281,
          360,
          452,
          960,
          466,
          5599,
          558,
          586,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5107.200000000001,
        "id": 1305,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5105.52,
        "temperature": 0,
        "text": " You guys have thrown me off.",
        "tokens": [
          51156,
          509,
          1074,
          362,
          11732,
          385,
          766,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5108.240000000001,
        "id": 1306,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5107.200000000001,
        "temperature": 0,
        "text": " I'm going to just use Adam",
        "tokens": [
          51240,
          286,
          478,
          516,
          281,
          445,
          764,
          7938,
          51292
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5109.52,
        "id": 1307,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5108.240000000001,
        "temperature": 0,
        "text": " because that's the way I like it.",
        "tokens": [
          51292,
          570,
          300,
          311,
          264,
          636,
          286,
          411,
          309,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5111.92,
        "id": 1308,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5110.240000000001,
        "temperature": 0,
        "text": " And I'm going to say commit dash V.",
        "tokens": [
          51392,
          400,
          286,
          478,
          516,
          281,
          584,
          5599,
          8240,
          691,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5114.56,
        "id": 1309,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5111.92,
        "temperature": 0,
        "text": " So what I like about this is it opens up the text editor",
        "tokens": [
          51476,
          407,
          437,
          286,
          411,
          466,
          341,
          307,
          309,
          9870,
          493,
          264,
          2487,
          9839,
          51608
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5117.68,
        "id": 1310,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5114.56,
        "temperature": 0,
        "text": " where I can write my commit message, adding,",
        "tokens": [
          51608,
          689,
          286,
          393,
          2464,
          452,
          5599,
          3636,
          11,
          5127,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.21399247271459806,
        "compression_ratio": 1.6764705882352942,
        "end": 5119.04,
        "id": 1311,
        "no_speech_prob": 0.00010071308497572318,
        "seek": 508968,
        "start": 5117.68,
        "temperature": 0,
        "text": " and it'll actually even like do stuff like,",
        "tokens": [
          51764,
          293,
          309,
          603,
          767,
          754,
          411,
          360,
          1507,
          411,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.25087655480228255,
        "compression_ratio": 1.4722222222222223,
        "end": 5121.12,
        "id": 1312,
        "no_speech_prob": 0.00002392345959378872,
        "seek": 511904,
        "start": 5119.04,
        "temperature": 0,
        "text": " hey, start that with a capital, adding,",
        "tokens": [
          50364,
          4177,
          11,
          722,
          300,
          365,
          257,
          4238,
          11,
          5127,
          11,
          50468
        ]
      },
      {
        "avg_logprob": -0.25087655480228255,
        "compression_ratio": 1.4722222222222223,
        "end": 5132.96,
        "id": 1313,
        "no_speech_prob": 0.00002392345959378872,
        "seek": 511904,
        "start": 5123.44,
        "temperature": 0,
        "text": " adding code from March 8th live stream on NeuroEvolution.",
        "tokens": [
          50584,
          5127,
          3089,
          490,
          6129,
          1649,
          392,
          1621,
          4309,
          322,
          1734,
          7052,
          36,
          85,
          3386,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.25087655480228255,
        "compression_ratio": 1.4722222222222223,
        "end": 5136.88,
        "id": 1314,
        "no_speech_prob": 0.00002392345959378872,
        "seek": 511904,
        "start": 5134.32,
        "temperature": 0,
        "text": " Because it doesn't like that I went so far on one line.",
        "tokens": [
          51128,
          1436,
          309,
          1177,
          380,
          411,
          300,
          286,
          1437,
          370,
          1400,
          322,
          472,
          1622,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.25087655480228255,
        "compression_ratio": 1.4722222222222223,
        "end": 5137.76,
        "id": 1315,
        "no_speech_prob": 0.00002392345959378872,
        "seek": 511904,
        "start": 5136.88,
        "temperature": 0,
        "text": " Oh, too many.",
        "tokens": [
          51256,
          876,
          11,
          886,
          867,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.25087655480228255,
        "compression_ratio": 1.4722222222222223,
        "end": 5140.32,
        "id": 1316,
        "no_speech_prob": 0.00002392345959378872,
        "seek": 511904,
        "start": 5137.76,
        "temperature": 0,
        "text": " Yeah, adding code for March 8th live stream.",
        "tokens": [
          51300,
          865,
          11,
          5127,
          3089,
          337,
          6129,
          1649,
          392,
          1621,
          4309,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.3166765371958415,
        "compression_ratio": 1.2456140350877194,
        "end": 5148.639999999999,
        "id": 1317,
        "no_speech_prob": 0.0017546005547046661,
        "seek": 514032,
        "start": 5141.04,
        "temperature": 0,
        "text": " So this here is the start of code I need",
        "tokens": [
          50400,
          407,
          341,
          510,
          307,
          264,
          722,
          295,
          3089,
          286,
          643,
          50780
        ]
      },
      {
        "avg_logprob": -0.3166765371958415,
        "compression_ratio": 1.2456140350877194,
        "end": 5153.04,
        "id": 1318,
        "no_speech_prob": 0.0017546005547046661,
        "seek": 514032,
        "start": 5148.639999999999,
        "temperature": 0,
        "text": " for my NeuroEvolution examples.",
        "tokens": [
          50780,
          337,
          452,
          1734,
          7052,
          36,
          85,
          3386,
          5110,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.3166765371958415,
        "compression_ratio": 1.2456140350877194,
        "end": 5159.679999999999,
        "id": 1319,
        "no_speech_prob": 0.0017546005547046661,
        "seek": 514032,
        "start": 5157.44,
        "temperature": 0,
        "text": " So far, I guess it wants me to.",
        "tokens": [
          51220,
          407,
          1400,
          11,
          286,
          2041,
          309,
          2738,
          385,
          281,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.3166765371958415,
        "compression_ratio": 1.2456140350877194,
        "end": 5164.639999999999,
        "id": 1320,
        "no_speech_prob": 0.0017546005547046661,
        "seek": 514032,
        "start": 5159.679999999999,
        "temperature": 0,
        "text": " So far, I have only implemented copy.",
        "tokens": [
          51332,
          407,
          1400,
          11,
          286,
          362,
          787,
          12270,
          5055,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.4970279756139536,
        "compression_ratio": 1.366412213740458,
        "end": 5172,
        "id": 1321,
        "no_speech_prob": 0.0005703091737814248,
        "seek": 516464,
        "start": 5165.200000000001,
        "temperature": 0,
        "text": " And I've only implemented copy and mutate.",
        "tokens": [
          50392,
          400,
          286,
          600,
          787,
          566,
          781,
          14684,
          5055,
          293,
          5839,
          473,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.4970279756139536,
        "compression_ratio": 1.366412213740458,
        "end": 5181.12,
        "id": 1322,
        "no_speech_prob": 0.0005703091737814248,
        "seek": 516464,
        "start": 5175.04,
        "temperature": 0,
        "text": " I still need to do crossover.",
        "tokens": [
          50884,
          286,
          920,
          643,
          281,
          360,
          33837,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.4970279756139536,
        "compression_ratio": 1.366412213740458,
        "end": 5184.72,
        "id": 1323,
        "no_speech_prob": 0.0005703091737814248,
        "seek": 516464,
        "start": 5183.92,
        "temperature": 0,
        "text": " Put these.",
        "tokens": [
          51328,
          4935,
          613,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.4970279756139536,
        "compression_ratio": 1.366412213740458,
        "end": 5189.280000000001,
        "id": 1324,
        "no_speech_prob": 0.0005703091737814248,
        "seek": 516464,
        "start": 5188.72,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51568,
          286,
          500,
          380,
          458,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.4970279756139536,
        "compression_ratio": 1.366412213740458,
        "end": 5191.280000000001,
        "id": 1325,
        "no_speech_prob": 0.0005703091737814248,
        "seek": 516464,
        "start": 5189.280000000001,
        "temperature": 0,
        "text": " I feel like I don't know where the period should go.",
        "tokens": [
          51596,
          286,
          841,
          411,
          286,
          500,
          380,
          458,
          689,
          264,
          2896,
          820,
          352,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.4970279756139536,
        "compression_ratio": 1.366412213740458,
        "end": 5192.64,
        "id": 1326,
        "no_speech_prob": 0.0005703091737814248,
        "seek": 516464,
        "start": 5191.280000000001,
        "temperature": 0,
        "text": " I'm having a grammar moment.",
        "tokens": [
          51696,
          286,
          478,
          1419,
          257,
          22317,
          1623,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5194.240000000001,
        "id": 1327,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5192.72,
        "temperature": 0,
        "text": " The period I thought should go inside,",
        "tokens": [
          50368,
          440,
          2896,
          286,
          1194,
          820,
          352,
          1854,
          11,
          50444
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5196.240000000001,
        "id": 1328,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5194.240000000001,
        "temperature": 0,
        "text": " but then the parentheses threw me off.",
        "tokens": [
          50444,
          457,
          550,
          264,
          34153,
          11918,
          385,
          766,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5196.72,
        "id": 1329,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5196.240000000001,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50544,
          2438,
          0,
          50568
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5197.92,
        "id": 1330,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5196.72,
        "temperature": 0,
        "text": " I still need to cross.",
        "tokens": [
          50568,
          286,
          920,
          643,
          281,
          3278,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5198.88,
        "id": 1331,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5197.92,
        "temperature": 0,
        "text": " I'll have an and here.",
        "tokens": [
          50628,
          286,
          603,
          362,
          364,
          293,
          510,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5200.56,
        "id": 1332,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5199.84,
        "temperature": 0,
        "text": " How about this?",
        "tokens": [
          50724,
          1012,
          466,
          341,
          30,
          50760
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5201.62,
        "id": 1333,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5201.12,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50788,
          2264,
          13,
          50813
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5203.84,
        "id": 1334,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5203.04,
        "temperature": 0,
        "text": " That fixes it.",
        "tokens": [
          50884,
          663,
          32539,
          309,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5215.360000000001,
        "id": 1335,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5204.96,
        "temperature": 0,
        "text": " I still need to do crossover and implement the GA itself,",
        "tokens": [
          50980,
          286,
          920,
          643,
          281,
          360,
          33837,
          293,
          4445,
          264,
          22841,
          2564,
          11,
          51500
        ]
      },
      {
        "avg_logprob": -0.599054678892478,
        "compression_ratio": 1.4171779141104295,
        "end": 5215.92,
        "id": 1336,
        "no_speech_prob": 0.016656801104545593,
        "seek": 519264,
        "start": 5215.360000000001,
        "temperature": 0,
        "text": " of course.",
        "tokens": [
          51500,
          295,
          1164,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.7211396905440318,
        "compression_ratio": 1.5961538461538463,
        "end": 5221.52,
        "id": 1337,
        "no_speech_prob": 0.0006986701628193259,
        "seek": 521592,
        "start": 5216.88,
        "temperature": 0,
        "text": " For reference, the live stream is here.",
        "tokens": [
          50412,
          1171,
          6408,
          11,
          264,
          1621,
          4309,
          307,
          510,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.7211396905440318,
        "compression_ratio": 1.5961538461538463,
        "end": 5226.96,
        "id": 1338,
        "no_speech_prob": 0.0006986701628193259,
        "seek": 521592,
        "start": 5226,
        "temperature": 0,
        "text": " Live stream is here.",
        "tokens": [
          50868,
          10385,
          4309,
          307,
          510,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.7211396905440318,
        "compression_ratio": 1.5961538461538463,
        "end": 5231.68,
        "id": 1339,
        "no_speech_prob": 0.0006986701628193259,
        "seek": 521592,
        "start": 5226.96,
        "temperature": 0,
        "text": " So how do I get YouTube, the coding train?",
        "tokens": [
          50916,
          407,
          577,
          360,
          286,
          483,
          3088,
          11,
          264,
          17720,
          3847,
          30,
          51152
        ]
      },
      {
        "avg_logprob": -0.7211396905440318,
        "compression_ratio": 1.5961538461538463,
        "end": 5234.4800000000005,
        "id": 1340,
        "no_speech_prob": 0.0006986701628193259,
        "seek": 521592,
        "start": 5233.2,
        "temperature": 0,
        "text": " Yeah, I really got to go, actually.",
        "tokens": [
          51228,
          865,
          11,
          286,
          534,
          658,
          281,
          352,
          11,
          767,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.7211396905440318,
        "compression_ratio": 1.5961538461538463,
        "end": 5237.68,
        "id": 1341,
        "no_speech_prob": 0.0006986701628193259,
        "seek": 521592,
        "start": 5234.4800000000005,
        "temperature": 0,
        "text": " Because and so if I go to coding train live,",
        "tokens": [
          51292,
          1436,
          293,
          370,
          498,
          286,
          352,
          281,
          17720,
          3847,
          1621,
          11,
          51452
        ]
      },
      {
        "avg_logprob": -0.7211396905440318,
        "compression_ratio": 1.5961538461538463,
        "end": 5241.68,
        "id": 1342,
        "no_speech_prob": 0.0006986701628193259,
        "seek": 521592,
        "start": 5237.68,
        "temperature": 0,
        "text": " this will be the live stream.",
        "tokens": [
          51452,
          341,
          486,
          312,
          264,
          1621,
          4309,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.7211396905440318,
        "compression_ratio": 1.5961538461538463,
        "end": 5243.12,
        "id": 1343,
        "no_speech_prob": 0.0006986701628193259,
        "seek": 521592,
        "start": 5241.68,
        "temperature": 0,
        "text": " And I'm going to do a live stream.",
        "tokens": [
          51652,
          400,
          286,
          478,
          516,
          281,
          360,
          257,
          1621,
          4309,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5248.8,
        "id": 1344,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5243.44,
        "temperature": 0,
        "text": " This URL will go on forever.",
        "tokens": [
          50380,
          639,
          12905,
          486,
          352,
          322,
          5680,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5253.5199999999995,
        "id": 1345,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5250.24,
        "temperature": 0,
        "text": " And so this, I think, is a nice, thoughtful commit message",
        "tokens": [
          50720,
          400,
          370,
          341,
          11,
          286,
          519,
          11,
          307,
          257,
          1481,
          11,
          21566,
          5599,
          3636,
          50884
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5254.88,
        "id": 1346,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5253.5199999999995,
        "temperature": 0,
        "text": " that explains everything.",
        "tokens": [
          50884,
          300,
          13948,
          1203,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5256.32,
        "id": 1347,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5254.88,
        "temperature": 0,
        "text": " I am now going to hit close.",
        "tokens": [
          50952,
          286,
          669,
          586,
          516,
          281,
          2045,
          1998,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5261.599999999999,
        "id": 1348,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5259.599999999999,
        "temperature": 0,
        "text": " And it added that.",
        "tokens": [
          51188,
          400,
          309,
          3869,
          300,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5262.64,
        "id": 1349,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5261.599999999999,
        "temperature": 0,
        "text": " Is it March 8?",
        "tokens": [
          51288,
          1119,
          309,
          6129,
          1649,
          30,
          51340
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5263.36,
        "id": 1350,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5262.64,
        "temperature": 0,
        "text": " I hope it's March.",
        "tokens": [
          51340,
          286,
          1454,
          309,
          311,
          6129,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5264.16,
        "id": 1351,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5263.36,
        "temperature": 0,
        "text": " It's March 9.",
        "tokens": [
          51376,
          467,
          311,
          6129,
          1722,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5266.32,
        "id": 1352,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5264.16,
        "temperature": 0,
        "text": " Ha ha ha ha ha!",
        "tokens": [
          51416,
          4064,
          324,
          324,
          324,
          324,
          0,
          51524
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5267.36,
        "id": 1353,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5266.32,
        "temperature": 0,
        "text": " Did nobody notice that?",
        "tokens": [
          51524,
          2589,
          5079,
          3449,
          300,
          30,
          51576
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5269.5199999999995,
        "id": 1354,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5267.92,
        "temperature": 0,
        "text": " There's like an amend thing, right?",
        "tokens": [
          51604,
          821,
          311,
          411,
          364,
          11704,
          551,
          11,
          558,
          30,
          51684
        ]
      },
      {
        "avg_logprob": -0.25677160614902533,
        "compression_ratio": 1.470873786407767,
        "end": 5271.599999999999,
        "id": 1355,
        "no_speech_prob": 0.0028895463328808546,
        "seek": 524312,
        "start": 5270.08,
        "temperature": 0,
        "text": " Git commit amend.",
        "tokens": [
          51712,
          16939,
          5599,
          11704,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5274.58,
        "id": 1356,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5274.08,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          50412,
          876,
          0,
          50437
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5275.86,
        "id": 1357,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5275.36,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          50476,
          13268,
          0,
          50501
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5279.5199999999995,
        "id": 1358,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5276.8,
        "temperature": 0,
        "text": " That was the most wonderful thing ever that just happened.",
        "tokens": [
          50548,
          663,
          390,
          264,
          881,
          3715,
          551,
          1562,
          300,
          445,
          2011,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5282.88,
        "id": 1359,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5280.16,
        "temperature": 0,
        "text": " This would've been so good for me to make this into a video tutorial.",
        "tokens": [
          50716,
          639,
          576,
          600,
          668,
          370,
          665,
          337,
          385,
          281,
          652,
          341,
          666,
          257,
          960,
          7073,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5287.28,
        "id": 1360,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5282.88,
        "temperature": 0,
        "text": " You, all of you who shamed me for using Adam as my text editor,",
        "tokens": [
          50852,
          509,
          11,
          439,
          295,
          291,
          567,
          402,
          3475,
          385,
          337,
          1228,
          7938,
          382,
          452,
          2487,
          9839,
          11,
          51072
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5290.32,
        "id": 1361,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5287.28,
        "temperature": 0,
        "text": " you are depriving the world of a nice standalone tutorial.",
        "tokens": [
          51072,
          291,
          366,
          27095,
          798,
          264,
          1002,
          295,
          257,
          1481,
          37454,
          7073,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5296.5599999999995,
        "id": 1362,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5292,
        "temperature": 0,
        "text": " I'm going to tweet a link to this time code in this video for people to see and find.",
        "tokens": [
          51308,
          286,
          478,
          516,
          281,
          15258,
          257,
          2113,
          281,
          341,
          565,
          3089,
          294,
          341,
          960,
          337,
          561,
          281,
          536,
          293,
          915,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5298.64,
        "id": 1363,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5296.5599999999995,
        "temperature": 0,
        "text": " Adding code for March 9 live stream.",
        "tokens": [
          51536,
          31204,
          3089,
          337,
          6129,
          1722,
          1621,
          4309,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.25535900309934456,
        "compression_ratio": 1.6124031007751938,
        "end": 5301.36,
        "id": 1364,
        "no_speech_prob": 0.00016865164798218757,
        "seek": 527312,
        "start": 5299.84,
        "temperature": 0,
        "text": " And now I'm going to close that.",
        "tokens": [
          51700,
          400,
          586,
          286,
          478,
          516,
          281,
          1998,
          300,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5302.88,
        "id": 1365,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5301.44,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50368,
          400,
          456,
          321,
          352,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5304.719999999999,
        "id": 1366,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5303.44,
        "temperature": 0,
        "text": " Git log dash one.",
        "tokens": [
          50468,
          16939,
          3565,
          8240,
          472,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5307.04,
        "id": 1367,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5304.719999999999,
        "temperature": 0,
        "text": " We can see here's my message.",
        "tokens": [
          50532,
          492,
          393,
          536,
          510,
          311,
          452,
          3636,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5312.4,
        "id": 1368,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5308.4,
        "temperature": 0,
        "text": " And now I can say git push origin master.",
        "tokens": [
          50716,
          400,
          586,
          286,
          393,
          584,
          18331,
          2944,
          4957,
          4505,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5319.44,
        "id": 1369,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5314.24,
        "temperature": 0,
        "text": " And we will go to the toy neural network.",
        "tokens": [
          51008,
          400,
          321,
          486,
          352,
          281,
          264,
          12058,
          18161,
          3209,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5323.04,
        "id": 1370,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5321.5199999999995,
        "temperature": 0,
        "text": " And I will look at the commits.",
        "tokens": [
          51372,
          400,
          286,
          486,
          574,
          412,
          264,
          48311,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5325.2,
        "id": 1371,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5324,
        "temperature": 0,
        "text": " And look, see?",
        "tokens": [
          51496,
          400,
          574,
          11,
          536,
          30,
          51556
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5326.24,
        "id": 1372,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5325.2,
        "temperature": 0,
        "text": " Ninth is right.",
        "tokens": [
          51556,
          16093,
          392,
          307,
          558,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5327.36,
        "id": 1373,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5326.24,
        "temperature": 0,
        "text": " Oh, it's running some tests.",
        "tokens": [
          51608,
          876,
          11,
          309,
          311,
          2614,
          512,
          6921,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5328.32,
        "id": 1374,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5327.36,
        "temperature": 0,
        "text": " I forgot that I have...",
        "tokens": [
          51664,
          286,
          5298,
          300,
          286,
          362,
          485,
          51712
        ]
      },
      {
        "avg_logprob": -0.3291020112879136,
        "compression_ratio": 1.515625,
        "end": 5329.92,
        "id": 1375,
        "no_speech_prob": 0.0001559797237860039,
        "seek": 530136,
        "start": 5328.32,
        "temperature": 0,
        "text": " Oh, I should've pushed it.",
        "tokens": [
          51712,
          876,
          11,
          286,
          820,
          600,
          9152,
          309,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5332.96,
        "id": 1376,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5330.08,
        "temperature": 0,
        "text": " I meant to push it to a different branch and then merge it.",
        "tokens": [
          50372,
          286,
          4140,
          281,
          2944,
          309,
          281,
          257,
          819,
          9819,
          293,
          550,
          22183,
          309,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5333.46,
        "id": 1377,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5332.96,
        "temperature": 0,
        "text": " Oh, well.",
        "tokens": [
          50516,
          876,
          11,
          731,
          13,
          50541
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5336.24,
        "id": 1378,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5335.04,
        "temperature": 0,
        "text": " At least the test passed.",
        "tokens": [
          50620,
          1711,
          1935,
          264,
          1500,
          4678,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5337.6,
        "id": 1379,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5336.8,
        "temperature": 0,
        "text": " And we can see, look.",
        "tokens": [
          50708,
          400,
          321,
          393,
          536,
          11,
          574,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5338.4,
        "id": 1380,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5337.6,
        "temperature": 0,
        "text": " See, look at this.",
        "tokens": [
          50748,
          3008,
          11,
          574,
          412,
          341,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5341.4400000000005,
        "id": 1381,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5339.12,
        "temperature": 0,
        "text": " This is the world we should be living in.",
        "tokens": [
          50824,
          639,
          307,
          264,
          1002,
          321,
          820,
          312,
          2647,
          294,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5345.28,
        "id": 1382,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5341.4400000000005,
        "temperature": 0,
        "text": " Where people write thoughtful and kind commit messages.",
        "tokens": [
          50940,
          2305,
          561,
          2464,
          21566,
          293,
          733,
          5599,
          7897,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5350.4800000000005,
        "id": 1383,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5349.6,
        "temperature": 0,
        "text": " The date is...",
        "tokens": [
          51348,
          440,
          4002,
          307,
          485,
          51392
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5351.12,
        "id": 1384,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5350.4800000000005,
        "temperature": 0,
        "text": " Right, I know.",
        "tokens": [
          51392,
          1779,
          11,
          286,
          458,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5351.68,
        "id": 1385,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5351.12,
        "temperature": 0,
        "text": " The date's below.",
        "tokens": [
          51424,
          440,
          4002,
          311,
          2507,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5352.32,
        "id": 1386,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5351.68,
        "temperature": 0,
        "text": " The date's in there.",
        "tokens": [
          51452,
          440,
          4002,
          311,
          294,
          456,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5353.12,
        "id": 1387,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5352.32,
        "temperature": 0,
        "text": " But it's fine.",
        "tokens": [
          51484,
          583,
          309,
          311,
          2489,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5353.68,
        "id": 1388,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5353.12,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51524,
          1057,
          558,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5354.4800000000005,
        "id": 1389,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5353.68,
        "temperature": 0,
        "text": " I've got to go.",
        "tokens": [
          51552,
          286,
          600,
          658,
          281,
          352,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.3653003781340843,
        "compression_ratio": 1.5809128630705394,
        "end": 5356.08,
        "id": 1390,
        "no_speech_prob": 0.0005112523213028908,
        "seek": 532992,
        "start": 5354.4800000000005,
        "temperature": 0,
        "text": " I even just got a calendar warning.",
        "tokens": [
          51592,
          286,
          754,
          445,
          658,
          257,
          12183,
          9164,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5364.4,
        "id": 1391,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5360.88,
        "temperature": 0,
        "text": " I've got to read some random numbers.",
        "tokens": [
          50412,
          286,
          600,
          658,
          281,
          1401,
          512,
          4974,
          3547,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5368.64,
        "id": 1392,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5364.4,
        "temperature": 0,
        "text": " Reminder that I'll be back on March 14th for Pi Day.",
        "tokens": [
          50588,
          4080,
          5669,
          300,
          286,
          603,
          312,
          646,
          322,
          6129,
          3499,
          392,
          337,
          17741,
          5226,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5373.84,
        "id": 1393,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5368.64,
        "temperature": 0,
        "text": " Submit your Pi Day coding challenge ideas to rainbow topics.",
        "tokens": [
          50800,
          8511,
          3508,
          428,
          17741,
          5226,
          17720,
          3430,
          3487,
          281,
          18526,
          8378,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5375.2,
        "id": 1394,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5373.84,
        "temperature": 0,
        "text": " Link in the description below.",
        "tokens": [
          51060,
          8466,
          294,
          264,
          3855,
          2507,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5377.28,
        "id": 1395,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5375.92,
        "temperature": 0,
        "text": " 7,785.",
        "tokens": [
          51164,
          1614,
          11,
          22,
          19287,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5378.4800000000005,
        "id": 1396,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5377.28,
        "temperature": 0,
        "text": " 2,854.",
        "tokens": [
          51232,
          568,
          11,
          19287,
          19,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5380,
        "id": 1397,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5378.4800000000005,
        "temperature": 0,
        "text": " 91,971.",
        "tokens": [
          51292,
          31064,
          11,
          23247,
          16,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5381.4400000000005,
        "id": 1398,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5380,
        "temperature": 0,
        "text": " 63,537.",
        "tokens": [
          51368,
          25082,
          11,
          20,
          12851,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5383.04,
        "id": 1399,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5381.4400000000005,
        "temperature": 0,
        "text": " 84,671.",
        "tokens": [
          51440,
          29018,
          11,
          22452,
          16,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5384.24,
        "id": 1400,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5383.04,
        "temperature": 0,
        "text": " 3,517.",
        "tokens": [
          51520,
          805,
          11,
          20,
          7773,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5385.52,
        "id": 1401,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5384.24,
        "temperature": 0,
        "text": " 28,914.",
        "tokens": [
          51580,
          7562,
          11,
          24,
          7271,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5386.72,
        "id": 1402,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5385.52,
        "temperature": 0,
        "text": " 48,762.",
        "tokens": [
          51644,
          11174,
          11,
          25026,
          17,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5387.92,
        "id": 1403,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5386.72,
        "temperature": 0,
        "text": " 76,952.",
        "tokens": [
          51704,
          24733,
          11,
          15718,
          17,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5389.12,
        "id": 1404,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5387.92,
        "temperature": 0,
        "text": " 76,837.",
        "tokens": [
          51764,
          24733,
          11,
          23,
          12851,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.18193752559151236,
        "compression_ratio": 1.291866028708134,
        "end": 5389.4400000000005,
        "id": 1405,
        "no_speech_prob": 0.07584867626428604,
        "seek": 535992,
        "start": 5389.12,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51824,
          1057,
          558,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5390.48,
        "id": 1406,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5389.44,
        "temperature": 0,
        "text": " I read some random numbers.",
        "tokens": [
          50364,
          286,
          1401,
          512,
          4974,
          3547,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5394.4,
        "id": 1407,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5393.04,
        "temperature": 0,
        "text": " And I'm going to put this song on.",
        "tokens": [
          50544,
          400,
          286,
          478,
          516,
          281,
          829,
          341,
          2153,
          322,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5396.32,
        "id": 1408,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5395.5199999999995,
        "temperature": 0,
        "text": " Goodbye, everyone.",
        "tokens": [
          50668,
          15528,
          11,
          1518,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5399.839999999999,
        "id": 1409,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5396.32,
        "temperature": 0,
        "text": " But it now has a different commit date to its creation date or something.",
        "tokens": [
          50708,
          583,
          309,
          586,
          575,
          257,
          819,
          5599,
          4002,
          281,
          1080,
          8016,
          4002,
          420,
          746,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5400.5599999999995,
        "id": 1410,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5399.839999999999,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50884,
          876,
          11,
          3237,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5401.2,
        "id": 1411,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5400.5599999999995,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50920,
          286,
          500,
          380,
          458,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5402.32,
        "id": 1412,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5401.2,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50952,
          286,
          500,
          380,
          458,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5405.36,
        "id": 1413,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5402.32,
        "temperature": 0,
        "text": " Just I can't get it right, everybody.",
        "tokens": [
          51008,
          1449,
          286,
          393,
          380,
          483,
          309,
          558,
          11,
          2201,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5406.4,
        "id": 1414,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5405.36,
        "temperature": 0,
        "text": " It is what it is.",
        "tokens": [
          51160,
          467,
          307,
          437,
          309,
          307,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.19317235355883572,
        "compression_ratio": 1.517094017094017,
        "end": 5416,
        "id": 1415,
        "no_speech_prob": 0.005301588214933872,
        "seek": 538944,
        "start": 5407.5199999999995,
        "temperature": 0,
        "text": " Thank you to Darius Kazemi, who gave me a lot of great tips on open source stuff in the last couple weeks.",
        "tokens": [
          51268,
          1044,
          291,
          281,
          413,
          27440,
          16264,
          13372,
          11,
          567,
          2729,
          385,
          257,
          688,
          295,
          869,
          6082,
          322,
          1269,
          4009,
          1507,
          294,
          264,
          1036,
          1916,
          3259,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5423.12,
        "id": 1416,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5416,
        "temperature": 0,
        "text": " I'm working, by the way, on an idea for a course about contributing to open source that I want to teach next year at NYU.",
        "tokens": [
          50364,
          286,
          478,
          1364,
          11,
          538,
          264,
          636,
          11,
          322,
          364,
          1558,
          337,
          257,
          1164,
          466,
          19270,
          281,
          1269,
          4009,
          300,
          286,
          528,
          281,
          2924,
          958,
          1064,
          412,
          42682,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5425.28,
        "id": 1417,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5423.12,
        "temperature": 0,
        "text": " I have a GitHub repository with ideas in it.",
        "tokens": [
          50720,
          286,
          362,
          257,
          23331,
          25841,
          365,
          3487,
          294,
          309,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5426.96,
        "id": 1418,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5425.28,
        "temperature": 0,
        "text": " At some point, I'll publish it.",
        "tokens": [
          50828,
          1711,
          512,
          935,
          11,
          286,
          603,
          11374,
          309,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5428.24,
        "id": 1419,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5426.96,
        "temperature": 0,
        "text": " You could find it, probably, if you want.",
        "tokens": [
          50912,
          509,
          727,
          915,
          309,
          11,
          1391,
          11,
          498,
          291,
          528,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5430.8,
        "id": 1420,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5428.24,
        "temperature": 0,
        "text": " But I'm soliciting contributions and ideas for that.",
        "tokens": [
          50976,
          583,
          286,
          478,
          23665,
          1748,
          15725,
          293,
          3487,
          337,
          300,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5437.04,
        "id": 1421,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5432.32,
        "temperature": 0,
        "text": " And I will continue to make more video tutorials.",
        "tokens": [
          51180,
          400,
          286,
          486,
          2354,
          281,
          652,
          544,
          960,
          17616,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5438.16,
        "id": 1422,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5437.04,
        "temperature": 0,
        "text": " I'll be back next Wednesday.",
        "tokens": [
          51416,
          286,
          603,
          312,
          646,
          958,
          10579,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.20382338303786057,
        "compression_ratio": 1.5811688311688312,
        "end": 5445.44,
        "id": 1423,
        "no_speech_prob": 0.6074240207672119,
        "seek": 541600,
        "start": 5438.16,
        "temperature": 0,
        "text": " There will be a surprise for you, because I am going to shortly record a guest video for the Coding Train channel.",
        "tokens": [
          51472,
          821,
          486,
          312,
          257,
          6365,
          337,
          291,
          11,
          570,
          286,
          669,
          516,
          281,
          13392,
          2136,
          257,
          8341,
          960,
          337,
          264,
          383,
          8616,
          28029,
          2269,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.25912039620535715,
        "compression_ratio": 1.28125,
        "end": 5447.04,
        "id": 1424,
        "no_speech_prob": 0.0014323886716738343,
        "seek": 544544,
        "start": 5445.44,
        "temperature": 0,
        "text": " It will come out sometime in the next couple weeks.",
        "tokens": [
          50364,
          467,
          486,
          808,
          484,
          15053,
          294,
          264,
          958,
          1916,
          3259,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.25912039620535715,
        "compression_ratio": 1.28125,
        "end": 5449.12,
        "id": 1425,
        "no_speech_prob": 0.0014323886716738343,
        "seek": 544544,
        "start": 5447.599999999999,
        "temperature": 0,
        "text": " So stay tuned for that.",
        "tokens": [
          50472,
          407,
          1754,
          10870,
          337,
          300,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.25912039620535715,
        "compression_ratio": 1.28125,
        "end": 5452.16,
        "id": 1426,
        "no_speech_prob": 0.0014323886716738343,
        "seek": 544544,
        "start": 5449.12,
        "temperature": 0,
        "text": " And I'll see you all.",
        "tokens": [
          50548,
          400,
          286,
          603,
          536,
          291,
          439,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.25912039620535715,
        "compression_ratio": 1.28125,
        "end": 5457.919999999999,
        "id": 1427,
        "no_speech_prob": 0.0014323886716738343,
        "seek": 544544,
        "start": 5457.12,
        "temperature": 0,
        "text": " I'm still here.",
        "tokens": [
          50948,
          286,
          478,
          920,
          510,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.25912039620535715,
        "compression_ratio": 1.28125,
        "end": 5459.839999999999,
        "id": 1428,
        "no_speech_prob": 0.0014323886716738343,
        "seek": 544544,
        "start": 5458.5599999999995,
        "temperature": 0,
        "text": " I'm looking at my phone now.",
        "tokens": [
          51020,
          286,
          478,
          1237,
          412,
          452,
          2593,
          586,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.25912039620535715,
        "compression_ratio": 1.28125,
        "end": 5473.759999999999,
        "id": 1429,
        "no_speech_prob": 0.0014323886716738343,
        "seek": 544544,
        "start": 5472.96,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          51740,
          1057,
          558,
          11,
          2201,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5475.76,
        "id": 1430,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5474.56,
        "temperature": 0,
        "text": " I'm going to hit stop streaming now.",
        "tokens": [
          50404,
          286,
          478,
          516,
          281,
          2045,
          1590,
          11791,
          586,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5481.52,
        "id": 1431,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5478.72,
        "temperature": 0,
        "text": " So I probably won't return to the neuroevolution thing next week.",
        "tokens": [
          50612,
          407,
          286,
          1391,
          1582,
          380,
          2736,
          281,
          264,
          16499,
          13379,
          3386,
          551,
          958,
          1243,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5482.72,
        "id": 1432,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5481.52,
        "temperature": 0,
        "text": " That'll come two weeks from now.",
        "tokens": [
          50752,
          663,
          603,
          808,
          732,
          3259,
          490,
          586,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5485.68,
        "id": 1433,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5482.72,
        "temperature": 0,
        "text": " So the next live stream, there will also be a guest two weeks from now.",
        "tokens": [
          50812,
          407,
          264,
          958,
          1621,
          4309,
          11,
          456,
          486,
          611,
          312,
          257,
          8341,
          732,
          3259,
          490,
          586,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5489.6,
        "id": 1434,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5485.68,
        "temperature": 0,
        "text": " I mean, I have a lot of guests scheduled that I'm excited about, like three or four so far coming up.",
        "tokens": [
          50960,
          286,
          914,
          11,
          286,
          362,
          257,
          688,
          295,
          9804,
          15678,
          300,
          286,
          478,
          2919,
          466,
          11,
          411,
          1045,
          420,
          1451,
          370,
          1400,
          1348,
          493,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5490.08,
        "id": 1435,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5489.6,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51156,
          2264,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5495.52,
        "id": 1436,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5491.04,
        "temperature": 0,
        "text": " Next live stream, Wednesday, March 14, probably in the morning of my time.",
        "tokens": [
          51228,
          3087,
          1621,
          4309,
          11,
          10579,
          11,
          6129,
          3499,
          11,
          1391,
          294,
          264,
          2446,
          295,
          452,
          565,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5500,
        "id": 1437,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5495.52,
        "temperature": 0,
        "text": " And then March, whatever it is, like 23rd, I think, is the next Friday.",
        "tokens": [
          51452,
          400,
          550,
          6129,
          11,
          2035,
          309,
          307,
          11,
          411,
          6673,
          7800,
          11,
          286,
          519,
          11,
          307,
          264,
          958,
          6984,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5500.4800000000005,
        "id": 1438,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5500,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51676,
          1057,
          558,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.31636101472462325,
        "compression_ratio": 1.664406779661017,
        "end": 5501.04,
        "id": 1439,
        "no_speech_prob": 0.0019875771831721067,
        "seek": 547376,
        "start": 5500.4800000000005,
        "temperature": 0,
        "text": " Goodbye, everybody.",
        "tokens": [
          51700,
          15528,
          11,
          2201,
          13,
          51728
        ]
      }
    ],
    "transcription": " Hello, good afternoon. Welcome to part 2 of today's Coding Training Live Stream Internet Coding Show Episode... thing. My name is Dan and I will be here with you for the next approximately one hour and thirty minutes. I don't have the YouTube chat going, I just realized, so let me see if I can pull that up. Alright. I don't see anybody say anything, like you see me and you hear me, but I assume that I am live streaming. So what's going to happen? So first of all, welcome. I think I already said that. Okay, yes, I see that there are people in the chat. This morning I spent some time talking about my new favorite subject, linting. Universal sign for linting. My phone is... notification. YouTube notification. YouTube notification. Watch now! The Coding Train is live! I got a notification. I probably always get that, I don't notice. So this morning I talked a little bit about linting, which is kind of new. I did a little video about GitHub, not GitHub, sorry, Gitremotes, one of which can be a GitHub repository and you can have multiple different... the same repository as part of different accounts on GitHub as different remotes. Boy, that was like, it was like a thrilling topic, the crowd was in front of me, they were standing, they were cheering, it was suspenseful, they were crying, there were tears. And no, it was me with the terminal typing like, Gitremote ad. But, you know, someday we can all dream, can't we? That I'll be here with my tuxedo and the masses out there will be with their laptops coding along, tears, because they're so moved by the Coding Train. No, no, yeah, very unlikely. Now, I'm really not sure, I think I better stick to what I said I was going to do because I know that'll be disappointing, but I'm a little bit concerned with the smallish amount of time that I have, so I'd like to just get started. But, let me make an announcement. There will be no, this is the bad news, there will be no Coding Train next Friday, March 16th. However, the good news is, there will be a Coding Train next Wednesday, March 14th, which as you may know is Pi Day 3.14. So, I'm going to be out of town on Friday, I'm not available. Scratch that, I'm not going to be available on Friday. Edit that out, never mind. I'm going dark on Friday. I'm not available on Friday, but I will be, what am I, what am I saying here? Yes, but I will be on Wednesday, and since it's Pi Day, I thought what I would do is do some Pi themed coding challenges. I was hoping that maybe I could also have somebody, I'll come here with like an actual Pi, and I could open the door and I could get like the sort of the Pi in the face thing. Anybody knows a way for me to make that happen? I think that'll be an excellent thing to do on Elias Dream on Pi Day. But I'm looking for, what I'm looking for are suggestions for things that are simple, like phylotaxis is a good example of that. It's a little algorithm, it's kind of got Pi in it. Blueberry Pi, my favorite kind of Pi. And so some things that I might, I know that Stand Up Maths, the YouTube channel, Matt Parker did an interesting video I think last year about calculating all the digital digits of Pi. Maybe I could make a piece of code that does that and displays them in the browser. So, so I am, yeah, maybe do Python, no. That does not count. Python does not count as something for Pi Day, especially because I, I mean actually it does, it totally does, but I don't know if that's going to happen. But, so I would like to take your suggestions. So where can you leave your suggestions for, let's do this for now. Rainbow Topics. I probably should come up with a better system, but I am going to create a new issue, Pi Day Coding Challenge Suggestions. Please add your suggestions for a Pi Day Coding Challenge in the comments below. And, you know, maybe we can do some kind of like, I guess I could do like a, maybe I should do a Reddit, subreddit thread, because there is a Coding Train Reddit. Should we try that? I don't know, I'm so used to GitHub. I'll close this and move it there if somebody has a better suggestion. But I'd like to, let me just do this right now. So you could add your suggestion here on GitHub and then people can like, thumbs up the ones that they like and I can kind of look through and pick them that way. You could do a tag on the GitHub topics. I could also do that. That might be better for me to just do a label. Yeah, let's not do it in the comments. Let's close this issue. Never mind. Let's use a label. I just thought it might be nice to be able to see them all in one place, but with labels you can do that. Let's use a label instead. All right, the trolls are out in full form today. Let's quickly, quickly lock this conversation. It's too heated. It's definitely too heated. And let's add a label. Oh, let's go to issues, labels, new label, Pi Day. Challenge for three. I'm going to do this because this is the kind of person I am. I'm going to put my date with the day, then the month. That's what I'm going to do. And I'm going to, let's get a color here. Oh, that's perfect. Okay, so now you can file an issue and I will label it as Pi Day, like this. Okay, so send me your, now, next up, moving right along. Let's see, am I in the correct directory? Let's just see what's been merged. Thank you again to Miyamasa-mi, who's been merging some, oh, merging some of these Flappy Bird pull requests, pull GitHub master. And we got some stuff. I think we have some unicorn horn pipes. Loading, loading, loading. Horn filled flipped.png. Looks like we're missing a file. Let's see what I can figure out there. Graphics, horn body filled, horn tip filled, horn body filled, horn tip filled, ooh, horn tip filled flipped. Do I need that one? Paint pant dot, ooh, horn tip filled, horn tip, oh, those are like, I don't know what that is, paint dot net. These were made by a GitHub user. These were made by GitHub user. Just want to, K1J Julian, K1G Julian, King Julian. And we can see them here, these lovely unicorn horns. So I'm a little bit concerned. I might really actually just want to replace these with just like drawn rectangles, mostly because I'm a little concerned about having the collision. I don't want to introduce extra complexity with the collision detection. Maybe Miyamasa-mi, maybe. Whoops, git pull, git pull. I can't, like I almost can't do it without saying origin. I just keep, until somebody fixes it, why do I just keep doing this? I'm just kidding, just kidding. Let's take a look here. Let's look at the pipe. Where is it being drawn? Draw, oh boy, this became incredible, this became very complicated. The good news is I was okay with all this becoming complicated because it's all just in the pipe class and I actually don't really mind if the pipe class is the super complicated thing because what I need to demonstrate will happen, can be applied to any game whether the code is very simple or complicated. So let me see here, what is the image that's missing? I'm sure there's a crack team of coders working, okay now it's fixed. Okay, thank you Miyamasa-mi. Let's, there we go. Looks like we've got that fixed. Let's go here and there we go. So now we have our beautiful Flappy Bird game so slow on my machine. And so let's see about this collision stuff. Yeah, that makes sense but let's see, let's see, let's see. Yeah, so it's using the rectangle up to the height of the tip of the unicorn horn. Almost look like candy here but yeah, I'm going to change these to rectangles. I can't tolerate it. I'm sorry everybody. This is, I really like these designs and I will maybe come back to them. If, I don't know if Miyamasa-mi, while you're watching, if you, while I'm kind of getting, I'm going to explain the GitHub, maybe make it a separate branch or just like push these unicorn horns into another branch. But let's just make these a nice purple, green, blue, rainbow colored rectangles. There's also something that's running really slow and I don't know why because it's not, yeah, it's running at 30 frames per second which is reasonable. So let's do that. If anybody can do a pull request, so because I think these are a problem. They're lovely, beautiful unicorn horns but I think the collision stuff and yeah, they kind of, they resemble the poop emoji but they're pink. There's, you know, there's a lot of, there's a lot of, it's just going to, I'm just going to be uncomfortable the entire time. Okay. Use Vim instead of Atom. Okay, let's get, let me, let's go over to the whiteboard for a minute here and let's do some erasing or let's not do some erasing. Hmm. I'm thinking. So I want to talk about neuro, I want to talk about neuro evolution and I think that to start talking about neuro evolution, it wouldn't be the worst thing in the world for me to have my leftover ending diagram from the doodle classification example because one of the key things I want to talk about is the difference between, train whistle? What about like a train whistle for the pipe? Here, somebody can like, right, I don't know, just make it a, just a rectangle, a plain rectangle. Okay. Is the chat going on in here? Okay. So what I want to talk about is how back propagation and gradient descent, while the sort of standard or probably most well-known technique for training the weights of a neural network is not the only technique. And so having this as a reference is good and then I need to, I'm just going to, and then what I'll do is erase this and diagram out how a genetic algorithm can be used to train a neural network. Okay. So I think I'm going to get started with this right now. Let's, let's take a look here. Oh, let's look at Simon's pull request. So here's the thing. This is very useful. Thank you, Simon, for this. I'm going to not, oh, I'm going to not merge this right now because I want to, I'm going to have to sort of like, the mechanics of the way the game works once I'm doing the evolution thing is going to be pretty different. Okay. Okay. Just push to change back to pipes. Great. Thank you. So now I'm going to do this, get pull origin master, get pull. I just rename it back to origin. And let's go here. There we go. Oh, look at those green pipes. Perfect. Oh, green pipes. Everything is right with the world. This is very, quite a hard to play, but I'm also probably in the end going to change this into circles, but okay. So that's good. I also, let me just see something here. Yeah, no, this is great. Okay. Perfect. Okay. Thank you for that. Now let us begin. I'm trying to think if I want to, what am I doing here? Let's go to, so I'm going to go away from flappy bird for a second. Let's get rid of this. Come on, computer. Terminate you. Okay. Then I want to open this up and Adam. What's going on in here? I guess I changed some stuff at one point. And I need the neural network library and let's get XOR. So desktop neural network coding train. Am I in the wrong? I've been in the wrong camera screen all this time again, as I always am. Sorry, everybody. Sorry, everybody. Sorry, everybody. I don't know. I'm doing my best. I'm doing my best. Okay. Let's see. What do I need now? Examples XOR. Let's copy paste that and let's just do, let's call neuro evolution. So I'm going to have an example and I'm going to, I want to do it with XOR, but but let's leave that out for right now. Okay. All right. And so now I also want to, I want to, whoa. Yeah. No kidding. Examples, doodle classification. Oops. Train. All right. All right. Test. Pretty good. Let's look at the rainbow here. Here we go. All right. So that's going to be, okay. So this is weirdly, not you for when you and everybody watching. This is weird. This is a new chapter that I, so the nature of code book, if I go to the book's website, I'm currently working on a, the chapter nine is all about genetic algorithms and I have a video tutorial series about genetic algorithms. Chapter 10 is about the basics of neural networks and the content that's currently in the book at the moment is pretty, it's from 2012. A lot's happened in the field of machine learning since then, you might've noticed. And so I'm trying to rewrite this chapter and I've been making these video tutorials and examples in this neural network library and working on this other thing called ML5, which is built on top of DeepLearn JS, all of which I am trying to get through and to do more and more stuff with. That I'm currently working on as part of a new chapter 10 and now. So chapter nine being about genetic algorithms, I think calling it the evolution of code is sort of silly and I should just call it evolutionary computing or genetic algorithms, but that aside, chapter 10 about neural networks, chapter 11, which does not exist, is going to be about using genetic algorithms with neural networks. So I'm about to start the first video for chapter 11 and repeat exactly what I just said because I think that would be useful just for part of the context. Because weirdly, typically in the past, for all my other nature of code content, the book came first and the videos came after the fact. And this is a little bit strange that I'm going to make the videos and then hopefully write that content into the book. All right, so I'm about to get started and I will get started. I'm just looking at my phone because, ah, because as I mentioned, I have a very exciting guest video that will be released to this channel hopefully next week sometime, but certainly sometime in the next week or two. And that guest is coming to record at around 5 p.m. today. So I've got to finish up by then. And just in case you were on the fence whether you wanted to be a patron of the Coding Train, sometimes, especially when I have guests, I'll keep a live stream going just to get a backup onto YouTube and I'll let people in the patron group kind of listen in on that as well. But don't worry, there's no need to be a patron of the Coding Train. The video will be released. But if you like a little advanced stuff, water. No, I don't have any water. This liquid beverage will have to do. It's so slurpy. Can you hear that? That's like terrible. Coding Train brought to you by anonymous cup of coffee. I usually don't drink coffee while I'm live streaming because it only leads to bad things. But every once in a while, it's just necessary. All right. So let's close this out. Let's leave. Whoops. What did I do? No, I don't want you to move anything. Let's leave this here. Move this out here. I'm just getting everything ready. Come on. Come on, Adam. Behave. I'll do this. Okay. All right. Here we go. Oh, yeah. It's fine. It's fine. I don't have a marker, but I will. I don't know if I need one this second, but it's like a... Some people have like a lovey or a teddy bear. That's their comfort object. It helps them sleep at night. I have a whiteboard marker. It's my comfort object. Hello. Welcome to the first video in a new chapter of the book, Nature of Code, chapter 11. Only strangely, chapter 11 does not exist. So I'm doing something a little different here, where all my previous other Nature of Code videos that go along with this Nature of Code book, the book was written first, came out in 2012. And this is the current version of it. And then I made videos after the fact. Now, what I'm going to do, I want... So chapter 9 is about genetic algorithms and chapter 10 is about neural networks. And I have a bunch of videos that go along with both of those chapters. Today, I'm going to start talking about something that I want to be in the next edition of the Nature of Code in chapter 11 called neuroevolution. So I want to take the idea of a genetic algorithm and a neural network and use them together in a magical way to make wonderful things happen on the screen. Or it doesn't have to even be on a screen in some other capacity that I can't even imagine right now. So what is neuroevolution? It's a very simple question. So what is it that I am going to do? So first of all, okay, so if you... wrong keyboard. If you have watched some of my other neural network tutorials, the most recent thing before the recording of this video that I made was a doodle classifier. It's kind of the classic machine learning classification example. I have some images, maybe they're handwritten digits, maybe they're doodles of cats and rainbows and unicorns and all that sort of stuff. I want to feed those things into a neural network and I want the neural network to classify them. And if you've watched those videos, you might have noticed that there's this whole elaborate training process. The training process involves making that guess, having some labeled correct data, and then feeding that and then looking at the error, like what is it supposed to be versus what it guessed and feeding that error back through the neural network. Just time out for a second. Okay, these messages, I really take seriously the at messages to my watch. So little notes to me. Don't little... thank you for the kind comments. Okay, come back, come back to my momentum. So try not to direct message me during the live stream. I probably should set up a separate Slack user that just sends the notifications so that regular other messages don't get here. All right, all right, all right. Let's see here. Looking at the guess output versus the correct label, calculating an error and setting that error backwards through the network through a process known as back propagation, where all of the weights are tuned and changed. So while this is the most well known and probably most common and sort of standard technique for training a neural network, back propagation with gradient descent, very fancy sounding, there are many other ways. I mean, there's other ways that you can train a neural network, one of which is using a genetic algorithm. So what if we just threw away all of that calculus math and all of this sort of like error this, error that, and back propagation this, and we just said, hey, I've got an idea. Why don't I make, instead of having one neural network, why don't I make a thousand of them, and I'll try them all. Maybe some of them will classify image, maybe one will classify images better than another one does. Maybe I'll keep that one. And one just gets everything wrong, maybe I won't keep that one at all. And maybe I'll pick from the ones that kind of do well, and take those and duplicate them or mix them up to make a new population of neural networks and see how those do. And this is the central idea of a genetic algorithm. Now, I might suggest if you want to, if genetic algorithms are totally new to you, you might want to pause this video right now and go watch my genetic algorithm tutorials. If the concept of a neural network is totally new to you, you could pause and go watch those tutorials, but you could probably also just keep going because I'm going to cover almost all of this stuff anyway, kind of as I try to sort this out. So I'm going to take a break for a minute. I'm going to erase this whiteboard here, what's there right now, left over from the doodle classification, and then I'm going to diagram out how a neural network can be trained using a genetic algorithm, and then through that diagram, I will discover things I need to add to my neural network code base. And at some point, if all goes according to plan, you know, I have this particular, this was the doodle classifier example, which you see here, it's classifying my rainbow. But what I want to do is take this version of the game, Flappy Coding Train, it's not very flappy, I guess, and see if I can use a neural network that evolves to play this particular game. So that's going to be the goal of this series, and then I have all sorts of other ideas for other types of neuroevolution tutorials. I believe this is often also referred to as NEET. NEET algorithm, because it's NEET, neuroevolution of, and see, here's the thing, I was just saying neuroevolution, and all the while, it could sound so much smarter by saying neuroevolution of augmenting topologies. That's totally NEET. All right, be back in a minute. Okay, I'm looking at the chat, everything seems okay. So now what I need to do is go erase this. Man, this copy is so slurpy. All right, so let's do some erasing. If anyone has any questions. I knew there was a reason why I didn't erase this whiteboard for like two weeks. Should I mute my microphone? Is this like some horrible scratching sound that I'm making into? It's really better if I erase it immediately after I use it. Look at all this. Oh, it's so... Anybody has any suggestions? Maybe there's like a squeegee company I could hire to come in here and just like make this shiny and new spick and span. You know, I said earlier today that my passion in life is indentation and spacing. And this is why linting, this idea of linting your coat is bringing such joy and happiness to me. And yet, in this moment right now, I think I might have discovered that my true passion is whiteboard erasing. There's nothing more soothing and meditative and relaxing than just a little cleaner. Look at the whiteboard. Look at the whiteboard. It's a good exercise. It's good physical therapy for my broken elbow that has pretty much healed all the way. Almost there. Just water. Make my hair look nicer. No nasty chemicals. No cleaning anything. Just a little water and a paper towel. Paper towel isn't so good for the earth, but I guess the earth will have to survive using some paper towels. Maybe I can get a nice cloth or rag that's more reusable. How am I doing? How's this whiteboard look to you? Is it all clear? It's pretty dirty, to be honest with you. I don't know what it looks like. Yeah, you can see all those smudges and things. I'm sure you'll want to edit a highlight reel of me erasing the whiteboard. You can do one of those things in the video where you do it really, really fast instead of just doing a jump cut. We got to up our coding train game here. I'm glad to see that the chat has moved on from discussing which coding language is the best to how to effectively clean a whiteboard. The chat's actually not discussing that. That's what I wish for. People are still like, I'm not sure what I'm doing. I'm just trying to get it right. I'm trying to get it right. I'm trying to get it right. I'm trying to get it right. I'm trying to get it right. I wish for. People are still like, discussing MATLAB versus Pascal versus Java. And yes, do you think I could have a YouTube channel where I just clean stuff and I'm like happy about it all the time? I would really like that. I've been thinking of starting a gaming channel because I recently acquired a Nintendo Switch. My kids and I, we play it a lot. And I was thinking, I don't know, maybe I'll make a gaming channel. That's all the rage. I'm like a 44 year old human who can have a YouTube gaming channel. People might watch, probably not. That's a terrible idea. Okay. I don't know how to set that up. I got to like get the output into the input to the output. This sort of thing. A Twitch channel. I'm a little bit afraid of Twitch, but I am a kind of a Twitchy person. All right. Let's see. Take a second. I'm getting a very excellent suggestion in the chat. Take a second and mark the edges of the whiteboard so you don't draw off the camera. But what would be the fun in that? We should be living on the edge here, don't you think? All right. Let's see. Let's make this happen. Yeah, I think I'm kind of all, for better or worse, I don't think that I can manage to like do different platforms. I've kind of got the YouTube thing going, so that's probably what I'm going to stick with. I don't know. I'm always conflicted about this sort of thing. Okay. Let me use a different color to mark the edges. This is actually already marked up here. I do actually have some markings already. This is marked here. This is probably more correct. This is marked down here. Is that right? Let me see here. I promise I can't see my monitor. Down, down, down, down, down, down, down. There. And over here, maybe. Over here. This is really the important one. This is the one that I mess up all the time. Can you see that line? It should be where the tip of my finger is. I think I got it right. Okay. Now that'll hopefully do. So I'm just checking the chat. Doesn't your current streaming setup not take the output into the input? It does. The output goes into the input here. Uh-huh. It does. It totally does. And then that input goes back to the output and back into a different input also. I'm really... The input output thing is totally working. I have all the plugs going from one electronic machine to the other electronic machine, and they're connected to the internet tube. That's how I'm live streaming. That's how I'm live streaming. So I could probably set that tube input output plug-based system up in my place of residence. I should really get going with some content. What time is it? 3.55. Okay. Okay. Okay, everyone. Okay. So let's... Okay. Now that I have a... Now that I have a blank whiteboard, let me review the steps of a genetic algorithm and think of them in the context of a neural network. So the first thing in a genetic algorithm that I need to do is create a population. And the population is going to be a whole lot of neural networks. Neural networks are the individual elements. So maybe my population is 100 neural networks. Two. I need to evaluate fitness of neural networks. Okay. So this is kind of like... Again, this is kind of like the setup. I know that's kind of getting close to the top there. It's the thing that I'm going to do once at the beginning of the program, my sort of initialization state. Then this is this thing that I'm going to do for a loop. Generation after generation in p5, this might be called the draw loop. I'm going to evaluate the fitness of all the neural networks. And then create a new population. And the way I will do that is by pick quote unquote parents based on... My handwriting is getting worse and worse over time. Based on... Pick parents based on fitness scores. Map to probability. I have so much room in this direction. Probability. And then I want to apply a crossover, which is a way... If I pick two parents, for example, I can take half of their so-called digital DNA of one, half of the other, or some random amount of one, random amount of another, and combine them into a new entity. And then I can apply mutation, which would be... Which is the step of saying, hey, let me look at the DNA. Let me... I have this child DNA that is made from two parents. Let me randomly just change some of it up as if it's spontaneously mutating to continue to have variation in the system. So again, you could go watch my genetic algorithm tutorials where I describe all this stuff in much greater detail. Much greater detail of different techniques and why and how. But this is the basic idea. But you might remember, if you did watch those tutorials, that this is kind of like the algorithm. And it... Obviously, you can change it and be creative with it, but it's kind of somewhat of a standard. The really tricky thing when you're making your own genetic algorithm and applying it to your own project is as follows. Number one is this idea of genotype versus phenotype. What is that so-called digital DNA? The genotype. What is the data of that DNA? And what does that data do? How does it express itself into a system? So this is really key in thinking, okay, well, the neural network is somehow the genotype. What could be the data? So in fact, thinking back to my simplest neural network, just has two layers, really, a hidden layer and output layer. The inputs come into the hidden layer. They get processed from the hidden to the output. They get processed, and then we have a final result. So the core elements of those layers are weights and biases. So all the weight matrices and the bias vectors, those things, which I describe in detail in my neural network tutorials, make up the genotype of the neural network, the core aspect of it. Now, the phenotype is the expression. It's really, really, what am I using the neural network for? So for example, the expression of the neural network might be in the game Flappy Bird, the decision whether to jump or not jump. That's the expression. That's how it's going to be used, applied in a given scenario. In a classification example, it could be it's classifying an image. That's how the data from the neural network is going to be used to make a guess based on this image and turn it into a string. So that's aspect number one. We've got that. So what that means is when I write the code, I need to somehow figure out how to do crossover and mutation with weights and biases. I think I can create probably a population of random neural networks. That's just going to be like new neural network, new neural network, new neural network. Evaluating the fitness I've got to get to, I can pick two random ones, but I need to apply crossover mutation. And to be honest, what I might do at first in my first implementation is not even bother with crossover and not even bother with picking more than one parent. So one technique to simplify the genetic algorithm is just to make copies. So I can pick the good ones and make copies of them, mutate a little bit and keep going. It might not work as effectively as if I use crossover, but it'll certainly be easier to code. So the other thing that's tricky with when you're making your own genetic algorithm and applying it to your own project is the fitness function. Question mark, question mark, question mark. So this is crucial. If you don't have a good fitness function, this whole selection process, this quote unquote natural slice, not very natural here, it's like digital selection. I'm not going to be able to distinguish between members of the population that do really well that should be that their digital DNA should be passed down to the next generation versus ones that don't. So I want a good fitness function that gives me a good range of probabilities. And so in this case, we could think about the classification. It could be, okay, well, this neural network, give it 100 images, its fitness is how many of those it classified correctly. We could even go into it deeper and somehow score the fitness according to its confidence level about classifying them correctly. But that might be flawed in some ways also. So that's one thing. With the flappy bird scenario, if we think about the flappy bird game, what is the fitness here? Well, the fitness would simply be the score. So I'm a neural network. I am a neural network playing flappy coding train now, beep beep, boop boop, input, output, beep boop. Am I still like recording a video tutorial? So it could just be like, how long am I able to go through this world without running into a pipe? So that could be the fitness. So I could say, hey, why don't you 1,000 of you try playing this game? 1,000 of you electronic neural network magic machines try playing this game and your fitness is how long you last before you run into a pipe. And so that is the fitness function. So we have all the pieces. So what do I have already? Like if I'm going for this flappy bird example, I already have the flappy bird game. So I have the flappy bird code. I have my genetic algorithm examples, but ultimately, there's not really, I don't really have a genetic algorithm library per se. So I'm probably gonna have to build the genetic algorithm stuff in the code. But I do have a neural network library. So I don't have to write, I don't have to write the flappy bird game. I don't have to write the neural network library. However, it might make sense for my neural network objects to know about crossover and mutation. That might be something that probably should go into the neural network library so that at any moment I could say like, hey, you neural network and you neural network, get together, make another one. Or hey, you neural network, mutate yourself. So I probably should, that's something, so that's the first thing I think I'm gonna do in the next video is add crossover and mutations or maybe to start more simply, I'm just gonna start with like a copy function just to kind of get going here, a copy function and mutation. So those things need to go into the neural network library and then the third thing is I just need to apply the GA. So this I really need to do a lot of work to write the genetic algorithm code. So I'm gonna start with my flappy bird code, import the neural network library, add crossover slash copy mutation and then start to implement the idea of a genetic algorithm in this particular program that started with the flappy bird code that imported the neural network library that my father bought for two zoozy, anyway, nevermind, random reference. Because it's like the flappy bird that imported the neural network library that added the genetic algorithm that there's a song going on there that somebody else will finish for me. All right, Passover is coming up. Okay, so that's that. Okay, so you've made it to the end of this first video for chapter 11 of the nature of code which doesn't even exist yet but maybe by the time you're watching it, I'll be so happy if it exists by the time you're watching this. And so in the next video, I'm going to revisit the neural network library and add functions for copy and mutation. I'll see you there. All right, how we doing everybody? Okay, everybody. Am I done? Can I go home now? No. Echo34, hello Dan. Did you have a chance to check my firework program on Twitter? I think that I did. That was a couple weeks ago. I remember seeing it. I remember it was beautiful. Send it to me again just in case I missed it. I recognize your name though, Echo34. You've made a lot of great contributions. Thank you. Dan, many questions about the ethics of neural nets. Yes, I have many questions about the ethics of neural networks itself. And I, but I, so I don't necessarily have questions about the ethics of neural networks. I have questions about the ethics of the people who have access and the ability to program neural networks and how those programs are applied in society. So hopefully, I hope, or that the work that I'm doing to provide educational materials about neural networks will provoke that discussion and make it easier and more accessible for understanding of these algorithms to be in the hands of more people. And so that we can ask the right questions and work together to make sure the power of these algorithms and the way that they can be applied and the data sets that can be used with them is not abused. That's what I have to say about that. Okay. I suggest you override the weights when you apply crossover. All right. So I think that's good. So anybody have any comments or questions before? Oh, this is not, this computer is not plugged in. All right. Anybody have any questions? So let me get set up, I guess, for the next video. Again, I don't think we're gonna have, I just wanna be honest here. It seems very unlikely at this point that I'm gonna have a finished Flappy Bird neuro evolution tutorial by the end of today. But I certainly, this is a project that I intend to complete. I intend to write a chapter for the nature of code book about it. And yes, so don't worry, even though I don't finish today, I will also mention that if you go to github.com slash Schiffman neural network p5. So you'll notice I have a repository called neural network p5, which says this repository has been archived by the owner, it is now read only. And I wrote this has been deprecated and it links to the coding train neural network JS. The reason why I mentioned this is I started doing this work last year and then decided I wanted to rebuild it again from scratch in video tutorial form. But there are, for example, there is a neuro evolution tutorial example here. Example here. And let's see if I go to click this link, this is actually running what I intend now to build. So let's take a look at this. So and one thing that I built into this is I can like speed it up. And by the way, I made it very easy to play. You notice that. So this over time, we can see like the all time high score. And what I can do now is I can also say run best so far. So this is now going to just show this is the current member of the population that has the best neural network so far to effectively play this game. So I probably should have shown this in the video tutorial itself, but you know. Next come, easy come, easy go or something like that. All right. So you can look at this for reference. I think there's flaws and mistakes and weirdness in here, but it's something. Oh, I forgot to tweet that I was live streaming again. This is the worst thing that I do while live stream, which is that I look at my phone and notifications. But sometimes I just want to make sure that my guest, which I'm very excited about, is not lost and figuring out where to go. Okay. All right, so neat. Nature of code, doodle classifier. So let's go to the code here and go to this neuro evolution sketch and just make sure it's importing the neural network library and the matrix library. And I also need to open up the, and let me do something here. What changes? I just want to like do some git cleanup for a second because this is going to go into the repo. Into the repo, git status here. What did I change? So first let me add and commit the, let me add neuro evolution. And let me say, adding new neuro evolution tutorial. Neuro evolution example. Nothing to see here yet. And, oops, escape. Oh my God. What is this? What is this dungeon that I am now in? WQ. What is this? Crazy. All right. Now let me git push origin master this. And now let me see what's going on here. Let me say git diff. There's some weirdness. I don't know what, I don't know what's going on here. I'm going to just stash this because I don't want to deal with that. And now I think I'm good. And I want to have the library code open neural network. Okay. Whoa. Oh, right. I have the activation function thing. This, I don't know. Semicolon there or no semicolon there. What to do about that? Never, never decide. I guess this is really should have a semicolon there. Yeah, yeah, that should. All right. Just want to see what the randomized function does. Oh, that's in the matrix library. Oh, it's really the matrix library that I want to randomize. Ah, I really should change this to a Gaussian distribution. So at some point I need to do that. I guess I will not worry about it right now. Boy, this has had some nice changes to it. Oh, it has serialize in it. Wait a second here. I forgot that that was in there. I've had some nice pull requests and also a lot of pull requests that I haven't had a chance to look over and figure out what to do about yet. Here's the thing. Yeah, I'm up to date. One of the reasons why I haven't merged some of the pull requests, which are amazing pull requests, is that I feel like what I want to do with crossover and mutation is going to be much simpler to demonstrate with just a single hidden layer than if there were multiple hidden layers. And to be honest, this sort of flappy bird scenario is so simple. It's just a few inputs. I'm not going to do, I could do all the pixels as input. That would be interesting. Actually, that would be really, I remember to mention that when I get to that. But I think it's going to be easier if there is just a single hidden layer and an output layer. Then I can just do the sort of copying and mutation stuff pretty manually. You know, I don't know. But I like, I think that's a good decision. That's a decision I'm making right now. All right, sorry, I'm looking at the chat. Okay. Yeah, I can just, oh, I can just do map. Right, right, right. All right, all right, all right, all right, all right, all right. Okay. So, so really what I want is some new stuff in the matrix class. Copy, okay. I found a wire on the floor. Can you see this wire? Look, someone's been making some physical computing tutorials in this room. That is, you can't even see it because of the focus. There's a wire there. How come you can't see that wire? All right. All right. Hello. Welcome to part two of my neuroevolution series where I am attempting to look at how I can train a neural network, or more accurately, a population of neural networks with a genetic algorithm. I talked about this in the previous video, which you could go back and watch if you haven't. But the main thing that I want to do in this video is look at, okay, well, if I have a neural network, if I have a neural network, how can I apply crossover and mutation to that neural network? So that will be the focus of this video. I do sort of remember, though, I did kind of remember that there's a lot of stuff that I haven't talked about yet. Because one of the reasons why I use a neural network is to be able to give it some inputs and to get some outputs. So that makes sense in the context of the doodle classification example, probably, but might not make sense to you immediately in terms of this idea of a flappy bird game. So I will get to all that. But right now, I'm going to focus on saying new neural network. And you know what? I'm going to stick with copy. Like I said, I'm going to get to crossover in a future video. I'm going to stick with copy for simplicity and mutation. So let's go back. Let's go over to the code. And let's take care of that. Now, let's start by having, I'm going to create a variable called break. And I'm using the p5.js library, though what I'm going to do right now, it's totally unnecessary for, but because the flappy bird game is programmed in p5, that's going to be helpful later. Also, I use it all the time. So I don't need a canvas. I'm just going to say no canvas. And I'm going to say brain equals new neural network. Now, when I create a new neural network object, if you remember the three arguments I need to give it, and this is just for this particular example, I'm going to say, this particular neural network implementation, it'll work differently if you're using, say, like a different machine learning framework like Keras or somebody else's neural network library. Maybe you might want to look at deeplearn.js. I will come back to that in a future video. So I need to give it a certain number of inputs. Well, all of a sudden, now we're back to that question. So let's actually not worry about that right now. Let's not worry about that question. I'm going to go back to that question. And I'm just going to make something up. So let's take the xor example. A trivial example of, OK, it has two inputs. They're either true, true, true, false, false, true, false, false. So there are going to be two inputs. Let's just have a hidden layer with four nodes and one output. So we can create some simple neural network. And what I want to be able to do is I want to say, let, I'll call it like child equal brain.copy. I want to be able to say, let me make a copy of that neural network. And I also want to say something like child.mutate. So let me take that copy and apply a mutation in it. Mutation, which is something I describe more in the genetic algorithm video series. So what this means is this neural network class needs to have two new functions. It needs to have a copy function. It needs to have a mutate function. So let's go into the neural network library code. This is the class. There's a lot of stuff in here. I have way too many videos going through all this code. Luckily, we can kind of ignore all of this. And I'm just going to go down to the bottom here. And I'm going to say something like adding functions for neuroevolution. Now, the truth of the matter is, what is it that I really want to copy? Well, if you recall, the neural network structure is such that if there are two inputs and four hidden nodes and one output, the neural network looks like this. It's connections between the inputs and the hidden layer and connections between the hidden layer and the output. And these connections, the sort of dials of the neural network, the data of the neural network, what controls how the information flows from the inputs and out through the output are all of these weights. And these are stored in matrices. It's just a whole bunch of numbers. So I have a weight matrix, which goes from input to hidden. I have a weight matrix that goes from hidden to output. And with each of these, I also have this thing called a bias. And if you recall, the bias is something, really all I'm doing in the end is like, all of this really boils down to like, hey, there's a whole bunch of points. Could I just fit a line to those points? And the bias is going to be like, move the line a little bit up, move the line a little bit down. So that's really, even though this all seems like fancy magic, ultimately, that's what it just boils down to in the end. So I also have the bias for the hidden, and I have the bias for the output. And I don't know. I don't know what the best way to write the notation for this is. Yeah. So all of these things, when I want to copy the neural network, what I'm really saying I want to do is copy all this stuff. So let me go ahead. And so what I need probably is a function inside of all. These are all matrix objects. I need a function probably in the matrix class to say copy. So let's start here and say copy. And clone could be used. And I want to make a deep copy, I think, not a shallow copy. These terms get thrown around a lot in computer science, deep versus shallow. But I don't want to just point to the data. I want just give me my own version of all of those numbers, because I'm going to mess around with them. And I want you to keep your numbers. I don't want to mess with your numbers. So instead of just saying, like, I'm a new neural network. Can I just point over to your numbers? I really want a whole version of those. So and if we go back to here, so things that I need to do is I need to keep track of these properties, input, output, the total input, output, and hidden nodes. So I want to say let's just put this in here. So I want to say let input nodes equal this dot input nodes. Let hidden nodes equal this dot hidden nodes. And let output nodes equal this dot output. And you know what? This is very poorly named. This is sort of silly what I'm doing, but I'm going to do it anyway. Input nodes. This is very, this is me, this is how I like to code. I like to make things as long-winded as possible so that I can really think it through and explain it. All I'm doing right now is taking the properties of the neural network I want to copy and put them into local variables. Why? Because I want to say neural network copy equals new neural network with what? Oh, I have a better idea how to do this. I have a better idea how to do this. So this could work, but I have a better idea. So actually what I want to do is I kind of just want to say this. Return new neural network this. Now you might be asking me, this isn't going to be bad. This isn't just going to work. But what I'm sort of realizing here is maybe I don't want to copy everything here. What I actually want to do is call the constructor, but give it a reference to the existing neural network and then have that constructor instead of creating a new weight matrices that are random, it'll create weight matrices that are copies of the existing one. In other words, let me go back up to the constructor and look at this. So what if, so the constructor gets three things. Right? A, B, I could just like rename the parameters of the constructor function for a second and just call them A, B, C. Right? A being the input nodes, B being the hidden nodes, C being the output nodes. But before I do that, what I actually want to say is, is A an instance of a neural network? Else. In other words, this is how I want to create, oh I turned, pause. I want to put a preference back that I turned off this morning and I got to check the time, 422. It's 422. Packages, beautify. I just, I really like having it beautify on save. I'm so used to that. So let me just put that back. Okay. This here. So what I want to do is if I'm being sent three integers, then I want to make the neural network the way I always have. However, if I'm being sent the first argument, and this is kind of, this is known as overloading. Typically in a programming language like Java, if I had to overload the constructor, like there's two different ways I could call the constructor. I could give you three numbers to make a brand new neural network, or I could give you a neural network to make a copy of yourself. I would write two versions of the constructor. But in JavaScript, you can only have one version of the constructor, but you can kind of check what you're passing in. And just to be clear about this, let me just make sure this instance of thing is correct. So if I were to say, let A be a new neural network. 4, 3, 2, just arbitrarily. And I can say A instance of, it's without a capital, instance of a string. I should get false. Instance of a neural network, I should get true. Okay, so that's right. This of should be lowercase though. If A is an instance of a neural network, then what am I doing? Then I am saying this.inputNodes equals A.inputNodes. Like I can start right here's where if it's not a neural network, I'm actually assigning it the numbers that are coming in. If it is, I can just keep going. Oh, actually, what am I doing? I can say this. And this should be hidden. And now I can say this. Maybe I should, if somebody has a suggestion for how to name these in a better way, I just, I didn't want to name them hidden, input, hidden, output anymore because A could be either of those things. So, you know, this maybe like to do, document what A, B, C are. OutputNodes, that's a little note to myself that I don't like what I've written here. And then now let's look at these. So I'm not going to need to randomize the weight matrices because I'm just going to say equals, what am I going to do here? A.weights.copy. Right? What I want to do is say, hey, my weights are your weights. And now my input to hidden weights are your weights and my hidden to output weights are your weights. Now, is this going to run? I don't think so because I probably have to add a copy method to the matrix object, but I'm getting somewhere. Now, what else do I need? I need the biases. So I need to set the biases. So the same thing. I'm just doing a lot of little copy-paste stuff here. So I need to set the hidden bias values and the output bias values. So this is me creating this new copy of a previous neural network. And then, you know, right now it looks like learning rate and activation function are at the moment, even though I have different activation functions, I can kind of write is this default is getting set to sigma and its default is getting set to 0.1. So I probably should copy those as well. I'm just going to just be simple about this right now and just assume that my program is never going to change learning rate or activation function. That should be a to do. To do copy these as well at some point. But I don't need to worry about that right now. And to be honest, the learning rate isn't going to play a role anymore. The learning rate is completely irrelevant. The learning rate is specifically tied to the gradient descent algorithm, I'm no longer using with the genetic algorithm. That's what I'm doing now. OK, we're getting somewhere. All right. So just out of curiosity, remember, this is the code. I'm making a new neural network. And I know I haven't done mutate yet. But is this even working? Is there was there by did I maybe in some other universe happen to write a copy function already into the matrix class? Seriously doubt it. But let's see. Yeah, copy is not a function. So what this means is I need to also go into the matrix library. And I think this I think is worth having in here. That's not just this isn't exclusive to genetic algorithms or neuro evolution. Like so I'm adding this stuff, you know, copy and mutate and crossover will be here specifically because of genetic algorithm. But the matrix I can the matrix objects, I can be a little less formal about this. So what do I want to do? I want to write a function copy. And what do I do? I'm going to say let m equal a new matrix with this dot rows, this dot columns. So I create a matrix object with the same number of rows and columns. And somebody in the chat I know is going to tell me there's some very fancy way that I could just instantly use some higher order array function to copy the whole thing over. But because I am who I am, I'm going to say I'm going to write a nice little nested loop, I can always refactor this later, I just know this is going to work. And I'm going to say m dot data index i index j equals this, this dot data index i index j. So this is manually me looping through the entire matrix. It's a grid of numbers. It's all the weights of the connection to the neural network and just manually copying them over one by one. And I think this will work. I have some breaking news from the chat that I need to mention in a second, but it's not relevant to what I'm doing right now. So I will come back to that. All right, so let's see. Let me hit refresh. There we go. So does this work? I have two neural networks. They both seem to have 2, 4, 1, 2, 4, 1. You know, I could go, let me look at one of these biases. Let me look at these values. So this is bias h. These are the values. Can you memorize those? Can you remember them? Let's go down here. OK, nope, nope, something is wrong. So this stuff did not get copied. Guess what? Guess what I forgot? I forgot something quite important. In this function, I did not forget to return the thing that's new. But in the matrix, I forgot to say return n. So this new matrix that I'm making, I've got to actually return it. I made the copy. You can make the copy. You can take the reservation. But you can't hold the return the copy. I don't know, a little Seinfeld reference for all of you. I probably shouldn't have said that. It'd be more interesting if I didn't say that. OK, so now I can look here. And I can see, OK, look at these numbers. Memorize these numbers. This is the way, actually, let me look at, I'm just going to look at one of the bias ones. This will be a little bit simpler. So here's the bias. Bias h has these values. Memorize them, memorize them. I could write a nice unit test to actually see if this function worked. That would be much better. But I'm going to eyeball it. 0.208415. Yep, these look like the same numbers. Same numbers, same numbers. So I'm going to just choose at the moment to believe that this worked. This is probably a bad idea. But this is the reality of what I'm going to do. And I'm OK with that. So let's move on. So we have now implemented copy. What I next need to do is implement mutation. Now, I do need, in order to do mutation, I need to have something called a mutation rate. And that mutation rate is essentially a probability of how likely it is for each element of every sort of DNA to alter itself randomly when that child DNA is made. So what that means in this context is for every single number that's a weight in these matrices, for every single number that's in the bias, there is a, say, 1% chance, 0.5% chance, 10% chance, then I'll pick a new random number. I could also, with mutation, like nudge the values. So instead of picking an entirely random number, I could push it a little higher, push it a little lower. But for simplicity right now, let's just pick a new random number. So what do I need to do? I need to go back to neuralnetwork.js, and I'm going to add a function called mutate. And what am I going to do here? I'm going to say there are four things that I need to mutate. So I'm going to say, let's think about this. What are all those things called? There's, I just got to go back up to here. There's weights i, h, weights h, o, bias h, bias o. So I need to say, what I need to do is say, weights, I'm going to map a mutation function. So remember there's the, the, the, sorry, I'm all of a sudden not able to type and talk at the same time. So if you recall, the matrix, the matrix library has a function called map. And what it allows you to do, it's a little unfortunate that there's also a JavaScript native function called map, which I'm using everywhere. It allows you to apply a function to every single element of the array. So I can pass in a function and apply it to every single element of the array. And the function that I'm going to pass in is mutate. So let's write this function now. And it's going to get, it receives a value, but to be honest, I don't care about, I do care about what the value is, if I were planning to nudge it higher and nudge it lower. But what I'm going to do right now is I'm just going to return a random number. So let me actually, I sort of, I should probably link these better in some way. But when I have this function called randomize, and this is the kind of random number that I'm asking for. So I am going to just return this. Ah, but am I always going to, oh, I do need the val. Guess what? If I do this, it'll completely randomize every single element. So this mutation function needs a mutation rate. And what I'm going to do is I'm going to pick a random number. If math.random is greater than or less than the rate, so let's say math.random will give me a number between zero and one. So if the mutation rate is 0.1, that random number between zero and one will be less than 0.1 10% of the time. Otherwise, stick with the same value. So this is now the function that I want to apply to every element of all of the weight matrices. I want to say, hey, mutate these weights, mutate these weights, mutate these biases, mutate these biases. And perhaps there's a more elegant way to write this, and I will consider that all in the future with your many comments and pull requests and complaints. I look forward to them, but this is what I'm going to leave it at right now. So let's see now if what I can do, if I go back to this particular program and I say child. Now, just out of curiosity, I'm going to say child.mutate one. So I'm giving it a mutation rate of one, which means everything should be completely random. And what I'm going to do is I'm going to say, I'm going to say, I'm going to give it a mutation rate of one, which means everything should be completely random. And what I'm going to do just as a way of testing, actually, is I'm going to change this to, I'm going to multiply it by 1,000, just because I want to see totally different numbers to see that this is working. So I'm going to go back, and I'm going to refresh the code. Weights i.h is not defined. Oh, right, I forgot about the this. That won't surprise any of you. So let's take a look. So here we have, once again, the biases. They're all reasonable numbers between negative one and one, which is how I started the neural network. And now, if I look at the child neural network, and I look at the biases, we can see, yep, so that mutated. Now, let's change the mutation rate. Let's change it to 0.5. So we have kind of, I mean, we're not going to get exactly 50% of them, because it's supposed to be random. But we'll at least see some of them didn't mutate and some of them did. So let's change now the mutation rate to 0.5, just to see that this is working. This is instead of me writing unit tests, manual unit testing. Let's look here. We can see, wonderful, here's some original values. And now, let's go down to here in the child object. And let's look at the biases again. And we can see, hey, it actually worked out exactly as planned. It mutated two of them and didn't mutate two of them, which is what most commonly with a 50% probability we're going to see. And I suspect that if I go into the output bias, oh, the output bias just has one value. It didn't get mutated, right? Because this is such a simple little neural network. If we go into these weights, we can see three out of four got mutated. I think it's working. So we are in good shape here. We now, and so I want to, probably the actual mutation rate I'm going to want to use is only like 1%, because I want to do it pretty rarely. But we now have the ability to both copy a neural network, again, as an exercise, if you're watching this and the future videos of this tutorial aren't released yet, or if you don't feel like watching them just yet, try as an exercise for yourself, go and implement crossover. How could instead of copy, could you create a new neural network that's a mixture of all of these weight matrices? That would be a really interesting thing to try. I will do that, hopefully, in a future video. So I've got copy, I've got mutation, I've got the floppy bird game, I've got the neural network library, I've added crossover mutation, so we're ready now. We're actually ready to implement the genetic algorithm. I'm going to say this twice. Someone in the chat pointed out that the NEAT algorithm, Neural Evolution Augmented Topology things, refers to a very specific implementation of neural evolution in a specific paper, and I'm obviously being much more informal about this here. So technically, this probably isn't the NEAT algorithm. And maybe I'll mention that at the beginning of the next video too, just to emphasize it a bit more. All right, thanks for watching, and I will see you when I continue. All right, let me look at the time. Where are we time-wise? It's 4.40. I think I should stop because the next aspect of this... I think I should stop because I don't have very much time left. And it's definitely going to take longer than 20 minutes to finish Neural Evolution. Let me just check some things here. Let me just check some things here. I'm just looking to make sure I don't have any important messages that I need to deal with right now, and I don't seem to. Okay. I do see that some people have suggested Pi Day coding challenges, which I'm excited about. I'm going to say, I'm going to say, Pi Day coding challenges is just a very simple thing. It's just a simple way to do a code. It's not a very complicated code, but it's just a simple way to do a code. So it's a very simple code, and it's going to take a little bit more time than Pi Day. Um, so, um, what have I done so far today? I have done one video about linting, which needs a follow-up. I have done one video about remote... Oh, oh, oh, oh, we don't have time for it. Oh, maybe I could do my load bytes pull request. All right, this could fail. This is probably going to fail horribly because, I mean, yeah. Eh, eh, mm. I should give myself more time for this. Yeah, it's a bad idea. I want to, I, let me just say what I was thinking about doing. I think it's better for me to just, it's not good for me to try to do something when I have a very limited amount of time, especially anything that's complicated. This will be way more complicated, but I want to go to what I was thinking about doing that I think would make a useful video tutorial. So let me add a comment here about this at least. Load bytes. So, so this, by the way, is a GitHub issue that I opened for the open source project p5.js, which is a project that I'm very much involved with, a wonderful community and open source project, where I created a version of the load bytes function to load a binary file to a JavaScript program which doesn't at present exist, which doesn't at present, yeah, which doesn't at present exist in p5. If you go and look in the p5 source code, it'll say to be implemented. And so some people gave me some feedback here, and I just keep, it's been on my list every day, I'll let me pull request this, and then I thought, oh, it would be useful to actually make this contribution to p5.js in a video tutorial, but I also feel like, oh, when am I ever going to get to that? So let me make a note here, and just say, FYI, I am writing this while live streaming. I would like to make a video tutorial where I walk through the steps of how to contribute this enhancement, but I did not get to it today. I think this would be useful. So I am holding off on submitting until another recording session. So this looks right. Okay, so wonderful. So I added that note there. Thank you to everyone who has been monitoring the YouTube chat today. That's not an easy thing to do, and I really appreciate it. It's very important to me. It's very important to me that the community that participates in the channel is kind and welcoming to everyone, and so as always, if you're running into any issues during any of the live streams, please send me a tweet or an email. You probably can figure out a way to get in contact with me. I'm happy to do anything I can to help. So I think what I'll do is, so I'm going to go in about five or 10 minutes. I'm happy to maybe take a few questions. Let me actually also... I don't think anything that I've done has broken any of my existing examples. Wouldn't it be nice to have unit testing here? But I'm going to say git add. And did I save everything that I've done? I'm going to go in, and I'm going to say git commit. Oh, let me do something. This is my new thing that I do, that I like. Git commit and atom editor. Wait, so let me do this. I want to make a video about this, but yes, this is what I want. So what I'm doing is I'm associating atom with git, and so I'm going to do this. And the wait is there because when I say commit, I want it to wait to make the commit until I finish typing in atom. So now if I say git commit, it'll open up the message in atom. And actually, I'm going to do control C because what is the thing where I say dash v? Is it dash v or verbose? Somebody must know. Where it, I should really just make this a video right now. 15 minutes. I just like when I have a nugget of something, I think people find it better if it's in the right playlist and it's an edited chunk as opposed to a random thing. Of course, all of this is a bad idea. In the chat, I'm being told that using atom for this is a bad idea. Guess what? It's all a bad idea. We should all just go back, relax by the fire with our friends and read a book, frankly. You know, playing the violin is something that I did for 12 years, and I probably should spend more time doing that. What is it, verbose? Nobody's answered my question. Oh, Yardi is asking when is the next ITP show? I think it's May 15th and 16th. You should come to it in person, but I will plan on doing a live stream from it again. I guess I could just try dash V. Yeah, that was it. Shows me all the diffs. Look at that. Boom, boom, boom. I like that. It's good. Okay, so, all right, why not? All right, use a sensible editor like VI. But I, but, but, but, but, but, oh, nice. Nice lollipops. You can't really do that. It takes time and googling all your questions. You need a violin coach. Am I, you know, I can't tell whether I'm doing something. All right, fine. I'm not going to do my video about commit right now. You guys have thrown me off. I'm going to just use Adam because that's the way I like it. And I'm going to say commit dash V. So what I like about this is it opens up the text editor where I can write my commit message, adding, and it'll actually even like do stuff like, hey, start that with a capital, adding, adding code from March 8th live stream on NeuroEvolution. Because it doesn't like that I went so far on one line. Oh, too many. Yeah, adding code for March 8th live stream. So this here is the start of code I need for my NeuroEvolution examples. So far, I guess it wants me to. So far, I have only implemented copy. And I've only implemented copy and mutate. I still need to do crossover. Put these. I don't know. I feel like I don't know where the period should go. I'm having a grammar moment. The period I thought should go inside, but then the parentheses threw me off. Ah! I still need to cross. I'll have an and here. How about this? OK. That fixes it. I still need to do crossover and implement the GA itself, of course. For reference, the live stream is here. Live stream is here. So how do I get YouTube, the coding train? Yeah, I really got to go, actually. Because and so if I go to coding train live, this will be the live stream. And I'm going to do a live stream. This URL will go on forever. And so this, I think, is a nice, thoughtful commit message that explains everything. I am now going to hit close. And it added that. Is it March 8? I hope it's March. It's March 9. Ha ha ha ha ha! Did nobody notice that? There's like an amend thing, right? Git commit amend. Oh! Yay! That was the most wonderful thing ever that just happened. This would've been so good for me to make this into a video tutorial. You, all of you who shamed me for using Adam as my text editor, you are depriving the world of a nice standalone tutorial. I'm going to tweet a link to this time code in this video for people to see and find. Adding code for March 9 live stream. And now I'm going to close that. And there we go. Git log dash one. We can see here's my message. And now I can say git push origin master. And we will go to the toy neural network. And I will look at the commits. And look, see? Ninth is right. Oh, it's running some tests. I forgot that I have... Oh, I should've pushed it. I meant to push it to a different branch and then merge it. Oh, well. At least the test passed. And we can see, look. See, look at this. This is the world we should be living in. Where people write thoughtful and kind commit messages. The date is... Right, I know. The date's below. The date's in there. But it's fine. All right. I've got to go. I even just got a calendar warning. I've got to read some random numbers. Reminder that I'll be back on March 14th for Pi Day. Submit your Pi Day coding challenge ideas to rainbow topics. Link in the description below. 7,785. 2,854. 91,971. 63,537. 84,671. 3,517. 28,914. 48,762. 76,952. 76,837. All right. I read some random numbers. And I'm going to put this song on. Goodbye, everyone. But it now has a different commit date to its creation date or something. Oh, boy. I don't know. I don't know. Just I can't get it right, everybody. It is what it is. Thank you to Darius Kazemi, who gave me a lot of great tips on open source stuff in the last couple weeks. I'm working, by the way, on an idea for a course about contributing to open source that I want to teach next year at NYU. I have a GitHub repository with ideas in it. At some point, I'll publish it. You could find it, probably, if you want. But I'm soliciting contributions and ideas for that. And I will continue to make more video tutorials. I'll be back next Wednesday. There will be a surprise for you, because I am going to shortly record a guest video for the Coding Train channel. It will come out sometime in the next couple weeks. So stay tuned for that. And I'll see you all. I'm still here. I'm looking at my phone now. All right, everybody. I'm going to hit stop streaming now. So I probably won't return to the neuroevolution thing next week. That'll come two weeks from now. So the next live stream, there will also be a guest two weeks from now. I mean, I have a lot of guests scheduled that I'm excited about, like three or four so far coming up. OK. Next live stream, Wednesday, March 14, probably in the morning of my time. And then March, whatever it is, like 23rd, I think, is the next Friday. All right. Goodbye, everybody.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:52.614212Z",
  "started_at": "2023-09-26T21:20:10.8222Z",
  "completed_at": "2023-09-26T21:43:21.651116Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=ASnCXW6pPSY",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1390.828916
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/bnnqufrb3alibm35ypbtk4jzyy/cancel",
    "get": "https://api.replicate.com/v1/predictions/bnnqufrb3alibm35ypbtk4jzyy"
  }
}