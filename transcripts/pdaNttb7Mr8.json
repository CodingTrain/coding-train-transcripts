{
  "id": "ruiu5nbbywufgdkl3gs5vqo3za",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/pdaNttb7Mr8.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/131666 [00:00<?, ?frames/s]\n  2%|▏         | 2888/131666 [00:06<04:59, 429.91frames/s]\n  4%|▍         | 5884/131666 [00:12<04:32, 461.20frames/s]\n  7%|▋         | 8880/131666 [00:19<04:31, 452.63frames/s]\n  9%|▊         | 11460/131666 [00:25<04:25, 453.47frames/s]\n 11%|█         | 14308/131666 [00:32<04:24, 443.35frames/s]\n 13%|█▎        | 17244/131666 [00:38<04:14, 448.72frames/s]\n 15%|█▌        | 20130/131666 [00:44<04:10, 445.47frames/s]\n 17%|█▋        | 22980/131666 [00:51<04:04, 444.57frames/s]\n 20%|█▉        | 25868/131666 [00:57<03:53, 452.25frames/s]\n 22%|██▏       | 28792/131666 [01:04<03:57, 433.15frames/s]\n 24%|██▍       | 31706/131666 [01:10<03:41, 451.37frames/s]\n 26%|██▋       | 34694/131666 [01:17<03:31, 458.21frames/s]\n 29%|██▊       | 37594/131666 [01:24<03:32, 443.64frames/s]\n 31%|███       | 40450/131666 [01:30<03:21, 452.50frames/s]\n 33%|███▎      | 43088/131666 [01:34<03:03, 481.74frames/s]\n 35%|███▍      | 45734/131666 [01:39<02:52, 497.68frames/s]\n 37%|███▋      | 48682/131666 [01:47<03:02, 455.78frames/s]\n 39%|███▉      | 51396/131666 [01:54<03:05, 433.30frames/s]\n 41%|████▏     | 54332/131666 [02:04<03:23, 380.02frames/s]\n 44%|████▎     | 57332/131666 [02:14<03:34, 347.19frames/s]\n 46%|████▌     | 60212/131666 [02:22<03:27, 343.83frames/s]\n 48%|████▊     | 62916/131666 [02:29<03:08, 365.47frames/s]\n 50%|█████     | 65916/131666 [02:35<02:48, 390.30frames/s]\n 52%|█████▏    | 68820/131666 [02:45<02:54, 359.84frames/s]\n 55%|█████▍    | 71820/131666 [02:52<02:41, 370.06frames/s]\n 57%|█████▋    | 74740/131666 [03:00<02:30, 377.15frames/s]\n 59%|█████▉    | 77598/131666 [03:08<02:27, 365.69frames/s]\n 61%|██████    | 80450/131666 [03:16<02:20, 365.01frames/s]\n 63%|██████▎   | 83370/131666 [03:24<02:10, 370.84frames/s]\n 66%|██████▌   | 86258/131666 [03:34<02:13, 339.38frames/s]\n 68%|██████▊   | 89102/131666 [03:44<02:14, 317.45frames/s]\n 70%|██████▉   | 91934/131666 [03:52<02:00, 330.49frames/s]\n 72%|███████▏  | 94854/131666 [03:59<01:44, 352.08frames/s]\n 74%|███████▍  | 97854/131666 [04:07<01:35, 355.89frames/s]\n 77%|███████▋  | 100770/131666 [04:16<01:28, 350.02frames/s]\n 78%|███████▊  | 103178/131666 [04:22<01:18, 362.34frames/s]\n 80%|████████  | 105690/131666 [04:28<01:10, 366.02frames/s]\n 83%|████████▎ | 108654/131666 [04:35<00:58, 391.07frames/s]\n 85%|████████▍ | 111390/131666 [04:43<00:53, 377.97frames/s]\n 87%|████████▋ | 114066/131666 [04:47<00:41, 425.79frames/s]\n 89%|████████▉ | 116948/131666 [04:52<00:31, 460.28frames/s]\n 91%|█████████ | 119948/131666 [04:58<00:24, 483.29frames/s]\n 93%|█████████▎| 122848/131666 [05:01<00:15, 563.18frames/s]\n 96%|█████████▌| 125820/131666 [05:06<00:10, 565.52frames/s]\n 98%|█████████▊| 128792/131666 [05:14<00:05, 495.64frames/s]\n 99%|█████████▉| 130724/131666 [05:18<00:01, 480.76frames/s]\n99%|█████████▉| 130724/131666 [05:23<00:02, 403.88frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 4.08,
        "id": 0,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, welcome to another holiday coding challenge,",
        "tokens": [
          50364,
          2425,
          11,
          2928,
          281,
          1071,
          9960,
          17720,
          3430,
          11,
          50568
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 5.92,
        "id": 1,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 4.08,
        "temperature": 0,
        "text": " again with the snowflakes.",
        "tokens": [
          50568,
          797,
          365,
          264,
          44124,
          3419,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 7.6000000000000005,
        "id": 2,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 5.92,
        "temperature": 0,
        "text": " This is my second snowflake challenge,",
        "tokens": [
          50660,
          639,
          307,
          452,
          1150,
          44124,
          619,
          3430,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 10.48,
        "id": 3,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 7.6000000000000005,
        "temperature": 0,
        "text": " but in this time, instead of creating an algorithm",
        "tokens": [
          50744,
          457,
          294,
          341,
          565,
          11,
          2602,
          295,
          4084,
          364,
          9284,
          50888
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 14,
        "id": 4,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 10.48,
        "temperature": 0,
        "text": " to draw a snowflake, I am going to ask a neural network",
        "tokens": [
          50888,
          281,
          2642,
          257,
          44124,
          619,
          11,
          286,
          669,
          516,
          281,
          1029,
          257,
          18161,
          3209,
          51064
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 15.4,
        "id": 5,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 14,
        "temperature": 0,
        "text": " to draw a snowflake for me.",
        "tokens": [
          51064,
          281,
          2642,
          257,
          44124,
          619,
          337,
          385,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 18.8,
        "id": 6,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 15.4,
        "temperature": 0,
        "text": " Now, there's a lot of pieces to all of the work",
        "tokens": [
          51134,
          823,
          11,
          456,
          311,
          257,
          688,
          295,
          3755,
          281,
          439,
          295,
          264,
          589,
          51304
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 21.28,
        "id": 7,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 18.8,
        "temperature": 0,
        "text": " that's gone in to making the fact that I'm going to be able",
        "tokens": [
          51304,
          300,
          311,
          2780,
          294,
          281,
          1455,
          264,
          1186,
          300,
          286,
          478,
          516,
          281,
          312,
          1075,
          51428
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 23.04,
        "id": 8,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 21.28,
        "temperature": 0,
        "text": " to do this in, well, what probably will be about",
        "tokens": [
          51428,
          281,
          360,
          341,
          294,
          11,
          731,
          11,
          437,
          1391,
          486,
          312,
          466,
          51516
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 24.88,
        "id": 9,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 23.04,
        "temperature": 0,
        "text": " four and a half hours, but really could take",
        "tokens": [
          51516,
          1451,
          293,
          257,
          1922,
          2496,
          11,
          457,
          534,
          727,
          747,
          51608
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 27.28,
        "id": 10,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 24.88,
        "temperature": 0,
        "text": " just about 15 minutes possible.",
        "tokens": [
          51608,
          445,
          466,
          2119,
          2077,
          1944,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.25051971961712016,
        "compression_ratio": 1.7269736842105263,
        "end": 28.88,
        "id": 11,
        "no_speech_prob": 0.004263827111572027,
        "seek": 0,
        "start": 27.28,
        "temperature": 0,
        "text": " So the first thing I want to reference",
        "tokens": [
          51728,
          407,
          264,
          700,
          551,
          286,
          528,
          281,
          6408,
          51808
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 30.24,
        "id": 12,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 28.88,
        "temperature": 0,
        "text": " is the Magenta Project.",
        "tokens": [
          50364,
          307,
          264,
          6395,
          8938,
          9849,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 32.78,
        "id": 13,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 30.24,
        "temperature": 0,
        "text": " So the Magenta Project is a make music and art",
        "tokens": [
          50432,
          407,
          264,
          6395,
          8938,
          9849,
          307,
          257,
          652,
          1318,
          293,
          1523,
          50559
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 34.72,
        "id": 14,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 32.78,
        "temperature": 0,
        "text": " using machine learning research project.",
        "tokens": [
          50559,
          1228,
          3479,
          2539,
          2132,
          1716,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 37.08,
        "id": 15,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 34.72,
        "temperature": 0,
        "text": " It's an open source research project from Google,",
        "tokens": [
          50656,
          467,
          311,
          364,
          1269,
          4009,
          2132,
          1716,
          490,
          3329,
          11,
          50774
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 42.08,
        "id": 16,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 37.08,
        "temperature": 0,
        "text": " and it has a ton of examples, projects,",
        "tokens": [
          50774,
          293,
          309,
          575,
          257,
          2952,
          295,
          5110,
          11,
          4455,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 45.2,
        "id": 17,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 42.2,
        "temperature": 0,
        "text": " with TensorFlow in both Python and JavaScript,",
        "tokens": [
          51030,
          365,
          37624,
          294,
          1293,
          15329,
          293,
          15778,
          11,
          51180
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 47.36,
        "id": 18,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 45.2,
        "temperature": 0,
        "text": " and you can look through it, all these featured projects.",
        "tokens": [
          51180,
          293,
          291,
          393,
          574,
          807,
          309,
          11,
          439,
          613,
          13822,
          4455,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 51.239999999999995,
        "id": 19,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 47.36,
        "temperature": 0,
        "text": " The project I want to mention is,",
        "tokens": [
          51288,
          440,
          1716,
          286,
          528,
          281,
          2152,
          307,
          11,
          51482
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 52.92,
        "id": 20,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 51.239999999999995,
        "temperature": 0,
        "text": " I'll just click over here, is this project",
        "tokens": [
          51482,
          286,
          603,
          445,
          2052,
          670,
          510,
          11,
          307,
          341,
          1716,
          51566
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 56.3,
        "id": 21,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 52.92,
        "temperature": 0,
        "text": " called Sketch RNN, or Draw Together with a Neural Network.",
        "tokens": [
          51566,
          1219,
          49245,
          45702,
          45,
          11,
          420,
          20386,
          15911,
          365,
          257,
          1734,
          1807,
          12640,
          13,
          51735
        ]
      },
      {
        "avg_logprob": -0.22821443997896634,
        "compression_ratio": 1.6531986531986531,
        "end": 58.84,
        "id": 22,
        "no_speech_prob": 0.0002453648776281625,
        "seek": 2888,
        "start": 56.3,
        "temperature": 0,
        "text": " Now, if you've watched any of my previous videos",
        "tokens": [
          51735,
          823,
          11,
          498,
          291,
          600,
          6337,
          604,
          295,
          452,
          3894,
          2145,
          51862
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 60.52,
        "id": 23,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 59.68000000000001,
        "temperature": 0,
        "text": " about the Quick Draw Dataset,",
        "tokens": [
          50406,
          466,
          264,
          12101,
          20386,
          9315,
          296,
          302,
          11,
          50448
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 62.92,
        "id": 24,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 60.52,
        "temperature": 0,
        "text": " the Quick Draw Dataset is this huge collection",
        "tokens": [
          50448,
          264,
          12101,
          20386,
          9315,
          296,
          302,
          307,
          341,
          2603,
          5765,
          50568
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 65.2,
        "id": 25,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 62.92,
        "temperature": 0,
        "text": " of millions upon millions of doodles",
        "tokens": [
          50568,
          295,
          6803,
          3564,
          6803,
          295,
          360,
          35192,
          50682
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 67.28,
        "id": 26,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 65.2,
        "temperature": 0,
        "text": " that users from around the world made",
        "tokens": [
          50682,
          300,
          5022,
          490,
          926,
          264,
          1002,
          1027,
          50786
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 69.92,
        "id": 27,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 67.28,
        "temperature": 0,
        "text": " playing the Google Quick Draw game.",
        "tokens": [
          50786,
          2433,
          264,
          3329,
          12101,
          20386,
          1216,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 73.04,
        "id": 28,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 69.92,
        "temperature": 0,
        "text": " So what the researchers from Google Brain did,",
        "tokens": [
          50918,
          407,
          437,
          264,
          10309,
          490,
          3329,
          29783,
          630,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 75.60000000000001,
        "id": 29,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 73.04,
        "temperature": 0,
        "text": " you can see them credited here, David Ha, Jonas,",
        "tokens": [
          51074,
          291,
          393,
          536,
          552,
          41155,
          510,
          11,
          4389,
          4064,
          11,
          34630,
          11,
          51202
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 79.64,
        "id": 30,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 75.60000000000001,
        "temperature": 0,
        "text": " and Young-Yun, and Ian Johnson, wrote this paper",
        "tokens": [
          51202,
          293,
          8160,
          12,
          56,
          409,
          11,
          293,
          19595,
          9779,
          11,
          4114,
          341,
          3035,
          51404
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 82.48,
        "id": 31,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 79.64,
        "temperature": 0,
        "text": " about how a neural network could be trained",
        "tokens": [
          51404,
          466,
          577,
          257,
          18161,
          3209,
          727,
          312,
          8895,
          51546
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 84.60000000000001,
        "id": 32,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 82.48,
        "temperature": 0,
        "text": " on all of those drawings.",
        "tokens": [
          51546,
          322,
          439,
          295,
          729,
          18618,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 87.08000000000001,
        "id": 33,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 84.60000000000001,
        "temperature": 0,
        "text": " So it could learn, okay, when somebody's drawing a cat,",
        "tokens": [
          51652,
          407,
          309,
          727,
          1466,
          11,
          1392,
          11,
          562,
          2618,
          311,
          6316,
          257,
          3857,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.2566435252521055,
        "compression_ratio": 1.7508532423208192,
        "end": 88.80000000000001,
        "id": 34,
        "no_speech_prob": 0.00007484565139748156,
        "seek": 5884,
        "start": 87.08000000000001,
        "temperature": 0,
        "text": " they kind of go like this, and then they go like this,",
        "tokens": [
          51776,
          436,
          733,
          295,
          352,
          411,
          341,
          11,
          293,
          550,
          436,
          352,
          411,
          341,
          11,
          51862
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 92.92,
        "id": 35,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 89.75999999999999,
        "temperature": 0,
        "text": " and it could start to imagine new drawings of cats.",
        "tokens": [
          50412,
          293,
          309,
          727,
          722,
          281,
          3811,
          777,
          18618,
          295,
          11111,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 96.56,
        "id": 36,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 92.92,
        "temperature": 0,
        "text": " And it's called Sketch RNN because the kind",
        "tokens": [
          50570,
          400,
          309,
          311,
          1219,
          49245,
          45702,
          45,
          570,
          264,
          733,
          50752
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 97.72,
        "id": 37,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 96.56,
        "temperature": 0,
        "text": " of neural network that it's using",
        "tokens": [
          50752,
          295,
          18161,
          3209,
          300,
          309,
          311,
          1228,
          50810
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 99.67999999999999,
        "id": 38,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 97.72,
        "temperature": 0,
        "text": " is something called a recurrent neural network.",
        "tokens": [
          50810,
          307,
          746,
          1219,
          257,
          18680,
          1753,
          18161,
          3209,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 101.14,
        "id": 39,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 99.67999999999999,
        "temperature": 0,
        "text": " And you might have also seen this,",
        "tokens": [
          50908,
          400,
          291,
          1062,
          362,
          611,
          1612,
          341,
          11,
          50981
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 103.32,
        "id": 40,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 101.14,
        "temperature": 0,
        "text": " I've had some other, Nabil Hussain was here",
        "tokens": [
          50981,
          286,
          600,
          632,
          512,
          661,
          11,
          426,
          5177,
          389,
          2023,
          491,
          390,
          510,
          51090
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 105.86,
        "id": 41,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 103.32,
        "temperature": 0,
        "text": " and did a guest video about generating text",
        "tokens": [
          51090,
          293,
          630,
          257,
          8341,
          960,
          466,
          17746,
          2487,
          51217
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 107.36,
        "id": 42,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 105.86,
        "temperature": 0,
        "text": " with a recurrent neural network.",
        "tokens": [
          51217,
          365,
          257,
          18680,
          1753,
          18161,
          3209,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 109.16,
        "id": 43,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 107.36,
        "temperature": 0,
        "text": " Recurrent neural network is good at learning",
        "tokens": [
          51292,
          9647,
          374,
          1753,
          18161,
          3209,
          307,
          665,
          412,
          2539,
          51382
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 111.32,
        "id": 44,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 109.16,
        "temperature": 0,
        "text": " about sequential information,",
        "tokens": [
          51382,
          466,
          42881,
          1589,
          11,
          51490
        ]
      },
      {
        "avg_logprob": -0.2618067466606528,
        "compression_ratio": 1.812,
        "end": 114.6,
        "id": 45,
        "no_speech_prob": 0.00001568952575325966,
        "seek": 8880,
        "start": 111.32,
        "temperature": 0,
        "text": " like, hello world is sequential information,",
        "tokens": [
          51490,
          411,
          11,
          7751,
          1002,
          307,
          42881,
          1589,
          11,
          51654
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 118.16,
        "id": 46,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 114.6,
        "temperature": 0,
        "text": " H-E-L-L-O space W-O-R-L-D.",
        "tokens": [
          50364,
          389,
          12,
          36,
          12,
          43,
          12,
          43,
          12,
          46,
          1901,
          343,
          12,
          46,
          12,
          49,
          12,
          43,
          12,
          35,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 120.67999999999999,
        "id": 47,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 118.16,
        "temperature": 0,
        "text": " Music is sequential information.",
        "tokens": [
          50542,
          7609,
          307,
          42881,
          1589,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 122.94,
        "id": 48,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 120.67999999999999,
        "temperature": 0,
        "text": " La la la la la la la la la.",
        "tokens": [
          50668,
          2369,
          635,
          635,
          635,
          635,
          635,
          635,
          635,
          635,
          13,
          50781
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 124.96,
        "id": 49,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 122.94,
        "temperature": 0,
        "text": " That's a sequence of notes and rhythms.",
        "tokens": [
          50781,
          663,
          311,
          257,
          8310,
          295,
          5570,
          293,
          44892,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 127.67999999999999,
        "id": 50,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 124.96,
        "temperature": 0,
        "text": " A drawing is a sequence of vectors.",
        "tokens": [
          50882,
          316,
          6316,
          307,
          257,
          8310,
          295,
          18875,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 130.84,
        "id": 51,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 127.67999999999999,
        "temperature": 0,
        "text": " So you can read this paper all about how they used",
        "tokens": [
          51018,
          407,
          291,
          393,
          1401,
          341,
          3035,
          439,
          466,
          577,
          436,
          1143,
          51176
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 134.24,
        "id": 52,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 130.84,
        "temperature": 0,
        "text": " the Google Quick Draw dataset to train a model",
        "tokens": [
          51176,
          264,
          3329,
          12101,
          20386,
          28872,
          281,
          3847,
          257,
          2316,
          51346
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 135.44,
        "id": 53,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 134.24,
        "temperature": 0,
        "text": " to create new drawings.",
        "tokens": [
          51346,
          281,
          1884,
          777,
          18618,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 137.28,
        "id": 54,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 135.44,
        "temperature": 0,
        "text": " You can also look at their demo,",
        "tokens": [
          51406,
          509,
          393,
          611,
          574,
          412,
          641,
          10723,
          11,
          51498
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 139.29999999999998,
        "id": 55,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 137.28,
        "temperature": 0,
        "text": " and this is the code, by the way, for their demo.",
        "tokens": [
          51498,
          293,
          341,
          307,
          264,
          3089,
          11,
          538,
          264,
          636,
          11,
          337,
          641,
          10723,
          13,
          51599
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 141.76,
        "id": 56,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 139.29999999999998,
        "temperature": 0,
        "text": " There's a lot involved here in all of these pieces,",
        "tokens": [
          51599,
          821,
          311,
          257,
          688,
          3288,
          510,
          294,
          439,
          295,
          613,
          3755,
          11,
          51722
        ]
      },
      {
        "avg_logprob": -0.20699679933745285,
        "compression_ratio": 1.661764705882353,
        "end": 143.07999999999998,
        "id": 57,
        "no_speech_prob": 0.000043318992538843304,
        "seek": 11460,
        "start": 141.76,
        "temperature": 0,
        "text": " and here's the demo right here.",
        "tokens": [
          51722,
          293,
          510,
          311,
          264,
          10723,
          558,
          510,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 145.64000000000001,
        "id": 58,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 143.08,
        "temperature": 0,
        "text": " So I'm going to pick a cat,",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          1888,
          257,
          3857,
          11,
          50492
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 147.88000000000002,
        "id": 59,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 145.64000000000001,
        "temperature": 0,
        "text": " and what I can do is I can start drawing,",
        "tokens": [
          50492,
          293,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          722,
          6316,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 151.20000000000002,
        "id": 60,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 148.96,
        "temperature": 0,
        "text": " whoops, I can start drawing a cat,",
        "tokens": [
          50658,
          567,
          3370,
          11,
          286,
          393,
          722,
          6316,
          257,
          3857,
          11,
          50770
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 152.08,
        "id": 61,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 151.20000000000002,
        "temperature": 0,
        "text": " I'm just going to draw a circle,",
        "tokens": [
          50770,
          286,
          478,
          445,
          516,
          281,
          2642,
          257,
          6329,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 153.76000000000002,
        "id": 62,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 152.08,
        "temperature": 0,
        "text": " and then it will pick up for me",
        "tokens": [
          50814,
          293,
          550,
          309,
          486,
          1888,
          493,
          337,
          385,
          50898
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 155.52,
        "id": 63,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 153.76000000000002,
        "temperature": 0,
        "text": " and finish the rest of the cat.",
        "tokens": [
          50898,
          293,
          2413,
          264,
          1472,
          295,
          264,
          3857,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 159.04000000000002,
        "id": 64,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 155.52,
        "temperature": 0,
        "text": " So at some point I will do a part two of this video",
        "tokens": [
          50986,
          407,
          412,
          512,
          935,
          286,
          486,
          360,
          257,
          644,
          732,
          295,
          341,
          960,
          51162
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 161.68,
        "id": 65,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 159.04000000000002,
        "temperature": 0,
        "text": " where I actually create an interactive version like that,",
        "tokens": [
          51162,
          689,
          286,
          767,
          1884,
          364,
          15141,
          3037,
          411,
          300,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 166.12,
        "id": 66,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 161.68,
        "temperature": 0,
        "text": " but one of the things that is in now the ML5 project,",
        "tokens": [
          51294,
          457,
          472,
          295,
          264,
          721,
          300,
          307,
          294,
          586,
          264,
          21601,
          20,
          1716,
          11,
          51516
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 169.98000000000002,
        "id": 67,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 166.12,
        "temperature": 0,
        "text": " ML5 is a friendly machine learning for the web library",
        "tokens": [
          51516,
          21601,
          20,
          307,
          257,
          9208,
          3479,
          2539,
          337,
          264,
          3670,
          6405,
          51709
        ]
      },
      {
        "avg_logprob": -0.20940381070993241,
        "compression_ratio": 1.708955223880597,
        "end": 172.44,
        "id": 68,
        "no_speech_prob": 0.00003883104000124149,
        "seek": 14308,
        "start": 169.98000000000002,
        "temperature": 0,
        "text": " that's built on top of TensorFlow.js.",
        "tokens": [
          51709,
          300,
          311,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 175.32,
        "id": 69,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 172.8,
        "temperature": 0,
        "text": " It works with P5, which is the open source",
        "tokens": [
          50382,
          467,
          1985,
          365,
          430,
          20,
          11,
          597,
          307,
          264,
          1269,
          4009,
          50508
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 178.92,
        "id": 70,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 175.32,
        "temperature": 0,
        "text": " JavaScript library that I use in a lot of my video tutorials",
        "tokens": [
          50508,
          15778,
          6405,
          300,
          286,
          764,
          294,
          257,
          688,
          295,
          452,
          960,
          17616,
          50688
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 181.64,
        "id": 71,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 178.92,
        "temperature": 0,
        "text": " is it has a Sketch RNN module for you.",
        "tokens": [
          50688,
          307,
          309,
          575,
          257,
          49245,
          45702,
          45,
          10088,
          337,
          291,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 184.52,
        "id": 72,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 181.64,
        "temperature": 0,
        "text": " So on the one hand, you might want to go",
        "tokens": [
          50824,
          407,
          322,
          264,
          472,
          1011,
          11,
          291,
          1062,
          528,
          281,
          352,
          50968
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 186.56,
        "id": 73,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 184.52,
        "temperature": 0,
        "text": " and look all the way through all this code",
        "tokens": [
          50968,
          293,
          574,
          439,
          264,
          636,
          807,
          439,
          341,
          3089,
          51070
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 188.78,
        "id": 74,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 186.56,
        "temperature": 0,
        "text": " and read the research paper to learn how it works,",
        "tokens": [
          51070,
          293,
          1401,
          264,
          2132,
          3035,
          281,
          1466,
          577,
          309,
          1985,
          11,
          51181
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 190.34,
        "id": 75,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 188.78,
        "temperature": 0,
        "text": " but if you want to quickly get up and running",
        "tokens": [
          51181,
          457,
          498,
          291,
          528,
          281,
          2661,
          483,
          493,
          293,
          2614,
          51259
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 192.52,
        "id": 76,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 190.34,
        "temperature": 0,
        "text": " with playing with the Sketch RNN model,",
        "tokens": [
          51259,
          365,
          2433,
          365,
          264,
          49245,
          45702,
          45,
          2316,
          11,
          51368
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 196.04,
        "id": 77,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 192.52,
        "temperature": 0,
        "text": " what we've tried to put in ML5 will help you.",
        "tokens": [
          51368,
          437,
          321,
          600,
          3031,
          281,
          829,
          294,
          21601,
          20,
          486,
          854,
          291,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 199.96,
        "id": 78,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 196.04,
        "temperature": 0,
        "text": " Now, you might notice that if I go click on reference,",
        "tokens": [
          51544,
          823,
          11,
          291,
          1062,
          3449,
          300,
          498,
          286,
          352,
          2052,
          322,
          6408,
          11,
          51740
        ]
      },
      {
        "avg_logprob": -0.21978027938950992,
        "compression_ratio": 1.6666666666666667,
        "end": 201.3,
        "id": 79,
        "no_speech_prob": 0.000027969221264356747,
        "seek": 17244,
        "start": 199.96,
        "temperature": 0,
        "text": " at the time of this recording,",
        "tokens": [
          51740,
          412,
          264,
          565,
          295,
          341,
          6613,
          11,
          51807
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 203.22,
        "id": 80,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 201.3,
        "temperature": 0,
        "text": " it doesn't say Sketch RNN here.",
        "tokens": [
          50364,
          309,
          1177,
          380,
          584,
          49245,
          45702,
          45,
          510,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 205.78,
        "id": 81,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 203.22,
        "temperature": 0,
        "text": " So this is actually a new feature.",
        "tokens": [
          50460,
          407,
          341,
          307,
          767,
          257,
          777,
          4111,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 209.94,
        "id": 82,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 205.78,
        "temperature": 0,
        "text": " There's a couple issues in the GitHub repository for ML5",
        "tokens": [
          50588,
          821,
          311,
          257,
          1916,
          2663,
          294,
          264,
          23331,
          25841,
          337,
          21601,
          20,
          50796
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 211.42000000000002,
        "id": 83,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 209.94,
        "temperature": 0,
        "text": " about things that don't work perfectly",
        "tokens": [
          50796,
          466,
          721,
          300,
          500,
          380,
          589,
          6239,
          50870
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 212.8,
        "id": 84,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 211.42000000000002,
        "temperature": 0,
        "text": " or need to be added or fixed.",
        "tokens": [
          50870,
          420,
          643,
          281,
          312,
          3869,
          420,
          6806,
          13,
          50939
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 214.58,
        "id": 85,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 212.8,
        "temperature": 0,
        "text": " We welcome contributions.",
        "tokens": [
          50939,
          492,
          2928,
          15725,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 217.10000000000002,
        "id": 86,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 214.58,
        "temperature": 0,
        "text": " I will come back and maybe do some more videos with it",
        "tokens": [
          51028,
          286,
          486,
          808,
          646,
          293,
          1310,
          360,
          512,
          544,
          2145,
          365,
          309,
          51154
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 219.58,
        "id": 87,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 217.10000000000002,
        "temperature": 0,
        "text": " once it's gotten further along and there is documentation,",
        "tokens": [
          51154,
          1564,
          309,
          311,
          5768,
          3052,
          2051,
          293,
          456,
          307,
          14333,
          11,
          51278
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 222.82000000000002,
        "id": 88,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 219.58,
        "temperature": 0,
        "text": " but for the holiday season, let's see if we can get it",
        "tokens": [
          51278,
          457,
          337,
          264,
          9960,
          3196,
          11,
          718,
          311,
          536,
          498,
          321,
          393,
          483,
          309,
          51440
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 225.06,
        "id": 89,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 222.82000000000002,
        "temperature": 0,
        "text": " to draw a snowflake for us.",
        "tokens": [
          51440,
          281,
          2642,
          257,
          44124,
          619,
          337,
          505,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 227.28,
        "id": 90,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 225.06,
        "temperature": 0,
        "text": " So I'm not going to be able to use the website",
        "tokens": [
          51552,
          407,
          286,
          478,
          406,
          516,
          281,
          312,
          1075,
          281,
          764,
          264,
          3144,
          51663
        ]
      },
      {
        "avg_logprob": -0.18114966240482053,
        "compression_ratio": 1.6161290322580646,
        "end": 229.8,
        "id": 91,
        "no_speech_prob": 0.0000061441523939720355,
        "seek": 20130,
        "start": 227.28,
        "temperature": 0,
        "text": " because the documentation isn't there,",
        "tokens": [
          51663,
          570,
          264,
          14333,
          1943,
          380,
          456,
          11,
          51789
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 232.64000000000001,
        "id": 92,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 229.8,
        "temperature": 0,
        "text": " but I've got some documentation over here",
        "tokens": [
          50364,
          457,
          286,
          600,
          658,
          512,
          14333,
          670,
          510,
          50506
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 235.8,
        "id": 93,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 232.64000000000001,
        "temperature": 0,
        "text": " on my invisible computer that I can look at if I need to.",
        "tokens": [
          50506,
          322,
          452,
          14603,
          3820,
          300,
          286,
          393,
          574,
          412,
          498,
          286,
          643,
          281,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 238.48000000000002,
        "id": 94,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 237.28,
        "temperature": 0,
        "text": " And so what do I have?",
        "tokens": [
          50738,
          400,
          370,
          437,
          360,
          286,
          362,
          30,
          50798
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 242.56,
        "id": 95,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 238.48000000000002,
        "temperature": 0,
        "text": " I have a blank p5 sketch with just setup and draw,",
        "tokens": [
          50798,
          286,
          362,
          257,
          8247,
          280,
          20,
          12325,
          365,
          445,
          8657,
          293,
          2642,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 244.8,
        "id": 96,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 242.56,
        "temperature": 0,
        "text": " and also an index.html, I should call this",
        "tokens": [
          51002,
          293,
          611,
          364,
          8186,
          13,
          357,
          15480,
          11,
          286,
          820,
          818,
          341,
          51114
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 247.92000000000002,
        "id": 97,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 244.8,
        "temperature": 0,
        "text": " a snowflake sketch RNN.",
        "tokens": [
          51114,
          257,
          44124,
          619,
          12325,
          45702,
          45,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 252.20000000000002,
        "id": 98,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 247.92000000000002,
        "temperature": 0,
        "text": " I have also, in addition to the p5 libraries being imported,",
        "tokens": [
          51270,
          286,
          362,
          611,
          11,
          294,
          4500,
          281,
          264,
          280,
          20,
          15148,
          885,
          25524,
          11,
          51484
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 254.24,
        "id": 99,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 252.20000000000002,
        "temperature": 0,
        "text": " I have the ML5 library, and again,",
        "tokens": [
          51484,
          286,
          362,
          264,
          21601,
          20,
          6405,
          11,
          293,
          797,
          11,
          51586
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 257.2,
        "id": 100,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 254.24,
        "temperature": 0,
        "text": " at the time of this recording, it's version 0.1.3.",
        "tokens": [
          51586,
          412,
          264,
          565,
          295,
          341,
          6613,
          11,
          309,
          311,
          3037,
          1958,
          13,
          16,
          13,
          18,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.22782553159273589,
        "compression_ratio": 1.539855072463768,
        "end": 258.68,
        "id": 101,
        "no_speech_prob": 0.000008398045793001074,
        "seek": 22980,
        "start": 257.2,
        "temperature": 0,
        "text": " Hopefully, there'll be future updates",
        "tokens": [
          51734,
          10429,
          11,
          456,
          603,
          312,
          2027,
          9205,
          51808
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 260.76,
        "id": 102,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 258.68,
        "temperature": 0,
        "text": " to improve Sketch RNN and there'll be",
        "tokens": [
          50364,
          281,
          3470,
          49245,
          45702,
          45,
          293,
          456,
          603,
          312,
          50468
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 262.56,
        "id": 103,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 260.76,
        "temperature": 0,
        "text": " a higher numbered version.",
        "tokens": [
          50468,
          257,
          2946,
          40936,
          3037,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 264.76,
        "id": 104,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 262.56,
        "temperature": 0,
        "text": " Okay, so the first thing that I want to do",
        "tokens": [
          50558,
          1033,
          11,
          370,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          50668
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 268.08,
        "id": 105,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 264.76,
        "temperature": 0,
        "text": " is I want to make a variable and I'm going to call it model.",
        "tokens": [
          50668,
          307,
          286,
          528,
          281,
          652,
          257,
          7006,
          293,
          286,
          478,
          516,
          281,
          818,
          309,
          2316,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 270,
        "id": 106,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 268.08,
        "temperature": 0,
        "text": " So model, I could call it Sketch RNN,",
        "tokens": [
          50834,
          407,
          2316,
          11,
          286,
          727,
          818,
          309,
          49245,
          45702,
          45,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 271.2,
        "id": 107,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 270,
        "temperature": 0,
        "text": " maybe I should call it Sketch RNN.",
        "tokens": [
          50930,
          1310,
          286,
          820,
          818,
          309,
          49245,
          45702,
          45,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 272.02,
        "id": 108,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 271.2,
        "temperature": 0,
        "text": " I'll just call it model.",
        "tokens": [
          50990,
          286,
          603,
          445,
          818,
          309,
          2316,
          13,
          51031
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 274.8,
        "id": 109,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 272.02,
        "temperature": 0,
        "text": " Model is the thing that's going to hold",
        "tokens": [
          51031,
          17105,
          307,
          264,
          551,
          300,
          311,
          516,
          281,
          1797,
          51170
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 276.84000000000003,
        "id": 110,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 274.8,
        "temperature": 0,
        "text": " the Sketch RNN model.",
        "tokens": [
          51170,
          264,
          49245,
          45702,
          45,
          2316,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 279.72,
        "id": 111,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 276.84000000000003,
        "temperature": 0,
        "text": " It is all of the information, it's the brain",
        "tokens": [
          51272,
          467,
          307,
          439,
          295,
          264,
          1589,
          11,
          309,
          311,
          264,
          3567,
          51416
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 282,
        "id": 112,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 279.72,
        "temperature": 0,
        "text": " of that neural network that we can ask",
        "tokens": [
          51416,
          295,
          300,
          18161,
          3209,
          300,
          321,
          393,
          1029,
          51530
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 283.48,
        "id": 113,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 282,
        "temperature": 0,
        "text": " to generate new stuff.",
        "tokens": [
          51530,
          281,
          8460,
          777,
          1507,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 285.6,
        "id": 114,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 283.48,
        "temperature": 0,
        "text": " So we can say, hey, give me a new point",
        "tokens": [
          51604,
          407,
          321,
          393,
          584,
          11,
          4177,
          11,
          976,
          385,
          257,
          777,
          935,
          51710
        ]
      },
      {
        "avg_logprob": -0.19931748828048226,
        "compression_ratio": 1.8475177304964538,
        "end": 287.92,
        "id": 115,
        "no_speech_prob": 0.00002796928492898587,
        "seek": 25868,
        "start": 285.6,
        "temperature": 0,
        "text": " along the path that you're imagining to draw.",
        "tokens": [
          51710,
          2051,
          264,
          3100,
          300,
          291,
          434,
          27798,
          281,
          2642,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 292.96000000000004,
        "id": 116,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 287.96000000000004,
        "temperature": 0,
        "text": " So I'm going to say model equals ML5 Sketch RNN",
        "tokens": [
          50366,
          407,
          286,
          478,
          516,
          281,
          584,
          2316,
          6915,
          21601,
          20,
          49245,
          45702,
          45,
          50616
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 299.68,
        "id": 117,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 296.28000000000003,
        "temperature": 0,
        "text": " and then I'm going to just put a callback in here,",
        "tokens": [
          50782,
          293,
          550,
          286,
          478,
          516,
          281,
          445,
          829,
          257,
          818,
          3207,
          294,
          510,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 301.16,
        "id": 118,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 299.68,
        "temperature": 0,
        "text": " model ready, and this is the important thing.",
        "tokens": [
          50952,
          2316,
          1919,
          11,
          293,
          341,
          307,
          264,
          1021,
          551,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 302.72,
        "id": 119,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 301.16,
        "temperature": 0,
        "text": " What goes here?",
        "tokens": [
          51026,
          708,
          1709,
          510,
          30,
          51104
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 306.88,
        "id": 120,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 302.72,
        "temperature": 0,
        "text": " So there are a bunch of available models",
        "tokens": [
          51104,
          407,
          456,
          366,
          257,
          3840,
          295,
          2435,
          5245,
          51312
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 309.12,
        "id": 121,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 306.88,
        "temperature": 0,
        "text": " with Sketch RNN and we could see that list here.",
        "tokens": [
          51312,
          365,
          49245,
          45702,
          45,
          293,
          321,
          727,
          536,
          300,
          1329,
          510,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 309.94,
        "id": 122,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 309.12,
        "temperature": 0,
        "text": " Whoops, here.",
        "tokens": [
          51424,
          45263,
          11,
          510,
          13,
          51465
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 311.20000000000005,
        "id": 123,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 309.94,
        "temperature": 0,
        "text": " For example, there is cat.",
        "tokens": [
          51465,
          1171,
          1365,
          11,
          456,
          307,
          3857,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 313.24,
        "id": 124,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 311.20000000000005,
        "temperature": 0,
        "text": " Let's start with cat, maybe.",
        "tokens": [
          51528,
          961,
          311,
          722,
          365,
          3857,
          11,
          1310,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 314.52000000000004,
        "id": 125,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 313.24,
        "temperature": 0,
        "text": " But we could see all the other ones,",
        "tokens": [
          51630,
          583,
          321,
          727,
          536,
          439,
          264,
          661,
          2306,
          11,
          51694
        ]
      },
      {
        "avg_logprob": -0.22869854286068775,
        "compression_ratio": 1.6326530612244898,
        "end": 317.06,
        "id": 126,
        "no_speech_prob": 0.000002813011178659508,
        "seek": 28792,
        "start": 314.52000000000004,
        "temperature": 0,
        "text": " like the Mona Lisa apparently is in there.",
        "tokens": [
          51694,
          411,
          264,
          43731,
          12252,
          7970,
          307,
          294,
          456,
          13,
          51821
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 321.66,
        "id": 127,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 317.06,
        "temperature": 0,
        "text": " Bird, so let's, whatever is available,",
        "tokens": [
          50364,
          15931,
          11,
          370,
          718,
          311,
          11,
          2035,
          307,
          2435,
          11,
          50594
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 323.42,
        "id": 128,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 321.66,
        "temperature": 0,
        "text": " we can put cat in here.",
        "tokens": [
          50594,
          321,
          393,
          829,
          3857,
          294,
          510,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 326.62,
        "id": 129,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 323.42,
        "temperature": 0,
        "text": " I'm asking ML5 to load the cat model.",
        "tokens": [
          50682,
          286,
          478,
          3365,
          21601,
          20,
          281,
          3677,
          264,
          3857,
          2316,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 329.22,
        "id": 130,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 326.62,
        "temperature": 0,
        "text": " It's actually doing this from the cloud.",
        "tokens": [
          50842,
          467,
          311,
          767,
          884,
          341,
          490,
          264,
          4588,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 331.7,
        "id": 131,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 329.22,
        "temperature": 0,
        "text": " The model, all of the data for this machine learning model",
        "tokens": [
          50972,
          440,
          2316,
          11,
          439,
          295,
          264,
          1412,
          337,
          341,
          3479,
          2539,
          2316,
          51096
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 333.22,
        "id": 132,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 331.7,
        "temperature": 0,
        "text": " is stored on a server somewhere",
        "tokens": [
          51096,
          307,
          12187,
          322,
          257,
          7154,
          4079,
          51172
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 335.54,
        "id": 133,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 333.22,
        "temperature": 0,
        "text": " and ML5 knows how to load that for you.",
        "tokens": [
          51172,
          293,
          21601,
          20,
          3255,
          577,
          281,
          3677,
          300,
          337,
          291,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 338.78,
        "id": 134,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 335.54,
        "temperature": 0,
        "text": " So then what I'm going to do is add a callback.",
        "tokens": [
          51288,
          407,
          550,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          909,
          257,
          818,
          3207,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 341.1,
        "id": 135,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 338.78,
        "temperature": 0,
        "text": " I'm going to say model ready.",
        "tokens": [
          51450,
          286,
          478,
          516,
          281,
          584,
          2316,
          1919,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 342.94,
        "id": 136,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 341.1,
        "temperature": 0,
        "text": " I'm going to write a function called model ready",
        "tokens": [
          51566,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          1219,
          2316,
          1919,
          51658
        ]
      },
      {
        "avg_logprob": -0.19509761951587817,
        "compression_ratio": 1.7786561264822134,
        "end": 346.94,
        "id": 137,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 31706,
        "start": 342.94,
        "temperature": 0,
        "text": " and I'm just going to say console.log model ready.",
        "tokens": [
          51658,
          293,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          13,
          4987,
          2316,
          1919,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 350.34,
        "id": 138,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 347.78,
        "temperature": 0,
        "text": " So let's just run this code and see if it even just works",
        "tokens": [
          50406,
          407,
          718,
          311,
          445,
          1190,
          341,
          3089,
          293,
          536,
          498,
          309,
          754,
          445,
          1985,
          50534
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 352.1,
        "id": 139,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 350.34,
        "temperature": 0,
        "text": " loading the model without an error.",
        "tokens": [
          50534,
          15114,
          264,
          2316,
          1553,
          364,
          6713,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 354.94,
        "id": 140,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 353.44,
        "temperature": 0,
        "text": " So I'm going to close this demo down.",
        "tokens": [
          50689,
          407,
          286,
          478,
          516,
          281,
          1998,
          341,
          10723,
          760,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 356.1,
        "id": 141,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 354.94,
        "temperature": 0,
        "text": " I have my own here.",
        "tokens": [
          50764,
          286,
          362,
          452,
          1065,
          510,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 358.1,
        "id": 142,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 356.1,
        "temperature": 0,
        "text": " Okay, great, the model is loaded.",
        "tokens": [
          50822,
          1033,
          11,
          869,
          11,
          264,
          2316,
          307,
          13210,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 359.9,
        "id": 143,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 358.1,
        "temperature": 0,
        "text": " And just to be sure, oh, yeah,",
        "tokens": [
          50922,
          400,
          445,
          281,
          312,
          988,
          11,
          1954,
          11,
          1338,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 361.58,
        "id": 144,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 359.9,
        "temperature": 0,
        "text": " initialize Sketch RNN model ready,",
        "tokens": [
          51012,
          5883,
          1125,
          49245,
          45702,
          45,
          2316,
          1919,
          11,
          51096
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 364.46,
        "id": 145,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 361.58,
        "temperature": 0,
        "text": " just to be sure if I put in here tiger,",
        "tokens": [
          51096,
          445,
          281,
          312,
          988,
          498,
          286,
          829,
          294,
          510,
          21432,
          11,
          51240
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 366.58,
        "id": 146,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 364.46,
        "temperature": 0,
        "text": " which I don't think is something in there.",
        "tokens": [
          51240,
          597,
          286,
          500,
          380,
          519,
          307,
          746,
          294,
          456,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 370.1,
        "id": 147,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 368.06,
        "temperature": 0,
        "text": " Oh, maybe it is.",
        "tokens": [
          51420,
          876,
          11,
          1310,
          309,
          307,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 372.7,
        "id": 148,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 370.1,
        "temperature": 0,
        "text": " Guacamole, that must not be something in there.",
        "tokens": [
          51522,
          2694,
          47190,
          4812,
          11,
          300,
          1633,
          406,
          312,
          746,
          294,
          456,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 374.46,
        "id": 149,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 372.7,
        "temperature": 0,
        "text": " I spelled guacamole wrong even, okay?",
        "tokens": [
          51652,
          286,
          34388,
          695,
          47190,
          4812,
          2085,
          754,
          11,
          1392,
          30,
          51740
        ]
      },
      {
        "avg_logprob": -0.2733325958251953,
        "compression_ratio": 1.7003610108303249,
        "end": 375.94,
        "id": 150,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 34694,
        "start": 374.46,
        "temperature": 0,
        "text": " Right, it couldn't find guacamole",
        "tokens": [
          51740,
          1779,
          11,
          309,
          2809,
          380,
          915,
          695,
          47190,
          4812,
          51814
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 377.38,
        "id": 151,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 375.94,
        "temperature": 0,
        "text": " and I know that's spelled wrong.",
        "tokens": [
          50364,
          293,
          286,
          458,
          300,
          311,
          34388,
          2085,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 380.54,
        "id": 152,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 377.38,
        "temperature": 0,
        "text": " Apologies to guacamole lovers all over the world.",
        "tokens": [
          50436,
          8723,
          6204,
          281,
          695,
          47190,
          4812,
          22697,
          439,
          670,
          264,
          1002,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 382.26,
        "id": 153,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 380.54,
        "temperature": 0,
        "text": " Okay, so we've got the cat.",
        "tokens": [
          50594,
          1033,
          11,
          370,
          321,
          600,
          658,
          264,
          3857,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 383.84,
        "id": 154,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 382.26,
        "temperature": 0,
        "text": " Now what do I need to do?",
        "tokens": [
          50680,
          823,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          50759
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 387.34,
        "id": 155,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 383.84,
        "temperature": 0,
        "text": " The first thing I need to do as soon as the model is ready",
        "tokens": [
          50759,
          440,
          700,
          551,
          286,
          643,
          281,
          360,
          382,
          2321,
          382,
          264,
          2316,
          307,
          1919,
          50934
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 389.16,
        "id": 156,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 387.34,
        "temperature": 0,
        "text": " is ask for something.",
        "tokens": [
          50934,
          307,
          1029,
          337,
          746,
          13,
          51025
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 393.22,
        "id": 157,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 389.16,
        "temperature": 0,
        "text": " So what Sketch RNN will give you every time",
        "tokens": [
          51025,
          407,
          437,
          49245,
          45702,
          45,
          486,
          976,
          291,
          633,
          565,
          51228
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 395.18,
        "id": 158,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 393.22,
        "temperature": 0,
        "text": " you ask for it to generate something",
        "tokens": [
          51228,
          291,
          1029,
          337,
          309,
          281,
          8460,
          746,
          51326
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 398.4,
        "id": 159,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 395.18,
        "temperature": 0,
        "text": " is what is referred to as a stroke.",
        "tokens": [
          51326,
          307,
          437,
          307,
          10839,
          281,
          382,
          257,
          12403,
          13,
          51487
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 400.78,
        "id": 160,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 398.4,
        "temperature": 0,
        "text": " Now I'm not going to use the variable named stroke",
        "tokens": [
          51487,
          823,
          286,
          478,
          406,
          516,
          281,
          764,
          264,
          7006,
          4926,
          12403,
          51606
        ]
      },
      {
        "avg_logprob": -0.18348766297333,
        "compression_ratio": 1.6590909090909092,
        "end": 404.5,
        "id": 161,
        "no_speech_prob": 9.721542255647364e-7,
        "seek": 37594,
        "start": 400.78,
        "temperature": 0,
        "text": " in my code because stroke is a global function in p5",
        "tokens": [
          51606,
          294,
          452,
          3089,
          570,
          12403,
          307,
          257,
          4338,
          2445,
          294,
          280,
          20,
          51792
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 406.46,
        "id": 162,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 404.5,
        "temperature": 0,
        "text": " that sets the outline color of a shape",
        "tokens": [
          50364,
          300,
          6352,
          264,
          16387,
          2017,
          295,
          257,
          3909,
          50462
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 408.14,
        "id": 163,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 406.46,
        "temperature": 0,
        "text": " and I don't want to get confused with that.",
        "tokens": [
          50462,
          293,
          286,
          500,
          380,
          528,
          281,
          483,
          9019,
          365,
          300,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 412.34,
        "id": 164,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 408.14,
        "temperature": 0,
        "text": " But the stroke is a particular,",
        "tokens": [
          50546,
          583,
          264,
          12403,
          307,
          257,
          1729,
          11,
          50756
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 414.94,
        "id": 165,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 412.34,
        "temperature": 0,
        "text": " a JavaScript object with a few properties.",
        "tokens": [
          50756,
          257,
          15778,
          2657,
          365,
          257,
          1326,
          7221,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 419.94,
        "id": 166,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 414.94,
        "temperature": 0,
        "text": " It has dx, dy, and I think it's just called pen.",
        "tokens": [
          50886,
          467,
          575,
          30017,
          11,
          14584,
          11,
          293,
          286,
          519,
          309,
          311,
          445,
          1219,
          3435,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 426.42,
        "id": 167,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 421.7,
        "temperature": 0,
        "text": " And dx is a floating point number, some number like 1.3.",
        "tokens": [
          51224,
          400,
          30017,
          307,
          257,
          12607,
          935,
          1230,
          11,
          512,
          1230,
          411,
          502,
          13,
          18,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 428.9,
        "id": 168,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 426.42,
        "temperature": 0,
        "text": " Dy is some number like negative four.",
        "tokens": [
          51460,
          31193,
          307,
          512,
          1230,
          411,
          3671,
          1451,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.1905025045077006,
        "compression_ratio": 1.5188679245283019,
        "end": 430.88,
        "id": 169,
        "no_speech_prob": 0.0000030415953915508,
        "seek": 40450,
        "start": 428.9,
        "temperature": 0,
        "text": " And pen is a string.",
        "tokens": [
          51584,
          400,
          3435,
          307,
          257,
          6798,
          13,
          51683
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 435.88,
        "id": 170,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 430.88,
        "temperature": 0,
        "text": " It can either be up, down, or end.",
        "tokens": [
          50364,
          467,
          393,
          2139,
          312,
          493,
          11,
          760,
          11,
          420,
          917,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 439.64,
        "id": 171,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 435.98,
        "temperature": 0,
        "text": " And what this refers to is a particular stroke",
        "tokens": [
          50619,
          400,
          437,
          341,
          14942,
          281,
          307,
          257,
          1729,
          12403,
          50802
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 441,
        "id": 172,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 439.64,
        "temperature": 0,
        "text": " of a pen basically.",
        "tokens": [
          50802,
          295,
          257,
          3435,
          1936,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 444.96,
        "id": 173,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 441,
        "temperature": 0,
        "text": " So if you could imagine dx for the change in x, delta x,",
        "tokens": [
          50870,
          407,
          498,
          291,
          727,
          3811,
          30017,
          337,
          264,
          1319,
          294,
          2031,
          11,
          8289,
          2031,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 447.71999999999997,
        "id": 174,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 444.96,
        "temperature": 0,
        "text": " dy for the change in y, delta y.",
        "tokens": [
          51068,
          14584,
          337,
          264,
          1319,
          294,
          288,
          11,
          8289,
          288,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 452.71999999999997,
        "id": 175,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 447.71999999999997,
        "temperature": 0,
        "text": " If I were to go over 1.3 units and up negative four units,",
        "tokens": [
          51206,
          759,
          286,
          645,
          281,
          352,
          670,
          502,
          13,
          18,
          6815,
          293,
          493,
          3671,
          1451,
          6815,
          11,
          51456
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 455.24,
        "id": 176,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 453.28,
        "temperature": 0,
        "text": " basically the stroke is this.",
        "tokens": [
          51484,
          1936,
          264,
          12403,
          307,
          341,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.18312859048648755,
        "compression_ratio": 1.5685279187817258,
        "end": 457.34,
        "id": 177,
        "no_speech_prob": 5.122897732690035e-7,
        "seek": 43088,
        "start": 455.24,
        "temperature": 0,
        "text": " This is the path of the pen.",
        "tokens": [
          51582,
          639,
          307,
          264,
          3100,
          295,
          264,
          3435,
          13,
          51687
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 461.7,
        "id": 178,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 457.34,
        "temperature": 0,
        "text": " That's what Sketch RNN should draw right now.",
        "tokens": [
          50364,
          663,
          311,
          437,
          49245,
          45702,
          45,
          820,
          2642,
          558,
          586,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 465.94,
        "id": 179,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 461.7,
        "temperature": 0,
        "text": " And it should either draw it as a line if the pen is down.",
        "tokens": [
          50582,
          400,
          309,
          820,
          2139,
          2642,
          309,
          382,
          257,
          1622,
          498,
          264,
          3435,
          307,
          760,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 468.7,
        "id": 180,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 465.94,
        "temperature": 0,
        "text": " If the pen is up, it should just move from here to there.",
        "tokens": [
          50794,
          759,
          264,
          3435,
          307,
          493,
          11,
          309,
          820,
          445,
          1286,
          490,
          510,
          281,
          456,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 470.73999999999995,
        "id": 181,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 468.7,
        "temperature": 0,
        "text": " Because if I'm drawing a cat, I'm going to draw this,",
        "tokens": [
          50932,
          1436,
          498,
          286,
          478,
          6316,
          257,
          3857,
          11,
          286,
          478,
          516,
          281,
          2642,
          341,
          11,
          51034
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 473.35999999999996,
        "id": 182,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 470.73999999999995,
        "temperature": 0,
        "text": " then I'm going to pick my pen up, move over here.",
        "tokens": [
          51034,
          550,
          286,
          478,
          516,
          281,
          1888,
          452,
          3435,
          493,
          11,
          1286,
          670,
          510,
          13,
          51165
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 476.02,
        "id": 183,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 473.35999999999996,
        "temperature": 0,
        "text": " So that action is also a stroke,",
        "tokens": [
          51165,
          407,
          300,
          3069,
          307,
          611,
          257,
          12403,
          11,
          51298
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 477.62,
        "id": 184,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 476.02,
        "temperature": 0,
        "text": " but it's a stroke with the pen up.",
        "tokens": [
          51298,
          457,
          309,
          311,
          257,
          12403,
          365,
          264,
          3435,
          493,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 481.97999999999996,
        "id": 185,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 477.62,
        "temperature": 0,
        "text": " And then pen end is when the drawing is finished.",
        "tokens": [
          51378,
          400,
          550,
          3435,
          917,
          307,
          562,
          264,
          6316,
          307,
          4335,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 484.29999999999995,
        "id": 186,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 481.97999999999996,
        "temperature": 0,
        "text": " So this is what ml5 does.",
        "tokens": [
          51596,
          407,
          341,
          307,
          437,
          23271,
          20,
          775,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.18918312297147863,
        "compression_ratio": 1.7588932806324111,
        "end": 486.82,
        "id": 187,
        "no_speech_prob": 0.0000010188089163420955,
        "seek": 45734,
        "start": 484.29999999999995,
        "temperature": 0,
        "text": " The actual native Sketch RNN model",
        "tokens": [
          51712,
          440,
          3539,
          8470,
          49245,
          45702,
          45,
          2316,
          51838
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 489.21999999999997,
        "id": 188,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 487.3,
        "temperature": 0,
        "text": " just gives you all these things as an array of numbers.",
        "tokens": [
          50388,
          445,
          2709,
          291,
          439,
          613,
          721,
          382,
          364,
          10225,
          295,
          3547,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 491.65999999999997,
        "id": 189,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 489.21999999999997,
        "temperature": 0,
        "text": " And so we've kind of made it as a JavaScript object",
        "tokens": [
          50484,
          400,
          370,
          321,
          600,
          733,
          295,
          1027,
          309,
          382,
          257,
          15778,
          2657,
          50606
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 494.7,
        "id": 190,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 491.65999999999997,
        "temperature": 0,
        "text": " that makes it a little bit easier to read, hopefully.",
        "tokens": [
          50606,
          300,
          1669,
          309,
          257,
          707,
          857,
          3571,
          281,
          1401,
          11,
          4696,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 496.82,
        "id": 191,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 494.7,
        "temperature": 0,
        "text": " Okay, so now coming back over here,",
        "tokens": [
          50758,
          1033,
          11,
          370,
          586,
          1348,
          646,
          670,
          510,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 501.82,
        "id": 192,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 496.82,
        "temperature": 0,
        "text": " I think I just say model.generate.sketch.",
        "tokens": [
          50864,
          286,
          519,
          286,
          445,
          584,
          2316,
          13,
          21848,
          473,
          13,
          5161,
          7858,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 505.36,
        "id": 193,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 503.03999999999996,
        "temperature": 0,
        "text": " I'm looking, oh, oh, oh, yes.",
        "tokens": [
          51175,
          286,
          478,
          1237,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          2086,
          13,
          51291
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 507.46,
        "id": 194,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 505.36,
        "temperature": 0,
        "text": " Now actually an important thing that I should probably do,",
        "tokens": [
          51291,
          823,
          767,
          364,
          1021,
          551,
          300,
          286,
          820,
          1391,
          360,
          11,
          51396
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 510.02,
        "id": 195,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 507.46,
        "temperature": 0,
        "text": " I don't necessarily need to do this the first time,",
        "tokens": [
          51396,
          286,
          500,
          380,
          4725,
          643,
          281,
          360,
          341,
          264,
          700,
          565,
          11,
          51524
        ]
      },
      {
        "avg_logprob": -0.2624206853106739,
        "compression_ratio": 1.568840579710145,
        "end": 513.96,
        "id": 196,
        "no_speech_prob": 0.00010889660916291177,
        "seek": 48682,
        "start": 510.02,
        "temperature": 0,
        "text": " but because this is a kind of machine learning model",
        "tokens": [
          51524,
          457,
          570,
          341,
          307,
          257,
          733,
          295,
          3479,
          2539,
          2316,
          51721
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 517.0400000000001,
        "id": 197,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 513.96,
        "temperature": 0,
        "text": " that is giving us sequential information,",
        "tokens": [
          50364,
          300,
          307,
          2902,
          505,
          42881,
          1589,
          11,
          50518
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 521.4200000000001,
        "id": 198,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 517.0400000000001,
        "temperature": 0,
        "text": " the next stroke, like the one that comes after this one,",
        "tokens": [
          50518,
          264,
          958,
          12403,
          11,
          411,
          264,
          472,
          300,
          1487,
          934,
          341,
          472,
          11,
          50737
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 524.62,
        "id": 199,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 521.4200000000001,
        "temperature": 0,
        "text": " is quite important, it's related to this one.",
        "tokens": [
          50737,
          307,
          1596,
          1021,
          11,
          309,
          311,
          4077,
          281,
          341,
          472,
          13,
          50897
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 527.24,
        "id": 200,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 524.62,
        "temperature": 0,
        "text": " But if I want to start over and draw a new cat,",
        "tokens": [
          50897,
          583,
          498,
          286,
          528,
          281,
          722,
          670,
          293,
          2642,
          257,
          777,
          3857,
          11,
          51028
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 528.9000000000001,
        "id": 201,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 527.24,
        "temperature": 0,
        "text": " I need to kind of go back to the beginning",
        "tokens": [
          51028,
          286,
          643,
          281,
          733,
          295,
          352,
          646,
          281,
          264,
          2863,
          51111
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 530.64,
        "id": 202,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 528.9000000000001,
        "temperature": 0,
        "text": " and say start a new cat over.",
        "tokens": [
          51111,
          293,
          584,
          722,
          257,
          777,
          3857,
          670,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 533.8000000000001,
        "id": 203,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 530.64,
        "temperature": 0,
        "text": " And so the model.reset function is a thing that does that.",
        "tokens": [
          51198,
          400,
          370,
          264,
          2316,
          13,
          495,
          302,
          2445,
          307,
          257,
          551,
          300,
          775,
          300,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 537,
        "id": 204,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 533.8000000000001,
        "temperature": 0,
        "text": " So model.reset, I'm going to call that,",
        "tokens": [
          51356,
          407,
          2316,
          13,
          495,
          302,
          11,
          286,
          478,
          516,
          281,
          818,
          300,
          11,
          51516
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 539,
        "id": 205,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 537,
        "temperature": 0,
        "text": " it should be reset the first time you load it,",
        "tokens": [
          51516,
          309,
          820,
          312,
          14322,
          264,
          700,
          565,
          291,
          3677,
          309,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 540.4000000000001,
        "id": 206,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 539,
        "temperature": 0,
        "text": " but I'm going to call that anyway.",
        "tokens": [
          51616,
          457,
          286,
          478,
          516,
          281,
          818,
          300,
          4033,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.18078480028126337,
        "compression_ratio": 1.7419354838709677,
        "end": 543.32,
        "id": 207,
        "no_speech_prob": 0.000010451539310452063,
        "seek": 51396,
        "start": 540.4000000000001,
        "temperature": 0,
        "text": " Then I could say model.generate.sketch,",
        "tokens": [
          51686,
          1396,
          286,
          727,
          584,
          2316,
          13,
          21848,
          473,
          13,
          5161,
          7858,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 544.9200000000001,
        "id": 208,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 543.32,
        "temperature": 0,
        "text": " and then I'm going to write a function,",
        "tokens": [
          50364,
          293,
          550,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          11,
          50444
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 546.44,
        "id": 209,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 544.9200000000001,
        "temperature": 0,
        "text": " I'm going to call it gotSketch.",
        "tokens": [
          50444,
          286,
          478,
          516,
          281,
          818,
          309,
          658,
          50,
          5758,
          339,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 548.48,
        "id": 210,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 546.44,
        "temperature": 0,
        "text": " It should get that strokePath.",
        "tokens": [
          50520,
          467,
          820,
          483,
          300,
          12403,
          47,
          998,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 553.1,
        "id": 211,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 548.48,
        "temperature": 0,
        "text": " Let's just call that s, and let's have a variable.",
        "tokens": [
          50622,
          961,
          311,
          445,
          818,
          300,
          262,
          11,
          293,
          718,
          311,
          362,
          257,
          7006,
          13,
          50853
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 557.24,
        "id": 212,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 553.1,
        "temperature": 0,
        "text": " I'm going to have a global variable called strokePath,",
        "tokens": [
          50853,
          286,
          478,
          516,
          281,
          362,
          257,
          4338,
          7006,
          1219,
          12403,
          47,
          998,
          11,
          51060
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 558.48,
        "id": 213,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 557.24,
        "temperature": 0,
        "text": " and I'm going to set that to,",
        "tokens": [
          51060,
          293,
          286,
          478,
          516,
          281,
          992,
          300,
          281,
          11,
          51122
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 560.9200000000001,
        "id": 214,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 558.48,
        "temperature": 0,
        "text": " I'm just going to set it to null when the program starts,",
        "tokens": [
          51122,
          286,
          478,
          445,
          516,
          281,
          992,
          309,
          281,
          18184,
          562,
          264,
          1461,
          3719,
          11,
          51244
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 562.32,
        "id": 215,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 560.9200000000001,
        "temperature": 0,
        "text": " and then when I get a new sketch,",
        "tokens": [
          51244,
          293,
          550,
          562,
          286,
          483,
          257,
          777,
          12325,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 564.72,
        "id": 216,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 562.32,
        "temperature": 0,
        "text": " I'm going to say strokePath equals s,",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          584,
          12403,
          47,
          998,
          6915,
          262,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 568.12,
        "id": 217,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 564.72,
        "temperature": 0,
        "text": " and then I'm just going to say console.log strokePath.",
        "tokens": [
          51434,
          293,
          550,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          13,
          4987,
          12403,
          47,
          998,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.19360954697067673,
        "compression_ratio": 2.0440528634361232,
        "end": 570.12,
        "id": 218,
        "no_speech_prob": 0.000042646955989766866,
        "seek": 54332,
        "start": 568.12,
        "temperature": 0,
        "text": " So let's see if we get this first thing.",
        "tokens": [
          51604,
          407,
          718,
          311,
          536,
          498,
          321,
          483,
          341,
          700,
          551,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 574.96,
        "id": 219,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 573.4000000000001,
        "temperature": 0,
        "text": " Model loaded!",
        "tokens": [
          50368,
          17105,
          13210,
          0,
          50446
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 575.8000000000001,
        "id": 220,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 574.96,
        "temperature": 0,
        "text": " Undefined.",
        "tokens": [
          50446,
          2719,
          5666,
          2001,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 576.6400000000001,
        "id": 221,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 575.8000000000001,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50488,
          7951,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 578.62,
        "id": 222,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 577.5600000000001,
        "temperature": 0,
        "text": " That was close.",
        "tokens": [
          50576,
          663,
          390,
          1998,
          13,
          50629
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 581.48,
        "id": 223,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 580.2800000000001,
        "temperature": 0,
        "text": " I forgot.",
        "tokens": [
          50712,
          286,
          5298,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 582.48,
        "id": 224,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 581.48,
        "temperature": 0,
        "text": " This is actually very hard for me.",
        "tokens": [
          50772,
          639,
          307,
          767,
          588,
          1152,
          337,
          385,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 584.72,
        "id": 225,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 582.48,
        "temperature": 0,
        "text": " I always make this mistake.",
        "tokens": [
          50822,
          286,
          1009,
          652,
          341,
          6146,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 587,
        "id": 226,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 584.72,
        "temperature": 0,
        "text": " ML5 is written in such a way",
        "tokens": [
          50934,
          21601,
          20,
          307,
          3720,
          294,
          1270,
          257,
          636,
          51048
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 589.22,
        "id": 227,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 587,
        "temperature": 0,
        "text": " that uses something called error first callbacks.",
        "tokens": [
          51048,
          300,
          4960,
          746,
          1219,
          6713,
          700,
          818,
          17758,
          13,
          51159
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 591.48,
        "id": 228,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 589.22,
        "temperature": 0,
        "text": " This is different than how P5 is written.",
        "tokens": [
          51159,
          639,
          307,
          819,
          813,
          577,
          430,
          20,
          307,
          3720,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 594.38,
        "id": 229,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 591.48,
        "temperature": 0,
        "text": " So this gotSketch function is receiving,",
        "tokens": [
          51272,
          407,
          341,
          658,
          50,
          5758,
          339,
          2445,
          307,
          10040,
          11,
          51417
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 596.44,
        "id": 230,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 594.38,
        "temperature": 0,
        "text": " what was actually undefined there was the error.",
        "tokens": [
          51417,
          437,
          390,
          767,
          674,
          5666,
          2001,
          456,
          390,
          264,
          6713,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 597.8800000000001,
        "id": 231,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 596.44,
        "temperature": 0,
        "text": " There was no error.",
        "tokens": [
          51520,
          821,
          390,
          572,
          6713,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.27533148193359375,
        "compression_ratio": 1.6804979253112033,
        "end": 602.12,
        "id": 232,
        "no_speech_prob": 0.000015936606359900907,
        "seek": 57332,
        "start": 597.8800000000001,
        "temperature": 0,
        "text": " All the callbacks need to have an error argument first.",
        "tokens": [
          51592,
          1057,
          264,
          818,
          17758,
          643,
          281,
          362,
          364,
          6713,
          6770,
          700,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 603.68,
        "id": 233,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 602.12,
        "temperature": 0,
        "text": " So if I wanted to be really,",
        "tokens": [
          50364,
          407,
          498,
          286,
          1415,
          281,
          312,
          534,
          11,
          50442
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 607.5600000000001,
        "id": 234,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 605.16,
        "temperature": 0,
        "text": " if I wanted to be really thorough about error handling,",
        "tokens": [
          50516,
          498,
          286,
          1415,
          281,
          312,
          534,
          12934,
          466,
          6713,
          13175,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 609.12,
        "id": 235,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 607.5600000000001,
        "temperature": 0,
        "text": " I might do something like this.",
        "tokens": [
          50636,
          286,
          1062,
          360,
          746,
          411,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 616.52,
        "id": 236,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 612.36,
        "temperature": 0,
        "text": " So I could console out the error,",
        "tokens": [
          50876,
          407,
          286,
          727,
          11076,
          484,
          264,
          6713,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 618.72,
        "id": 237,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 616.52,
        "temperature": 0,
        "text": " and then if there is no error,",
        "tokens": [
          51084,
          293,
          550,
          498,
          456,
          307,
          572,
          6713,
          11,
          51194
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 620.88,
        "id": 238,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 618.72,
        "temperature": 0,
        "text": " now just console.log out the strokePath.",
        "tokens": [
          51194,
          586,
          445,
          11076,
          13,
          4987,
          484,
          264,
          12403,
          47,
          998,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 622.16,
        "id": 239,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 620.88,
        "temperature": 0,
        "text": " So this should work now.",
        "tokens": [
          51302,
          407,
          341,
          820,
          589,
          586,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 626.96,
        "id": 240,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 625.72,
        "temperature": 0,
        "text": " Look at that model!",
        "tokens": [
          51544,
          2053,
          412,
          300,
          2316,
          0,
          51606
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 627.8,
        "id": 241,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 626.96,
        "temperature": 0,
        "text": " Ah, there we go!",
        "tokens": [
          51606,
          2438,
          11,
          456,
          321,
          352,
          0,
          51648
        ]
      },
      {
        "avg_logprob": -0.2550829857895055,
        "compression_ratio": 1.6538461538461537,
        "end": 629.16,
        "id": 242,
        "no_speech_prob": 0.0000012289182222957606,
        "seek": 60212,
        "start": 627.8,
        "temperature": 0,
        "text": " So look at this!",
        "tokens": [
          51648,
          407,
          574,
          412,
          341,
          0,
          51716
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 632.16,
        "id": 243,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 629.16,
        "temperature": 0,
        "text": " I need to move this many pixels in the x direction,",
        "tokens": [
          50364,
          286,
          643,
          281,
          1286,
          341,
          867,
          18668,
          294,
          264,
          2031,
          3513,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 633.9599999999999,
        "id": 244,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 632.16,
        "temperature": 0,
        "text": " this many pixels in the y direction,",
        "tokens": [
          50514,
          341,
          867,
          18668,
          294,
          264,
          288,
          3513,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 635.78,
        "id": 245,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 633.9599999999999,
        "temperature": 0,
        "text": " and the pen is down.",
        "tokens": [
          50604,
          293,
          264,
          3435,
          307,
          760,
          13,
          50695
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 638.56,
        "id": 246,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 635.78,
        "temperature": 0,
        "text": " So this should be easy enough for us to implement.",
        "tokens": [
          50695,
          407,
          341,
          820,
          312,
          1858,
          1547,
          337,
          505,
          281,
          4445,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 643.56,
        "id": 247,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 638.56,
        "temperature": 0,
        "text": " If I have an x and a y, global variable,",
        "tokens": [
          50834,
          759,
          286,
          362,
          364,
          2031,
          293,
          257,
          288,
          11,
          4338,
          7006,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 646.54,
        "id": 248,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 644.64,
        "temperature": 0,
        "text": " I'm going to start them in the middle.",
        "tokens": [
          51138,
          286,
          478,
          516,
          281,
          722,
          552,
          294,
          264,
          2808,
          13,
          51233
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 654,
        "id": 249,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 650.3199999999999,
        "temperature": 0,
        "text": " Then I am going to, in the draw loop,",
        "tokens": [
          51422,
          1396,
          286,
          669,
          516,
          281,
          11,
          294,
          264,
          2642,
          6367,
          11,
          51606
        ]
      },
      {
        "avg_logprob": -0.21255682028976142,
        "compression_ratio": 1.690721649484536,
        "end": 659,
        "id": 250,
        "no_speech_prob": 7.811481168573664e-7,
        "seek": 62916,
        "start": 654,
        "temperature": 0,
        "text": " I'm going to say if strokePath is not equal to x,",
        "tokens": [
          51606,
          286,
          478,
          516,
          281,
          584,
          498,
          12403,
          47,
          998,
          307,
          406,
          2681,
          281,
          2031,
          11,
          51856
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 662.12,
        "id": 251,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 659.16,
        "temperature": 0,
        "text": " not equal to null, I got to check.",
        "tokens": [
          50364,
          406,
          2681,
          281,
          18184,
          11,
          286,
          658,
          281,
          1520,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 664.04,
        "id": 252,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 662.12,
        "temperature": 0,
        "text": " Do I have a new strokePath?",
        "tokens": [
          50512,
          1144,
          286,
          362,
          257,
          777,
          12403,
          47,
          998,
          30,
          50608
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 667.36,
        "id": 253,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 664.04,
        "temperature": 0,
        "text": " The new strokePath will come in the callback here,",
        "tokens": [
          50608,
          440,
          777,
          12403,
          47,
          998,
          486,
          808,
          294,
          264,
          818,
          3207,
          510,
          11,
          50774
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 668.6,
        "id": 254,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 667.36,
        "temperature": 0,
        "text": " and draw is always looping.",
        "tokens": [
          50774,
          293,
          2642,
          307,
          1009,
          6367,
          278,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 670.0799999999999,
        "id": 255,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 668.6,
        "temperature": 0,
        "text": " So draw is looping to wait to see",
        "tokens": [
          50836,
          407,
          2642,
          307,
          6367,
          278,
          281,
          1699,
          281,
          536,
          50910
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 671.16,
        "id": 256,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 670.0799999999999,
        "temperature": 0,
        "text": " that there's a strokePath.",
        "tokens": [
          50910,
          300,
          456,
          311,
          257,
          12403,
          47,
          998,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 674.24,
        "id": 257,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 671.16,
        "temperature": 0,
        "text": " And again, I could control how the draw loop works",
        "tokens": [
          50964,
          400,
          797,
          11,
          286,
          727,
          1969,
          577,
          264,
          2642,
          6367,
          1985,
          51118
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 677.6,
        "id": 258,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 674.24,
        "temperature": 0,
        "text": " with the query to the model in a different way,",
        "tokens": [
          51118,
          365,
          264,
          14581,
          281,
          264,
          2316,
          294,
          257,
          819,
          636,
          11,
          51286
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 679.3399999999999,
        "id": 259,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 677.6,
        "temperature": 0,
        "text": " but this is an easy way for me to do it.",
        "tokens": [
          51286,
          457,
          341,
          307,
          364,
          1858,
          636,
          337,
          385,
          281,
          360,
          309,
          13,
          51373
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 680.6,
        "id": 260,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 679.3399999999999,
        "temperature": 0,
        "text": " Draw is just going to loop.",
        "tokens": [
          51373,
          20386,
          307,
          445,
          516,
          281,
          6367,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 683.88,
        "id": 261,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 680.6,
        "temperature": 0,
        "text": " Then I'm going to say draw a line from x, y",
        "tokens": [
          51436,
          1396,
          286,
          478,
          516,
          281,
          584,
          2642,
          257,
          1622,
          490,
          2031,
          11,
          288,
          51600
        ]
      },
      {
        "avg_logprob": -0.23060881516029094,
        "compression_ratio": 1.6755725190839694,
        "end": 688.1999999999999,
        "id": 262,
        "no_speech_prob": 0.00009170172415906563,
        "seek": 65916,
        "start": 683.88,
        "temperature": 0,
        "text": " to x plus dx, y plus dy.",
        "tokens": [
          51600,
          281,
          2031,
          1804,
          30017,
          11,
          288,
          1804,
          14584,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 690.2,
        "id": 263,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 688.2,
        "temperature": 0,
        "text": " Just draw that line, and then what?",
        "tokens": [
          50364,
          1449,
          2642,
          300,
          1622,
          11,
          293,
          550,
          437,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 692.6800000000001,
        "id": 264,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 690.2,
        "temperature": 0,
        "text": " Let's set strokePath to null again.",
        "tokens": [
          50464,
          961,
          311,
          992,
          12403,
          47,
          998,
          281,
          18184,
          797,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 695.76,
        "id": 265,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 692.6800000000001,
        "temperature": 0,
        "text": " So once I'm done, set that strokePath to null.",
        "tokens": [
          50588,
          407,
          1564,
          286,
          478,
          1096,
          11,
          992,
          300,
          12403,
          47,
          998,
          281,
          18184,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 699.1,
        "id": 266,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 695.76,
        "temperature": 0,
        "text": " Okay, so we should just see that one first line.",
        "tokens": [
          50742,
          1033,
          11,
          370,
          321,
          820,
          445,
          536,
          300,
          472,
          700,
          1622,
          13,
          50909
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 705.12,
        "id": 267,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 702.7800000000001,
        "temperature": 0,
        "text": " Oh, dx is not defined.",
        "tokens": [
          51093,
          876,
          11,
          30017,
          307,
          406,
          7642,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 709.08,
        "id": 268,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 705.12,
        "temperature": 0,
        "text": " I don't know, strokePath.dx, right?",
        "tokens": [
          51210,
          286,
          500,
          380,
          458,
          11,
          12403,
          47,
          998,
          13,
          67,
          87,
          11,
          558,
          30,
          51408
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 709.96,
        "id": 269,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 709.08,
        "temperature": 0,
        "text": " It's part of strokePath.",
        "tokens": [
          51408,
          467,
          311,
          644,
          295,
          12403,
          47,
          998,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 711.2,
        "id": 270,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 709.96,
        "temperature": 0,
        "text": " I don't know why.",
        "tokens": [
          51452,
          286,
          500,
          380,
          458,
          983,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 713.3000000000001,
        "id": 271,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 711.2,
        "temperature": 0,
        "text": " The dx and dy is in the object.",
        "tokens": [
          51514,
          440,
          30017,
          293,
          14584,
          307,
          294,
          264,
          2657,
          13,
          51619
        ]
      },
      {
        "avg_logprob": -0.19851016998291016,
        "compression_ratio": 1.5909090909090908,
        "end": 717.0400000000001,
        "id": 272,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 68820,
        "start": 716.2,
        "temperature": 0,
        "text": " Here it goes.",
        "tokens": [
          51764,
          1692,
          309,
          1709,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 720.5600000000001,
        "id": 273,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 719.2,
        "temperature": 0,
        "text": " Do you see it?",
        "tokens": [
          50414,
          1144,
          291,
          536,
          309,
          30,
          50482
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 721.88,
        "id": 274,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 720.5600000000001,
        "temperature": 0,
        "text": " Is there a line?",
        "tokens": [
          50482,
          1119,
          456,
          257,
          1622,
          30,
          50548
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 723.24,
        "id": 275,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 721.88,
        "temperature": 0,
        "text": " Why haven't I seen that line?",
        "tokens": [
          50548,
          1545,
          2378,
          380,
          286,
          1612,
          300,
          1622,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 724.4000000000001,
        "id": 276,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 723.24,
        "temperature": 0,
        "text": " Oh, hmm.",
        "tokens": [
          50616,
          876,
          11,
          16478,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 726.5200000000001,
        "id": 277,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 725.2800000000001,
        "temperature": 0,
        "text": " Stroke zero?",
        "tokens": [
          50718,
          42196,
          330,
          4018,
          30,
          50780
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 732.5200000000001,
        "id": 278,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 727.84,
        "temperature": 0,
        "text": " Stroke weight, stroke weight four?",
        "tokens": [
          50846,
          42196,
          330,
          3364,
          11,
          12403,
          3364,
          1451,
          30,
          51080
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 735.48,
        "id": 279,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 734.4000000000001,
        "temperature": 0,
        "text": " What did I miss?",
        "tokens": [
          51174,
          708,
          630,
          286,
          1713,
          30,
          51228
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 737.9200000000001,
        "id": 280,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 735.48,
        "temperature": 0,
        "text": " Line, oh, you know what?",
        "tokens": [
          51228,
          14670,
          11,
          1954,
          11,
          291,
          458,
          437,
          30,
          51350
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 741.2,
        "id": 281,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 739.96,
        "temperature": 0,
        "text": " I'm sort of forgetting.",
        "tokens": [
          51452,
          286,
          478,
          1333,
          295,
          25428,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 743.6,
        "id": 282,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 741.2,
        "temperature": 0,
        "text": " I just don't want to, I just want to draw the background.",
        "tokens": [
          51514,
          286,
          445,
          500,
          380,
          528,
          281,
          11,
          286,
          445,
          528,
          281,
          2642,
          264,
          3678,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 745.12,
        "id": 283,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 743.6,
        "temperature": 0,
        "text": " I'm redrawing the background.",
        "tokens": [
          51634,
          286,
          478,
          2182,
          5131,
          278,
          264,
          3678,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.3433210997454888,
        "compression_ratio": 1.5989583333333333,
        "end": 747.4000000000001,
        "id": 284,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 71820,
        "start": 745.12,
        "temperature": 0,
        "text": " So as soon as I draw the line, ah!",
        "tokens": [
          51710,
          407,
          382,
          2321,
          382,
          286,
          2642,
          264,
          1622,
          11,
          3716,
          0,
          51824
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 749.64,
        "id": 285,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 747.4,
        "temperature": 0,
        "text": " That's such a mistake that I always make.",
        "tokens": [
          50364,
          663,
          311,
          1270,
          257,
          6146,
          300,
          286,
          1009,
          652,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 752.84,
        "id": 286,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 749.64,
        "temperature": 0,
        "text": " I drew that line, but then draw looped again",
        "tokens": [
          50476,
          286,
          12804,
          300,
          1622,
          11,
          457,
          550,
          2642,
          6367,
          292,
          797,
          50636
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 754.04,
        "id": 287,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 752.84,
        "temperature": 0,
        "text": " and drew the background over it.",
        "tokens": [
          50636,
          293,
          12804,
          264,
          3678,
          670,
          309,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 755.48,
        "id": 288,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 754.04,
        "temperature": 0,
        "text": " So this is a thing where I just want to draw",
        "tokens": [
          50696,
          407,
          341,
          307,
          257,
          551,
          689,
          286,
          445,
          528,
          281,
          2642,
          50768
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 759.26,
        "id": 289,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 755.48,
        "temperature": 0,
        "text": " the background once, and I'll draw it in setup in this case.",
        "tokens": [
          50768,
          264,
          3678,
          1564,
          11,
          293,
          286,
          603,
          2642,
          309,
          294,
          8657,
          294,
          341,
          1389,
          13,
          50957
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 762.24,
        "id": 290,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 761.12,
        "temperature": 0,
        "text": " So let's draw it in setup.",
        "tokens": [
          51050,
          407,
          718,
          311,
          2642,
          309,
          294,
          8657,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 764.4399999999999,
        "id": 291,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 762.24,
        "temperature": 0,
        "text": " Here we go, we're getting there.",
        "tokens": [
          51106,
          1692,
          321,
          352,
          11,
          321,
          434,
          1242,
          456,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 765.56,
        "id": 292,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 764.4399999999999,
        "temperature": 0,
        "text": " Let's see that line.",
        "tokens": [
          51216,
          961,
          311,
          536,
          300,
          1622,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 769.52,
        "id": 293,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 766.48,
        "temperature": 0,
        "text": " There it is, that's the first stroke of our cat.",
        "tokens": [
          51318,
          821,
          309,
          307,
          11,
          300,
          311,
          264,
          700,
          12403,
          295,
          527,
          3857,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 773.68,
        "id": 294,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 769.52,
        "temperature": 0,
        "text": " So we got this first path that the neural network,",
        "tokens": [
          51470,
          407,
          321,
          658,
          341,
          700,
          3100,
          300,
          264,
          18161,
          3209,
          11,
          51678
        ]
      },
      {
        "avg_logprob": -0.2566968973945169,
        "compression_ratio": 1.7509727626459144,
        "end": 775.98,
        "id": 295,
        "no_speech_prob": 0.00003269923763582483,
        "seek": 74740,
        "start": 773.68,
        "temperature": 0,
        "text": " the Sketch RNN model, imagined for the cat.",
        "tokens": [
          51678,
          264,
          49245,
          45702,
          45,
          2316,
          11,
          16590,
          337,
          264,
          3857,
          13,
          51793
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 780.28,
        "id": 296,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 775.98,
        "temperature": 0,
        "text": " So now what we're going to do is,",
        "tokens": [
          50364,
          407,
          586,
          437,
          321,
          434,
          516,
          281,
          360,
          307,
          11,
          50579
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 784.86,
        "id": 297,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 782.94,
        "temperature": 0,
        "text": " ah, wait, what do we need to do?",
        "tokens": [
          50712,
          3716,
          11,
          1699,
          11,
          437,
          360,
          321,
          643,
          281,
          360,
          30,
          50808
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 785.94,
        "id": 298,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 784.86,
        "temperature": 0,
        "text": " Are you thinking what I'm thinking?",
        "tokens": [
          50808,
          2014,
          291,
          1953,
          437,
          286,
          478,
          1953,
          30,
          50862
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 787.66,
        "id": 299,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 785.94,
        "temperature": 0,
        "text": " Let's just ask for the next one.",
        "tokens": [
          50862,
          961,
          311,
          445,
          1029,
          337,
          264,
          958,
          472,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 789.46,
        "id": 300,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 787.66,
        "temperature": 0,
        "text": " So how did I ask for the first one?",
        "tokens": [
          50948,
          407,
          577,
          630,
          286,
          1029,
          337,
          264,
          700,
          472,
          30,
          51038
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 792.4200000000001,
        "id": 301,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 789.46,
        "temperature": 0,
        "text": " Model.generate, I can just say, okay, I got one.",
        "tokens": [
          51038,
          17105,
          13,
          21848,
          473,
          11,
          286,
          393,
          445,
          584,
          11,
          1392,
          11,
          286,
          658,
          472,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 795.4200000000001,
        "id": 302,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 792.4200000000001,
        "temperature": 0,
        "text": " Set it to null, generate, and wait for the next one.",
        "tokens": [
          51186,
          8928,
          309,
          281,
          18184,
          11,
          8460,
          11,
          293,
          1699,
          337,
          264,
          958,
          472,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 799.26,
        "id": 303,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 795.4200000000001,
        "temperature": 0,
        "text": " Also, though, I need to move x and y to that new point.",
        "tokens": [
          51336,
          2743,
          11,
          1673,
          11,
          286,
          643,
          281,
          1286,
          2031,
          293,
          288,
          281,
          300,
          777,
          935,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 801.1800000000001,
        "id": 304,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 799.26,
        "temperature": 0,
        "text": " So it actually might make sense for me to say,",
        "tokens": [
          51528,
          407,
          309,
          767,
          1062,
          652,
          2020,
          337,
          385,
          281,
          584,
          11,
          51624
        ]
      },
      {
        "avg_logprob": -0.2002572877066476,
        "compression_ratio": 1.712,
        "end": 804.5,
        "id": 305,
        "no_speech_prob": 0.00000664343269818346,
        "seek": 77598,
        "start": 801.1800000000001,
        "temperature": 0,
        "text": " like, new x equals, and this will clean up the code",
        "tokens": [
          51624,
          411,
          11,
          777,
          2031,
          6915,
          11,
          293,
          341,
          486,
          2541,
          493,
          264,
          3089,
          51790
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 806.58,
        "id": 306,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 804.5,
        "temperature": 0,
        "text": " a little bit in a way that makes it more readable.",
        "tokens": [
          50364,
          257,
          707,
          857,
          294,
          257,
          636,
          300,
          1669,
          309,
          544,
          49857,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 808.86,
        "id": 307,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 806.58,
        "temperature": 0,
        "text": " This is the new x value.",
        "tokens": [
          50468,
          639,
          307,
          264,
          777,
          2031,
          2158,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 810.96,
        "id": 308,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 808.86,
        "temperature": 0,
        "text": " This is the new y value.",
        "tokens": [
          50582,
          639,
          307,
          264,
          777,
          288,
          2158,
          13,
          50687
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 816.54,
        "id": 309,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 813.18,
        "temperature": 0,
        "text": " Draw the line from old x to new x.",
        "tokens": [
          50798,
          20386,
          264,
          1622,
          490,
          1331,
          2031,
          281,
          777,
          2031,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 821.44,
        "id": 310,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 818.38,
        "temperature": 0,
        "text": " Set the stroke path to null, ask for a new one,",
        "tokens": [
          51058,
          8928,
          264,
          12403,
          3100,
          281,
          18184,
          11,
          1029,
          337,
          257,
          777,
          472,
          11,
          51211
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 825.46,
        "id": 311,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 821.44,
        "temperature": 0,
        "text": " and also move x and y to the new position.",
        "tokens": [
          51211,
          293,
          611,
          1286,
          2031,
          293,
          288,
          281,
          264,
          777,
          2535,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 826.92,
        "id": 312,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 825.46,
        "temperature": 0,
        "text": " So now, when there's a new one,",
        "tokens": [
          51412,
          407,
          586,
          11,
          562,
          456,
          311,
          257,
          777,
          472,
          11,
          51485
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 828.1,
        "id": 313,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 826.92,
        "temperature": 0,
        "text": " we should get the new one in.",
        "tokens": [
          51485,
          321,
          820,
          483,
          264,
          777,
          472,
          294,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 829.7,
        "id": 314,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 828.1,
        "temperature": 0,
        "text": " Guess what, here we go.",
        "tokens": [
          51544,
          17795,
          437,
          11,
          510,
          321,
          352,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.20113472389963877,
        "compression_ratio": 1.6467661691542288,
        "end": 833.7,
        "id": 315,
        "no_speech_prob": 0.00001805851024982985,
        "seek": 80450,
        "start": 832.46,
        "temperature": 0,
        "text": " Let's see our cat.",
        "tokens": [
          51762,
          961,
          311,
          536,
          527,
          3857,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 835.1800000000001,
        "id": 316,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 833.7,
        "temperature": 0,
        "text": " There's our cat.",
        "tokens": [
          50364,
          821,
          311,
          527,
          3857,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 837.4200000000001,
        "id": 317,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 835.1800000000001,
        "temperature": 0,
        "text": " Whoa, woohoo, look, and it's console.log and it's run.",
        "tokens": [
          50438,
          7521,
          11,
          21657,
          19069,
          11,
          574,
          11,
          293,
          309,
          311,
          11076,
          13,
          4987,
          293,
          309,
          311,
          1190,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 838.7,
        "id": 318,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 837.4200000000001,
        "temperature": 0,
        "text": " Now, it looks crazy, right?",
        "tokens": [
          50550,
          823,
          11,
          309,
          1542,
          3219,
          11,
          558,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 841.86,
        "id": 319,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 838.7,
        "temperature": 0,
        "text": " Because I completely ignored the whole pen up",
        "tokens": [
          50614,
          1436,
          286,
          2584,
          19735,
          264,
          1379,
          3435,
          493,
          50772
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 843.0200000000001,
        "id": 320,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 841.86,
        "temperature": 0,
        "text": " versus down thing.",
        "tokens": [
          50772,
          5717,
          760,
          551,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 844.1400000000001,
        "id": 321,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 843.0200000000001,
        "temperature": 0,
        "text": " So that's something really important.",
        "tokens": [
          50830,
          407,
          300,
          311,
          746,
          534,
          1021,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 845.26,
        "id": 322,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 844.1400000000001,
        "temperature": 0,
        "text": " And there's something that's actually",
        "tokens": [
          50886,
          400,
          456,
          311,
          746,
          300,
          311,
          767,
          50942
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 847.26,
        "id": 323,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 845.26,
        "temperature": 0,
        "text": " that I didn't bother to tell you",
        "tokens": [
          50942,
          300,
          286,
          994,
          380,
          8677,
          281,
          980,
          291,
          51042
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 848.7,
        "id": 324,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 847.26,
        "temperature": 0,
        "text": " that's kind of important and makes it",
        "tokens": [
          51042,
          300,
          311,
          733,
          295,
          1021,
          293,
          1669,
          309,
          51114
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 849.82,
        "id": 325,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 848.7,
        "temperature": 0,
        "text": " a little bit more confusing.",
        "tokens": [
          51114,
          257,
          707,
          857,
          544,
          13181,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 852.1800000000001,
        "id": 326,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 849.82,
        "temperature": 0,
        "text": " Let's take out this console log, by the way.",
        "tokens": [
          51170,
          961,
          311,
          747,
          484,
          341,
          11076,
          3565,
          11,
          538,
          264,
          636,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 854.5,
        "id": 327,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 852.1800000000001,
        "temperature": 0,
        "text": " So the thing that's extra confusing",
        "tokens": [
          51288,
          407,
          264,
          551,
          300,
          311,
          2857,
          13181,
          51404
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 856.34,
        "id": 328,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 854.5,
        "temperature": 0,
        "text": " about the pen up and pen down",
        "tokens": [
          51404,
          466,
          264,
          3435,
          493,
          293,
          3435,
          760,
          51496
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 859.4200000000001,
        "id": 329,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 856.34,
        "temperature": 0,
        "text": " is when you get this information,",
        "tokens": [
          51496,
          307,
          562,
          291,
          483,
          341,
          1589,
          11,
          51650
        ]
      },
      {
        "avg_logprob": -0.25238024960657596,
        "compression_ratio": 1.813953488372093,
        "end": 862.58,
        "id": 330,
        "no_speech_prob": 0.00002507151111785788,
        "seek": 83370,
        "start": 859.4200000000001,
        "temperature": 0,
        "text": " it's actually telling you the pen state for the next stroke.",
        "tokens": [
          51650,
          309,
          311,
          767,
          3585,
          291,
          264,
          3435,
          1785,
          337,
          264,
          958,
          12403,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 866.22,
        "id": 331,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 862.58,
        "temperature": 0,
        "text": " This is not the pen state for this particular path.",
        "tokens": [
          50364,
          639,
          307,
          406,
          264,
          3435,
          1785,
          337,
          341,
          1729,
          3100,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 868.0200000000001,
        "id": 332,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 866.22,
        "temperature": 0,
        "text": " It's the pen state for the next one.",
        "tokens": [
          50546,
          467,
          311,
          264,
          3435,
          1785,
          337,
          264,
          958,
          472,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 869.38,
        "id": 333,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 868.0200000000001,
        "temperature": 0,
        "text": " Why is that?",
        "tokens": [
          50636,
          1545,
          307,
          300,
          30,
          50704
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 870.6,
        "id": 334,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 869.38,
        "temperature": 0,
        "text": " Well, it's a little bit weird,",
        "tokens": [
          50704,
          1042,
          11,
          309,
          311,
          257,
          707,
          857,
          3657,
          11,
          50765
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 872.82,
        "id": 335,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 870.6,
        "temperature": 0,
        "text": " but if you think about it, when you first start drawing,",
        "tokens": [
          50765,
          457,
          498,
          291,
          519,
          466,
          309,
          11,
          562,
          291,
          700,
          722,
          6316,
          11,
          50876
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 874.5,
        "id": 336,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 872.82,
        "temperature": 0,
        "text": " I mean, the pen is down.",
        "tokens": [
          50876,
          286,
          914,
          11,
          264,
          3435,
          307,
          760,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 875.34,
        "id": 337,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 874.5,
        "temperature": 0,
        "text": " It has to be down.",
        "tokens": [
          50960,
          467,
          575,
          281,
          312,
          760,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 877.86,
        "id": 338,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 875.34,
        "temperature": 0,
        "text": " That's the definition of the beginning of the drawing.",
        "tokens": [
          51002,
          663,
          311,
          264,
          7123,
          295,
          264,
          2863,
          295,
          264,
          6316,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 879.7800000000001,
        "id": 339,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 877.86,
        "temperature": 0,
        "text": " And then when you're done,",
        "tokens": [
          51128,
          400,
          550,
          562,
          291,
          434,
          1096,
          11,
          51224
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 882.72,
        "id": 340,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 879.7800000000001,
        "temperature": 0,
        "text": " you're saying finish that last one, then end.",
        "tokens": [
          51224,
          291,
          434,
          1566,
          2413,
          300,
          1036,
          472,
          11,
          550,
          917,
          13,
          51371
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 885.74,
        "id": 341,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 882.72,
        "temperature": 0,
        "text": " So what it really is, it's the pen state",
        "tokens": [
          51371,
          407,
          437,
          309,
          534,
          307,
          11,
          309,
          311,
          264,
          3435,
          1785,
          51522
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 887.1,
        "id": 342,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 885.74,
        "temperature": 0,
        "text": " that you get in the previous stroke",
        "tokens": [
          51522,
          300,
          291,
          483,
          294,
          264,
          3894,
          12403,
          51590
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 889.38,
        "id": 343,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 887.1,
        "temperature": 0,
        "text": " sets the next one, and when it's end, we're done.",
        "tokens": [
          51590,
          6352,
          264,
          958,
          472,
          11,
          293,
          562,
          309,
          311,
          917,
          11,
          321,
          434,
          1096,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.19667519330978395,
        "compression_ratio": 1.8505338078291815,
        "end": 891.0200000000001,
        "id": 344,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 86258,
        "start": 889.38,
        "temperature": 0,
        "text": " So let's try implementing that.",
        "tokens": [
          51704,
          407,
          718,
          311,
          853,
          18114,
          300,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 893.18,
        "id": 345,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 891.02,
        "temperature": 0,
        "text": " And a way we can do that, I think,",
        "tokens": [
          50364,
          400,
          257,
          636,
          321,
          393,
          360,
          300,
          11,
          286,
          519,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 897.42,
        "id": 346,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 893.18,
        "temperature": 0,
        "text": " is just by having a variable that's called previousPen,",
        "tokens": [
          50472,
          307,
          445,
          538,
          1419,
          257,
          7006,
          300,
          311,
          1219,
          3894,
          47,
          268,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 900.6999999999999,
        "id": 347,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 897.42,
        "temperature": 0,
        "text": " and previousPen, or I could just call it pen, actually.",
        "tokens": [
          50684,
          293,
          3894,
          47,
          268,
          11,
          420,
          286,
          727,
          445,
          818,
          309,
          3435,
          11,
          767,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 904.16,
        "id": 348,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 900.6999999999999,
        "temperature": 0,
        "text": " Let's just call it pen, because by definition, pen is down.",
        "tokens": [
          50848,
          961,
          311,
          445,
          818,
          309,
          3435,
          11,
          570,
          538,
          7123,
          11,
          3435,
          307,
          760,
          13,
          51021
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 906.78,
        "id": 349,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 904.16,
        "temperature": 0,
        "text": " So pen is going to be down to start with.",
        "tokens": [
          51021,
          407,
          3435,
          307,
          516,
          281,
          312,
          760,
          281,
          722,
          365,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 911.34,
        "id": 350,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 906.78,
        "temperature": 0,
        "text": " Pen is down, and here, I'm only going to actually draw it",
        "tokens": [
          51152,
          10571,
          307,
          760,
          11,
          293,
          510,
          11,
          286,
          478,
          787,
          516,
          281,
          767,
          2642,
          309,
          51380
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 917.26,
        "id": 351,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 912.26,
        "temperature": 0,
        "text": " if pen, whoops, sorry, if pen equals down,",
        "tokens": [
          51426,
          498,
          3435,
          11,
          567,
          3370,
          11,
          2597,
          11,
          498,
          3435,
          6915,
          760,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.2582597652403246,
        "compression_ratio": 1.7889908256880733,
        "end": 919.34,
        "id": 352,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 89102,
        "start": 917.26,
        "temperature": 0,
        "text": " then I should actually draw the drawing,",
        "tokens": [
          51676,
          550,
          286,
          820,
          767,
          2642,
          264,
          6316,
          11,
          51780
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 922.14,
        "id": 353,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 920.34,
        "temperature": 0,
        "text": " draw the line, sorry.",
        "tokens": [
          50414,
          2642,
          264,
          1622,
          11,
          2597,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 926.48,
        "id": 354,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 922.14,
        "temperature": 0,
        "text": " I should always, oh, I should always move x.",
        "tokens": [
          50504,
          286,
          820,
          1009,
          11,
          1954,
          11,
          286,
          820,
          1009,
          1286,
          2031,
          13,
          50721
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 930.6600000000001,
        "id": 355,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 928.1800000000001,
        "temperature": 0,
        "text": " So I always want to move x,",
        "tokens": [
          50806,
          407,
          286,
          1009,
          528,
          281,
          1286,
          2031,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 935.58,
        "id": 356,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 930.6600000000001,
        "temperature": 0,
        "text": " but I only want to draw the line if pen is down,",
        "tokens": [
          50930,
          457,
          286,
          787,
          528,
          281,
          2642,
          264,
          1622,
          498,
          3435,
          307,
          760,
          11,
          51176
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 937.88,
        "id": 357,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 935.58,
        "temperature": 0,
        "text": " and then what I need to do is here,",
        "tokens": [
          51176,
          293,
          550,
          437,
          286,
          643,
          281,
          360,
          307,
          510,
          11,
          51291
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 940.38,
        "id": 358,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 937.88,
        "temperature": 0,
        "text": " I need to say pen equals,",
        "tokens": [
          51291,
          286,
          643,
          281,
          584,
          3435,
          6915,
          11,
          51416
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 942.1800000000001,
        "id": 359,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 940.38,
        "temperature": 0,
        "text": " oh, I am going to need a previousPen.",
        "tokens": [
          51416,
          1954,
          11,
          286,
          669,
          516,
          281,
          643,
          257,
          3894,
          47,
          268,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 947.62,
        "id": 360,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 943.34,
        "temperature": 0,
        "text": " Or can I do this right before I get the new stroke path?",
        "tokens": [
          51564,
          1610,
          393,
          286,
          360,
          341,
          558,
          949,
          286,
          483,
          264,
          777,
          12403,
          3100,
          30,
          51778
        ]
      },
      {
        "avg_logprob": -0.22699640415332936,
        "compression_ratio": 1.6443298969072164,
        "end": 948.5400000000001,
        "id": 361,
        "no_speech_prob": 0.00000966610423347447,
        "seek": 91934,
        "start": 947.62,
        "temperature": 0,
        "text": " Hmm, I'm confused.",
        "tokens": [
          51778,
          8239,
          11,
          286,
          478,
          9019,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 953.62,
        "id": 362,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 948.62,
        "temperature": 0,
        "text": " Oh, I can just say, I could say pen equals strokePath.pen.",
        "tokens": [
          50368,
          876,
          11,
          286,
          393,
          445,
          584,
          11,
          286,
          727,
          584,
          3435,
          6915,
          12403,
          47,
          998,
          13,
          5200,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 958.3,
        "id": 363,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 954.78,
        "temperature": 0,
        "text": " So basically, the pen starts as down,",
        "tokens": [
          50676,
          407,
          1936,
          11,
          264,
          3435,
          3719,
          382,
          760,
          11,
          50852
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 961.0999999999999,
        "id": 364,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 958.3,
        "temperature": 0,
        "text": " then I'm going to draw, and then pick up that",
        "tokens": [
          50852,
          550,
          286,
          478,
          516,
          281,
          2642,
          11,
          293,
          550,
          1888,
          493,
          300,
          50992
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 962.9,
        "id": 365,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 961.0999999999999,
        "temperature": 0,
        "text": " for when the next time comes around.",
        "tokens": [
          50992,
          337,
          562,
          264,
          958,
          565,
          1487,
          926,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 967.3399999999999,
        "id": 366,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 962.9,
        "temperature": 0,
        "text": " So don't pick up the actual pen value from the object.",
        "tokens": [
          51082,
          407,
          500,
          380,
          1888,
          493,
          264,
          3539,
          3435,
          2158,
          490,
          264,
          2657,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 969.42,
        "id": 367,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 967.3399999999999,
        "temperature": 0,
        "text": " You might need to think about this for a little bit.",
        "tokens": [
          51304,
          509,
          1062,
          643,
          281,
          519,
          466,
          341,
          337,
          257,
          707,
          857,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 970.86,
        "id": 368,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 969.42,
        "temperature": 0,
        "text": " This is really like previousPen.",
        "tokens": [
          51408,
          639,
          307,
          534,
          411,
          3894,
          47,
          268,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 972.98,
        "id": 369,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 970.86,
        "temperature": 0,
        "text": " Maybe I should call it previous,",
        "tokens": [
          51480,
          2704,
          286,
          820,
          818,
          309,
          3894,
          11,
          51586
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 974.52,
        "id": 370,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 972.98,
        "temperature": 0,
        "text": " because really what I'm checking here",
        "tokens": [
          51586,
          570,
          534,
          437,
          286,
          478,
          8568,
          510,
          51663
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 975.98,
        "id": 371,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 974.52,
        "temperature": 0,
        "text": " is the pen from the last time,",
        "tokens": [
          51663,
          307,
          264,
          3435,
          490,
          264,
          1036,
          565,
          11,
          51736
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 977.2199999999999,
        "id": 372,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 975.98,
        "temperature": 0,
        "text": " because I'm picking it up after.",
        "tokens": [
          51736,
          570,
          286,
          478,
          8867,
          309,
          493,
          934,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.20913555252719934,
        "compression_ratio": 1.6783216783216783,
        "end": 978.42,
        "id": 373,
        "no_speech_prob": 0.000002994439455505926,
        "seek": 94854,
        "start": 977.2199999999999,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          51798,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 980.8,
        "id": 374,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 979.38,
        "temperature": 0,
        "text": " Look at that cat.",
        "tokens": [
          50406,
          2053,
          412,
          300,
          3857,
          13,
          50477
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 986.26,
        "id": 375,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 985.42,
        "temperature": 0,
        "text": " I'm waiting for like a cat.",
        "tokens": [
          50708,
          286,
          478,
          3806,
          337,
          411,
          257,
          3857,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 988.6999999999999,
        "id": 376,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 986.26,
        "temperature": 0,
        "text": " Here's the thing, we don't know what we're going to get.",
        "tokens": [
          50750,
          1692,
          311,
          264,
          551,
          11,
          321,
          500,
          380,
          458,
          437,
          321,
          434,
          516,
          281,
          483,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 991.14,
        "id": 377,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 988.6999999999999,
        "temperature": 0,
        "text": " This has just been trained on what users",
        "tokens": [
          50872,
          639,
          575,
          445,
          668,
          8895,
          322,
          437,
          5022,
          50994
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 992.5,
        "id": 378,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 991.14,
        "temperature": 0,
        "text": " all over the world drew cats,",
        "tokens": [
          50994,
          439,
          670,
          264,
          1002,
          12804,
          11111,
          11,
          51062
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 994.3,
        "id": 379,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 992.5,
        "temperature": 0,
        "text": " and sometimes we're going to get a nose and whiskers,",
        "tokens": [
          51062,
          293,
          2171,
          321,
          434,
          516,
          281,
          483,
          257,
          6690,
          293,
          24485,
          433,
          11,
          51152
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 995.28,
        "id": 380,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 994.3,
        "temperature": 0,
        "text": " and sometimes we're not.",
        "tokens": [
          51152,
          293,
          2171,
          321,
          434,
          406,
          13,
          51201
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 997.0999999999999,
        "id": 381,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 995.28,
        "temperature": 0,
        "text": " We're going to see a variety of different kinds of cats.",
        "tokens": [
          51201,
          492,
          434,
          516,
          281,
          536,
          257,
          5673,
          295,
          819,
          3685,
          295,
          11111,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 1000.14,
        "id": 382,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 997.0999999999999,
        "temperature": 0,
        "text": " Okay, but now we also need to figure out what to do.",
        "tokens": [
          51292,
          1033,
          11,
          457,
          586,
          321,
          611,
          643,
          281,
          2573,
          484,
          437,
          281,
          360,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 1001.86,
        "id": 383,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 1000.14,
        "temperature": 0,
        "text": " We need to check for pen ending.",
        "tokens": [
          51444,
          492,
          643,
          281,
          1520,
          337,
          3435,
          8121,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.28718621803052496,
        "compression_ratio": 1.7258064516129032,
        "end": 1007.6999999999999,
        "id": 384,
        "no_speech_prob": 0.000009972917723644059,
        "seek": 97854,
        "start": 1002.6999999999999,
        "temperature": 0,
        "text": " So if I here were to say if pen,",
        "tokens": [
          51572,
          407,
          498,
          286,
          510,
          645,
          281,
          584,
          498,
          3435,
          11,
          51822
        ]
      },
      {
        "avg_logprob": -0.28582941548208174,
        "compression_ratio": 1.615819209039548,
        "end": 1009.9000000000001,
        "id": 385,
        "no_speech_prob": 0.0000015057004247864825,
        "seek": 100770,
        "start": 1008.46,
        "temperature": 0,
        "text": " so let's set the stroke path to null.",
        "tokens": [
          50402,
          370,
          718,
          311,
          992,
          264,
          12403,
          3100,
          281,
          18184,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.28582941548208174,
        "compression_ratio": 1.615819209039548,
        "end": 1014.9000000000001,
        "id": 386,
        "no_speech_prob": 0.0000015057004247864825,
        "seek": 100770,
        "start": 1009.9000000000001,
        "temperature": 0,
        "text": " We can do all this, but as long as pen is not equal to end,",
        "tokens": [
          50474,
          492,
          393,
          360,
          439,
          341,
          11,
          457,
          382,
          938,
          382,
          3435,
          307,
          406,
          2681,
          281,
          917,
          11,
          50724
        ]
      },
      {
        "avg_logprob": -0.28582941548208174,
        "compression_ratio": 1.615819209039548,
        "end": 1023.0600000000001,
        "id": 387,
        "no_speech_prob": 0.0000015057004247864825,
        "seek": 100770,
        "start": 1018.1,
        "temperature": 0,
        "text": " then I am going to say, I'll generate the new.",
        "tokens": [
          50884,
          550,
          286,
          669,
          516,
          281,
          584,
          11,
          286,
          603,
          8460,
          264,
          777,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.28582941548208174,
        "compression_ratio": 1.615819209039548,
        "end": 1024.74,
        "id": 388,
        "no_speech_prob": 0.0000015057004247864825,
        "seek": 100770,
        "start": 1023.0600000000001,
        "temperature": 0,
        "text": " So if pen is equal to end,",
        "tokens": [
          51132,
          407,
          498,
          3435,
          307,
          2681,
          281,
          917,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.28582941548208174,
        "compression_ratio": 1.615819209039548,
        "end": 1026.94,
        "id": 389,
        "no_speech_prob": 0.0000015057004247864825,
        "seek": 100770,
        "start": 1024.74,
        "temperature": 0,
        "text": " don't bother to generate another stroke,",
        "tokens": [
          51216,
          500,
          380,
          8677,
          281,
          8460,
          1071,
          12403,
          11,
          51326
        ]
      },
      {
        "avg_logprob": -0.28582941548208174,
        "compression_ratio": 1.615819209039548,
        "end": 1028.78,
        "id": 390,
        "no_speech_prob": 0.0000015057004247864825,
        "seek": 100770,
        "start": 1026.94,
        "temperature": 0,
        "text": " and then I'm going to just put in here",
        "tokens": [
          51326,
          293,
          550,
          286,
          478,
          516,
          281,
          445,
          829,
          294,
          510,
          51418
        ]
      },
      {
        "avg_logprob": -0.28582941548208174,
        "compression_ratio": 1.615819209039548,
        "end": 1031.78,
        "id": 391,
        "no_speech_prob": 0.0000015057004247864825,
        "seek": 100770,
        "start": 1028.78,
        "temperature": 0,
        "text": " else console.log drawing complete.",
        "tokens": [
          51418,
          1646,
          11076,
          13,
          4987,
          6316,
          3566,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1036.78,
        "id": 392,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1031.78,
        "temperature": 0,
        "text": " Okay, let's give this a try.",
        "tokens": [
          50364,
          1033,
          11,
          718,
          311,
          976,
          341,
          257,
          853,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1040.26,
        "id": 393,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1038.34,
        "temperature": 0,
        "text": " We're going to see the cat.",
        "tokens": [
          50692,
          492,
          434,
          516,
          281,
          536,
          264,
          3857,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1043.66,
        "id": 394,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1042.7,
        "temperature": 0,
        "text": " There's our cat.",
        "tokens": [
          50910,
          821,
          311,
          527,
          3857,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1045.92,
        "id": 395,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1044.86,
        "temperature": 0,
        "text": " There's our cat.",
        "tokens": [
          51018,
          821,
          311,
          527,
          3857,
          13,
          51071
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1047.1,
        "id": 396,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1045.92,
        "temperature": 0,
        "text": " Drawing complete.",
        "tokens": [
          51071,
          20386,
          278,
          3566,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1049.46,
        "id": 397,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1047.1,
        "temperature": 0,
        "text": " So maybe we should have it restart a new one,",
        "tokens": [
          51130,
          407,
          1310,
          321,
          820,
          362,
          309,
          21022,
          257,
          777,
          472,
          11,
          51248
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1050.98,
        "id": 398,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1049.46,
        "temperature": 0,
        "text": " and this is going to be good for our snowflakes.",
        "tokens": [
          51248,
          293,
          341,
          307,
          516,
          281,
          312,
          665,
          337,
          527,
          44124,
          3419,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1052.06,
        "id": 399,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1050.98,
        "temperature": 0,
        "text": " You'll see in a second.",
        "tokens": [
          51324,
          509,
          603,
          536,
          294,
          257,
          1150,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1053.86,
        "id": 400,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1052.06,
        "temperature": 0,
        "text": " So actually instead of drawing complete,",
        "tokens": [
          51378,
          407,
          767,
          2602,
          295,
          6316,
          3566,
          11,
          51468
        ]
      },
      {
        "avg_logprob": -0.26886190152635764,
        "compression_ratio": 1.6275510204081634,
        "end": 1056.8999999999999,
        "id": 401,
        "no_speech_prob": 0.000037052905099699274,
        "seek": 103178,
        "start": 1053.86,
        "temperature": 0,
        "text": " what I could actually do now is I could say model,",
        "tokens": [
          51468,
          437,
          286,
          727,
          767,
          360,
          586,
          307,
          286,
          727,
          584,
          2316,
          11,
          51620
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1062.7800000000002,
        "id": 402,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1057.7800000000002,
        "temperature": 0,
        "text": " model.reset, and model.generate again.",
        "tokens": [
          50408,
          2316,
          13,
          495,
          302,
          11,
          293,
          2316,
          13,
          21848,
          473,
          797,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1067.92,
        "id": 403,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1065.1000000000001,
        "temperature": 0,
        "text": " So this is going to instantaneously do another one.",
        "tokens": [
          50774,
          407,
          341,
          307,
          516,
          281,
          9836,
          13131,
          360,
          1071,
          472,
          13,
          50915
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1072.5400000000002,
        "id": 404,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1071.18,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          51078,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1074.3400000000001,
        "id": 405,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1072.5400000000002,
        "temperature": 0,
        "text": " Here's a cat.",
        "tokens": [
          51146,
          1692,
          311,
          257,
          3857,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1075.18,
        "id": 406,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1074.3400000000001,
        "temperature": 0,
        "text": " Oh, you know what?",
        "tokens": [
          51236,
          876,
          11,
          291,
          458,
          437,
          30,
          51278
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1077.26,
        "id": 407,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1075.18,
        "temperature": 0,
        "text": " It's going to do it from wherever it ended.",
        "tokens": [
          51278,
          467,
          311,
          516,
          281,
          360,
          309,
          490,
          8660,
          309,
          4590,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1080.18,
        "id": 408,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1077.26,
        "temperature": 0,
        "text": " So the other thing I need to do is reset where x and y go.",
        "tokens": [
          51382,
          407,
          264,
          661,
          551,
          286,
          643,
          281,
          360,
          307,
          14322,
          689,
          2031,
          293,
          288,
          352,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1084.22,
        "id": 409,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1080.18,
        "temperature": 0,
        "text": " So let's say x goes back to the middle of the screen.",
        "tokens": [
          51528,
          407,
          718,
          311,
          584,
          2031,
          1709,
          646,
          281,
          264,
          2808,
          295,
          264,
          2568,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.215272171156747,
        "compression_ratio": 1.7128712871287128,
        "end": 1086.5400000000002,
        "id": 410,
        "no_speech_prob": 0.000005014729595131939,
        "seek": 105690,
        "start": 1084.22,
        "temperature": 0,
        "text": " Y goes back to the middle of the screen.",
        "tokens": [
          51730,
          398,
          1709,
          646,
          281,
          264,
          2808,
          295,
          264,
          2568,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1089.34,
        "id": 411,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1087.54,
        "temperature": 0,
        "text": " It takes a while to load the model,",
        "tokens": [
          50414,
          467,
          2516,
          257,
          1339,
          281,
          3677,
          264,
          2316,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1093.06,
        "id": 412,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1089.34,
        "temperature": 0,
        "text": " so each time I'm refreshing, I have to wait a little bit.",
        "tokens": [
          50504,
          370,
          1184,
          565,
          286,
          478,
          19772,
          11,
          286,
          362,
          281,
          1699,
          257,
          707,
          857,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1093.98,
        "id": 413,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1093.06,
        "temperature": 0,
        "text": " So let's see our cat.",
        "tokens": [
          50690,
          407,
          718,
          311,
          536,
          527,
          3857,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1094.8999999999999,
        "id": 414,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1093.98,
        "temperature": 0,
        "text": " I obviously need to give myself,",
        "tokens": [
          50736,
          286,
          2745,
          643,
          281,
          976,
          2059,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1096.46,
        "id": 415,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1094.8999999999999,
        "temperature": 0,
        "text": " oh, look at that, it's a very different kind of cat.",
        "tokens": [
          50782,
          1954,
          11,
          574,
          412,
          300,
          11,
          309,
          311,
          257,
          588,
          819,
          733,
          295,
          3857,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1097.3,
        "id": 416,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1096.46,
        "temperature": 0,
        "text": " Drawing complete.",
        "tokens": [
          50860,
          20386,
          278,
          3566,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1098.1399999999999,
        "id": 417,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1097.3,
        "temperature": 0,
        "text": " Now it's doing another one.",
        "tokens": [
          50902,
          823,
          309,
          311,
          884,
          1071,
          472,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1098.98,
        "id": 418,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1098.1399999999999,
        "temperature": 0,
        "text": " So this is perfect,",
        "tokens": [
          50944,
          407,
          341,
          307,
          2176,
          11,
          50986
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1101.34,
        "id": 419,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1098.98,
        "temperature": 0,
        "text": " because this is exactly what I want to do with snowflakes.",
        "tokens": [
          50986,
          570,
          341,
          307,
          2293,
          437,
          286,
          528,
          281,
          360,
          365,
          44124,
          3419,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1103.22,
        "id": 420,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1101.34,
        "temperature": 0,
        "text": " This is exactly what I want to do with snowflakes.",
        "tokens": [
          51104,
          639,
          307,
          2293,
          437,
          286,
          528,
          281,
          360,
          365,
          44124,
          3419,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1106.06,
        "id": 421,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1103.22,
        "temperature": 0,
        "text": " So first, let's change this to snowflake.",
        "tokens": [
          51198,
          407,
          700,
          11,
          718,
          311,
          1319,
          341,
          281,
          44124,
          619,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1109.34,
        "id": 422,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1106.06,
        "temperature": 0,
        "text": " Let's make this x a random place.",
        "tokens": [
          51340,
          961,
          311,
          652,
          341,
          2031,
          257,
          4974,
          1081,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2377205905535363,
        "compression_ratio": 1.8171641791044777,
        "end": 1113.8999999999999,
        "id": 423,
        "no_speech_prob": 0.000001370956397295231,
        "seek": 108654,
        "start": 1110.22,
        "temperature": 0,
        "text": " Let's make this y a random place.",
        "tokens": [
          51548,
          961,
          311,
          652,
          341,
          288,
          257,
          4974,
          1081,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1118.6200000000001,
        "id": 424,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1113.9,
        "temperature": 0,
        "text": " And actually, let's also translate to the center.",
        "tokens": [
          50364,
          400,
          767,
          11,
          718,
          311,
          611,
          13799,
          281,
          264,
          3056,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1122.26,
        "id": 425,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1120.38,
        "temperature": 0,
        "text": " I want to translate to the center,",
        "tokens": [
          50688,
          286,
          528,
          281,
          13799,
          281,
          264,
          3056,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1124.66,
        "id": 426,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1122.26,
        "temperature": 0,
        "text": " and I'll explain why in a second.",
        "tokens": [
          50782,
          293,
          286,
          603,
          2903,
          983,
          294,
          257,
          1150,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1128.1000000000001,
        "id": 427,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1124.66,
        "temperature": 0,
        "text": " So actually, this is going to be at random,",
        "tokens": [
          50902,
          407,
          767,
          11,
          341,
          307,
          516,
          281,
          312,
          412,
          4974,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1133.3400000000001,
        "id": 428,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1130.6200000000001,
        "temperature": 0,
        "text": " anywhere randomly in the canvas.",
        "tokens": [
          51200,
          4992,
          16979,
          294,
          264,
          16267,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1136.46,
        "id": 429,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1133.3400000000001,
        "temperature": 0,
        "text": " So x is going to be between negative half width",
        "tokens": [
          51336,
          407,
          2031,
          307,
          516,
          281,
          312,
          1296,
          3671,
          1922,
          11402,
          51492
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1139.22,
        "id": 430,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1136.46,
        "temperature": 0,
        "text": " and positive half width, half height,",
        "tokens": [
          51492,
          293,
          3353,
          1922,
          11402,
          11,
          1922,
          6681,
          11,
          51630
        ]
      },
      {
        "avg_logprob": -0.25878302630256206,
        "compression_ratio": 1.8083832335329342,
        "end": 1140.66,
        "id": 431,
        "no_speech_prob": 0.000004092909421160584,
        "seek": 111390,
        "start": 1139.22,
        "temperature": 0,
        "text": " positive half width.",
        "tokens": [
          51630,
          3353,
          1922,
          11402,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1145.5400000000002,
        "id": 432,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1140.7,
        "temperature": 0,
        "text": " Y is negative half height, positive half height.",
        "tokens": [
          50366,
          398,
          307,
          3671,
          1922,
          6681,
          11,
          3353,
          1922,
          6681,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1150.18,
        "id": 433,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1147.22,
        "temperature": 0,
        "text": " And then I want to do exactly the same thing",
        "tokens": [
          50692,
          400,
          550,
          286,
          528,
          281,
          360,
          2293,
          264,
          912,
          551,
          50840
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1153.5,
        "id": 434,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1150.18,
        "temperature": 0,
        "text": " whenever I finish the snowflake.",
        "tokens": [
          50840,
          5699,
          286,
          2413,
          264,
          44124,
          619,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1155.3000000000002,
        "id": 435,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1153.5,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          51006,
          1033,
          11,
          510,
          321,
          352,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1158.74,
        "id": 436,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1155.3000000000002,
        "temperature": 0,
        "text": " And let's see what happens.",
        "tokens": [
          51096,
          400,
          718,
          311,
          536,
          437,
          2314,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1161.7,
        "id": 437,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1158.74,
        "temperature": 0,
        "text": " I don't know how big these snowflakes are going to be.",
        "tokens": [
          51268,
          286,
          500,
          380,
          458,
          577,
          955,
          613,
          44124,
          3419,
          366,
          516,
          281,
          312,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1162.98,
        "id": 438,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1161.7,
        "temperature": 0,
        "text": " Here's a nice snowflake.",
        "tokens": [
          51416,
          1692,
          311,
          257,
          1481,
          44124,
          619,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1165.02,
        "id": 439,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1163.9,
        "temperature": 0,
        "text": " Yeah, there we go.",
        "tokens": [
          51526,
          865,
          11,
          456,
          321,
          352,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1166.66,
        "id": 440,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1165.02,
        "temperature": 0,
        "text": " Look, it's drawing snowflakes.",
        "tokens": [
          51582,
          2053,
          11,
          309,
          311,
          6316,
          44124,
          3419,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1879296609021108,
        "compression_ratio": 1.6875,
        "end": 1169.48,
        "id": 441,
        "no_speech_prob": 0.000027108771973871626,
        "seek": 114066,
        "start": 1166.66,
        "temperature": 0,
        "text": " So I wanted to create a big scene of snowflakes.",
        "tokens": [
          51664,
          407,
          286,
          1415,
          281,
          1884,
          257,
          955,
          4145,
          295,
          44124,
          3419,
          13,
          51805
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1171.16,
        "id": 442,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1169.48,
        "temperature": 0,
        "text": " So I think in order to do that,",
        "tokens": [
          50364,
          407,
          286,
          519,
          294,
          1668,
          281,
          360,
          300,
          11,
          50448
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1174,
        "id": 443,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1171.16,
        "temperature": 0,
        "text": " I need to scale everything down.",
        "tokens": [
          50448,
          286,
          643,
          281,
          4373,
          1203,
          760,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1176.96,
        "id": 444,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1174,
        "temperature": 0,
        "text": " And so, I mean, I could do this in so many,",
        "tokens": [
          50590,
          400,
          370,
          11,
          286,
          914,
          11,
          286,
          727,
          360,
          341,
          294,
          370,
          867,
          11,
          50738
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1181.96,
        "id": 445,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1176.96,
        "temperature": 0,
        "text": " what if I just, what if I just did this?",
        "tokens": [
          50738,
          437,
          498,
          286,
          445,
          11,
          437,
          498,
          286,
          445,
          630,
          341,
          30,
          50988
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1188.08,
        "id": 446,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1184.6,
        "temperature": 0,
        "text": " What if I just scaled all the dx's and dy's",
        "tokens": [
          51120,
          708,
          498,
          286,
          445,
          36039,
          439,
          264,
          30017,
          311,
          293,
          14584,
          311,
          51294
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1191.6,
        "id": 447,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1188.08,
        "temperature": 0,
        "text": " by like 1%, by 10%?",
        "tokens": [
          51294,
          538,
          411,
          502,
          8923,
          538,
          1266,
          4,
          30,
          51470
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1193.68,
        "id": 448,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1191.6,
        "temperature": 0,
        "text": " I was actually going to do it a totally different way,",
        "tokens": [
          51470,
          286,
          390,
          767,
          516,
          281,
          360,
          309,
          257,
          3879,
          819,
          636,
          11,
          51574
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1194.88,
        "id": 449,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1193.68,
        "temperature": 0,
        "text": " but would this actually work?",
        "tokens": [
          51574,
          457,
          576,
          341,
          767,
          589,
          30,
          51634
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1196.72,
        "id": 450,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1194.88,
        "temperature": 0,
        "text": " This might be an easier way to do it.",
        "tokens": [
          51634,
          639,
          1062,
          312,
          364,
          3571,
          636,
          281,
          360,
          309,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.20251156733586237,
        "compression_ratio": 1.6210045662100456,
        "end": 1198.92,
        "id": 451,
        "no_speech_prob": 0.0000011544618701009313,
        "seek": 116948,
        "start": 1198,
        "temperature": 0,
        "text": " Yeah, there we go.",
        "tokens": [
          51790,
          865,
          11,
          456,
          321,
          352,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.25763505697250366,
        "compression_ratio": 1.3656716417910448,
        "end": 1205.2,
        "id": 452,
        "no_speech_prob": 0.00000729636667529121,
        "seek": 119948,
        "start": 1200.2,
        "temperature": 0,
        "text": " All right, here is our festive world of snowflakes.",
        "tokens": [
          50400,
          1057,
          558,
          11,
          510,
          307,
          527,
          42729,
          1002,
          295,
          44124,
          3419,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.25763505697250366,
        "compression_ratio": 1.3656716417910448,
        "end": 1209.68,
        "id": 453,
        "no_speech_prob": 0.00000729636667529121,
        "seek": 119948,
        "start": 1205.24,
        "temperature": 0,
        "text": " And I am going to make this larger.",
        "tokens": [
          50652,
          400,
          286,
          669,
          516,
          281,
          652,
          341,
          4833,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.25763505697250366,
        "compression_ratio": 1.3656716417910448,
        "end": 1217.1200000000001,
        "id": 454,
        "no_speech_prob": 0.00000729636667529121,
        "seek": 119948,
        "start": 1213.16,
        "temperature": 0,
        "text": " I'm going to get rid of the console, do this.",
        "tokens": [
          51048,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          11076,
          11,
          360,
          341,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.25763505697250366,
        "compression_ratio": 1.3656716417910448,
        "end": 1217.96,
        "id": 455,
        "no_speech_prob": 0.00000729636667529121,
        "seek": 119948,
        "start": 1217.1200000000001,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51246,
          45263,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.25763505697250366,
        "compression_ratio": 1.3656716417910448,
        "end": 1221.8,
        "id": 456,
        "no_speech_prob": 0.00000729636667529121,
        "seek": 119948,
        "start": 1220.96,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51438,
          45263,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.25763505697250366,
        "compression_ratio": 1.3656716417910448,
        "end": 1226.96,
        "id": 457,
        "no_speech_prob": 0.00000729636667529121,
        "seek": 119948,
        "start": 1225.24,
        "temperature": 0,
        "text": " Nice big canvas.",
        "tokens": [
          51652,
          5490,
          955,
          16267,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.25763505697250366,
        "compression_ratio": 1.3656716417910448,
        "end": 1228.48,
        "id": 458,
        "no_speech_prob": 0.00000729636667529121,
        "seek": 119948,
        "start": 1226.96,
        "temperature": 0,
        "text": " Oh, there we go.",
        "tokens": [
          51738,
          876,
          11,
          456,
          321,
          352,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1229.56,
        "id": 459,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1228.48,
        "temperature": 0,
        "text": " That's good enough.",
        "tokens": [
          50364,
          663,
          311,
          665,
          1547,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1231.1200000000001,
        "id": 460,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1229.56,
        "temperature": 0,
        "text": " Okay, go.",
        "tokens": [
          50418,
          1033,
          11,
          352,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1232.44,
        "id": 461,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1231.1200000000001,
        "temperature": 0,
        "text": " Draw snowflakes.",
        "tokens": [
          50496,
          20386,
          44124,
          3419,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1236.08,
        "id": 462,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1233.4,
        "temperature": 0,
        "text": " So, there we are, everybody.",
        "tokens": [
          50610,
          407,
          11,
          456,
          321,
          366,
          11,
          2201,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1238.56,
        "id": 463,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1236.08,
        "temperature": 0,
        "text": " So you can imagine you could probably create a whole scene",
        "tokens": [
          50744,
          407,
          291,
          393,
          3811,
          291,
          727,
          1391,
          1884,
          257,
          1379,
          4145,
          50868
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1240.84,
        "id": 464,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1238.56,
        "temperature": 0,
        "text": " with a bunch of different things and do much more.",
        "tokens": [
          50868,
          365,
          257,
          3840,
          295,
          819,
          721,
          293,
          360,
          709,
          544,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1242.6,
        "id": 465,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1240.84,
        "temperature": 0,
        "text": " I'm going to let this run for a little bit.",
        "tokens": [
          50982,
          286,
          478,
          516,
          281,
          718,
          341,
          1190,
          337,
          257,
          707,
          857,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1244.6,
        "id": 466,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1242.6,
        "temperature": 0,
        "text": " We'll speed this up so we can see what this scene",
        "tokens": [
          51070,
          492,
          603,
          3073,
          341,
          493,
          370,
          321,
          393,
          536,
          437,
          341,
          4145,
          51170
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1247.2,
        "id": 467,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1244.6,
        "temperature": 0,
        "text": " of snowflakes looks like in a couple minutes.",
        "tokens": [
          51170,
          295,
          44124,
          3419,
          1542,
          411,
          294,
          257,
          1916,
          2077,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2464121197341779,
        "compression_ratio": 1.517094017094017,
        "end": 1258.2,
        "id": 468,
        "no_speech_prob": 0.000009818309990805574,
        "seek": 122848,
        "start": 1247.2,
        "temperature": 0,
        "text": " All right, so as you can see,",
        "tokens": [
          51300,
          220,
          7868,
          558,
          11,
          370,
          382,
          291,
          393,
          536,
          11,
          51850
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1260.52,
        "id": 469,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1258.28,
        "temperature": 0,
        "text": " by the way, during all that time,",
        "tokens": [
          50368,
          538,
          264,
          636,
          11,
          1830,
          439,
          300,
          565,
          11,
          50480
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1262.2,
        "id": 470,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1260.52,
        "temperature": 0,
        "text": " I changed the background to black,",
        "tokens": [
          50480,
          286,
          3105,
          264,
          3678,
          281,
          2211,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1263.28,
        "id": 471,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1262.2,
        "temperature": 0,
        "text": " made it sort of full screen,",
        "tokens": [
          50564,
          1027,
          309,
          1333,
          295,
          1577,
          2568,
          11,
          50618
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1264.52,
        "id": 472,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1263.28,
        "temperature": 0,
        "text": " and drawing the snowflakes white.",
        "tokens": [
          50618,
          293,
          6316,
          264,
          44124,
          3419,
          2418,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1265.76,
        "id": 473,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1264.52,
        "temperature": 0,
        "text": " But you can see this is what,",
        "tokens": [
          50680,
          583,
          291,
          393,
          536,
          341,
          307,
          437,
          11,
          50742
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1267.28,
        "id": 474,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1265.76,
        "temperature": 0,
        "text": " after it's drawn a whole bunch of them,",
        "tokens": [
          50742,
          934,
          309,
          311,
          10117,
          257,
          1379,
          3840,
          295,
          552,
          11,
          50818
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1269.0800000000002,
        "id": 475,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1267.28,
        "temperature": 0,
        "text": " this is what we get.",
        "tokens": [
          50818,
          341,
          307,
          437,
          321,
          483,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1269.92,
        "id": 476,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1269.0800000000002,
        "temperature": 0,
        "text": " So I would encourage you,",
        "tokens": [
          50908,
          407,
          286,
          576,
          5373,
          291,
          11,
          50950
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1271.04,
        "id": 477,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1269.92,
        "temperature": 0,
        "text": " what's going to be interesting about this is,",
        "tokens": [
          50950,
          437,
          311,
          516,
          281,
          312,
          1880,
          466,
          341,
          307,
          11,
          51006
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1273.4,
        "id": 478,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1271.04,
        "temperature": 0,
        "text": " oh, could you save those in objects",
        "tokens": [
          51006,
          1954,
          11,
          727,
          291,
          3155,
          729,
          294,
          6565,
          51124
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1276.16,
        "id": 479,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1273.4,
        "temperature": 0,
        "text": " and then combine this with my last year's",
        "tokens": [
          51124,
          293,
          550,
          10432,
          341,
          365,
          452,
          1036,
          1064,
          311,
          51262
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1279.04,
        "id": 480,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1276.16,
        "temperature": 0,
        "text": " snowflake snowfall coding challenge?",
        "tokens": [
          51262,
          44124,
          619,
          5756,
          6691,
          17720,
          3430,
          30,
          51406
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1280.68,
        "id": 481,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1279.04,
        "temperature": 0,
        "text": " Could you think about color?",
        "tokens": [
          51406,
          7497,
          291,
          519,
          466,
          2017,
          30,
          51488
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1282.64,
        "id": 482,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1280.68,
        "temperature": 0,
        "text": " Could you animate them in some way?",
        "tokens": [
          51488,
          7497,
          291,
          36439,
          552,
          294,
          512,
          636,
          30,
          51586
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1284.32,
        "id": 483,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1282.64,
        "temperature": 0,
        "text": " What other types of things might you do",
        "tokens": [
          51586,
          708,
          661,
          3467,
          295,
          721,
          1062,
          291,
          360,
          51670
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1286.3600000000001,
        "id": 484,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1284.32,
        "temperature": 0,
        "text": " with SketchRNN into a scene?",
        "tokens": [
          51670,
          365,
          49245,
          49,
          45,
          45,
          666,
          257,
          4145,
          30,
          51772
        ]
      },
      {
        "avg_logprob": -0.21866223884351327,
        "compression_ratio": 1.7048192771084338,
        "end": 1287.92,
        "id": 485,
        "no_speech_prob": 0.019418766722083092,
        "seek": 125820,
        "start": 1286.3600000000001,
        "temperature": 0,
        "text": " So many possibilities.",
        "tokens": [
          51772,
          407,
          867,
          12178,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1290.72,
        "id": 486,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1288.5600000000002,
        "temperature": 0,
        "text": " I'm sure you will create something.",
        "tokens": [
          50396,
          286,
          478,
          988,
          291,
          486,
          1884,
          746,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1292.96,
        "id": 487,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1290.72,
        "temperature": 0,
        "text": " Take a look in this video's description",
        "tokens": [
          50504,
          3664,
          257,
          574,
          294,
          341,
          960,
          311,
          3855,
          50616
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1295.24,
        "id": 488,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1292.96,
        "temperature": 0,
        "text": " for the link to the CodingDrain.com page",
        "tokens": [
          50616,
          337,
          264,
          2113,
          281,
          264,
          383,
          8616,
          35,
          7146,
          13,
          1112,
          3028,
          50730
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1297.48,
        "id": 489,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1295.24,
        "temperature": 0,
        "text": " where you can submit your versions of this.",
        "tokens": [
          50730,
          689,
          291,
          393,
          10315,
          428,
          9606,
          295,
          341,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1301.1200000000001,
        "id": 490,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1297.48,
        "temperature": 0,
        "text": " And hopefully, when you're watching this,",
        "tokens": [
          50842,
          400,
          4696,
          11,
          562,
          291,
          434,
          1976,
          341,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1303.44,
        "id": 491,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1301.1200000000001,
        "temperature": 0,
        "text": " there'll be more information also about SketchRNN",
        "tokens": [
          51024,
          456,
          603,
          312,
          544,
          1589,
          611,
          466,
          49245,
          49,
          45,
          45,
          51140
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1304.92,
        "id": 492,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1303.44,
        "temperature": 0,
        "text": " on the ML5 website itself.",
        "tokens": [
          51140,
          322,
          264,
          21601,
          20,
          3144,
          2564,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1306.4,
        "id": 493,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1304.92,
        "temperature": 0,
        "text": " Okay, thanks for watching.",
        "tokens": [
          51214,
          1033,
          11,
          3231,
          337,
          1976,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2945060319797967,
        "compression_ratio": 1.4383561643835616,
        "end": 1307.24,
        "id": 494,
        "no_speech_prob": 0.0000809268094599247,
        "seek": 128792,
        "start": 1306.4,
        "temperature": 0,
        "text": " Woo woo!",
        "tokens": [
          51288,
          10468,
          21657,
          0,
          51330
        ]
      }
    ],
    "transcription": " Hello, welcome to another holiday coding challenge, again with the snowflakes. This is my second snowflake challenge, but in this time, instead of creating an algorithm to draw a snowflake, I am going to ask a neural network to draw a snowflake for me. Now, there's a lot of pieces to all of the work that's gone in to making the fact that I'm going to be able to do this in, well, what probably will be about four and a half hours, but really could take just about 15 minutes possible. So the first thing I want to reference is the Magenta Project. So the Magenta Project is a make music and art using machine learning research project. It's an open source research project from Google, and it has a ton of examples, projects, with TensorFlow in both Python and JavaScript, and you can look through it, all these featured projects. The project I want to mention is, I'll just click over here, is this project called Sketch RNN, or Draw Together with a Neural Network. Now, if you've watched any of my previous videos about the Quick Draw Dataset, the Quick Draw Dataset is this huge collection of millions upon millions of doodles that users from around the world made playing the Google Quick Draw game. So what the researchers from Google Brain did, you can see them credited here, David Ha, Jonas, and Young-Yun, and Ian Johnson, wrote this paper about how a neural network could be trained on all of those drawings. So it could learn, okay, when somebody's drawing a cat, they kind of go like this, and then they go like this, and it could start to imagine new drawings of cats. And it's called Sketch RNN because the kind of neural network that it's using is something called a recurrent neural network. And you might have also seen this, I've had some other, Nabil Hussain was here and did a guest video about generating text with a recurrent neural network. Recurrent neural network is good at learning about sequential information, like, hello world is sequential information, H-E-L-L-O space W-O-R-L-D. Music is sequential information. La la la la la la la la la. That's a sequence of notes and rhythms. A drawing is a sequence of vectors. So you can read this paper all about how they used the Google Quick Draw dataset to train a model to create new drawings. You can also look at their demo, and this is the code, by the way, for their demo. There's a lot involved here in all of these pieces, and here's the demo right here. So I'm going to pick a cat, and what I can do is I can start drawing, whoops, I can start drawing a cat, I'm just going to draw a circle, and then it will pick up for me and finish the rest of the cat. So at some point I will do a part two of this video where I actually create an interactive version like that, but one of the things that is in now the ML5 project, ML5 is a friendly machine learning for the web library that's built on top of TensorFlow.js. It works with P5, which is the open source JavaScript library that I use in a lot of my video tutorials is it has a Sketch RNN module for you. So on the one hand, you might want to go and look all the way through all this code and read the research paper to learn how it works, but if you want to quickly get up and running with playing with the Sketch RNN model, what we've tried to put in ML5 will help you. Now, you might notice that if I go click on reference, at the time of this recording, it doesn't say Sketch RNN here. So this is actually a new feature. There's a couple issues in the GitHub repository for ML5 about things that don't work perfectly or need to be added or fixed. We welcome contributions. I will come back and maybe do some more videos with it once it's gotten further along and there is documentation, but for the holiday season, let's see if we can get it to draw a snowflake for us. So I'm not going to be able to use the website because the documentation isn't there, but I've got some documentation over here on my invisible computer that I can look at if I need to. And so what do I have? I have a blank p5 sketch with just setup and draw, and also an index.html, I should call this a snowflake sketch RNN. I have also, in addition to the p5 libraries being imported, I have the ML5 library, and again, at the time of this recording, it's version 0.1.3. Hopefully, there'll be future updates to improve Sketch RNN and there'll be a higher numbered version. Okay, so the first thing that I want to do is I want to make a variable and I'm going to call it model. So model, I could call it Sketch RNN, maybe I should call it Sketch RNN. I'll just call it model. Model is the thing that's going to hold the Sketch RNN model. It is all of the information, it's the brain of that neural network that we can ask to generate new stuff. So we can say, hey, give me a new point along the path that you're imagining to draw. So I'm going to say model equals ML5 Sketch RNN and then I'm going to just put a callback in here, model ready, and this is the important thing. What goes here? So there are a bunch of available models with Sketch RNN and we could see that list here. Whoops, here. For example, there is cat. Let's start with cat, maybe. But we could see all the other ones, like the Mona Lisa apparently is in there. Bird, so let's, whatever is available, we can put cat in here. I'm asking ML5 to load the cat model. It's actually doing this from the cloud. The model, all of the data for this machine learning model is stored on a server somewhere and ML5 knows how to load that for you. So then what I'm going to do is add a callback. I'm going to say model ready. I'm going to write a function called model ready and I'm just going to say console.log model ready. So let's just run this code and see if it even just works loading the model without an error. So I'm going to close this demo down. I have my own here. Okay, great, the model is loaded. And just to be sure, oh, yeah, initialize Sketch RNN model ready, just to be sure if I put in here tiger, which I don't think is something in there. Oh, maybe it is. Guacamole, that must not be something in there. I spelled guacamole wrong even, okay? Right, it couldn't find guacamole and I know that's spelled wrong. Apologies to guacamole lovers all over the world. Okay, so we've got the cat. Now what do I need to do? The first thing I need to do as soon as the model is ready is ask for something. So what Sketch RNN will give you every time you ask for it to generate something is what is referred to as a stroke. Now I'm not going to use the variable named stroke in my code because stroke is a global function in p5 that sets the outline color of a shape and I don't want to get confused with that. But the stroke is a particular, a JavaScript object with a few properties. It has dx, dy, and I think it's just called pen. And dx is a floating point number, some number like 1.3. Dy is some number like negative four. And pen is a string. It can either be up, down, or end. And what this refers to is a particular stroke of a pen basically. So if you could imagine dx for the change in x, delta x, dy for the change in y, delta y. If I were to go over 1.3 units and up negative four units, basically the stroke is this. This is the path of the pen. That's what Sketch RNN should draw right now. And it should either draw it as a line if the pen is down. If the pen is up, it should just move from here to there. Because if I'm drawing a cat, I'm going to draw this, then I'm going to pick my pen up, move over here. So that action is also a stroke, but it's a stroke with the pen up. And then pen end is when the drawing is finished. So this is what ml5 does. The actual native Sketch RNN model just gives you all these things as an array of numbers. And so we've kind of made it as a JavaScript object that makes it a little bit easier to read, hopefully. Okay, so now coming back over here, I think I just say model.generate.sketch. I'm looking, oh, oh, oh, yes. Now actually an important thing that I should probably do, I don't necessarily need to do this the first time, but because this is a kind of machine learning model that is giving us sequential information, the next stroke, like the one that comes after this one, is quite important, it's related to this one. But if I want to start over and draw a new cat, I need to kind of go back to the beginning and say start a new cat over. And so the model.reset function is a thing that does that. So model.reset, I'm going to call that, it should be reset the first time you load it, but I'm going to call that anyway. Then I could say model.generate.sketch, and then I'm going to write a function, I'm going to call it gotSketch. It should get that strokePath. Let's just call that s, and let's have a variable. I'm going to have a global variable called strokePath, and I'm going to set that to, I'm just going to set it to null when the program starts, and then when I get a new sketch, I'm going to say strokePath equals s, and then I'm just going to say console.log strokePath. So let's see if we get this first thing. Model loaded! Undefined. Ooh. That was close. I forgot. This is actually very hard for me. I always make this mistake. ML5 is written in such a way that uses something called error first callbacks. This is different than how P5 is written. So this gotSketch function is receiving, what was actually undefined there was the error. There was no error. All the callbacks need to have an error argument first. So if I wanted to be really, if I wanted to be really thorough about error handling, I might do something like this. So I could console out the error, and then if there is no error, now just console.log out the strokePath. So this should work now. Look at that model! Ah, there we go! So look at this! I need to move this many pixels in the x direction, this many pixels in the y direction, and the pen is down. So this should be easy enough for us to implement. If I have an x and a y, global variable, I'm going to start them in the middle. Then I am going to, in the draw loop, I'm going to say if strokePath is not equal to x, not equal to null, I got to check. Do I have a new strokePath? The new strokePath will come in the callback here, and draw is always looping. So draw is looping to wait to see that there's a strokePath. And again, I could control how the draw loop works with the query to the model in a different way, but this is an easy way for me to do it. Draw is just going to loop. Then I'm going to say draw a line from x, y to x plus dx, y plus dy. Just draw that line, and then what? Let's set strokePath to null again. So once I'm done, set that strokePath to null. Okay, so we should just see that one first line. Oh, dx is not defined. I don't know, strokePath.dx, right? It's part of strokePath. I don't know why. The dx and dy is in the object. Here it goes. Do you see it? Is there a line? Why haven't I seen that line? Oh, hmm. Stroke zero? Stroke weight, stroke weight four? What did I miss? Line, oh, you know what? I'm sort of forgetting. I just don't want to, I just want to draw the background. I'm redrawing the background. So as soon as I draw the line, ah! That's such a mistake that I always make. I drew that line, but then draw looped again and drew the background over it. So this is a thing where I just want to draw the background once, and I'll draw it in setup in this case. So let's draw it in setup. Here we go, we're getting there. Let's see that line. There it is, that's the first stroke of our cat. So we got this first path that the neural network, the Sketch RNN model, imagined for the cat. So now what we're going to do is, ah, wait, what do we need to do? Are you thinking what I'm thinking? Let's just ask for the next one. So how did I ask for the first one? Model.generate, I can just say, okay, I got one. Set it to null, generate, and wait for the next one. Also, though, I need to move x and y to that new point. So it actually might make sense for me to say, like, new x equals, and this will clean up the code a little bit in a way that makes it more readable. This is the new x value. This is the new y value. Draw the line from old x to new x. Set the stroke path to null, ask for a new one, and also move x and y to the new position. So now, when there's a new one, we should get the new one in. Guess what, here we go. Let's see our cat. There's our cat. Whoa, woohoo, look, and it's console.log and it's run. Now, it looks crazy, right? Because I completely ignored the whole pen up versus down thing. So that's something really important. And there's something that's actually that I didn't bother to tell you that's kind of important and makes it a little bit more confusing. Let's take out this console log, by the way. So the thing that's extra confusing about the pen up and pen down is when you get this information, it's actually telling you the pen state for the next stroke. This is not the pen state for this particular path. It's the pen state for the next one. Why is that? Well, it's a little bit weird, but if you think about it, when you first start drawing, I mean, the pen is down. It has to be down. That's the definition of the beginning of the drawing. And then when you're done, you're saying finish that last one, then end. So what it really is, it's the pen state that you get in the previous stroke sets the next one, and when it's end, we're done. So let's try implementing that. And a way we can do that, I think, is just by having a variable that's called previousPen, and previousPen, or I could just call it pen, actually. Let's just call it pen, because by definition, pen is down. So pen is going to be down to start with. Pen is down, and here, I'm only going to actually draw it if pen, whoops, sorry, if pen equals down, then I should actually draw the drawing, draw the line, sorry. I should always, oh, I should always move x. So I always want to move x, but I only want to draw the line if pen is down, and then what I need to do is here, I need to say pen equals, oh, I am going to need a previousPen. Or can I do this right before I get the new stroke path? Hmm, I'm confused. Oh, I can just say, I could say pen equals strokePath.pen. So basically, the pen starts as down, then I'm going to draw, and then pick up that for when the next time comes around. So don't pick up the actual pen value from the object. You might need to think about this for a little bit. This is really like previousPen. Maybe I should call it previous, because really what I'm checking here is the pen from the last time, because I'm picking it up after. Let's see if this works. Look at that cat. I'm waiting for like a cat. Here's the thing, we don't know what we're going to get. This has just been trained on what users all over the world drew cats, and sometimes we're going to get a nose and whiskers, and sometimes we're not. We're going to see a variety of different kinds of cats. Okay, but now we also need to figure out what to do. We need to check for pen ending. So if I here were to say if pen, so let's set the stroke path to null. We can do all this, but as long as pen is not equal to end, then I am going to say, I'll generate the new. So if pen is equal to end, don't bother to generate another stroke, and then I'm going to just put in here else console.log drawing complete. Okay, let's give this a try. We're going to see the cat. There's our cat. There's our cat. Drawing complete. So maybe we should have it restart a new one, and this is going to be good for our snowflakes. You'll see in a second. So actually instead of drawing complete, what I could actually do now is I could say model, model.reset, and model.generate again. So this is going to instantaneously do another one. Let's see if this works. Here's a cat. Oh, you know what? It's going to do it from wherever it ended. So the other thing I need to do is reset where x and y go. So let's say x goes back to the middle of the screen. Y goes back to the middle of the screen. It takes a while to load the model, so each time I'm refreshing, I have to wait a little bit. So let's see our cat. I obviously need to give myself, oh, look at that, it's a very different kind of cat. Drawing complete. Now it's doing another one. So this is perfect, because this is exactly what I want to do with snowflakes. This is exactly what I want to do with snowflakes. So first, let's change this to snowflake. Let's make this x a random place. Let's make this y a random place. And actually, let's also translate to the center. I want to translate to the center, and I'll explain why in a second. So actually, this is going to be at random, anywhere randomly in the canvas. So x is going to be between negative half width and positive half width, half height, positive half width. Y is negative half height, positive half height. And then I want to do exactly the same thing whenever I finish the snowflake. Okay, here we go. And let's see what happens. I don't know how big these snowflakes are going to be. Here's a nice snowflake. Yeah, there we go. Look, it's drawing snowflakes. So I wanted to create a big scene of snowflakes. So I think in order to do that, I need to scale everything down. And so, I mean, I could do this in so many, what if I just, what if I just did this? What if I just scaled all the dx's and dy's by like 1%, by 10%? I was actually going to do it a totally different way, but would this actually work? This might be an easier way to do it. Yeah, there we go. All right, here is our festive world of snowflakes. And I am going to make this larger. I'm going to get rid of the console, do this. Whoops. Whoops. Nice big canvas. Oh, there we go. That's good enough. Okay, go. Draw snowflakes. So, there we are, everybody. So you can imagine you could probably create a whole scene with a bunch of different things and do much more. I'm going to let this run for a little bit. We'll speed this up so we can see what this scene of snowflakes looks like in a couple minutes. All right, so as you can see, by the way, during all that time, I changed the background to black, made it sort of full screen, and drawing the snowflakes white. But you can see this is what, after it's drawn a whole bunch of them, this is what we get. So I would encourage you, what's going to be interesting about this is, oh, could you save those in objects and then combine this with my last year's snowflake snowfall coding challenge? Could you think about color? Could you animate them in some way? What other types of things might you do with SketchRNN into a scene? So many possibilities. I'm sure you will create something. Take a look in this video's description for the link to the CodingDrain.com page where you can submit your versions of this. And hopefully, when you're watching this, there'll be more information also about SketchRNN on the ML5 website itself. Okay, thanks for watching. Woo woo!",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:57.33951Z",
  "started_at": "2023-09-26T21:24:11.228792Z",
  "completed_at": "2023-09-26T21:29:39.587112Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=pdaNttb7Mr8",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 328.35832
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/ruiu5nbbywufgdkl3gs5vqo3za/cancel",
    "get": "https://api.replicate.com/v1/predictions/ruiu5nbbywufgdkl3gs5vqo3za"
  }
}