{
  "id": "qazp3gbb4um3eutyzrr7qy6fai",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/UaKab6h9Z0I.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/111711 [00:00<?, ?frames/s]\n  3%|▎         | 2800/111711 [00:07<04:41, 386.46frames/s]\n  5%|▍         | 5504/111711 [00:16<05:21, 329.91frames/s]\n  8%|▊         | 8504/111711 [00:23<04:48, 358.22frames/s]\n 10%|█         | 11420/111711 [00:31<04:25, 377.44frames/s]\n 13%|█▎        | 14392/111711 [00:37<04:05, 397.22frames/s]\n 15%|█▌        | 17168/111711 [00:42<03:29, 450.65frames/s]\n 18%|█▊        | 20072/111711 [00:49<03:32, 430.99frames/s]\n 21%|██        | 22948/111711 [00:58<03:46, 391.64frames/s]\n 23%|██▎       | 25882/111711 [01:06<03:40, 388.76frames/s]\n 26%|██▌       | 28730/111711 [01:13<03:38, 380.39frames/s]\n 28%|██▊       | 31456/111711 [01:22<03:41, 362.90frames/s]\n 31%|███       | 34400/111711 [01:30<03:37, 354.81frames/s]\n 33%|███▎      | 37368/111711 [01:39<03:27, 358.85frames/s]\n 36%|███▌      | 40252/111711 [01:46<03:17, 362.00frames/s]\n 39%|███▊      | 43068/111711 [01:55<03:17, 348.35frames/s]\n 41%|████      | 46064/111711 [02:03<03:04, 355.53frames/s]\n 44%|████▍     | 48928/111711 [02:09<02:42, 385.95frames/s]\n 46%|████▋     | 51780/111711 [02:15<02:27, 405.02frames/s]\n 49%|████▊     | 54448/111711 [02:21<02:17, 414.98frames/s]\n 51%|█████▏    | 57374/111711 [02:27<02:02, 442.81frames/s]\n 54%|█████▍    | 60294/111711 [02:33<01:54, 447.97frames/s]\n 57%|█████▋    | 63266/111711 [02:39<01:45, 458.25frames/s]\n 59%|█████▉    | 65974/111711 [02:45<01:39, 459.63frames/s]\n 62%|██████▏   | 68974/111711 [02:50<01:24, 504.76frames/s]\n 64%|██████▍   | 71838/111711 [02:56<01:18, 505.11frames/s]\n 67%|██████▋   | 74838/111711 [03:01<01:10, 523.13frames/s]\n 70%|██████▉   | 77714/111711 [03:07<01:07, 500.04frames/s]\n 72%|███████▏  | 80302/111711 [03:13<01:04, 486.90frames/s]\n 74%|███████▍  | 83202/111711 [03:17<00:53, 535.38frames/s]\n 77%|███████▋  | 85586/111711 [03:20<00:45, 575.58frames/s]\n 79%|███████▉  | 88474/111711 [03:25<00:38, 596.06frames/s]\n 82%|████████▏ | 91474/111711 [03:30<00:33, 608.99frames/s]\n 84%|████████▍ | 94238/111711 [03:35<00:29, 586.03frames/s]\n 87%|████████▋ | 97230/111711 [03:38<00:22, 650.74frames/s]\n 90%|████████▉ | 100218/111711 [03:44<00:18, 609.48frames/s]\n 92%|█████████▏| 103186/111711 [03:50<00:14, 577.42frames/s]\n 95%|█████████▍| 105818/111711 [03:55<00:10, 539.39frames/s]\n 97%|█████████▋| 108790/111711 [04:04<00:06, 461.56frames/s]\n 99%|█████████▉| 110742/111711 [04:09<00:02, 445.32frames/s]\n100%|██████████| 111711/111711 [04:09<00:00, 491.66frames/s]\n100%|██████████| 111711/111711 [04:09<00:00, 447.06frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 5.46,
        "id": 0,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " And you thought we were done with the ML5 neural network",
        "tokens": [
          50364,
          400,
          291,
          1194,
          321,
          645,
          1096,
          365,
          264,
          21601,
          20,
          18161,
          3209,
          50637
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 6.24,
        "id": 1,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 5.46,
        "temperature": 0,
        "text": " tutorials.",
        "tokens": [
          50637,
          17616,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 8.56,
        "id": 2,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 6.24,
        "temperature": 0,
        "text": " But no, there is one more because I",
        "tokens": [
          50676,
          583,
          572,
          11,
          456,
          307,
          472,
          544,
          570,
          286,
          50792
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 10.06,
        "id": 3,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 8.56,
        "temperature": 0,
        "text": " am leading to something.",
        "tokens": [
          50792,
          669,
          5775,
          281,
          746,
          13,
          50867
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 14,
        "id": 4,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 10.06,
        "temperature": 0,
        "text": " I am going to, you will soon see in this playlist,",
        "tokens": [
          50867,
          286,
          669,
          516,
          281,
          11,
          291,
          486,
          2321,
          536,
          294,
          341,
          16788,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 16.5,
        "id": 5,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 14,
        "temperature": 0,
        "text": " a section on convolutional neural networks.",
        "tokens": [
          51064,
          257,
          3541,
          322,
          45216,
          304,
          18161,
          9590,
          13,
          51189
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 18.88,
        "id": 6,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 16.5,
        "temperature": 0,
        "text": " But before I get to convolutional neural networks,",
        "tokens": [
          51189,
          583,
          949,
          286,
          483,
          281,
          45216,
          304,
          18161,
          9590,
          11,
          51308
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 23.6,
        "id": 7,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 18.88,
        "temperature": 0,
        "text": " I want to look at reasons why a convolutional layer,",
        "tokens": [
          51308,
          286,
          528,
          281,
          574,
          412,
          4112,
          983,
          257,
          45216,
          304,
          4583,
          11,
          51544
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 26.76,
        "id": 8,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 23.6,
        "temperature": 0,
        "text": " I have to answer this question, like what is a convolution?",
        "tokens": [
          51544,
          286,
          362,
          281,
          1867,
          341,
          1168,
          11,
          411,
          437,
          307,
          257,
          45216,
          30,
          51702
        ]
      },
      {
        "avg_logprob": -0.2597152308413857,
        "compression_ratio": 1.7758620689655173,
        "end": 28,
        "id": 9,
        "no_speech_prob": 0.00033534204703755677,
        "seek": 0,
        "start": 26.76,
        "temperature": 0,
        "text": " I've got to get to that.",
        "tokens": [
          51702,
          286,
          600,
          658,
          281,
          483,
          281,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 29.52,
        "id": 10,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 28,
        "temperature": 0,
        "text": " But before I get to that, I want",
        "tokens": [
          50364,
          583,
          949,
          286,
          483,
          281,
          300,
          11,
          286,
          528,
          50440
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 32.68,
        "id": 11,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 29.52,
        "temperature": 0,
        "text": " to just see why they exist in the first place.",
        "tokens": [
          50440,
          281,
          445,
          536,
          983,
          436,
          2514,
          294,
          264,
          700,
          1081,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 35.88,
        "id": 12,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 32.68,
        "temperature": 0,
        "text": " So I want to start with another scenario for training",
        "tokens": [
          50598,
          407,
          286,
          528,
          281,
          722,
          365,
          1071,
          9005,
          337,
          3097,
          50758
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 37.64,
        "id": 13,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 35.88,
        "temperature": 0,
        "text": " your own neural network.",
        "tokens": [
          50758,
          428,
          1065,
          18161,
          3209,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 40.76,
        "id": 14,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 37.64,
        "temperature": 0,
        "text": " That scenario is an image classifier.",
        "tokens": [
          50846,
          663,
          9005,
          307,
          364,
          3256,
          1508,
          9902,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 43,
        "id": 15,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 40.76,
        "temperature": 0,
        "text": " Now, you might rightfully be sitting there saying",
        "tokens": [
          51002,
          823,
          11,
          291,
          1062,
          558,
          2277,
          312,
          3798,
          456,
          1566,
          51114
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 46.92,
        "id": 16,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 43,
        "temperature": 0,
        "text": " to yourself, you've done videos on image classifiers before.",
        "tokens": [
          51114,
          281,
          1803,
          11,
          291,
          600,
          1096,
          2145,
          322,
          3256,
          1508,
          23463,
          949,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 48.28,
        "id": 17,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 46.92,
        "temperature": 0,
        "text": " And in fact, I have.",
        "tokens": [
          51310,
          400,
          294,
          1186,
          11,
          286,
          362,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 50.92,
        "id": 18,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 48.28,
        "temperature": 0,
        "text": " The very beginning of this whole series",
        "tokens": [
          51378,
          440,
          588,
          2863,
          295,
          341,
          1379,
          2638,
          51510
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 53.84,
        "id": 19,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 50.92,
        "temperature": 0,
        "text": " was about using a pre-trained model for an image classifier.",
        "tokens": [
          51510,
          390,
          466,
          1228,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          337,
          364,
          3256,
          1508,
          9902,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.17860291643840512,
        "compression_ratio": 1.718146718146718,
        "end": 55.04,
        "id": 20,
        "no_speech_prob": 0.00007602446567034349,
        "seek": 2800,
        "start": 53.84,
        "temperature": 0,
        "text": " And guess what?",
        "tokens": [
          51656,
          400,
          2041,
          437,
          30,
          51716
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 58.08,
        "id": 21,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 55.04,
        "temperature": 0,
        "text": " That pre-trained model had convolutional layers in it.",
        "tokens": [
          50364,
          663,
          659,
          12,
          17227,
          2001,
          2316,
          632,
          45216,
          304,
          7914,
          294,
          309,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 62.879999999999995,
        "id": 22,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 58.08,
        "temperature": 0,
        "text": " So I want to now take the time to unpack what that means more",
        "tokens": [
          50516,
          407,
          286,
          528,
          281,
          586,
          747,
          264,
          565,
          281,
          26699,
          437,
          300,
          1355,
          544,
          50756
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 67,
        "id": 23,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 62.879999999999995,
        "temperature": 0,
        "text": " and look at how you could train your own convolutional neural",
        "tokens": [
          50756,
          293,
          574,
          412,
          577,
          291,
          727,
          3847,
          428,
          1065,
          45216,
          304,
          18161,
          50962
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 67.96,
        "id": 24,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 67,
        "temperature": 0,
        "text": " network.",
        "tokens": [
          50962,
          3209,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 69.88,
        "id": 25,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 67.96,
        "temperature": 0,
        "text": " Again, first though, let's just think",
        "tokens": [
          51010,
          3764,
          11,
          700,
          1673,
          11,
          718,
          311,
          445,
          519,
          51106
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 72.08,
        "id": 26,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 69.88,
        "temperature": 0,
        "text": " about how we would make an image classifier",
        "tokens": [
          51106,
          466,
          577,
          321,
          576,
          652,
          364,
          3256,
          1508,
          9902,
          51216
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 73.88,
        "id": 27,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 72.08,
        "temperature": 0,
        "text": " with what we have so far.",
        "tokens": [
          51216,
          365,
          437,
          321,
          362,
          370,
          1400,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 74.72,
        "id": 28,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 73.88,
        "temperature": 0,
        "text": " We have an image.",
        "tokens": [
          51306,
          492,
          362,
          364,
          3256,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.18652228938723073,
        "compression_ratio": 1.6157205240174672,
        "end": 82.24,
        "id": 29,
        "no_speech_prob": 0.0000022959177385928342,
        "seek": 5504,
        "start": 77.75999999999999,
        "temperature": 0,
        "text": " And that image is being sent into an ML5 neural network.",
        "tokens": [
          51500,
          400,
          300,
          3256,
          307,
          885,
          2279,
          666,
          364,
          21601,
          20,
          18161,
          3209,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 88.44000000000001,
        "id": 30,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 85.2,
        "temperature": 0,
        "text": " And out of that neural network comes either a classification",
        "tokens": [
          50372,
          400,
          484,
          295,
          300,
          18161,
          3209,
          1487,
          2139,
          257,
          21538,
          50534
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 89.28,
        "id": 31,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 88.44000000000001,
        "temperature": 0,
        "text": " or regression.",
        "tokens": [
          50534,
          420,
          24590,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 91.64,
        "id": 32,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 89.28,
        "temperature": 0,
        "text": " And in fact, we could do an image regression.",
        "tokens": [
          50576,
          400,
          294,
          1186,
          11,
          321,
          727,
          360,
          364,
          3256,
          24590,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 92.84,
        "id": 33,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 91.64,
        "temperature": 0,
        "text": " And I would love to do that.",
        "tokens": [
          50694,
          400,
          286,
          576,
          959,
          281,
          360,
          300,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 94.26,
        "id": 34,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 92.84,
        "temperature": 0,
        "text": " But let me start with a classifier",
        "tokens": [
          50754,
          583,
          718,
          385,
          722,
          365,
          257,
          1508,
          9902,
          50825
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 95.92,
        "id": 35,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 94.26,
        "temperature": 0,
        "text": " because I think it's a little simpler",
        "tokens": [
          50825,
          570,
          286,
          519,
          309,
          311,
          257,
          707,
          18587,
          50908
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 98.24000000000001,
        "id": 36,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 95.92,
        "temperature": 0,
        "text": " to think about and consider.",
        "tokens": [
          50908,
          281,
          519,
          466,
          293,
          1949,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 103.28,
        "id": 37,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 98.24000000000001,
        "temperature": 0,
        "text": " So maybe it comes out with one of two things, either a cat",
        "tokens": [
          51024,
          407,
          1310,
          309,
          1487,
          484,
          365,
          472,
          295,
          732,
          721,
          11,
          2139,
          257,
          3857,
          51276
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 109.84,
        "id": 38,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 103.28,
        "temperature": 0,
        "text": " or a dog and some type of confidence score.",
        "tokens": [
          51276,
          420,
          257,
          3000,
          293,
          512,
          2010,
          295,
          6687,
          6175,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 112.44000000000001,
        "id": 39,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 109.84,
        "temperature": 0,
        "text": " I previously zoomed in on the ML5 neural network",
        "tokens": [
          51604,
          286,
          8046,
          8863,
          292,
          294,
          322,
          264,
          21601,
          20,
          18161,
          3209,
          51734
        ]
      },
      {
        "avg_logprob": -0.2299846331278483,
        "compression_ratio": 1.6848249027237354,
        "end": 114.2,
        "id": 40,
        "no_speech_prob": 0.00001384599363518646,
        "seek": 8504,
        "start": 112.44000000000001,
        "temperature": 0,
        "text": " and looked at what's inside.",
        "tokens": [
          51734,
          293,
          2956,
          412,
          437,
          311,
          1854,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 117.72,
        "id": 41,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 114.24000000000001,
        "temperature": 0,
        "text": " We have this hidden layer with some number of units",
        "tokens": [
          50366,
          492,
          362,
          341,
          7633,
          4583,
          365,
          512,
          1230,
          295,
          6815,
          50540
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 119.64,
        "id": 42,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 117.72,
        "temperature": 0,
        "text": " and an output layer, which in this case",
        "tokens": [
          50540,
          293,
          364,
          5598,
          4583,
          11,
          597,
          294,
          341,
          1389,
          50636
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 121.76,
        "id": 43,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 119.64,
        "temperature": 0,
        "text": " would have just two if there's two classes.",
        "tokens": [
          50636,
          576,
          362,
          445,
          732,
          498,
          456,
          311,
          732,
          5359,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 123.92,
        "id": 44,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 121.76,
        "temperature": 0,
        "text": " Everything is connected.",
        "tokens": [
          50742,
          5471,
          307,
          4582,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 127.2,
        "id": 45,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 123.92,
        "temperature": 0,
        "text": " And then there are the inputs.",
        "tokens": [
          50850,
          400,
          550,
          456,
          366,
          264,
          15743,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 130.52,
        "id": 46,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 127.2,
        "temperature": 0,
        "text": " With PostNet, you might recall there were 34 inputs",
        "tokens": [
          51014,
          2022,
          10223,
          31890,
          11,
          291,
          1062,
          9901,
          456,
          645,
          12790,
          15743,
          51180
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 132.68,
        "id": 47,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 130.52,
        "temperature": 0,
        "text": " because there were 17 points on my body,",
        "tokens": [
          51180,
          570,
          456,
          645,
          3282,
          2793,
          322,
          452,
          1772,
          11,
          51288
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 135.36,
        "id": 48,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 132.68,
        "temperature": 0,
        "text": " each with an xy position.",
        "tokens": [
          51288,
          1184,
          365,
          364,
          2031,
          88,
          2535,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 138.08,
        "id": 49,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 135.36,
        "temperature": 0,
        "text": " What are these?",
        "tokens": [
          51422,
          708,
          366,
          613,
          30,
          51558
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 139.84,
        "id": 50,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 138.08,
        "temperature": 0,
        "text": " Let's just say for the sake of argument",
        "tokens": [
          51558,
          961,
          311,
          445,
          584,
          337,
          264,
          9717,
          295,
          6770,
          51646
        ]
      },
      {
        "avg_logprob": -0.21500479436553685,
        "compression_ratio": 1.558139534883721,
        "end": 143.92000000000002,
        "id": 51,
        "no_speech_prob": 9.721530886963592e-7,
        "seek": 11420,
        "start": 139.84,
        "temperature": 0,
        "text": " that this image is 10 by 10 pixels.",
        "tokens": [
          51646,
          300,
          341,
          3256,
          307,
          1266,
          538,
          1266,
          18668,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.24921592589347594,
        "compression_ratio": 1.3190184049079754,
        "end": 148.35999999999999,
        "id": 52,
        "no_speech_prob": 4.888301532446349e-7,
        "seek": 14392,
        "start": 144.11999999999998,
        "temperature": 0,
        "text": " So I could consider every single pixel",
        "tokens": [
          50374,
          407,
          286,
          727,
          1949,
          633,
          2167,
          19261,
          50586
        ]
      },
      {
        "avg_logprob": -0.24921592589347594,
        "compression_ratio": 1.3190184049079754,
        "end": 156.44,
        "id": 53,
        "no_speech_prob": 4.888301532446349e-7,
        "seek": 14392,
        "start": 148.35999999999999,
        "temperature": 0,
        "text": " to be an individual input into this ML5 neural network.",
        "tokens": [
          50586,
          281,
          312,
          364,
          2609,
          4846,
          666,
          341,
          21601,
          20,
          18161,
          3209,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.24921592589347594,
        "compression_ratio": 1.3190184049079754,
        "end": 163.39999999999998,
        "id": 54,
        "no_speech_prob": 4.888301532446349e-7,
        "seek": 14392,
        "start": 156.44,
        "temperature": 0,
        "text": " But each pixel has three channels, an R, G, and B.",
        "tokens": [
          50990,
          583,
          1184,
          19261,
          575,
          1045,
          9235,
          11,
          364,
          497,
          11,
          460,
          11,
          293,
          363,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.24921592589347594,
        "compression_ratio": 1.3190184049079754,
        "end": 169.83999999999997,
        "id": 55,
        "no_speech_prob": 4.888301532446349e-7,
        "seek": 14392,
        "start": 163.39999999999998,
        "temperature": 0,
        "text": " So that would make 100 times 3 inputs, 300 inputs.",
        "tokens": [
          51338,
          407,
          300,
          576,
          652,
          2319,
          1413,
          805,
          15743,
          11,
          6641,
          15743,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.24921592589347594,
        "compression_ratio": 1.3190184049079754,
        "end": 171.67999999999998,
        "id": 56,
        "no_speech_prob": 4.888301532446349e-7,
        "seek": 14392,
        "start": 169.83999999999997,
        "temperature": 0,
        "text": " That's reasonable.",
        "tokens": [
          51660,
          663,
          311,
          10585,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 174.12,
        "id": 57,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 171.68,
        "temperature": 0,
        "text": " So this is actually what I want to implement.",
        "tokens": [
          50364,
          407,
          341,
          307,
          767,
          437,
          286,
          528,
          281,
          4445,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 176.68,
        "id": 58,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 174.12,
        "temperature": 0,
        "text": " Take the idea of a two-layer neural network",
        "tokens": [
          50486,
          3664,
          264,
          1558,
          295,
          257,
          732,
          12,
          8376,
          260,
          18161,
          3209,
          50614
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 178.84,
        "id": 59,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 176.68,
        "temperature": 0,
        "text": " to perform classification, the same thing",
        "tokens": [
          50614,
          281,
          2042,
          21538,
          11,
          264,
          912,
          551,
          50722
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 181.96,
        "id": 60,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 178.84,
        "temperature": 0,
        "text": " I've done in previous videos, but this time",
        "tokens": [
          50722,
          286,
          600,
          1096,
          294,
          3894,
          2145,
          11,
          457,
          341,
          565,
          50878
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 185,
        "id": 61,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 181.96,
        "temperature": 0,
        "text": " use as the input the actual raw pixels.",
        "tokens": [
          50878,
          764,
          382,
          264,
          4846,
          264,
          3539,
          8936,
          18668,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 189.12,
        "id": 62,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 185,
        "temperature": 0,
        "text": " Can we get meaningful results from just doing that?",
        "tokens": [
          51030,
          1664,
          321,
          483,
          10995,
          3542,
          490,
          445,
          884,
          300,
          30,
          51236
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 192.44,
        "id": 63,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 189.12,
        "temperature": 0,
        "text": " After we do that, I want to return back to here",
        "tokens": [
          51236,
          2381,
          321,
          360,
          300,
          11,
          286,
          528,
          281,
          2736,
          646,
          281,
          510,
          51402
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 196.56,
        "id": 64,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 192.44,
        "temperature": 0,
        "text": " and talk about why this is inadequate, or not necessarily",
        "tokens": [
          51402,
          293,
          751,
          466,
          983,
          341,
          307,
          42107,
          11,
          420,
          406,
          4725,
          51608
        ]
      },
      {
        "avg_logprob": -0.21991518381479624,
        "compression_ratio": 1.5932835820895523,
        "end": 200.72,
        "id": 65,
        "no_speech_prob": 0.0002868532610591501,
        "seek": 17168,
        "start": 196.56,
        "temperature": 0,
        "text": " inadequate, but how this can be improved on by adding",
        "tokens": [
          51608,
          42107,
          11,
          457,
          577,
          341,
          393,
          312,
          9689,
          322,
          538,
          5127,
          51816
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 202.35999999999999,
        "id": 66,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 200.8,
        "temperature": 0,
        "text": " another layer.",
        "tokens": [
          50368,
          1071,
          4583,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 206.28,
        "id": 67,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 202.35999999999999,
        "temperature": 0,
        "text": " So this layer won't, sorry, the inputs will still be there.",
        "tokens": [
          50446,
          407,
          341,
          4583,
          1582,
          380,
          11,
          2597,
          11,
          264,
          15743,
          486,
          920,
          312,
          456,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 208.4,
        "id": 68,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 206.28,
        "temperature": 0,
        "text": " We're always going to have the inputs.",
        "tokens": [
          50642,
          492,
          434,
          1009,
          516,
          281,
          362,
          264,
          15743,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 211.2,
        "id": 69,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 208.4,
        "temperature": 0,
        "text": " The hidden layer will still be there,",
        "tokens": [
          50748,
          440,
          7633,
          4583,
          486,
          920,
          312,
          456,
          11,
          50888
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 213.32,
        "id": 70,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 211.2,
        "temperature": 0,
        "text": " and the output layer will still be there.",
        "tokens": [
          50888,
          293,
          264,
          5598,
          4583,
          486,
          920,
          312,
          456,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 216.16,
        "id": 71,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 213.32,
        "temperature": 0,
        "text": " But I want to insert right in here something",
        "tokens": [
          50994,
          583,
          286,
          528,
          281,
          8969,
          558,
          294,
          510,
          746,
          51136
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 218.88,
        "id": 72,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 216.16,
        "temperature": 0,
        "text": " called a convolutional layer.",
        "tokens": [
          51136,
          1219,
          257,
          45216,
          304,
          4583,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 220.48,
        "id": 73,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 218.88,
        "temperature": 0,
        "text": " And I want to do a convolutional,",
        "tokens": [
          51272,
          400,
          286,
          528,
          281,
          360,
          257,
          45216,
          304,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 222.4,
        "id": 74,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 220.48,
        "temperature": 0,
        "text": " a two-dimensional convolutional layer.",
        "tokens": [
          51352,
          257,
          732,
          12,
          18759,
          45216,
          304,
          4583,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 223.84,
        "id": 75,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 222.4,
        "temperature": 0,
        "text": " So I will come back.",
        "tokens": [
          51448,
          407,
          286,
          486,
          808,
          646,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 226.36,
        "id": 76,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 223.84,
        "temperature": 0,
        "text": " You want to just skip to that next video,",
        "tokens": [
          51520,
          509,
          528,
          281,
          445,
          10023,
          281,
          300,
          958,
          960,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 227.64,
        "id": 77,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 226.36,
        "temperature": 0,
        "text": " if and when it exists.",
        "tokens": [
          51646,
          498,
          293,
          562,
          309,
          8198,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.265414462370031,
        "compression_ratio": 1.858267716535433,
        "end": 229.48,
        "id": 78,
        "no_speech_prob": 0.00003535622454364784,
        "seek": 20072,
        "start": 227.64,
        "temperature": 0,
        "text": " That's where we'll start talking about that.",
        "tokens": [
          51710,
          663,
          311,
          689,
          321,
          603,
          722,
          1417,
          466,
          300,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 233.44,
        "id": 79,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 229.48,
        "temperature": 0,
        "text": " Let's just get this working as a frame of reference.",
        "tokens": [
          50364,
          961,
          311,
          445,
          483,
          341,
          1364,
          382,
          257,
          3920,
          295,
          6408,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 235.92,
        "id": 80,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 233.44,
        "temperature": 0,
        "text": " I'm going to start with some pre-written code.",
        "tokens": [
          50562,
          286,
          478,
          516,
          281,
          722,
          365,
          512,
          659,
          12,
          26859,
          3089,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 238.83999999999997,
        "id": 81,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 235.92,
        "temperature": 0,
        "text": " All this does, it's a simple p5.js sketch",
        "tokens": [
          50686,
          1057,
          341,
          775,
          11,
          309,
          311,
          257,
          2199,
          280,
          20,
          13,
          25530,
          12325,
          50832
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 241.23999999999998,
        "id": 82,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 238.83999999999997,
        "temperature": 0,
        "text": " that opens a connection to the webcam,",
        "tokens": [
          50832,
          300,
          9870,
          257,
          4984,
          281,
          264,
          39490,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 244.83999999999997,
        "id": 83,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 241.23999999999998,
        "temperature": 0,
        "text": " resizes it to 10 by 10 pixels, and then",
        "tokens": [
          50952,
          725,
          5660,
          309,
          281,
          1266,
          538,
          1266,
          18668,
          11,
          293,
          550,
          51132
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 250.6,
        "id": 84,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 244.83999999999997,
        "temperature": 0,
        "text": " draws a rectangle in the canvas for each and every pixel.",
        "tokens": [
          51132,
          20045,
          257,
          21930,
          294,
          264,
          16267,
          337,
          1184,
          293,
          633,
          19261,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 252.92,
        "id": 85,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 250.6,
        "temperature": 0,
        "text": " So this could be unfamiliar to you.",
        "tokens": [
          51420,
          407,
          341,
          727,
          312,
          29415,
          281,
          291,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 256.28,
        "id": 86,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 252.92,
        "temperature": 0,
        "text": " How do you look at an image in JavaScript in p5",
        "tokens": [
          51536,
          1012,
          360,
          291,
          574,
          412,
          364,
          3256,
          294,
          15778,
          294,
          280,
          20,
          51704
        ]
      },
      {
        "avg_logprob": -0.1785616169805112,
        "compression_ratio": 1.5300751879699248,
        "end": 258.82,
        "id": 87,
        "no_speech_prob": 0.004198751877993345,
        "seek": 22948,
        "start": 256.28,
        "temperature": 0,
        "text": " and address every single pixel individually?",
        "tokens": [
          51704,
          293,
          2985,
          633,
          2167,
          19261,
          16652,
          30,
          51831
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 260.46,
        "id": 88,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 258.82,
        "temperature": 0,
        "text": " If that's unfamiliar to you, I would",
        "tokens": [
          50364,
          759,
          300,
          311,
          29415,
          281,
          291,
          11,
          286,
          576,
          50446
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 264.54,
        "id": 89,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 260.46,
        "temperature": 0,
        "text": " refer to my video on that topic that's appearing over next",
        "tokens": [
          50446,
          2864,
          281,
          452,
          960,
          322,
          300,
          4829,
          300,
          311,
          19870,
          670,
          958,
          50650
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 265.38,
        "id": 90,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 264.54,
        "temperature": 0,
        "text": " to me right now.",
        "tokens": [
          50650,
          281,
          385,
          558,
          586,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 267.88,
        "id": 91,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 265.38,
        "temperature": 0,
        "text": " And you could go take a look at that and then come back here.",
        "tokens": [
          50692,
          400,
          291,
          727,
          352,
          747,
          257,
          574,
          412,
          300,
          293,
          550,
          808,
          646,
          510,
          13,
          50817
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 270.42,
        "id": 92,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 267.88,
        "temperature": 0,
        "text": " But really, this is just looking at every x and y position,",
        "tokens": [
          50817,
          583,
          534,
          11,
          341,
          307,
          445,
          1237,
          412,
          633,
          2031,
          293,
          288,
          2535,
          11,
          50944
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 274.62,
        "id": 93,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 270.42,
        "temperature": 0,
        "text": " getting the RGB values, filling a rectangle, and drawing it.",
        "tokens": [
          50944,
          1242,
          264,
          31231,
          4190,
          11,
          10623,
          257,
          21930,
          11,
          293,
          6316,
          309,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 277.58,
        "id": 94,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 274.62,
        "temperature": 0,
        "text": " So what I want to do next is think",
        "tokens": [
          51154,
          407,
          437,
          286,
          528,
          281,
          360,
          958,
          307,
          519,
          51302
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 282.3,
        "id": 95,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 277.58,
        "temperature": 0,
        "text": " about how do I configure this ml5 neural network, which",
        "tokens": [
          51302,
          466,
          577,
          360,
          286,
          22162,
          341,
          23271,
          20,
          18161,
          3209,
          11,
          597,
          51538
        ]
      },
      {
        "avg_logprob": -0.2187246595110212,
        "compression_ratio": 1.5563636363636364,
        "end": 287.3,
        "id": 96,
        "no_speech_prob": 0.00002178263275709469,
        "seek": 25882,
        "start": 282.3,
        "temperature": 0,
        "text": " expects that 10 by 10 image as its input.",
        "tokens": [
          51538,
          33280,
          300,
          1266,
          538,
          1266,
          3256,
          382,
          1080,
          4846,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 290.58,
        "id": 97,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 287.3,
        "temperature": 0,
        "text": " I'm going to make a variable called pixelBrain.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          19261,
          33,
          7146,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 293.22,
        "id": 98,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 290.58,
        "temperature": 0,
        "text": " And pixelBrain will be a new ml5 neural network.",
        "tokens": [
          50528,
          400,
          19261,
          33,
          7146,
          486,
          312,
          257,
          777,
          23271,
          20,
          18161,
          3209,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 300.58000000000004,
        "id": 99,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 293.22,
        "temperature": 0,
        "text": " I should have mentioned that you can find the link to the code",
        "tokens": [
          50660,
          286,
          820,
          362,
          2835,
          300,
          291,
          393,
          915,
          264,
          2113,
          281,
          264,
          3089,
          51028
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 302.68,
        "id": 100,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 300.58000000000004,
        "temperature": 0,
        "text": " that I'm starting with in case you wanted to code along",
        "tokens": [
          51028,
          300,
          286,
          478,
          2891,
          365,
          294,
          1389,
          291,
          1415,
          281,
          3089,
          2051,
          51133
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 303.26,
        "id": 101,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 302.68,
        "temperature": 0,
        "text": " with me.",
        "tokens": [
          51133,
          365,
          385,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 304.92,
        "id": 102,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 303.26,
        "temperature": 0,
        "text": " Both the finished code and the code I'm starting with",
        "tokens": [
          51162,
          6767,
          264,
          4335,
          3089,
          293,
          264,
          3089,
          286,
          478,
          2891,
          365,
          51245
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 306.58000000000004,
        "id": 103,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 304.92,
        "temperature": 0,
        "text": " will be in this video's description.",
        "tokens": [
          51245,
          486,
          312,
          294,
          341,
          960,
          311,
          3855,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 309.42,
        "id": 104,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 306.58000000000004,
        "temperature": 0,
        "text": " So to create a neural network, I call the neural network",
        "tokens": [
          51328,
          407,
          281,
          1884,
          257,
          18161,
          3209,
          11,
          286,
          818,
          264,
          18161,
          3209,
          51470
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 311.86,
        "id": 105,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 309.42,
        "temperature": 0,
        "text": " function and give it a set of options.",
        "tokens": [
          51470,
          2445,
          293,
          976,
          309,
          257,
          992,
          295,
          3956,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2618902600000775,
        "compression_ratio": 1.830708661417323,
        "end": 314.56,
        "id": 106,
        "no_speech_prob": 0.00006922164902789518,
        "seek": 28730,
        "start": 311.86,
        "temperature": 0,
        "text": " One thing I should mention is while in all the videos",
        "tokens": [
          51592,
          1485,
          551,
          286,
          820,
          2152,
          307,
          1339,
          294,
          439,
          264,
          2145,
          51727
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 317.32,
        "id": 107,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 314.56,
        "temperature": 0,
        "text": " I've done so far, I've said that you",
        "tokens": [
          50364,
          286,
          600,
          1096,
          370,
          1400,
          11,
          286,
          600,
          848,
          300,
          291,
          50502
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 319.52,
        "id": 108,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 317.32,
        "temperature": 0,
        "text": " need to specify the number of inputs",
        "tokens": [
          50502,
          643,
          281,
          16500,
          264,
          1230,
          295,
          15743,
          50612
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 322.56,
        "id": 109,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 319.52,
        "temperature": 0,
        "text": " and the number of outputs to configure your neural network.",
        "tokens": [
          50612,
          293,
          264,
          1230,
          295,
          23930,
          281,
          22162,
          428,
          18161,
          3209,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 325.6,
        "id": 110,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 322.56,
        "temperature": 0,
        "text": " The truth is ml5 is set up to infer",
        "tokens": [
          50764,
          440,
          3494,
          307,
          23271,
          20,
          307,
          992,
          493,
          281,
          13596,
          50916
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 328.24,
        "id": 111,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 325.6,
        "temperature": 0,
        "text": " the total number of inputs and outputs based on the data",
        "tokens": [
          50916,
          264,
          3217,
          1230,
          295,
          15743,
          293,
          23930,
          2361,
          322,
          264,
          1412,
          51048
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 329.4,
        "id": 112,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 328.24,
        "temperature": 0,
        "text": " you're training it with.",
        "tokens": [
          51048,
          291,
          434,
          3097,
          309,
          365,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 331.68,
        "id": 113,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 329.4,
        "temperature": 0,
        "text": " But to be really explicit about things",
        "tokens": [
          51106,
          583,
          281,
          312,
          534,
          13691,
          466,
          721,
          51220
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 334.68,
        "id": 114,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 331.68,
        "temperature": 0,
        "text": " and make the tutorial as clear as possible,",
        "tokens": [
          51220,
          293,
          652,
          264,
          7073,
          382,
          1850,
          382,
          1944,
          11,
          51370
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 337.36,
        "id": 115,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 334.68,
        "temperature": 0,
        "text": " I'm going to write those into the options.",
        "tokens": [
          51370,
          286,
          478,
          516,
          281,
          2464,
          729,
          666,
          264,
          3956,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 340.2,
        "id": 116,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 337.36,
        "temperature": 0,
        "text": " So how many inputs?",
        "tokens": [
          51504,
          407,
          577,
          867,
          15743,
          30,
          51646
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 341.88,
        "id": 117,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 340.2,
        "temperature": 0,
        "text": " Think about that for a second.",
        "tokens": [
          51646,
          6557,
          466,
          300,
          337,
          257,
          1150,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.19577525212214544,
        "compression_ratio": 1.7610294117647058,
        "end": 344,
        "id": 118,
        "no_speech_prob": 0.00564183434471488,
        "seek": 31456,
        "start": 341.88,
        "temperature": 0,
        "text": " The number of columns times the number of the rows",
        "tokens": [
          51730,
          440,
          1230,
          295,
          13766,
          1413,
          264,
          1230,
          295,
          264,
          13241,
          51836
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 345.08,
        "id": 119,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 344,
        "temperature": 0,
        "text": " times RGB.",
        "tokens": [
          50364,
          1413,
          31231,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 346.8,
        "id": 120,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 345.08,
        "temperature": 0,
        "text": " Maybe I would have a grayscale image.",
        "tokens": [
          50418,
          2704,
          286,
          576,
          362,
          257,
          677,
          3772,
          37088,
          3256,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 347.96,
        "id": 121,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 346.8,
        "temperature": 0,
        "text": " Maybe I could just make it.",
        "tokens": [
          50504,
          2704,
          286,
          727,
          445,
          652,
          309,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 349.84,
        "id": 122,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 347.96,
        "temperature": 0,
        "text": " I don't need a separate input for RGB.",
        "tokens": [
          50562,
          286,
          500,
          380,
          643,
          257,
          4994,
          4846,
          337,
          31231,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 350.56,
        "id": 123,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 349.84,
        "temperature": 0,
        "text": " But let's do that.",
        "tokens": [
          50656,
          583,
          718,
          311,
          360,
          300,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 351.4,
        "id": 124,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 350.56,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          50692,
          1545,
          406,
          30,
          50734
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 355.24,
        "id": 125,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 351.4,
        "temperature": 0,
        "text": " And I have the 10 by 10 in a variable called video size.",
        "tokens": [
          50734,
          400,
          286,
          362,
          264,
          1266,
          538,
          1266,
          294,
          257,
          7006,
          1219,
          960,
          2744,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 359.4,
        "id": 126,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 355.24,
        "temperature": 0,
        "text": " So let's make that video size times video size times 3.",
        "tokens": [
          50926,
          407,
          718,
          311,
          652,
          300,
          960,
          2744,
          1413,
          960,
          2744,
          1413,
          805,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 361.74,
        "id": 127,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 359.4,
        "temperature": 0,
        "text": " Let's just make a really simple classifier that's",
        "tokens": [
          51134,
          961,
          311,
          445,
          652,
          257,
          534,
          2199,
          1508,
          9902,
          300,
          311,
          51251
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 364.84,
        "id": 128,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 361.74,
        "temperature": 0,
        "text": " like I'm here or not here.",
        "tokens": [
          51251,
          411,
          286,
          478,
          510,
          420,
          406,
          510,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 366.28,
        "id": 129,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 364.84,
        "temperature": 0,
        "text": " So I'm going to make that 2.",
        "tokens": [
          51406,
          407,
          286,
          478,
          516,
          281,
          652,
          300,
          568,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.22948825073242188,
        "compression_ratio": 1.652542372881356,
        "end": 373.68,
        "id": 130,
        "no_speech_prob": 0.00005920900002820417,
        "seek": 34400,
        "start": 369.72,
        "temperature": 0,
        "text": " The task is classification.",
        "tokens": [
          51650,
          440,
          5633,
          307,
          21538,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 378.40000000000003,
        "id": 131,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 373.76,
        "temperature": 0,
        "text": " And I want to see debugging when I train the model.",
        "tokens": [
          50368,
          400,
          286,
          528,
          281,
          536,
          45592,
          562,
          286,
          3847,
          264,
          2316,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 382.40000000000003,
        "id": 132,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 378.40000000000003,
        "temperature": 0,
        "text": " Now I have my pixel brain, my neural network.",
        "tokens": [
          50600,
          823,
          286,
          362,
          452,
          19261,
          3567,
          11,
          452,
          18161,
          3209,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 385.24,
        "id": 133,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 382.40000000000003,
        "temperature": 0,
        "text": " Oops, that should be 3.",
        "tokens": [
          50800,
          21726,
          11,
          300,
          820,
          312,
          805,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 388.40000000000003,
        "id": 134,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 385.24,
        "temperature": 0,
        "text": " Let's go with my usual typical terrible interface,",
        "tokens": [
          50942,
          961,
          311,
          352,
          365,
          452,
          7713,
          7476,
          6237,
          9226,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 389.28000000000003,
        "id": 135,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 388.40000000000003,
        "temperature": 0,
        "text": " meaning no interface.",
        "tokens": [
          51100,
          3620,
          572,
          9226,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 391.44,
        "id": 136,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 389.28000000000003,
        "temperature": 0,
        "text": " And I'm just going to train the model based on when",
        "tokens": [
          51144,
          400,
          286,
          478,
          445,
          516,
          281,
          3847,
          264,
          2316,
          2361,
          322,
          562,
          51252
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 393.8,
        "id": 137,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 391.44,
        "temperature": 0,
        "text": " I press keys on the keyboard.",
        "tokens": [
          51252,
          286,
          1886,
          9317,
          322,
          264,
          10186,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 396.96000000000004,
        "id": 138,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 393.8,
        "temperature": 0,
        "text": " So I'll add a key press function.",
        "tokens": [
          51370,
          407,
          286,
          603,
          909,
          257,
          2141,
          1886,
          2445,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 399.6,
        "id": 139,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 396.96000000000004,
        "temperature": 0,
        "text": " And then I'm going to do something a little goofy here,",
        "tokens": [
          51528,
          400,
          550,
          286,
          478,
          516,
          281,
          360,
          746,
          257,
          707,
          42995,
          510,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.24439916610717774,
        "compression_ratio": 1.7049180327868851,
        "end": 402.52,
        "id": 140,
        "no_speech_prob": 0.000002123375907103764,
        "seek": 37368,
        "start": 399.6,
        "temperature": 0,
        "text": " which I'm just going to say when I press the key,",
        "tokens": [
          51660,
          597,
          286,
          478,
          445,
          516,
          281,
          584,
          562,
          286,
          1886,
          264,
          2141,
          11,
          51806
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 404.56,
        "id": 141,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 402.52,
        "temperature": 0,
        "text": " add example key.",
        "tokens": [
          50364,
          909,
          1365,
          2141,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 410.79999999999995,
        "id": 142,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 404.56,
        "temperature": 0,
        "text": " So I need a new function called add example label.",
        "tokens": [
          50466,
          407,
          286,
          643,
          257,
          777,
          2445,
          1219,
          909,
          1365,
          7645,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 413.52,
        "id": 143,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 410.79999999999995,
        "temperature": 0,
        "text": " So basically, I'm going to make the key that I press the label.",
        "tokens": [
          50778,
          407,
          1936,
          11,
          286,
          478,
          516,
          281,
          652,
          264,
          2141,
          300,
          286,
          1886,
          264,
          7645,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 414.91999999999996,
        "id": 144,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 413.52,
        "temperature": 0,
        "text": " So I'm going to press a bunch of keys",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          1886,
          257,
          3840,
          295,
          9317,
          50984
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 416.32,
        "id": 145,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 414.91999999999996,
        "temperature": 0,
        "text": " when I'm standing in front of the camera",
        "tokens": [
          50984,
          562,
          286,
          478,
          4877,
          294,
          1868,
          295,
          264,
          2799,
          51054
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 418.12,
        "id": 146,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 416.32,
        "temperature": 0,
        "text": " and then press a different key when I'm not",
        "tokens": [
          51054,
          293,
          550,
          1886,
          257,
          819,
          2141,
          562,
          286,
          478,
          406,
          51144
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 419.64,
        "id": 147,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 418.12,
        "temperature": 0,
        "text": " standing in front of the camera.",
        "tokens": [
          51144,
          4877,
          294,
          1868,
          295,
          264,
          2799,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 421.79999999999995,
        "id": 148,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 419.64,
        "temperature": 0,
        "text": " Now comes the harder work.",
        "tokens": [
          51220,
          823,
          1487,
          264,
          6081,
          589,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 425.32,
        "id": 149,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 421.79999999999995,
        "temperature": 0,
        "text": " I need to figure out how to make an array of inputs out",
        "tokens": [
          51328,
          286,
          643,
          281,
          2573,
          484,
          577,
          281,
          652,
          364,
          10225,
          295,
          15743,
          484,
          51504
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 427.84,
        "id": 150,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 425.32,
        "temperature": 0,
        "text": " of all of the pixels.",
        "tokens": [
          51504,
          295,
          439,
          295,
          264,
          18668,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 429.24,
        "id": 151,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 427.84,
        "temperature": 0,
        "text": " Luckily for me, this is something",
        "tokens": [
          51630,
          19726,
          337,
          385,
          11,
          341,
          307,
          746,
          51700
        ]
      },
      {
        "avg_logprob": -0.2297821044921875,
        "compression_ratio": 1.8408163265306123,
        "end": 430.68,
        "id": 152,
        "no_speech_prob": 0.00023782132484484464,
        "seek": 40252,
        "start": 429.24,
        "temperature": 0,
        "text": " that I have done before.",
        "tokens": [
          51700,
          300,
          286,
          362,
          1096,
          949,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 432.36,
        "id": 153,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 430.68,
        "temperature": 0,
        "text": " And in fact, I actually have some code",
        "tokens": [
          50364,
          400,
          294,
          1186,
          11,
          286,
          767,
          362,
          512,
          3089,
          50448
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 435,
        "id": 154,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 432.36,
        "temperature": 0,
        "text": " that I could pull from right in here,",
        "tokens": [
          50448,
          300,
          286,
          727,
          2235,
          490,
          558,
          294,
          510,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 437.64,
        "id": 155,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 435,
        "temperature": 0,
        "text": " which is looking at how to go through all the pixels",
        "tokens": [
          50580,
          597,
          307,
          1237,
          412,
          577,
          281,
          352,
          807,
          439,
          264,
          18668,
          50712
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 438.8,
        "id": 156,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 437.64,
        "temperature": 0,
        "text": " to draw them.",
        "tokens": [
          50712,
          281,
          2642,
          552,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 440.24,
        "id": 157,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 438.8,
        "temperature": 0,
        "text": " But here's the thing.",
        "tokens": [
          50770,
          583,
          510,
          311,
          264,
          551,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 443.68,
        "id": 158,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 440.24,
        "temperature": 0,
        "text": " I am going to do something to flatten the data.",
        "tokens": [
          50842,
          286,
          669,
          516,
          281,
          360,
          746,
          281,
          24183,
          264,
          1412,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 447.5,
        "id": 159,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 443.68,
        "temperature": 0,
        "text": " I am not going to keep the data in its original columns",
        "tokens": [
          51014,
          286,
          669,
          406,
          516,
          281,
          1066,
          264,
          1412,
          294,
          1080,
          3380,
          13766,
          51205
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 448.88,
        "id": 160,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 447.5,
        "temperature": 0,
        "text": " and rows orientation.",
        "tokens": [
          51205,
          293,
          13241,
          14764,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 451.08,
        "id": 161,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 448.88,
        "temperature": 0,
        "text": " I'm going to take the pixels and flatten them out",
        "tokens": [
          51274,
          286,
          478,
          516,
          281,
          747,
          264,
          18668,
          293,
          24183,
          552,
          484,
          51384
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 452.76,
        "id": 162,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 451.08,
        "temperature": 0,
        "text": " into one single array.",
        "tokens": [
          51384,
          666,
          472,
          2167,
          10225,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 453.76,
        "id": 163,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 452.76,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          51468,
          17795,
          437,
          30,
          51518
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 456.28000000000003,
        "id": 164,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 453.76,
        "temperature": 0,
        "text": " This is actually the problem that convolutional neural",
        "tokens": [
          51518,
          639,
          307,
          767,
          264,
          1154,
          300,
          45216,
          304,
          18161,
          51644
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 457.44,
        "id": 165,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 456.28000000000003,
        "temperature": 0,
        "text": " networks will address.",
        "tokens": [
          51644,
          9590,
          486,
          2985,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.21789895201758516,
        "compression_ratio": 1.7758620689655173,
        "end": 460.64,
        "id": 166,
        "no_speech_prob": 0.000027969255825155415,
        "seek": 43068,
        "start": 457.44,
        "temperature": 0,
        "text": " It's bad to flatten the data because its spatial arrangement",
        "tokens": [
          51702,
          467,
          311,
          1578,
          281,
          24183,
          264,
          1412,
          570,
          1080,
          23598,
          17620,
          51862
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 462.08,
        "id": 167,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 460.64,
        "temperature": 0,
        "text": " is meaningful.",
        "tokens": [
          50364,
          307,
          10995,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 465.71999999999997,
        "id": 168,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 462.08,
        "temperature": 0,
        "text": " I'll start by creating an empty array called inputs.",
        "tokens": [
          50436,
          286,
          603,
          722,
          538,
          4084,
          364,
          6707,
          10225,
          1219,
          15743,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 467.59999999999997,
        "id": 169,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 465.71999999999997,
        "temperature": 0,
        "text": " Then I'll loop through all of the pixels.",
        "tokens": [
          50618,
          1396,
          286,
          603,
          6367,
          807,
          439,
          295,
          264,
          18668,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 472.68,
        "id": 170,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 467.59999999999997,
        "temperature": 0,
        "text": " And to be safe, I should probably",
        "tokens": [
          50712,
          400,
          281,
          312,
          3273,
          11,
          286,
          820,
          1391,
          50966
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 475.12,
        "id": 171,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 472.68,
        "temperature": 0,
        "text": " say video.loadPixels.",
        "tokens": [
          50966,
          584,
          960,
          13,
          2907,
          47,
          970,
          1625,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 477.32,
        "id": 172,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 475.12,
        "temperature": 0,
        "text": " The pixels may already be loaded because I'm",
        "tokens": [
          51088,
          440,
          18668,
          815,
          1217,
          312,
          13210,
          570,
          286,
          478,
          51198
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 479.2,
        "id": 173,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 477.32,
        "temperature": 0,
        "text": " doing that for down here.",
        "tokens": [
          51198,
          884,
          300,
          337,
          760,
          510,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 481.36,
        "id": 174,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 479.2,
        "temperature": 0,
        "text": " And I could do something where if I'm drawing them,",
        "tokens": [
          51292,
          400,
          286,
          727,
          360,
          746,
          689,
          498,
          286,
          478,
          6316,
          552,
          11,
          51400
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 483.12,
        "id": 175,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 481.36,
        "temperature": 0,
        "text": " I might as well create the data here.",
        "tokens": [
          51400,
          286,
          1062,
          382,
          731,
          1884,
          264,
          1412,
          510,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 485.28,
        "id": 176,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 483.12,
        "temperature": 0,
        "text": " But I'm going to be redundant about it.",
        "tokens": [
          51488,
          583,
          286,
          478,
          516,
          281,
          312,
          40997,
          466,
          309,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.23308750890916394,
        "compression_ratio": 1.670731707317073,
        "end": 489.28,
        "id": 177,
        "no_speech_prob": 0.000038229074561968446,
        "seek": 46064,
        "start": 485.28,
        "temperature": 0,
        "text": " And I'm going to say, ah, but this is weird.",
        "tokens": [
          51596,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          3716,
          11,
          457,
          341,
          307,
          3657,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 491.32,
        "id": 178,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 489.28,
        "temperature": 0,
        "text": " Here's the weird thing.",
        "tokens": [
          50364,
          1692,
          311,
          264,
          3657,
          551,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 493.52,
        "id": 179,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 491.32,
        "temperature": 0,
        "text": " I thought I wasn't going to talk about the pixel",
        "tokens": [
          50466,
          286,
          1194,
          286,
          2067,
          380,
          516,
          281,
          751,
          466,
          264,
          19261,
          50576
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 496,
        "id": 180,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 493.52,
        "temperature": 0,
        "text": " array in this video and just refer you to the previous one.",
        "tokens": [
          50576,
          10225,
          294,
          341,
          960,
          293,
          445,
          2864,
          291,
          281,
          264,
          3894,
          472,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 498.2,
        "id": 181,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 496,
        "temperature": 0,
        "text": " But I can't escape it right now.",
        "tokens": [
          50700,
          583,
          286,
          393,
          380,
          7615,
          309,
          558,
          586,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 503.35999999999996,
        "id": 182,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 498.2,
        "temperature": 0,
        "text": " For every single pixel in an image in p5.js,",
        "tokens": [
          50810,
          1171,
          633,
          2167,
          19261,
          294,
          364,
          3256,
          294,
          280,
          20,
          13,
          25530,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 508.2,
        "id": 183,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 503.35999999999996,
        "temperature": 0,
        "text": " there are four spots in the array, a red value,",
        "tokens": [
          51068,
          456,
          366,
          1451,
          10681,
          294,
          264,
          10225,
          11,
          257,
          2182,
          2158,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 510.67999999999995,
        "id": 184,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 508.2,
        "temperature": 0,
        "text": " a green value, a blue value, and an alpha value.",
        "tokens": [
          51310,
          257,
          3092,
          2158,
          11,
          257,
          3344,
          2158,
          11,
          293,
          364,
          8961,
          2158,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 512.4399999999999,
        "id": 185,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 510.67999999999995,
        "temperature": 0,
        "text": " Alpha value for transparency.",
        "tokens": [
          51434,
          20588,
          2158,
          337,
          17131,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 514.1999999999999,
        "id": 186,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 512.4399999999999,
        "temperature": 0,
        "text": " The alpha value I can ignore because it's",
        "tokens": [
          51522,
          440,
          8961,
          2158,
          286,
          393,
          11200,
          570,
          309,
          311,
          51610
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 516.8399999999999,
        "id": 187,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 514.1999999999999,
        "temperature": 0,
        "text": " going to be 255 for everything.",
        "tokens": [
          51610,
          516,
          281,
          312,
          3552,
          20,
          337,
          1203,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.1948392242193222,
        "compression_ratio": 1.7098039215686274,
        "end": 517.8,
        "id": 188,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 48928,
        "start": 516.8399999999999,
        "temperature": 0,
        "text": " There's no transparency.",
        "tokens": [
          51742,
          821,
          311,
          572,
          17131,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 519.3599999999999,
        "id": 189,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 517.8,
        "temperature": 0,
        "text": " If I wanted to learn transparency,",
        "tokens": [
          50364,
          759,
          286,
          1415,
          281,
          1466,
          17131,
          11,
          50442
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 522.92,
        "id": 190,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 519.3599999999999,
        "temperature": 0,
        "text": " I could make that an input and have 10 by 10 times 4.",
        "tokens": [
          50442,
          286,
          727,
          652,
          300,
          364,
          4846,
          293,
          362,
          1266,
          538,
          1266,
          1413,
          1017,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 524.64,
        "id": 191,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 522.92,
        "temperature": 0,
        "text": " But I don't need to do that here.",
        "tokens": [
          50620,
          583,
          286,
          500,
          380,
          643,
          281,
          360,
          300,
          510,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 529.4399999999999,
        "id": 192,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 524.64,
        "temperature": 0,
        "text": " So in other words, pixel 0 starts here, 0, 1, 2, 3.",
        "tokens": [
          50706,
          407,
          294,
          661,
          2283,
          11,
          19261,
          1958,
          3719,
          510,
          11,
          1958,
          11,
          502,
          11,
          568,
          11,
          805,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 532.4799999999999,
        "id": 193,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 529.4399999999999,
        "temperature": 0,
        "text": " And the second pixel starts at index 4.",
        "tokens": [
          50946,
          400,
          264,
          1150,
          19261,
          3719,
          412,
          8186,
          1017,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 536.24,
        "id": 194,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 532.4799999999999,
        "temperature": 0,
        "text": " So as I'm iterating over all of the pixels,",
        "tokens": [
          51098,
          407,
          382,
          286,
          478,
          17138,
          990,
          670,
          439,
          295,
          264,
          18668,
          11,
          51286
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 539.56,
        "id": 195,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 536.24,
        "temperature": 0,
        "text": " I want to move through the array four spaces at a time.",
        "tokens": [
          51286,
          286,
          528,
          281,
          1286,
          807,
          264,
          10225,
          1451,
          7673,
          412,
          257,
          565,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 541.76,
        "id": 196,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 539.56,
        "temperature": 0,
        "text": " There's a variety of ways I could approach this.",
        "tokens": [
          51452,
          821,
          311,
          257,
          5673,
          295,
          2098,
          286,
          727,
          3109,
          341,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.19661477661132812,
        "compression_ratio": 1.611764705882353,
        "end": 544.4799999999999,
        "id": 197,
        "no_speech_prob": 0.000144259596709162,
        "seek": 51780,
        "start": 541.76,
        "temperature": 0,
        "text": " But that's going to make things easiest for me.",
        "tokens": [
          51562,
          583,
          300,
          311,
          516,
          281,
          652,
          721,
          12889,
          337,
          385,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 548.2,
        "id": 198,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 544.48,
        "temperature": 0,
        "text": " So that means right over here, this should be plus equals 4.",
        "tokens": [
          50364,
          407,
          300,
          1355,
          558,
          670,
          510,
          11,
          341,
          820,
          312,
          1804,
          6915,
          1017,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 554.04,
        "id": 199,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 548.2,
        "temperature": 0,
        "text": " Then I can say the red value is video.pixels index i.",
        "tokens": [
          50550,
          1396,
          286,
          393,
          584,
          264,
          2182,
          2158,
          307,
          960,
          13,
          79,
          970,
          1625,
          8186,
          741,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 559.6800000000001,
        "id": 200,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 556.88,
        "temperature": 0,
        "text": " The green value is at i plus 1.",
        "tokens": [
          50984,
          440,
          3092,
          2158,
          307,
          412,
          741,
          1804,
          502,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 562.12,
        "id": 201,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 559.6800000000001,
        "temperature": 0,
        "text": " And the blue value is at i plus 2.",
        "tokens": [
          51124,
          400,
          264,
          3344,
          2158,
          307,
          412,
          741,
          1804,
          568,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 563.6800000000001,
        "id": 202,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 562.12,
        "temperature": 0,
        "text": " And just to be consistent, I'm going",
        "tokens": [
          51246,
          400,
          445,
          281,
          312,
          8398,
          11,
          286,
          478,
          516,
          51324
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 567.08,
        "id": 203,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 563.6800000000001,
        "temperature": 0,
        "text": " to just put a plus 0 in there so everything lines up nicely.",
        "tokens": [
          51324,
          281,
          445,
          829,
          257,
          1804,
          1958,
          294,
          456,
          370,
          1203,
          3876,
          493,
          9594,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 570.16,
        "id": 204,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 567.08,
        "temperature": 0,
        "text": " So that's the R, G, and B values.",
        "tokens": [
          51494,
          407,
          300,
          311,
          264,
          497,
          11,
          460,
          11,
          293,
          363,
          4190,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.18911193979197535,
        "compression_ratio": 1.6666666666666667,
        "end": 573.74,
        "id": 205,
        "no_speech_prob": 0.000005682432401954429,
        "seek": 54448,
        "start": 570.16,
        "temperature": 0,
        "text": " Then I want those R, G, and B values for this particular",
        "tokens": [
          51648,
          1396,
          286,
          528,
          729,
          497,
          11,
          460,
          11,
          293,
          363,
          4190,
          337,
          341,
          1729,
          51827
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 575.74,
        "id": 206,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 573.78,
        "temperature": 0,
        "text": " pixel to go in the inputs array.",
        "tokens": [
          50366,
          19261,
          281,
          352,
          294,
          264,
          15743,
          10225,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 580.22,
        "id": 207,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 578.5,
        "temperature": 0,
        "text": " The chat is making a very good point,",
        "tokens": [
          50602,
          440,
          5081,
          307,
          1455,
          257,
          588,
          665,
          935,
          11,
          50688
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 584.42,
        "id": 208,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 580.22,
        "temperature": 0,
        "text": " which is that I have all of the stuff in an array already.",
        "tokens": [
          50688,
          597,
          307,
          300,
          286,
          362,
          439,
          295,
          264,
          1507,
          294,
          364,
          10225,
          1217,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 587.62,
        "id": 209,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 584.42,
        "temperature": 0,
        "text": " And all I'm really doing is making a slightly smaller array.",
        "tokens": [
          50898,
          400,
          439,
          286,
          478,
          534,
          884,
          307,
          1455,
          257,
          4748,
          4356,
          10225,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 589.82,
        "id": 210,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 587.62,
        "temperature": 0,
        "text": " That's removing every fourth element.",
        "tokens": [
          51058,
          663,
          311,
          12720,
          633,
          6409,
          4478,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 592.36,
        "id": 211,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 589.82,
        "temperature": 0,
        "text": " I could probably do that with the filter function or some kind",
        "tokens": [
          51168,
          286,
          727,
          1391,
          360,
          300,
          365,
          264,
          6608,
          2445,
          420,
          512,
          733,
          51295
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 593.94,
        "id": 212,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 592.36,
        "temperature": 0,
        "text": " of higher order function or maybe just",
        "tokens": [
          51295,
          295,
          2946,
          1668,
          2445,
          420,
          1310,
          445,
          51374
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 595.26,
        "id": 213,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 593.94,
        "temperature": 0,
        "text": " use the original array.",
        "tokens": [
          51374,
          764,
          264,
          3380,
          10225,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 597.3,
        "id": 214,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 595.26,
        "temperature": 0,
        "text": " So I'm not really sure why I'm doing it this way.",
        "tokens": [
          51440,
          407,
          286,
          478,
          406,
          534,
          988,
          983,
          286,
          478,
          884,
          309,
          341,
          636,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 600.2,
        "id": 215,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 597.3,
        "temperature": 0,
        "text": " But I'm going to emphasize the data preparation step.",
        "tokens": [
          51542,
          583,
          286,
          478,
          516,
          281,
          16078,
          264,
          1412,
          13081,
          1823,
          13,
          51687
        ]
      },
      {
        "avg_logprob": -0.2822755799257666,
        "compression_ratio": 1.7422680412371134,
        "end": 602.94,
        "id": 216,
        "no_speech_prob": 0.002050728304311633,
        "seek": 57374,
        "start": 600.2,
        "temperature": 0,
        "text": " So I look forward to hearing your comments about",
        "tokens": [
          51687,
          407,
          286,
          574,
          2128,
          281,
          4763,
          428,
          3053,
          466,
          51824
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 604.9000000000001,
        "id": 217,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 602.94,
        "temperature": 0,
        "text": " and maybe re-implementations of this that just",
        "tokens": [
          50364,
          293,
          1310,
          319,
          12,
          332,
          43704,
          763,
          295,
          341,
          300,
          445,
          50462
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 606.1,
        "id": 218,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 604.9000000000001,
        "temperature": 0,
        "text": " use the pixel array directly.",
        "tokens": [
          50462,
          764,
          264,
          19261,
          10225,
          3838,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 608.1400000000001,
        "id": 219,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 606.1,
        "temperature": 0,
        "text": " But I'm going to keep it this way for right now.",
        "tokens": [
          50522,
          583,
          286,
          478,
          516,
          281,
          1066,
          309,
          341,
          636,
          337,
          558,
          586,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 610.2600000000001,
        "id": 220,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 608.1400000000001,
        "temperature": 0,
        "text": " So I'm taking the R, G, and B and putting them",
        "tokens": [
          50624,
          407,
          286,
          478,
          1940,
          264,
          497,
          11,
          460,
          11,
          293,
          363,
          293,
          3372,
          552,
          50730
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 612.3000000000001,
        "id": 221,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 610.2600000000001,
        "temperature": 0,
        "text": " all into my new array.",
        "tokens": [
          50730,
          439,
          666,
          452,
          777,
          10225,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 614.82,
        "id": 222,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 612.3000000000001,
        "temperature": 0,
        "text": " Then the target is just the label,",
        "tokens": [
          50832,
          1396,
          264,
          3779,
          307,
          445,
          264,
          7645,
          11,
          50958
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 617.1800000000001,
        "id": 223,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 614.82,
        "temperature": 0,
        "text": " a single label in an array.",
        "tokens": [
          50958,
          257,
          2167,
          7645,
          294,
          364,
          10225,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 619.22,
        "id": 224,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 617.1800000000001,
        "temperature": 0,
        "text": " And I can now add this as training data.",
        "tokens": [
          51076,
          400,
          286,
          393,
          586,
          909,
          341,
          382,
          3097,
          1412,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 625.1400000000001,
        "id": 225,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 619.22,
        "temperature": 0,
        "text": " Pixel brain add data inputs target.",
        "tokens": [
          51178,
          28323,
          3567,
          909,
          1412,
          15743,
          3779,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 628.2600000000001,
        "id": 226,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 625.1400000000001,
        "temperature": 0,
        "text": " Let's console log something just to see that this is working.",
        "tokens": [
          51474,
          961,
          311,
          11076,
          3565,
          746,
          445,
          281,
          536,
          300,
          341,
          307,
          1364,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.20194018164346383,
        "compression_ratio": 1.7003891050583657,
        "end": 632.6600000000001,
        "id": 227,
        "no_speech_prob": 0.000096102237876039,
        "seek": 60294,
        "start": 628.2600000000001,
        "temperature": 0,
        "text": " So I'm going to console log the inputs.",
        "tokens": [
          51630,
          407,
          286,
          478,
          516,
          281,
          11076,
          3565,
          264,
          15743,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 636.5,
        "id": 228,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 632.66,
        "temperature": 0,
        "text": " And let's also console log the target just to see",
        "tokens": [
          50364,
          400,
          718,
          311,
          611,
          11076,
          3565,
          264,
          3779,
          445,
          281,
          536,
          50556
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 639.02,
        "id": 229,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 636.5,
        "temperature": 0,
        "text": " that something's coming out.",
        "tokens": [
          50556,
          300,
          746,
          311,
          1348,
          484,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 642.8199999999999,
        "id": 230,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 639.02,
        "temperature": 0,
        "text": " So A, yeah, we can see there's an array there.",
        "tokens": [
          50682,
          407,
          316,
          11,
          1338,
          11,
          321,
          393,
          536,
          456,
          311,
          364,
          10225,
          456,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 645.6999999999999,
        "id": 231,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 642.8199999999999,
        "temperature": 0,
        "text": " And there's the A. And now if I do B,",
        "tokens": [
          50872,
          400,
          456,
          311,
          264,
          316,
          13,
          400,
          586,
          498,
          286,
          360,
          363,
          11,
          51016
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 647.8199999999999,
        "id": 232,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 645.6999999999999,
        "temperature": 0,
        "text": " I'm getting a different array with B there.",
        "tokens": [
          51016,
          286,
          478,
          1242,
          257,
          819,
          10225,
          365,
          363,
          456,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 649.92,
        "id": 233,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 647.8199999999999,
        "temperature": 0,
        "text": " So I'm going to assume this is working.",
        "tokens": [
          51122,
          407,
          286,
          478,
          516,
          281,
          6552,
          341,
          307,
          1364,
          13,
          51227
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 652.3399999999999,
        "id": 234,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 649.92,
        "temperature": 0,
        "text": " I could say inputs.length to make sure",
        "tokens": [
          51227,
          286,
          727,
          584,
          15743,
          13,
          45390,
          281,
          652,
          988,
          51348
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 654.98,
        "id": 235,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 652.3399999999999,
        "temperature": 0,
        "text": " that that's the right idea.",
        "tokens": [
          51348,
          300,
          300,
          311,
          264,
          558,
          1558,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 656.6999999999999,
        "id": 236,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 654.98,
        "temperature": 0,
        "text": " Yeah, it's got 300 things in it.",
        "tokens": [
          51480,
          865,
          11,
          309,
          311,
          658,
          6641,
          721,
          294,
          309,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 657.6999999999999,
        "id": 237,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 656.6999999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51566,
          2264,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.20937515074206936,
        "compression_ratio": 1.5802469135802468,
        "end": 659.74,
        "id": 238,
        "no_speech_prob": 0.00001165951198345283,
        "seek": 63266,
        "start": 657.6999999999999,
        "temperature": 0,
        "text": " Next step is to train the model.",
        "tokens": [
          51616,
          3087,
          1823,
          307,
          281,
          3847,
          264,
          2316,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.2503280438874897,
        "compression_ratio": 1.5235849056603774,
        "end": 666.46,
        "id": 239,
        "no_speech_prob": 0.000001994728791032685,
        "seek": 65974,
        "start": 659.74,
        "temperature": 0,
        "text": " So I'm going to say if the key pressed is T,",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          584,
          498,
          264,
          2141,
          17355,
          307,
          314,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.2503280438874897,
        "compression_ratio": 1.5235849056603774,
        "end": 671.14,
        "id": 240,
        "no_speech_prob": 0.000001994728791032685,
        "seek": 65974,
        "start": 666.46,
        "temperature": 0,
        "text": " don't add an example, but rather train the model.",
        "tokens": [
          50700,
          500,
          380,
          909,
          364,
          1365,
          11,
          457,
          2831,
          3847,
          264,
          2316,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.2503280438874897,
        "compression_ratio": 1.5235849056603774,
        "end": 676.5,
        "id": 241,
        "no_speech_prob": 0.000001994728791032685,
        "seek": 65974,
        "start": 671.14,
        "temperature": 0,
        "text": " And let's give it, train it over 50 epochs",
        "tokens": [
          50934,
          400,
          718,
          311,
          976,
          309,
          11,
          3847,
          309,
          670,
          2625,
          30992,
          28346,
          51202
        ]
      },
      {
        "avg_logprob": -0.2503280438874897,
        "compression_ratio": 1.5235849056603774,
        "end": 678.74,
        "id": 242,
        "no_speech_prob": 0.000001994728791032685,
        "seek": 65974,
        "start": 676.5,
        "temperature": 0,
        "text": " and have a callback when it's finished training.",
        "tokens": [
          51202,
          293,
          362,
          257,
          818,
          3207,
          562,
          309,
          311,
          4335,
          3097,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2503280438874897,
        "compression_ratio": 1.5235849056603774,
        "end": 684.58,
        "id": 243,
        "no_speech_prob": 0.000001994728791032685,
        "seek": 65974,
        "start": 678.74,
        "temperature": 0,
        "text": " Let's also add an option to save the data just in case",
        "tokens": [
          51314,
          961,
          311,
          611,
          909,
          364,
          3614,
          281,
          3155,
          264,
          1412,
          445,
          294,
          1389,
          51606
        ]
      },
      {
        "avg_logprob": -0.2503280438874897,
        "compression_ratio": 1.5235849056603774,
        "end": 686.9,
        "id": 244,
        "no_speech_prob": 0.000001994728791032685,
        "seek": 65974,
        "start": 684.58,
        "temperature": 0,
        "text": " I kind of want to stop and start a bunch of times",
        "tokens": [
          51606,
          286,
          733,
          295,
          528,
          281,
          1590,
          293,
          722,
          257,
          3840,
          295,
          1413,
          51722
        ]
      },
      {
        "avg_logprob": -0.2503280438874897,
        "compression_ratio": 1.5235849056603774,
        "end": 688.58,
        "id": 245,
        "no_speech_prob": 0.000001994728791032685,
        "seek": 65974,
        "start": 686.9,
        "temperature": 0,
        "text": " and not collect the data again.",
        "tokens": [
          51722,
          293,
          406,
          2500,
          264,
          1412,
          797,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 694.74,
        "id": 246,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 690.74,
        "temperature": 0,
        "text": " And I'm ready to go, except I missed something important.",
        "tokens": [
          50414,
          400,
          286,
          478,
          1919,
          281,
          352,
          11,
          3993,
          286,
          6721,
          746,
          1021,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 696.9,
        "id": 247,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 694.74,
        "temperature": 0,
        "text": " I have emphasized before that when",
        "tokens": [
          50614,
          286,
          362,
          34068,
          949,
          300,
          562,
          50722
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 699.14,
        "id": 248,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 696.9,
        "temperature": 0,
        "text": " working with neural networks, it's",
        "tokens": [
          50722,
          1364,
          365,
          18161,
          9590,
          11,
          309,
          311,
          50834
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 701.5,
        "id": 249,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 699.14,
        "temperature": 0,
        "text": " important to normalize your data,",
        "tokens": [
          50834,
          1021,
          281,
          2710,
          1125,
          428,
          1412,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 705.14,
        "id": 250,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 701.5,
        "temperature": 0,
        "text": " to take the data that you're using as inputs or outputs,",
        "tokens": [
          50952,
          281,
          747,
          264,
          1412,
          300,
          291,
          434,
          1228,
          382,
          15743,
          420,
          23930,
          11,
          51134
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 707.58,
        "id": 251,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 705.14,
        "temperature": 0,
        "text": " look at its range, and standardize it",
        "tokens": [
          51134,
          574,
          412,
          1080,
          3613,
          11,
          293,
          3832,
          1125,
          309,
          51256
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 710.48,
        "id": 252,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 707.58,
        "temperature": 0,
        "text": " to some specific range, typically between 0 and 1",
        "tokens": [
          51256,
          281,
          512,
          2685,
          3613,
          11,
          5850,
          1296,
          1958,
          293,
          502,
          51401
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 712.5,
        "id": 253,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 710.48,
        "temperature": 0,
        "text": " or maybe between negative 1 and 1.",
        "tokens": [
          51401,
          420,
          1310,
          1296,
          3671,
          502,
          293,
          502,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 716.38,
        "id": 254,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 712.5,
        "temperature": 0,
        "text": " And it is true that ml5 will do this for you.",
        "tokens": [
          51502,
          400,
          309,
          307,
          2074,
          300,
          23271,
          20,
          486,
          360,
          341,
          337,
          291,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.20265721860139266,
        "compression_ratio": 1.6356589147286822,
        "end": 718.38,
        "id": 255,
        "no_speech_prob": 0.00008220178278861567,
        "seek": 68974,
        "start": 716.38,
        "temperature": 0,
        "text": " I could just call normalized data.",
        "tokens": [
          51696,
          286,
          727,
          445,
          818,
          48704,
          1412,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 721.3,
        "id": 256,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 718.38,
        "temperature": 0,
        "text": " But this is a nice opportunity to show that I can just",
        "tokens": [
          50364,
          583,
          341,
          307,
          257,
          1481,
          2650,
          281,
          855,
          300,
          286,
          393,
          445,
          50510
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 723.3,
        "id": 257,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 721.3,
        "temperature": 0,
        "text": " do the normalization myself.",
        "tokens": [
          50510,
          360,
          264,
          2710,
          2144,
          2059,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 726.34,
        "id": 258,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 723.3,
        "temperature": 0,
        "text": " For example, I know, this is another reason",
        "tokens": [
          50610,
          1171,
          1365,
          11,
          286,
          458,
          11,
          341,
          307,
          1071,
          1778,
          50762
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 728.38,
        "id": 259,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 726.34,
        "temperature": 0,
        "text": " to make a separate array, sort of.",
        "tokens": [
          50762,
          281,
          652,
          257,
          4994,
          10225,
          11,
          1333,
          295,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 732.34,
        "id": 260,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 728.38,
        "temperature": 0,
        "text": " I know that the range of any given pixel color",
        "tokens": [
          50864,
          286,
          458,
          300,
          264,
          3613,
          295,
          604,
          2212,
          19261,
          2017,
          51062
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 734.38,
        "id": 261,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 732.34,
        "temperature": 0,
        "text": " is between 0 and 255.",
        "tokens": [
          51062,
          307,
          1296,
          1958,
          293,
          3552,
          20,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 740.78,
        "id": 262,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 734.38,
        "temperature": 0,
        "text": " So let me take the opportunity to just divide every RGB value",
        "tokens": [
          51164,
          407,
          718,
          385,
          747,
          264,
          2650,
          281,
          445,
          9845,
          633,
          31231,
          2158,
          51484
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 744.62,
        "id": 263,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 740.78,
        "temperature": 0,
        "text": " by 255 to squash it to normalize it between 0 and 1.",
        "tokens": [
          51484,
          538,
          3552,
          20,
          281,
          30725,
          309,
          281,
          2710,
          1125,
          309,
          1296,
          1958,
          293,
          502,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.20296979173321592,
        "compression_ratio": 1.5588235294117647,
        "end": 745.66,
        "id": 264,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 71838,
        "start": 744.62,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          51676,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 749.54,
        "id": 265,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 748.42,
        "temperature": 0,
        "text": " I'm going to collect it.",
        "tokens": [
          50366,
          286,
          478,
          516,
          281,
          2500,
          309,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 751.78,
        "id": 266,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 749.54,
        "temperature": 0,
        "text": " So I'm going to press, this is a little bit silly,",
        "tokens": [
          50422,
          407,
          286,
          478,
          516,
          281,
          1886,
          11,
          341,
          307,
          257,
          707,
          857,
          11774,
          11,
          50534
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 754.26,
        "id": 267,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 751.78,
        "temperature": 0,
        "text": " but I'm going to press H for me being here",
        "tokens": [
          50534,
          457,
          286,
          478,
          516,
          281,
          1886,
          389,
          337,
          385,
          885,
          510,
          50658
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 755.26,
        "id": 268,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 754.26,
        "temperature": 0,
        "text": " in front of the camera.",
        "tokens": [
          50658,
          294,
          1868,
          295,
          264,
          2799,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 760.38,
        "id": 269,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 755.26,
        "temperature": 0,
        "text": " Then I'm going to move off to the side.",
        "tokens": [
          50708,
          1396,
          286,
          478,
          516,
          281,
          1286,
          766,
          281,
          264,
          1252,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 765.22,
        "id": 270,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 760.38,
        "temperature": 0,
        "text": " And I'm going to use N for not being in front of the camera.",
        "tokens": [
          50964,
          400,
          286,
          478,
          516,
          281,
          764,
          426,
          337,
          406,
          885,
          294,
          1868,
          295,
          264,
          2799,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 766.54,
        "id": 271,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 765.22,
        "temperature": 0,
        "text": " So I'm not here.",
        "tokens": [
          51206,
          407,
          286,
          478,
          406,
          510,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 768.66,
        "id": 272,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 766.54,
        "temperature": 0,
        "text": " And I'm just going to do a little bit right now.",
        "tokens": [
          51272,
          400,
          286,
          478,
          445,
          516,
          281,
          360,
          257,
          707,
          857,
          558,
          586,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 772.22,
        "id": 273,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 768.66,
        "temperature": 0,
        "text": " And then I'm going to hit T for train.",
        "tokens": [
          51378,
          400,
          550,
          286,
          478,
          516,
          281,
          2045,
          314,
          337,
          3847,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 775.26,
        "id": 274,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 772.22,
        "temperature": 0,
        "text": " And whoa, loss function going crazy.",
        "tokens": [
          51556,
          400,
          13310,
          11,
          4470,
          2445,
          516,
          3219,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.2636963289175461,
        "compression_ratio": 1.9212962962962963,
        "end": 777.14,
        "id": 275,
        "no_speech_prob": 0.0000640199359622784,
        "seek": 74838,
        "start": 775.26,
        "temperature": 0,
        "text": " But eventually, it gets down.",
        "tokens": [
          51708,
          583,
          4728,
          11,
          309,
          2170,
          760,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 779.66,
        "id": 276,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 777.18,
        "temperature": 0,
        "text": " It's a very small amount of data that I gave it to train.",
        "tokens": [
          50366,
          467,
          311,
          257,
          588,
          1359,
          2372,
          295,
          1412,
          300,
          286,
          2729,
          309,
          281,
          3847,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 782.74,
        "id": 277,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 779.66,
        "temperature": 0,
        "text": " But we can see that I'm getting a low loss function.",
        "tokens": [
          50490,
          583,
          321,
          393,
          536,
          300,
          286,
          478,
          1242,
          257,
          2295,
          4470,
          2445,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 787.02,
        "id": 278,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 782.74,
        "temperature": 0,
        "text": " If I had built in the inference stage to the code,",
        "tokens": [
          50644,
          759,
          286,
          632,
          3094,
          294,
          264,
          38253,
          3233,
          281,
          264,
          3089,
          11,
          50858
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 789.9,
        "id": 279,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 787.02,
        "temperature": 0,
        "text": " it would probably start to guess Dan or no Dan.",
        "tokens": [
          50858,
          309,
          576,
          1391,
          722,
          281,
          2041,
          3394,
          420,
          572,
          3394,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 791.22,
        "id": 280,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 789.9,
        "temperature": 0,
        "text": " So let's add that in.",
        "tokens": [
          51002,
          407,
          718,
          311,
          909,
          300,
          294,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 794.06,
        "id": 281,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 791.22,
        "temperature": 0,
        "text": " When I'm finished training, then I'll start classifying.",
        "tokens": [
          51068,
          1133,
          286,
          478,
          4335,
          3097,
          11,
          550,
          286,
          603,
          722,
          1508,
          5489,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 799.06,
        "id": 282,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 794.06,
        "temperature": 0,
        "text": " The first thing I need to do if I'm going to classify the video",
        "tokens": [
          51210,
          440,
          700,
          551,
          286,
          643,
          281,
          360,
          498,
          286,
          478,
          516,
          281,
          33872,
          264,
          960,
          51460
        ]
      },
      {
        "avg_logprob": -0.22455471959607354,
        "compression_ratio": 1.58984375,
        "end": 803.02,
        "id": 283,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 77714,
        "start": 799.06,
        "temperature": 0,
        "text": " is pack all of those pixels into an input array again.",
        "tokens": [
          51460,
          307,
          2844,
          439,
          295,
          729,
          18668,
          666,
          364,
          4846,
          10225,
          797,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.3002474911241646,
        "compression_ratio": 1.5076923076923077,
        "end": 811.8199999999999,
        "id": 284,
        "no_speech_prob": 0.00001241147310793167,
        "seek": 80302,
        "start": 803.62,
        "temperature": 0,
        "text": " Then I can call classify on pixel brain",
        "tokens": [
          50394,
          1396,
          286,
          393,
          818,
          33872,
          322,
          19261,
          3567,
          50804
        ]
      },
      {
        "avg_logprob": -0.3002474911241646,
        "compression_ratio": 1.5076923076923077,
        "end": 813.8199999999999,
        "id": 285,
        "no_speech_prob": 0.00001241147310793167,
        "seek": 80302,
        "start": 811.8199999999999,
        "temperature": 0,
        "text": " and add a function to receive the results.",
        "tokens": [
          50804,
          293,
          909,
          257,
          2445,
          281,
          4774,
          264,
          3542,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.3002474911241646,
        "compression_ratio": 1.5076923076923077,
        "end": 820.78,
        "id": 286,
        "no_speech_prob": 0.00001241147310793167,
        "seek": 80302,
        "start": 818.54,
        "temperature": 0,
        "text": " Let's do something fun and have it say hi to me.",
        "tokens": [
          51140,
          961,
          311,
          360,
          746,
          1019,
          293,
          362,
          309,
          584,
          4879,
          281,
          385,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.3002474911241646,
        "compression_ratio": 1.5076923076923077,
        "end": 825.26,
        "id": 287,
        "no_speech_prob": 0.00001241147310793167,
        "seek": 80302,
        "start": 820.78,
        "temperature": 0,
        "text": " So I'm going to make this label a global variable with nothing",
        "tokens": [
          51252,
          407,
          286,
          478,
          516,
          281,
          652,
          341,
          7645,
          257,
          4338,
          7006,
          365,
          1825,
          51476
        ]
      },
      {
        "avg_logprob": -0.3002474911241646,
        "compression_ratio": 1.5076923076923077,
        "end": 825.98,
        "id": 288,
        "no_speech_prob": 0.00001241147310793167,
        "seek": 80302,
        "start": 825.26,
        "temperature": 0,
        "text": " in it.",
        "tokens": [
          51476,
          294,
          309,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.3002474911241646,
        "compression_ratio": 1.5076923076923077,
        "end": 829.14,
        "id": 289,
        "no_speech_prob": 0.00001241147310793167,
        "seek": 80302,
        "start": 825.98,
        "temperature": 0,
        "text": " And then I'll say label equals results label.",
        "tokens": [
          51512,
          400,
          550,
          286,
          603,
          584,
          7645,
          6915,
          3542,
          7645,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.3002474911241646,
        "compression_ratio": 1.5076923076923077,
        "end": 832.02,
        "id": 290,
        "no_speech_prob": 0.00001241147310793167,
        "seek": 80302,
        "start": 829.14,
        "temperature": 0,
        "text": " After I draw the pixels, let's either write hi",
        "tokens": [
          51670,
          2381,
          286,
          2642,
          264,
          18668,
          11,
          718,
          311,
          2139,
          2464,
          4879,
          51814
        ]
      },
      {
        "avg_logprob": -0.26614601885686157,
        "compression_ratio": 1.3671875,
        "end": 832.9399999999999,
        "id": 291,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 83202,
        "start": 832.02,
        "temperature": 0,
        "text": " or not write hi.",
        "tokens": [
          50364,
          420,
          406,
          2464,
          4879,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.26614601885686157,
        "compression_ratio": 1.3671875,
        "end": 844.18,
        "id": 292,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 83202,
        "start": 839.22,
        "temperature": 0,
        "text": " So just to see that this works, let's make the label h to start.",
        "tokens": [
          50724,
          407,
          445,
          281,
          536,
          300,
          341,
          1985,
          11,
          718,
          311,
          652,
          264,
          7645,
          276,
          281,
          722,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.26614601885686157,
        "compression_ratio": 1.3671875,
        "end": 846.22,
        "id": 293,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 83202,
        "start": 844.18,
        "temperature": 0,
        "text": " It says hi.",
        "tokens": [
          50972,
          467,
          1619,
          4879,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.26614601885686157,
        "compression_ratio": 1.3671875,
        "end": 848.6999999999999,
        "id": 294,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 83202,
        "start": 846.22,
        "temperature": 0,
        "text": " Now let's not make it h.",
        "tokens": [
          51074,
          823,
          718,
          311,
          406,
          652,
          309,
          276,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.26614601885686157,
        "compression_ratio": 1.3671875,
        "end": 850.26,
        "id": 295,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 83202,
        "start": 848.6999999999999,
        "temperature": 0,
        "text": " And let's go through the whole process.",
        "tokens": [
          51198,
          400,
          718,
          311,
          352,
          807,
          264,
          1379,
          1399,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.26614601885686157,
        "compression_ratio": 1.3671875,
        "end": 855.86,
        "id": 296,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 83202,
        "start": 855.18,
        "temperature": 0,
        "text": " Train the model.",
        "tokens": [
          51522,
          28029,
          264,
          2316,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 861.86,
        "id": 297,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 855.86,
        "temperature": 0,
        "text": " And it says hi.",
        "tokens": [
          50364,
          400,
          309,
          1619,
          4879,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 870.58,
        "id": 298,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 865.3000000000001,
        "temperature": 0,
        "text": " I forgot to classify the video again after I get the results.",
        "tokens": [
          50836,
          286,
          5298,
          281,
          33872,
          264,
          960,
          797,
          934,
          286,
          483,
          264,
          3542,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 872.46,
        "id": 299,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 870.58,
        "temperature": 0,
        "text": " So it classified it only once.",
        "tokens": [
          51100,
          407,
          309,
          20627,
          309,
          787,
          1564,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 874.58,
        "id": 300,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 872.46,
        "temperature": 0,
        "text": " And I want to then recursively continue",
        "tokens": [
          51194,
          400,
          286,
          528,
          281,
          550,
          20560,
          3413,
          2354,
          51300
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 879.26,
        "id": 301,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 874.58,
        "temperature": 0,
        "text": " after I get the results to classify the video again.",
        "tokens": [
          51300,
          934,
          286,
          483,
          264,
          3542,
          281,
          33872,
          264,
          960,
          797,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 881.02,
        "id": 302,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 879.26,
        "temperature": 0,
        "text": " Just so we can finish this out, I actually",
        "tokens": [
          51534,
          1449,
          370,
          321,
          393,
          2413,
          341,
          484,
          11,
          286,
          767,
          51622
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 882.6800000000001,
        "id": 303,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 881.02,
        "temperature": 0,
        "text": " saved all of the data I collected",
        "tokens": [
          51622,
          6624,
          439,
          295,
          264,
          1412,
          286,
          11087,
          51705
        ]
      },
      {
        "avg_logprob": -0.294233040376143,
        "compression_ratio": 1.7191011235955056,
        "end": 884.74,
        "id": 304,
        "no_speech_prob": 0.0011878963559865952,
        "seek": 85586,
        "start": 882.6800000000001,
        "temperature": 0,
        "text": " to a file called data.json.",
        "tokens": [
          51705,
          281,
          257,
          3991,
          1219,
          1412,
          13,
          73,
          3015,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 890.74,
        "id": 305,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 884.74,
        "temperature": 0,
        "text": " And now I can say pixel brain load data, data.json.",
        "tokens": [
          50364,
          400,
          586,
          286,
          393,
          584,
          19261,
          3567,
          3677,
          1412,
          11,
          1412,
          13,
          73,
          3015,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 897.78,
        "id": 306,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 890.74,
        "temperature": 0,
        "text": " And when the data is loaded, then I can train the model.",
        "tokens": [
          50664,
          400,
          562,
          264,
          1412,
          307,
          13210,
          11,
          550,
          286,
          393,
          3847,
          264,
          2316,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 902.54,
        "id": 307,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 900.66,
        "temperature": 0,
        "text": " So now I've eliminated the need to collect",
        "tokens": [
          51160,
          407,
          586,
          286,
          600,
          20308,
          264,
          643,
          281,
          2500,
          51254
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 904.14,
        "id": 308,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 902.54,
        "temperature": 0,
        "text": " the data every single time.",
        "tokens": [
          51254,
          264,
          1412,
          633,
          2167,
          565,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 906.34,
        "id": 309,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 904.14,
        "temperature": 0,
        "text": " Let's run the sketch.",
        "tokens": [
          51334,
          961,
          311,
          1190,
          264,
          12325,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 908.42,
        "id": 310,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 906.34,
        "temperature": 0,
        "text": " It's going to train the model.",
        "tokens": [
          51444,
          467,
          311,
          516,
          281,
          3847,
          264,
          2316,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 910.22,
        "id": 311,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 908.42,
        "temperature": 0,
        "text": " I don't really even need to see this.",
        "tokens": [
          51548,
          286,
          500,
          380,
          534,
          754,
          643,
          281,
          536,
          341,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 911.26,
        "id": 312,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 910.22,
        "temperature": 0,
        "text": " And it gets to the end.",
        "tokens": [
          51638,
          400,
          309,
          2170,
          281,
          264,
          917,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.24347472190856934,
        "compression_ratio": 1.6195652173913044,
        "end": 911.76,
        "id": 313,
        "no_speech_prob": 0.000014738957361259963,
        "seek": 88474,
        "start": 911.26,
        "temperature": 0,
        "text": " Hi.",
        "tokens": [
          51690,
          2421,
          13,
          51715
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 915.24,
        "id": 314,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 914.74,
        "temperature": 0,
        "text": " Hi.",
        "tokens": [
          50364,
          2421,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 922.46,
        "id": 315,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 920.2,
        "temperature": 0,
        "text": " Hooray.",
        "tokens": [
          50637,
          3631,
          284,
          320,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 924.78,
        "id": 316,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 922.46,
        "temperature": 0,
        "text": " I'm pleased that that worked.",
        "tokens": [
          50750,
          286,
          478,
          10587,
          300,
          300,
          2732,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 926.26,
        "id": 317,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 924.78,
        "temperature": 0,
        "text": " I probably shouldn't, but I just want",
        "tokens": [
          50866,
          286,
          1391,
          4659,
          380,
          11,
          457,
          286,
          445,
          528,
          50940
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 928.78,
        "id": 318,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 926.26,
        "temperature": 0,
        "text": " to try having three outputs.",
        "tokens": [
          50940,
          281,
          853,
          1419,
          1045,
          23930,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 930.54,
        "id": 319,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 928.78,
        "temperature": 0,
        "text": " So let's try something similar to what",
        "tokens": [
          51066,
          407,
          718,
          311,
          853,
          746,
          2531,
          281,
          437,
          51154
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 933.66,
        "id": 320,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 930.54,
        "temperature": 0,
        "text": " I did in my previous videos using Teachable Machine",
        "tokens": [
          51154,
          286,
          630,
          294,
          452,
          3894,
          2145,
          1228,
          26816,
          712,
          22155,
          51310
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 935.14,
        "id": 321,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 933.66,
        "temperature": 0,
        "text": " to train an image classifier.",
        "tokens": [
          51310,
          281,
          3847,
          364,
          3256,
          1508,
          9902,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 938.22,
        "id": 322,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 935.14,
        "temperature": 0,
        "text": " And we'll look at this ukulele, coding train notebook,",
        "tokens": [
          51384,
          400,
          321,
          603,
          574,
          412,
          341,
          26769,
          2271,
          306,
          11,
          17720,
          3847,
          21060,
          11,
          51538
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 939.94,
        "id": 323,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 938.22,
        "temperature": 0,
        "text": " and a Rubik's Cube.",
        "tokens": [
          51538,
          293,
          257,
          10518,
          1035,
          311,
          33003,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.27517867971349647,
        "compression_ratio": 1.478448275862069,
        "end": 942.38,
        "id": 324,
        "no_speech_prob": 0.0001881410280475393,
        "seek": 91474,
        "start": 939.94,
        "temperature": 0,
        "text": " So let me collect a whole lot of data.",
        "tokens": [
          51624,
          407,
          718,
          385,
          2500,
          257,
          1379,
          688,
          295,
          1412,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.3039834119271541,
        "compression_ratio": 1.3795620437956204,
        "end": 946.18,
        "id": 325,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 94238,
        "start": 942.38,
        "temperature": 0,
        "text": " I'm going to press U for ukulele, R for Rubik's Cube,",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          1886,
          624,
          337,
          26769,
          2271,
          306,
          11,
          497,
          337,
          10518,
          1035,
          311,
          33003,
          11,
          50554
        ]
      },
      {
        "avg_logprob": -0.3039834119271541,
        "compression_ratio": 1.3795620437956204,
        "end": 947.3,
        "id": 326,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 94238,
        "start": 946.18,
        "temperature": 0,
        "text": " and N for notebook.",
        "tokens": [
          50554,
          293,
          426,
          337,
          21060,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.3039834119271541,
        "compression_ratio": 1.3795620437956204,
        "end": 961.98,
        "id": 327,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 94238,
        "start": 957.42,
        "temperature": 0,
        "text": " Save the data in case I need it later and train the model.",
        "tokens": [
          51116,
          15541,
          264,
          1412,
          294,
          1389,
          286,
          643,
          309,
          1780,
          293,
          3847,
          264,
          2316,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.3039834119271541,
        "compression_ratio": 1.3795620437956204,
        "end": 967.34,
        "id": 328,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 94238,
        "start": 961.98,
        "temperature": 0,
        "text": " So now, ukulele, U, N for notebook.",
        "tokens": [
          51344,
          407,
          586,
          11,
          26769,
          2271,
          306,
          11,
          624,
          11,
          426,
          337,
          21060,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.3039834119271541,
        "compression_ratio": 1.3795620437956204,
        "end": 972.3,
        "id": 329,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 94238,
        "start": 970.46,
        "temperature": 0,
        "text": " And can we get an R?",
        "tokens": [
          51768,
          400,
          393,
          321,
          483,
          364,
          497,
          30,
          51860
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 975.4599999999999,
        "id": 330,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 972.74,
        "temperature": 0,
        "text": " I stood to the side when I was doing the Rubik's Cube.",
        "tokens": [
          50386,
          286,
          9371,
          281,
          264,
          1252,
          562,
          286,
          390,
          884,
          264,
          10518,
          1035,
          311,
          33003,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 978.0999999999999,
        "id": 331,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 975.4599999999999,
        "temperature": 0,
        "text": " So that is pretty important.",
        "tokens": [
          50522,
          407,
          300,
          307,
          1238,
          1021,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 980.42,
        "id": 332,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 978.0999999999999,
        "temperature": 0,
        "text": " So it's not working so well.",
        "tokens": [
          50654,
          407,
          309,
          311,
          406,
          1364,
          370,
          731,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 981.5799999999999,
        "id": 333,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 980.42,
        "temperature": 0,
        "text": " So that's not a surprise.",
        "tokens": [
          50770,
          407,
          300,
          311,
          406,
          257,
          6365,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 983.66,
        "id": 334,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 981.5799999999999,
        "temperature": 0,
        "text": " I don't expect it to work that well.",
        "tokens": [
          50828,
          286,
          500,
          380,
          2066,
          309,
          281,
          589,
          300,
          731,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 988.02,
        "id": 335,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 983.66,
        "temperature": 0,
        "text": " This is why I want to make another video that",
        "tokens": [
          50932,
          639,
          307,
          983,
          286,
          528,
          281,
          652,
          1071,
          960,
          300,
          51150
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 993.0999999999999,
        "id": 336,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 988.02,
        "temperature": 0,
        "text": " covers how to take this very simplistic approach",
        "tokens": [
          51150,
          10538,
          577,
          281,
          747,
          341,
          588,
          44199,
          3109,
          51404
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 995.42,
        "id": 337,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 993.0999999999999,
        "temperature": 0,
        "text": " and improve upon it by adding something",
        "tokens": [
          51404,
          293,
          3470,
          3564,
          309,
          538,
          5127,
          746,
          51520
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 998.3,
        "id": 338,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 995.42,
        "temperature": 0,
        "text": " called a convolutional layer.",
        "tokens": [
          51520,
          1219,
          257,
          45216,
          304,
          4583,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 1000.02,
        "id": 339,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 998.3,
        "temperature": 0,
        "text": " So what is a convolution?",
        "tokens": [
          51664,
          407,
          437,
          307,
          257,
          45216,
          30,
          51750
        ]
      },
      {
        "avg_logprob": -0.17232061858870026,
        "compression_ratio": 1.7107438016528926,
        "end": 1002.18,
        "id": 340,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 97230,
        "start": 1000.02,
        "temperature": 0,
        "text": " What are the elements of a convolutional layer?",
        "tokens": [
          51750,
          708,
          366,
          264,
          4959,
          295,
          257,
          45216,
          304,
          4583,
          30,
          51858
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1004.8199999999999,
        "id": 341,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1003.06,
        "temperature": 0,
        "text": " How do I add one with the ml5 library?",
        "tokens": [
          50408,
          1012,
          360,
          286,
          909,
          472,
          365,
          264,
          23271,
          20,
          6405,
          30,
          50496
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1006.8199999999999,
        "id": 342,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1004.8199999999999,
        "temperature": 0,
        "text": " That's what I'm going to start looking at",
        "tokens": [
          50496,
          663,
          311,
          437,
          286,
          478,
          516,
          281,
          722,
          1237,
          412,
          50596
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1009.5,
        "id": 343,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1006.8199999999999,
        "temperature": 0,
        "text": " in the next section of videos.",
        "tokens": [
          50596,
          294,
          264,
          958,
          3541,
          295,
          2145,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1013.8599999999999,
        "id": 344,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1009.5,
        "temperature": 0,
        "text": " But before I go, I can't resist just doing one more thing.",
        "tokens": [
          50730,
          583,
          949,
          286,
          352,
          11,
          286,
          393,
          380,
          4597,
          445,
          884,
          472,
          544,
          551,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1017.3,
        "id": 345,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1013.8599999999999,
        "temperature": 0,
        "text": " Because I really want to look at and demonstrate to you",
        "tokens": [
          50948,
          1436,
          286,
          534,
          528,
          281,
          574,
          412,
          293,
          11698,
          281,
          291,
          51120
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1021.2199999999999,
        "id": 346,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1017.3,
        "temperature": 0,
        "text": " what happens if you change from using pixel input",
        "tokens": [
          51120,
          437,
          2314,
          498,
          291,
          1319,
          490,
          1228,
          19261,
          4846,
          51316
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1023.9399999999999,
        "id": 347,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1021.2199999999999,
        "temperature": 0,
        "text": " to perform a classification to a regression.",
        "tokens": [
          51316,
          281,
          2042,
          257,
          21538,
          281,
          257,
          24590,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1028.02,
        "id": 348,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1023.9399999999999,
        "temperature": 0,
        "text": " So I took code from my previous examples that just demonstrated",
        "tokens": [
          51452,
          407,
          286,
          1890,
          3089,
          490,
          452,
          3894,
          5110,
          300,
          445,
          18772,
          51656
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1029.8999999999999,
        "id": 349,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1028.02,
        "temperature": 0,
        "text": " how ml5 and regression works.",
        "tokens": [
          51656,
          577,
          23271,
          20,
          293,
          24590,
          1985,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.22309365272521972,
        "compression_ratio": 1.6485507246376812,
        "end": 1031.86,
        "id": 350,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 100218,
        "start": 1029.8999999999999,
        "temperature": 0,
        "text": " And I changed the task to a regression.",
        "tokens": [
          51750,
          400,
          286,
          3105,
          264,
          5633,
          281,
          257,
          24590,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1033.58,
        "id": 351,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1031.86,
        "temperature": 0,
        "text": " I had to lower the learning rate.",
        "tokens": [
          50364,
          286,
          632,
          281,
          3126,
          264,
          2539,
          3314,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1035.9799999999998,
        "id": 352,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1033.58,
        "temperature": 0,
        "text": " Thank you to the live chat who helped me figure this out",
        "tokens": [
          50450,
          1044,
          291,
          281,
          264,
          1621,
          5081,
          567,
          4254,
          385,
          2573,
          341,
          484,
          50570
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1038.1799999999998,
        "id": 353,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1035.9799999999998,
        "temperature": 0,
        "text": " after over an hour of debugging.",
        "tokens": [
          50570,
          934,
          670,
          364,
          1773,
          295,
          45592,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1040.9399999999998,
        "id": 354,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1038.1799999999998,
        "temperature": 0,
        "text": " I had to lower the learning rate to get this to work.",
        "tokens": [
          50680,
          286,
          632,
          281,
          3126,
          264,
          2539,
          3314,
          281,
          483,
          341,
          281,
          589,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1042.6599999999999,
        "id": 355,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1040.9399999999998,
        "temperature": 0,
        "text": " I trained the model with me standing",
        "tokens": [
          50818,
          286,
          8895,
          264,
          2316,
          365,
          385,
          4877,
          50904
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1044.5,
        "id": 356,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1042.6599999999999,
        "temperature": 0,
        "text": " in different positions associated",
        "tokens": [
          50904,
          294,
          819,
          8432,
          6615,
          50996
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1047.5,
        "id": 357,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1044.5,
        "temperature": 0,
        "text": " with a different frequency that p5 sound library played.",
        "tokens": [
          50996,
          365,
          257,
          819,
          7893,
          300,
          280,
          20,
          1626,
          6405,
          3737,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1050.54,
        "id": 358,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1047.5,
        "temperature": 0,
        "text": " And you can see some examples of me training it over here.",
        "tokens": [
          51146,
          400,
          291,
          393,
          536,
          512,
          5110,
          295,
          385,
          3097,
          309,
          670,
          510,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1054.4199999999998,
        "id": 359,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1050.54,
        "temperature": 0,
        "text": " And now I am going to run it and see if it works.",
        "tokens": [
          51298,
          400,
          586,
          286,
          669,
          516,
          281,
          1190,
          309,
          293,
          536,
          498,
          309,
          1985,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2694875543767756,
        "compression_ratio": 1.7596899224806202,
        "end": 1058.1799999999998,
        "id": 360,
        "no_speech_prob": 0.00018814047507476062,
        "seek": 103186,
        "start": 1054.4199999999998,
        "temperature": 0,
        "text": " And that will be the end of this video.",
        "tokens": [
          51492,
          400,
          300,
          486,
          312,
          264,
          917,
          295,
          341,
          960,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1059.3400000000001,
        "id": 361,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1058.18,
        "temperature": 0,
        "text": " So I had saved the data.",
        "tokens": [
          50364,
          407,
          286,
          632,
          6624,
          264,
          1412,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1062.0600000000002,
        "id": 362,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1059.3400000000001,
        "temperature": 0,
        "text": " And now it's training the model.",
        "tokens": [
          50422,
          400,
          586,
          309,
          311,
          3097,
          264,
          2316,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1063.74,
        "id": 363,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1062.0600000000002,
        "temperature": 0,
        "text": " And as soon as it finishes training,",
        "tokens": [
          50558,
          400,
          382,
          2321,
          382,
          309,
          23615,
          3097,
          11,
          50642
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1064.8200000000002,
        "id": 364,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1063.74,
        "temperature": 0,
        "text": " you'll be able to hear.",
        "tokens": [
          50642,
          291,
          603,
          312,
          1075,
          281,
          1568,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1065.3200000000002,
        "id": 365,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1064.8200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50696,
          10468,
          13,
          50721
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1065.8200000000002,
        "id": 366,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1065.3200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50721,
          10468,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1066.3200000000002,
        "id": 367,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1065.8200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50746,
          10468,
          13,
          50771
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1066.8200000000002,
        "id": 368,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1066.3200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50771,
          10468,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1067.3200000000002,
        "id": 369,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1066.8200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50796,
          10468,
          13,
          50821
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1067.8200000000002,
        "id": 370,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1067.3200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50821,
          10468,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1068.3200000000002,
        "id": 371,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1067.8200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50846,
          10468,
          13,
          50871
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1068.8200000000002,
        "id": 372,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1068.3200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50871,
          10468,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1069.3200000000002,
        "id": 373,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1068.8200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50896,
          10468,
          13,
          50921
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1069.8200000000002,
        "id": 374,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1069.3200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50921,
          10468,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1070.3200000000002,
        "id": 375,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1069.8200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50946,
          10468,
          13,
          50971
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1070.8200000000002,
        "id": 376,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1070.3200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50971,
          10468,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1071.3200000000002,
        "id": 377,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1070.8200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50996,
          10468,
          13,
          51021
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1071.8200000000002,
        "id": 378,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1071.3200000000002,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          51021,
          10468,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1072.3400000000001,
        "id": 379,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1071.8200000000002,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51046,
          1057,
          558,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1075.1000000000001,
        "id": 380,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1072.3400000000001,
        "temperature": 0,
        "text": " So I will leave that to you as an exercise.",
        "tokens": [
          51072,
          407,
          286,
          486,
          1856,
          300,
          281,
          291,
          382,
          364,
          5380,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1077.46,
        "id": 381,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1075.1000000000001,
        "temperature": 0,
        "text": " I'll obviously include the link to the code",
        "tokens": [
          51210,
          286,
          603,
          2745,
          4090,
          264,
          2113,
          281,
          264,
          3089,
          51328
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1079.1000000000001,
        "id": 382,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1077.46,
        "temperature": 0,
        "text": " for this in the video's description",
        "tokens": [
          51328,
          337,
          341,
          294,
          264,
          960,
          311,
          3855,
          51410
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1081.22,
        "id": 383,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1079.1000000000001,
        "temperature": 0,
        "text": " or on the web page on thecodingtrain.com",
        "tokens": [
          51410,
          420,
          322,
          264,
          3670,
          3028,
          322,
          264,
          66,
          8616,
          83,
          7146,
          13,
          1112,
          51516
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1082.38,
        "id": 384,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1081.22,
        "temperature": 0,
        "text": " with this particular video.",
        "tokens": [
          51516,
          365,
          341,
          1729,
          960,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1083.74,
        "id": 385,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1082.38,
        "temperature": 0,
        "text": " I can come back and implement it.",
        "tokens": [
          51574,
          286,
          393,
          808,
          646,
          293,
          4445,
          309,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1085.54,
        "id": 386,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1083.74,
        "temperature": 0,
        "text": " You can go find the link to the live stream",
        "tokens": [
          51642,
          509,
          393,
          352,
          915,
          264,
          2113,
          281,
          264,
          1621,
          4309,
          51732
        ]
      },
      {
        "avg_logprob": -0.2852333311050657,
        "compression_ratio": 1.8759124087591241,
        "end": 1087.9,
        "id": 387,
        "no_speech_prob": 0.000379981443984434,
        "seek": 105818,
        "start": 1085.54,
        "temperature": 0,
        "text": " where I spent over an hour implementing it.",
        "tokens": [
          51732,
          689,
          286,
          4418,
          670,
          364,
          1773,
          18114,
          309,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1089.7,
        "id": 388,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1087.94,
        "temperature": 0,
        "text": " But I'll leave that to you as an exercise.",
        "tokens": [
          50366,
          583,
          286,
          603,
          1856,
          300,
          281,
          291,
          382,
          364,
          5380,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1091.6200000000001,
        "id": 389,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1089.7,
        "temperature": 0,
        "text": " See if any of you follow this video",
        "tokens": [
          50454,
          3008,
          498,
          604,
          295,
          291,
          1524,
          341,
          960,
          50550
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1093.38,
        "id": 390,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1091.6200000000001,
        "temperature": 0,
        "text": " and have image classification working,",
        "tokens": [
          50550,
          293,
          362,
          3256,
          21538,
          1364,
          11,
          50638
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1095.18,
        "id": 391,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1093.38,
        "temperature": 0,
        "text": " can you change it to a regression",
        "tokens": [
          50638,
          393,
          291,
          1319,
          309,
          281,
          257,
          24590,
          50728
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1097.94,
        "id": 392,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1095.18,
        "temperature": 0,
        "text": " and have it control something with continuous output?",
        "tokens": [
          50728,
          293,
          362,
          309,
          1969,
          746,
          365,
          10957,
          5598,
          30,
          50866
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1099.1000000000001,
        "id": 393,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1097.94,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50866,
          2264,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1099.6000000000001,
        "id": 394,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1099.1000000000001,
        "temperature": 0,
        "text": " Woo.",
        "tokens": [
          50924,
          10468,
          13,
          50949
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1102.1000000000001,
        "id": 395,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1099.6000000000001,
        "temperature": 0,
        "text": " If you made it this far, thank you.",
        "tokens": [
          50949,
          759,
          291,
          1027,
          309,
          341,
          1400,
          11,
          1309,
          291,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1103.98,
        "id": 396,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1102.1000000000001,
        "temperature": 0,
        "text": " And I will be back and start to talk",
        "tokens": [
          51074,
          400,
          286,
          486,
          312,
          646,
          293,
          722,
          281,
          751,
          51168
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1105.7800000000002,
        "id": 397,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1103.98,
        "temperature": 0,
        "text": " about convolutional neural networks, what",
        "tokens": [
          51168,
          466,
          45216,
          304,
          18161,
          9590,
          11,
          437,
          51258
        ]
      },
      {
        "avg_logprob": -0.2857333538579006,
        "compression_ratio": 1.536480686695279,
        "end": 1107.42,
        "id": 398,
        "no_speech_prob": 0.00024156244762707502,
        "seek": 108790,
        "start": 1105.7800000000002,
        "temperature": 0,
        "text": " they mean in the next video.",
        "tokens": [
          51258,
          436,
          914,
          294,
          264,
          958,
          960,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.7023514111836752,
        "compression_ratio": 0.5555555555555556,
        "end": 1109.1000000000001,
        "id": 399,
        "no_speech_prob": 0.23038674890995026,
        "seek": 110742,
        "start": 1107.42,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50370,
          1044,
          291,
          13,
          50448
        ]
      }
    ],
    "transcription": " And you thought we were done with the ML5 neural network tutorials. But no, there is one more because I am leading to something. I am going to, you will soon see in this playlist, a section on convolutional neural networks. But before I get to convolutional neural networks, I want to look at reasons why a convolutional layer, I have to answer this question, like what is a convolution? I've got to get to that. But before I get to that, I want to just see why they exist in the first place. So I want to start with another scenario for training your own neural network. That scenario is an image classifier. Now, you might rightfully be sitting there saying to yourself, you've done videos on image classifiers before. And in fact, I have. The very beginning of this whole series was about using a pre-trained model for an image classifier. And guess what? That pre-trained model had convolutional layers in it. So I want to now take the time to unpack what that means more and look at how you could train your own convolutional neural network. Again, first though, let's just think about how we would make an image classifier with what we have so far. We have an image. And that image is being sent into an ML5 neural network. And out of that neural network comes either a classification or regression. And in fact, we could do an image regression. And I would love to do that. But let me start with a classifier because I think it's a little simpler to think about and consider. So maybe it comes out with one of two things, either a cat or a dog and some type of confidence score. I previously zoomed in on the ML5 neural network and looked at what's inside. We have this hidden layer with some number of units and an output layer, which in this case would have just two if there's two classes. Everything is connected. And then there are the inputs. With PostNet, you might recall there were 34 inputs because there were 17 points on my body, each with an xy position. What are these? Let's just say for the sake of argument that this image is 10 by 10 pixels. So I could consider every single pixel to be an individual input into this ML5 neural network. But each pixel has three channels, an R, G, and B. So that would make 100 times 3 inputs, 300 inputs. That's reasonable. So this is actually what I want to implement. Take the idea of a two-layer neural network to perform classification, the same thing I've done in previous videos, but this time use as the input the actual raw pixels. Can we get meaningful results from just doing that? After we do that, I want to return back to here and talk about why this is inadequate, or not necessarily inadequate, but how this can be improved on by adding another layer. So this layer won't, sorry, the inputs will still be there. We're always going to have the inputs. The hidden layer will still be there, and the output layer will still be there. But I want to insert right in here something called a convolutional layer. And I want to do a convolutional, a two-dimensional convolutional layer. So I will come back. You want to just skip to that next video, if and when it exists. That's where we'll start talking about that. Let's just get this working as a frame of reference. I'm going to start with some pre-written code. All this does, it's a simple p5.js sketch that opens a connection to the webcam, resizes it to 10 by 10 pixels, and then draws a rectangle in the canvas for each and every pixel. So this could be unfamiliar to you. How do you look at an image in JavaScript in p5 and address every single pixel individually? If that's unfamiliar to you, I would refer to my video on that topic that's appearing over next to me right now. And you could go take a look at that and then come back here. But really, this is just looking at every x and y position, getting the RGB values, filling a rectangle, and drawing it. So what I want to do next is think about how do I configure this ml5 neural network, which expects that 10 by 10 image as its input. I'm going to make a variable called pixelBrain. And pixelBrain will be a new ml5 neural network. I should have mentioned that you can find the link to the code that I'm starting with in case you wanted to code along with me. Both the finished code and the code I'm starting with will be in this video's description. So to create a neural network, I call the neural network function and give it a set of options. One thing I should mention is while in all the videos I've done so far, I've said that you need to specify the number of inputs and the number of outputs to configure your neural network. The truth is ml5 is set up to infer the total number of inputs and outputs based on the data you're training it with. But to be really explicit about things and make the tutorial as clear as possible, I'm going to write those into the options. So how many inputs? Think about that for a second. The number of columns times the number of the rows times RGB. Maybe I would have a grayscale image. Maybe I could just make it. I don't need a separate input for RGB. But let's do that. Why not? And I have the 10 by 10 in a variable called video size. So let's make that video size times video size times 3. Let's just make a really simple classifier that's like I'm here or not here. So I'm going to make that 2. The task is classification. And I want to see debugging when I train the model. Now I have my pixel brain, my neural network. Oops, that should be 3. Let's go with my usual typical terrible interface, meaning no interface. And I'm just going to train the model based on when I press keys on the keyboard. So I'll add a key press function. And then I'm going to do something a little goofy here, which I'm just going to say when I press the key, add example key. So I need a new function called add example label. So basically, I'm going to make the key that I press the label. So I'm going to press a bunch of keys when I'm standing in front of the camera and then press a different key when I'm not standing in front of the camera. Now comes the harder work. I need to figure out how to make an array of inputs out of all of the pixels. Luckily for me, this is something that I have done before. And in fact, I actually have some code that I could pull from right in here, which is looking at how to go through all the pixels to draw them. But here's the thing. I am going to do something to flatten the data. I am not going to keep the data in its original columns and rows orientation. I'm going to take the pixels and flatten them out into one single array. Guess what? This is actually the problem that convolutional neural networks will address. It's bad to flatten the data because its spatial arrangement is meaningful. I'll start by creating an empty array called inputs. Then I'll loop through all of the pixels. And to be safe, I should probably say video.loadPixels. The pixels may already be loaded because I'm doing that for down here. And I could do something where if I'm drawing them, I might as well create the data here. But I'm going to be redundant about it. And I'm going to say, ah, but this is weird. Here's the weird thing. I thought I wasn't going to talk about the pixel array in this video and just refer you to the previous one. But I can't escape it right now. For every single pixel in an image in p5.js, there are four spots in the array, a red value, a green value, a blue value, and an alpha value. Alpha value for transparency. The alpha value I can ignore because it's going to be 255 for everything. There's no transparency. If I wanted to learn transparency, I could make that an input and have 10 by 10 times 4. But I don't need to do that here. So in other words, pixel 0 starts here, 0, 1, 2, 3. And the second pixel starts at index 4. So as I'm iterating over all of the pixels, I want to move through the array four spaces at a time. There's a variety of ways I could approach this. But that's going to make things easiest for me. So that means right over here, this should be plus equals 4. Then I can say the red value is video.pixels index i. The green value is at i plus 1. And the blue value is at i plus 2. And just to be consistent, I'm going to just put a plus 0 in there so everything lines up nicely. So that's the R, G, and B values. Then I want those R, G, and B values for this particular pixel to go in the inputs array. The chat is making a very good point, which is that I have all of the stuff in an array already. And all I'm really doing is making a slightly smaller array. That's removing every fourth element. I could probably do that with the filter function or some kind of higher order function or maybe just use the original array. So I'm not really sure why I'm doing it this way. But I'm going to emphasize the data preparation step. So I look forward to hearing your comments about and maybe re-implementations of this that just use the pixel array directly. But I'm going to keep it this way for right now. So I'm taking the R, G, and B and putting them all into my new array. Then the target is just the label, a single label in an array. And I can now add this as training data. Pixel brain add data inputs target. Let's console log something just to see that this is working. So I'm going to console log the inputs. And let's also console log the target just to see that something's coming out. So A, yeah, we can see there's an array there. And there's the A. And now if I do B, I'm getting a different array with B there. So I'm going to assume this is working. I could say inputs.length to make sure that that's the right idea. Yeah, it's got 300 things in it. OK. Next step is to train the model. So I'm going to say if the key pressed is T, don't add an example, but rather train the model. And let's give it, train it over 50 epochs and have a callback when it's finished training. Let's also add an option to save the data just in case I kind of want to stop and start a bunch of times and not collect the data again. And I'm ready to go, except I missed something important. I have emphasized before that when working with neural networks, it's important to normalize your data, to take the data that you're using as inputs or outputs, look at its range, and standardize it to some specific range, typically between 0 and 1 or maybe between negative 1 and 1. And it is true that ml5 will do this for you. I could just call normalized data. But this is a nice opportunity to show that I can just do the normalization myself. For example, I know, this is another reason to make a separate array, sort of. I know that the range of any given pixel color is between 0 and 255. So let me take the opportunity to just divide every RGB value by 255 to squash it to normalize it between 0 and 1. Let's see if this works. I'm going to collect it. So I'm going to press, this is a little bit silly, but I'm going to press H for me being here in front of the camera. Then I'm going to move off to the side. And I'm going to use N for not being in front of the camera. So I'm not here. And I'm just going to do a little bit right now. And then I'm going to hit T for train. And whoa, loss function going crazy. But eventually, it gets down. It's a very small amount of data that I gave it to train. But we can see that I'm getting a low loss function. If I had built in the inference stage to the code, it would probably start to guess Dan or no Dan. So let's add that in. When I'm finished training, then I'll start classifying. The first thing I need to do if I'm going to classify the video is pack all of those pixels into an input array again. Then I can call classify on pixel brain and add a function to receive the results. Let's do something fun and have it say hi to me. So I'm going to make this label a global variable with nothing in it. And then I'll say label equals results label. After I draw the pixels, let's either write hi or not write hi. So just to see that this works, let's make the label h to start. It says hi. Now let's not make it h. And let's go through the whole process. Train the model. And it says hi. I forgot to classify the video again after I get the results. So it classified it only once. And I want to then recursively continue after I get the results to classify the video again. Just so we can finish this out, I actually saved all of the data I collected to a file called data.json. And now I can say pixel brain load data, data.json. And when the data is loaded, then I can train the model. So now I've eliminated the need to collect the data every single time. Let's run the sketch. It's going to train the model. I don't really even need to see this. And it gets to the end. Hi. Hi. Hooray. I'm pleased that that worked. I probably shouldn't, but I just want to try having three outputs. So let's try something similar to what I did in my previous videos using Teachable Machine to train an image classifier. And we'll look at this ukulele, coding train notebook, and a Rubik's Cube. So let me collect a whole lot of data. I'm going to press U for ukulele, R for Rubik's Cube, and N for notebook. Save the data in case I need it later and train the model. So now, ukulele, U, N for notebook. And can we get an R? I stood to the side when I was doing the Rubik's Cube. So that is pretty important. So it's not working so well. So that's not a surprise. I don't expect it to work that well. This is why I want to make another video that covers how to take this very simplistic approach and improve upon it by adding something called a convolutional layer. So what is a convolution? What are the elements of a convolutional layer? How do I add one with the ml5 library? That's what I'm going to start looking at in the next section of videos. But before I go, I can't resist just doing one more thing. Because I really want to look at and demonstrate to you what happens if you change from using pixel input to perform a classification to a regression. So I took code from my previous examples that just demonstrated how ml5 and regression works. And I changed the task to a regression. I had to lower the learning rate. Thank you to the live chat who helped me figure this out after over an hour of debugging. I had to lower the learning rate to get this to work. I trained the model with me standing in different positions associated with a different frequency that p5 sound library played. And you can see some examples of me training it over here. And now I am going to run it and see if it works. And that will be the end of this video. So I had saved the data. And now it's training the model. And as soon as it finishes training, you'll be able to hear. Woo. Woo. Woo. Woo. Woo. Woo. Woo. Woo. Woo. Woo. Woo. Woo. Woo. Woo. All right. So I will leave that to you as an exercise. I'll obviously include the link to the code for this in the video's description or on the web page on thecodingtrain.com with this particular video. I can come back and implement it. You can go find the link to the live stream where I spent over an hour implementing it. But I'll leave that to you as an exercise. See if any of you follow this video and have image classification working, can you change it to a regression and have it control something with continuous output? OK. Woo. If you made it this far, thank you. And I will be back and start to talk about convolutional neural networks, what they mean in the next video. Thank you.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:49:15.903335Z",
  "started_at": "2023-09-26T21:49:15.921638Z",
  "completed_at": "2023-09-26T21:53:32.537688Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=UaKab6h9Z0I",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 256.61605
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/qazp3gbb4um3eutyzrr7qy6fai/cancel",
    "get": "https://api.replicate.com/v1/predictions/qazp3gbb4um3eutyzrr7qy6fai"
  }
}